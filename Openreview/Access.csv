title,abstract
socially aware synthetic data generation for suicidal ideation detection using large language models,"Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation."
hope: holistic stt-ram architecture exploration framework for future cross-platform analysis,"Spin Transfer Torque Random Access Memory (STT-RAM) is an emerging Non-Volatile Memory (NVM) technology that has garnered attention to overcome the drawbacks of conventional CMOS-based technologies. However, such technologies must be evaluated before deployment under real workloads and architecture. But there is a lack of available open-source STT-RAM-based system evaluation framework, which hampers research and experimentation and impacts the adoption of STT-RAM in a system. This paper proposes a novel, extendable STT-RAM memory controller design integrated inside the gem5 simulator. Our framework enables understanding various aspects of STT-RAM, i.e., power, delay, clock cycles, energy, and system throughput. We will open-source our HOPE framework, which will fuel research and aid in accelerating the development of future system architectures based on STT-RAM. It will also facilitate the user for further tool enhancement."
stretching the limits of mri—stretchable and modular coil array using conductive thread technology,"Objective: We propose a modular stretchable coil design using conductive threads and commercially available embroidery machines. The coil design increases customizability of coil arrays for individual patients and each body part. Methods: Eight rectangular coils were constructed with custom-fabricated stretchable tinsel copper threads incorporated onto textile. Tune, match, and detune circuits were incorporated on the coil. A hook-and-loop mechanism was used to attach and decouple the modular coils. Phantom and in vivo scans at various anatomical flexion angles were acquired to highlight performance, and a temperature test was performed to verify safety. Results: In vivo MRI experiments demonstrate high sensitivity and coverage of each anatomy. As the coils are stretched, the sensitive volume increases at a rate of 10.93 mL/cm2. The SNR reduction of a single coil was greater during compression than when stretched, but this did not affect image quality for the array. The modularity of the array allows for adaptability for any anatomy with simple on-demand adjustment to the number and position of coil elements. Conclusion: The images demonstrated high sensitivity and coverage of the stretchable array for various anatomies and flexion angles. Stretching the coils increases the sensitive volume, allowing for a larger region to be effectively imaged. The resonance shift and SNR decrease during stretch and compression support further investigation of methods to reduce frequency shift in stretchable coils. Significance: The proposed array design allows for highly stretchable, flexible, modular, and conformal patient-centered coils that allow for increased imaging quality, greater comfort, and rapid production."
traffic divergence theory: an analysis formalism for dynamic networks,"Traffic dynamics is universally crucial in analyzing and designing almost any network. This article introduces a novel theoretical approach to analyzing network traffic dynamics. This theory’s machinery is based on the notion of traffic divergence, which captures the flow (im)balance of network nodes and links. It features various analytical probes to investigate both spatial and temporal traffic dynamics. In particular, the maximal traffic distribution in a network can be characterized by spatial traffic divergence rate, which reveals the relative difference among node traffic divergence. To illustrate the usefulness, we apply the theory to two network-driven problems: throughput estimation of data center networks and power-optimized communication planning for robot networks, and show the merits of the proposed theory through simulations."
coronary artery disease classification with different lesion degree ranges based on deep learning,"Invasive Coronary Angiography (ICA) images are considered the gold standard for assessing the state of the coronary arteries. Deep learning classification methods are widely used and well-developed in different areas where medical imaging evaluation has an essential impact due to the development of computer-aided diagnosis systems that can support physicians in their clinical procedures. In this paper, a new performance analysis of deep learning methods for binary ICA classification with different lesion degrees is reported. To reach this goal, an annotated dataset of ICA images containing the ground truth, the location of lesions, and seven possible severity degrees ranging between 0% and 100% was employed. The ICA images were divided into “lesion” or “non-lesion” patches. We aim to study how binary classification performance is affected by the different lesion degrees considered in the positive class. Therefore, five Convolutional Neural Network architectures – DenseNet-201, MobileNet-V2, NasNet-Mobile, ResNet-18, and ResNet-50 – were trained with different input images where different lesion degree ranges were gradually incorporated until considering the seven lesion degrees. Besides, four types of experiments with and without data augmentation were designed, whose F-measure and Area Under Curve (AUC) were computed. Reported results achieved an F-measure and AUC of 92.7% and 98.1%, respectively. However, lesion classification is highly affected by the degree of the lesion intended to be classified, with 15% less accuracy when < 99% lesion patches are present."
a domain translation framework with an adversarial denoising diffusion model to generate synthetic datasets of echocardiography images,"Currently, medical image domain translation operations show a high demand from researchers and clinicians. Amongst other capabilities, this task allows the generation of new medical images with sufficiently high image quality, making them clinically relevant. Deep Learning (DL) architectures, most specifically deep generative models, are widely used to generate and translate images from one domain to another. The proposed framework relies on an adversarial Denoising Diffusion Model (DDM) to synthesize echocardiography images and perform domain translation. Contrary to Generative Adversarial Networks (GANs), DDMs are able to generate high quality image samples with a large diversity. If a DDM is combined with a GAN, this ability to generate new data is completed at an even faster sampling time. In this work we trained an adversarial DDM combined with a GAN to learn the reverse denoising process, relying on a guide image, making sure relevant anatomical structures of each echocardiography image were kept and represented on the generated image samples. For several domain translation operations, the results verified that such generative model was able to synthesize high quality image samples: MSE: 11.50 ± 3.69, PSNR (dB): 30.48 ± 0.09, SSIM: 0.47 ± 0.03. The proposed method showed high generalization ability, introducing a framework to create echocardiography images suitable to be used for clinical research purposes."
identifying banking transaction descriptions via support vector machine short-text classification based on a specialized labelled corpus,"Short texts are omnipresent in real-time news, social network commentaries, etc. Traditional text representation methods have been successfully applied to self-contained documents of medium size. However, information in short texts is often insufficient, due, for example, to the use of mnemonics, which makes them hard to classify. Therefore, the particularities of specific domains must be exploited. In this article we describe a novel system that combines Natural Language Processing techniques with Machine Learning algorithms to classify banking transaction descriptions for personal finance management, a problem that was not previously considered in the literature. We trained and tested that system on a labelled dataset with real customer transactions that will be available to other researchers on request. Motivated by existing solutions in spam detection, we also propose a short text similarity detector to reduce training set size based on the Jaccard distance. Experimental results with a two-stage classifier combining this detector with a SVM indicate a high accuracy in comparison with alternative approaches, taking into account complexity and computing time. Finally, we present a use case with a personal finance application, CoinScrap, which is available at Google Play and App Store."
"explainable predictive maintenance: a survey of current methods, challenges and opportunities","Predictive maintenance is a well studied collection of techniques that aims to prolong the life of a mechanical system by using artificial intelligence and machine learning to predict the optimal time to perform maintenance. The methods allow maintainers of systems and hardware to reduce financial and time costs of upkeep. As these methods are adopted for more serious and potentially life-threatening applications, the human operators need trust the predictive system. This attracts the field of Explainable AI (XAI) to introduce explainability and interpretability into the predictive system. XAI brings methods to the field of predictive maintenance that can amplify trust in the users while maintaining well-performing systems. This survey on explainable predictive maintenance (XPM) discusses and presents the current methods of XAI as applied to predictive maintenance while following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) 2020 guidelines. We categorize the different XPM methods into groups that follow the XAI literature. Additionally, we include current challenges and a discussion on future research directions in XPM."
methods and strategies for improving the novel view synthesis quality of neural radiation field,"Neural Radiation Field (NeRF) technology can learn a 3D implicit model of a scene from 2D images and synthesize realistic novel view images. This technology has received widespread attention from the industry and has good application prospects. In response to the problem that the rendering quality of NeRF images needs to be improved, many researchers have proposed various methods to improve the rendering quality in the past three years. The latest relevant papers are classified and reviewed, the technical principles behind quality improvement are analyzed, and the future evolution direction of quality improvement methods is discussed. This study can help researchers quickly understand the current state and evolutionary context of technology in this field, which is helpful in inspiring the development of more efficient algorithms and promoting the application of NeRF technology in related fields."
seqnas: neural architecture search for event sequence classification,"Neural Architecture Search (NAS) methods are widely used in various industries to obtain high-quality, task-specific solutions with minimal human intervention. Event Sequences (EvS) find widespread use in various industrial applications, including churn prediction, customer segmentation, fraud detection, and fault diagnosis, among others. Such data consist of categorical and real-valued components with irregular timestamps. Despite the usefulness of NAS methods, previous approaches only have been applied to other domains: images, texts or time series. Our work addresses this limitation by introducing a novel NAS algorithm — SeqNAS, specifically designed for event sequence classification. We develop a simple yet expressive search space that leverages commonly used building blocks for event sequence classification, including multi-head self attention, convolutions, and recurrent cells. To perform the search, we adopt sequential Bayesian Optimization and utilize previously trained models as an ensemble of teachers to augment knowledge distillation. As a result of our work, we demonstrate that our method surpasses state-of-the-art NAS methods and popular architectures suitable for sequence classification and holds great potential for various industrial applications."
contrastcad: contrastive learning-based representation learning for computer-aided design models,"The success of Transformer-based models has encouraged many researchers to learn CAD models using sequence-based approaches. However, learning CAD models is still a challenge, because they can be represented as complex shapes with long construction sequences. Furthermore, the same CAD model can be expressed using different CAD construction sequences. We propose a novel contrastive learning-based approach, named ContrastCAD, that effectively captures semantic information within the construction sequences of the CAD model. ContrastCAD generates augmented views using dropout techniques without altering the shape of the CAD model. We also propose a new CAD data augmentation method, called a Random Replace and Extrude (RRE) method, to enhance the learning performance of the model when training an imbalanced training CAD dataset. Experimental results show that the proposed RRE augmentation method significantly enhances the learning performance of Transformer-based autoencoders, even for complex CAD models having very long construction sequences. The proposed ContrastCAD model is shown to be robust to permutation changes of construction sequences and performs better representation learning by generating representation spaces where similar CAD models are more closely clustered. Our codes are available at https://github.com/cm8908/ContrastCAD."
blockchain-based management for organ donation and transplantation,"Today’s organ donation and transplantation systems pose different requirements and challenges in terms of registration, donor-recipient matching, organ removal, organ delivery, and transplantation with legal, clinical, ethical, and technical constraints. Therefore, an end-to-end organ donation and transplantation system is required to guarantee a fair and efficient process to enhance patient experience and trust. In this paper, we propose a private Ethereum blockchain-based solution to enable organ donation and transplantation management in a manner that is fully decentralized, secure, traceable, auditable, private, and trustworthy. We develop smart contracts and present six algorithms along with their implementation, testing, and validation details. We evaluate the performance of the proposed solution by performing privacy, security, and confidentiality analyses as well as comparing our solution with the existing solutions. We make the smart contract code publicly available on Github."
detection of financial opportunities in micro-blogging data with a stacked classification system,"Micro-blogging sources such as the Twitter social network provide valuable real-time data for market prediction models. Investors’ opinions in this network follow the fluctuations of the stock markets and often include educated speculations on market opportunities that may have impact on the actions of other investors. In view of this, we propose a novel system to detect positive predictions in tweets, a type of financial emotions which we term “opportunities” that are akin to “anticipation” in Plutchik’s theory. Specifically, we seek a high detection precision to present a financial operator a substantial amount of such tweets while differentiating them from the rest of financial emotions in our system. We achieve it with a three-layer stacked Machine Learning classification system with sophisticated features that result from applying Natural Language Processing techniques to extract valuable linguistic information. Experimental results on a dataset that has been manually annotated with financial emotion and ticker occurrence tags demonstrate that our system yields satisfactory and competitive performance in financial opportunity detection, with precision values up to 83%. This promising outcome endorses the usability of our system to support investors’ decision making."
adaptive prognostic malfunction based processor for autonomous landing guidance assistance system using fpga,"The demand for more developed and agile urban taxi drones is increasing rapidly nowadays to sustain crowded cities and their traffic issues. The critical factor for spreading such technology could be related to the safety criteria that must be considered. One of the most critical safety aspects for such vertical and/or Short Take-Off and Landing (V/STOL) drones is related to safety during the landing stage, in which most of the recent flight accidents have occurred. This paper focused on solving this issue by proposing decentralized processing cores that could improve the landing failure rate by depending on a Fuzzy Logic System (FLS) and additional Digital Signal Processing (DSP) elements. Also, the proposed system will enhance the safety factor during the landing stages by adding a self-awareness feature in case a certain sensor malfunction occurs using the proposed Adaptive Prognostic Malfunction Unit (APMU). This proposed coarse-grained Autonomous Landing Guidance Assistance System (ALGAS4) processing architecture has been optimized using different optimization techniques. The ALGAS4 architecture has been designed completely using VHDL, and the targeted FPGA was the INTEL Cyclone V 5CGXFC9D6F27C7 chip. According to the synthesis findings of the INTEL Quartus Prime software, the maximum working frequency of the ALGAS4 system is 278.24 MHz. In addition, the proposed ALGAS4 system could maintain a maximum computing performance of approximately 74.85 GOPS while using just 166.56 mW for dynamic and I/O power dissipation."
modeling and characterizing service interference in dynamic infrastructures,"Performance interference can occur when various services are executed over the same physical infrastructure in a cloud system. This can lead to performance degradation compared to the execution of services in isolation. This work proposes a Confirmatory Factor Analysis (CFA)-based model to estimate performance interference across containers, caused by the use of CPU, memory and IO across a number of co-hosted applications. The approach provides resource characterization through human comprehensible indices expressed as time series, so the interference in the entire execution lifetime of a service can be analyzed. Our experiments, based on the combination of real services with different profiles executed in Docker containers, suggest that our model can accurately predict the overall execution time, for different service combinations. The approach can be used by a service designer to identify phases, during the execution life-cycle of a service, that are likely to lead to a greater degree of interference, and to ensure that only complementary services are hosted on the same physical machine. Interference-awareness of this kind will enable more intelligent resource management and scheduling for cloud systems, and may be used to dynamically modify scheduling decisions."
leveraging machine learning for wi-fi-based environmental continuous two-factor authentication,"The traditional two-factor authentication (2FA) methods primarily rely on the user manually entering a code or token during the authentication process. This can be burdensome and time-consuming, particularly for users who must be authenticated frequently. To tackle this challenge, we present a novel 2FA approach replacing the user’s input with decisions made by Machine Learning (ML) that continuously verifies the user’s identity with zero effort. Our system exploits unique environmental features associated with the user, such as beacon frame characteristics and Received Signal Strength Indicator (RSSI) values from Wi-Fi Access Points (APs). These features are gathered and analyzed in real-time by our ML algorithm to ascertain the user’s identity. For enhanced security, our system mandates that the user’s two devices (i.e., a login device and a mobile device) be situated within a predetermined proximity before granting access. This precaution ensures that unauthorized users cannot access sensitive information or systems, even with the correct login credentials. Through experimentation, we have demonstrated our system’s effectiveness in determining the location of the user’s devices based on beacon frame characteristics and RSSI values, achieving an accuracy of 92.4%. Additionally, we conducted comprehensive security analysis experiments to evaluate the proposed 2FA system’s resilience against various cyberattacks. Our findings indicate that the system exhibits robustness and reliability in the face of these threats. The scalability, flexibility, and adaptability of our system render it a promising option for organizations and users seeking a secure and convenient authentication system."
a lumped-parameter model of the cardiovascular system response for evaluating automated fluid resuscitation systems,"Physiological closed-loop controlled (PCLC) medical devices, such as those designed for blood pressure regulation, can be tested for safety and efficacy in real-world clinical settings. However, relying solely on limited animal and clinical studies may not capture the diverse range of physiological conditions. Credible mathematical models can complement these studies by allowing the testing of the device against simulated patient scenarios. This research involves the development and validation of a low-order lumped-parameter mathematical model of the cardiovascular system’s response to fluid perturbation. The model takes rates of hemorrhage and fluid infusion as inputs and provides hematocrit and blood volume, heart rate, stroke volume, cardiac output and mean arterial blood pressure as outputs. The model was calibrated using data from 27 sheep subjects, and its predictive capability was evaluated through a leave-one-out cross-validation procedure, followed by independent validation using 12 swine subjects. Our findings showed small model calibration error against the training dataset, with the normalized root-mean-square error (NRMSE) less than 10% across all variables. The mathematical model and virtual patient cohort generation tool demonstrated a high level of predictive capability and successfully generated a sufficient number of subjects that closely resembled the test dataset. The average NRMSE for the best virtual subject, across two distinct samples of virtual subjects, was below 12.7% and 11.9% for the leave-one-out cross-validation and independent validation dataset. These findings suggest that the model and virtual cohort generator are suitable for simulating patient populations under fluid perturbation, indicating their potential value in PCLC medical device evaluation."
latentcolorization: latent diffusion-based speaker video colorization,"While current research predominantly focuses on image-based colorization, the domain of video-based colorization remains relatively unexplored. Many existing video colorization techniques operate frame-by-frame, often overlooking the critical aspect of temporal coherence between successive frames. This approach can result in inconsistencies across frames, leading to undesirable effects like flickering or abrupt color transitions between frames. To address these challenges, we combine the generative capabilities of a fine-tuned latent diffusion model with an autoregressive conditioning mechanism to ensure temporal consistency in automatic speaker video colorization. We demonstrate strong improvements on established quality metrics compared to existing methods, namely, PSNR, SSIM, FID, FVD, NIQE and BRISQUE. Specifically, we achieve an 18% improvement in performance when FVD is employed as the evaluation metric. Furthermore, we performed a subjective study, where users preferred LatentColorization to the existing state-of-the-art DeOldify 80% of the time. Our dataset combines conventional datasets and videos from television/movies. A short demonstration of our results can be seen in some example videos available at https://youtu.be/vDbzsZdFuxM."
efpb: efficient fair payment based on blockchain for outsourcing services in cloud computing,"Despite the maturity of cloud services (e.g., outsourcing of computational tasks), a number of operational challenges remain. For example, how do we ensure trust between outsourcers and workers in a zero-trust environment? While a number of blockchain-based solutions that eliminate the reliance on trusted third parties have been presented, many of these existing approaches do not achieve robust fairness and/or support compatibility with other systems. In this paper, we propose an efficient fair payment system using blockchain (EFPB), designed to achieve robust fairness and compatibility. Specifically, EFPB comprises a number of cryptographic building blocks, mainly: one-way accumulator (RSA-based construction), stealth address and symmetric encryption. We then evaluate the performance of EFPB to demonstrate that it is more efficient and low-cost than other competing schemes, as well as presenting a comparative summary of functionalities."
coordinated allocation of radio resources to wi-fi and cellular technologies in shared unlicensed frequencies,"Wireless connectivity is essential for industrial production processes and workflow management. Moreover, the connectivity requirements of industrial devices, which are usually long-term investments, are diverse and require different radio interfaces. In this regard, the 3GPP has studied how to support heterogeneous radio access technologies (RATs) such as Wi-Fi and unlicensed cellular technologies in 5G core networks. In some cases, these technologies coexist in the same spectrum. Dynamic spectrum sharing (DSS), which has already been proven to increase spectrum efficiency in licensed bands, can also be applied to this scenario. In this paper, we propose two solutions for mobile network operators (MNOs) or service providers to dynamically divide (multiplex) the radio resources of a shared channel between a Wi-Fi basic service set (BSS) and one or several carriers of scheduled wireless networks, such as cellular technologies, with a configurable level of sharing granularity. These solutions do not require modifications to the current commercial off-the-shelf (COTS) end devices. We adapt the existing IEEE 802.11 procedures to notify the Wi-Fi stations that they must share channels with different access networks. We demonstrate that our dynamic sharing proposals are also advantageous over direct coexistence and evaluate each of them quantitatively and qualitatively to determine when one or the other is preferable. The evaluation is particularized for IEEE 802.11ac and long-term evolution (LTE) license assisted access (LAA), but the solutions can be easily extended to 5G new radio-unlicensed (5G NR-U) or to any other wireless technology in which the network side schedules end device transmissions."
harvesting energy from soil-air temperature differences for batteryless iot devices: a case study,"The temperature difference between soil and air holds the potential to generate energy to power many low-power IoT devices. However, there is a lack of studies in the literature that explore the nuances of soil-air thermal energy harvesting. This paper offers a comprehensive discussion on soil-air thermal energy harvesting. We engineer a custom Soil-air Thermoelectric Generator (SoTEG) that incorporates an off-the-shelf TEG and an efficient heat transfer network. A detailed discussion of the design and analysis of SoTEG is presented along with a simulation model which can be used to simulate the performance of the harvester under different ambient conditions. Investigations using the model and results gathered from experiments demonstrate that the SoTEG has a heat transfer efficiency of 34.5% with room for improvement and can power a load from temperature differences as low as 3 °C between soil and air, or 1 °C across the TEG. Power generated by SoTEG at 3 °C difference amounts to <inline-formula> <tex-math notation= LaTeX >$\mathrm {110~\mu { W} }$ </tex-math></inline-formula> or a power density of 11.58 mW/m2. When connected to a Power Management Unit (PMU), the combined system generates around <inline-formula> <tex-math notation= LaTeX >$\mathrm {30~\mu { W} }$ </tex-math></inline-formula> at 3 °C. During a 14-day outdoor deployment in a winter month, the maximum power generated by the combined system is <inline-formula> <tex-math notation= LaTeX >$\mathrm {337~\mu { W} }$ </tex-math></inline-formula> when the temperature difference across the TEG is 2.75 °C. Additionally, the model analysis reveals that the weather conditions have an impact on the harvester. While Solar radiation enhances power generation, wind can either improve or diminish the harvested energy depending on whether it is day or night."
entertainment chatbot for the digital inclusion of elderly people without abstraction capabilities,"Current language processing technologies allow the creation of conversational chatbot platforms. Even though artificial intelligence is still too immature to support satisfactory user experience in many mass market domains, conversational interfaces have found their way into ad hoc applications such as call centres and online shopping assistants. However, they have not been applied so far to social inclusion of elderly people, who are particularly vulnerable to the digital divide. Many of them relieve their loneliness with traditional media such as TV and radio, which are known to create a feeling of companionship. In this paper we present the EBER chatbot, designed to reduce the digital gap for the elderly. EBER reads news in the background and adapts its responses to the user’s mood. Its novelty lies in the concept of “intelligent radio”, according to which, instead of simplifying a digital information system to make it accessible to the elderly, a traditional channel they find familiar -background news- is augmented with interactions via voice dialogues. We make it possible by combining Artificial Intelligence Modelling Language, automatic Natural Language Generation and Sentiment Analysis. The system allows accessing digital content of interest by combining words extracted from user answers to chatbot questions with keywords extracted from the news items. This approach permits defining metrics of the abstraction capabilities of the users depending on a spatial representation of the word space. To prove the suitability of the proposed solution we present results of real experiments conducted with elderly people that provided valuable insights. Our approach was considered satisfactory during the tests and improved the information search capabilities of the participants."
quantum optimization methods for satellite mission planning,"Satellite mission planning for Earth observation satellites is a combinatorial optimization problem that consists of selecting the optimal subset of imaging requests, subject to constraints, to be fulfilled during an orbit pass of a satellite. The ever-growing amount of satellites in orbit underscores the need to operate them efficiently, which requires solving many instances of the problem in short periods of time. However, current classical algorithms often fail to find the global optimum or take too long to execute. Here, we approach the problem from a quantum computing point of view, which offers a promising alternative that could lead to significant improvements in solution quality or execution speed in the future. To this end, we study a planning problem with a variety of intricate constraints and discuss methods to encode them for quantum computers. Additionally, we experimentally assess the performance of quantum annealing and the quantum approximate optimization algorithm on a realistic and diverse dataset. Our results identify key aspects like graph connectivity and constraint structure that influence the performance of the methods. We explore the limits of today’s quantum algorithms and hardware, providing bounds on the problems that can be currently solved successfully and showing how the solution degrades as the complexity grows. This work aims to serve as a baseline for further research in the field and establish realistic expectations on current quantum optimization capabilities."
cardamom plant disease detection approach using efficientnetv2,"Cardamom is a queen of spices. It is indigenously grown in the evergreen forests of Karnataka, Kerala, Tamil Nadu, and the northeastern states of India. India is the third largest producer of cardamom. Plant diseases cause a catastrophic influence on food production safety; they reduce the eminence and quantum of agricultural products. Plant diseases may cause significantly high loss or no harvest in dreadful cases. Various diseases and pests affect the growth of cardamom plants at different stages and crop yields. This study concentrated on two diseases of cardamom plants, Colletotrichum Blight and Phyllosticta Leaf Spot of cardamom and three diseases of grape, Black Rot, ESCA, and Isariopsis Leaf Spot. Various methods have been proposed for plant disease detection, and deep learning has become the preferred method because of its spectacular accomplishment. In this study, U2-Net was used to remove the unwanted background of an input image by selecting multiscale features. This work proposes a cardamom plant disease detection approach using the EfficientNetV2 model. A comprehensive set of experiments was carried out to ascertain the performance of the proposed approach and compare it with other models such as EfficientNet and Convolutional Neural Network (CNN). The experimental results showed that the proposed approach achieved a detection accuracy of 98.26%."
statistical and machine learning models for predicting fire and other emergency events in the city of edmonton,"Emergency events in a city cause considerable economic loss to individuals, their families, and the community. Accurate and timely prediction of events can help the emergency fire and rescue services in preparing for and mitigating the consequences of emergency events. In this paper, we present a systematic development of predictive models for various types of emergency events in the City of Edmonton, Canada. We present methods for (i) data collection and dataset development; (ii) descriptive analysis of each event type and its characteristics at different spatiotemporal levels; (iii) feature analysis and selection based on correlation coefficient analysis and feature importance analysis; and (iv) development of prediction models for the likelihood of occurrence of each event type at different temporal and spatial resolutions. We analyze the association of event types with socioeconomic and demographic data at the neighborhood level, identify a set of predictors for each event type, and develop predictive models with negative binomial regression. We conduct evaluations at neighborhood and fire station service area levels. Our results show that the models perform well for most of the event types with acceptable prediction errors for weekly and monthly periods. The evaluation shows that the prediction accuracy is consistent at the level of the fire station, so the predictions can be used in management by fire rescue service departments for planning resource allocation for these time periods. We also examine the impact of the COVID-19 pandemic on the occurrence of events and on the accuracy of event predictor models. Our findings show that COVID-19 had a significant impact on the performance of the event prediction models."
autogcn-toward generic human activity recognition with neural architecture search,"This paper introduces AutoGCN, a generic Neural Architecture Search (NAS) algorithm for Human Activity Recognition (HAR) using Graph Convolution Networks (GCNs). HAR has enjoyed increased attention due to advances in deep learning, increased data availability, and enhanced computational capabilities. Concurrently, GCNs have shown promising abilities in modeling relationships between body key points in a skeletal graph. Typically, domain experts develop dataset-specific GCN-based methods, which limits their applicability beyond the specific context. AutoGCN seeks to address this limitation by simultaneously searching for the ideal hyperparameters and architecture combination within a versatile search space using a reinforcement controller while balancing optimal exploration and exploitation behavior with a knowledge reservoir during the search process. We conduct extensive experiments on two large datasets focused on skeleton-based action recognition to assess the proposed algorithm’s performance. Our experimental results demonstrate the effectiveness of AutoGCN in constructing optimal GCN architectures for HAR, outperforming conventional NAS and GCN methods, as well as random search. These findings highlight the significance of a diverse search space and an expressive input representation to achieve good model performance and generalizability."
distributed maze exploration using multiple agents and optimal goal assignment,"Robotic exploration has long captivated researchers aiming to map complex environments efficiently. Techniques such as potential fields and frontier exploration have traditionally been employed in this pursuit, primarily focusing on solitary agents. Recent advancements have shifted towards optimizing exploration efficiency through multiagent systems. However, many existing approaches overlook critical real-world factors, such as broadcast range limitations, communication costs, and coverage overlap. This paper addresses these gaps by proposing a distributed maze exploration strategy (CU-LVP) that assumes constrained broadcast ranges and utilizes Voronoi diagrams for better area partitioning. By adapting traditional multiagent methods to distributed environments with limited broadcast ranges, this study evaluates their performance across diverse maze topologies, demonstrating the efficacy and practical applicability of the proposed method. The code and experimental results supporting this study are available in the following repository: https://github.com/manouslinard/multiagent-exploration/."
hiris: an airborne sonar sensor with a 1024 channel microphone array for in-air acoustic imaging,"Airborne 3D imaging using ultrasound is a promising sensing modality for robotic applications in harsh environments. Over the last decade, several high-performance systems have been proposed in the literature. Most of these sensors use a reduced aperture microphone array, leading to artifacts in the resulting acoustic images. This paper presents a novel in-air ultrasound sensor that incorporates 1024 microphones, in a 32-by-32 uniform rectangular array, in combination with a distributed embedded hardware design to perform the data acquisition. Using a broadband Minimum Variance Distortionless Response (MVDR) beamformer with Forward-Backward Spatial Smoothing (FB-SS), the sensor is able to create both 2D and 3D ultrasound images of the full-frontal hemisphere with high angular accuracy with up to 70 $\mathrm { \text {dB}}$ main lobe to side lobe ratioin the array response in a single-source scenario. This paper describes both the hardware infrastructure needed to obtain such highly detailed acoustical images, as well as the signal processing chain needed to convert the raw acoustic data into said images. Utilizing this novel high-resolution ultrasound imaging sensor, we wish to investigate the limits of both passive and active airborne ultrasound sensing by utilizing this virtually artifact-free imaging modality."
publication venue recommendation using profiles based on clustering,"In this paper, we study the venue recommendation problem in order to help researchers identify a journal or conference to submit a given paper. A common approach for tackling this problem is to build profiles to define the scope of each venue. These profiles are then compared against the target paper. In our approach, we will study how clustering techniques can be used to construct topic-based profiles and an information retrieval-based approach be used to obtain the final recommendations. Additionally, we will explore how the use of authorship (which supplements the information) helps to improve the recommendations."
deep learning for multi-level detection and localization of myocardial scars based on regional strain validated on virtual patients,"How well the heart is functioning can be quantified through measurements of myocardial deformation via echocardiography. Clinical assessment of cardiac function is generally focused on global indices of relative shortening; however, segmental strain indices have been shown to be abnormal in regions of myocardial disease such as scarring. In this work, we propose a single framework to predict myocardial scars at global, territorial, and segmental levels using regional myocardial strain traces as input to a convolutional neural network (CNN). An anatomically meaningful representation of the input data from the clinically standard bullseye representation to a multi-channel 2D image is proposed, thus enabling the use of state-of-the-art neural network configurations. A Fully Convolutional Network (FCN) is trained to detect and localize myocardial scar from regional left ventricular (LV) strain traces. Simulated regional strain data from a controlled dataset of virtual patients with varying degrees and locations of myocardial scar is used for training and validation. The proposed method successfully detects and localizes the scars on 98% of the 5490 left ventricle (LV) segments of the 305 patients in the test set using strain traces only. Due to the sparse existence of scar in the dataset, only 10% of the LV segments are scarred. Taking the imbalance into account, the class balanced accuracy is calculated as 95%. The proposed method proves successful on the strain traces of the virtual cohort and offers the potential to solve the regional myocardial scar detection problem on the strain traces of the real patient cohorts."
"a survey on security of ultra/hyper reliable low latency communication: recent advancements, challenges, and future directions","Ultra-reliable low latency communication (URLLC) is an innovative service offered by fifth-generation (5G) wireless systems. URLLC enables various mission-critical applications by facilitating reliable and low-latency signal transmission to support extreme Quality of Service (QoS) requirements. Apart from reliability and latency, ensuring secure data transmission for URLLC has been a prominent issue for researchers in recent years. Using finite blocklength signals to achieve the stringent reliability and latency criteria in URLLC eliminates the possibility of using conventional complex cryptographic security enhancement techniques based on encoding and decoding of secret keys. Thus, the development of lightweight security mechanisms is of paramount importance for URLLC. Recently, Physical-Layer Security (PLS) techniques have emerged as a powerful alternative to the complex cryptography-based security approaches for facilitating secure URLLC by exploiting the randomness of the wireless channel. Therefore, in this survey, we present a comprehensive and in-depth review of the state-of-the-art PLS enhancements utilized to unleash secure URLLC while analyzing the impact of various system design parameters on its performance. Moreover, the survey incorporates a detailed overview of the recent advancements in ensuring secure URLLC using PLS in various mission-critical applications, and 5G URLLC enabling technologies like non-orthogonal multiple access (NOMA), multi-antenna systems, cooperative communication using unmanned aerial vehicles (UAV), and intelligent reflective surfaces (IRS). Apart from this, we briefly discuss the role of advanced Machine Learning (ML) techniques in designing robust and intelligent PLS schemes for URLLC service."
generation of asset administration shell with large language model agents: toward semantic interoperability in digital twins in the context of industry 4.0,"This research introduces a novel approach for achieving semantic interoperability in digital twins and assisting the creation of Asset Administration Shell (AAS) as digital twin model within the context of Industry 4.0. The foundational idea of our research is that the communication based on semantics and the generation of meaningful textual data are directly linked, and we posit that these processes are equivalent if the exchanged information can be serialized in text form. Based on this, we construct a “semantic node” data structure in our research to capture the semantic essence of textual data. Then, a system powered by large language models is designed and implemented to process the “semantic node” and generate standardized digital twin models (AAS instance models in the context of Industry 4.0) from raw textual data collected from datasheets describing technical assets. Our evaluation demonstrates an effective generation rate of 62-79%, indicating a substantial proportion of the information from the source text can be translated error-free to the target digital twin instance model with the generative capability of large language models. This result has a direct application in the context of Industry 4.0, and the designed system is implemented as a data model generation tool for reducing the manual effort in creating AAS model by automatically translating unstructured textual data into a standardized AAS model. The generated AAS model can be integrated into AAS-compliant digital twin software for seamless information exchange and communication. In our evaluation, a comparative analysis of different LLMs and an in-depth ablation study of Retrieval-Augmented Generation (RAG) mechanisms provide insights into the effectiveness of LLM systems for interpreting technical concepts and translating data. Our findings emphasize LLMs’ capability to automate AAS instance creation and contribute to the broader field of semantic interoperability for digital twins in industrial applications. The prototype implementation and evaluation results are presented on our GitHub Repository: https://github.com/YuchenXia/AASbyLLM."
low cost carriers induce specific and identifiable delay propagation patterns: an analysis of the eu and us systems,"The impact of air transport delays and their propagation has long been studied, mainly from environmental and mobility viewpoints, using a wide range of data analysis tools and simulations. Less attention has nevertheless been devoted to how delays create meso-scale structures around each airport. In this work we tackle this issue by reconstructing functional networks of delay propagation centred at each airport, and studying their identifiability (i.e. how unique they are) using Deep Learning models. We find that such delay propagation neighbourhoods are highly unique when they correspond to airports with a high share of Low Cost Carriers operations; and demonstrate the robustness of these findings for the EU and US systems, and to different methodological choices. We further discuss some operational implications of this uniqueness."
dense optical flow estimation using sparse regularizers from reduced measurements,"Optical flow is the pattern of apparent motion of objects in a scene. The computation of optical flow is a critical component in numerous computer vision tasks such as object detection, visual object tracking, and activity recognition. Despite a lot of research, efficiently managing abrupt changes in motion remains a challenge in motion estimation. This paper proposes novel variational regularization methods to address this problem since they allow combining different mathematical concepts into a joint energy minimization framework. In this work, we incorporate concepts from signal sparsity into variational regularization for motion estimation. The proposed regularization uses robust $\ell _{1}$ norm, which promotes sparsity and handles motion discontinuities. By using this regularization, we promote the sparsity of the optical flow gradient. This sparsity helps recover a signal even with just a few measurements. We explore recovering optical flow from a limited set of linear measurements using this regularizer. Our findings show that leveraging the sparsity of the derivatives of optical flow reduces computational complexity and memory needs."
analytical model for the relation between signal bandwidth and spatial resolution in steered-response power phase transform (srp-phat) maps,"An analysis of the relationship between the bandwidth of acoustic signals and the required resolution of steered-response power phase transform (SRP-PHAT) maps used for sound source localization is presented. This relationship does not rely on the far-field assumption, nor does it depend on any specific array topology. The proposed analysis considers the computation of a SRP map as a process of sampling a set of generalized cross-correlation (GCC) functions, each one corresponding to a different microphone pair. From this approach, we derive a rule that relates GCC bandwidth with inter-microphone distance, resolution of the SRP map, and the potential position of the sound source relative to the array position. This rule is a sufficient condition for an aliasing-free calculation of the specified SRP-PHAT map. Simulation results show that limiting the bandwidth of the GCC according to such rule leads to significant reductions in sound source localization errors when sources are not in the immediate vicinity of the microphone array. These error reductions are more relevant for coarser resolutions of the SRP map, and they happen in both anechoic and reverberant environments."
a backdoor approach with inverted labels using dirty label-flipping attacks,"Audio-based machine learning systems frequently use public or third-party data, which might be inaccurate. This exposes deep neural network (DNN) models trained on such data to potential data poisoning attacks. In this type of assault, attackers can train the DNN model using poisoned data, potentially degrading its performance. Another type of data poisoning attack that is extremely relevant to our investigation is label flipping, in which the attacker manipulates the labels for a subset of data. It has been demonstrated that these assaults may drastically reduce system performance, even for attackers with minimal abilities. In this study, we propose a backdoor attack named 'DirtyFlipping', which uses dirty label techniques, label-on-label , to input triggers (clapping) in the selected data patterns associated with the target class, thereby enabling a stealthy backdoor."
interpretable classification of wiki-review streams,"Wiki articles are created and maintained by a crowd of editors, producing a continuous stream of reviews. Reviews can take the form of additions, reverts, or both. This crowdsourcing model is exposed to manipulation since neither reviews nor editors are automatically screened and purged. To protect articles against vandalism or damage, the stream of reviews can be mined to classify reviews and profile editors in real-time. The goal of this work is to anticipate and explain which reviews to revert. This way, editors are informed why their edits will be reverted. The proposed method employs stream-based processing, updating the profiling and classification models on each incoming event. The profiling uses side and content-based features employing Natural Language Processing, and editor profiles are incrementally updated based on their reviews. Since the proposed method relies on self-explainable classification algorithms, it is possible to understand why a review has been classified as a revert or a non-revert. In addition, this work contributes an algorithm for generating synthetic data for class balancing, making the final classification fairer. The proposed online method was tested with a real data set from Wikivoyage, which was balanced through the aforementioned synthetic data generation. The results attained near-90% values for all evaluation metrics (accuracy, precision, recall, and ${F}$ -measure)."
a decoupling and aggregating framework for joint extraction of entities and relations,"Named Entity Recognition and Relation Extraction are two crucial and challenging subtasks in the field of Information Extraction. Despite the successes achieved by the traditional approaches, fundamental research questions remain open. First, most recent studies use parameter sharing for a single subtask or shared features for both two subtasks, ignoring their semantic differences. Second, information interaction mainly focuses on the two subtasks, leaving the fine-grained informtion interaction among the subtask-specific features of encoding subjects, relations, and objects unexplored. Motivated by the aforementioned limitations, we propose a novel model to jointly extract entities and relations. The main novelties are as follows: (1) We propose to decouple the feature encoding process into three parts, namely encoding subjects, encoding objects, and encoding relations. Thanks to this, we are able to use fine-grained subtask-specific features. (2) We propose novel inter-aggregation and intra-aggregation strategies to enhance the information interaction and construct individual fine-grained subtask-specific features, respectively. The experimental results demonstrate that our model outperforms several previous state-of-the-art models. Extensive additional experiments further confirm the effectiveness of our model."
comprehensive evaluation and insights into the use of large language models in the automation of behavior-driven development acceptance test formulation,"Behavior-driven development (BDD) is an Agile testing methodology fostering collaboration among developers, QA analysts, and stakeholders. In this manuscript, we propose a novel approach to enhance BDD practices using large language models (LLMs) to automate acceptance test generation. Our study uses zero and few-shot prompts to evaluate LLMs such as GPT-3.5, GPT-4, Llama-2-13B, and PaLM-2. The paper presents a detailed methodology that includes the dataset, prompt techniques, LLMs, and the evaluation process. The results demonstrate that GPT-3.5 and GPT-4 generate error-free BDD acceptance tests with better performance. The few-shot prompt technique highlights its ability to provide higher accuracy by incorporating examples for in-context learning. Furthermore, the study examines syntax errors, validation accuracy, and comparative analysis of LLMs, revealing their effectiveness in enhancing BDD practices. However, our study acknowledges that there are limitations to the proposed approach. We emphasize that this approach can support collaborative BDD processes and create opportunities for future research into automated BDD acceptance test generation using LLMs."
motion prediction with gaussian processes for safe human–robot interaction in virtual environments,"Humans use collaborative robots as tools for accomplishing various tasks. The interaction between humans and robots happens in tight shared workspaces. However, these machines must be safe to operate alongside humans to minimize the risk of accidental collisions. Ensuring safety imposes many constraints, such as reduced torque and velocity limits during operation, thus increasing the time to accomplish many tasks. However, for applications such as using collaborative robots as haptic interfaces with intermittent contacts for virtual reality applications, speed limitations result in poor user experiences. This research aims to improve the efficiency of a collaborative robot while improving the safety of the human user. We used Gaussian process models to predict human hand motion and developed strategies for human intention detection based on hand motion and gaze to improve the time for the robot and human security in a virtual environment. We then studied the effect of prediction. Results from comparisons show that the prediction models improved the robot time by 3% and safety by 17%. When used alongside gaze, prediction with Gaussian process models resulted in an improvement of the robot time by 2% and the safety by 13%."
mentalqa: an annotated arabic corpus for questions and answers of mental healthcare,"Mental health disorders significantly impact people globally, regardless of background, education, or socioeconomic status. However, access to adequate care remains a challenge, particularly for underserved communities with limited resources. Text mining tools offer immense potential to support mental healthcare by assisting professionals in diagnosing and treating patients. This study addresses the scarcity of Arabic mental health resources for developing such tools. We introduce MentalQA, a novel Arabic dataset featuring conversational-style question-and-answer (QA) interactions. To ensure data quality, we conducted a rigorous annotation process using a well-defined schema with quality control measures. Data was collected from a question-answering medical platform. The annotation schema for mental health questions and corresponding answers draws upon existing classification schemes with some modifications. Question types encompass six distinct categories: diagnosis, treatment, anatomy \&physiology, epidemiology, healthy lifestyle, and provider choice. Answer strategies include information provision, direct guidance, and emotional support. Three experienced annotators collaboratively annotated the data to ensure consistency. Our findings demonstrate high inter-annotator agreement, with Fleiss' Kappa of $0.61$ for question types and $0.98$ for answer strategies. In-depth analysis revealed insightful patterns, including variations in question preferences across age groups and a strong correlation between question types and answer strategies. MentalQA offers a valuable foundation for developing Arabic text mining tools capable of supporting mental health professionals and individuals seeking information."
tag: guidance-free open-vocabulary semantic segmentation,"Semantic segmentation is a crucial task in computer vision, where each pixel in an image is classified into a category. However, traditional methods face significant challenges, including the need for pixel-level annotations and extensive training. Furthermore, because supervised learning uses a limited set of predefined categories, models typically struggle with rare classes and cannot recognize new ones. Unsupervised and open-vocabulary segmentation, proposed to tackle these issues, faces challenges, including the inability to assign specific class labels to clusters and the necessity of user-provided text queries for guidance. In this context, we propose a novel approach, TAG which achieves Training, Annotation, and Guidance-free open-vocabulary semantic segmentation. TAG utilizes pre-trained models such as CLIP and DINO to segment images into meaningful categories without additional training or dense annotations. It retrieves class labels from an external database, providing flexibility to adapt to new scenarios. Our TAG achieves state-of-the-art results on PascalVOC, PascalContext and ADE20K for open-vocabulary segmentation without given class names, i.e. improvement of +15.3 mIoU on PascalVOC."
automatic modulation classification for mimo system based on the mutual information feature extraction,"Automatic Modulation Classification (AMC) is an essential technology that is widely applied into various communications scenarios. In recent years, many Machine Learning and Deep-Learning methods have been introduced into AMC, and a lot of them apply different approaches to eliminate interference in complex Multiple-Input and Multiple-Output (MIMO) signals and improve classification performance. However, in practical communication systems, the perfect elimination of MIMO signal interference is impossible, and therefore classification performance suffers. In this paper, we propose a new AMC algorithm for MIMO system based on mutual information (MI) features extraction, which does not require a large amount of training data and the elimination of MIMO signal interference. In this approach, features based on mutual information are extracted using In-Phase and Quadrature (IQ) constellation diagrams of MIMO signals, which have not been explored previously. Our method can be effective since mutual information considers the interdependencies among variables and measures how much information about one variable reduces uncertainty about another, providing a valuable perspective for extracting higher-level and interesting features from the data. The effectiveness of our method is evaluated on several model and real-world datasets, and its applicability is proven."
masklrf: self-supervised pretraining via masked autoencoding of local reference frames for rotation-invariant 3d point set analysis,"Following the successes in the fields of vision and language, self-supervised pretraining via masked autoencoding of 3D point set data, or Masked Point Modeling (MPM), has achieved state-of-the-art accuracy in various downstream tasks. However, current MPM methods lack a property essential for 3D point set analysis, namely, invariance against rotation of 3D objects/scenes. Existing MPM methods are thus not necessarily suitable for real-world applications where 3D point sets may have inconsistent orientations. This paper develops, for the first time, a rotation-invariant self-supervised pretraining framework for practical 3D point set analysis. The proposed algorithm, called MaskLRF, learns rotation-invariant and highly generalizable latent features via masked autoencoding of 3D points within Local Reference Frames (LRFs), which are not affected by rotation of 3D point sets. MaskLRF enhances the quality of latent features by integrating feature refinement using relative pose encoding and feature reconstruction using low-level but rich 3D geometry. The efficacy of MaskLRF is validated via extensive experiments on diverse downstream tasks including classification, segmentation, registration, and domain adaptation. The experiments demonstrate that MaskLRF achieves new state-of-the-art accuracies in analyzing 3D point sets having inconsistent orientations. Code will be available at: https://github.com/takahikof/MaskLRF."
a software-defined networking solution for interconnecting network functions in service-based architectures,"Mobile core networks handle critical control functions for delivering services in modern cellular networks. Traditional point-to-point architectures, where network functions are directly connected through standardized interfaces, are being substituted by service-based architectures (SBAs), where core functionalities are finer-grained microservices decoupled from the underlying infrastructure. In this way, network functions and services can be distributed, with scaling and fail-over mechanisms, and can be dynamically deployed, updated, or removed to support slicing. A myriad of network functions can be deployed or removed according to traffic flows, thereby increasing the complexity of connection management. In this context, 3GPP Release 16 defines the service communication proxy (SCP) as a unified communication interface for a set of network functions. In this paper, we propose a novel software-defined networking (SDN)-based solution with the same role for a service mesh architecture where network functions can be deployed anywhere in the infrastructure. We demonstrated its efficiency in comparison with alternative architectures."
blockchain for healthcare management systems: a survey on interoperability and security,"n recent years it has been shown that the secure exchange of medical information significantly benefits people’s life quality, improving their care and treatment. The interoperability of the entire healthcare ecosystem is a constant challenge, and even more, with all the risks posed to the security of healthcare information. Blockchain technology is emerging as one of the main alternatives when it comes to finding a balance in the healthcare ecosystem. However, the constant development of new Blockchain technologies and the evolution of healthcare systems make it difficult to find established proposals. From an architectural point of view, the design of blockchain-based solutions requires trade-offs e.g., security and interoperability. This paper focuses on two main objectives, in the first one, it was carried out a Systematic Literature Review for exploring architectural mechanisms used to support the interoperability and security of Blockchain-based Health Management Systems. Taking into account of results, a series of scenarios were generated where these mechanisms can be used along with their context, issues, and various architectural concerns (interoperability and security). In the second objective, a high-level architecture and its validation were proposed through an experiment for the whole process of developing a Domain Specific Language, using the Model Driven Engineering methodology for specific Smart Contracts."
fighting against the repetitive training and sample dependency problem in few-shot named entity recognition,"Few-shot named entity recognition (NER) systems recognize entities using a few labeled training examples. The general pipeline consists of a span detector to identify entity spans in text and an entity-type classifier to assign types to entities. Current span detectors rely on extensive manual labeling to guide training. Almost every span detector requires initial training on basic span features followed by adaptation to task-specific features. This process leads to repetitive training of the basic span features among span detectors. Additionally, metric-based entity-type classifiers, such as prototypical networks, typically employ a specific metric that gauges the distance between the query sample and entity-type referents, ultimately assigning the most probable entity type to the query sample. However, these classifiers encounter the sample dependency problem, primarily stemming from the limited samples available for each entity-type referent. To address these challenges, we proposed an improved few-shot NER pipeline. First, we introduce a steppingstone span detector that is pre-trained on open-domain Wikipedia data. It can be used to initialize the pipeline span detector to reduce the repetitive training of basic features. Second, we leverage a large language model (LLM) to set reliable entity-type referents, eliminating reliance on few-shot samples of each type. Our model exhibits superior performance with fewer training steps and human-labeled data compared with baselines, as demonstrated through extensive experiments on various datasets. Particularly in fine-grained few-shot NER settings, our model outperforms strong baselines, including ChatGPT. We will publicly release the code, datasets, LLM outputs, and model checkpoints."
"a comprehensive survey of convolutions in deep learning: applications, challenges, and future trends","In today’s digital age, Convolutional Neural Networks (CNNs), a subset of Deep Learning (DL), are widely used for various computer vision tasks such as image classification, object detection, and image segmentation. There are numerous types of CNNs designed to meet specific needs and requirements, including 1D, 2D, and 3D CNNs, as well as dilated, grouped, attention, depthwise convolutions, and NAS, among others. Each type of CNN has its unique structure and characteristics, making it suitable for specific tasks. It’s crucial to gain a thorough understanding and perform a comparative analysis of these different CNN types to understand their strengths and weaknesses. Furthermore, studying the performance, limitations, and practical applications of each type of CNN can aid in the development of new and improved architectures in the future. We also dive into the platforms and frameworks that researchers utilize for their research or development from various perspectives. Additionally, we explore the main research fields of CNN like 6D vision, generative models, and meta-learning. This survey paper provides a comprehensive examination and comparison of various CNN architectures, highlighting their architectural differences and emphasizing their respective advantages, disadvantages, applications, challenges, and future trends."
video relationship detection using mixture of experts,"Machine comprehension of visual information from images and videos by neural networks suffers from two limitations: (1) the computational and inference gap in vision and language to accurately determine which object a given agent acts on and then to represent it by language, and (2) the shortcoming in stability and generalization of the classifier trained by a single, monolithic neural network. To address these limitations, we propose MoE-VRD, a novel approach to visual relationship detection via a mixture of experts. MoE-VRD recognizes language triplets in the form of a < subject, predicate, object > tuple to extract the relationship between subject, predicate, and object from visual processing. Since detecting a relationship between a subject (acting) and the object(s) (being acted upon) requires that the action be recognized, we base our network on recent work in visual relationship detection. To address the limitations associated with single monolithic networks, our mixture of experts is based on multiple small models, whose outputs are aggregated. That is, each expert in MoE-VRD is a visual relationship learner capable of detecting and tagging objects. MoE-VRD employs an ensemble of networks while preserving the complexity and computational cost of the original underlying visual relationship model by applying a sparsely-gated mixture of experts, which allows for conditional computation and a significant gain in neural network capacity. We show that the conditional computation capabilities and massive ability to scale the mixture-of-experts leads to an approach to the visual relationship detection problem which outperforms the state-of-the-art."
"artificial intelligence for cochlear implants: review of strategies, challenges, and perspectives","Automatic speech recognition (ASR) plays a pivotal role in our daily lives, offering utility not only for interacting with machines but also for facilitating communication for individuals with partial or profound hearing impairments. The process involves receiving the speech signal in analog form, followed by various signal processing algorithms to make it compatible with devices of limited capacities, such as cochlear implants (CIs). Unfortunately, these implants, equipped with a finite number of electrodes, often result in speech distortion during synthesis. Despite efforts by researchers to enhance received speech quality using various state-of-the-art (SOTA) signal processing techniques, challenges persist, especially in scenarios involving multiple sources of speech, environmental noise, and other adverse conditions. The advent of new artificial intelligence (AI) methods has ushered in cutting-edge strategies to address the limitations and difficulties associated with traditional signal processing techniques dedicated to CIs. This review aims to comprehensively cover advancements in CI-based ASR and speech enhancement, among other related aspects. The primary objective is to provide a thorough overview of metrics and datasets, exploring the capabilities of AI algorithms in this biomedical field, and summarizing and commenting on the best results obtained. Additionally, the review will delve into potential applications and suggest future directions to bridge existing research gaps in this domain."
guidance design for escape flight vehicle using evolution strategy enhanced deep reinforcement learning,"Guidance commands of flight vehicles can be regarded as a series of data sets having fixed time intervals, thus guidance design constitutes a typical sequential decision problem and satisfies the basic conditions for using the deep reinforcement learning (DRL) technique. In this paper, we consider the scenario where the escape flight vehicle (EFV) generates guidance commands based on the DRL technique and the pursuit flight vehicle (PFV) generates guidance commands based on the proportional navigation method. Evasion distance is described as the minimum distance between the EFV and the PFV during the escape-and-pursuit process. For the EFV, the objective of the guidance design entails progressively maximizing the residual velocity, which is described as the EFV’s velocity when the evasion distance occurs, subject to the constraint imposed by the given evasion distance. Thus an irregular dynamic max-min problem of extremely large-scale is formulated. In this problem, the time instant when the optimal solution (i.e., the maximum residual velocity satisfying the evasion distance constraint) can be attained is uncertain and the optimum solution is dependent on all the intermediate guidance commands generated before. For solving this challenging problem, a two-step strategy is conceived. In the first step, we use the proximal policy optimization (PPO) algorithm to generate the guidance commands of the EFV. The results obtained by PPO in the global search space are coarse, despite the fact that the reward function, the neural network parameters and the learning rate are designed elaborately. Therefore, in the second step, we propose to invoke the evolution strategy (ES) based algorithm, which uses the result of PPO as the initial value, to further improve the quality of the solution by searching in the local space. Extensive simulation results demonstrate that the proposed guidance design method based on the PPO algorithm is capable of achieving a residual velocity of 67.24 m/s, higher than the residual velocities achieved by the benchmark soft actor-critic and deep deterministic policy gradient algorithms. Furthermore, the proposed ES-enhanced PPO algorithm outperforms the PPO algorithm by 2.7%, achieving a residual velocity of 69.04 m/s."
characterization of magnetic labyrinthine structures through junctions and terminals detection using template matching and cnn,"Defects influence diverse properties of materials, shaping their structural, mechanical, and electronic characteristics. Among a variety of materials exhibiting unique defects, magnets exhibit diverse nano- to micro-scale defects and have been intensively studied in materials science. Specifically, defects in magnetic labyrinthine patterns, called junctions and terminals are ubiquitous and serve as points of interest. While detecting and characterizing such defects is crucial for understanding magnets, systematically investigating large-scale images containing over a thousand closely packed junctions and terminals remains a formidable challenge. This study introduces a new technique called TM-CNN (Template Matching - Convolutional Neural Network) designed to detect a multitude of small objects in images, such as the defects in magnetic labyrinthine patterns. TM-CNN was used to identify 641,649 such structures in 444 experimental images, and the results were explored to deepen understanding of magnetic materials. It employs a two-stage detection approach combining template matching, used in initial detection, with a convolutional neural network, used to eliminate incorrect identifications. To train a CNN classifier, it is necessary to annotate a large number of training images. This difficulty prevents the use of CNN in many practical applications. TM-CNN significantly reduces the manual workload for creating training images by automatically making most of the annotations and leaving only a small number of corrections to human reviewers. In testing, TM-CNN achieved an impressive F1 score of 0.991, far outperforming traditional template matching and CNN-based object detection algorithms."
net-zero energy house-oriented linear programming for the sizing problem of photovoltaic panels and batteries,"The global drive towards carbon neutrality has led to a significant increase in the number of power plants based on renewable energy sources (RES). Concurrently, numerous households are adopting RES to generate their own energy, aiming to decrease both electricity costs and carbon footprints. To support these users, many papers have been devoted to developing optimal investment strategies for residential energy systems. However, there is still a significant gap as these studies often neglect important aspects like carbon neutrality. For this reason, in this paper, we explore the concept of net-zero energy houses (ZEHs)—houses designed to have an annual net energy consumption around zero—by presenting a constrained optimization problem to find the optimal number of photovoltaic panels and the optimal size of the battery system for home integration. Solving this constrained optimization problem is difficult due to its nonconvex constraints. Nevertheless, by applying a series of transformations, we reveal that it is possible to find an equivalent linear programming (LP) problem which is computationally tractable. The attainment of ZEH can be tackled by introducing a single constraint in the optimization problem. Additionally, we propose a sharing economy approach to the investment problem, offering a strategy that could potentially reduce investment costs and facilitate the attainment of ZEH more efficiently. Finally, we apply the proposed frameworks to a neighborhood in Japan as a case study, demonstrating the potential for long-term ZEH attainment. The results show that, under the right incentive, users can achieve ZEH, reduce their electricity costs and have a minimal impact on the main grid."
"latent denoising diffusion gan: faster sampling, higher image quality","Diffusion models are emerging as powerful solutions for generating high-fidelity and diverse images, often surpassing GANs under many circumstances. However, their slow inference speed hinders their potential for real-time applications. To address this, DiffusionGAN leveraged a conditional GAN to drastically reduce the denoising steps and speed up inference. Its advancement, Wavelet Diffusion, further accelerated the process by converting data into wavelet space, thus enhancing efficiency. Nonetheless, these models still fall short of GANs in terms of speed and image quality. To bridge these gaps, this paper introduces the Latent Denoising Diffusion GAN, which employs pre-trained autoencoders to compress images into a compact latent space, significantly improving inference speed and image quality. Furthermore, we propose a Weighted Learning strategy to enhance diversity and image quality. Experimental results on the CIFAR-10, CelebA-HQ, and LSUN-Church datasets prove that our model achieves state-of-the-art running speed among diffusion models. Compared to its predecessors, DiffusionGAN and Wavelet Diffusion, our model shows remarkable improvements in all evaluation metrics. Code and pre-trained checkpoints: https://github.com/thanhluantrinh/LDDGAN.git."
a study on self-supervised pretraining for vision problems in gastrointestinal endoscopy,"Solutions to vision tasks in gastrointestinal endoscopy (GIE) conventionally use image encoders pretrained in a supervised manner with ImageNet-1k as backbones. However, the use of modern self-supervised pretraining algorithms and a recent dataset of 100k unlabelled GIE images (Hyperkvasir-unlabelled) may allow for improvements. In this work, we study the fine-tuned performance of models with ResNet50 and ViT-B backbones pretrained in self-supervised and supervised manners with ImageNet-1k and Hyperkvasir-unlabelled (self-supervised only) in a range of GIE vision tasks. In addition to identifying the most suitable pretraining pipeline and backbone architecture for each task, out of those considered, our results suggest three general principles. Firstly, that self-supervised pretraining generally produces more suitable backbones for GIE vision tasks than supervised pretraining. Secondly, that self-supervised pretraining with ImageNet-1k is typically more suitable than pretraining with Hyperkvasir-unlabelled, with the notable exception of monocular depth estimation in colonoscopy. Thirdly, that ViT-Bs are more suitable in polyp segmentation and monocular depth estimation in colonoscopy, ResNet50s are more suitable in polyp detection, and both architectures perform similarly in anatomical landmark recognition and pathological finding characterisation. We hope this work draws attention to the complexity of pretraining for GIE vision tasks, informs this development of more suitable approaches than the convention, and inspires further research on this topic to help advance this development. Code available: https://www.github.com/ESandML/SSL4GIE."
knowledge graph generation and enabling multidimensional analytics on bangladesh agricultural data,"In Bangladesh, agriculture is a crucial driver for addressing Sustainable Development Goal 1 (no poverty) and 2 (zero hunger), playing a fundamental role in the economy and people’s livelihoods. To enhance the sustainability and resilience of the agriculture industry through data-driven insights, the Bangladesh Bureau of Statistics, open data portal, and other organizations consistently collect and publish agricultural data on the Web. Nevertheless, the current datasets encounter various challenges: 1) they are presented in an unsustainable, static, read-only, and aggregated format, 2) they do not conform to the Findable, Accessible, Interoperable, and Reusable (FAIR) principles, and 3) they do not facilitate interactive analysis and integration with other data sources. In this paper, we present a thorough solution, delineating a systematic procedure for developing BDAKG: a knowledge graph that semantically and multidimensionally integrates Bangladesh agricultural data. BDAKG incorporates multidimensional semantics, is linked with external knowledge graphs, is compatible with OLAP, and adheres to the FAIR principles. Our experimental evaluation centers on evaluating the integration process and assessing the quality of the resultant knowledge graph in terms of completeness, timeliness, FAIRness, OLAP compatibility, correctness, and data-driven analysis. Our federated data analyses recommend a strategic approach focused on decreasing CO2 emissions, fostering economic growth, and promoting sustainable forestry."
ris-noma integrated low-complexity transceiver architecture: sum rate and energy efficiency perspective,"This paper aims to explore reconfigurable intelligent surface (RIS) integration in a millimeter wave (mmWave) communication system with low-complexity transceiver architecture under imperfect channel state information (CSI) assumption. Motivated by this, we propose a RIS-aided system with a fully analog architecture at the base station (BS). However, to overcome the drawback of single-user transmission due to the single RF chain in the analog architecture, we propose to employ NOMA to enable multi-user transmission. For such a system, we formulate two problems to obtain the joint transmit beamformer, RIS phase shift matrix, and power allocation solutions that maximize sum rate and energy efficiency such that the minimum rate for each user is satisfied. However, both problems are intractable due to: 1) fractional objective; 2) non-convex minimum rate and unit modulus RIS phase shift constraints; and 3) the coupled optimization variables. Hence, we first tackle the fractional objectives of both problems by reformulating the sum rate and energy efficiency maximization problems into equivalent quadratic forms using the quadratic transform. On the other hand, we employ successive convex approximation and the semi-definite relaxation technique to handle the non-convex minimum rate and unit modulus constraint of the RIS phase shifts, respectively. However, the problems remain non-convex due to the coupled optimization variables. Thus, we propose an alternating optimization-based algorithm that iterates over the transmit beamformer, power allocation, and RIS phase shift subproblems. Further, we also show that the quadratic reformulation is equivalent to the weighted mean square error-based reformulation for the case of the sum rate maximization problem. Our numerical results show that the proposed RIS-NOMA integrated analog architecture system outperforms the optimally configured fully digital architecture in terms of sum rate at low signal-to-noise ratio (SNR) and energy efficiency for a wide range of SNR while still maintaining low hardware complexity and cost. Finally, we present the numerical performance analysis of the RIS-NOMA integrated low-complexity system for various system configuration parameters."
"from digital twins to digital twin prototypes: concepts, formalization, and applications","The transformation to Industry 4.0 also transforms the processes of developing intelligent manufacturing production systems. Digital twins may be employed to advance the development of these new (embedded) software systems. However, there is no consensual definition of what a digital twin is. In this paper, we provide an overview of the current state of the digital twin concept and formalize the digital twin concept using the Object-Z notation. This formalization includes the concepts of physical twins, digital models, digital templates, digital threads, digital shadows, digital twins, and digital twin prototypes. The relationships between all these concepts are visualized as class diagrams using the Unified Modeling Language. Our digital twin prototype approach supports engineers in the development and automated testing of complex embedded software systems. This approach enables engineers to test embedded software systems in a virtual context without the need of a connection to a physical object. In continuous integration/continuous deployment pipelines, such digital twin prototypes can be used for automated integration testing and, thus, allow for an agile verification and validation process. In this paper, we demonstrate and report on the application and implementation of a digital twin using the example of two real-world field studies (ocean observation systems and smart farming). For independent replication and extension of our approach by other researchers, we provide a laboratory study published open source on GitHub."
pulse-width modulation technique with harmonic injection in the modulating wave and discontinuous frequency modulation for the carrier wave for multilevel inverters: an application to the reduction of acoustic noise in induction motors,"An implementation of a harmonic injection pulse width modulation frequency-modulated triangular carrier (HIPWM-FMTC) control strategy applied to a multilevel power inverter feeding an asynchronous motor is presented. The aim was to justify the reduction in acoustic noise emitted by the machine compared with other strategies in the technical literature. In addition, we checked how the THD at the inverter output was reduced compared to the other control techniques used as a reference. The proposed strategy is based on frequency modulation of the triangular carrier. The main advantage of the proposed method is that only one control parameter is required for modifying the electrical spectrum. Therefore, the mechanical natural frequencies and spatial harmonics of the machine can be avoided, and acoustic noise can be reduced. The effectiveness of the technique was demonstrated after laboratory validation by comparing the acoustic results for a 1 kW motor. The results obtained from the laboratory tests are presented and compared with those of other acoustic measurements using different PWM strategies."
prediction of tuberculosis from lung tissue images of diversity outbred mice using jump knowledge based cell graph neural network,"Tuberculosis (TB), primarily affecting the lungs, is caused by the bacterium Mycobacterium tuberculosis and poses a significant health risk. Detecting acid-fast bacilli (AFB) in stained samples is critical for TB diagnosis. Whole Slide (WS) Imaging allows for digitally examining these stained samples. However, current deep-learning approaches to analyzing large-sized whole slide images (WSIs) often employ patch-wise analysis, potentially missing the complex spatial patterns observed in the granuloma essential for accurate TB classification. To address this limitation, we propose an approach that models cell characteristics and interactions as a graph, capturing both cell-level information and the overall tissue micro-architecture. This method differs from the strategies in related cell graph-based works that rely on edge thresholds based on sparsity/density in cell graph construction, emphasizing a biologically informed threshold determination instead. We introduce a cell graph-based jumping knowledge neural network (CG-JKNN) that operates on the cell graphs where the edge thresholds are selected based on the length of the mycobacteria’s cords and the activated macrophage nucleus’s size to reflect the actual biological interactions observed in the tissue. The primary process involves training a Convolutional Neural Network (CNN) to segment AFBs and macrophage nuclei, followed by converting large (42831*41159 pixels) lung histology images into cell graphs where an activated macrophage nucleus/AFB represents each node within the graph and their interactions are denoted as edges. To enhance the interpretability of our model, we employ Integrated Gradients and Shapely Additive Explanations (SHAP). Our analysis incorporated a combination of 33 graph metrics and 20 cell morphology features. In terms of traditional machine learning models, Extreme Gradient Boosting (XGBoost) was the best performer, achieving an F1 score of 0.9813 and an Area under the Precision-Recall Curve (AUPRC) of 0.9848 on the test set. Among graph-based models, our CG-JKNN was the top performer, attaining an F1 score of 0.9549 and an AUPRC of 0.9846 on the held-out test set. The integration of graph-based and morphological features proved highly effective, with CG-JKNN and XGBoost showing promising results in classifying instances into AFB and activated macrophage nucleus. The features identified as significant by our models closely align with the criteria used by pathologists in practice, highlighting the clinical applicability of our approach. Future work will explore knowledge distillation techniques and graph-level classification into distinct TB progression categories."
supdqn: supervised rewarding strategy driven deep q-network for semg signal decontamination,"The presence of muscles throughout the active parts of the body, such as the upper and lower limbs, makes electromyography-based human-machine interaction prevalent. However, muscle signals are stochastic and noisy, with noises being both regular and irregular. Irregular noises due to movements or electrical switching require dynamic filtering. Conventionally, filters are stacked, which unnecessarily trims and delays the signal. This study introduces a decontamination technique involving a supervised rewarding strategy to drive a deep Q-network-based agent (supDQN). It applies one of three filters to decontaminate a 1 sec long surface electromyography signal, which is dynamically contaminated. A machine learning agent identifies whether the signal after filtering is clean or noisy, generating a reward accordingly. The identification accuracy is enhanced by using a local interpretable model-agnostic explanation. The deep Q-network is guided by this reward to select the filter optimally while decontaminating a signal. The proposed filtering strategy is tested on four noise levels (−5 dB, −1 dB, +1 dB, +5 dB). supDQN filters the signal desirably when the signal-to-noise ratio (SNR) is between -5 dB to +1 dB but filters less desirably at high SNR (+5 dB). A normalized root mean square ( $\Omega $ ) is formulated to depict the difference of the filtered signal from the ground truth. This is used to compare supDQN and conventional methods, including wavelet denoising with debauchies and symlet wavelet, high-order low-pass filter, notch filter, and high-pass filter. The proposed filtering strategy gives an average $\Omega $ value of 1.1974, which is lower than that of the conventional filters."
t-tame: trainable attention mechanism for explaining convolutional networks and vision transformers,"The development and adoption of Vision Transformers and other deep-learning architectures for image classification tasks has been rapid. However, the “black box” nature of neural networks is a barrier to adoption in applications where explainability is essential. While some techniques for generating explanations have been proposed, primarily for Convolutional Neural Networks, adapting such techniques to the new paradigm of Vision Transformers is non-trivial. This paper presents T-TAME, Transformer-compatible Trainable Attention Mechanism for Explanations (https://github.com/IDT-ITI/T-TAME), a general methodology for explaining deep neural networks used in image classification tasks. The proposed architecture and training technique can be easily applied to any convolutional or Vision Transformer-like neural network, using a streamlined training approach. After training, explanation maps can be computed in a single forward pass; these explanation maps are comparable to or outperform the outputs of computationally expensive perturbation-based explainability techniques, achieving SOTA performance. We apply T-TAME to three popular deep learning classifier architectures, VGG-16, ResNet-50, and ViT-B-16, trained on the ImageNet dataset, and we demonstrate improvements over existing state-of-the-art explainability methods. A detailed analysis of the results and an ablation study provide insights into how the T-TAME design choices affect the quality of the generated explanation maps."
intelligence and motion models of continuum robots: an overview,"Many technical solutions are bio-inspired. Octopus-inspired robotic arms belong to continuum robots which are used in minimally invasive surgery or for technical system restoration in areas difficult-to-access. Continuum robot missions are bounded with their motions, whereby the motion of the robots is controlled by humans via wireless communication. In case of a lost connection, robot autonomy is required. Distributed control and distributed decision-making mechanisms based on artificial intelligence approaches can be a promising solution to achieve autonomy of technical systems and to increase their resilience. However these methods are not well investigated yet. Octopuses are the living example of natural distributed intelligence but their learning and decision-making mechanisms are also not fully investigated and understood yet. Our major interest is investigating mechanisms of Distributed Artificial Intelligence as a basis for improving resilience of complex systems. We decided to use a physical continuum robot prototype that is able to perform some basic movements for our research. The idea is to research how a technical system can be empowered to combine movements into sequences of motions by itself. For the experimental investigations a suitable physical prototype has to be selected, its motion control has to be implemented and automated. In this paper, we give an overview combining different fields of research, such as Distributed Artificial Intelligence and continuum robots based on 98 publications. We provide a detailed description of the basic motion control models of continuum robots based on the literature reviewed, discuss different aspects of autonomy and give an overview of physical prototypes of continuum robots."
human-centric and integrative lighting asset management in public libraries: qualitative insights and challenges from a swedish field study,"Traditional reliability evaluation of lighting sources often assesses only 50% of a lamp’s volume, which can lead to performance disparities and misapplications due to their limited reflection of real-world scenarios. To address the limitations, it is essential to adopt advanced asset management approaches that enhance awareness and provide a more comprehensive evaluation framework. This paper delves into the nuances of human-centric and integrative lighting asset management in Swedish public libraries, employing a qualitative field study to ascertain the alignment of current practices with these advanced lighting principles. Expanding library services to 20 high-latitude locations (>55° N) in Sweden, our research employed field observations, stakeholder interviews, and questionnaires, coupled with a thorough gap analysis, to understand the current landscape and stakeholder perceptions. Our findings reveal a dichotomy between the existing conditions of library lighting and the stakeholders’ experiences and expectations. Despite the intention to create conducive environments, there is a clear disconnect, with overt problems and covert challenges affecting user satisfaction and efficacy of lighting management. Managers, staff, and users reported varied concerns, including eye strain and discomfort, indicative of substantial room for improvement. The study advocates for a paradigm shift in not only lighting asset management but also reliability evaluation of lighting sources, moving toward continuous improvement, and enhanced awareness and training on human-centric and integrative lighting principles."
bidirectional progressive neural networks with episodic return progress for emergent task sequencing and robotic skill transfer,"Human brain and behavior provide a rich venue that can inspire novel control and learning methods for robotics. In an attempt to exemplify such a development by inspiring how humans acquire knowledge and transfer skills among tasks, we introduce a novel multi-task reinforcement learning framework named Episodic Return Progress with Bidirectional Progressive Neural Networks (ERP-BPNN). The proposed ERP-BPNN model 1) learns in a human-like interleaved manner by 2) autonomous task switching based on a novel intrinsic motivation signal and, in contrast to existing methods, 3) allows bidirectional skill transfer among tasks. ERP-BPNN is a general architecture applicable to several multi-task learning settings; in this paper, we present the details of its neural architecture and show its ability to enable effective learning and skill transfer among morphologically different robots in a reaching task. The developed Bidirectional Progressive Neural Network (BPNN) architecture enables bidirectional skill transfer without requiring incremental training and seamlessly integrates with online task arbitration. The task arbitration mechanism developed is based on soft Episodic Return progress (ERP), a novel intrinsic motivation (IM) signal. To evaluate our method, we use quantifiable robotics metrics such as ‘expected distance to goal’ and ‘path straightness’ in addition to the usual reward-based measure of episodic return common in reinforcement learning. With simulation experiments, we show that ERP-BPNN achieves faster cumulative convergence and improves performance in all metrics considered among morphologically different robots compared to the baselines. Overall, our method provides a human-inspired and efficient multi-task reinforcement learning approach with interleaved learning, making it highly suitable for lifelong learning applications."
self-healing effects in oam beams observed on a 28 ghz experimental link,"In this paper we document for the first time some of the effects of self-healing, a property of orbital-angular-momentum (OAM) or vortex beams, as observed on a millimeter-wave experimental communications link in an outdoors line-of-sight (LOS) scenario. The OAM beams have a helical phase and polarization structure, and have conical amplitude shape in the far field. The Poynting vectors of the OAM beams also possess helical structures, orthogonal to the corresponding helical phase-fronts. Due to such non-planar structure in the direction orthogonal to the beam axis, OAM beams are a subset of “structured light” beams. Such structured beams are known to possess self-healing properties when partially obstructed along their propagation axis, especially in their near fields, resulting in partial reconstruction of their structures at larger distances along their beam axis. This has practical implications in siting antennas where obstructions due to people or vegetation may occur. Various theoretical rationales have been proposed to explain, model and experimentally verify the self-healing physical effects in structured optical beams, using various types of obstructions and experimental techniques. Based on these models, we hypothesize that any self-healing observed will be greater as the OAM order increases. Here we observe the self-healing effects for the first time in structured OAM radio beams, in terms of communication signals and channel parameters rather than beam structures. We capture the effects of partial near-field obstructions of OAM beams of different orders on the communications signals, and provide a physical rationale to substantiate that the self-healing effect was observed to increase with the order of OAM, agreeing with our hypothesis."
mathnet: a data-centric approach for printed mathematical expression recognition,"Printed mathematical expression recognition (MER) models are usually trained and tested using LaTeX-generated mathematical expressions (MEs) as input and the LaTeX source code as ground truth. As the same ME can be generated by various different LaTeX source codes, this leads to unwanted variations in the ground truth data that bias test performance results and hinder efficient learning. In addition, the use of only one font to generate the MEs heavily limits the generalization of the reported results to realistic scenarios. We propose a data-centric approach to overcome this problem, and present convincing experimental results: Our main contribution is an enhanced LaTeX normalization to map any LaTeX ME to a canonical form. Based on this process, we developed an improved version of the benchmark dataset im2latex-100k, featuring 30 fonts instead of one. Second, we introduce the real-world dataset realFormula, with MEs extracted from papers. Third, we developed a MER model, MathNet, based on a convolutional vision transformer, with superior results on all four test sets (im2latex-100k, im2latexv2, realFormula, and InftyMDB-1), outperforming the previous state of the art by up to 88.3%."
typing requirement model as coroutines,"Model-Driven Engineering (MDE) is a technique that aims to boost productivity in software development and ensure the safety of critical systems. Central to MDE is the refinement of high-level requirement models into executable code. Given that requirement models form the foundation of the entire development process, ensuring their correctness is crucial. RM2PT is a widely used MDE platform that employs the REModel language for requirement modeling. REModel contains contract sections and other sections including a UML sequence diagram. This paper contributes a coroutine-based type system that represents pre- and post-conditions in the contract sections in a requirement model as the receiving and yielding parts of coroutines, respectively. The type system is capable of composing coroutine types, so that users can view functions as a whole system and check their collective behavior. By doing so, our type system ensures that the contracts defined in it are executed as outlined in the accompanied sequence diagram. We assessed our approach using four case studies provided by RM2PT, validating the accuracy of the models."
a random ensemble of encrypted vision transformers for adversarially robust defense,"Deep neural networks (DNNs) are well known to be vulnerable to adversarial examples (AEs). In previous studies, the use of models encrypted with a secret key was demonstrated to be robust against white-box attacks, but not against black-box ones. In this paper, we propose a novel method using the vision transformer (ViT) that is a random ensemble of encrypted models for enhancing robustness against both white-box and black-box attacks. In addition, a benchmark attack method, called AutoAttack, is applied to models to test adversarial robustness objectively. In experiments, the method was demonstrated to be robust against not only white-box attacks but also black-box ones in an image classification task on the CIFAR-10 and ImageNet datasets. The method was also compared with the state-of-the-art in a standardized benchmark for adversarial robustness, RobustBench, and it was verified to outperform conventional defenses in terms of clean accuracy and robust accuracy."
a data augmentation pipeline to generate synthetic labeled datasets of 3d echocardiography images using a gan,"Due to privacy issues and limited amount of publicly available labeled datasets in the domain of medical imaging, we propose an image generation pipeline to synthesize 3D echocardiographic images with corresponding ground truth labels, to alleviate the need for data collection and for laborious and error-prone human labeling of images for subsequent Deep Learning (DL) tasks. The proposed method utilizes detailed anatomical segmentations of the heart as ground truth label sources. This initial dataset is combined with a second dataset made up of real 3D echocardiographic images to train a Generative Adversarial Network (GAN) to synthesize realistic 3D cardiovascular Ultrasound images paired with ground truth labels. To generate the synthetic 3D dataset, the trained GAN uses high resolution anatomical models from Computed Tomography (CT) as input. A qualitative analysis of the synthesized images showed that the main structures of the heart are well delineated and closely follow the labels obtained from the anatomical models. To assess the usability of these synthetic images for DL tasks, segmentation algorithms were trained to delineate the left ventricle, left atrium, and myocardium. A quantitative analysis of the 3D segmentations given by the models trained with the synthetic images indicated the potential use of this GAN approach to generate 3D synthetic data, use the data to train DL models for different clinical tasks, and therefore tackle the problem of scarcity of 3D labeled echocardiography datasets."
obstacle-aware navigation of soft growing robots via deep reinforcement learning,"Soft growing robots, are a type of robots that are designed to move and adapt to their environment in a similar way to how plants grow and move with potential applications where they could be used to navigate through tight spaces, dangerous terrain, and hard-to-reach areas. This research explores the application of deep reinforcement Q-learning algorithm for facilitating the navigation of the soft growing robots in cluttered environments. The proposed algorithm utilizes the flexibility of the soft robot to adapt and incorporate the interaction between the robot and the environment into the decision-making process. Results from simulations show that the proposed algorithm improves the soft robot’s ability to navigate effectively and efficiently in confined spaces. This study presents a promising approach to addressing the challenges faced by growing robots in particular and soft robots general in planning obstacle-aware paths in real-world scenarios."
a design space of control coordinate systems in telemanipulation,"Teleoperation systems map operator commands from an input device into some coordinate frame in the remote environment. This frame, which we call a control coordinate system, should be carefully chosen as it determines how operators should move to get desired robot motions. While specific choices made by individual systems have been described in prior work, a design space, i.e., an abstraction that encapsulates the range of possible options, has not been codified. In this paper, we articulate a design space of control coordinate systems, which can be defined by choosing a direction in the remote environment for each axis of the input device. Our key insight is that there is a small set of meaningful directions in the remote environment. Control coordinate systems in prior works can be organized by the alignments of their axes with these directions and new control coordinate systems can be designed by choosing from these directions. We also provide three design criteria to reason about the suitability of control coordinate systems for various scenarios. To demonstrate the utility of our design space, we use it to organize prior systems and design control coordinate systems for three scenarios that we assess through human-subject experiments. Our results highlight the promise of our design space as a conceptual tool to assist system designers to design control coordinate systems that are effective and intuitive for operators."
umbrella: a one-stop shop bridging the gap from lab to real-world iot experimentation,"UMBRELLA (A Living Laboratory: https://www.umbrellaiot.com/) is an open, large-scale IoT ecosystem deployed across South Gloucestershire, UK. It is intended to accelerate innovation across multiple technology domains. UMBRELLA is built to bridge the gap between existing specialised testbeds and address holistically real-world technological challenges in a System-of-Systems (SoS) fashion. UMBRELLA provides open access to real-world devices and infrastructure, enabling researchers and the industry to evaluate solutions for Smart Cities, Robotics, Wireless Communications, Edge Intelligence, and more. Key features include over 200 multi-sensor nodes installed on public infrastructure, a robotics arena with 20 mobile robots, a 5G network-in-a-box solution, and a unified backend platform for management, control and secure user access. The heterogeneity of hardware components, including diverse sensors, communication interfaces, and GPU-enabled edge devices, coupled with tools like digital twins, allows for comprehensive experimentation and benchmarking of innovative solutions unviable in lab environments. This paper provides a comprehensive overview of UMBRELLA’s multi-domain architecture and capabilities, making it an ideal playground for Internet of Things (IoT) and Industrial IoT (IIoT) innovation. It discusses the challenges in designing, developing and operating UMBRELLA as an open, sustainable testbed and shares lessons learned to guide similar future initiatives. With its unique openness, heterogeneity, realism and tools, UMBRELLA aims to continue accelerating cutting-edge technology research, development and translation into real-world progress."
toward practical benchmarks of ising machines: a case study on the quadratic knapsack problem,"Combinatorial optimization has wide applications from industry to natural science. Ising machines bring an emerging computing paradigm for efficiently solving a combinatorial optimization problem by searching a ground state of a given Ising model. Current cutting-edge Ising machines achieve fast sampling of near-optimal solutions of the max-cut problem. However, for problems with additional constraint conditions, their advantages have been hardly shown due to difficulties in handling the constraints. In this work, we focus on benchmarks of Ising machines on the quadratic knapsack problem (QKP). To bring out their practical performance, we propose fast two-stage post-processing for Ising machines, which makes handling the constraint easier. Simulation based on simulated annealing shows that the proposed method substantially improves the solving performance of Ising machines and the improvement is robust to a choice of encoding of the constraint condition. Through evaluation using an Ising machine called Amplify Annealing Engine, the proposed method is shown to dramatically improve its solving performance on the QKP. These results are a crucial step toward showing advantages of Ising machines on practical problems involving various constraint conditions."
artifact reduction in 3d and 4d cone-beam computed tomography images with deep learning: a review,"Deep learning based approaches have been used to improve image quality in cone-beam computed tomography (CBCT), a medical imaging technique often used in applications such as image-guided radiation therapy, implant dentistry or orthopaedics. While deep learning methods have been applied to reduce various types of CBCT image artifacts arising from motion, metal objects, or low-dose acquisition, a comprehensive review summarizing the successes and shortcomings of these approaches, with a primary focus on the type of artifacts rather than the architecture of neural networks, is lacking in the literature. In this review, the data generation and simulation pipelines, as well as artifact reduction techniques are specifically investigated for each type of artifact. We provide an overview of deep learning techniques that have successfully been shown to reduce artifacts in 3D, as well as in time-resolved (4D) CBCT through the use of projection- and/or volume-domain optimizations, or by introducing neural networks directly within the CBCT reconstruction algorithms. Research gaps are identified to suggest avenues for future exploration. One of the key findings of this work is an observed trend towards the use of generative models including GANs and score-based or diffusion models, accompanied with the need for more diverse and open training datasets and simulations."
systematic literature review on application of learning-based approaches in continuous integration,"Context: Machine learning (ML) and deep learning (DL) analyze raw data to extract valuable insights in specific phases. The rise of continuous practices in software projects emphasizes automating Continuous Integration (CI) with these learning-based methods, while the growing adoption of such approaches underscores the need for systematizing knowledge. Objective: Our objective is to comprehensively review and analyze existing literature concerning learning-based methods within the CI domain. We endeavour to identify and analyse various techniques documented in the literature, emphasizing the fundamental attributes of training phases within learning-based solutions in the context of CI. Method: We conducted a Systematic Literature Review (SLR) involving 52 primary studies. Through statistical and thematic analyses, we explored the correlations between CI tasks and the training phases of learning-based methodologies across the selected studies, encompassing a spectrum from data engineering techniques to evaluation metrics. Results: This paper presents an analysis of the automation of CI tasks utilizing learning-based methods. We identify and analyze nine types of data sources, four steps in data preparation, four feature types, nine subsets of data features, five approaches for hyperparameter selection and tuning, and fifteen evaluation metrics. Furthermore, we discuss the latest techniques employed, existing gaps in CI task automation, and the characteristics of the utilized learning-based techniques. Conclusion: This study provides a comprehensive overview of learning-based methods in CI, offering valuable insights for researchers and practitioners developing CI task automation. It also highlights the need for further research to advance these methods in CI."
swaptransformer: highway overtaking tactical planner model via imitation learning on osha dataset,"This paper investigates the high-level decision-making problem in highway scenarios regarding lane changing and over-taking other slower vehicles. In particular, this paper aims to improve the Travel Assist feature for automatic overtaking and lane changes on highways. About 9 million samples including lane images and other dynamic objects are collected in simulation. This data; Overtaking on Simulated HighwAys (OSHA) dataset is released to tackle this challenge. To solve this problem, an architecture called SwapTransformer is designed and implemented as an imitation learning approach on the OSHA dataset. Moreover, auxiliary tasks such as future points and car distance network predictions are proposed to aid the model in better understanding the surrounding environment. The performance of the proposed solution is compared with a multi-layer perceptron (MLP) and multi-head self-attention networks as baselines in a simulation environment. We also demonstrate the performance of the model with and without auxiliary tasks. All models are evaluated based on different metrics such as time to finish each lap, number of overtakes, and speed difference with speed limit. The evaluation shows that the SwapTransformer model outperforms other models in different traffic densities in the inference phase."
scheduled curiosity-deep dyna-q: efficient exploration for dialog policy learning,"Training task-oriented dialog agents based on reinforcement learning is time-consuming and requires a large number of interactions with real users. How to grasp dialog policy within limited dialog experiences remains an obstacle that makes the agent training process less efficient. In addition, most previous frameworks start training by randomly choosing training samples, which differs from the human learning method and hurts the efficiency and stability of training. Therefore, we propose Scheduled Curiosity-Deep Dyna-Q (SC-DDQ), a curiosity-driven curriculum learning framework based on a state-of- the-art model-based reinforcement learning dialog model, Deep Dyna-Q (DDQ). Furthermore, we design ed learning schedules for SC-DDQ and DDQ, respectively, following two opposite training strategies: classic curriculum learning and its reverse version. Our results show that by introducing scheduled learning and curiosity, the new framework leads to a significant improvement over the DDQ and Deep Q-learning (DQN). Surprisingly, we found that traditional curriculum learning was not always effective. Specifically, according to the experimental results, the easy-first and difficult-first strategies are more suitable for SC-DDQ and DDQ. To analyze our results, we adopt ed the entropy of sampled actions to depict action exploration and found that training strategies with high entropy in the first stage and low entropy in the last stage lead to better performance."
efficient uavs deployment and resource allocation in uav-relay assisted public safety networks for video transmission,"Wireless communication highly depends on the cellular ground base station (GBS). A failure of the cellular GBS, fully or partially, during natural or man-made disasters creates a communication gap in the disaster-affected areas. In such situations, public safety communication (PSC) can significantly save the national infrastructure, property, and lives. Throughout emergencies, the PSC can provide mission-critical communication and video transmission services in the affected area. Unmanned aerial vehicles (UAVs) as flying base stations (UAV-BSs) are particularly suitable for PSC services as they are flexible, mobile, and easily deployable. This manuscript considers a multi-UAV-assisted PSC network with an observational UAV receiving videos from the affected area’s ground users (AGUs) and transmitting them to the nearby GBS via a relay UAV. The objective of the proposed study is to maximize the average utility of the video streams generated by the AGUs upon reaching the GBS. This is achieved by optimizing the positions of the observational and relay UAVs, as well as the distribution of communication resources, such as bandwidth, and transmit power, while satisfying the system-designed constraints, such as transmission rate, rate outage probability, transmit power budget, and available bandwidth. To this end, a joint UAVs placement and resource allocation problem is mathematically formulated. The proposed problem poses a significant challenge for a solution. Considering the block coordinate descent and successive convex approximation techniques, an efficient iterative algorithm is proposed. Finally, simulation results are provided which show that our proposed approach outperforms the existing methods."
enhanced security and efficiency in blockchain with aggregated zero-knowledge proof mechanisms,"Blockchain technology has emerged as a revolutionary tool in ensuring data integrity and security in digital transactions. However, the current approaches to data verification in blockchain systems, particularly in Ethereum, face challenges in terms of efficiency and computational overhead. The traditional use of Merkle Trees and cryptographic hash functions, while effective, leads to significant resource consumption, especially for large datasets. This highlights a gap in existing research: the need for more efficient methods of data verification in blockchain networks. Our study addresses this gap by proposing an innovative aggregation scheme for Zero-Knowledge Proofs within the structure of Merkle Trees. We develop a system that significantly reduces the size of the proof and the computational resources needed for its generation and verification. Our approach represents a paradigm shift in blockchain data verification, balancing security with efficiency. We conducted extensive experimental evaluations using real Ethereum block data to validate the effectiveness of our proposed scheme. The results demonstrate a drastic reduction in proof size and computational requirements compared to traditional methods, making the verification process more efficient and economically viable. Our contribution fills a critical research void, offering a scalable and secure solution for blockchain data verification. The implications of our work are far-reaching, enhancing the overall performance and adaptability of blockchain technology in various applications, from financial transactions to supply chain management."
"forging the industrial metaverse for industry 5.0: where extended reality, iiot, opportunistic edge computing, and digital twins meet","The Industrial Metaverse can benefit from the concepts fostered by Industry 5.0, since it implies making use of dynamic and up-to-date content, as well as fast human-to-machine interactions. To enable such enhancements, this article proposes the concept of Meta-Operator, which is essentially an industrial worker that follows the principles of Industry 5.0 and interacts with Industrial Metaverse applications and with his/her surroundings through advanced Extended Reality (XR) devices. In order to build the foundations of future Meta-Operators, this article provides a thorough description of the main technologies that support such a concept: the main components of the Industrial Metaverse, the latest XR technologies and accessories and the use of Opportunistic Edge Computing (OEC) communications (to detect and interact with the surrounding Internet of Things (IoT) and Industrial IoT (IIoT) devices). Moreover, this paper analyzes how to create the next generation of Industrial Metaverse applications based on the Industry 5.0 concepts, including the most relevant standardization initiatives, the integration of AR/MR devices with IoT/IIoT solutions, the development of advanced communications and software architectures and the creation of shared experiences and opportunistic collaborative protocols. Finally, this article provides an extensive list of potential Industry 5.0 applications for the Industrial Metaverse and analyzes thoroughly the main challenges and research lines. Thus, this article provides a holistic view and useful guidelines for the future developers and researchers that will create the next generation of applications for the Industrial Metaverse."
sonotracelab—a raytracing-based acoustic modeling system for simulating echolocation behavior of bats,"Echolocation is the prime sensing modality for many species of bats, who show the intricate ability to perform a plethora of tasks in complex and unstructured environments. Understanding this exceptional feat of sensorimotor interaction is a key aspect into building more robust and performant man-made sonar sensors. In order to better understand the underlying perception mechanisms it is important to get a good insight into the nature of the reflected signals that the bat perceives. While ensonification experiments are an important way to better understand the nature of these signals, they are as time-consuming to perform as they are informative. In this paper we present SonoTraceLab, an open-source software package for simulating both technical as well as biological sonar systems in complex scenes. Using simulation approaches can drastically increase insights into the nature of biological echolocation systems, while reducing the time- and material complexity of performing them."
gaussian embedding of temporal networks,"Representing the nodes of continuous-time temporal graphs in a low-dimensional latent space has wide-ranging applications, from prediction to visualization. Yet, analyzing continuous-time relational data with timestamped interactions introduces unique challenges due to its sparsity. Merely embedding nodes as trajectories in the latent space overlooks this sparsity. However, a natural way to account for this sparsity is to model the uncertainty around the latent positions. In this paper, we propose TGNE (Temporal Gaussian Network Embedding), an innovative method that bridges two distinct strands of literature: the statistical analysis of networks via Latent Space Models (LSM) and temporal graph machine learning. TGNE embeds nodes as piece-wise linear trajectories of Gaussian distributions in the latent space, capturing both structural information and uncertainty around the trajectories. We evaluate TGNE’s effectiveness in reconstructing the original graph and modelling uncertainty. The results demonstrate that TGNE generates time-varying embedding locations that can accurately reconstruct missing parts of the network based on observed ones. Furthermore, the uncertainty estimates align experimentally with the time-varying degree distribution in the network, providing valuable insights into the temporal dynamics of the graph. To facilitate reproducibility, we provide an open-source implementation of TGNE at https://github.com/aida-ugent/tgne/."
a quality-aware voltage overscaling framework to improve the energy efficiency and lifetime of tpus based on statistical error modeling,"Deep neural networks (DNNs) are a type of artificial intelligence models that are inspired by the structure and function of the human brain, designed to process and learn from large amounts of data, making them particularly well-suited for tasks such as image and speech recognition. However, applications of DNNs are experiencing emerging growth due to the deployment of specialized accelerators such as the Google’s Tensor Processing Units (TPUs). In large-scale deployments, the energy efficiency of such accelerators may become a critical concern. In the voltage overscaling (VOS) technique, the operating voltage of the system is scaled down beyond the nominal operating voltage, which increases the energy efficiency and lifetime of digital circuits. The VOS technique is usually performed without changing the frequency resulting in timing errors. However, some applications such as multimedia processing, including DNNs, have intrinsic resilience against errors and noise. In this paper, we exploit the inherent resilience of DNNs to propose a quality-aware voltage overscaling framework for TPUs, named X-TPU, which offers higher energy efficiency and lifetime compared to conventional TPUs. The X-TPU framework is composed of two main parts, a modified TPU architecture that supports a runtime voltage overscaling, and a statistical error modeling-based algorithm to determine the voltage of neurons such that the output quality is retained above a given user-defined quality threshold. We synthesized a single-neuron architecture using a 15-nm FinFET technology under various operating voltage levels. Then, we extracted different statistical error models for a neuron corresponding to those voltage levels. Using these models and the proposed algorithm, we determined the appropriate voltage of each neuron (the voltage level of each column of the X-TPU). Results show that running a DNN on X-TPU can achieve 32% energy saving for only 0.6% accuracy loss."
power flow analysis using deep neural networks in three-phase unbalanced smart distribution grids,"Most power systems’ approaches are currently tending towards stochastic and probabilistic methods due to the high variability of renewable sources and the stochastic nature of loads. Conventional power flow (PF) approaches such as forward-backward sweep (FBS) and Newton-Raphson require a high number of iterations to solve non-linear PF equations making them computationally very intensive. PF is the most important study performed by utility, required in all stages of the power system, especially in operations and planning. This paper discusses the applications of deep learning (DL) to predict PF solutions for three-phase unbalanced power distribution grids. Three deep neural networks (DNNs); Radial Basis Function Network (RBFnet), Multi-Layer Perceptron (MLP), and Convolutional Neural Network (CNN), are proposed in this paper to predict PF solutions. The strength of the proposed DNN models over the traditional iterative-based PF solvers is that these models can capture the nonlinear relationships in PF calculations to accurately predict the solutions. The PF problem is formulated as a multi-output regression model where two or more output values are predicted based on the inputs. The training and testing data are generated through the OpenDSS-MATLAB COM interface. These methods are completely data-driven where the training relies on reducing the mismatch at each node without the need for the knowledge of the system. The novelty of the proposed methodology is that the models can accurately predict the PF solutions for the unbalanced distribution grids with mutual coupling and are robust to different R/X ratios, topology changes as well as generation and load variability introduced by the integration of distributed energy resources (DERs) and electric vehicles (EVs). To test the efficacy of the DNN models, they are applied to IEEE 4-node and 123-node test cases, and the American Electric Power (AEP) feeder model. The PF results for RBFnet, MLP, and CNN models are discussed in this paper which demonstrate that all three DNN models provide highly accurate results in predicting PF solutions."
"how good is chatgpt at face biometrics? a first look into recognition, soft biometrics, and explainability","Large Language Models (LLMs) such as GPT developed by OpenAI, have already shown astonishing results, introducing quick changes in our society. This has been intensified by the release of ChatGPT which allows anyone to interact in a simple conversational way with LLMs, without any experience in the field needed. As a result, ChatGPT has been rapidly applied to many different tasks such as code- and song-writer, education, virtual assistants, etc., showing impressive results for tasks for which it was not trained (zero-shot learning). The present study aims to explore the ability of ChatGPT, based on the recent GPT-4 multimodal LLM, for the task of face biometrics. In particular, we analyze the ability of ChatGPT to perform tasks such as face verification, soft-biometrics estimation, and explainability of the results. ChatGPT could be very valuable to further increase the explainability and transparency of automatic decisions in human scenarios. Experiments are carried out in order to evaluate the performance and robustness of ChatGPT, using popular public benchmarks and comparing the results with state-of-the-art methods in the field. The results achieved in this study show the potential of LLMs such as ChatGPT for face biometrics, especially to enhance explainability. For reproducibility reasons, we release all the code in GitHub."
logical synchrony networks: a formal model for deterministic distribution,"In the modelling of distributed systems, most Model of Computations (MoCs) rely on blocking communication to preserve determinism. A prominent example is Kahn Process Networks (KPNs), which supports non-blocking writes and blocking reads, and its implementable variant Finite FIFO Platforms (FFPs) which enforces boundedness using blocking writes. An issue with these models is that they mix process synchronisation with process execution, necessitating frequent blocking during synchronisation. This paper explores a recent alternative called bittide, which decouples the execution of a process from the synchronisation behaviour. Determinism and boundedness is preserved while enabling pipelined execution for better throughput. To understand the behaviour of these systems we define a formal model – a deterministic MoC called Logical Synchrony Networks (LSNs). LSNs describes a network of processes modelled as a graph, with edges representing invariant logical delays between a producer process and the corresponding consumer process. We show that this abstraction is satisfied by the KPN model, and subsequently by both the concrete FFPs and bittide architectures. Thus, we show that FFPs and bittide offer two ways of implementing deterministic distributed systems, with the latter being more performant."
npix2cpix: a gan-based image-to-image translation network with retrieval- classification integration for watermark retrieval from historical document images,"The identification and restoration of ancient watermarks have long been a major topic in codicology and history. Classifying historical documents based on watermarks is challenging due to their diversity, noisy samples, multiple representation modes, and minor distinctions between classes and intra-class variations. This paper proposes a modified U-net-based conditional generative adversarial network (GAN) named Npix2Cpix to translate noisy raw historical watermarked images into clean, handwriting-free watermarked images by performing image translation from degraded (noisy) pixels to clean pixels. Using image-to-image translation and adversarial learning, the network creates clutter-free images for watermark restoration and categorization. The generator and discriminator of the proposed GAN are trained using two separate loss functions, each based on the distance between images, to learn the mapping from the input noisy image to the output clean image. After using the proposed GAN to pre-process noisy watermarked images, Siamese-based one-shot learning is employed for watermark classification. Experimental results on a large-scale historical watermark dataset demonstrate that cleaning the noisy watermarked images can help to achieve high one-shot classification accuracy. The qualitative and quantitative evaluation of the retrieved watermarked image highlights the effectiveness of the proposed approach."
vi-pann: harnessing transfer learning and uncertainty-aware variational inference for improved generalization in audio pattern recognition,"Transfer learning (TL) is an increasingly popular approach to training deep learning (DL) models that leverages the knowledge gained by training a foundation model on diverse, large-scale datasets for use on downstream tasks where less domain- or task-specific data is available. The literature is rich with TL techniques and applications; however, the bulk of the research makes use of deterministic DL models which are often uncalibrated and lack the ability to communicate a measure of epistemic (model) uncertainty in prediction. Unlike their deterministic counterparts, Bayesian DL (BDL) models are often well-calibrated, provide access to epistemic uncertainty for a prediction, and are capable of achieving competitive predictive performance. In this study, we propose variational inference pre-trained audio neural networks (VI-PANNs). VI-PANNs are a variational inference variant of the popular ResNet-54 architecture which are pre-trained on AudioSet, a large-scale audio event detection dataset. We evaluate the quality of the resulting uncertainty when transferring knowledge from VI-PANNs to other downstream acoustic classification tasks using the ESC-50, UrbanSound8K, and DCASE2013 datasets. We demonstrate, for the first time, that it is possible to transfer calibrated uncertainty information along with knowledge from upstream tasks to enhance a model’s capability to perform downstream tasks."
adversarial robustness of deep learning-based malware detectors via (de)randomized smoothing,"Deep learning-based malware detectors have been shown to be susceptible to adversarial malware examples, i.e. malware examples that have been deliberately manipulated in order to avoid detection. In light of the vulnerability of deep learning detectors to subtle input file modifications, we propose a practical defense against adversarial malware examples inspired by (de)randomized smoothing. In this work, we reduce the chances of sampling adversarial content injected by malware authors by selecting correlated subsets of bytes, rather than using Gaussian noise to randomize inputs like in the Computer Vision domain. During training, our chunk-based smoothing scheme trains a base classifier to make classifications on a subset of contiguous bytes or chunk of bytes. At test time, a large number of chunks are then classified by a base classifier and the consensus among these classifications is then reported as the final prediction. We propose two strategies to determine the location of the chunks used for classification: 1) randomly selecting the locations of the chunks and 2) selecting contiguous adjacent chunks. To showcase the effectiveness of our approach, we have trained two classifiers with our chunk-based smoothing schemes on the BODMAS dataset. Our findings reveal that the chunk-based smoothing classifiers exhibit greater resilience against adversarial malware examples generated with state-of-the-art evasion attacks, outperforming a non-smoothed classifier and a randomized smoothing-based classifier by a great margin."
exploring the influence of dimensionality reduction on anomaly detection performance in multivariate time series,"This paper presents an extensive empirical study on the integration of dimensionality reduction techniques with advanced unsupervised time series anomaly detection models, focusing on the MUTANT and Anomaly-Transformer models. The study involves a comprehensive evaluation across three different datasets: MSL, SMAP, and SWaT. Each dataset poses unique challenges, allowing for a robust assessment of the models’ capabilities in varied contexts. The dimensionality reduction techniques examined include PCA, UMAP, Random Projection, and t-SNE, each offering distinct advantages in simplifying high-dimensional data. Our findings reveal that dimensionality reduction not only aids in reducing computational complexity but also significantly enhances anomaly detection performance in certain scenarios. Moreover, a remarkable reduction in training times was observed, with reductions by approximately 300% and 650% when dimensionality was halved and minimized to the lowest dimensions, respectively. This efficiency gain underscores the dual benefit of dimensionality reduction in both performance enhancement and operational efficiency. The MUTANT model exhibits notable adaptability, especially with UMAP reduction, while the Anomaly-Transformer demonstrates versatility across various reduction techniques. These insights provide a deeper understanding of the synergistic effects of dimensionality reduction and anomaly detection, contributing valuable perspectives to the field of time series analysis. The study underscores the importance of selecting appropriate dimensionality reduction strategies based on specific model requirements and dataset characteristics, paving the way for more efficient, accurate, and scalable solutions in anomaly detection."
transfer learning-assisted inverse modeling in nanophotonics based on mixture density networks,"The simulation of nanophotonic structures relies on electromagnetic solvers, which play a crucial role in understanding their behavior. However, these solvers often come with a significant computational cost, making their application in design tasks, such as optimization, impractical. To address this challenge, machine learning techniques have been explored for accurate and efficient modeling and design of photonic devices. Deep neural networks, in particular, have gained considerable attention in this field. They can be used to create both forward and inverse models. An inverse modeling approach avoids the need for coupling a forward model with an optimizer and directly performs the prediction of the optimal design parameters values. In this paper, we propose an inverse modeling method for nanophotonic structures, based on a mixture density network model enhanced by transfer learning. Mixture density networks can predict multiple possible solutions at a time including their respective importance as Gaussian distributions. However, multiple challenges exist for mixture density network models. An important challenge is that an upper bound on the number of possible simultaneous solutions needs to be specified in advance. Also, another challenge is that the model parameters must be jointly optimized, which can result computationally expensive. Moreover, optimizing all parameters simultaneously can result numerically unstable and lead to degenerate predictions. The proposed approach copes with these limitations using transfer learning-based techniques, while obtaining accurate results in the prediction of the design solutions given an optical response as an input. A dimensionality reduction step is also explored. Numerical results validate the proposed method."
machine learning for healthcare-iot security: a review and risk mitigation,"The Healthcare Internet-of-Things (H-IoT), commonly known as Digital Healthcare, is a data-driven infrastructure that highly relies on smart sensing devices (i.e., blood pressure monitors, temperature sensors, etc.) for faster response time, treatments, and diagnosis. However, with the evolving cyber threat landscape, IoT devices have become more vulnerable to the broader risk surface (e.g., risks associated with generative AI, 5G-IoT, etc.), which, if exploited, may lead to data breaches, unauthorized access, and lack of command and control and potential harm. This paper reviews the fundamentals of healthcare IoT, its privacy, and data security challenges associated with machine learning and H-IoT devices. The paper further emphasizes the importance of monitoring healthcare IoT layers such as perception, network, cloud, and application. Detecting and responding to anomalies involves various cyber-attacks and protocols such as Wi-Fi 6, Narrowband Internet of Things (NB-IoT), Bluetooth, ZigBee, LoRa, and 5G New Radio (5G NR). A robust authentication mechanism based on machine learning and deep learning techniques is required to protect and mitigate H-IoT devices from increasing cybersecurity vulnerabilities. Hence, in this review paper, security and privacy challenges and risk mitigation strategies for building resilience in H-IoT are explored and reported."
programmablegrass: a shape-changing artificial grass display adapted for dynamic and interactive display features,"There are various proposals for employing grass materials as a green landscape-friendly display. However, it is difficult for current techniques to display smooth animations using 8-bit images and to adjust display resolution, similar to conventional displays. We present ProgrammableGrass, an artificial grass display with scalable resolution, capable of swiftly controlling grass color at 8-bit levels. This grass display can control grass colors linearly at the 8-bit level, similar to an LCD display, and can also display not only 8-bit -based images but also videos. This display enables pixel-by-pixel color transitions from yellow to green using fixed-length yellow and adjustable-length green grass. We designed a grass module that can be connected to other modules. Utilizing a proportional derivative control, the grass colors are manipulated to display animations at approximately 10 [fps]. Since the relationship between grass lengths and colors is nonlinear, we developed a calibration system for ProgrammableGrass. We revealed that this calibration system allows ProgrammableGrass to linearly control grass colors at 8-bit levels through experiments under multiple conditions. Lastly, we demonstrate ProgrammableGrass to show smooth animations with 8-bit grayscale images. Moreover, we show several application examples to illustrate the potential of ProgrammableGrass. With the advancement of this technology, users will be able to treat grass as a green-based interactive display device."
avi-talking: learning audio-visual instructions for expressive 3d talking face generation,"While considerable progress has been made in achieving accurate lip synchronization for 3D speech-driven talking face generation, the task of incorporating expressive facial detail synthesis aligned with the speaker’s speaking status remains challenging. Existing efforts either focus on learning a dynamic talking head pose synchronized with speech rhythm or aim for stylized facial movements guided by external reference such as emotional labels or reference video clips. The former works often yield coarse alignment, neglecting the emotional nuances present in the audio content while the latter studies lead to unnatural applications, requiring manual style source selection by users. Our goal is to directly leverage the inherent style information conveyed by human speech for generating an expressive talking face that aligns with the speaking status. In this paper, we propose AVI-Talking, an Audio-Visual Instruction system for expressive Talking face generation. This system harnesses the robust contextual reasoning and hallucination capability offered by Large Language Models (LLMs) to instruct the realistic synthesis of 3D talking faces. Instead of directly learning facial movements from human speech, our two-stage strategy involves the LLMs first comprehending audio information and generating instructions implying expressive facial details seamlessly corresponding to the speech. Subsequently, a diffusion-based generative network executes these instructions. This two-stage process, coupled with the incorporation of LLMs, enhances model interpretability and provides users with flexibility to comprehend instructions and specify desired operations or modifications. Specifically, given a speech clip, we first employ a Q-Former for contrastive alignment the speech features with visual instructions, which is then projected to input text embedding of LLMs. It functions as a prompting strategy, prompting LLMs to generate plausible visual instructions that encompass diverse facial details. In order to use these predicted instructions, a language-guided talking face generation system with disentangled latent space is delicately derived, where the speech content related lip movements and emotion correlated facial expressions are separately represented in speech content space and content irrelevant space. Additionally, we introduce a contrastive instruction-style alignment and diffusion technique within the content-irrelevant space to fully exploit the talking prior network for diverse instruction-following synthesis. Extensive experiments showcase the effectiveness of our approach in producing vivid talking faces with expressive facial movements and consistent emotional status."
keeping deep learning models in check: a history-based approach to mitigate overfitting,"In software engineering, deep learning models are increasingly deployed for critical tasks such as bug detection and code review. However, overfitting remains a challenge that affects the quality, reliability, and trustworthiness of software systems that utilize deep learning models. Overfitting can be (1) prevented (e.g., using dropout or early stopping) or (2) detected in a trained model (e.g., using correlation-based approaches). Both overfitting detection and prevention approaches that are currently used have constraints (e.g., requiring modification of the model structure, and high computing resources). In this paper, we propose a simple, yet powerful approach that can both detect and prevent overfitting based on the training history (i.e., validation losses). Our approach first trains a time series classifier on training histories of overfit models. This classifier is then used to detect if a trained model is overfit. In addition, our trained classifier can be used to prevent overfitting by identifying the optimal point to stop a model’s training. We evaluate our approach on its ability to identify and prevent overfitting in real-world samples. We compare our approach against correlation-based detection approaches and the most commonly used prevention approach (i.e., early stopping). Our approach achieves an F1 score of 0.91 which is at least 5% higher than the current best-performing non-intrusive overfitting detection approach. Furthermore, our approach can stop training to avoid overfitting at least 32% of the times earlier than early stopping and has the same or a better rate of returning the best model."
improving the representativeness of simulation intervals for the cache memory system,"Accurate simulation techniques are indispensable to efficiently propose new memory or architectural organizations. As implementing new hardware concepts in real systems is often not feasible, cycle-accurate simulators employed together with certain benchmarks are commonly used. However, detailed simulators may take too much time to execute these programs until completion. Therefore, several techniques aimed at reducing this time are usually employed. These schemes select fragments of the source code considered as representative of the entire application’s behaviour–mainly in terms of performance, but not plenty considering the behaviour of cache memory levels–and only these intervals are simulated. Our hypothesis is that the different simulation windows currently employed when evaluating microarchitectural proposals, especially those involving the last level cache (LLC), do not reproduce the overall cache behaviour during the entire execution, potentially leading to wrong conclusions on the real performance of the proposals assessed. In this work, we first demonstrate this hypothesis by evaluating different cache replacement policies using various typical simulation approaches. Consequently, we also propose a simulation strategy, based on the applications’ LLC activity, which mimics the overall behaviour of the cache much closer than conventional simulation intervals. Our proposal allows a fairer comparison between cache-related approaches as it reports, on average, a number of changes in the relative order among the policies assessed – with respect to the full simulation – more than 30% lower than that of conventional strategies, maintaining the simulation time largely unchanged and without losing accuracy on performance terms, especially for memory-intensive applications."
spatial clustering approach for vessel path identification,"This paper addresses the challenge of identifying the paths for vessels with operating routes of repetitive paths, partially repetitive paths, and new paths. We propose a spatial clustering approach for labeling the vessel paths by using only position information. We develop a path clustering framework employing two methods: a distance-based path modeling and a likelihood estimation method. The former enhances the accuracy of path clustering through the integration of unsupervised machine learning techniques, while the latter focuses on likelihood-based path modeling and introduces segmentation for a more detailed analysis. The result findings highlight the superior performance and efficiency of the developed approach, as both methods for clustering vessel paths into five clusters achieve a perfect F1-score. The approach aims to offer valuable insights for route planning, ultimately contributing to improving safety and efficiency in maritime transportation."
long-term human participation assessment in collaborative learning environments using dynamic scene analysis,"The paper develops datasets and methods to assess student participation in real-life collaborative learning environments. In collaborative learning environments, students are organized into small groups where they are free to interact within their group. Thus, students can move around freely causing issues with strong pose variation, move out and re-enter the camera scene, or face away from the camera. We formulate the problem of assessing student participation into two subproblems: (i) student group detection against strong background interference from other groups, and (ii) dynamic participant tracking within the group. A massive independent testing dataset of 12,518,250 student label instances, of total duration of 21 hours and 22 minutes of real-life videos, is used for evaluating the performance of our proposed method for student group detection. The proposed method of using multiple image representations is shown to perform equally or better than YOLO on all video instances. Over the entire dataset, the proposed method achieved an F1 score of 0.85 compared to 0.80 for YOLO. Following student group detection, the paper presents the development of a dynamic participant tracking system for assessing student group participation through long video sessions. The proposed dynamic participant tracking system is shown to perform exceptionally well, missing a student in just one out of 35 testing videos. In comparison, a state-of-the-art method fails to track students in 14 out of the 35 testing videos. The proposed method achieves 82.3% accuracy on an independent set of long, real-life collaborative videos."
evaluation of road user radio-frequency exposure levels in an urban environment from vehicular antennas and the infrastructure in its-g5 5.9 ghz communication,"This study aims to investigate the variability of exposure levels among road users generated in a realistic urban scenario by Vehicle-to-Vehicle (V2V) and Vehicle-to-Infrastructure (V2I) communication technologies operating at 5.9 GHz. The exposure levels were evaluated in terms of whole-body Specific Absorption Rate (wbSAR) [W/kg] in three different human models, ranging from children to adults. We calculated the electromagnetic field exposure level generated by V2V and V2I using raytracing and we assessed wbSAR resulting in urban exposure scenarios with an increasing number of transmitting antennas. Whole-body SAR was generally very low, on the order of 10−4 W/kg. The maximum wbSAR, of $4.9\cdot 10^{-4}$ W/kg, was obtained in the worst-case exposure condition comprising more than one transmitting vehicle and was found in the adult model for a distance within 10 m from the transmitting cars. We found that the height of the human model highly impacted the exposure level. Namely, the child (which is the shortest human model) was generally much less exposed than adults. All the wbSAR values found by varying the number of transmitting antennas, the distance of the road user from the antennas, and the type of human model (adult vs. child) were very well below the limits set by the ICNIRP guidelines and IEEE standard of 0.08 W/kg for exposure of the general population or persons in unrestricted environments in the 100 kHz – 300 GHz range."
self-corrective sensor fusion for drone positioning in indoor facilities,"Drones may be more advantageous than fixed cameras for quality control applications in industrial facilities, since they can be redeployed dynamically and adjusted to production planning. The practical scenario that has motivated this paper, image acquisition with drones in a car manufacturing plant, requires drone positioning accuracy in the order of 5 cm. During repetitive manufacturing processes, it is assumed that quality control imaging drones will follow highly deterministic periodic paths, stop at predefined points to take images and send them to image recognition servers. Therefore, by relying on prior knowledge about production chain schedules, it is possible to optimize the positioning technologies for the drones to stay at all times within the boundaries of their flight plans, which will be composed of stopping points and the paths in between. This involves mitigating issues such as temporary blocking of line-of-sight between the drone and any existing radio beacons; sensor data noise; and the loss of visual references. We present a self-corrective solution for this purpose. It corrects visual odometer readings based on filtered and clustered Ultra-Wide Band (UWB) data, as an alternative to direct Kalman fusion. The approach combines the advantages of these technologies when at least one of them works properly at any measurement spot. It has three method components: independent Kalman filtering, data association by means of stream clustering and mutual correction of sensor readings based on the generation of cumulative correction vectors. The approach is inspired by the observation that UWB positioning works reasonably well at static spots whereas visual odometer measurements reflect straight displacements correctly but can underestimate their length. Our experimental results demonstrate the advantages of the approach in the application scenario over Kalman fusion, in terms of stopping point detection and trajectory estimation error."
toward long range detection of elephants using seismic signals: a geophone-sensor interface for embedded systems,"The long-distance detection of the presence of elephants is pivotal to addressing the human-elephant conflict. IoT-based solutions utilizing seismic signals originating from the movement of elephants are a novel approach to solving this problem. This study introduces an instrumentation system comprising a specially designed geophone-sensor interface for non-invasive, long-range elephant detection using seismic waves while minimizing the vulnerability of seismic signals to noise. The geophone-sensor interface involves a cascade array of an instrumentation amplifier, a second-order Butterworth filter for signal filtering, and a signal amplifier. The introduced geophone-sensor interface was tested under laboratory conditions, and then real-world experiments were carried out for tamed, partly tamed, and untamed elephants. The experimental results reveal that the system remains stable within the tested frequency range from 1 Hz to 1 kHz and the temperature range of 10° C to 40° C. The system successfully captured the seismic signals generated by the footfalls of elephants within a maximum detection range of 155.6 m, with an overall detection accuracy of 99.5%."
simulator demonstration of large scale variational quantum algorithm on hpc cluster,"Advances in quantum simulator technology are increasingly required because research on quantum algorithms is becoming more sophisticated and complex. State vector simulation utilizes CPU and memory resources in computing nodes exponentially with respect to the number of qubits; furthermore, in a variational quantum algorithm, the large number of repeated runs by classical optimization is also a heavy load. This problem has been addressed by preparing numerous computing nodes or simulation frameworks that operate effectively. This study aimed to accelerate quantum simulation using two newly proposed methods: to efficiently utilize limited computational resources by adjusting the ratio of the MPI and distributed processing parallelism corresponding to the target problem settings and to slim down the Hamiltonian by considering the effect of accuracy on the calculation result. Ground-state energy calculations of a fermionic model were performed using a variational quantum eigensolver (VQE) on an HPC cluster with up to 1024 FUJITSU Processor A64FX connected to each other by InfiniBand; the processor is also used on supercomputer Fugaku. We achieved 200 times higher speed over VQE simulations and demonstrated 32 qubits ground-state energy calculations in acceptable time. This result indicates that > 30 qubit state vector simulations can be realistically utilized for further research on variational quantum algorithms."
two-stage stochastic optimal power flow for microgrids with uncertain wildfire effects,"Large-scale power outages caused by extreme weather events are one of the major factors weakening grid resilience. In order to prevent the critical infrastructure from cascading failure, power lines are often proactively de-energized under the threat of a progressing wildfire. In this context, the potential of microgrid (MG) functioning in islanded mode can be exploited to enhance the resiliency of the power grid. However, there are numerous uncertainties originating from these types of events and an accurate modeling of the MG is required to harness its full potential. In this paper, we consider the uncertainty in line outages depending on fire propagation and reduced solar power generation due to the particulate matter in wildfire smoke. We formulate a two-stage stochastic MG optimal power flow problem by utilizing a second-order cone relaxation of the DistFlow model. Leveraging an effective approximation of the resistive heat gain, we separate the complicating constraints of dynamic line rating from the resulting optimization problem. Extensive simulation results corroborate the merits of our proposed framework, which is tested on a modified IEEE 22-bus system."
pseudo-haptics survey: human-computer interaction in extended reality and teleoperation,"Pseudo-haptic techniques are becoming increasingly popular in human-computer interaction. They replicate haptic sensations by leveraging primarily visual feedback rather than mechanical actuators. These techniques bridge the gap between the real and virtual worlds by exploring the brain’s ability to integrate visual and haptic information. One of the many advantages of pseudo-haptic techniques is that they are cost-effective, portable, and flexible. They eliminate the need for direct attachment of haptic devices to the body, which can be heavy and large and require a lot of power and maintenance. Recent research has focused on applying these techniques to extended reality and mid-air interactions. To better understand the potential of pseudo-haptic techniques, the authors developed a novel taxonomy encompassing tactile feedback, kinesthetic feedback, and combined categories in multimodal approaches, ground not covered by previous surveys. This survey highlights multimodal strategies and potential avenues for future studies, particularly regarding integrating these techniques into extended reality and collaborative virtual environments."
gaussian splatting: 3d reconstruction and novel view synthesis: a review,"Image-based 3D reconstruction is a challenging task that involves inferring the 3D shape of an object or scene from a set of input images. Learning-based methods have gained attention for their ability to directly estimate 3D shapes. This review paper focuses on state-of-the-art techniques for 3D reconstruction, including the generation of novel, unseen views. An overview of recent developments in the Gaussian Splatting method is provided, covering input types, model structures, output representations, and training strategies. Unresolved challenges and future directions are also discussed. Given the rapid progress in this domain and the numerous opportunities for enhancing 3D reconstruction methods, a comprehensive examination of algorithms appears essential. Consequently, this study offers a thorough overview of the latest advancements in Gaussian Splatting."
systematic review of extended reality for smart built environments lighting design simulations,"This systematic literature review paper explores the use of extended reality (XR) technology for smart built environments and particularly for smart lighting systems design. Smart lighting is a novel concept that has emerged over a decade now and is being used and tested in commercial and industrial built environments. We used PRISMA methodology to review 270 research papers published from 1968 to 2023. Following a discussion of historical advances and key modeling techniques, a description of lighting simulation in the context of extended reality and smart built environment is given, followed by a discussion of the current trends and challenges."
explainable automatic industrial carbon footprint estimation from bank transaction classification using natural language processing,"Concerns about the effect of greenhouse gases have motivated the development of certification protocols to quantify the industrial carbon footprint (cf). These protocols are manual, work-intensive, and expensive. All of the above have led to a shift towards automatic data-driven approaches to estimate the cf, including Machine Learning (ml) solutions. Unfortunately, as in other sectors of interest, the decision-making processes involved in these solutions lack transparency from the end user’s point of view, who must blindly trust their outcomes compared to intelligible traditional manual approaches. In this research, manual and automatic methodologies for cf estimation were reviewed, taking into account their transparency limitations. This analysis led to the proposal of a new explainable ml solution for automatic cf calculations through bank transaction classification. Consideration should be given to the fact that no previous research has considered the explainability of bank transaction classification for this purpose. For classification, different ml models have been employed based on their promising performance in similar problems in the literature, such as Support Vector Machine, Random Forest, and Recursive Neural Networks. The results obtained were in the 90 % range for accuracy, precision, and recall evaluation metrics. From their decision paths, the proposed solution estimates the co2 emissions associated with bank transactions. The explainability methodology is based on an agnostic evaluation of the influence of the input terms extracted from the descriptions of transactions using locally interpretable models. The explainability terms were automatically validated using a similarity metric over the descriptions of the target categories. Conclusively, the explanation performance is satisfactory in terms of the proximity of the explanations to the associated activity sector descriptions, endorsing the trustworthiness of the process for a human operator and end users."
metastates: an approach for representing human workers’ psychophysiological states in the industrial metaverse,"Photo-realistic avatar is a modern term referring to the digital asset that represents a human in computer graphic advanced systems such as video games and simulation tools. These avatars utilize the advances in graphic technologies in both software and hardware aspects. While photo-realistic avatars are increasingly used in industrial simulations, representing human factors such as human workers’ psychophysiological states, remains a challenge. This article contributes to resolving this issue by introducing the novel concept of MetaStates which are the digitization and representation of the psychophysiological states of a human worker in the digital world. The MetaStates influence the physical representation and performance of a digital human worker while performing a task. To demonstrate this concept, this study presents the development of a photo-realistic avatar enhanced with multi-level graphical representations of psychophysiological states relevant to Industry 5.0. This approach represents a major step forward in the use of digital humans for industrial simulations, allowing companies to better leverage the benefits of the Industrial Metaverse in their daily operations and simulations while keeping human workers at the center of the system."
