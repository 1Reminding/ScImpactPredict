id,title,TNCSI,abstract,OA,authors_title
0ea03d3a-43d1-4906-8fae-b5468a31b3da,A knowledge graph representation learning approach to predict novel kinase-substrate interactions,0.479691,"The human proteome contains a vast network of interacting kinases and
substrates. Even though some kinases have proven to be immensely useful as
therapeutic targets, a majority are still understudied. In this work, we
present a novel knowledge graph representation learning approach to predict
novel interaction partners for understudied kinases. Our approach uses a
phosphoproteomic knowledge graph constructed by integrating data from iPTMnet,
Protein Ontology, Gene Ontology and BioKG. The representation of kinases and
substrates in this knowledge graph are learned by performing directed random
walks on triples coupled with a modified SkipGram or CBOW model. These
representations are then used as an input to a supervised classification model
to predict novel interactions for understudied kinases. We also present a
post-predictive analysis of the predicted interactions and an ablation study of
the phosphoproteomic knowledge graph to gain an insight into the biology of the
understudied kinases.",https://github.com/udel-cbcb/ikg_v2_public.git,-1
07fabc45-4826-4835-aa92-3889d5184f16,Unpaired Image Translation via Vector Symbolic Architectures,0.702435,"Image-to-image translation has played an important role in enabling synthetic
data for computer vision. However, if the source and target domains have a
large semantic mismatch, existing techniques often suffer from source content
corruption aka semantic flipping. To address this problem, we propose a new
paradigm for image-to-image translation using Vector Symbolic Architectures
(VSA), a theoretical framework which defines algebraic operations in a
high-dimensional vector (hypervector) space. We introduce VSA-based constraints
on adversarial learning for source-to-target translations by learning a
hypervector mapping that inverts the translation to ensure consistency with
source content. We show both qualitatively and quantitatively that our method
improves over other state-of-the-art techniques.",https://github.com/facebookresearch/vsait,146
07b18a80-5e9a-4bfc-94a3-2eec5ca48301,Better Intermediates Improve CTC Inference,0.028484,"This paper proposes a method for improved CTC inference with searched
intermediates and multi-pass conditioning. The paper first formulates
self-conditioned CTC as a probabilistic model with an intermediate prediction
as a latent representation and provides a tractable conditioning framework. We
then propose two new conditioning methods based on the new formulation: (1)
Searched intermediate conditioning that refines intermediate predictions with
beam-search, (2) Multi-pass conditioning that uses predictions of previous
inference for conditioning the next inference. These new approaches enable
better conditioning than the original self-conditioned CTC during inference and
improve the final performance. Experiments with the LibriSpeech dataset show
relative 3%/12% performance improvement at the maximum in test clean/other sets
compared to the original self-conditioned CTC.",None,-1
83d0199e-67d7-448e-ae41-3d65e9392a20,Categorical Tools for Natural Language Processing,0.0953772,"This thesis develops the translation between category theory and
computational linguistics as a foundation for natural language processing. The
three chapters deal with syntax, semantics and pragmatics. First, string
diagrams provide a unified model of syntactic structures in formal grammars.
Second, functors compute semantics by turning diagrams into logical, tensor,
neural or quantum computation. Third, the resulting functorial models can be
composed to form games where equilibria are the solutions of language
processing tasks. This framework is implemented as part of DisCoPy, the Python
library for computing with string diagrams. We describe the correspondence
between categorical, linguistic and computational structures, and demonstrate
their applications in compositional natural language processing.",https://github.com/oxford-quantum-group/discopy,-1
50a32756-278a-4c49-9cd4-fce476346a2d,Fair NLP Models with Differentially Private Text Encoders,0.332056,"Encoded text representations often capture sensitive attributes about
individuals (e.g., race or gender), which raise privacy concerns and can make
downstream models unfair to certain groups. In this work, we propose FEDERATE,
an approach that combines ideas from differential privacy and adversarial
training to learn private text representations which also induces fairer
models. We empirically evaluate the trade-off between the privacy of the
representations and the fairness and accuracy of the downstream model on four
NLP datasets. Our results show that FEDERATE consistently improves upon
previous methods, and thus suggest that privacy and fairness can positively
reinforce each other.",https://github.com/saist1993/DPNLP,-1
1964cf85-6b0d-4333-830f-9b74a6b2f4d8,Style Matters! Investigating Linguistic Style in Online Communities,0.2038,"Content has historically been the primary lens used to study language in
online communities. This paper instead focuses on the linguistic style of
communities. While we know that individuals have distinguishable styles, here
we ask whether communities have distinguishable styles. Additionally, while
prior work has relied on a narrow definition of style, we employ a broad
definition involving 262 features to analyze the linguistic style of 9 online
communities from 3 social media platforms discussing politics, television and
travel. We find that communities indeed have distinct styles. Also, style is an
excellent predictor of group membership (F-score 0.952 and Accuracy 96.09%).
While on average it is statistically equivalent to predictions using content
alone, it is more resilient to reductions in training data.",https://github.com/pushshift/api,8411
2095a4cf-fc43-49cd-be98-2f45472c0aca,DraftRec: Personalized Draft Recommendation for Winning in Multi-Player Online Battle Arena Games,0.882195,"This paper presents a personalized character recommendation system for
Multiplayer Online Battle Arena (MOBA) games which are considered as one of the
most popular online video game genres around the world. When playing MOBA
games, players go through a draft stage, where they alternately select a
virtual character to play. When drafting, players select characters by not only
considering their character preferences, but also the synergy and competence of
their team's character combination. However, the complexity of drafting induces
difficulties for beginners to choose the appropriate characters based on the
characters of their team while considering their own champion preferences. To
alleviate this problem, we propose DraftRec, a novel hierarchical model which
recommends characters by considering each player's champion preferences and the
interaction between the players. DraftRec consists of two networks: the player
network and the match network. The player network captures the individual
player's champion preference, and the match network integrates the complex
relationship between the players and their respective champions. We train and
evaluate our model from a manually collected 280,000 matches of League of
Legends and a publicly available 50,000 matches of Dota2. Empirically, our
method achieved state-of-the-art performance in character recommendation and
match outcome prediction task. Furthermore, a comprehensive user survey
confirms that DraftRec provides convincing and satisfying recommendations. Our
code and dataset are available at https://github.com/dojeon-ai/DraftRec.",https://github.com/dojeon-ai/DraftRec,12146
4a5d162c-439c-47bf-982b-507d2051e6d9,DimonGen: Diversified Generative Commonsense Reasoning for Explaining Concept Relationships,0.117042,"In this paper, we propose DimonGen, which aims to generate diverse sentences
describing concept relationships in various everyday scenarios. To support
this, we first create a benchmark dataset for this task by adapting the
existing CommonGen dataset. We then propose a two-stage model called MoREE to
generate the target sentences. MoREE consists of a mixture of retrievers model
that retrieves diverse context sentences related to the given concepts, and a
mixture of generators model that generates diverse sentences based on the
retrieved contexts. We conduct experiments on the DimonGen task and show that
MoREE outperforms strong baselines in terms of both the quality and diversity
of the generated sentences. Our results demonstrate that MoREE is able to
generate diverse sentences that reflect different relationships between
concepts, leading to a comprehensive understanding of concept relationships.",https://github.com/liuchenzhengyi/DimonGen,-1
6eedc5c2-6b8d-4bb9-8eb3-fd68e0836125,Graph Neural Network Bandits,0.169289,"We consider the bandit optimization problem with the reward function defined
over graph-structured data. This problem has important applications in molecule
design and drug discovery, where the reward is naturally invariant to graph
permutations. The key challenges in this setting are scaling to large domains,
and to graphs with many nodes. We resolve these challenges by embedding the
permutation invariance into our model. In particular, we show that graph neural
networks (GNNs) can be used to estimate the reward function, assuming it
resides in the Reproducing Kernel Hilbert Space of a permutation-invariant
additive kernel. By establishing a novel connection between such kernels and
the graph neural tangent kernel (GNTK), we introduce the first GNN confidence
bound and use it to design a phased-elimination algorithm with sublinear
regret. Our regret bound depends on the GNTK's maximum information gain, which
we also provide a bound for. While the reward function depends on all $N$ node
features, our guarantees are independent of the number of graph nodes $N$.
Empirically, our approach exhibits competitive performance and scales well on
graph-structured domains.",None,-1
304708e7-16bb-4968-96f0-753c9a704ddf,Calibration of Machine Reading Systems at Scale,0.330954,"In typical machine learning systems, an estimate of the probability of the
prediction is used to assess the system's confidence in the prediction. This
confidence measure is usually uncalibrated; i.e.\ the system's confidence in
the prediction does not match the true probability of the predicted output. In
this paper, we present an investigation into calibrating open setting machine
reading systems such as open-domain question answering and claim verification
systems. We show that calibrating such complex systems which contain discrete
retrieval and deep reading components is challenging and current calibration
techniques fail to scale to these settings. We propose simple extensions to
existing calibration approaches that allows us to adapt them to these settings.
Our experimental results reveal that the approach works well, and can be useful
to selectively predict answers when question answering systems are posed with
unanswerable or out-of-the-training distribution questions.",None,-1
a37af22e-315f-4815-93be-ef731b5dc6fa,Integrating Human-in-the-loop into Swarm Learning for Decentralized Fake News Detection,0.77687,"Social media has become an effective platform to generate and spread fake
news that can mislead people and even distort public opinion. Centralized
methods for fake news detection, however, cannot effectively protect user
privacy during the process of centralized data collection for training models.
Moreover, it cannot fully involve user feedback in the loop of learning
detection models for further enhancing fake news detection. To overcome these
challenges, this paper proposed a novel decentralized method, Human-in-the-loop
Based Swarm Learning (HBSL), to integrate user feedback into the loop of
learning and inference for recognizing fake news without violating user privacy
in a decentralized manner. It consists of distributed nodes that are able to
independently learn and detect fake news on local data. Furthermore, detection
models trained on these nodes can be enhanced through decentralized model
merging. Experimental results demonstrate that the proposed method outperforms
the state-of-the-art decentralized method in regard of detecting fake news on a
benchmark dataset.",None,-1
7246123d-666a-4a5f-8879-52ccc42f7ee2,Meta-Learning Parameterized Skills,0.102912,"We propose a novel parameterized skill-learning algorithm that aims to learn
transferable parameterized skills and synthesize them into a new action space
that supports efficient learning in long-horizon tasks. We propose to leverage
off-policy Meta-RL combined with a trajectory-centric smoothness term to learn
a set of parameterized skills. Our agent can use these learned skills to
construct a three-level hierarchical framework that models a
Temporally-extended Parameterized Action Markov Decision Process. We
empirically demonstrate that the proposed algorithms enable an agent to solve a
set of difficult long-horizon (obstacle-course and robot manipulation) tasks.",https://github.com/Minusadd/,-1
1dcf8741-a35d-4ba4-9d15-d2b5b0e392ab,"M-SpeechCLIP: Leveraging Large-Scale, Pre-Trained Models for Multilingual Speech to Image Retrieval",0.864665,"This work investigates the use of large-scale, English-only pre-trained
models (CLIP and HuBERT) for multilingual image-speech retrieval. For
non-English image-speech retrieval, we outperform the current state-of-the-art
performance by a wide margin both when training separate models for each
language, and with a single model which processes speech in all three
languages. We identify key differences in model behavior and performance
between English and non-English settings, attributable to the English-only
pre-training of CLIP and HuBERT, and investigate how fine-tuning the
pre-trained models impacts these differences. Finally, we show that our models
can be used for mono- and cross-lingual speech-text retrieval and cross-lingual
speech-speech retrieval, despite never having seen any parallel speech-text or
speech-speech data during training.",None,9523
12c23e9e-c962-49a6-9a21-b0cadd4cf9c3,Part-guided Relational Transformers for Fine-grained Visual Recognition,0.358089,"Fine-grained visual recognition is to classify objects with visually similar
appearances into subcategories, which has made great progress with the
development of deep CNNs. However, handling subtle differences between
different subcategories still remains a challenge. In this paper, we propose to
solve this issue in one unified framework from two aspects, i.e., constructing
feature-level interrelationships, and capturing part-level discriminative
features. This framework, namely PArt-guided Relational Transformers (PART), is
proposed to learn the discriminative part features with an automatic part
discovery module, and to explore the intrinsic correlations with a feature
transformation module by adapting the Transformer models from the field of
natural language processing. The part discovery module efficiently discovers
the discriminative regions which are highly-corresponded to the gradient
descent procedure. Then the second feature transformation module builds
correlations within the global embedding and multiple part embedding, enhancing
spatial interactions among semantic pixels. Moreover, our proposed approach
does not rely on additional part branches in the inference time and reaches
state-of-the-art performance on 3 widely-used fine-grained object recognition
benchmarks. Experimental results and explainable visualizations demonstrate the
effectiveness of our proposed approach. The code can be found at
https://github.com/iCVTEAM/PART.",https://github.com/iCVTEAM/PART,-1
4d1adb7c-ccb4-455f-bc5b-59426b85a047,High-Res Facial Appearance Capture from Polarized Smartphone Images,0.74146,"We propose a novel method for high-quality facial texture reconstruction from
RGB images using a novel capturing routine based on a single smartphone which
we equip with an inexpensive polarization foil. Specifically, we turn the
flashlight into a polarized light source and add a polarization filter on top
of the camera. Leveraging this setup, we capture the face of a subject with
cross-polarized and parallel-polarized light. For each subject, we record two
short sequences in a dark environment under flash illumination with different
light polarization using the modified smartphone. Based on these observations,
we reconstruct an explicit surface mesh of the face using structure from
motion. We then exploit the camera and light co-location within a
differentiable renderer to optimize the facial textures using an
analysis-by-synthesis approach. Our method optimizes for high-resolution normal
textures, diffuse albedo, and specular albedo using a coarse-to-fine
optimization scheme. We show that the optimized textures can be used in a
standard rendering pipeline to synthesize high-quality photo-realistic 3D
digital humans in novel environments.",None,-1
8a4b6c7d-fa36-45ab-a17c-f86bb8a9f4fc,Crosslingual Generalization through Multitask Finetuning,0.772832,"Multitask prompted finetuning (MTF) has been shown to help large language
models generalize to new tasks in a zero-shot setting, but so far explorations
of MTF have focused on English data and models. We apply MTF to the pretrained
multilingual BLOOM and mT5 model families to produce finetuned variants called
BLOOMZ and mT0. We find finetuning large multilingual language models on
English tasks with English prompts allows for task generalization to
non-English languages that appear only in the pretraining corpus. Finetuning on
multilingual tasks with English prompts further improves performance on English
and non-English tasks leading to various state-of-the-art zero-shot results. We
also investigate finetuning on multilingual tasks with prompts that have been
machine-translated from English to match the language of each dataset. We find
training on these machine-translated prompts leads to better performance on
human-written prompts in the respective languages. Surprisingly, we find models
are capable of zero-shot generalization to tasks in languages they have never
intentionally seen. We conjecture that the models are learning higher-level
capabilities that are both task- and language-agnostic. In addition, we
introduce xP3, a composite of supervised datasets in 46 languages with English
and machine-translated prompts. Our code, datasets and models are freely
available at https://github.com/bigscience-workshop/xmtf.",None,-1
ab2409b0-3911-4e9d-8f3e-928bf406c362,Enhancing Task Bot Engagement with Synthesized Open-Domain Dialog,0.603242,"Many efforts have been made to construct dialog systems for different types
of conversations, such as task-oriented dialog (TOD) and open-domain dialog
(ODD). To better mimic human-level conversations that usually fuse various
dialog modes, it is essential to build a system that can effectively handle
both TOD and ODD and access different knowledge sources. To address the lack of
available data for the fused task, we propose a framework for automatically
generating dialogues that combine knowledge-grounded ODDs and TODs in various
settings. Additionally, we introduce a unified model PivotBot that is capable
of appropriately adopting TOD and ODD modes and accessing different knowledge
sources in order to effectively tackle the fused task. Evaluation results
demonstrate the superior ability of the proposed model to switch seamlessly
between TOD and ODD tasks.",None,-1
b0812fb7-5330-45fe-926b-e20270beea4a,Imperceptible Adversarial Attack via Invertible Neural Networks,0.250418,"Adding perturbations via utilizing auxiliary gradient information or
discarding existing details of the benign images are two common approaches for
generating adversarial examples. Though visual imperceptibility is the desired
property of adversarial examples, conventional adversarial attacks still
generate traceable adversarial perturbations. In this paper, we introduce a
novel Adversarial Attack via Invertible Neural Networks (AdvINN) method to
produce robust and imperceptible adversarial examples. Specifically, AdvINN
fully takes advantage of the information preservation property of Invertible
Neural Networks and thereby generates adversarial examples by simultaneously
adding class-specific semantic information of the target class and dropping
discriminant information of the original class. Extensive experiments on
CIFAR-10, CIFAR-100, and ImageNet-1K demonstrate that the proposed AdvINN
method can produce less imperceptible adversarial images than the
state-of-the-art methods and AdvINN yields more robust adversarial examples
with high confidence compared to other adversarial attacks.",https://github.com/jjhuangcs/AdvINN,-1
dd6d5197-b3ae-4c3d-b46c-0fb78bd83592,PalGAN: Image Colorization with Palette Generative Adversarial Networks,0.595831,"Multimodal ambiguity and color bleeding remain challenging in colorization.
To tackle these problems, we propose a new GAN-based colorization approach
PalGAN, integrated with palette estimation and chromatic attention. To
circumvent the multimodality issue, we present a new colorization formulation
that estimates a probabilistic palette from the input gray image first, then
conducts color assignment conditioned on the palette through a generative
model. Further, we handle color bleeding with chromatic attention. It studies
color affinities by considering both semantic and intensity correlation. In
extensive experiments, PalGAN outperforms state-of-the-arts in quantitative
evaluation and visual comparison, delivering notable diverse, contrastive, and
edge-preserving appearances. With the palette design, our method enables color
transfer between images even with irrelevant contexts.",https://github.com/shepnerd/PalGAN,-1
c852c642-eedb-4805-9da2-e76f3d2ededf,Instruction Tuning for Few-Shot Aspect-Based Sentiment Analysis,0.881274,"Aspect-based Sentiment Analysis (ABSA) is a fine-grained sentiment analysis
task which involves four elements from user-generated texts: aspect term,
aspect category, opinion term, and sentiment polarity. Most computational
approaches focus on some of the ABSA sub-tasks such as tuple (aspect term,
sentiment polarity) or triplet (aspect term, opinion term, sentiment polarity)
extraction using either pipeline or joint modeling approaches. Recently,
generative approaches have been proposed to extract all four elements as (one
or more) quadruplets from text as a single task. In this work, we take a step
further and propose a unified framework for solving ABSA, and the associated
sub-tasks to improve the performance in few-shot scenarios. To this end, we
fine-tune a T5 model with instructional prompts in a multi-task learning
fashion covering all the sub-tasks, as well as the entire quadruple prediction
task. In experiments with multiple benchmark datasets, we show that the
proposed multi-task prompting approach brings performance boost (by absolute
8.29 F1) in the few-shot learning setting.",https://github.com/amazon-science/instruction-tuning-for-absa,-1
2d38072f-5c9f-4b7e-a50c-3926467104af,Event Transformer. A sparse-aware solution for efficient event data processing,0.917554,"Event cameras are sensors of great interest for many applications that run in
low-resource and challenging environments. They log sparse illumination changes
with high temporal resolution and high dynamic range, while they present
minimal power consumption. However, top-performing methods often ignore
specific event-data properties, leading to the development of generic but
computationally expensive algorithms. Efforts toward efficient solutions
usually do not achieve top-accuracy results for complex tasks. This work
proposes a novel framework, Event Transformer (EvT), that effectively takes
advantage of event-data properties to be highly efficient and accurate. We
introduce a new patch-based event representation and a compact transformer-like
architecture to process it. EvT is evaluated on different event-based
benchmarks for action and gesture recognition. Evaluation results show better
or comparable accuracy to the state-of-the-art while requiring significantly
less computation resources, which makes EvT able to work with minimal latency
both on GPU and CPU.",https://github.com/AlbertoSabater/EventTransformer,6081
35a8d24e-125a-41f8-a641-96c0c8e09077,StereoKG: Data-Driven Knowledge Graph Construction for Cultural Knowledge and Stereotypes,0.274136,"Analyzing ethnic or religious bias is important for improving fairness,
accountability, and transparency of natural language processing models.
However, many techniques rely on human-compiled lists of bias terms, which are
expensive to create and are limited in coverage. In this study, we present a
fully data-driven pipeline for generating a knowledge graph (KG) of cultural
knowledge and stereotypes. Our resulting KG covers 5 religious groups and 5
nationalities and can easily be extended to include more entities. Our human
evaluation shows that the majority (59.2%) of non-singleton entries are
coherent and complete stereotypes. We further show that performing intermediate
masked language model training on the verbalized KG leads to a higher level of
cultural awareness in the model and has the potential to increase
classification performance on knowledge-crucial samples on a related task,
i.e., hate speech detection.",https://github.com/uds-lsv/StereoKG,4373
a3b1cba4-e0fc-4bc9-b3ee-a6c33dca0d6c,Grouped Adaptive Loss Weighting for Person Search,0.0853963,"Person search is an integrated task of multiple sub-tasks such as
foreground/background classification, bounding box regression and person
re-identification. Therefore, person search is a typical multi-task learning
problem, especially when solved in an end-to-end manner. Recently, some works
enhance person search features by exploiting various auxiliary information,
e.g. person joint keypoints, body part position, attributes, etc., which brings
in more tasks and further complexifies a person search model. The inconsistent
convergence rate of each task could potentially harm the model optimization. A
straightforward solution is to manually assign different weights to different
tasks, compensating for the diverse convergence rates. However, given the
special case of person search, i.e. with a large number of tasks, it is
impractical to weight the tasks manually. To this end, we propose a Grouped
Adaptive Loss Weighting (GALW) method which adjusts the weight of each task
automatically and dynamically. Specifically, we group tasks according to their
convergence rates. Tasks within the same group share the same learnable weight,
which is dynamically assigned by considering the loss uncertainty. Experimental
results on two typical benchmarks, CUHK-SYSU and PRW, demonstrate the
effectiveness of our method.",None,-1
c0342fbf-94c3-4917-ac43-fb7bd85e6d05,Using Bottleneck Adapters to Identify Cancer in Clinical Notes under Low-Resource Constraints,0.31674,"Processing information locked within clinical health records is a challenging
task that remains an active area of research in biomedical NLP. In this work,
we evaluate a broad set of machine learning techniques ranging from simple RNNs
to specialised transformers such as BioBERT on a dataset containing clinical
notes along with a set of annotations indicating whether a sample is
cancer-related or not.
  Furthermore, we specifically employ efficient fine-tuning methods from NLP,
namely, bottleneck adapters and prompt tuning, to adapt the models to our
specialised task. Our evaluations suggest that fine-tuning a frozen BERT model
pre-trained on natural language and with bottleneck adapters outperforms all
other strategies, including full fine-tuning of the specialised BioBERT model.
Based on our findings, we suggest that using bottleneck adapters in
low-resource situations with limited access to labelled data or processing
capacity could be a viable strategy in biomedical text mining. The code used in
the experiments are going to be made available at
https://github.com/omidrohanian/bottleneck-adapters.",https://github.com/omidrohanian/bottleneck-adapters,-1
2c72d822-76a8-482a-b9ed-dd52deb5454a,Region Embedding with Intra and Inter-View Contrastive Learning,0.481917,"Unsupervised region representation learning aims to extract dense and
effective features from unlabeled urban data. While some efforts have been made
for solving this problem based on multiple views, existing methods are still
insufficient in extracting representations in a view and/or incorporating
representations from different views. Motivated by the success of contrastive
learning for representation learning, we propose to leverage it for multi-view
region representation learning and design a model called ReMVC (Region
Embedding with Multi-View Contrastive Learning) by following two guidelines: i)
comparing a region with others within each view for effective representation
extraction and ii) comparing a region with itself across different views for
cross-view information sharing. We design the intra-view contrastive learning
module which helps to learn distinguished region embeddings and the inter-view
contrastive learning module which serves as a soft co-regularizer to constrain
the embedding parameters and transfer knowledge across multi-views. We exploit
the learned region embeddings in two downstream tasks named land usage
clustering and region popularity prediction. Extensive experiments demonstrate
that our model achieves impressive improvements compared with seven
state-of-the-art baseline methods, and the margins are over 30% in the land
usage clustering task.",https://github.com/Liang-NTU/ReMVC,2797
3ed13204-7720-4412-8ce6-1100e86e9e15,Video Frame Interpolation with Transformer,0.114828,"Video frame interpolation (VFI), which aims to synthesize intermediate frames
of a video, has made remarkable progress with development of deep convolutional
networks over past years. Existing methods built upon convolutional networks
generally face challenges of handling large motion due to the locality of
convolution operations. To overcome this limitation, we introduce a novel
framework, which takes advantage of Transformer to model long-range pixel
correlation among video frames. Further, our network is equipped with a novel
cross-scale window-based attention mechanism, where cross-scale windows
interact with each other. This design effectively enlarges the receptive field
and aggregates multi-scale information. Extensive quantitative and qualitative
experiments demonstrate that our method achieves new state-of-the-art results
on various benchmarks.",https://github.com/dvlab-research/VFIformer,76411
28dc92f4-bd49-4e3c-80c7-b50786fdd600,Higher-order Clustering and Pooling for Graph Neural Networks,0.560582,"Graph Neural Networks achieve state-of-the-art performance on a plethora of
graph classification tasks, especially due to pooling operators, which
aggregate learned node embeddings hierarchically into a final graph
representation. However, they are not only questioned by recent work showing on
par performance with random pooling, but also ignore completely higher-order
connectivity patterns. To tackle this issue, we propose HoscPool, a
clustering-based graph pooling operator that captures higher-order information
hierarchically, leading to richer graph representations. In fact, we learn a
probabilistic cluster assignment matrix end-to-end by minimising relaxed
formulations of motif spectral clustering in our objective function, and we
then extend it to a pooling operator. We evaluate HoscPool on graph
classification tasks and its clustering component on graphs with ground-truth
community structure, achieving best performance. Lastly, we provide a deep
empirical analysis of pooling operators' inner functioning.",None,-1
57d24ffe-9217-4a5a-8d69-eda4ca03f0b0,Improving Cross-Modal Retrieval with Set of Diverse Embeddings,0.498425,"Cross-modal retrieval across image and text modalities is a challenging task
due to its inherent ambiguity: An image often exhibits various situations, and
a caption can be coupled with diverse images. Set-based embedding has been
studied as a solution to this problem. It seeks to encode a sample into a set
of different embedding vectors that capture different semantics of the sample.
In this paper, we present a novel set-based embedding method, which is distinct
from previous work in two aspects. First, we present a new similarity function
called smooth-Chamfer similarity, which is designed to alleviate the side
effects of existing similarity functions for set-based embedding. Second, we
propose a novel set prediction module to produce a set of embedding vectors
that effectively captures diverse semantics of input by the slot attention
mechanism. Our method is evaluated on the COCO and Flickr30K datasets across
different visual backbones, where it outperforms existing methods including
ones that demand substantially larger computation at inference.",None,-1
1055cc29-a8d8-4ef5-8d44-0fc13a887230,PSMNet: Position-aware Stereo Merging Network for Room Layout Estimation,0.824345,"In this paper, we propose a new deep learning-based method for estimating
room layout given a pair of 360 panoramas. Our system, called Position-aware
Stereo Merging Network or PSMNet, is an end-to-end joint layout-pose estimator.
PSMNet consists of a Stereo Pano Pose (SP2) transformer and a novel
Cross-Perspective Projection (CP2) layer. The stereo-view SP2 transformer is
used to implicitly infer correspondences between views, and can handle noisy
poses. The pose-aware CP2 layer is designed to render features from the
adjacent view to the anchor (reference) view, in order to perform view fusion
and estimate the visible layout. Our experiments and analysis validate our
method, which significantly outperforms the state-of-the-art layout estimators,
especially for large and complex room spaces.",None,28982
f71a861d-f652-4f33-b3db-aa66a5a5a408,Generalizing to the Future: Mitigating Entity Bias in Fake News Detection,0.722496,"The wide dissemination of fake news is increasingly threatening both
individuals and society. Fake news detection aims to train a model on the past
news and detect fake news of the future. Though great efforts have been made,
existing fake news detection methods overlooked the unintended entity bias in
the real-world data, which seriously influences models' generalization ability
to future data. For example, 97\% of news pieces in 2010-2017 containing the
entity `Donald Trump' are real in our data, but the percentage falls down to
merely 33\% in 2018. This would lead the model trained on the former set to
hardly generalize to the latter, as it tends to predict news pieces about
`Donald Trump' as real for lower training loss. In this paper, we propose an
entity debiasing framework (\textbf{ENDEF}) which generalizes fake news
detection models to the future data by mitigating entity bias from a
cause-effect perspective. Based on the causal graph among entities, news
contents, and news veracity, we separately model the contribution of each cause
(entities and contents) during training. In the inference stage, we remove the
direct effect of the entities to mitigate entity bias. Extensive offline
experiments on the English and Chinese datasets demonstrate that the proposed
framework can largely improve the performance of base fake news detectors, and
online tests verify its superiority in practice. To the best of our knowledge,
this is the first work to explicitly improve the generalization ability of fake
news detection models to the future data. The code has been released at
https://github.com/ICTMCG/ENDEF-SIGIR2022.",https://github.com/ICTMCG/ENDEF-SIGIR2022,-1
1f5a7c2a-b950-4e1f-84a2-723723065cc0,"Knock, knock. Who's there? -- Identifying football player jersey numbers with synthetic data",0.77021,"Automatic player identification is an essential and complex task in sports
video analysis. Different strategies have been devised over the years, but
identification based on jersey numbers is one of the most common approaches
given its versatility and relative simplicity. However, automatic detection of
jersey numbers is still challenging due to changing camera angles, low video
resolution, small object size in wide-range shots and transient changes in the
player's posture and movement. In this paper we present a novel approach for
jersey number identification in a small, highly imbalanced dataset from the
Seattle Seahawks practice videos. Our results indicate that simple models can
achieve an acceptable performance on the jersey number detection task and that
synthetic data can improve the performance dramatically (accuracy increase of
~9% overall, ~18% on low frequency numbers) making our approach achieve state
of the art results.",None,-1
a45102d3-5747-4d95-9be6-20c212dae0ea,Unsupervised Unlearning of Concept Drift with Autoencoders,0.562066,"Concept drift refers to a change in the data distribution affecting the data
stream of future samples. Consequently, learning models operating on the data
stream might become obsolete, and need costly and difficult adjustments such as
retraining or adaptation. Existing methods usually implement a local concept
drift adaptation scheme, where either incremental learning of the models is
used, or the models are completely retrained when a drift detection mechanism
triggers an alarm. This paper proposes an alternative approach in which an
unsupervised and model-agnostic concept drift adaptation method at the global
level is introduced, based on autoencoders. Specifically, the proposed method
aims to ``unlearn'' the concept drift without having to retrain or adapt any of
the learning models operating on the data. An extensive experimental evaluation
is conducted in two application domains. We consider a realistic water
distribution network with more than 30 models in-place, from which we create
200 simulated data sets / scenarios. We further consider an image-related task
to demonstrate the effectiveness of our method.",https://github.com/HammerLabML/UnsupervisedUnlearningConceptDriftAutoencoders,-1
5be1c56b-f6e5-4c0d-9715-bec8f4981a62,End-to-End Speech to Intent Prediction to improve E-commerce Customer Support Voicebot in Hindi and English,0.2387,"Automation of on-call customer support relies heavily on accurate and
efficient speech-to-intent (S2I) systems. Building such systems using
multi-component pipelines can pose various challenges because they require
large annotated datasets, have higher latency, and have complex deployment.
These pipelines are also prone to compounding errors. To overcome these
challenges, we discuss an end-to-end (E2E) S2I model for customer support
voicebot task in a bilingual setting. We show how we can solve E2E intent
classification by leveraging a pre-trained automatic speech recognition (ASR)
model with slight modification and fine-tuning on small annotated datasets.
Experimental results show that our best E2E model outperforms a conventional
pipeline by a relative ~27% on the F1 score.",None,-1
f0756b58-0d0c-4ad3-b802-c854e3376b7b,End-to-end Algorithm Synthesis with Recurrent Networks: Logical Extrapolation Without Overthinking,0.197419,"Machine learning systems perform well on pattern matching tasks, but their
ability to perform algorithmic or logical reasoning is not well understood. One
important reasoning capability is algorithmic extrapolation, in which models
trained only on small/simple reasoning problems can synthesize complex
strategies for large/complex problems at test time. Algorithmic extrapolation
can be achieved through recurrent systems, which can be iterated many times to
solve difficult reasoning problems. We observe that this approach fails to
scale to highly complex problems because behavior degenerates when many
iterations are applied -- an issue we refer to as ""overthinking."" We propose a
recall architecture that keeps an explicit copy of the problem instance in
memory so that it cannot be forgotten. We also employ a progressive training
routine that prevents the model from learning behaviors that are specific to
iteration number and instead pushes it to learn behaviors that can be repeated
indefinitely. These innovations prevent the overthinking problem, and enable
recurrent systems to solve extremely hard extrapolation tasks.",https://github.com/aks2203/deep-thinking,-1
69218241-ced2-4fd2-a626-aa7da4b03763,An Initial Investigation for Detecting Vocoder Fingerprints of Fake Audio,0.920893,"Many effective attempts have been made for fake audio detection. However,
they can only provide detection results but no countermeasures to curb this
harm. For many related practical applications, what model or algorithm
generated the fake audio also is needed. Therefore, We propose a new problem
for detecting vocoder fingerprints of fake audio. Experiments are conducted on
the datasets synthesized by eight state-of-the-art vocoders. We have
preliminarily explored the features and model architectures. The t-SNE
visualization shows that different vocoders generate distinct vocoder
fingerprints.",https://github.com/xiph/LPCNet.git,-1
1adf3521-b001-4b55-9a3f-52a571dadd36,StretchBEV: Stretching Future Instance Prediction Spatially and Temporally,0.709014,"In self-driving, predicting future in terms of location and motion of all the
agents around the vehicle is a crucial requirement for planning. Recently, a
new joint formulation of perception and prediction has emerged by fusing rich
sensory information perceived from multiple cameras into a compact bird's-eye
view representation to perform prediction. However, the quality of future
predictions degrades over time while extending to longer time horizons due to
multiple plausible predictions. In this work, we address this inherent
uncertainty in future predictions with a stochastic temporal model. Our model
learns temporal dynamics in a latent space through stochastic residual updates
at each time step. By sampling from a learned distribution at each time step,
we obtain more diverse future predictions that are also more accurate compared
to previous work, especially stretching both spatially further regions in the
scene and temporally over longer time horizons. Despite separate processing of
each time step, our model is still efficient through decoupling of the learning
of dynamics and the generation of future predictions.",https://kuis-ai.github.io/stretchbev,111
5fadd2dd-3c74-4c8f-b0df-41cde61b2b96,A Unified View of Masked Image Modeling,0.728224,"Masked image modeling has demonstrated great potential to eliminate the
label-hungry problem of training large-scale vision Transformers, achieving
impressive performance on various downstream tasks. In this work, we propose a
unified view of masked image modeling after revisiting existing methods. Under
the unified view, we introduce a simple yet effective method, termed as
MaskDistill, which reconstructs normalized semantic features from teacher
models at the masked positions, conditioning on corrupted input images.
Experimental results on image classification and semantic segmentation show
that MaskDistill achieves comparable or superior performance than
state-of-the-art methods. When using the huge vision Transformer and
pretraining 300 epochs, MaskDistill obtains 88.3% fine-tuning top-1 accuracy on
ImageNet-1k (224 size) and 58.8% semantic segmentation mIoU metric on ADE20k
(512 size). The code and pretrained models will be available at
https://aka.ms/unimim.",https://aka.ms/unimim,-1
ff3dc86f-cad7-47ef-ab63-ae6ad65bf479,Less is More: Task-aware Layer-wise Distillation for Language Model Compression,0.675151,"Layer-wise distillation is a powerful tool to compress large models (i.e.
teacher models) into small ones (i.e., student models). The student distills
knowledge from the teacher by mimicking the hidden representations of the
teacher at every intermediate layer. However, layer-wise distillation is
difficult. Since the student has a smaller model capacity than the teacher, it
is often under-fitted. Furthermore, the hidden representations of the teacher
contain redundant information that the student does not necessarily need for
the target task's learning. To address these challenges, we propose a novel
Task-aware layEr-wise Distillation (TED). TED designs task-aware filters to
align the hidden representations of the student and the teacher at each layer.
The filters select the knowledge that is useful for the target task from the
hidden representations. As such, TED reduces the knowledge gap between the two
models and helps the student to fit better on the target task. We evaluate TED
in two scenarios: continual pre-training and fine-tuning. TED demonstrates
significant and consistent improvements over existing distillation methods in
both scenarios. Code is available at
https://github.com/cliang1453/task-aware-distillation.",https://github.com/cliang1453/task-aware-distillation,-1
481537be-afff-446f-922b-690bf36849b3,PP-YOLOE: An evolved version of YOLO,0.87966,"In this report, we present PP-YOLOE, an industrial state-of-the-art object
detector with high performance and friendly deployment. We optimize on the
basis of the previous PP-YOLOv2, using anchor-free paradigm, more powerful
backbone and neck equipped with CSPRepResStage, ET-head and dynamic label
assignment algorithm TAL. We provide s/m/l/x models for different practice
scenarios. As a result, PP-YOLOE-l achieves 51.4 mAP on COCO test-dev and 78.1
FPS on Tesla V100, yielding a remarkable improvement of (+1.9 AP, +13.35% speed
up) and (+1.3 AP, +24.96% speed up), compared to the previous state-of-the-art
industrial models PP-YOLOv2 and YOLOX respectively. Further, PP-YOLOE inference
speed achieves 149.2 FPS with TensorRT and FP16-precision. We also conduct
extensive experiments to verify the effectiveness of our designs. Source code
and pre-trained models are available at
https://github.com/PaddlePaddle/PaddleDetection.",https://github.com/PaddlePaddle/PaddleDetection,-1
dea930b6-4bb9-47bd-aac9-b4b3cc964204,Neuro-Symbolic Verification of Deep Neural Networks,0.435713,"Formal verification has emerged as a powerful approach to ensure the safety
and reliability of deep neural networks. However, current verification tools
are limited to only a handful of properties that can be expressed as
first-order constraints over the inputs and output of a network. While
adversarial robustness and fairness fall under this category, many real-world
properties (e.g., ""an autonomous vehicle has to stop in front of a stop sign"")
remain outside the scope of existing verification technology. To mitigate this
severe practical restriction, we introduce a novel framework for verifying
neural networks, named neuro-symbolic verification. The key idea is to use
neural networks as part of the otherwise logical specification, enabling the
verification of a wide variety of complex, real-world properties, including the
one above. Moreover, we demonstrate how neuro-symbolic verification can be
implemented on top of existing verification infrastructure for neural networks,
making our framework easily accessible to researchers and practitioners alike.",https://github.com/LebronX/Neuro-Symbolic-Verification,-1
d160a03f-29bb-490c-9362-5f8104e342e3,Overcoming Barriers to Skill Injection in Language Modeling: Case Study in Arithmetic,0.0961061,"Through their transfer learning abilities, highly-parameterized large
pre-trained language models have dominated the NLP landscape for a multitude of
downstream language tasks. Though linguistically proficient, the inability of
these models to incorporate the learning of non-linguistic entities (numerals
and arithmetic reasoning) limits their usage for tasks that require numeric
comprehension or strict mathematical reasoning. However, as we illustrate in
this paper, building a general purpose language model that also happens to be
proficient in mathematical reasoning is not as straight-forward as training it
on a numeric dataset. In this work, we develop a novel framework that enables
language models to be mathematically proficient while retaining their
linguistic prowess. Specifically, we offer information-theoretic interventions
to overcome the catastrophic forgetting of linguistic skills that occurs while
injecting non-linguistic skills into language models.",None,-1
57e1dc25-4ca5-486e-b807-9601dff37a66,Capabilities for Better ML Engineering,0.254747,"In spite of machine learning's rapid growth, its engineering support is
scattered in many forms, and tends to favor certain engineering stages,
stakeholders, and evaluation preferences. We envision a capability-based
framework, which uses fine-grained specifications for ML model behaviors to
unite existing efforts towards better ML engineering. We use concrete scenarios
(model design, debugging, and maintenance) to articulate capabilities' broad
applications across various different dimensions, and their impact on building
safer, more generalizable and more trustworthy models that reflect human needs.
Through preliminary experiments, we show capabilities' potential for reflecting
model generalizability, which can provide guidance for ML engineering process.
We discuss challenges and opportunities for capabilities' integration into ML
engineering.",https://github.com/malusamayo/Capabilities-Experiment-Details,-1
5821d329-767d-4828-b16c-39ccee9714e8,Coloring the Blank Slate: Pre-training Imparts a Hierarchical Inductive Bias to Sequence-to-sequence Models,0.280011,"Relations between words are governed by hierarchical structure rather than
linear ordering. Sequence-to-sequence (seq2seq) models, despite their success
in downstream NLP applications, often fail to generalize in a
hierarchy-sensitive manner when performing syntactic transformations - for
example, transforming declarative sentences into questions. However, syntactic
evaluations of seq2seq models have only observed models that were not
pre-trained on natural language data before being trained to perform syntactic
transformations, in spite of the fact that pre-training has been found to
induce hierarchical linguistic generalizations in language models; in other
words, the syntactic capabilities of seq2seq models may have been greatly
understated. We address this gap using the pre-trained seq2seq models T5 and
BART, as well as their multilingual variants mT5 and mBART. We evaluate whether
they generalize hierarchically on two transformations in two languages:
question formation and passivization in English and German. We find that
pre-trained seq2seq models generalize hierarchically when performing syntactic
transformations, whereas models trained from scratch on syntactic
transformations do not. This result presents evidence for the learnability of
hierarchical syntactic information from non-annotated natural language text
while also demonstrating that seq2seq models are capable of syntactic
generalization, though only after exposure to much more language data than
human learners receive.",https://github.com/sebschu/multilingual-transformations,-1
b63135ad-1f4f-4cad-acfb-3485e4309753,Automatic Summarization of Russian Texts: Comparison of Extractive and Abstractive Methods,0.108884,"The development of large and super-large language models, such as GPT-3, T5,
Switch Transformer, ERNIE, etc., has significantly improved the performance of
text generation. One of the important research directions in this area is the
generation of texts with arguments. The solution of this problem can be used in
business meetings, political debates, dialogue systems, for preparation of
student essays. One of the main domains for these applications is the economic
sphere. The key problem of the argument text generation for the Russian
language is the lack of annotated argumentation corpora. In this paper, we use
translated versions of the Argumentative Microtext, Persuasive Essays and UKP
Sentential corpora to fine-tune RuBERT model. Further, this model is used to
annotate the corpus of economic news by argumentation. Then the annotated
corpus is employed to fine-tune the ruGPT-3 model, which generates argument
texts. The results show that this approach improves the accuracy of the
argument generation by more than 20 percentage points (63.2% vs. 42.5%)
compared to the original ruGPT-3 model.",https://github.com/sberbank-ai/ru-gpts,-1
7ac3d517-44da-4f2a-8085-d3f348db80b5,Face Relighting with Geometrically Consistent Shadows,0.653585,"Most face relighting methods are able to handle diffuse shadows, but struggle
to handle hard shadows, such as those cast by the nose. Methods that propose
techniques for handling hard shadows often do not produce geometrically
consistent shadows since they do not directly leverage the estimated face
geometry while synthesizing them. We propose a novel differentiable algorithm
for synthesizing hard shadows based on ray tracing, which we incorporate into
training our face relighting model. Our proposed algorithm directly utilizes
the estimated face geometry to synthesize geometrically consistent hard
shadows. We demonstrate through quantitative and qualitative experiments on
Multi-PIE and FFHQ that our method produces more geometrically consistent
shadows than previous face relighting methods while also achieving
state-of-the-art face relighting performance under directional lighting. In
addition, we demonstrate that our differentiable hard shadow modeling improves
the quality of the estimated face geometry over diffuse shading models.",https://github.com/andrewhou1/GeomConsistentFR,-1
897dbf13-791f-41df-872f-e662abf17ccf,Task Transfer and Domain Adaptation for Zero-Shot Question Answering,0.0707825,"Pretrained language models have shown success in various areas of natural
language processing, including reading comprehension tasks. However, when
applying machine learning methods to new domains, labeled data may not always
be available. To address this, we use supervised pretraining on source-domain
data to reduce sample complexity on domain-specific downstream tasks. We
evaluate zero-shot performance on domain-specific reading comprehension tasks
by combining task transfer with domain adaptation to fine-tune a pretrained
model with no labelled data from the target task. Our approach outperforms
Domain-Adaptive Pretraining on downstream domain-specific reading comprehension
tasks in 3 out of 4 domains.",https://github.com/adityaarunsinghal/,-1
767beecb-44e4-4a30-8554-5597d344b917,iSimLoc: Visual Global Localization for Previously Unseen Environments with Simulated Images,0.219413,"The visual camera is an attractive device in beyond visual line of sight
(B-VLOS) drone operation, since they are low in size, weight, power, and cost,
and can provide redundant modality to GPS failures. However, state-of-the-art
visual localization algorithms are unable to match visual data that have a
significantly different appearance due to illuminations or viewpoints. This
paper presents iSimLoc, a condition/viewpoint consistent hierarchical global
re-localization approach. The place features of iSimLoc can be utilized to
search target images under changing appearances and viewpoints. Additionally,
our hierarchical global re-localization module refines in a coarse-to-fine
manner, allowing iSimLoc to perform a fast and accurate estimation. We evaluate
our method on one dataset with appearance variations and one dataset that
focuses on demonstrating large-scale matching over a long flight in complicated
environments. On our two datasets, iSimLoc achieves 88.7\% and 83.8\%
successful retrieval rates with 1.5s inferencing time, compared to 45.8% and
39.7% using the next best method. These results demonstrate robust localization
in a range of environments.",None,-1
01d83098-3e11-4d3e-bc67-499b07b8c4f5,PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales,0.64001,"Neural language models (LMs) have achieved impressive results on various
language-based reasoning tasks by utilizing latent knowledge encoded in their
own pretrained parameters. To make this reasoning process more explicit, recent
works retrieve a rationalizing LM's internal knowledge by training or prompting
it to generate free-text rationales, which can be used to guide task
predictions made by either the same LM or a separate reasoning LM. However,
rationalizing LMs require expensive rationale annotation and/or computation,
without any assurance that their generated rationales improve LM task
performance or faithfully reflect LM decision-making. In this paper, we propose
PINTO, an LM pipeline that rationalizes via prompt-based learning, and learns
to faithfully reason over rationales via counterfactual regularization. First,
PINTO maps out a suitable reasoning process for the task input by prompting a
frozen rationalizing LM to generate a free-text rationale. Second, PINTO's
reasoning LM is fine-tuned to solve the task using the generated rationale as
context, while regularized to output less confident predictions when the
rationale is perturbed. Across four datasets, we show that PINTO significantly
improves the generalization ability of the reasoning LM, yielding higher
performance on both in-distribution and out-of-distribution test sets. Also, we
find that PINTO's rationales are more faithful to its task predictions than
those generated by competitive baselines.",https://github.com/wangpf3/pinto-faithful-language-reasoning,-1
680eb8d5-27e7-4acc-802c-cf2347e81173,Meta Spatio-Temporal Debiasing for Video Scene Graph Generation,0.818597,"Video scene graph generation (VidSGG) aims to parse the video content into
scene graphs, which involves modeling the spatio-temporal contextual
information in the video. However, due to the long-tailed training data in
datasets, the generalization performance of existing VidSGG models can be
affected by the spatio-temporal conditional bias problem. In this work, from
the perspective of meta-learning, we propose a novel Meta Video Scene Graph
Generation (MVSGG) framework to address such a bias problem. Specifically, to
handle various types of spatio-temporal conditional biases, our framework first
constructs a support set and a group of query sets from the training data,
where the data distribution of each query set is different from that of the
support set w.r.t. a type of conditional bias. Then, by performing a novel meta
training and testing process to optimize the model to obtain good testing
performance on these query sets after training on the support set, our
framework can effectively guide the model to learn to well generalize against
biases. Extensive experiments demonstrate the efficacy of our proposed
framework.",None,-1
cac84599-4755-4957-9f6a-fa41c58b55da,Implementing Deep Learning-Based Approaches for Article Summarization in Indian Languages,0.440309,"The research on text summarization for low-resource Indian languages has been
limited due to the availability of relevant datasets. This paper presents a
summary of various deep-learning approaches used for the ILSUM 2022 Indic
language summarization datasets. The ISUM 2022 dataset consists of news
articles written in Indian English, Hindi, and Gujarati respectively, and their
ground-truth summarizations. In our work, we explore different pre-trained
seq2seq models and fine-tune those with the ILSUM 2022 datasets. In our case,
the fine-tuned SoTA PEGASUS model worked the best for English, the fine-tuned
IndicBART model with augmented data for Hindi, and again fine-tuned PEGASUS
model along with a translation mapping-based approach for Gujarati. Our scores
on the obtained inferences were evaluated using ROUGE-1, ROUGE-2, and ROUGE-4
as the evaluation metrics.",None,-1
377421cc-c6ae-43b0-a0f1-cbcf334f9749,No Parameters Left Behind: Sensitivity Guided Adaptive Learning Rate for Training Large Transformer Models,0.565007,"Recent research has shown the existence of significant redundancy in large
Transformer models. One can prune the redundant parameters without
significantly sacrificing the generalization performance. However, we question
whether the redundant parameters could have contributed more if they were
properly trained. To answer this question, we propose a novel training strategy
that encourages all parameters to be trained sufficiently. Specifically, we
adaptively adjust the learning rate for each parameter according to its
sensitivity, a robust gradient-based measure reflecting this parameter's
contribution to the model performance. A parameter with low sensitivity is
redundant, and we improve its fitting by increasing its learning rate. In
contrast, a parameter with high sensitivity is well-trained, and we regularize
it by decreasing its learning rate to prevent further overfitting. We conduct
extensive experiments on natural language understanding, neural machine
translation, and image classification to demonstrate the effectiveness of the
proposed schedule. Analysis shows that the proposed schedule indeed reduces the
redundancy and improves generalization performance.",https://github.com/cliang1453/SAGE,82331
e37aa94c-d109-44d3-bc89-1c983a62e930,Check and Link: Pairwise Lesion Correspondence Guides Mammogram Mass Detection,0.613655,"Detecting mass in mammogram is significant due to the high occurrence and
mortality of breast cancer. In mammogram mass detection, modeling pairwise
lesion correspondence explicitly is particularly important. However, most of
the existing methods build relatively coarse correspondence and have not
utilized correspondence supervision. In this paper, we propose a new
transformer-based framework CL-Net to learn lesion detection and pairwise
correspondence in an end-to-end manner. In CL-Net, View-Interactive Lesion
Detector is proposed to achieve dynamic interaction across candidates of cross
views, while Lesion Linker employs the correspondence supervision to guide the
interaction process more accurately. The combination of these two designs
accomplishes precise understanding of pairwise lesion correspondence for
mammograms. Experiments show that CL-Net yields state-of-the-art performance on
the public DDSM dataset and our in-house dataset. Moreover, it outperforms
previous methods by a large margin in low FPI regime.",None,-1
0517b7fa-2e51-4891-9f32-254acdf1040b,Spiking Graph Convolutional Networks,0.831234,"Graph Convolutional Networks (GCNs) achieve an impressive performance due to
the remarkable representation ability in learning the graph information.
However, GCNs, when implemented on a deep network, require expensive
computation power, making them difficult to be deployed on battery-powered
devices. In contrast, Spiking Neural Networks (SNNs), which perform a
bio-fidelity inference process, offer an energy-efficient neural architecture.
In this work, we propose SpikingGCN, an end-to-end framework that aims to
integrate the embedding of GCNs with the biofidelity characteristics of SNNs.
The original graph data are encoded into spike trains based on the
incorporation of graph convolution. We further model biological information
processing by utilizing a fully connected layer combined with neuron nodes. In
a wide range of scenarios (e.g. citation networks, image graph classification,
and recommender systems), our experimental results show that the proposed
method could gain competitive performance against state-of-the-art approaches.
Furthermore, we show that SpikingGCN on a neuromorphic chip can bring a clear
advantage of energy efficiency into graph data analysis, which demonstrates its
great potential to construct environment-friendly machine learning models.",https://github.com/ZulunZhu/SpikingGCN.git,-1
91c8f7d7-0ff7-4bc2-8178-1c53db29427d,Two-stream Multi-dimensional Convolutional Network for Real-time Violence Detection,0.081662,"The increasing number of surveillance cameras and security concerns have made
automatic violent activity detection from surveillance footage an active area
for research. Modern deep learning methods have achieved good accuracy in
violence detection and proved to be successful because of their applicability
in intelligent surveillance systems. However, the models are computationally
expensive and large in size because of their inefficient methods for feature
extraction. This work presents a novel architecture for violence detection
called Two-stream Multi-dimensional Convolutional Network (2s-MDCN), which uses
RGB frames and optical flow to detect violence. Our proposed method extracts
temporal and spatial information independently by 1D, 2D, and 3D convolutions.
Despite combining multi-dimensional convolutional networks, our models are
lightweight and efficient due to reduced channel capacity, yet they learn to
extract meaningful spatial and temporal information. Additionally, combining
RGB frames and optical flow yields 2.2% more accuracy than a single RGB stream.
Regardless of having less complexity, our models obtained state-of-the-art
accuracy of 89.7% on the largest violence detection benchmark dataset.",None,-1
01ccc45c-2168-45e4-8051-58f1a40b8276,Compressing Pre-trained Transformers via Low-Bit NxM Sparsity for Natural Language Understanding,0.0417614,"In recent years, large pre-trained Transformer networks have demonstrated
dramatic improvements in many natural language understanding tasks. However,
the huge size of these models brings significant challenges to their
fine-tuning and online deployment due to latency and cost constraints. New
hardware supporting both N:M semi-structured sparsity and low-precision integer
computation is a promising solution to boost DNN model serving efficiency.
However, there have been very few studies that systematically investigate to
what extent pre-trained Transformer networks benefit from the combination of
these techniques, as well as how to best compress each component of the
Transformer. We propose a flexible compression framework NxMiFormer that
performs simultaneous sparsification and quantization using ADMM and STE-based
QAT. Furthermore, we present and inexpensive, heuristic-driven search algorithm
that identifies promising heterogeneous compression configurations that meet a
compression ratio constraint. When evaluated across the GLUE suite of NLU
benchmarks, our approach can achieve up to 93% compression of the encoders of a
BERT model while retaining 98.2% of the original model accuracy and taking full
advantage of the hardware's capabilities. Heterogeneous configurations found
the by the search heuristic maintain 99.5% of the baseline accuracy while still
compressing the model by 87.5%.",None,7580
8d076cd8-6687-4c43-a536-6922a2f62150,A general-purpose method for applying Explainable AI for Anomaly Detection,0.320443,"The need for explainable AI (XAI) is well established but relatively little
has been published outside of the supervised learning paradigm. This paper
focuses on a principled approach to applying explainability and
interpretability to the task of unsupervised anomaly detection. We argue that
explainability is principally an algorithmic task and interpretability is
principally a cognitive task, and draw on insights from the cognitive sciences
to propose a general-purpose method for practical diagnosis using explained
anomalies. We define Attribution Error, and demonstrate, using real-world
labeled datasets, that our method based on Integrated Gradients (IG) yields
significantly lower attribution errors than alternative methods.",None,-1
ef579802-ee26-429a-a4e3-dd88d51461cc,Toward Robust Spiking Neural Network Against Adversarial Perturbation,0.408406,"As spiking neural networks (SNNs) are deployed increasingly in real-world
efficiency critical applications, the security concerns in SNNs attract more
attention. Currently, researchers have already demonstrated an SNN can be
attacked with adversarial examples. How to build a robust SNN becomes an urgent
issue. Recently, many studies apply certified training in artificial neural
networks (ANNs), which can improve the robustness of an NN model promisely.
However, existing certifications cannot transfer to SNNs directly because of
the distinct neuron behavior and input formats for SNNs. In this work, we first
design S-IBP and S-CROWN that tackle the non-linear functions in SNNs' neuron
modeling. Then, we formalize the boundaries for both digital and spike inputs.
Finally, we demonstrate the efficiency of our proposed robust training method
in different datasets and model architectures. Based on our experiment, we can
achieve a maximum $37.7\%$ attack error reduction with $3.7\%$ original
accuracy loss. To the best of our knowledge, this is the first analysis on
robust training of SNNs.",None,-1
94db08d1-35be-4b42-bbe4-17370f526064,A Structure-guided Effective and Temporal-lag Connectivity Network for Revealing Brain Disorder Mechanisms,0.351935,"Brain network provides important insights for the diagnosis of many brain
disorders, and how to effectively model the brain structure has become one of
the core issues in the domain of brain imaging analysis. Recently, various
computational methods have been proposed to estimate the causal relationship
(i.e., effective connectivity) between brain regions. Compared with traditional
correlation-based methods, effective connectivity can provide the direction of
information flow, which may provide additional information for the diagnosis of
brain diseases. However, existing methods either ignore the fact that there is
a temporal-lag in the information transmission across brain regions, or simply
set the temporal-lag value between all brain regions to a fixed value. To
overcome these issues, we design an effective temporal-lag neural network
(termed ETLN) to simultaneously infer the causal relationships and the
temporal-lag values between brain regions, which can be trained in an
end-to-end manner. In addition, we also introduce three mechanisms to better
guide the modeling of brain networks. The evaluation results on the Alzheimer's
Disease Neuroimaging Initiative (ADNI) database demonstrate the effectiveness
of the proposed method.",None,-1
7729be9f-2c8a-4e29-b7e0-867b826f9d68,Attention-based Random Forest and Contamination Model,0.512115,"A new approach called ABRF (the attention-based random forest) and its
modifications for applying the attention mechanism to the random forest (RF)
for regression and classification are proposed. The main idea behind the
proposed ABRF models is to assign attention weights with trainable parameters
to decision trees in a specific way. The weights depend on the distance between
an instance, which falls into a corresponding leaf of a tree, and instances,
which fall in the same leaf. This idea stems from representation of the
Nadaraya-Watson kernel regression in the form of a RF. Three modifications of
the general approach are proposed. The first one is based on applying the
Huber's contamination model and on computing the attention weights by solving
quadratic or linear optimization problems. The second and the third
modifications use the gradient-based algorithms for computing trainable
parameters. Numerical experiments with various regression and classification
datasets illustrate the proposed method.",None,-1
587bf69c-28cb-441b-b8e2-4da7dabaadd6,Leveraging Pre-Trained Language Models to Streamline Natural Language Interaction for Self-Tracking,0.286404,"Current natural language interaction for self-tracking tools largely depends
on bespoke implementation optimized for a specific tracking theme and data
format, which is neither generalizable nor scalable to a tremendous design
space of self-tracking. However, training machine learning models in the
context of self-tracking is challenging due to the wide variety of tracking
topics and data formats. In this paper, we propose a novel NLP task for
self-tracking that extracts close- and open-ended information from a
retrospective activity log described as a plain text, and a domain-agnostic,
GPT-3-based NLU framework that performs this task. The framework augments the
prompt using synthetic samples to transform the task into 10-shot learning, to
address a cold-start problem in bootstrapping a new tracking topic. Our
preliminary evaluation suggests that our approach significantly outperforms the
baseline QA models. Going further, we discuss future application domains toward
which the NLP and HCI researchers can collaborate.",None,-1
dabcc7ac-3f13-4341-84b7-9d9c119d5915,MAESTRO: Matched Speech Text Representations through Modality Matching,0.842436,"We present Maestro, a self-supervised training method to unify
representations learnt from speech and text modalities. Self-supervised
learning from speech signals aims to learn the latent structure inherent in the
signal, while self-supervised learning from text attempts to capture lexical
information. Learning aligned representations from unpaired speech and text
sequences is a challenging task. Previous work either implicitly enforced the
representations learnt from these two modalities to be aligned in the latent
space through multitasking and parameter sharing or explicitly through
conversion of modalities via speech synthesis. While the former suffers from
interference between the two modalities, the latter introduces additional
complexity. In this paper, we propose Maestro, a novel algorithm to learn
unified representations from both these modalities simultaneously that can
transfer to diverse downstream tasks such as Automated Speech Recognition (ASR)
and Speech Translation (ST). Maestro learns unified representations through
sequence alignment, duration prediction and matching embeddings in the learned
space through an aligned masked-language model loss. We establish a new
state-of-the-art (SOTA) on VoxPopuli multilingual ASR with a 8% relative
reduction in Word Error Rate (WER), multidomain SpeechStew ASR (3.7% relative)
and 21 languages to English multilingual ST on CoVoST 2 with an improvement of
2.8 BLEU averaged over 21 languages.",None,-1
c166812c-6c3e-441c-bd84-c6a743f9b581,ASSIST: Towards Label Noise-Robust Dialogue State Tracking,0.447257,"The MultiWOZ 2.0 dataset has greatly boosted the research on dialogue state
tracking (DST). However, substantial noise has been discovered in its state
annotations. Such noise brings about huge challenges for training DST models
robustly. Although several refined versions, including MultiWOZ 2.1-2.4, have
been published recently, there are still lots of noisy labels, especially in
the training set. Besides, it is costly to rectify all the problematic
annotations. In this paper, instead of improving the annotation quality
further, we propose a general framework, named ASSIST (lAbel noiSe-robuSt
dIalogue State Tracking), to train DST models robustly from noisy labels.
ASSIST first generates pseudo labels for each sample in the training set by
using an auxiliary model trained on a small clean dataset, then puts the
generated pseudo labels and vanilla noisy labels together to train the primary
model. We show the validity of ASSIST theoretically. Experimental results also
demonstrate that ASSIST improves the joint goal accuracy of DST by up to
$28.16\%$ on MultiWOZ 2.0 and $8.41\%$ on MultiWOZ 2.4, compared to using only
the vanilla noisy labels.",https://github.com/smartyfh/DST-ASSIST,-1
b2185f69-c281-467c-9932-1b03d1ba30be,Soundness of Data-Aware Processes with Arithmetic Conditions,0.335974,"Data-aware processes represent and integrate structural and behavioural
constraints in a single model, and are thus increasingly investigated in
business process management and information systems engineering. In this
spectrum, Data Petri nets (DPNs) have gained increasing popularity thanks to
their ability to balance simplicity with expressiveness. The interplay of data
and control-flow makes checking the correctness of such models, specifically
the well-known property of soundness, crucial and challenging. A major
shortcoming of previous approaches for checking soundness of DPNs is that they
consider data conditions without arithmetic, an essential feature when dealing
with real-world, concrete applications. In this paper, we attack this open
problem by providing a foundational and operational framework for assessing
soundness of DPNs enriched with arithmetic data conditions. The framework comes
with a proof-of-concept implementation that, instead of relying on ad-hoc
techniques, employs off-the-shelf established SMT technologies. The
implementation is validated on a collection of examples from the literature,
and on synthetic variants constructed from such examples.",None,-1
2deeed2b-53d8-45aa-830f-572f0a8a4c8d,Vision Transformer Equipped with Neural Resizer on Facial Expression Recognition Task,0.52048,"When it comes to wild conditions, Facial Expression Recognition is often
challenged with low-quality data and imbalanced, ambiguous labels. This field
has much benefited from CNN based approaches; however, CNN models have
structural limitation to see the facial regions in distant. As a remedy,
Transformer has been introduced to vision fields with global receptive field,
but requires adjusting input spatial size to the pretrained models to enjoy
their strong inductive bias at hands. We herein raise a question whether using
the deterministic interpolation method is enough to feed low-resolution data to
Transformer. In this work, we propose a novel training framework, Neural
Resizer, to support Transformer by compensating information and downscaling in
a data-driven manner trained with loss function balancing the noisiness and
imbalance. Experiments show our Neural Resizer with F-PDLS loss function
improves the performance with Transformer variants in general and nearly
achieves the state-of-the-art performance.",None,-1
5655d591-e4e8-4d29-b933-a5356c7e143c,End-to-End Topology-Aware Machine Learning for Power System Reliability Assessment,0.22544,"Conventional power system reliability suffers from the long run time of Monte
Carlo simulation and the dimension-curse of analytic enumeration methods. This
paper proposes a preliminary investigation on end-to-end machine learning for
directly predicting the reliability index, e.g., the Loss of Load Probability
(LOLP). By encoding the system admittance matrix into the input feature, the
proposed machine learning pipeline can consider the impact of specific topology
changes due to regular maintenances of transmission lines. Two models (Support
Vector Machine and Boosting Trees) are trained and compared. Details regarding
the training data creation and preprocessing are also discussed. Finally,
experiments are conducted on the IEEE RTS-79 system. Results demonstrate the
applicability of the proposed end-to-end machine learning pipeline in
reliability assessment.",None,-1
e99b83b8-8a76-4a83-abc7-0475a9544ec0,BOME! Bilevel Optimization Made Easy: A Simple First-Order Approach,0.99964,"Bilevel optimization (BO) is useful for solving a variety of important
machine learning problems including but not limited to hyperparameter
optimization, meta-learning, continual learning, and reinforcement learning.
Conventional BO methods need to differentiate through the low-level
optimization process with implicit differentiation, which requires expensive
calculations related to the Hessian matrix. There has been a recent quest for
first-order methods for BO, but the methods proposed to date tend to be
complicated and impractical for large-scale deep learning applications. In this
work, we propose a simple first-order BO algorithm that depends only on
first-order gradient information, requires no implicit differentiation, and is
practical and efficient for large-scale non-convex functions in deep learning.
We provide non-asymptotic convergence analysis of the proposed method to
stationary points for non-convex objectives and present empirical results that
show its superior practical performance.",https://github.com/JunjieYang97/stocBiO,-1
25b24946-0464-4443-88d6-dc62797558c6,Machine Learning Challenges of Biological Factors in Insect Image Data,0.0662177,"The BIOSCAN project, led by the International Barcode of Life Consortium,
seeks to study changes in biodiversity on a global scale. One component of the
project is focused on studying the species interaction and dynamics of all
insects. In addition to genetically barcoding insects, over 1.5 million images
per year will be collected, each needing taxonomic classification. With the
immense volume of incoming images, relying solely on expert taxonomists to
label the images would be impossible; however, artificial intelligence and
computer vision technology may offer a viable high-throughput solution.
Additional tasks including manually weighing individual insects to determine
biomass, remain tedious and costly. Here again, computer vision may offer an
efficient and compelling alternative. While the use of computer vision methods
is appealing for addressing these problems, significant challenges resulting
from biological factors present themselves. These challenges are formulated in
the context of machine learning in this paper.",None,14680
58e86c86-593f-488e-a3b4-fdaeaaf3e91c,Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models,0.906471,"Despite the success, the process of fine-tuning large-scale PLMs brings
prohibitive adaptation costs. In fact, fine-tuning all the parameters of a
colossal model and retaining separate instances for different tasks are
practically infeasible. This necessitates a new branch of research focusing on
the parameter-efficient adaptation of PLMs, dubbed as delta tuning in this
paper. In contrast with the standard fine-tuning, delta tuning only fine-tunes
a small portion of the model parameters while keeping the rest untouched,
largely reducing both the computation and storage costs. Recent studies have
demonstrated that a series of delta tuning methods with distinct tuned
parameter selection could achieve performance on a par with full-parameter
fine-tuning, suggesting a new promising way of stimulating large-scale PLMs. In
this paper, we first formally describe the problem of delta tuning and then
comprehensively review recent delta tuning approaches. We also propose a
unified categorization criterion that divide existing delta tuning methods into
three groups: addition-based, specification-based, and reparameterization-based
methods. Though initially proposed as an efficient method to steer large
models, we believe that some of the fascinating evidence discovered along with
delta tuning could help further reveal the mechanisms of PLMs and even deep
neural networks. To this end, we discuss the theoretical principles underlying
the effectiveness of delta tuning and propose frameworks to interpret delta
tuning from the perspective of optimization and optimal control, respectively.
Furthermore, we provide a holistic empirical study of representative methods,
where results on over 100 NLP tasks demonstrate a comprehensive performance
comparison of different approaches. The experimental results also cover the
analysis of combinatorial, scaling and transferable properties of delta tuning.",None,-1
9392c43f-d32e-40d8-b290-6d05434b05ac,MIAD: A Maintenance Inspection Dataset for Unsupervised Anomaly Detection,0.884824,"Visual anomaly detection plays a crucial role in not only manufacturing
inspection to find defects of products during manufacturing processes, but also
maintenance inspection to keep equipment in optimum working condition
particularly outdoors. Due to the scarcity of the defective samples,
unsupervised anomaly detection has attracted great attention in recent years.
However, existing datasets for unsupervised anomaly detection are biased
towards manufacturing inspection, not considering maintenance inspection which
is usually conducted under outdoor uncontrolled environment such as varying
camera viewpoints, messy background and degradation of object surface after
long-term working. We focus on outdoor maintenance inspection and contribute a
comprehensive Maintenance Inspection Anomaly Detection (MIAD) dataset which
contains more than 100K high-resolution color images in various outdoor
industrial scenarios. This dataset is generated by a 3D graphics software and
covers both surface and logical anomalies with pixel-precise ground truth.
Extensive evaluations of representative algorithms for unsupervised anomaly
detection are conducted, and we expect MIAD and corresponding experimental
results can inspire research community in outdoor unsupervised anomaly
detection tasks. Worthwhile and related future work can be spawned from our new
dataset.",https://github.com/vitjanz/draem,-1
e2e0dc23-cb86-4a01-ac2a-abd85a6aa124,Adapting Task-Oriented Dialogue Models for Email Conversations,0.244503,"Intent detection is a key part of any Natural Language Understanding (NLU)
system of a conversational assistant. Detecting the correct intent is essential
yet difficult for email conversations where multiple directives and intents are
present. In such settings, conversation context can become a key disambiguating
factor for detecting the user's request from the assistant. One prominent way
of incorporating context is modeling past conversation history like
task-oriented dialogue models. However, the nature of email conversations (long
form) restricts direct usage of the latest advances in task-oriented dialogue
models. So in this paper, we provide an effective transfer learning framework
(EMToD) that allows the latest development in dialogue models to be adapted for
long-form conversations. We show that the proposed EMToD framework improves
intent detection performance over pre-trained language models by 45% and over
pre-trained dialogue models by 30% for task-oriented email conversations.
Additionally, the modular nature of the proposed framework allows plug-and-play
for any future developments in both pre-trained language and task-oriented
dialogue models.",None,-1
17af170b-e16c-48a1-93aa-01a6848a7ca8,Multi-Scale Representation Learning on Proteins,0.52746,"Proteins are fundamental biological entities mediating key roles in cellular
function and disease. This paper introduces a multi-scale graph construction of
a protein -- HoloProt -- connecting surface to structure and sequence. The
surface captures coarser details of the protein, while sequence as primary
component and structure -- comprising secondary and tertiary components --
capture finer details. Our graph encoder then learns a multi-scale
representation by allowing each level to integrate the encoding from level(s)
below with the graph at that level. We test the learned representation on
different tasks, (i.) ligand binding affinity (regression), and (ii.) protein
function prediction (classification). On the regression task, contrary to
previous methods, our model performs consistently and reliably across different
dataset splits, outperforming all baselines on most splits. On the
classification task, it achieves a performance close to the top-performing
model while using 10x fewer parameters. To improve the memory efficiency of our
construction, we segment the multiplex protein surface manifold into molecular
superpixels and substitute the surface with these superpixels at little to no
performance loss.",https://github.com/rdkit/rdkit/releases/tag/Release_2016_09_4,925
5432686a-e34d-4f7d-8f7a-9e07c57f01a2,Towards Textual Out-of-Domain Detection without In-Domain Labels,0.872743,"In many real-world settings, machine learning models need to identify user
inputs that are out-of-domain (OOD) so as to avoid performing wrong actions.
This work focuses on a challenging case of OOD detection, where no labels for
in-domain data are accessible (e.g., no intent labels for the intent
classification task). To this end, we first evaluate different language model
based approaches that predict likelihood for a sequence of tokens. Furthermore,
we propose a novel representation learning based method by combining
unsupervised clustering and contrastive learning so that better data
representations for OOD detection can be learned. Through extensive
experiments, we demonstrate that this method can significantly outperform
likelihood-based methods and can be even competitive to the state-of-the-art
supervised approaches with label information.",None,-1
86efba07-6608-4a2a-b8fb-8a9089ee18e1,Speaker Information Can Guide Models to Better Inductive Biases: A Case Study On Predicting Code-Switching,0.964326,"Natural language processing (NLP) models trained on people-generated data can
be unreliable because, without any constraints, they can learn from spurious
correlations that are not relevant to the task. We hypothesize that enriching
models with speaker information in a controlled, educated way can guide them to
pick up on relevant inductive biases. For the speaker-driven task of predicting
code-switching points in English--Spanish bilingual dialogues, we show that
adding sociolinguistically-grounded speaker features as prepended prompts
significantly improves accuracy. We find that by adding influential phrases to
the input, speaker-informed models learn useful and explainable linguistic
information. To our knowledge, we are the first to incorporate speaker
characteristics in a neural model for code-switching, and more generally, take
a step towards developing transparent, personalized models that use speaker
information in a controlled way.",https://github.com/ostapen/Switch-and-Explain,-1
05d1c26f-2171-4fd7-8f51-e1a3cbd2d381,Contrastive Learning with Prompt-derived Virtual Semantic Prototypes for Unsupervised Sentence Embedding,0.27441,"Contrastive learning has become a new paradigm for unsupervised sentence
embeddings. Previous studies focus on instance-wise contrastive learning,
attempting to construct positive pairs with textual data augmentation. In this
paper, we propose a novel Contrastive learning method with Prompt-derived
Virtual semantic Prototypes (ConPVP). Specifically, with the help of prompts,
we construct virtual semantic prototypes to each instance, and derive negative
prototypes by using the negative form of the prompts. Using a prototypical
contrastive loss, we enforce the anchor sentence embedding to be close to its
corresponding semantic prototypes, and far apart from the negative prototypes
as well as the prototypes of other sentences. Extensive experimental results on
semantic textual similarity, transfer, and clustering tasks demonstrate the
effectiveness of our proposed model compared to strong baselines. Code is
available at https://github.com/lemon0830/promptCSE.",https://github.com/lemon0830/promptCSE,5610
28f679df-767e-4053-9ba1-4859434038c0,Controllable Evaluation and Generation of Physical Adversarial Patch on Face Recognition,0.521623,"Recent studies have revealed the vulnerability of face recognition models
against physical adversarial patches, which raises security concerns about the
deployed face recognition systems. However, it is still challenging to ensure
the reproducibility for most attack algorithms under complex physical
conditions, which leads to the lack of a systematic evaluation of the existing
methods. It is therefore imperative to develop a framework that can enable a
comprehensive evaluation of the vulnerability of face recognition in the
physical world. To this end, we propose to simulate the complex transformations
of faces in the physical world via 3D-face modeling, which serves as a digital
counterpart of physical faces. The generic framework allows us to control
different face variations and physical conditions to conduct reproducible
evaluations comprehensively. With this digital simulator, we further propose a
Face3DAdv method considering the 3D face transformations and realistic physical
variations. Extensive experiments validate that Face3DAdv can significantly
improve the effectiveness of diverse physically realizable adversarial patches
in both simulated and physical environments, against various white-box and
black-box face recognition models.",None,12717
b38d962e-1ccb-458d-b25e-846de86ee0fe,ASOCEM: Automatic Segmentation Of Contaminations in cryo-EM,0.131905,"Particle picking is currently a critical step in the cryo-electron microscopy
single particle reconstruction pipeline. Contaminations in the acquired
micrographs severely degrade the performance of particle pickers, resulting is
many ``non-particles'' in the collected stack of particles. In this paper, we
present ASOCEM (Automatic Segmentation Of Contaminations in cryo-EM), an
automatic method to detect and segment contaminations, which requires as an
input only the approximated particle size. In particular, it does not require
any parameter tuning nor manual intervention. Our method is based on the
observation that the statistical distribution of contaminated regions is
different from that of the rest of the micrograph. This nonrestrictive
assumption allows to automatically detect various types of contaminations, from
the carbon edges of the supporting grid to high contrast blobs of different
sizes. We demonstrate the efficiency of our algorithm using various
experimental data sets containing various types of contaminations. ASOCEM is
integrated as part of the KLT picker \cite{ELDAR2020107473} and is available at
\url{https://github.com/ShkolniskyLab/kltpicker2}.",https://github.com/ShkolniskyLab/kltpicker2,-1
3296f199-df92-4cd9-a52b-32bc8e04d42f,A Streamlit-based Artificial Intelligence Trust Platform for Next-Generation Wireless Networks,0.527545,"With the rapid development and integration of artificial intelligence (AI)
methods in next-generation networks (NextG), AI algorithms have provided
significant advantages for NextG in terms of frequency spectrum usage,
bandwidth, latency, and security. A key feature of NextG is the integration of
AI, i.e., self-learning architecture based on self-supervised algorithms, to
improve the performance of the network. A secure AI-powered structure is also
expected to protect NextG networks against cyber-attacks. However, AI itself
may be attacked, i.e., model poisoning targeted by attackers, and it results in
cybersecurity violations. This paper proposes an AI trust platform using
Streamlit for NextG networks that allows researchers to evaluate, defend,
certify, and verify their AI models and applications against adversarial
threats of evasion, poisoning, extraction, and interference.",https://github.com/muratkuzlu/NextG,4955
47ffb4f2-dbcb-40cb-904c-f40e60595b7c,SDF-StyleGAN: Implicit SDF-Based StyleGAN for 3D Shape Generation,0.976614,"We present a StyleGAN2-based deep learning approach for 3D shape generation,
called SDF-StyleGAN, with the aim of reducing visual and geometric
dissimilarity between generated shapes and a shape collection. We extend
StyleGAN2 to 3D generation and utilize the implicit signed distance function
(SDF) as the 3D shape representation, and introduce two novel global and local
shape discriminators that distinguish real and fake SDF values and gradients to
significantly improve shape geometry and visual quality. We further complement
the evaluation metrics of 3D generative models with the shading-image-based
Fr\'echet inception distance (FID) scores to better assess visual quality and
shape distribution of the generated shapes. Experiments on shape generation
demonstrate the superior performance of SDF-StyleGAN over the state-of-the-art.
We further demonstrate the efficacy of SDF-StyleGAN in various tasks based on
GAN inversion, including shape reconstruction, shape completion from partial
point clouds, single-view image-based shape generation, and shape style
editing. Extensive ablation studies justify the efficacy of our framework
design. Our code and trained models are available at
https://github.com/Zhengxinyang/SDF-StyleGAN.",https://github.com/Zhengxinyang/SDF-StyleGAN,-1
ee601675-0aa5-44aa-9eb6-bf838d67a8ce,TextGrad: Advancing Robustness Evaluation in NLP by Gradient-Driven Optimization,0.591278,"Robustness evaluation against adversarial examples has become increasingly
important to unveil the trustworthiness of the prevailing deep models in
natural language processing (NLP). However, in contrast to the computer vision
domain where the first-order projected gradient descent (PGD) is used as the
benchmark approach to generate adversarial examples for robustness evaluation,
there lacks a principled first-order gradient-based robustness evaluation
framework in NLP. The emerging optimization challenges lie in 1) the discrete
nature of textual inputs together with the strong coupling between the
perturbation location and the actual content, and 2) the additional constraint
that the perturbed text should be fluent and achieve a low perplexity under a
language model. These challenges make the development of PGD-like NLP attacks
difficult. To bridge the gap, we propose TextGrad, a new attack generator using
gradient-driven optimization, supporting high-accuracy and high-quality
assessment of adversarial robustness in NLP. Specifically, we address the
aforementioned challenges in a unified optimization framework. And we develop
an effective convex relaxation method to co-optimize the continuously-relaxed
site selection and perturbation variables and leverage an effective sampling
method to establish an accurate mapping from the continuous optimization
variables to the discrete textual perturbations. Moreover, as a first-order
attack generation method, TextGrad can be baked into adversarial training to
further improve the robustness of NLP models. Extensive experiments are
provided to demonstrate the effectiveness of TextGrad not only in attack
generation for robustness evaluation but also in adversarial defense.",https://github.com/UCSB-NLP-Chang/TextGrad,-1
4308be46-0e95-4516-955f-702e8250d433,Distilling Style from Image Pairs for Global Forward and Inverse Tone Mapping,0.214744,"Many image enhancement or editing operations, such as forward and inverse
tone mapping or color grading, do not have a unique solution, but instead a
range of solutions, each representing a different style. Despite this, existing
learning-based methods attempt to learn a unique mapping, disregarding this
style. In this work, we show that information about the style can be distilled
from collections of image pairs and encoded into a 2- or 3-dimensional vector.
This gives us not only an efficient representation but also an interpretable
latent space for editing the image style. We represent the global color mapping
between a pair of images as a custom normalizing flow, conditioned on a
polynomial basis of the pixel color. We show that such a network is more
effective than PCA or VAE at encoding image style in low-dimensional space and
lets us obtain an accuracy close to 40 dB, which is about 7-10 dB improvement
over the state-of-the-art methods.",None,-1
fb2bc100-65c8-41e0-b770-01b4bd4a249e,When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment,0.684473,"AI systems are becoming increasingly intertwined with human life. In order to
effectively collaborate with humans and ensure safety, AI systems need to be
able to understand, interpret and predict human moral judgments and decisions.
Human moral judgments are often guided by rules, but not always. A central
challenge for AI safety is capturing the flexibility of the human moral mind --
the ability to determine when a rule should be broken, especially in novel or
unusual situations. In this paper, we present a novel challenge set consisting
of rule-breaking question answering (RBQA) of cases that involve potentially
permissible rule-breaking -- inspired by recent moral psychology studies. Using
a state-of-the-art large language model (LLM) as a basis, we propose a novel
moral chain of thought (MORALCOT) prompting strategy that combines the
strengths of LLMs with theories of moral reasoning developed in cognitive
science to predict human moral judgments. MORALCOT outperforms seven existing
LLMs by 6.2% F1, suggesting that modeling human reasoning might be necessary to
capture the flexibility of the human moral mind. We also conduct a detailed
error analysis to suggest directions for future work to improve AI safety using
RBQA. Our data is open-sourced at
https://huggingface.co/datasets/feradauto/MoralExceptQA and code at
https://github.com/feradauto/MoralCoT",https://github.com/feradauto/MoralCoT,-1
887e6780-c73a-42db-aa2e-97ddfe322121,Zeus: Understanding and Optimizing GPU Energy Consumption of DNN Training,0.976004,"Training deep neural networks (DNNs) is becoming increasingly more resource-
and energy-intensive every year. Unfortunately, existing works primarily focus
on optimizing DNN training for faster completion, often without considering the
impact on energy efficiency.
  In this paper, we observe that common practices to improve training
performance can often lead to inefficient energy usage. More importantly, we
demonstrate that there is a tradeoff between energy consumption and performance
optimization. To this end, we propose Zeus, an optimization framework to
navigate this tradeoff by automatically finding optimal job- and GPU-level
configurations for recurring DNN training jobs. Zeus uses an online
exploration-exploitation approach in conjunction with just-in-time energy
profiling, averting the need for expensive offline measurements, while adapting
to data drifts over time. Our evaluation shows that Zeus can improve the energy
efficiency of DNN training by 15.3%-75.8% for diverse workloads.",https://github.com/SymbioticLab/Zeus,-1
c01b4f42-f79c-4035-a1e4-263bda180195,CAGroup3D: Class-Aware Grouping for 3D Object Detection on Point Clouds,0.987915,"We present a novel two-stage fully sparse convolutional 3D object detection
framework, named CAGroup3D. Our proposed method first generates some
high-quality 3D proposals by leveraging the class-aware local group strategy on
the object surface voxels with the same semantic predictions, which considers
semantic consistency and diverse locality abandoned in previous bottom-up
approaches. Then, to recover the features of missed voxels due to incorrect
voxel-wise segmentation, we build a fully sparse convolutional RoI pooling
module to directly aggregate fine-grained spatial information from backbone for
further proposal refinement. It is memory-and-computation efficient and can
better encode the geometry-specific features of each 3D proposal. Our model
achieves state-of-the-art 3D detection performance with remarkable gains of
+\textit{3.6\%} on ScanNet V2 and +\textit{2.6}\% on SUN RGB-D in term of
mAP@0.25. Code will be available at https://github.com/Haiyang-W/CAGroup3D.",https://github.com/Haiyang-W/CAGroup3D,-1
cc27d849-2caa-4506-b31b-d1d1ae1062f0,Improving the Factual Accuracy of Abstractive Clinical Text Summarization using Multi-Objective Optimization,0.243931,"While there has been recent progress in abstractive summarization as applied
to different domains including news articles, scientific articles, and blog
posts, the application of these techniques to clinical text summarization has
been limited. This is primarily due to the lack of large-scale training data
and the messy/unstructured nature of clinical notes as opposed to other domains
where massive training data come in structured or semi-structured form.
Further, one of the least explored and critical components of clinical text
summarization is factual accuracy of clinical summaries. This is specifically
crucial in the healthcare domain, cardiology in particular, where an accurate
summary generation that preserves the facts in the source notes is critical to
the well-being of a patient. In this study, we propose a framework for
improving the factual accuracy of abstractive summarization of clinical text
using knowledge-guided multi-objective optimization. We propose to jointly
optimize three cost functions in our proposed architecture during training:
generative loss, entity loss and knowledge loss and evaluate the proposed
architecture on 1) clinical notes of patients with heart failure (HF), which we
collect for this study; and 2) two benchmark datasets, Indiana University Chest
X-ray collection (IU X-Ray), and MIMIC-CXR, that are publicly available. We
experiment with three transformer encoder-decoder architectures and demonstrate
that optimizing different loss functions leads to improved performance in terms
of entity-level factual accuracy.",None,-1
7b63b587-9fd2-4fc3-b0ec-b5293d89cc2a,Pre-trained Language Models Can be Fully Zero-Shot Learners,0.246877,"How can we extend a pre-trained model to many language understanding tasks,
without labeled or additional unlabeled data? Pre-trained language models
(PLMs) have been effective for a wide range of NLP tasks. However, existing
approaches either require fine-tuning on downstream labeled datasets or
manually constructing proper prompts. In this paper, we propose nonparametric
prompting PLM (NPPrompt) for fully zero-shot language understanding. Unlike
previous methods, NPPrompt uses only pre-trained language models and does not
require any labeled data or additional raw corpus for further fine-tuning, nor
does it rely on humans to construct a comprehensive set of prompt label words.
We evaluate NPPrompt against previous major few-shot and zero-shot learning
methods on diverse NLP tasks: including text classification, text entailment,
similar text retrieval, and paraphrasing. Experimental results demonstrate that
our NPPrompt outperforms the previous best fully zero-shot method by big
margins, with absolute gains of 12.8% in accuracy on text classification and
18.9% on the GLUE benchmark.",https://github.com/XuandongZhao/NPPrompt,-1
03d1a0ed-f4e1-4914-9cda-17ab07fae04e,Dynamically Refined Regularization for Improving Cross-corpora Hate Speech Detection,0.270472,"Hate speech classifiers exhibit substantial performance degradation when
evaluated on datasets different from the source. This is due to learning
spurious correlations between words that are not necessarily relevant to
hateful language, and hate speech labels from the training corpus. Previous
work has attempted to mitigate this problem by regularizing specific terms from
pre-defined static dictionaries. While this has been demonstrated to improve
the generalizability of classifiers, the coverage of such methods is limited
and the dictionaries require regular manual updates from human experts. In this
paper, we propose to automatically identify and reduce spurious correlations
using attribution methods with dynamic refinement of the list of terms that
need to be regularized during training. Our approach is flexible and improves
the cross-corpora performance over previous work independently and in
combination with pre-defined dictionaries.",https://github.com/tbose20/D-Ref,-1
84dad1b1-d5e3-4b1b-8ea3-0ba08bff4ece,A simple language-agnostic yet very strong baseline system for hate speech and offensive content identification,0.794308,"For automatically identifying hate speech and offensive content in tweets, a
system based on a classical supervised algorithm only fed with character
n-grams, and thus completely language-agnostic, is proposed by the SATLab team.
After its optimization in terms of the feature weighting and the classifier
parameters, it reached, in the multilingual HASOC 2021 challenge, a medium
performance level in English, the language for which it is easy to develop deep
learning approaches relying on many external linguistic resources, but a far
better level for the two less resourced language, Hindi and Marathi. It ends
even first when performances are averaged over the three tasks in these
languages, outperforming many deep learning approaches. These performances
suggest that it is an interesting reference level to evaluate the benefits of
using more complex approaches such as deep learning or taking into account
complementary resources.",None,-1
0dc6ee54-5872-4032-984c-86068c2e48f4,"A Benchmark for Automatic Medical Consultation System: Frameworks, Tasks and Datasets",0.927264,"In recent years, interest has arisen in using machine learning to improve the
efficiency of automatic medical consultation and enhance patient experience. In
this article, we propose two frameworks to support automatic medical
consultation, namely doctor-patient dialogue understanding and task-oriented
interaction. We create a new large medical dialogue dataset with multi-level
finegrained annotations and establish five independent tasks, including named
entity recognition, dialogue act classification, symptom label inference,
medical report generation and diagnosis-oriented dialogue policy. We report a
set of benchmark results for each task, which shows the usability of the
dataset and sets a baseline for future studies. Both code and data is available
from https://github.com/lemuria-wchen/imcs21.",https://github.com/lemuria-wchen/imcs21,21857
2e3b4f2d-4768-48e9-b1df-51a634c18d3e,Poseur: Direct Human Pose Regression with Transformers,0.914351,"We propose a direct, regression-based approach to 2D human pose estimation
from single images. We formulate the problem as a sequence prediction task,
which we solve using a Transformer network. This network directly learns a
regression mapping from images to the keypoint coordinates, without resorting
to intermediate representations such as heatmaps. This approach avoids much of
the complexity associated with heatmap-based approaches. To overcome the
feature misalignment issues of previous regression-based methods, we propose an
attention mechanism that adaptively attends to the features that are most
relevant to the target keypoints, considerably improving the accuracy.
Importantly, our framework is end-to-end differentiable, and naturally learns
to exploit the dependencies between keypoints. Experiments on MS-COCO and MPII,
two predominant pose-estimation datasets, demonstrate that our method
significantly improves upon the state-of-the-art in regression-based pose
estimation. More notably, ours is the first regression-based approach to
perform favorably compared to the best heatmap-based pose estimation methods.",https://github.com/aim-uofa/Poseur,-1
1e69e5ab-82a8-4ecd-84f7-d759d963afcc,Proximal Policy Optimization with Graph Neural Networks for Optimal Power Flow,0.0804247,"Optimal Power Flow (OPF) is a very traditional research area within the power
systems field that seeks for the optimal operation point of electric power
plants, and which needs to be solved every few minutes in real-world scenarios.
However, due to the nonconvexities that arise in power generation systems,
there is not yet a fast, robust solution technique for the full Alternating
Current Optimal Power Flow (ACOPF). In the last decades, power grids have
evolved into a typical dynamic, non-linear and large-scale control system,
known as the power system, so searching for better and faster ACOPF solutions
is becoming crucial. Appearance of Graph Neural Networks (GNN) has allowed the
natural use of Machine Learning (ML) algorithms on graph data, such as power
networks. On the other hand, Deep Reinforcement Learning (DRL) is known for its
powerful capability to solve complex decision-making problems. Although
solutions that use these two methods separately are beginning to appear in the
literature, none has yet combined the advantages of both. We propose a novel
architecture based on the Proximal Policy Optimization algorithm with Graph
Neural Networks to solve the Optimal Power Flow. The objective is to design an
architecture that learns how to solve the optimization problem and that is at
the same time able to generalize to unseen scenarios. We compare our solution
with the DCOPF in terms of cost after having trained our DRL agent on IEEE 30
bus system and then computing the OPF on that base network with topology
changes",None,7078
50ac2ecd-9291-4300-b749-9d7be7d537d5,ComMU: Dataset for Combinatorial Music Generation,0.677715,"Commercial adoption of automatic music composition requires the capability of
generating diverse and high-quality music suitable for the desired context
(e.g., music for romantic movies, action games, restaurants, etc.). In this
paper, we introduce combinatorial music generation, a new task to create
varying background music based on given conditions. Combinatorial music
generation creates short samples of music with rich musical metadata, and
combines them to produce a complete music. In addition, we introduce ComMU, the
first symbolic music dataset consisting of short music samples and their
corresponding 12 musical metadata for combinatorial music generation. Notable
properties of ComMU are that (1) dataset is manually constructed by
professional composers with an objective guideline that induces regularity, and
(2) it has 12 musical metadata that embraces composers' intentions. Our results
show that we can generate diverse high-quality music only with metadata, and
that our unique metadata such as track-role and extended chord quality improves
the capacity of the automatic composition. We highly recommend watching our
video before reading the paper (https://pozalabs.github.io/ComMU).",None,-1
99ae61de-01f5-48dd-9545-0a1789c993b7,Block-NeRF: Scalable Large Scene Neural View Synthesis,0.999458,"We present Block-NeRF, a variant of Neural Radiance Fields that can represent
large-scale environments. Specifically, we demonstrate that when scaling NeRF
to render city-scale scenes spanning multiple blocks, it is vital to decompose
the scene into individually trained NeRFs. This decomposition decouples
rendering time from scene size, enables rendering to scale to arbitrarily large
environments, and allows per-block updates of the environment. We adopt several
architectural changes to make NeRF robust to data captured over months under
different environmental conditions. We add appearance embeddings, learned pose
refinement, and controllable exposure to each individual NeRF, and introduce a
procedure for aligning appearance between adjacent NeRFs so that they can be
seamlessly combined. We build a grid of Block-NeRFs from 2.8 million images to
create the largest neural scene representation to date, capable of rendering an
entire neighborhood of San Francisco.",None,-1
069452b6-684e-44f7-aabd-d2630473b812,Task-specific Compression for Multi-task Language Models using Attribution-based Pruning,0.289678,"Multi-task language models show outstanding performance for various natural
language understanding tasks with only a single model. However, these language
models utilize an unnecessarily large number of model parameters, even when
used only for a specific task. This paper proposes a novel training-free
compression method for multi-task language models using a pruning method.
Specifically, we use an attribution method to determine which neurons are
essential for performing a specific task. We task-specifically prune
unimportant neurons and leave only task-specific parameters. Furthermore, we
extend our method to be applicable in low-resource and unsupervised settings.
Since our compression method is training-free, it uses few computing resources
and does not destroy the pre-trained knowledge of language models. Experimental
results on the six widely-used datasets show that our proposed pruning method
significantly outperforms baseline pruning methods. In addition, we demonstrate
that our method preserves performance even in an unseen domain setting.",None,4966
767767f9-f7d0-4fed-82fb-35f1a4810eca,Deanthropomorphising NLP: Can a Language Model Be Conscious?,0.85037,"This work is intended as a voice in the discussion over previous claims that
a pretrained large language model (LLM) based on the Transformer model
architecture can be sentient. Such claims have been made concerning the LaMDA
model and also concerning the current wave of LLM-powered chatbots, such as
ChatGPT. This claim, if confirmed, would have serious ramifications in the
Natural Language Processing (NLP) community due to wide-spread use of similar
models. However, here we take the position that such a large language model
cannot be sentient, or conscious, and that LaMDA in particular exhibits no
advances over other similar models that would qualify it. We justify this by
analysing the Transformer architecture through Integrated Information Theory of
consciousness. We see the claims of sentience as part of a wider tendency to
use anthropomorphic language in NLP reporting. Regardless of the veracity of
the claims, we consider this an opportune moment to take stock of progress in
language modelling and consider the ethical implications of the task. In order
to make this work helpful for readers outside the NLP community, we also
present the necessary background in language modelling.",None,-1
7203aa2b-4bed-4800-9ecb-e3084e93fba5,Arabic Fake News Detection Based on Deep Contextualized Embedding Models,0.928891,"Social media is becoming a source of news for many people due to its ease and
freedom of use. As a result, fake news has been spreading quickly and easily
regardless of its credibility, especially in the last decade. Fake news
publishers take advantage of critical situations such as the Covid-19 pandemic
and the American presidential elections to affect societies negatively. Fake
news can seriously impact society in many fields including politics, finance,
sports, etc. Many studies have been conducted to help detect fake news in
English, but research conducted on fake news detection in the Arabic language
is scarce. Our contribution is twofold: first, we have constructed a large and
diverse Arabic fake news dataset. Second, we have developed and evaluated
transformer-based classifiers to identify fake news while utilizing eight
state-of-the-art Arabic contextualized embedding models. The majority of these
models had not been previously used for Arabic fake news detection. We conduct
a thorough analysis of the state-of-the-art Arabic contextualized embedding
models as well as comparison with similar fake news detection systems.
Experimental results confirm that these state-of-the-art models are robust,
with accuracy exceeding 98%.",None,-1
5f73878e-48e9-4231-a0af-1e5b3b7e172d,Human-centric Image Cropping with Partition-aware and Content-preserving Features,0.511555,"Image cropping aims to find visually appealing crops in an image, which is an
important yet challenging task. In this paper, we consider a specific and
practical application: human-centric image cropping, which focuses on the
depiction of a person. To this end, we propose a human-centric image cropping
method with two novel feature designs for the candidate crop: partition-aware
feature and content-preserving feature. For partition-aware feature, we divide
the whole image into nine partitions based on the human bounding box and treat
different partitions in a candidate crop differently conditioned on the human
information. For content-preserving feature, we predict a heatmap indicating
the important content to be included in a good crop, and extract the geometric
relation between the heatmap and a candidate crop. Extensive experiments
demonstrate that our method can perform favorably against state-of-the-art
image cropping methods on human-centric image cropping task. Code is available
at https://github.com/bcmi/Human-Centric-Image-Cropping.",https://github.com/bcmi/Human-Centric-Image-Cropping,-1
d127a589-afae-425b-badb-1ba5c5dc275d,EA$^2$E: Improving Consistency with Event Awareness for Document-Level Argument Extraction,0.771406,"Events are inter-related in documents. Motivated by the
one-sense-per-discourse theory, we hypothesize that a participant tends to play
consistent roles across multiple events in the same document. However recent
work on document-level event argument extraction models each individual event
in isolation and therefore causes inconsistency among extracted arguments
across events, which will further cause discrepancy for downstream applications
such as event knowledge base population, question answering, and hypothesis
generation. In this work, we formulate event argument consistency as the
constraints from event-event relations under the document-level setting. To
improve consistency we introduce the Event-Aware Argument Extraction (EA$^2$E)
model with augmented context for training and inference. Experiment results on
WIKIEVENTS and ACE2005 datasets demonstrate the effectiveness of EA$^2$E
compared to baseline methods.",https://github.com/ZQS1943/DOCIE,-1
49ab3066-ff2f-4fce-a56b-ab5a00c3ce96,Towards Boosting the Open-Domain Chatbot with Human Feedback,0.426885,"Many open-domain dialogue models pre-trained with social media comments can
generate coherent replies but have difficulties producing engaging responses
when interacting with real users. This phenomenon might mainly result from the
deficiency of annotated human-human conversations and the misalignment with
human preference. In this paper, we propose a novel and efficient approach
Diamante to boost the open-domain chatbot, where two kinds of human feedback
(including explicit demonstration and implicit preference) are collected and
leveraged. By asking annotators to select or amend the model-generated
candidate responses, Diamante efficiently collects the human demonstrated
responses and constructs a Chinese chit-chat dataset. To enhance the alignment
with human preference, Diamante leverages the implicit preference in the data
collection process and introduces the generation-evaluation joint training.
Comprehensive experiments indicate that the Diamante dataset and joint training
paradigm can significantly boost the performance of Chinese pre-trained
dialogue models.",https://github.com/PaddlePaddle/Knover/tree/develop/projects/Diamante,-1
58275832-143a-403a-b0ee-1a72b7787e51,High-resolution Face Swapping via Latent Semantics Disentanglement,0.865615,"We present a novel high-resolution face swapping method using the inherent
prior knowledge of a pre-trained GAN model. Although previous research can
leverage generative priors to produce high-resolution results, their quality
can suffer from the entangled semantics of the latent space. We explicitly
disentangle the latent semantics by utilizing the progressive nature of the
generator, deriving structure attributes from the shallow layers and appearance
attributes from the deeper ones. Identity and pose information within the
structure attributes are further separated by introducing a landmark-driven
structure transfer latent direction. The disentangled latent code produces rich
generative features that incorporate feature blending to produce a plausible
swapping result. We further extend our method to video face swapping by
enforcing two spatio-temporal constraints on the latent space and the image
space. Extensive experiments demonstrate that the proposed method outperforms
state-of-the-art image/video face swapping methods in terms of hallucination
quality and consistency. Code can be found at:
https://github.com/cnnlstm/FSLSD_HiRes.",https://github.com/cnnlstm/FSLSD_HiRes,-1
997f93dc-8c78-410e-8001-a1bf77b85bd4,SimPer: Simple Self-Supervised Learning of Periodic Targets,0.64874,"From human physiology to environmental evolution, important processes in
nature often exhibit meaningful and strong periodic or quasi-periodic changes.
Due to their inherent label scarcity, learning useful representations for
periodic tasks with limited or no supervision is of great benefit. Yet,
existing self-supervised learning (SSL) methods overlook the intrinsic
periodicity in data, and fail to learn representations that capture periodic or
frequency attributes. In this paper, we present SimPer, a simple contrastive
SSL regime for learning periodic information in data. To exploit the periodic
inductive bias, SimPer introduces customized augmentations, feature similarity
measures, and a generalized contrastive loss for learning efficient and robust
periodic representations. Extensive experiments on common real-world tasks in
human behavior analysis, environmental sensing, and healthcare domains verify
the superior performance of SimPer compared to state-of-the-art SSL methods,
highlighting its intriguing properties including better data efficiency,
robustness to spurious correlations, and generalization to distribution shifts.
Code and data are available at: https://github.com/YyzHarry/SimPer.",https://github.com/YyzHarry/SimPer,-1
367a5374-00d2-46c5-8067-124c10957152,Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners,0.418028,"Meta-training, which fine-tunes the language model (LM) on various downstream
tasks by maximizing the likelihood of the target label given the task
instruction and input instance, has improved the zero-shot task generalization
performance. However, meta-trained LMs still struggle to generalize to
challenging tasks containing novel labels unseen during meta-training. In this
paper, we propose Flipped Learning, an alternative method of meta-training
which trains the LM to generate the task instruction given the input instance
and label. During inference, the LM trained with Flipped Learning, referred to
as Flipped, selects the label option that is most likely to generate the task
instruction. On 14 tasks of the BIG-bench benchmark, the 11B-sized Flipped
outperforms zero-shot T0-11B and even a 16 times larger 3-shot GPT-3 (175B) on
average by 8.4% and 9.7% points, respectively. Flipped gives particularly large
improvements on tasks with unseen labels, outperforming T0-11B by up to +20%
average F1 score. This indicates that the strong task generalization of Flipped
comes from improved generalization to novel labels. We release our code at
https://github.com/seonghyeonye/Flipped-Learning.",https://github.com/seonghyeonye/Flipped-Learning,-1
11f7ca6f-4d62-4b8b-9682-503053ec0b18,Strategy Synthesis for Zero-Sum Neuro-Symbolic Concurrent Stochastic Games,0.864665,"Neuro-symbolic approaches to artificial intelligence, which combine neural
networks with classical symbolic techniques, are growing in prominence,
necessitating formal approaches to reason about their correctness. We propose a
novel modelling formalism called neuro-symbolic concurrent stochastic games
(NS-CSGs), which comprise two probabilistic finite-state agents interacting in
a shared continuous-state environment. Each agent observes the environment
using a neural perception mechanism, which converts inputs such as images into
symbolic percepts, and makes decisions symbolically. We focus on the class of
NS-CSGs with Borel state spaces and prove the existence and measurability of
the value function for zero-sum discounted cumulative rewards under
piecewise-constant restrictions on the components of this class of models. To
compute values and synthesise strategies, we present, for the first time,
practical value iteration (VI) and policy iteration (PI) algorithms to solve
this new subclass of continuous-state CSGs. These require a finite
decomposition of the environment induced by the neural perception mechanisms of
the agents and rely on finite abstract representations of value functions and
strategies closed under VI or PI. First, we introduce a Borel measurable
piecewise-constant (B-PWC) representation of value functions, extend minimax
backups to this representation and propose a value iteration algorithm called
B-PWC VI. Second, we introduce two novel representations for the value
functions and strategies, constant-piecewise-linear (CON-PWL) and
constant-piecewise-constant (CON-PWC) respectively, and propose
Minimax-action-free PI by extending a recent PI method based on alternating
player choices for finite state spaces to Borel state spaces, which does not
require normal-form games to be solved.",None,16419
8741a635-6805-478a-9750-ddd8c7d7ec6e,AnyFace: Free-style Text-to-Face Synthesis and Manipulation,0.994248,"Existing text-to-image synthesis methods generally are only applicable to
words in the training dataset. However, human faces are so variable to be
described with limited words. So this paper proposes the first free-style
text-to-face method namely AnyFace enabling much wider open world applications
such as metaverse, social media, cosmetics, forensics, etc. AnyFace has a novel
two-stream framework for face image synthesis and manipulation given arbitrary
descriptions of the human face. Specifically, one stream performs text-to-face
generation and the other conducts face image reconstruction. Facial text and
image features are extracted using the CLIP (Contrastive Language-Image
Pre-training) encoders. And a collaborative Cross Modal Distillation (CMD)
module is designed to align the linguistic and visual features across these two
streams. Furthermore, a Diverse Triplet Loss (DT loss) is developed to model
fine-grained features and improve facial diversity. Extensive experiments on
Multi-modal CelebA-HQ and CelebAText-HQ demonstrate significant advantages of
AnyFace over state-of-the-art methods. AnyFace can achieve high-quality,
high-resolution, and high-diversity face synthesis and manipulation results
without any constraints on the number and content of input captions.",None,-1
7f8f9713-3983-42f7-ab16-1a5a0cdd4701,Spatio-Temporal Tuples Transformer for Skeleton-Based Action Recognition,0.920629,"Capturing the dependencies between joints is critical in skeleton-based
action recognition task. Transformer shows great potential to model the
correlation of important joints. However, the existing Transformer-based
methods cannot capture the correlation of different joints between frames,
which the correlation is very useful since different body parts (such as the
arms and legs in ""long jump"") between adjacent frames move together. Focus on
this problem, A novel spatio-temporal tuples Transformer (STTFormer) method is
proposed. The skeleton sequence is divided into several parts, and several
consecutive frames contained in each part are encoded. And then a
spatio-temporal tuples self-attention module is proposed to capture the
relationship of different joints in consecutive frames. In addition, a feature
aggregation module is introduced between non-adjacent frames to enhance the
ability to distinguish similar actions. Compared with the state-of-the-art
methods, our method achieves better performance on two large-scale datasets.",https://github.com/heleiqiu/STTFormer,-1
fa9e382a-283f-4c67-8b32-396e6d2dbb71,A Binary Characterization Method for Shape Convexity and Applications,0.0395454,"Convexity prior is one of the main cue for human vision and shape completion
with important applications in image processing, computer vision. This paper
focuses on characterization methods for convex objects and applications in
image processing. We present a new method for convex objects representations
using binary functions, that is, the convexity of a region is equivalent to a
simple quadratic inequality constraint on its indicator function. Models are
proposed firstly by incorporating this result for image segmentation with
convexity prior and convex hull computation of a given set with and without
noises. Then, these models are summarized to a general optimization problem on
binary function(s) with the quadratic inequality. Numerical algorithm is
proposed based on linearization technique, where the linearized problem is
solved by a proximal alternating direction method of multipliers with
guaranteed convergent. Numerical experiments demonstrate the efficiency and
effectiveness of the proposed methods for image segmentation and convex hull
computation in accuracy and computing time.",None,-1
2eedc60c-493a-4517-a60b-de7c267f8eec,Super-resolution 3D Human Shape from a Single Low-Resolution Image,0.350102,"We propose a novel framework to reconstruct super-resolution human shape from
a single low-resolution input image. The approach overcomes limitations of
existing approaches that reconstruct 3D human shape from a single image, which
require high-resolution images together with auxiliary data such as surface
normal or a parametric model to reconstruct high-detail shape. The proposed
framework represents the reconstructed shape with a high-detail implicit
function. Analogous to the objective of 2D image super-resolution, the approach
learns the mapping from a low-resolution shape to its high-resolution
counterpart and it is applied to reconstruct 3D shape detail from
low-resolution images. The approach is trained end-to-end employing a novel
loss function which estimates the information lost between a low and
high-resolution representation of the same 3D surface shape. Evaluation for
single image reconstruction of clothed people demonstrates that our method
achieves high-detail surface reconstruction from low-resolution images without
auxiliary data. Extensive experiments show that the proposed approach can
estimate super-resolution human geometries with a significantly higher level of
detail than that obtained with previous approaches when applied to
low-resolution images.",None,13308
22b31a80-89bd-4820-b1eb-352d520ac379,SATformer: Transformer-Based UNSAT Core Learning,0.301348,"This paper introduces SATformer, a novel Transformer-based approach for the
Boolean Satisfiability (SAT) problem. Rather than solving the problem directly,
SATformer approaches the problem from the opposite direction by focusing on
unsatisfiability. Specifically, it models clause interactions to identify any
unsatisfiable sub-problems. Using a graph neural network, we convert clauses
into clause embeddings and employ a hierarchical Transformer-based model to
understand clause correlation. SATformer is trained through a multi-task
learning approach, using the single-bit satisfiability result and the minimal
unsatisfiable core (MUC) for UNSAT problems as clause supervision. As an
end-to-end learning-based satisfiability classifier, the performance of
SATformer surpasses that of NeuroSAT significantly. Furthermore, we integrate
the clause predictions made by SATformer into modern heuristic-based SAT
solvers and validate our approach with a logic equivalence checking task.
Experimental results show that our SATformer can decrease the runtime of
existing solvers by an average of 21.33%.",None,8741
226d764b-efc9-4997-9adb-7f6851d12dfe,A Classical-Quantum Convolutional Neural Network for Detecting Pneumonia from Chest Radiographs,0.221785,"While many quantum computing techniques for machine learning have been
proposed, their performance on real-world datasets remains to be studied. In
this paper, we explore how a variational quantum circuit could be integrated
into a classical neural network for the problem of detecting pneumonia from
chest radiographs. We substitute one layer of a classical convolutional neural
network with a variational quantum circuit to create a hybrid neural network.
We train both networks on an image dataset containing chest radiographs and
benchmark their performance. To mitigate the influence of different sources of
randomness in network training, we sample the results over multiple rounds. We
show that the hybrid network outperforms the classical network on different
performance measures, and that these improvements are statistically
significant. Our work serves as an experimental demonstration of the potential
of quantum computing to significantly improve neural network performance for
real-world, non-trivial problems relevant to society and industry.",None,-1
205845e4-c425-4ccd-a0de-f4ac56a856f0,Table-based Fact Verification with Self-adaptive Mixture of Experts,0.876011,"The table-based fact verification task has recently gained widespread
attention and yet remains to be a very challenging problem. It inherently
requires informative reasoning over natural language together with different
numerical and logical reasoning on tables (e.g., count, superlative,
comparative). Considering that, we exploit mixture-of-experts and present in
this paper a new method: Self-adaptive Mixture-of-Experts Network (SaMoE).
Specifically, we have developed a mixture-of-experts neural network to
recognize and execute different types of reasoning -- the network is composed
of multiple experts, each handling a specific part of the semantics for
reasoning, whereas a management module is applied to decide the contribution of
each expert network to the verification result. A self-adaptive method is
developed to teach the management module combining results of different experts
more efficiently without external knowledge. The experimental results
illustrate that our framework achieves 85.1% accuracy on the benchmark dataset
TabFact, comparable with the previous state-of-the-art models. We hope our
framework can serve as a new baseline for table-based verification. Our code is
available at https://github.com/THUMLP/SaMoE.",https://github.com/THUMLP/SaMoE,2921
d9840282-d1c6-432f-8075-5a3d80d13195,Gendered Mental Health Stigma in Masked Language Models,0.979246,"Mental health stigma prevents many individuals from receiving the appropriate
care, and social psychology studies have shown that mental health tends to be
overlooked in men. In this work, we investigate gendered mental health stigma
in masked language models. In doing so, we operationalize mental health stigma
by developing a framework grounded in psychology research: we use clinical
psychology literature to curate prompts, then evaluate the models' propensity
to generate gendered words. We find that masked language models capture
societal stigma about gender in mental health: models are consistently more
likely to predict female subjects than male in sentences about having a mental
health condition (32% vs. 19%), and this disparity is exacerbated for sentences
that indicate treatment-seeking behavior. Furthermore, we find that different
models capture dimensions of stigma differently for men and women, associating
stereotypes like anger, blame, and pity more with women with mental health
conditions than with men. In showing the complex nuances of models' gendered
mental health stigma, we demonstrate that context and overlapping dimensions of
identity are important considerations when assessing computational models'
social biases.",https://github.com/LucilleN/Gendered-MH-Stigma-in-Masked-LMs,-1
cef3d039-e935-4120-b6c3-6dddfb9969ce,SATr: Slice Attention with Transformer for Universal Lesion Detection,0.845477,"Universal Lesion Detection (ULD) in computed tomography plays an essential
role in computer-aided diagnosis. Promising ULD results have been reported by
multi-slice-input detection approaches which model 3D context from multiple
adjacent CT slices, but such methods still experience difficulty in obtaining a
global representation among different slices and within each individual slice
since they only use convolution-based fusion operations. In this paper, we
propose a novel Slice Attention Transformer (SATr) block which can be easily
plugged into convolution-based ULD backbones to form hybrid network structures.
Such newly formed hybrid backbones can better model long-distance feature
dependency via the cascaded self-attention modules in the Transformer block
while still holding a strong power of modeling local features with the
convolutional operations in the original backbone. Experiments with five
state-of-the-art methods show that the proposed SATr block can provide an
almost free boost to lesion detection accuracy without extra hyperparameters or
special network designs.",https://github.com/jacobgil/pytorch-grad-cam,-1
8154cd56-8a92-4597-8d22-11dd1c706368,DyLoRA: Parameter Efficient Tuning of Pre-trained Models using Dynamic Search-Free Low-Rank Adaptation,0.999942,"With the ever-growing size of pretrained models (PMs), fine-tuning them has
become more expensive and resource-hungry. As a remedy, low-rank adapters
(LoRA) keep the main pretrained weights of the model frozen and just introduce
some learnable truncated SVD modules (so-called LoRA blocks) to the model.
While LoRA blocks are parameter-efficient, they suffer from two major problems:
first, the size of these blocks is fixed and cannot be modified after training
(for example, if we need to change the rank of LoRA blocks, then we need to
re-train them from scratch); second, optimizing their rank requires an
exhaustive search and effort. In this work, we introduce a dynamic low-rank
adaptation (DyLoRA) technique to address these two problems together. Our
DyLoRA method trains LoRA blocks for a range of ranks instead of a single rank
by sorting the representation learned by the adapter module at different ranks
during training. We evaluate our solution on different natural language
understanding (GLUE benchmark) and language generation tasks (E2E, DART and
WebNLG) using different pretrained models such as RoBERTa and GPT with
different sizes. Our results show that we can train dynamic search-free models
with DyLoRA at least 4 to 7 times (depending to the task) faster than LoRA
without significantly compromising performance. Moreover, our models can
perform consistently well on a much larger range of ranks compared to LoRA.",https://github.com/huawei-noah/KD-NLP/tree/main/DyLoRA,-1
2694bee1-f257-476a-8b71-47516e0ea4ad,A dynamic programming algorithm for span-based nested named-entity recognition in O(n^2),0.624836,"Span-based nested named-entity recognition (NER) has a cubic-time complexity
using a variant of the CYK algorithm. We show that by adding a supplementary
structural constraint on the search space, nested NER has a quadratic-time
complexity, that is the same asymptotic complexity than the non-nested case.
The proposed algorithm covers a large part of three standard English benchmarks
and delivers comparable experimental results.",None,-1
510338b9-49fb-498e-856a-8e9eb073fc9a,Probing Speech Emotion Recognition Transformers for Linguistic Knowledge,0.820586,"Large, pre-trained neural networks consisting of self-attention layers
(transformers) have recently achieved state-of-the-art results on several
speech emotion recognition (SER) datasets. These models are typically
pre-trained in self-supervised manner with the goal to improve automatic speech
recognition performance -- and thus, to understand linguistic information. In
this work, we investigate the extent in which this information is exploited
during SER fine-tuning. Using a reproducible methodology based on open-source
tools, we synthesise prosodically neutral speech utterances while varying the
sentiment of the text. Valence predictions of the transformer model are very
reactive to positive and negative sentiment content, as well as negations, but
not to intensifiers or reducers, while none of those linguistic features impact
arousal or dominance. These findings show that transformers can successfully
leverage linguistic information to improve their valence predictions, and that
linguistic analysis should be included in their testing.",https://github.com/espnet/espnet,-1
c1c5a5d5-3fa3-475b-92fe-1b348fbfe232,EC-KitY: Evolutionary Computation Tool Kit in Python with Seamless Machine Learning Integration,0.553022,"EC-KitY is a comprehensive Python library for doing evolutionary computation
(EC), licensed under the BSD 3-Clause License, and compatible with
scikit-learn. Designed with modern software engineering and machine learning
integration in mind, EC-KitY can support all popular EC paradigms, including
genetic algorithms, genetic programming, coevolution, evolutionary
multi-objective optimization, and more. This paper provides an overview of the
package, including the ease of setting up an EC experiment, the architecture,
the main features, and a comparison with other libraries.",https://github.com/EC-KitY/EC-KitY,-1
1267352f-2412-4931-9375-0855a3e5e33a,Hierarchical Compositional Representations for Few-shot Action Recognition,0.320683,"Recently action recognition has received more and more attention for its
comprehensive and practical applications in intelligent surveillance and
human-computer interaction. However, few-shot action recognition has not been
well explored and remains challenging because of data scarcity. In this paper,
we propose a novel hierarchical compositional representations (HCR) learning
approach for few-shot action recognition. Specifically, we divide a complicated
action into several sub-actions by carefully designed hierarchical clustering
and further decompose the sub-actions into more fine-grained spatially
attentional sub-actions (SAS-actions). Although there exist large differences
between base classes and novel classes, they can share similar patterns in
sub-actions or SAS-actions. Furthermore, we adopt the Earth Mover's Distance in
the transportation problem to measure the similarity between video samples in
terms of sub-action representations. It computes the optimal matching flows
between sub-actions as distance metric, which is favorable for comparing
fine-grained patterns. Extensive experiments show our method achieves the
state-of-the-art results on HMDB51, UCF101 and Kinetics datasets.",None,38355
21817089-4764-453b-b838-8bb7af6e7cdf,"Mintaka: A Complex, Natural, and Multilingual Dataset for End-to-End Question Answering",0.546409,"We introduce Mintaka, a complex, natural, and multilingual dataset designed
for experimenting with end-to-end question-answering models. Mintaka is
composed of 20,000 question-answer pairs collected in English, annotated with
Wikidata entities, and translated into Arabic, French, German, Hindi, Italian,
Japanese, Portuguese, and Spanish for a total of 180,000 samples. Mintaka
includes 8 types of complex questions, including superlative, intersection, and
multi-hop questions, which were naturally elicited from crowd workers. We run
baselines over Mintaka, the best of which achieves 38% hits@1 in English and
31% hits@1 multilingually, showing that existing models have room for
improvement. We release Mintaka at https://github.com/amazon-research/mintaka.",https://github.com/amazon-research/mintaka,-1
8c92f3fe-0adf-489b-b4b4-9a43a20d5cc9,Variational Reasoning over Incomplete Knowledge Graphs for Conversational Recommendation,0.629163,"Conversational recommender systems (CRSs) often utilize external knowledge
graphs (KGs) to introduce rich semantic information and recommend relevant
items through natural language dialogues. However, original KGs employed in
existing CRSs are often incomplete and sparse, which limits the reasoning
capability in recommendation. Moreover, only few of existing studies exploit
the dialogue context to dynamically refine knowledge from KGs for better
recommendation. To address the above issues, we propose the Variational
Reasoning over Incomplete KGs Conversational Recommender (VRICR). Our key idea
is to incorporate the large dialogue corpus naturally accompanied with CRSs to
enhance the incomplete KGs; and perform dynamic knowledge reasoning conditioned
on the dialogue context. Specifically, we denote the dialogue-specific
subgraphs of KGs as latent variables with categorical priors for adaptive
knowledge graphs refactor. We propose a variational Bayesian method to
approximate posterior distributions over dialogue-specific subgraphs, which not
only leverages the dialogue corpus for restructuring missing entity relations
but also dynamically selects knowledge based on the dialogue context. Finally,
we infuse the dialogue-specific subgraphs to decode the recommendation and
responses. We conduct experiments on two benchmark CRSs datasets. Experimental
results confirm the effectiveness of our proposed method.",https://github.com/zxd-octopus/VRICR,-1
237a2c06-ba6f-469c-9bd1-35f2adce3c89,Contrastive Representation Learning for Cross-Document Coreference Resolution of Events and Entities,0.143337,"Identifying related entities and events within and across documents is
fundamental to natural language understanding. We present an approach to entity
and event coreference resolution utilizing contrastive representation learning.
Earlier state-of-the-art methods have formulated this problem as a binary
classification problem and leveraged large transformers in a cross-encoder
architecture to achieve their results. For large collections of documents and
corresponding set of $n$ mentions, the necessity of performing $n^{2}$
transformer computations in these earlier approaches can be computationally
intensive. We show that it is possible to reduce this burden by applying
contrastive learning techniques that only require $n$ transformer computations
at inference time. Our method achieves state-of-the-art results on a number of
key metrics on the ECB+ corpus and is competitive on others.",https://github.com/scikit-optimize/scikit-optimize,-1
d93957a4-2256-48d2-8ab0-7da64cbfa65f,Instance-specific and Model-adaptive Supervision for Semi-supervised Semantic Segmentation,0.692204,"Recently, semi-supervised semantic segmentation has achieved promising
performance with a small fraction of labeled data. However, most existing
studies treat all unlabeled data equally and barely consider the differences
and training difficulties among unlabeled instances. Differentiating unlabeled
instances can promote instance-specific supervision to adapt to the model's
evolution dynamically. In this paper, we emphasize the cruciality of instance
differences and propose an instance-specific and model-adaptive supervision for
semi-supervised semantic segmentation, named iMAS. Relying on the model's
performance, iMAS employs a class-weighted symmetric intersection-over-union to
evaluate quantitative hardness of each unlabeled instance and supervises the
training on unlabeled data in a model-adaptive manner. Specifically, iMAS
learns from unlabeled instances progressively by weighing their corresponding
consistency losses based on the evaluated hardness. Besides, iMAS dynamically
adjusts the augmentation for each instance such that the distortion degree of
augmented instances is adapted to the model's generalization capability across
the training course. Not integrating additional losses and training procedures,
iMAS can obtain remarkable performance gains against current state-of-the-art
approaches on segmentation benchmarks under different semi-supervised partition
protocols.",https://github.com/zhenzhao/iMAS,-1
43609747-0743-40a7-81d1-f88441468d3c,Optical tracking in team sports,0.798104,"Sports analysis has gained paramount importance for coaches, scouts, and
fans. Recently, computer vision researchers have taken on the challenge of
collecting the necessary data by proposing several methods of automatic player
and ball tracking. Building on the gathered tracking data, data miners are able
to perform quantitative analysis on the performance of players and teams. With
this survey, our goal is to provide a basic understanding for quantitative data
analysts about the process of creating the input data and the characteristics
thereof. Thus, we summarize the recent methods of optical tracking by providing
a comprehensive taxonomy of conventional and deep learning methods, separately.
Moreover, we discuss the preprocessing steps of tracking, the most common
challenges in this domain, and the application of tracking data to sports
teams. Finally, we compare the methods by their cost and limitations, and
conclude the work by highlighting potential future research directions.",None,-1
9e678550-9b42-44ad-aefb-7fc4dbddf379,Towards standardizing Korean Grammatical Error Correction: Datasets and Annotation,0.594463,"Research on Korean grammatical error correction (GEC) is limited, compared to
other major languages such as English. We attribute this problematic
circumstance to the lack of a carefully designed evaluation benchmark for
Korean GEC. In this work, we collect three datasets from different sources
(Kor-Lang8, Kor-Native, and Kor-Learner) that covers a wide range of Korean
grammatical errors. Considering the nature of Korean grammar, We then define 14
error types for Korean and provide KAGAS (Korean Automatic Grammatical error
Annotation System), which can automatically annotate error types from parallel
corpora. We use KAGAS on our datasets to make an evaluation benchmark for
Korean, and present baseline models trained from our datasets. We show that the
model trained with our datasets significantly outperforms the currently used
statistical Korean GEC system (Hanspell) on a wider range of error types,
demonstrating the diversity and usefulness of the datasets. The implementations
and datasets are open-sourced.",https://github.com/soyoung97/Standard_Korean_GEC,-1
19c52dd5-cc02-4d9d-99c6-50daa1472dba,Unsupervised Wildfire Change Detection based on Contrastive Learning,0.247728,"The accurate characterization of the severity of the wildfire event strongly
contributes to the characterization of the fuel conditions in fire-prone areas,
and provides valuable information for disaster response. The aim of this study
is to develop an autonomous system built on top of high-resolution
multispectral satellite imagery, with an advanced deep learning method for
detecting burned area change. This work proposes an initial exploration of
using an unsupervised model for feature extraction in wildfire scenarios. It is
based on the contrastive learning technique SimCLR, which is trained to
minimize the cosine distance between augmentations of images. The distance
between encoded images can also be used for change detection. We propose
changes to this method that allows it to be used for unsupervised burned area
detection and following downstream tasks. We show that our proposed method
outperforms the tested baseline approaches.",None,-1
2ab76533-e95a-43ae-88c9-4339c90698ae,From Pedestrian Detection to Crosswalk Estimation: An EM Algorithm and Analysis on Diverse Datasets,0.0922986,"In this work, we contribute an EM algorithm for estimation of corner points
and linear crossing segments for both marked and unmarked pedestrian crosswalks
using the detections of pedestrians from processed LiDAR point clouds or camera
images. We demonstrate the algorithmic performance by analyzing three
real-world datasets containing multiple periods of data collection for
four-corner and two-corner intersections with marked and unmarked crosswalks.
Additionally, we include a Python video tool to visualize the crossing
parameter estimation, pedestrian trajectories, and phase intervals in our
public source code.",None,39442
62dbdfaf-6b06-4660-8ae4-048a8c27673b,Exploring Document-Level Literary Machine Translation with Parallel Paragraphs from World Literature,0.83929,"Literary translation is a culturally significant task, but it is bottlenecked
by the small number of qualified literary translators relative to the many
untranslated works published around the world. Machine translation (MT) holds
potential to complement the work of human translators by improving both
training procedures and their overall efficiency. Literary translation is less
constrained than more traditional MT settings since translators must balance
meaning equivalence, readability, and critical interpretability in the target
language. This property, along with the complex discourse-level context present
in literary texts, also makes literary MT more challenging to computationally
model and evaluate. To explore this task, we collect a dataset (Par3) of
non-English language novels in the public domain, each aligned at the paragraph
level to both human and automatic English translations. Using Par3, we discover
that expert literary translators prefer reference human translations over
machine-translated paragraphs at a rate of 84%, while state-of-the-art
automatic MT metrics do not correlate with those preferences. The experts note
that MT outputs contain not only mistranslations, but also discourse-disrupting
errors and stylistic inconsistencies. To address these problems, we train a
post-editing model whose output is preferred over normal MT output at a rate of
69% by experts. We publicly release Par3 at
https://github.com/katherinethai/par3/ to spur future research into literary
MT.",https://github.com/katherinethai/par3/,-1
72574dd8-678d-4252-bf9b-2a3e014e9861,Consistent Range Approximation for Fair Predictive Modeling,0.319464,"This paper proposes a novel framework for certifying the fairness of
predictive models trained on biased data. It draws from query answering for
incomplete and inconsistent databases to formulate the problem of consistent
range approximation (CRA) of fairness queries for a predictive model on a
target population. The framework employs background knowledge of the data
collection process and biased data, working with or without limited statistics
about the target population, to compute a range of answers for fairness
queries. Using CRA, the framework builds predictive models that are certifiably
fair on the target population, regardless of the availability of external data
during training. The framework's efficacy is demonstrated through evaluations
on real data, showing substantial improvement over existing state-of-the-art
methods.",https://github.com/lodino/Crab,-1
5f5a6108-7f14-4735-89f2-8e59d6091370,Co-evolving morphology and control of soft robots using a single genome,0.793808,"When simulating soft robots, both their morphology and their controllers play
important roles in task performance. This paper introduces a new method to
co-evolve these two components in the same process. We do that by using the
hyperNEAT algorithm to generate two separate neural networks in one pass, one
responsible for the design of the robot body structure and the other for the
control of the robot.
  The key difference between our method and most existing approaches is that it
does not treat the development of the morphology and the controller as separate
processes. Similar to nature, our method derives both the ""brain"" and the
""body"" of an agent from a single genome and develops them together. While our
approach is more realistic and doesn't require an arbitrary separation of
processes during evolution, it also makes the problem more complex because the
search space for this single genome becomes larger and any mutation to the
genome affects ""brain"" and the ""body"" at the same time.
  Additionally, we present a new speciation function that takes into
consideration both the genotypic distance, as is the standard for NEAT, and the
similarity between robot bodies. By using this function, agents with very
different bodies are more likely to be in different species, this allows robots
with different morphologies to have more specialized controllers since they
won't crossover with other robots that are too different from them.
  We evaluate the presented methods on four tasks and observe that even if the
search space was larger, having a single genome makes the evolution process
converge faster when compared to having separated genomes for body and control.
The agents in our population also show morphologies with a high degree of
regularity and controllers capable of coordinating the voxels to produce the
necessary movements.",https://github.com/fhtanaka/SGR,-1
b4cd9873-d026-4e4c-af20-bac38de3ebc7,Understanding and Improving Knowledge Distillation for Quantization-Aware Training of Large Transformer Encoders,0.511428,"Knowledge distillation (KD) has been a ubiquitous method for model
compression to strengthen the capability of a lightweight model with the
transferred knowledge from the teacher. In particular, KD has been employed in
quantization-aware training (QAT) of Transformer encoders like BERT to improve
the accuracy of the student model with the reduced-precision weight parameters.
However, little is understood about which of the various KD approaches best
fits the QAT of Transformers. In this work, we provide an in-depth analysis of
the mechanism of KD on attention recovery of quantized large Transformers. In
particular, we reveal that the previously adopted MSE loss on the attention
score is insufficient for recovering the self-attention information. Therefore,
we propose two KD methods; attention-map and attention-output losses.
Furthermore, we explore the unification of both losses to address
task-dependent preference between attention-map and output losses. The
experimental results on various Transformer encoder models demonstrate that the
proposed KD methods achieve state-of-the-art accuracy for QAT with sub-2-bit
weight quantization.",https://github.com/MarsJacobs/kd-qat-large-enc,-1
e8e04a72-0850-488d-b952-ecdb6c18b295,Optimizing LLVM Pass Sequences with Shackleton: A Linear Genetic Programming Framework,0.566381,"In this paper we introduce Shackleton as a generalized framework enabling the
application of linear genetic programming -- a technique under the umbrella of
evolutionary algorithms -- to a variety of use cases. We also explore here a
novel application for this class of methods: optimizing sequences of LLVM
optimization passes. The algorithm underpinning Shackleton is discussed, with
an emphasis on the effects of different features unique to the framework when
applied to LLVM pass sequences. Combined with analysis of different
hyperparameter settings, we report the results on automatically optimizing pass
sequences using Shackleton for two software applications at differing
complexity levels. Finally, we reflect on the advantages and limitations of our
current implementation and lay out a path for further improvements. These
improvements aim to surpass hand-crafted solutions with an automatic discovery
method for an optimal pass sequence.",None,-1
5a374ec8-f171-4cd0-b5b6-0bdf76ac02dd,UniCLIP: Unified Framework for Contrastive Language-Image Pre-training,0.600511,"Pre-training vision-language models with contrastive objectives has shown
promising results that are both scalable to large uncurated datasets and
transferable to many downstream applications. Some following works have
targeted to improve data efficiency by adding self-supervision terms, but
inter-domain (image-text) contrastive loss and intra-domain (image-image)
contrastive loss are defined on individual spaces in those works, so many
feasible combinations of supervision are overlooked. To overcome this issue, we
propose UniCLIP, a Unified framework for Contrastive Language-Image
Pre-training. UniCLIP integrates the contrastive loss of both inter-domain
pairs and intra-domain pairs into a single universal space. The discrepancies
that occur when integrating contrastive loss between different domains are
resolved by the three key components of UniCLIP: (1) augmentation-aware feature
embedding, (2) MP-NCE loss, and (3) domain dependent similarity measure.
UniCLIP outperforms previous vision-language pre-training methods on various
single- and multi-modality downstream tasks. In our experiments, we show that
each component that comprises UniCLIP contributes well to the final
performance.",https://github.com/Sense-GVT/DeCLIP,-1
156644e2-07dd-44e5-918d-001561ceec97,"Event Causality Identification with Causal News Corpus -- Shared Task 3, CASE 2022",0.797048,"The Event Causality Identification Shared Task of CASE 2022 involved two
subtasks working on the Causal News Corpus. Subtask 1 required participants to
predict if a sentence contains a causal relation or not. This is a supervised
binary classification task. Subtask 2 required participants to identify the
Cause, Effect and Signal spans per causal sentence. This could be seen as a
supervised sequence labeling task. For both subtasks, participants uploaded
their predictions for a held-out test set, and ranking was done based on binary
F1 and macro F1 scores for Subtask 1 and 2, respectively. This paper summarizes
the work of the 17 teams that submitted their results to our competition and 12
system description papers that were received. The best F1 scores achieved for
Subtask 1 and 2 were 86.19% and 54.15%, respectively. All the top-performing
approaches involved pre-trained language models fine-tuned to the targeted
task. We further discuss these approaches and analyze errors across
participants' systems in this paper.",https://github.com/tanfiona/UniCausal,3459
59357ca4-e025-43f4-9f2f-a010cc227d69,Robust Region Feature Synthesizer for Zero-Shot Object Detection,0.642312,"Zero-shot object detection aims at incorporating class semantic vectors to
realize the detection of (both seen and) unseen classes given an unconstrained
test image. In this study, we reveal the core challenges in this research area:
how to synthesize robust region features (for unseen objects) that are as
intra-class diverse and inter-class separable as the real samples, so that
strong unseen object detectors can be trained upon them. To address these
challenges, we build a novel zero-shot object detection framework that contains
an Intra-class Semantic Diverging component and an Inter-class Structure
Preserving component. The former is used to realize the one-to-more mapping to
obtain diverse visual features from each class semantic vector, preventing
miss-classifying the real unseen objects as image backgrounds. While the latter
is used to avoid the synthesized features too scattered to mix up the
inter-class and foreground-background relationship. To demonstrate the
effectiveness of the proposed approach, comprehensive experiments on PASCAL
VOC, COCO, and DIOR datasets are conducted. Notably, our approach achieves the
new state-of-the-art performance on PASCAL VOC and COCO and it is the first
study to carry out zero-shot object detection in remote sensing imagery.",None,-1
bda9aa11-8aa8-49c9-8314-cf3019d796b9,AWADA: Attention-Weighted Adversarial Domain Adaptation for Object Detection,0.1685,"Object detection networks have reached an impressive performance level, yet a
lack of suitable data in specific applications often limits it in practice.
Typically, additional data sources are utilized to support the training task.
In these, however, domain gaps between different data sources pose a challenge
in deep learning. GAN-based image-to-image style-transfer is commonly applied
to shrink the domain gap, but is unstable and decoupled from the object
detection task. We propose AWADA, an Attention-Weighted Adversarial Domain
Adaptation framework for creating a feedback loop between style-transformation
and detection task. By constructing foreground object attention maps from
object detector proposals, we focus the transformation on foreground object
regions and stabilize style-transfer training. In extensive experiments and
ablation studies, we show that AWADA reaches state-of-the-art unsupervised
domain adaptation object detection performance in the commonly used benchmarks
for tasks such as synthetic-to-real, adverse weather and cross-camera
adaptation.",None,-1
aea1167f-300e-4d04-ba6d-7f0961952c65,Multi-Faceted Distillation of Base-Novel Commonality for Few-shot Object Detection,0.393716,"Most of existing methods for few-shot object detection follow the fine-tuning
paradigm, which potentially assumes that the class-agnostic generalizable
knowledge can be learned and transferred implicitly from base classes with
abundant samples to novel classes with limited samples via such a two-stage
training strategy. However, it is not necessarily true since the object
detector can hardly distinguish between class-agnostic knowledge and
class-specific knowledge automatically without explicit modeling. In this work
we propose to learn three types of class-agnostic commonalities between base
and novel classes explicitly: recognition-related semantic commonalities,
localization-related semantic commonalities and distribution commonalities. We
design a unified distillation framework based on a memory bank, which is able
to perform distillation of all three types of commonalities jointly and
efficiently. Extensive experiments demonstrate that our method can be readily
integrated into most of existing fine-tuning based methods and consistently
improve the performance by a large margin.",https://github.com/WuShuang1998/MFDC,-1
5dfc6a72-9982-460b-85cb-bb58a3fb948a,SparseNeuS: Fast Generalizable Neural Surface Reconstruction from Sparse Views,0.991195,"We introduce SparseNeuS, a novel neural rendering based method for the task
of surface reconstruction from multi-view images. This task becomes more
difficult when only sparse images are provided as input, a scenario where
existing neural reconstruction approaches usually produce incomplete or
distorted results. Moreover, their inability of generalizing to unseen new
scenes impedes their application in practice. Contrarily, SparseNeuS can
generalize to new scenes and work well with sparse images (as few as 2 or 3).
SparseNeuS adopts signed distance function (SDF) as the surface representation,
and learns generalizable priors from image features by introducing geometry
encoding volumes for generic surface prediction. Moreover, several strategies
are introduced to effectively leverage sparse views for high-quality
reconstruction, including 1) a multi-level geometry reasoning framework to
recover the surfaces in a coarse-to-fine manner; 2) a multi-scale color
blending scheme for more reliable color prediction; 3) a consistency-aware
fine-tuning scheme to control the inconsistent regions caused by occlusion and
noise. Extensive experiments demonstrate that our approach not only outperforms
the state-of-the-art methods, but also exhibits good efficiency,
generalizability, and flexibility.",https://www.xxlong.site/SparseNeuSarXiv:2206.05737v2,-1
a00f56c7-2516-4f66-b537-3df03bc5f2a0,DisenHCN: Disentangled Hypergraph Convolutional Networks for Spatiotemporal Activity Prediction,0.518827,"Spatiotemporal activity prediction, aiming to predict user activities at a
specific location and time, is crucial for applications like urban planning and
mobile advertising. Existing solutions based on tensor decomposition or graph
embedding suffer from the following two major limitations: 1) ignoring the
fine-grained similarities of user preferences; 2) user's modeling is entangled.
In this work, we propose a hypergraph neural network model called DisenHCN to
bridge the above gaps. In particular, we first unify the fine-grained user
similarity and the complex matching between user preferences and spatiotemporal
activity into a heterogeneous hypergraph. We then disentangle the user
representations into different aspects (location-aware, time-aware, and
activity-aware) and aggregate corresponding aspect's features on the
constructed hypergraph, capturing high-order relations from different aspects
and disentangles the impact of each aspect for final prediction. Extensive
experiments show that our DisenHCN outperforms the state-of-the-art methods by
14.23% to 18.10% on four real-world datasets. Further studies also convincingly
verify the rationality of each component in our DisenHCN.",None,-1
fc5c238f-4d15-4e53-9293-0edf1d1e2f8f,"To Softmax, or not to Softmax: that is the question when applying Active Learning for Transformer Models",0.31508,"Despite achieving state-of-the-art results in nearly all Natural Language
Processing applications, fine-tuning Transformer-based language models still
requires a significant amount of labeled data to work. A well known technique
to reduce the amount of human effort in acquiring a labeled dataset is
\textit{Active Learning} (AL): an iterative process in which only the minimal
amount of samples is labeled. AL strategies require access to a quantified
confidence measure of the model predictions. A common choice is the softmax
activation function for the final layer. As the softmax function provides
misleading probabilities, this paper compares eight alternatives on seven
datasets. Our almost paradoxical finding is that most of the methods are too
good at identifying the true most uncertain samples (outliers), and that
labeling therefore exclusively outliers results in worse performance. As a
heuristic we propose to systematically ignore samples, which results in
improvements of various methods compared to the softmax function.",https://github.com/jgonsior/btw-softmax-clipping,-1
cbad936b-914a-4aed-b01f-3f034a457785,Continuous Scene Representations for Embodied AI,0.861507,"We propose Continuous Scene Representations (CSR), a scene representation
constructed by an embodied agent navigating within a space, where objects and
their relationships are modeled by continuous valued embeddings. Our method
captures feature relationships between objects, composes them into a graph
structure on-the-fly, and situates an embodied agent within the representation.
Our key insight is to embed pair-wise relationships between objects in a latent
space. This allows for a richer representation compared to discrete relations
(e.g., [support], [next-to]) commonly used for building scene representations.
CSR can track objects as the agent moves in a scene, update the representation
accordingly, and detect changes in room configurations. Using CSR, we
outperform state-of-the-art approaches for the challenging downstream task of
visual room rearrangement, without any task specific training. Moreover, we
show the learned embeddings capture salient spatial details of the scene and
show applicability to real world data. A summery video and code is available at
https://prior.allenai.org/projects/csr.",https://github.com/facebookresearch/detectron2,-1
5794824d-9ab6-48a7-bb5d-0642d006facf,The 8-Point Algorithm as an Inductive Bias for Relative Pose Prediction by ViTs,0.873884,"We present a simple baseline for directly estimating the relative pose
(rotation and translation, including scale) between two images. Deep methods
have recently shown strong progress but often require complex or multi-stage
architectures. We show that a handful of modifications can be applied to a
Vision Transformer (ViT) to bring its computations close to the Eight-Point
Algorithm. This inductive bias enables a simple method to be competitive in
multiple settings, often substantially improving over the state of the art with
strong performance gains in limited data regimes.",https://github.com/rwightman/pytorch-image-models,-1
2bce53af-22d4-4cad-8df2-fcfeaabbab7e,Use of a smartphone camera to determine the focal length of a thin lens by finding the transverse magnification of the virtual image of an object,0.241674,"In this work we have determined the focal length of a concave lens by
photographing the virtual image of an object by a smartphone camera. We have
similarly determined the focal length of a convex lens by forming a virtual
image of an object keeping it within the focal distance from the lens. When a
photograph is taken by a smartphone, the transverse width of the image on the
sensor of the camera in pixels can be read off by software available freely
from the internet. By taking a photograph of the virtual image from two
positions of the camera separated by a distance along the line of sight of the
camera, we have determined the transverse width of the virtual image. From this
we find the focal lengths of the lenses knowing the transverse width and the
distance of the object from the lenses.",None,-1
469dd034-345f-4ea4-aedc-9b89b0361c02,GROOT: Corrective Reward Optimization for Generative Sequential Labeling,0.0703775,"Sequential labeling is a fundamental NLP task, forming the backbone of many
applications. Supervised learning of Seq2Seq models has shown great success on
these problems. However, the training objectives are still significantly
disconnected with the metrics and desiderata we care about in practice. For
example, a practical sequence tagging application may want to optimize for a
certain precision-recall trade-off (of the top-k predictions) which is quite
different from the standard objective of maximizing the likelihood of the gold
labeled sequence. Thus to bridge this gap, we propose GROOT -- a simple yet
effective framework for Generative Reward Optimization Of Text sequences. GROOT
works by training a generative sequential labeling model to match the decoder
output distribution with that of the (black-box) reward function. Using an
iterative training regime, we first generate prediction candidates, then
correct errors in them, and finally contrast those candidates (based on their
reward values). As demonstrated via extensive experiments on four public
benchmarks, GROOT significantly improves all reward metrics. Furthermore, GROOT
leads to improvements of the overall decoder distribution as evidenced by the
quality gains of the top-$k$ candidates.",https://github.com/google-research/t5x/blob/main/t5x/examples/t5/mt5/,-1
5477b618-abc5-4232-8cb9-b3f60aa8eb4f,Detector-Free Weakly Supervised Group Activity Recognition,0.814712,"Group activity recognition is the task of understanding the activity
conducted by a group of people as a whole in a multi-person video. Existing
models for this task are often impractical in that they demand ground-truth
bounding box labels of actors even in testing or rely on off-the-shelf object
detectors. Motivated by this, we propose a novel model for group activity
recognition that depends neither on bounding box labels nor on object detector.
Our model based on Transformer localizes and encodes partial contexts of a
group activity by leveraging the attention mechanism, and represents a video
clip as a set of partial context embeddings. The embedding vectors are then
aggregated to form a single group representation that reflects the entire
context of an activity while capturing temporal evolution of each partial
context. Our method achieves outstanding performance on two benchmarks,
Volleyball and NBA datasets, surpassing not only the state of the art trained
with the same level of supervision, but also some of existing models relying on
stronger supervision.",https://github.com/JacobYuan7/DIN_GAR,-1
48801d31-d6e4-4293-8c2e-bdbb05266e8e,Understanding the Domain Gap in LiDAR Object Detection Networks,0.049866,"In order to make autonomous driving a reality, artificial neural networks
have to work reliably in the open-world. However, the open-world is vast and
continuously changing, so it is not technically feasible to collect and
annotate training datasets which accurately represent this domain. Therefore,
there are always domain gaps between training datasets and the open-world which
must be understood. In this work, we investigate the domain gaps between
high-resolution and low-resolution LiDAR sensors in object detection networks.
Using a unique dataset, which enables us to study sensor resolution domain gaps
independent of other effects, we show two distinct domain gaps - an inference
domain gap and a training domain gap. The inference domain gap is characterised
by a strong dependence on the number of LiDAR points per object, while the
training gap shows no such dependence. These fndings show that different
approaches are required to close these inference and training domain gaps.",None,-1
0621e379-52b2-4c8c-9503-91ba1696a152,Far Away in the Deep Space: Dense Nearest-Neighbor-Based Out-of-Distribution Detection,0.0555147,"The key to out-of-distribution detection is density estimation of the
in-distribution data or of its feature representations. This is particularly
challenging for dense anomaly detection in domains where the in-distribution
data has a complex underlying structure. Nearest-Neighbors approaches have been
shown to work well in object-centric data domains, such as industrial
inspection and image classification. In this paper, we show that
nearest-neighbor approaches also yield state-of-the-art results on dense
novelty detection in complex driving scenes when working with an appropriate
feature representation. In particular, we find that transformer-based
architectures produce representations that yield much better similarity metrics
for the task. We identify the multi-head structure of these models as one of
the reasons, and demonstrate a way to transfer some of the improvements to
CNNs. Ultimately, the approach is simple and non-invasive, i.e., it does not
affect the primary segmentation performance, refrains from training on examples
of anomalies, and achieves state-of-the-art results on RoadAnomaly,
StreetHazards, and SegmentMeIfYouCan-Anomaly.",https://github.com/silviogalesso/dense-ood-knns,155608
0c7da365-cf5f-4753-8c3c-7c710d5c073c,On Improving Cross-dataset Generalization of Deepfake Detectors,0.478737,"Facial manipulation by deep fake has caused major security risks and raised
severe societal concerns. As a countermeasure, a number of deep fake detection
methods have been proposed recently. Most of them model deep fake detection as
a binary classification problem using a backbone convolutional neural network
(CNN) architecture pretrained for the task. These CNN-based methods have
demonstrated very high efficacy in deep fake detection with the Area under the
Curve (AUC) as high as 0.99. However, the performance of these methods degrades
significantly when evaluated across datasets. In this paper, we formulate deep
fake detection as a hybrid combination of supervised and reinforcement learning
(RL) to improve its cross-dataset generalization performance. The proposed
method chooses the top-k augmentations for each test sample by an RL agent in
an image-specific manner. The classification scores, obtained using CNN, of all
the augmentations of each test image are averaged together for final real or
fake classification. Through extensive experimental validation, we demonstrate
the superiority of our method over existing published research in cross-dataset
generalization of deep fake detectors, thus obtaining state-of-the-art
performance.",None,3040
bdcf963e-3f76-401f-9e47-d74b3dc3efce,Hyperbolic Vision Transformers: Combining Improvements in Metric Learning,0.819661,"Metric learning aims to learn a highly discriminative model encouraging the
embeddings of similar classes to be close in the chosen metrics and pushed
apart for dissimilar ones. The common recipe is to use an encoder to extract
embeddings and a distance-based loss function to match the representations --
usually, the Euclidean distance is utilized. An emerging interest in learning
hyperbolic data embeddings suggests that hyperbolic geometry can be beneficial
for natural data. Following this line of work, we propose a new
hyperbolic-based model for metric learning. At the core of our method is a
vision transformer with output embeddings mapped to hyperbolic space. These
embeddings are directly optimized using modified pairwise cross-entropy loss.
We evaluate the proposed model with six different formulations on four datasets
achieving the new state-of-the-art performance. The source code is available at
https://github.com/htdt/hyp_metric.",https://github.com/htdt/hyp_metric,-1
88eb2437-41a8-426e-840f-7d31d07b9e8e,All you need is feedback: Communication with block attention feedback codes,0.398667,"Deep learning based channel code designs have recently gained interest as an
alternative to conventional coding algorithms, particularly for channels for
which existing codes do not provide effective solutions. Communication over a
feedback channel is one such problem, for which promising results have recently
been obtained by employing various deep learning architectures. In this paper,
we introduce a novel learning-aided code design for feedback channels, called
generalized block attention feedback (GBAF) codes, which i) employs a modular
architecture that can be implemented using different neural network
architectures; ii) provides order-of-magnitude improvements in the probability
of error compared to existing designs; and iii) can transmit at desired code
rates.",None,-1
39e62539-3a47-4c8d-af80-f22d07055ff7,Learning Efficient Representations for Enhanced Object Detection on Large-scene SAR Images,0.0341252,"It is a challenging problem to detect and recognize targets on complex
large-scene Synthetic Aperture Radar (SAR) images. Recently developed deep
learning algorithms can automatically learn the intrinsic features of SAR
images, but still have much room for improvement on large-scene SAR images with
limited data. In this paper, based on learning representations and multi-scale
features of SAR images, we propose an efficient and robust deep learning based
target detection method. Especially, by leveraging the effectiveness of
adversarial autoencoder (AAE) which influences the distribution of the
investigated data explicitly, the raw SAR dataset is augmented into an enhanced
version with a large quantity and diversity. Besides, an auto-labeling scheme
is proposed to improve labeling efficiency. Finally, with jointly training
small target chips and large-scene images, an integrated YOLO network combining
non-maximum suppression on sub-images is used to realize multiple targets
detection of high resolution images. The numerical experimental results on the
MSTAR dataset show that our method can realize target detection and recognition
on large-scene images accurately and efficiently. The superior anti-noise
performance is also confirmed by experiments.",None,9295
a0cd8f1d-84d4-4af0-90cf-6e78b59468b8,Decoder Tuning: Efficient Language Understanding as Decoding,0.0832789,"With the evergrowing sizes of pre-trained models (PTMs), it has been an
emerging practice to only provide the inference APIs for users, namely
model-as-a-service (MaaS) setting. To adapt PTMs with model parameters frozen,
most current approaches focus on the input side, seeking for powerful prompts
to stimulate models for correct answers. However, we argue that input-side
adaptation could be arduous due to the lack of gradient signals and they
usually require thousands of API queries, resulting in high computation and
time costs. In light of this, we present Decoder Tuning (DecT), which in
contrast optimizes task-specific decoder networks on the output side.
Specifically, DecT first extracts prompt-stimulated output scores for initial
predictions. On top of that, we train an additional decoder network on the
output representations to incorporate posterior data knowledge. By
gradient-based optimization, DecT can be trained within several seconds and
requires only one PTM query per sample. Empirically, we conduct extensive
natural language understanding experiments and show that DecT significantly
outperforms state-of-the-art algorithms with a $200\times$ speed-up.",https://github.com/thunlp/DecT,-1
91535f71-835a-4a9a-a8e8-ae72772b9d8e,GERE: Generative Evidence Retrieval for Fact Verification,0.928613,"Fact verification (FV) is a challenging task which aims to verify a claim
using multiple evidential sentences from trustworthy corpora, e.g., Wikipedia.
Most existing approaches follow a three-step pipeline framework, including
document retrieval, sentence retrieval and claim verification. High-quality
evidences provided by the first two steps are the foundation of the effective
reasoning in the last step. Despite being important, high-quality evidences are
rarely studied by existing works for FV, which often adopt the off-the-shelf
models to retrieve relevant documents and sentences in an
""index-retrieve-then-rank"" fashion. This classical approach has clear drawbacks
as follows: i) a large document index as well as a complicated search process
is required, leading to considerable memory and computational overhead; ii)
independent scoring paradigms fail to capture the interactions among documents
and sentences in ranking; iii) a fixed number of sentences are selected to form
the final evidence set. In this work, we propose GERE, the first system that
retrieves evidences in a generative fashion, i.e., generating the document
titles as well as evidence sentence identifiers. This enables us to mitigate
the aforementioned technical issues since: i) the memory and computational cost
is greatly reduced because the document index is eliminated and the heavy
ranking process is replaced by a light generative process; ii) the dependency
between documents and that between sentences could be captured via sequential
generation process; iii) the generative formulation allows us to dynamically
select a precise set of relevant evidences for each claim. The experimental
results on the FEVER dataset show that GERE achieves significant improvements
over the state-of-the-art baselines, with both time-efficiency and
memory-efficiency.",https://github.com/Chriskuei/GERE,-1
6797656f-250a-4356-8ec1-cbd95003b08d,NERDA-Con: Extending NER models for Continual Learning -- Integrating Distinct Tasks and Updating Distribution Shifts,0.424776,"With increasing applications in areas such as biomedical information
extraction pipelines and social media analytics, Named Entity Recognition (NER)
has become an indispensable tool for knowledge extraction. However, with the
gradual shift in language structure and vocabulary, NERs are plagued with
distribution shifts, making them redundant or not as profitable without
re-training. Re-training NERs based on Large Language Models (LLMs) from
scratch over newly acquired data poses economic disadvantages. In contrast,
re-training only with newly acquired data will result in Catastrophic
Forgetting of previously acquired knowledge. Therefore, we propose NERDA-Con, a
pipeline for training NERs with LLM bases by incorporating the concept of
Elastic Weight Consolidation (EWC) into the NER fine-tuning NERDA pipeline. As
we believe our work has implications to be utilized in the pipeline of
continual learning and NER, we open-source our code as well as provide the
fine-tuning library of the same name NERDA-Con at
https://github.com/SupritiVijay/NERDA-Con and
https://pypi.org/project/NERDA-Con/.",https://github.com/SupritiVijay/NERDA-Con,-1
fdf44a88-103b-4556-b79d-efcb5e763038,ProSky: NEAT Meets NOMA-mmWave in the Sky of 6G,0.166027,"Rendering to their abilities to provide ubiquitous connectivity, flexibly and
cost effectively, unmanned aerial vehicles (UAVs) have been getting more and
more research attention. To take the UAVs' performance to the next level,
however, they need to be merged with some other technologies like
non-orthogonal multiple access (NOMA) and millimeter wave (mmWave), which both
promise high spectral efficiency (SE). As managing UAVs efficiently may not be
possible using model-based techniques, another key innovative technology that
UAVs will inevitably need to leverage is artificial intelligence (AI).
Designing an AI-based technique that adaptively allocates radio resources and
places UAVs in 3D space to meet certain communication objectives, however, is a
tough row to hoe. In this paper, we propose a neuroevolution of augmenting
topologies NEAT framework, referred to as ProSky, to manage NOMA-mmWave-UAV
networks. ProSky exhibits a remarkable performance improvement over a
model-based method. Moreover, ProSky learns 5.3 times faster than and
outperforms, in both SE and energy efficiency EE while being reasonably fair, a
deep reinforcement learning DRL based scheme. The ProSky source code is
accessible to use here: https://github.com/Fouzibenfaid/ProSky",https://github.com/Fouzibenfaid/ProSky,-1
9e718c6a-bcf3-4960-9106-758b59af238f,Coordinating CAV Swarms at Intersections with a Deep Learning Model,0.449175,"Connected and automated vehicles (CAVs) are viewed as a special kind of
robots that have the potential to significantly improve the safety and
efficiency of traffic. In contrast to many swarm robotics studies that are
demonstrated in labs by employing a small number of robots, CAV studies aims to
achieve cooperative driving of unceasing robot swarm flows. However, how to get
the optimal passing order of such robot swarm flows even for a signal-free
intersection is an NP-hard problem (specifically, enumerating based algorithm
takes days to find the optimal solution to a 20-CAV scenario). Here, we
introduce a novel cooperative driving algorithm (AlphaOrder) that combines
offline deep learning and online tree searching to find a near-optimal passing
order in real-time. AlphaOrder builds a pointer network model from solved
scenarios and generates near-optimal passing orders instantaneously for new
scenarios. Furthermore, our approach provides a general approach to managing
preemptive resource sharing between swarm robotics (e.g., scheduling multiple
automated guided vehicles (AGVs) and unmanned aerial vehicles (UAVs) at
conflicting areas",None,-1
01039c3a-8003-4619-9079-f55622a3c7c7,Calibration Meets Explanation: A Simple and Effective Approach for Model Confidence Estimates,0.32746,"Calibration strengthens the trustworthiness of black-box models by producing
better accurate confidence estimates on given examples. However, little is
known about if model explanations can help confidence calibration. Intuitively,
humans look at important features attributions and decide whether the model is
trustworthy. Similarly, the explanations can tell us when the model may or may
not know. Inspired by this, we propose a method named CME that leverages model
explanations to make the model less confident with non-inductive attributions.
The idea is that when the model is not highly confident, it is difficult to
identify strong indications of any class, and the tokens accordingly do not
have high attribution scores for any class and vice versa. We conduct extensive
experiments on six datasets with two popular pre-trained language models in the
in-domain and out-of-domain settings. The results show that CME improves
calibration performance in all settings. The expected calibration errors are
further reduced when combined with temperature scaling. Our findings highlight
that model explanations can help calibrate posterior estimates.",https://github.com/crazyofapple/CME-EMNLP2022/,-1
12690778-e838-4891-93f0-ebc6e3a79489,Analyzing Wrap-Up Effects through an Information-Theoretic Lens,0.679312,"Numerous analyses of reading time (RT) data have been implemented -- all in
an effort to better understand the cognitive processes driving reading
comprehension. However, data measured on words at the end of a sentence -- or
even at the end of a clause -- is often omitted due to the confounding factors
introduced by so-called ""wrap-up effects,"" which manifests as a skewed
distribution of RTs for these words. Consequently, the understanding of the
cognitive processes that might be involved in these wrap-up effects is limited.
In this work, we attempt to learn more about these processes by examining the
relationship between wrap-up effects and information-theoretic quantities, such
as word and context surprisals. We find that the distribution of information in
prior contexts is often predictive of sentence- and clause-final RTs (while not
of sentence-medial RTs). This lends support to several prior hypotheses about
the processes involved in wrap-up effects.",https://github.com/rycolab/wrap-up-effects,-1
ba0d61da-2aa0-46df-ac41-1d98acbfff58,Are disentangled representations all you need to build speaker anonymization systems?,0.615406,"Speech signals contain a lot of sensitive information, such as the speaker's
identity, which raises privacy concerns when speech data get collected. Speaker
anonymization aims to transform a speech signal to remove the source speaker's
identity while leaving the spoken content unchanged. Current methods perform
the transformation by relying on content/speaker disentanglement and voice
conversion. Usually, an acoustic model from an automatic speech recognition
system extracts the content representation while an x-vector system extracts
the speaker representation. Prior work has shown that the extracted features
are not perfectly disentangled. This paper tackles how to improve features
disentanglement, and thus the converted anonymized speech. We propose enhancing
the disentanglement by removing speaker information from the acoustic model
using vector quantization. Evaluation done using the VoicePrivacy 2022 toolkit
showed that vector quantization helps conceal the original speaker identity
while maintaining utility for speech recognition.",https://colab.research.google.com/github/deep-privacy/SA-toolkit/blob/master/SA-colab.ipynb,-1
2193f18e-f940-49be-97ec-c79f46cd9269,Read Top News First: A Document Reordering Approach for Multi-Document News Summarization,0.456774,"A common method for extractive multi-document news summarization is to
re-formulate it as a single-document summarization problem by concatenating all
documents as a single meta-document. However, this method neglects the relative
importance of documents. We propose a simple approach to reorder the documents
according to their relative importance before concatenating and summarizing
them. The reordering makes the salient content easier to learn by the
summarization model. Experiments show that our approach outperforms previous
state-of-the-art methods with more complex architectures.",https://github.com/zhaochaocs/MDS-DR,30354
4f3c1a69-74bc-4de3-ad4b-a7cfd9e0b31e,Multi scale Feature Extraction and Fusion for Online Knowledge Distillation,0.17769,"Online knowledge distillation conducts knowledge transfer among all student
models to alleviate the reliance on pre-trained models. However, existing
online methods rely heavily on the prediction distributions and neglect the
further exploration of the representational knowledge. In this paper, we
propose a novel Multi-scale Feature Extraction and Fusion method (MFEF) for
online knowledge distillation, which comprises three key components:
Multi-scale Feature Extraction, Dual-attention and Feature Fusion, towards
generating more informative feature maps for distillation. The multiscale
feature extraction exploiting divide-and-concatenate in channel dimension is
proposed to improve the multi-scale representation ability of feature maps. To
obtain more accurate information, we design a dual-attention to strengthen the
important channel and spatial regions adaptively. Moreover, we aggregate and
fuse the former processed feature maps via feature fusion to assist the
training of student models. Extensive experiments on CIF AR-10, CIF AR-100, and
CINIC-10 show that MFEF transfers more beneficial representational knowledge
for distillation and outperforms alternative methods among various network
architectures",None,-1
7d40a347-4adf-41e3-be6b-e68c301c78f2,MABEL: Attenuating Gender Bias using Textual Entailment Data,0.651926,"Pre-trained language models encode undesirable social biases, which are
further exacerbated in downstream use. To this end, we propose MABEL (a Method
for Attenuating Gender Bias using Entailment Labels), an intermediate
pre-training approach for mitigating gender bias in contextualized
representations. Key to our approach is the use of a contrastive learning
objective on counterfactually augmented, gender-balanced entailment pairs from
natural language inference (NLI) datasets. We also introduce an alignment
regularizer that pulls identical entailment pairs along opposite gender
directions closer. We extensively evaluate our approach on intrinsic and
extrinsic metrics, and show that MABEL outperforms previous task-agnostic
debiasing approaches in terms of fairness. It also preserves task performance
after fine-tuning on downstream tasks. Together, these findings demonstrate the
suitability of NLI data as an effective means of bias mitigation, as opposed to
only using unlabeled sentences in the literature. Finally, we identify that
existing approaches often use evaluation settings that are insufficient or
inconsistent. We make an effort to reproduce and compare previous methods, and
call for unifying the evaluation settings across gender debiasing methods for
better future comparison.",https://github.com/princeton-nlp/MABEL,-1
d0c2a34f-eba0-4d77-9dc9-81f1f485f108,IDEA-Net: Dynamic 3D Point Cloud Interpolation via Deep Embedding Alignment,0.362645,"This paper investigates the problem of temporally interpolating dynamic 3D
point clouds with large non-rigid deformation. We formulate the problem as
estimation of point-wise trajectories (i.e., smooth curves) and further reason
that temporal irregularity and under-sampling are two major challenges. To
tackle the challenges, we propose IDEA-Net, an end-to-end deep learning
framework, which disentangles the problem under the assistance of the
explicitly learned temporal consistency. Specifically, we propose a temporal
consistency learning module to align two consecutive point cloud frames
point-wisely, based on which we can employ linear interpolation to obtain
coarse trajectories/in-between frames. To compensate the high-order nonlinear
components of trajectories, we apply aligned feature embeddings that encode
local geometry properties to regress point-wise increments, which are combined
with the coarse estimations. We demonstrate the effectiveness of our method on
various point cloud sequences and observe large improvement over
state-of-the-art methods both quantitatively and visually. Our framework can
bring benefits to 3D motion data acquisition. The source code is publicly
available at https://github.com/ZENGYIMING-EAMON/IDEA-Net.git.",https://github.com/ZENGYIMING-EAMON/IDEA-Net.git,-1
735b4e3b-eba9-40b2-9917-f8866a69eee9,Target-aware Molecular Graph Generation,0.680885,"Generating molecules with desired biological activities has attracted growing
attention in drug discovery. Previous molecular generation models are designed
as chemocentric methods that hardly consider the drug-target interaction,
limiting their practical applications. In this paper, we aim to generate
molecular drugs in a target-aware manner that bridges biological activity and
molecular design. To solve this problem, we compile a benchmark dataset from
several publicly available datasets and build baselines in a unified framework.
Building on the recent advantages of flow-based molecular generation models, we
propose SiamFlow, which forces the flow to fit the distribution of target
sequence embeddings in latent space. Specifically, we employ an alignment loss
and a uniform loss to bring target sequence embeddings and drug graph
embeddings into agreements while avoiding collapse. Furthermore, we formulate
the alignment into a one-to-many problem by learning spaces of target sequence
embeddings. Experiments quantitatively show that our proposed method learns
meaningful representations in the latent space toward the target-aware
molecular graph generation and provides an alternative approach to bridge
biology and chemistry in drug discovery.",None,-1
6dbda123-abbf-4e26-8208-2df98a184b18,SVG Vector Font Generation for Chinese Characters with Transformer,0.615773,"Designing fonts for Chinese characters is highly labor-intensive and
time-consuming. While the latest methods successfully generate the English
alphabet vector font, despite the high demand for automatic font generation,
Chinese vector font generation has been an unsolved problem owing to its
complex shape and numerous characters. This study addressed the problem of
automatically generating Chinese vector fonts from only a single style and
content reference. We proposed a novel network architecture with Transformer
and loss functions to capture structural features without differentiable
rendering. Although the dataset range was still limited to the sans-serif
family, we successfully generated the Chinese vector font for the first time
using the proposed method.",None,-1
4458f859-7793-4ed6-83a5-6b16b4662c84,PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search,0.414396,"While contextualized word embeddings have been a de-facto standard, learning
contextualized phrase embeddings is less explored and being hindered by the
lack of a human-annotated benchmark that tests machine understanding of phrase
semantics given a context sentence or paragraph (instead of phrases alone). To
fill this gap, we propose PiC -- a dataset of ~28K of noun phrases accompanied
by their contextual Wikipedia pages and a suite of three tasks for training and
evaluating phrase embeddings. Training on PiC improves ranking models' accuracy
and remarkably pushes span-selection (SS) models (i.e., predicting the start
and end index of the target phrase) near-human accuracy, which is 95% Exact
Match (EM) on semantic search given a query phrase and a passage.
Interestingly, we find evidence that such impressive performance is because the
SS models learn to better capture the common meaning of a phrase regardless of
its actual context. SotA models perform poorly in distinguishing two senses of
the same phrase in two contexts (~60% EM) and in estimating the similarity
between two different phrases in the same context (~70% EM).",https://phrase-in-context.github.io,-1
9ae7f0a0-039c-4acf-91db-49cca2baaef8,MCoNaLa: A Benchmark for Code Generation from Multiple Natural Languages,0.568546,"While there has been a recent burgeoning of applications at the intersection
of natural and programming languages, such as code generation and code
summarization, these applications are usually English-centric. This creates a
barrier for program developers who are not proficient in English. To mitigate
this gap in technology development across languages, we propose a multilingual
dataset, MCoNaLa, to benchmark code generation from natural language commands
extending beyond English. Modeled off of the methodology from the English
Code/Natural Language Challenge (CoNaLa) dataset, we annotated a total of 896
NL-code pairs in three languages: Spanish, Japanese, and Russian. We present a
quantitative evaluation of performance on the MCoNaLa dataset by testing with
state-of-the-art code generation systems. While the difficulties vary across
these three languages, all systems lag significantly behind their English
counterparts, revealing the challenges in adapting code generation to new
languages.",https://github.com/zorazrw/multilingual-conala,-1
c08c74ad-aeab-4d59-adb9-02bc8ada192e,Bayes risk CTC: Controllable CTC alignment in Sequence-to-Sequence tasks,0.793711,"Sequence-to-Sequence (seq2seq) tasks transcribe the input sequence to a
target sequence. The Connectionist Temporal Classification (CTC) criterion is
widely used in multiple seq2seq tasks. Besides predicting the target sequence,
a side product of CTC is to predict the alignment, which is the most probable
input-long sequence that specifies a hard aligning relationship between the
input and target units. As there are multiple potential aligning sequences
(called paths) that are equally considered in CTC formulation, the choice of
which path will be most probable and become the predicted alignment is always
uncertain. In addition, it is usually observed that the alignment predicted by
vanilla CTC will drift compared with its reference and rarely provides
practical functionalities. Thus, the motivation of this work is to make the CTC
alignment prediction controllable and thus equip CTC with extra
functionalities. The Bayes risk CTC (BRCTC) criterion is then proposed in this
work, in which a customizable Bayes risk function is adopted to enforce the
desired characteristics of the predicted alignment. With the risk function, the
BRCTC is a general framework to adopt some customizable preference over the
paths in order to concentrate the posterior into a particular subset of the
paths. In applications, we explore one particular preference which yields
models with the down-sampling ability and reduced inference costs. By using
BRCTC with another preference for early emissions, we obtain an improved
performance-latency trade-off for online models. Experimentally, the proposed
BRCTC reduces the inference cost of offline models by up to 47% without
performance degradation and cuts down the overall latency of online systems to
an unseen level.",https://github.com/k2-fsa/k2,-1
a293726f-ea27-4775-a8fc-c44be8592ec4,Improving the Factual Correctness of Radiology Report Generation with Semantic Rewards,0.982963,"Neural image-to-text radiology report generation systems offer the potential
to improve radiology reporting by reducing the repetitive process of report
drafting and identifying possible medical errors. These systems have achieved
promising performance as measured by widely used NLG metrics such as BLEU and
CIDEr. However, the current systems face important limitations. First, they
present an increased complexity in architecture that offers only marginal
improvements on NLG metrics. Secondly, these systems that achieve high
performance on these metrics are not always factually complete or consistent
due to both inadequate training and evaluation. Recent studies have shown the
systems can be substantially improved by using new methods encouraging 1) the
generation of domain entities consistent with the reference and 2) describing
these entities in inferentially consistent ways. So far, these methods rely on
weakly-supervised approaches (rule-based) and named entity recognition systems
that are not specific to the chest X-ray domain. To overcome this limitation,
we propose a new method, the RadGraph reward, to further improve the factual
completeness and correctness of generated radiology reports. More precisely, we
leverage the RadGraph dataset containing annotated chest X-ray reports with
entities and relations between entities. On two open radiology report datasets,
our system substantially improves the scores up to 14.2% and 25.3% on metrics
evaluating the factual correctness and completeness of reports.",https://github.com/jbdel/vilmedic,-1
2ba62675-df7c-4b98-b3f5-a3c8c784871d,Do Bayesian Neural Networks Need To Be Fully Stochastic?,0.811019,"We investigate the benefit of treating all the parameters in a Bayesian
neural network stochastically and find compelling theoretical and empirical
evidence that this standard construction may be unnecessary. To this end, we
prove that expressive predictive distributions require only small amounts of
stochasticity. In particular, partially stochastic networks with only $n$
stochastic biases are universal probabilistic predictors for $n$-dimensional
predictive problems. In empirical investigations, we find no systematic benefit
of full stochasticity across four different inference modalities and eight
datasets; partially stochastic networks can match and sometimes even outperform
fully stochastic networks, despite their reduced memory costs.",https://github.com/IntelLabs/bayesian-torch,2733
2ab0ab90-8cd0-4dc5-9c86-bb5a6325fc50,Generative Adversarial Super-Resolution at the Edge with Knowledge Distillation,0.501909,"Single-Image Super-Resolution can support robotic tasks in environments where
a reliable visual stream is required to monitor the mission, handle
teleoperation or study relevant visual details. In this work, we propose an
efficient Generative Adversarial Network model for real-time Super-Resolution,
called EdgeSRGAN (code available at https://github.com/PIC4SeR/EdgeSRGAN). We
adopt a tailored architecture of the original SRGAN and model quantization to
boost the execution on CPU and Edge TPU devices, achieving up to 200 fps
inference. We further optimize our model by distilling its knowledge to a
smaller version of the network and obtain remarkable improvements compared to
the standard training approach. Our experiments show that our fast and
lightweight model preserves considerably satisfying image quality compared to
heavier state-of-the-art models. Finally, we conduct experiments on image
transmission with bandwidth degradation to highlight the advantages of the
proposed system for mobile robotic applications.",https://github.com/PIC4SeR/EdgeSRGAN,-1
1c3813cc-2f7c-449a-9eb6-ada2cce63fd2,Task Phasing: Automated Curriculum Learning from Demonstrations,0.130418,"Applying reinforcement learning (RL) to sparse reward domains is notoriously
challenging due to insufficient guiding signals. Common RL techniques for
addressing such domains include (1) learning from demonstrations and (2)
curriculum learning. While these two approaches have been studied in detail,
they have rarely been considered together. This paper aims to do so by
introducing a principled task phasing approach that uses demonstrations to
automatically generate a curriculum sequence. Using inverse RL from
(suboptimal) demonstrations we define a simple initial task. Our task phasing
approach then provides a framework to gradually increase the complexity of the
task all the way to the target task, while retuning the RL agent in each
phasing iteration. Two approaches for phasing are considered: (1) gradually
increasing the proportion of time steps an RL agent is in control, and (2)
phasing out a guiding informative reward function. We present conditions that
guarantee the convergence of these approaches to an optimal policy.
Experimental results on 3 sparse reward domains demonstrate that our task
phasing approaches outperform state-of-the-art approaches with respect to
asymptotic performance.",https://github.com/ParanoidAndroid96/Task-Phasing.git,-1
86a9b69d-7173-4dfb-a406-fdf3094d9ec8,"Vision-Language Pre-training: Basics, Recent Advances, and Future Trends",0.90895,"This paper surveys vision-language pre-training (VLP) methods for multimodal
intelligence that have been developed in the last few years. We group these
approaches into three categories: ($i$) VLP for image-text tasks, such as image
captioning, image-text retrieval, visual question answering, and visual
grounding; ($ii$) VLP for core computer vision tasks, such as (open-set) image
classification, object detection, and segmentation; and ($iii$) VLP for
video-text tasks, such as video captioning, video-text retrieval, and video
question answering. For each category, we present a comprehensive review of
state-of-the-art methods, and discuss the progress that has been made and
challenges still being faced, using specific systems and models as case
studies. In addition, for each category, we discuss advanced topics being
actively explored in the research community, such as big foundation models,
unified modeling, in-context few-shot learning, knowledge, robustness, and
computer vision in the wild, to name a few.",None,-1
88fa2781-486d-42f6-a489-f0fd0f584675,Learning to Detect Good Keypoints to Match Non-Rigid Objects in RGB Images,0.054485,"We present a novel learned keypoint detection method designed to maximize the
number of correct matches for the task of non-rigid image correspondence. Our
training framework uses true correspondences, obtained by matching annotated
image pairs with a predefined descriptor extractor, as a ground-truth to train
a convolutional neural network (CNN). We optimize the model architecture by
applying known geometric transformations to images as the supervisory signal.
Experiments show that our method outperforms the state-of-the-art keypoint
detector on real images of non-rigid objects by 20 p.p. on Mean Matching
Accuracy and also improves the matching performance of several descriptors when
coupled with our detection method. We also employ the proposed method in one
challenging realworld application: object retrieval, where our detector
exhibits performance on par with the best available keypoint detectors. The
source code and trained model are publicly available at
https://github.com/verlab/LearningToDetect SIBGRAPI 2022",https://github.com/verlab/LearningToDetect,-1
a8a2136f-9877-490c-8acd-9a39e04e90a6,STEdge: Self-training Edge Detection with Multi-layer Teaching and Regularization,0.163589,"Learning-based edge detection has hereunto been strongly supervised with
pixel-wise annotations which are tedious to obtain manually. We study the
problem of self-training edge detection, leveraging the untapped wealth of
large-scale unlabeled image datasets. We design a self-supervised framework
with multi-layer regularization and self-teaching. In particular, we impose a
consistency regularization which enforces the outputs from each of the multiple
layers to be consistent for the input image and its perturbed counterpart. We
adopt L0-smoothing as the 'perturbation' to encourage edge prediction lying on
salient boundaries following the cluster assumption in self-supervised
learning. Meanwhile, the network is trained with multi-layer supervision by
pseudo labels which are initialized with Canny edges and then iteratively
refined by the network as the training proceeds. The regularization and
self-teaching together attain a good balance of precision and recall, leading
to a significant performance boost over supervised methods, with lightweight
refinement on the target dataset. Furthermore, our method demonstrates strong
cross-dataset generality. For example, it attains 4.8% improvement for ODS and
5.8% for OIS when tested on the unseen BIPED dataset, compared to the
state-of-the-art methods.",None,-1
513976e1-26b8-4335-bf8c-a1ec323bd6f5,Transcending Scaling Laws with 0.1% Extra Compute,0.508321,"Scaling language models improves performance but comes with significant
computational costs. This paper proposes UL2R, a method that substantially
improves existing language models and their scaling curves with a relatively
tiny amount of extra compute. The key idea is to continue training a
state-of-the-art large language model (e.g., PaLM) on a few more steps with
UL2's mixture-of-denoiser objective. We show that, with almost negligible extra
computational costs and no new sources of data, we are able to substantially
improve the scaling properties of large language models on downstream metrics.
In this paper, we continue training PaLM with UL2R, introducing a new set of
models at 8B, 62B, and 540B scale which we call U-PaLM. Impressively, at 540B
scale, we show an approximately 2x computational savings rate where U-PaLM
achieves the same performance as the final PaLM 540B model at around half its
computational budget (i.e., saving $\sim$4.4 million TPUv4 hours). We further
show that this improved scaling curve leads to 'emergent abilities' on
challenging BIG-Bench tasks -- for instance, U-PaLM does much better than PaLM
on some tasks or demonstrates better quality at much smaller scale (62B as
opposed to 540B). Overall, we show that U-PaLM outperforms PaLM on many
few-shot setups, i.e., English NLP tasks (e.g., commonsense reasoning, question
answering), reasoning tasks with chain-of-thought (e.g., GSM8K), multilingual
tasks (MGSM, TydiQA), MMLU and challenging BIG-Bench tasks. Finally, we provide
qualitative examples showing the new capabilities of U-PaLM for single and
multi-span infilling.",None,-1
1683067c-f3b7-4124-b2ef-3a51c187ce99,AugESC: Dialogue Augmentation with Large Language Models for Emotional Support Conversation,0.404982,"Crowdsourced dialogue corpora are usually limited in scale and topic coverage
due to the expensive cost of data curation. This would hinder the
generalization of downstream dialogue models to open-domain topics. In this
work, we leverage large language models for dialogue augmentation in the task
of emotional support conversation (ESC). By treating dialogue augmentation as a
dialogue completion task, we prompt a fine-tuned language model to complete
full dialogues from available dialogue posts of various topics, which are then
postprocessed based on heuristics. Applying this approach, we construct AugESC,
an augmented dataset for the ESC task, which largely extends the scale and
topic coverage of the crowdsourced ESConv corpus. Through comprehensive human
evaluation, we demonstrate that our approach is superior to strong baselines of
dialogue augmentation and that AugESC has comparable dialogue quality to the
crowdsourced corpus. We also conduct human interactive evaluation and prove
that post-training on AugESC improves downstream dialogue models'
generalization ability to open-domain topics. These results suggest the utility
of AugESC and highlight the potential of large language models in improving
data-scarce dialogue generation tasks.",https://github.com/thu-coai/AugESC,39147
4d3a412c-c40e-4646-b20e-730aa2741e7c,Unleashing the Power of Transformer for Graphs,0.0873068,"Despite recent successes in natural language processing and computer vision,
Transformer suffers from the scalability problem when dealing with graphs. The
computational complexity is unacceptable for large-scale graphs, e.g.,
knowledge graphs. One solution is to consider only the near neighbors, which,
however, will lose the key merit of Transformer to attend to the elements at
any distance. In this paper, we propose a new Transformer architecture, named
dual-encoding Transformer (DET). DET has a structural encoder to aggregate
information from connected neighbors and a semantic encoder to focus on
semantically useful distant nodes. In comparison with resorting to multi-hop
neighbors, DET seeks the desired distant neighbors via self-supervised
training. We further find these two encoders can be incorporated to boost each
others' performance. Our experiments demonstrate DET has achieved superior
performance compared to the respective state-of-the-art methods in dealing with
molecules, networks and knowledge graphs with various sizes.",None,-1
fe54dbe4-78bf-4b9c-a9e8-0de8c6b7aca0,"Gathering Strength, Gathering Storms: The One Hundred Year Study on Artificial Intelligence (AI100) 2021 Study Panel Report",0.971254,"In September 2021, the ""One Hundred Year Study on Artificial Intelligence""
project (AI100) issued the second report of its planned long-term periodic
assessment of artificial intelligence (AI) and its impact on society. It was
written by a panel of 17 study authors, each of whom is deeply rooted in AI
research, chaired by Michael Littman of Brown University. The report, entitled
""Gathering Strength, Gathering Storms,"" answers a set of 14 questions probing
critical areas of AI development addressing the major risks and dangers of AI,
its effects on society, its public perception and the future of the field. The
report concludes that AI has made a major leap from the lab to people's lives
in recent years, which increases the urgency to understand its potential
negative effects. The questions were developed by the AI100 Standing Committee,
chaired by Peter Stone of the University of Texas at Austin, consisting of a
group of AI leaders with expertise in computer science, sociology, ethics,
economics, and other disciplines.",None,-1
d768c5c8-54af-425a-9b8d-e36da3171924,Semantic properties of English nominal pluralization: Insights from word embeddings,0.718231,"Semantic differentiation of nominal pluralization is grammaticalized in many
languages. For example, plural markers may only be relevant for human nouns.
English does not appear to make such distinctions. Using distributional
semantics, we show that English nominal pluralization exhibits semantic
clusters. For instance, pluralization of fruit words is more similar to one
another and less similar to pluralization of other semantic classes. Therefore,
reduction of the meaning shift in plural formation to the addition of an
abstract plural meaning is too simplistic. A semantically informed method,
called CosClassAvg, is introduced that outperforms pluralization methods in
distributional semantics which assume plural formation amounts to the addition
of a fixed plural vector. In comparison with our approach, a method from
compositional distributional semantics, called FRACSS, predicted plural vectors
that were more similar to the corpus-extracted plural vectors in terms of
direction but not vector length. A modeling study reveals that the observed
difference between the two predicted semantic spaces by CosClassAvg and FRACSS
carries over to how well a computational model of the listener can understand
previously unencountered plural forms. Mappings from word forms, represented
with triphone vectors, to predicted semantic vectors are more productive when
CosClassAvg-generated semantic vectors are employed as gold standard vectors
instead of FRACSS-generated vectors.",None,-1
ccb23d0b-a386-4d36-b691-a8e62ebd4102,Is the Elephant Flying? Resolving Ambiguities in Text-to-Image Generative Models,0.102053,"Natural language often contains ambiguities that can lead to
misinterpretation and miscommunication. While humans can handle ambiguities
effectively by asking clarifying questions and/or relying on contextual cues
and common-sense knowledge, resolving ambiguities can be notoriously hard for
machines. In this work, we study ambiguities that arise in text-to-image
generative models. We curate a benchmark dataset covering different types of
ambiguities that occur in these systems. We then propose a framework to
mitigate ambiguities in the prompts given to the systems by soliciting
clarifications from the user. Through automatic and human evaluations, we show
the effectiveness of our framework in generating more faithful images aligned
with human intention in the presence of ambiguities.",None,-1
cc1739ae-b485-415d-b9c8-b44b0dccd46b,PTSEFormer: Progressive Temporal-Spatial Enhanced TransFormer Towards Video Object Detection,0.796125,"Recent years have witnessed a trend of applying context frames to boost the
performance of object detection as video object detection. Existing methods
usually aggregate features at one stroke to enhance the feature. These methods,
however, usually lack spatial information from neighboring frames and suffer
from insufficient feature aggregation. To address the issues, we perform a
progressive way to introduce both temporal information and spatial information
for an integrated enhancement. The temporal information is introduced by the
temporal feature aggregation model (TFAM), by conducting an attention mechanism
between the context frames and the target frame (i.e., the frame to be
detected). Meanwhile, we employ a Spatial Transition Awareness Model (STAM) to
convey the location transition information between each context frame and
target frame. Built upon a transformer-based detector DETR, our PTSEFormer also
follows an end-to-end fashion to avoid heavy post-processing procedures while
achieving 88.1% mAP on the ImageNet VID dataset. Codes are available at
https://github.com/Hon-Wong/PTSEFormer.",https://github.com/Hon-Wong/PTSEFormer,-1
e86f3640-a36c-4f28-beff-43872ed8e7d5,CNTN: Cyclic Noise-tolerant Network for Gait Recognition,0.203255,"Gait recognition aims to identify individuals by recognizing their walking
patterns. However, an observation is made that most of the previous gait
recognition methods degenerate significantly due to two memorization effects,
namely appearance memorization and label noise memorization. To address the
problem, for the first time noisy gait recognition is studied, and a cyclic
noise-tolerant network (CNTN) is proposed with a cyclic training algorithm,
which equips the two parallel networks with explicitly different abilities,
namely one forgetting network and one memorizing network. The overall model
will not memorize the pattern unless the two different networks both memorize
it. Further, a more refined co-teaching constraint is imposed to help the model
learn intrinsic patterns which are less influenced by memorization. Also, to
address label noise memorization, an adaptive noise detection module is
proposed to rule out the samples with high possibility to be noisy from
updating the model. Experiments are conducted on the three most popular
benchmarks and CNTN achieves state-of-the-art performances. We also reconstruct
two noisy gait recognition datasets, and CNTN gains significant improvements
(especially 6% improvements on CL setting). CNTN is also compatible with any
off-the-shelf backbones and improves them consistently.",https://github.com/ShiqiYu/OpenGait.git,-1
90f9dfbc-5f75-4635-9307-d0e96cd5ab1e,The Topological BERT: Transforming Attention into Topology for Natural Language Processing,0.775584,"In recent years, the introduction of the Transformer models sparked a
revolution in natural language processing (NLP). BERT was one of the first text
encoders using only the attention mechanism without any recurrent parts to
achieve state-of-the-art results on many NLP tasks.
  This paper introduces a text classifier using topological data analysis. We
use BERT's attention maps transformed into attention graphs as the only input
to that classifier. The model can solve tasks such as distinguishing spam from
ham messages, recognizing whether a sentence is grammatically correct, or
evaluating a movie review as negative or positive. It performs comparably to
the BERT baseline and outperforms it on some tasks.
  Additionally, we propose a new method to reduce the number of BERT's
attention heads considered by the topological classifier, which allows us to
prune the number of heads from 144 down to as few as ten with no reduction in
performance. Our work also shows that the topological model displays higher
robustness against adversarial attacks than the original BERT model, which is
maintained during the pruning process. To the best of our knowledge, this work
is the first to confront topological-based models with adversarial attacks in
the context of NLP.",None,-1
262b0008-3186-46a2-aa57-1f29e34124ff,RigoBERTa: A State-of-the-Art Language Model For Spanish,0.050971,"This paper presents RigoBERTa, a State-of-the-Art Language Model for Spanish.
RigoBERTa is trained over a well-curated corpus formed up from different
subcorpora with key features. It follows the DeBERTa architecture, which has
several advantages over other architectures of similar size as BERT or RoBERTa.
RigoBERTa performance is assessed over 13 NLU tasks in comparison with other
available Spanish language models, namely, MarIA, BERTIN and BETO. RigoBERTa
outperformed the three models in 10 out of the 13 tasks, achieving new
""State-of-the-Art"" results.",None,-1
91a3a04a-ae6c-429a-8187-720ccc99bb1a,Unified Speech-Text Pre-training for Speech Translation and Recognition,0.867796,"We describe a method to jointly pre-train speech and text in an
encoder-decoder modeling framework for speech translation and recognition. The
proposed method incorporates four self-supervised and supervised subtasks for
cross modality learning. A self-supervised speech subtask leverages unlabelled
speech data, and a (self-)supervised text to text subtask makes use of abundant
text training data. Two auxiliary supervised speech tasks are included to unify
speech and text modeling space. Our contribution lies in integrating linguistic
information from the text corpus into the speech pre-training. Detailed
analysis reveals learning interference among subtasks. Two pre-training
configurations for speech translation and recognition, respectively, are
presented to alleviate subtask interference. Our experiments show the proposed
method can effectively fuse speech and text information into one model. It
achieves between 1.7 and 2.3 BLEU improvement above the state of the art on the
MuST-C speech translation dataset and comparable WERs to wav2vec 2.0 on the
Librispeech speech recognition task.",https://github.com/pytorch/fairseq/tree/main/examples/speech_text_joint_to_text,-1
01fd442a-a12e-4c23-ad2a-88af47ae53cf,Project proposal: A modular reinforcement learning based automated theorem prover,0.0317988,"We propose to build a reinforcement learning prover of independent
components: a deductive system (an environment), the proof state representation
(how an agent sees the environment), and an agent training algorithm. To that
purpose, we contribute an additional Vampire-based environment to
$\texttt{gym-saturation}$ package of OpenAI Gym environments for saturation
provers. We demonstrate a prototype of using $\texttt{gym-saturation}$ together
with a popular reinforcement learning framework (Ray $\texttt{RLlib}$).
Finally, we discuss our plans for completing this work in progress to a
competitive automated theorem prover.",https://github.com/inpefess/basic-rl-prover,-1
a0a6949d-aa9d-4142-be28-dc7e15468bc8,Worldwide city transport typology prediction with sentence-BERT based supervised learning via Wikipedia,0.649246,"An overwhelming majority of the world's human population lives in urban areas
and cities. Understanding a city's transportation typology is immensely
valuable for planners and policy makers whose decisions can potentially impact
millions of city residents. Despite the value of understanding a city's
typology, labeled data (city and it's typology) is scarce, and spans at most a
few hundred cities in the current transportation literature. To break this
barrier, we propose a supervised machine learning approach to predict a city's
typology given the information in its Wikipedia page. Our method leverages
recent breakthroughs in natural language processing, namely sentence-BERT, and
shows how the text-based information from Wikipedia can be effectively used as
a data source for city typology prediction tasks that can be applied to over
2000 cities worldwide. We propose a novel method for low-dimensional city
representation using a city's Wikipedia page, which makes supervised learning
of city typology labels tractable even with a few hundred labeled samples.
These features are used with labeled city samples to train binary classifiers
(logistic regression) for four different city typologies: (i) congestion, (ii)
auto-heavy, (iii) transit-heavy, and (iv) bike-friendly cities resulting in
reasonably high AUC scores of 0.87, 0.86, 0.61 and 0.94 respectively. Our
approach provides sufficient flexibility for incorporating additional variables
in the city typology models and can be applied to study other city typologies
as well. Our findings can assist a diverse group of stakeholders in
transportation and urban planning fields, and opens up new opportunities for
using text-based information from Wikipedia (or similar platforms) as data
sources in such fields.",None,-1
14bada1b-2a4c-4ab9-a648-8a393952b84e,ParkPredict+: Multimodal Intent and Motion Prediction for Vehicles in Parking Lots with CNN and Transformer,0.494068,"The problem of multimodal intent and trajectory prediction for human-driven
vehicles in parking lots is addressed in this paper. Using models designed with
CNN and Transformer networks, we extract temporal-spatial and contextual
information from trajectory history and local bird's eye view (BEV) semantic
images, and generate predictions about intent distribution and future
trajectory sequences. Our methods outperform existing models in accuracy, while
allowing an arbitrary number of modes, encoding complex multi-agent scenarios,
and adapting to different parking maps. To train and evaluate our method, we
present the first public 4K video dataset of human driving in parking lots with
accurate annotation, high frame rate, and rich traffic scenarios.",https://github.com/XuShenLZ/ParkSim/,29242
de50c004-2471-45f1-9a72-d11beaf0eb4e,Acknowledging the Unknown for Multi-label Learning with Single Positive Labels,0.90977,"Due to the difficulty of collecting exhaustive multi-label annotations,
multi-label datasets often contain partial labels. We consider an extreme of
this weakly supervised learning problem, called single positive multi-label
learning (SPML), where each multi-label training image has only one positive
label. Traditionally, all unannotated labels are assumed as negative labels in
SPML, which introduces false negative labels and causes model training to be
dominated by assumed negative labels. In this work, we choose to treat all
unannotated labels from an alternative perspective, i.e. acknowledging they are
unknown. Hence, we propose entropy-maximization (EM) loss to attain a special
gradient regime for providing proper supervision signals. Moreover, we propose
asymmetric pseudo-labeling (APL), which adopts asymmetric-tolerance strategies
and a self-paced procedure, to cooperate with EM loss and then provide more
precise supervision. Experiments show that our method significantly improves
performance and achieves state-of-the-art results on all four benchmarks. Code
is available at https://github.com/Correr-Zhou/SPML-AckTheUnknown.",https://github.com/Correr-Zhou/SPML-AckTheUnknown,-1
ca15bd4c-b404-4cf1-a08c-dff6be94e0c4,Saliency-based Multiple Region of Interest Detection from a Single 360° image,0.249849,"360{\deg} images are informative -- it contains omnidirectional visual
information around the camera. However, the areas that cover a 360{\deg} image
is much larger than the human's field of view, therefore important information
in different view directions is easily overlooked. To tackle this issue, we
propose a method for predicting the optimal set of Region of Interest (RoI)
from a single 360{\deg} image using the visual saliency as a clue. To deal with
the scarce, strongly biased training data of existing single 360{\deg} image
saliency prediction dataset, we also propose a data augmentation method based
on the spherical random data rotation. From the predicted saliency map and
redundant candidate regions, we obtain the optimal set of RoIs considering both
the saliency within a region and the Interaction-Over-Union (IoU) between
regions. We conduct the subjective evaluation to show that the proposed method
can select regions that properly summarize the input 360{\deg} image.",None,-1
7b095e53-15fc-4ff1-84e8-2c707789ecea,NU HLT at CMCL 2022 Shared Task: Multilingual and Crosslingual Prediction of Human Reading Behavior in Universal Language Space,0.0164904,"In this paper, we present a unified model that works for both multilingual
and crosslingual prediction of reading times of words in various languages. The
secret behind the success of this model is in the preprocessing step where all
words are transformed to their universal language representation via the
International Phonetic Alphabet (IPA). To the best of our knowledge, this is
the first study to favorable exploit this phonological property of language for
the two tasks. Various feature types were extracted covering basic frequencies,
n-grams, information theoretic, and psycholinguistically-motivated predictors
for model training. A finetuned Random Forest model obtained best performance
for both tasks with 3.8031 and 3.9065 MAE scores for mean first fixation
duration (FFDAvg) and mean total reading time (TRTAvg) respectively.",https://github.com/imperialite/cmcl2022-unified-eye-tracking-ipa,-1
36ae12af-e3ba-4b96-9f20-8bead6179b73,Investigating data partitioning strategies for crosslinguistic low-resource ASR evaluation,0.473378,"Many automatic speech recognition (ASR) data sets include a single
pre-defined test set consisting of one or more speakers whose speech never
appears in the training set. This ""hold-speaker(s)-out"" data partitioning
strategy, however, may not be ideal for data sets in which the number of
speakers is very small. This study investigates ten different data split
methods for five languages with minimal ASR training resources. We find that
(1) model performance varies greatly depending on which speaker is selected for
testing; (2) the average word error rate (WER) across all held-out speakers is
comparable not only to the average WER over multiple random splits but also to
any given individual random split; (3) WER is also generally comparable when
the data is split heuristically or adversarially; (4) utterance duration and
intensity are comparatively more predictive factors of variability regardless
of the data split. These results suggest that the widely used hold-speakers-out
approach to ASR data partitioning can yield results that do not reflect model
performance on unseen data or speakers. Random splits can yield more reliable
and generalizable estimates when facing data sparsity.",None,1027
886ab7ac-2dcc-4dd3-a951-ae7755820d7b,Learn what matters: cross-domain imitation learning with task-relevant embeddings,0.613829,"We study how an autonomous agent learns to perform a task from demonstrations
in a different domain, such as a different environment or different agent. Such
cross-domain imitation learning is required to, for example, train an
artificial agent from demonstrations of a human expert. We propose a scalable
framework that enables cross-domain imitation learning without access to
additional demonstrations or further domain knowledge. We jointly train the
learner agent's policy and learn a mapping between the learner and expert
domains with adversarial training. We effect this by using a mutual information
criterion to find an embedding of the expert's state space that contains
task-relevant information and is invariant to domain specifics. This step
significantly simplifies estimating the mapping between the learner and expert
domains and hence facilitates end-to-end learning. We demonstrate successful
transfer of policies between considerably different domains, without extra
supervision such as additional demonstrations, and in situations where other
methods fail.",https://github.com/HumanCompatibleAI/seals,-1
185abb0e-af35-4e46-9455-dc6f8c1ba0ed,Counterfactually Measuring and Eliminating Social Bias in Vision-Language Pre-training Models,0.691178,"Vision-Language Pre-training (VLP) models have achieved state-of-the-art
performance in numerous cross-modal tasks. Since they are optimized to capture
the statistical properties of intra- and inter-modality, there remains risk to
learn social biases presented in the data as well. In this work, we (1)
introduce a counterfactual-based bias measurement \emph{CounterBias} to
quantify the social bias in VLP models by comparing the [MASK]ed prediction
probabilities of factual and counterfactual samples; (2) construct a novel
VL-Bias dataset including 24K image-text pairs for measuring gender bias in VLP
models, from which we observed that significant gender bias is prevalent in VLP
models; and (3) propose a VLP debiasing method \emph{FairVLP} to minimize the
difference in the [MASK]ed prediction probabilities between factual and
counterfactual image-text pairs for VLP debiasing. Although CounterBias and
FairVLP focus on social bias, they are generalizable to serve as tools and
provide new insights to probe and regularize more knowledge in VLP models.",https://github.com/VL-Bias/VL-Bias,-1
30e5b2d5-5a77-422f-b2b6-9cf90f71e134,Quark: Controllable Text Generation with Reinforced Unlearning,0.882168,"Large-scale language models often learn behaviors that are misaligned with
user expectations. Generated text may contain offensive or toxic language,
contain significant repetition, or be of a different sentiment than desired by
the user. We consider the task of unlearning these misalignments by fine-tuning
the language model on signals of what not to do. We introduce Quantized Reward
Konditioning (Quark), an algorithm for optimizing a reward function that
quantifies an (un)wanted property, while not straying too far from the original
model. Quark alternates between (i) collecting samples with the current
language model, (ii) sorting them into quantiles based on reward, with each
quantile identified by a reward token prepended to the language model's input,
and (iii) using a standard language modeling loss on samples from each quantile
conditioned on its reward token, while remaining nearby the original language
model via a KL-divergence penalty. By conditioning on a high-reward token at
generation time, the model generates text that exhibits less of the unwanted
property. For unlearning toxicity, negative sentiment, and repetition, our
experiments show that Quark outperforms both strong baselines and
state-of-the-art reinforcement learning methods like PPO (Schulman et al.
2017), while relying only on standard language modeling primitives.",https://github.com/GXimingLu/Quark,46374
552b2305-3b7e-4c13-b54b-2819204229c9,Investigating Lexical Replacements for Arabic-English Code-Switched Data Augmentation,0.349556,"Data sparsity is a main problem hindering the development of code-switching
(CS) NLP systems. In this paper, we investigate data augmentation techniques
for synthesizing dialectal Arabic-English CS text. We perform lexical
replacements using word-aligned parallel corpora where CS points are either
randomly chosen or learnt using a sequence-to-sequence model. We compare these
approaches against dictionary-based replacements. We assess the quality of the
generated sentences through human evaluation and evaluate the effectiveness of
data augmentation on machine translation (MT), automatic speech recognition
(ASR), and speech translation (ST) tasks. Results show that using a predictive
model results in more natural CS sentences compared to the random approach, as
reported in human judgements. In the downstream tasks, despite the random
approach generating more data, both approaches perform equally (outperforming
dictionary-based replacements). Overall, data augmentation achieves 34%
improvement in perplexity, 5.2% relative improvement on WER for ASR task,
+4.0-5.1 BLEU points on MT task, and +2.1-2.2 BLEU points on ST over a baseline
trained on available data without augmentation.",http://arzen.camel-lab.com/,-1
2d65fea0-e537-42c0-81dd-f23ed755c43b,TE2Rules: Explaining Tree Ensembles using Rules,0.216296,"Tree Ensemble (TE) models, such as Gradient Boosted Trees, often achieve
optimal performance on tabular datasets, yet their lack of transparency poses
challenges for comprehending their decision logic. This paper introduces
TE2Rules (Tree Ensemble to Rules), a novel approach for explaining binary
classification tree ensemble models through a list of rules, particularly
focusing on explaining the minority class. Many state-of-the-art explainers
struggle with minority class explanations, making TE2Rules valuable in such
cases. The rules generated by TE2Rules closely approximate the original model,
ensuring high fidelity, providing an accurate and interpretable means to
understand decision-making. Experimental results demonstrate that TE2Rules
scales effectively to tree ensembles with hundreds of trees, achieving higher
fidelity within runtimes comparable to baselines. TE2Rules allows for a
trade-off between runtime and fidelity, enhancing its practical applicability.
The implementation is available here: https://github.com/linkedin/TE2Rules.",https://github.com/linkedin/TE2Rules,-1
769e9773-b7ef-4597-aa18-2f5af363700a,Learning to Listen: Modeling Non-Deterministic Dyadic Facial Motion,0.80512,"We present a framework for modeling interactional communication in dyadic
conversations: given multimodal inputs of a speaker, we autoregressively output
multiple possibilities of corresponding listener motion. We combine the motion
and speech audio of the speaker using a motion-audio cross attention
transformer. Furthermore, we enable non-deterministic prediction by learning a
discrete latent representation of realistic listener motion with a novel
motion-encoding VQ-VAE. Our method organically captures the multimodal and
non-deterministic nature of nonverbal dyadic interactions. Moreover, it
produces realistic 3D listener facial motion synchronous with the speaker (see
video). We demonstrate that our method outperforms baselines qualitatively and
quantitatively via a rich suite of experiments. To facilitate this line of
research, we introduce a novel and large in-the-wild dataset of dyadic
conversations. Code, data, and videos available at
https://evonneng.github.io/learning2listen/.",None,-1
1be6fd32-a077-4753-9e05-6ff963b3bf7e,Human Evaluation of Conversations is an Open Problem: comparing the sensitivity of various methods for evaluating dialogue agents,0.715892,"At the heart of improving conversational AI is the open problem of how to
evaluate conversations. Issues with automatic metrics are well known (Liu et
al., 2016, arXiv:1603.08023), with human evaluations still considered the gold
standard. Unfortunately, how to perform human evaluations is also an open
problem: differing data collection methods have varying levels of human
agreement and statistical sensitivity, resulting in differing amounts of human
annotation hours and labor costs. In this work we compare five different
crowdworker-based human evaluation methods and find that different methods are
best depending on the types of models compared, with no clear winner across the
board. While this highlights the open problems in the area, our analysis leads
to advice of when to use which one, and possible future directions.",None,7769
2fd61224-05e8-4455-88ee-1db935a5b8f1,Pavementscapes: a large-scale hierarchical image dataset for asphalt pavement damage segmentation,0.211872,"Pavement damage segmentation has benefited enormously from deep learning. %
and large-scale datasets. However, few current public datasets limit the
potential exploration of deep learning in the application of pavement damage
segmentation. To address this problem, this study has proposed Pavementscapes,
a large-scale dataset to develop and evaluate methods for pavement damage
segmentation. Pavementscapes is comprised of 4,000 images with a resolution of
$1024 \times 2048$, which have been recorded in the real-world pavement
inspection projects with 15 different pavements. A total of 8,680 damage
instances are manually labeled with six damage classes at the pixel level. The
statistical study gives a thorough investigation and analysis of the proposed
dataset. The numeral experiments propose the top-performing deep neural
networks capable of segmenting pavement damages, which provides the baselines
of the open challenge for pavement inspection. The experiment results also
indicate the existing problems for damage segmentation using deep learning, and
this study provides potential solutions.",https://github.com/tongzheng1992/E-FCN,2235
360cabc9-2682-4871-bc93-2d825b9df956,An integrated Auto Encoder-Block Switching defense approach to prevent adversarial attacks,0.187896,"According to recent studies, the vulnerability of state-of-the-art Neural
Networks to adversarial input samples has increased drastically. A neural
network is an intermediate path or technique by which a computer learns to
perform tasks using Machine learning algorithms. Machine Learning and
Artificial Intelligence model has become a fundamental aspect of life, such as
self-driving cars [1], smart home devices, so any vulnerability is a
significant concern. The smallest input deviations can fool these extremely
literal systems and deceive their users as well as administrator into
precarious situations. This article proposes a defense algorithm that utilizes
the combination of an auto-encoder [3] and block-switching architecture.
Auto-coder is intended to remove any perturbations found in input images
whereas the block switching method is used to make it more robust against
White-box attacks. The attack is planned using FGSM [9] model, and the
subsequent counter-attack by the proposed architecture will take place thereby
demonstrating the feasibility and security delivered by the algorithm.",None,-1
1ca17405-7a85-427d-a54b-0f9a6916624a,Smart Speech Segmentation using Acousto-Linguistic Features with look-ahead,0.519278,"Segmentation for continuous Automatic Speech Recognition (ASR) has
traditionally used silence timeouts or voice activity detectors (VADs), which
are both limited to acoustic features. This segmentation is often overly
aggressive, given that people naturally pause to think as they speak.
Consequently, segmentation happens mid-sentence, hindering both punctuation and
downstream tasks like machine translation for which high-quality segmentation
is critical. Model-based segmentation methods that leverage acoustic features
are powerful, but without an understanding of the language itself, these
approaches are limited. We present a hybrid approach that leverages both
acoustic and language information to improve segmentation. Furthermore, we show
that including one word as a look-ahead boosts segmentation quality. On
average, our models improve segmentation-F0.5 score by 9.8% over baseline. We
show that this approach works for multiple languages. For the downstream task
of machine translation, it improves the translation BLEU score by an average of
1.05 points.",None,753
e4715570-8890-4fe9-9f97-ee41d36856d3,Realistic Synthetic Social Networks with Graph Neural Networks,0.318818,"Social network analysis faces profound difficulties in sharing data between
researchers due to privacy and security concerns. A potential remedy to this
issue are synthetic networks, that closely resemble their real counterparts,
but can be freely distributed. generating synthetic networks requires the
creation of network topologies that, in application, function as realistically
as possible. Widely applied models are currently rule-based and can struggle to
reproduce structural dynamics. Lead by recent developments in Graph Neural
Network (GNN) models for network generation we evaluate the potential of GNNs
for synthetic social networks. Our GNN use is specifically within a reasonable
use-case and includes empirical evaluation using Maximum Mean Discrepancy
(MMD). We include social network specific measurements which allow evaluation
of how realistically synthetic networks behave in typical social network
analysis applications.
  We find that the Gated Recurrent Attention Network (GRAN) extends well to
social networks, and in comparison to a benchmark popular rule-based generation
Recursive-MATrix (R-MAT) method, is better able to replicate realistic
structural dynamics. We find that GRAN is more computationally costly than
R-MAT, but is not excessively costly to employ, so would be effective for
researchers seeking to create datasets of synthetic social networks.",None,-1
dfc3845f-dfda-4bd6-94c7-55956935d932,MuCPAD: A Multi-Domain Chinese Predicate-Argument Dataset,0.0945803,"During the past decade, neural network models have made tremendous progress
on in-domain semantic role labeling (SRL). However, performance drops
dramatically under the out-of-domain setting. In order to facilitate research
on cross-domain SRL, this paper presents MuCPAD, a multi-domain Chinese
predicate-argument dataset, which consists of 30,897 sentences and 92,051
predicates from six different domains. MuCPAD exhibits three important
features. 1) Based on a frame-free annotation methodology, we avoid writing
complex frames for new predicates. 2) We explicitly annotate omitted core
arguments to recover more complete semantic structure, considering that
omission of content words is ubiquitous in multi-domain Chinese texts. 3) We
compile 53 pages of annotation guidelines and adopt strict double annotation
for improving data quality. This paper describes in detail the annotation
methodology and annotation process of MuCPAD, and presents in-depth data
analysis. We also give benchmark results on cross-domain SRL based on MuCPAD.",https://github.com/SUDA-LA/MuCPAD,-1
1aa4200a-c11b-4f96-b425-bec47bce056e,InstantAvatar: Learning Avatars from Monocular Video in 60 Seconds,0.884219,"In this paper, we take a significant step towards real-world applicability of
monocular neural avatar reconstruction by contributing InstantAvatar, a system
that can reconstruct human avatars from a monocular video within seconds, and
these avatars can be animated and rendered at an interactive rate. To achieve
this efficiency we propose a carefully designed and engineered system, that
leverages emerging acceleration structures for neural fields, in combination
with an efficient empty space-skipping strategy for dynamic scenes. We also
contribute an efficient implementation that we will make available for research
purposes. Compared to existing methods, InstantAvatar converges 130x faster and
can be trained in minutes instead of hours. It achieves comparable or even
better reconstruction quality and novel pose synthesis results. When given the
same time budget, our method significantly outperforms SoTA methods.
InstantAvatar can yield acceptable visual quality in as little as 10 seconds
training time.",None,-1
615d42f7-d108-4ad1-841e-8c4b3c612147,Semantic Image Synthesis via Diffusion Models,0.905988,"Denoising Diffusion Probabilistic Models (DDPMs) have achieved remarkable
success in various image generation tasks compared with Generative Adversarial
Nets (GANs). Recent work on semantic image synthesis mainly follows the
\emph{de facto} GAN-based approaches, which may lead to unsatisfactory quality
or diversity of generated images. In this paper, we propose a novel framework
based on DDPM for semantic image synthesis. Unlike previous conditional
diffusion model directly feeds the semantic layout and noisy image as input to
a U-Net structure, which may not fully leverage the information in the input
semantic mask, our framework processes semantic layout and noisy image
differently. It feeds noisy image to the encoder of the U-Net structure while
the semantic layout to the decoder by multi-layer spatially-adaptive
normalization operators. To further improve the generation quality and semantic
interpretability in semantic image synthesis, we introduce the classifier-free
guidance sampling strategy, which acknowledge the scores of an unconditional
model for sampling process. Extensive experiments on three benchmark datasets
demonstrate the effectiveness of our proposed method, achieving
state-of-the-art performance in terms of fidelity (FID) and diversity (LPIPS).",https://github.com/WeilunWang/semantic-diffusion-model,-1
8445e0c3-e5ec-4456-bec7-cc6caf4e1535,A Mask Attention Interaction and Scale Enhancement Network for SAR Ship Instance Segmentation,0.991808,"Most of existing synthetic aperture radar (SAR) ship in-stance segmentation
models do not achieve mask interac-tion or offer limited interaction
performance. Besides, their multi-scale ship instance segmentation performance
is moderate especially for small ships. To solve these problems, we propose a
mask attention interaction and scale enhancement network (MAI-SE-Net) for SAR
ship instance segmentation. MAI uses an atrous spatial pyra-mid pooling (ASPP)
to gain multi-resolution feature re-sponses, a non-local block (NLB) to model
long-range spa-tial dependencies, and a concatenation shuffle attention block
(CSAB) to improve interaction benefits. SE uses a content-aware reassembly of
features block (CARAFEB) to generate an extra pyramid bottom-level to boost
small ship performance, a feature balance operation (FBO) to improve scale
feature description, and a global context block (GCB) to refine features.
Experimental results on two public SSDD and HRSID datasets reveal that
MAI-SE-Net outperforms the other nine competitive models, better than the
suboptimal model by 4.7% detec-tion AP and 3.4% segmentation AP on SSDD and by
3.0% detection AP and 2.4% segmentation AP on HRSID.",None,-1
01cafb4a-650d-4a69-a622-5e0f554d1053,Towards Responsible AI: A Design Space Exploration of Human-Centered Artificial Intelligence User Interfaces to Investigate Fairness,0.56065,"With Artificial intelligence (AI) to aid or automate decision-making
advancing rapidly, a particular concern is its fairness. In order to create
reliable, safe and trustworthy systems through human-centred artificial
intelligence (HCAI) design, recent efforts have produced user interfaces (UIs)
for AI experts to investigate the fairness of AI models. In this work, we
provide a design space exploration that supports not only data scientists but
also domain experts to investigate AI fairness. Using loan applications as an
example, we held a series of workshops with loan officers and data scientists
to elicit their requirements. We instantiated these requirements into FairHIL,
a UI to support human-in-the-loop fairness investigations, and describe how
this UI could be generalized to other use cases. We evaluated FairHIL through a
think-aloud user study. Our work contributes better designs to investigate an
AI model's fairness-and move closer towards responsible AI.",None,758
f3c38f86-e861-4ae2-88f7-92df4b8147a3,"The $(1+(λ,λ))$ Global SEMO Algorithm",0.455936,"The $(1+(\lambda,\lambda))$ genetic algorithm is a recently proposed
single-objective evolutionary algorithm with several interesting properties. We
show that its main working principle, mutation with a high rate and crossover
as repair mechanism, can be transported also to multi-objective evolutionary
computation. We define the $(1+(\lambda,\lambda))$ global SEMO algorithm, a
variant of the classic global SEMO algorithm, and prove that it optimizes the
OneMinMax benchmark asymptotically faster than the global SEMO. Following the
single-objective example, we design a one-fifth rule inspired dynamic parameter
setting (to the best of our knowledge for the first time in discrete
multi-objective optimization) and prove that it further improves the runtime to
$O(n^2)$, whereas the best runtime guarantee for the global SEMO is only $O(n^2
\log n)$.",None,-1
6702d09e-8d59-4596-b084-37ce3838a7b4,Interactive Multi-Class Tiny-Object Detection,0.804051,"Annotating tens or hundreds of tiny objects in a given image is laborious yet
crucial for a multitude of Computer Vision tasks. Such imagery typically
contains objects from various categories, yet the multi-class interactive
annotation setting for the detection task has thus far been unexplored. To
address these needs, we propose a novel interactive annotation method for
multiple instances of tiny objects from multiple classes, based on a few
point-based user inputs. Our approach, C3Det, relates the full image context
with annotator inputs in a local and global manner via late-fusion and
feature-correlation, respectively. We perform experiments on the Tiny-DOTA and
LCell datasets using both two-stage and one-stage object detection
architectures to verify the efficacy of our approach. Our approach outperforms
existing approaches in interactive annotation, achieving higher mAP with fewer
clicks. Furthermore, we validate the annotation efficiency of our approach in a
user study where it is shown to be 2.85x faster and yield only 0.36x task load
(NASA-TLX, lower is better) compared to manual annotation. The code is
available at
https://github.com/ChungYi347/Interactive-Multi-Class-Tiny-Object-Detection.",https://github.com/ChungYi347/Interactive-Multi-Class-Tiny-Object-Detection,-1
1f275255-093e-46f8-af12-174a2a3de448,Learning Local Displacements for Point Cloud Completion,0.684097,"We propose a novel approach aimed at object and semantic scene completion
from a partial scan represented as a 3D point cloud. Our architecture relies on
three novel layers that are used successively within an encoder-decoder
structure and specifically developed for the task at hand. The first one
carries out feature extraction by matching the point features to a set of
pre-trained local descriptors. Then, to avoid losing individual descriptors as
part of standard operations such as max-pooling, we propose an alternative
neighbor-pooling operation that relies on adopting the feature vectors with the
highest activations. Finally, up-sampling in the decoder modifies our feature
extraction in order to increase the output dimension. While this model is
already able to achieve competitive results with the state of the art, we
further propose a way to increase the versatility of our approach to process
point clouds. To this aim, we introduce a second model that assembles our
layers within a transformer architecture. We evaluate both architectures on
object and indoor scene completion tasks, achieving state-of-the-art
performance.",None,-1
c195ea1b-96b9-4bfe-99ca-e8de8c6d768a,Local Contrastive Feature learning for Tabular Data,0.230875,"Contrastive self-supervised learning has been successfully used in many
domains, such as images, texts, graphs, etc., to learn features without
requiring label information. In this paper, we propose a new local contrastive
feature learning (LoCL) framework, and our theme is to learn local
patterns/features from tabular data. In order to create a niche for local
learning, we use feature correlations to create a maximum-spanning tree, and
break the tree into feature subsets, with strongly correlated features being
assigned next to each other. Convolutional learning of the features is used to
learn latent feature space, regulated by contrastive and reconstruction losses.
Experiments on public tabular datasets show the effectiveness of the proposed
method versus state-of-the-art baseline methods.",None,-1
4bf1033a-2116-4e14-8728-49d90a26e9d1,MAGVIT: Masked Generative Video Transformer,0.903484,"We introduce the MAsked Generative VIdeo Transformer, MAGVIT, to tackle
various video synthesis tasks with a single model. We introduce a 3D tokenizer
to quantize a video into spatial-temporal visual tokens and propose an
embedding method for masked video token modeling to facilitate multi-task
learning. We conduct extensive experiments to demonstrate the quality,
efficiency, and flexibility of MAGVIT. Our experiments show that (i) MAGVIT
performs favorably against state-of-the-art approaches and establishes the
best-published FVD on three video generation benchmarks, including the
challenging Kinetics-600. (ii) MAGVIT outperforms existing methods in inference
time by two orders of magnitude against diffusion models and by 60x against
autoregressive models. (iii) A single MAGVIT model supports ten diverse
generation tasks and generalizes across videos from different visual domains.
The source code and trained models will be released to the public at
https://magvit.cs.cmu.edu.",https://magvit.cs.cmu.edu,-1
8a4bf3ed-d555-4090-9701-3a209a5bd97a,Examining Scaling and Transfer of Language Model Architectures for Machine Translation,0.137502,"Natural language understanding and generation models follow one of the two
dominant architectural paradigms: language models (LMs) that process
concatenated sequences in a single stack of layers, and encoder-decoder models
(EncDec) that utilize separate layer stacks for input and output processing. In
machine translation, EncDec has long been the favoured approach, but with few
studies investigating the performance of LMs. In this work, we thoroughly
examine the role of several architectural design choices on the performance of
LMs on bilingual, (massively) multilingual and zero-shot translation tasks,
under systematic variations of data conditions and model sizes. Our results
show that: (i) Different LMs have different scaling properties, where
architectural differences often have a significant impact on model performance
at small scales, but the performance gap narrows as the number of parameters
increases, (ii) Several design choices, including causal masking and
language-modeling objectives for the source sequence, have detrimental effects
on translation quality, and (iii) When paired with full-visible masking for
source sequences, LMs could perform on par with EncDec on supervised bilingual
and multilingual translation tasks, and improve greatly on zero-shot directions
by facilitating the reduction of off-target translations.",None,-1
87a379ef-c5da-42c4-8baf-d3e08794ecdf,MMGL: Multi-Scale Multi-View Global-Local Contrastive learning for Semi-supervised Cardiac Image Segmentation,0.509484,"With large-scale well-labeled datasets, deep learning has shown significant
success in medical image segmentation. However, it is challenging to acquire
abundant annotations in clinical practice due to extensive expertise
requirements and costly labeling efforts. Recently, contrastive learning has
shown a strong capacity for visual representation learning on unlabeled data,
achieving impressive performance rivaling supervised learning in many domains.
In this work, we propose a novel multi-scale multi-view global-local
contrastive learning (MMGL) framework to thoroughly explore global and local
features from different scales and views for robust contrastive learning
performance, thereby improving segmentation performance with limited
annotations. Extensive experiments on the MM-WHS dataset demonstrate the
effectiveness of MMGL framework on semi-supervised cardiac image segmentation,
outperforming the state-of-the-art contrastive learning methods by a large
margin.",None,-1
72e3689a-37c7-433b-af3a-1b697c4ac6c3,Domain Adaptation meets Individual Fairness. And they get along,0.540242,"Many instances of algorithmic bias are caused by distributional shifts. For
example, machine learning (ML) models often perform worse on demographic groups
that are underrepresented in the training data. In this paper, we leverage this
connection between algorithmic fairness and distribution shifts to show that
algorithmic fairness interventions can help ML models overcome distribution
shifts, and that domain adaptation methods (for overcoming distribution shifts)
can mitigate algorithmic biases. In particular, we show that (i) enforcing
suitable notions of individual fairness (IF) can improve the
out-of-distribution accuracy of ML models under the covariate shift assumption
and that (ii) it is possible to adapt representation alignment methods for
domain adaptation to enforce individual fairness. The former is unexpected
because IF interventions were not developed with distribution shifts in mind.
The latter is also unexpected because representation alignment is not a common
approach in the individual fairness literature.",None,-1
2c140b7e-5b71-47e5-926a-29d2b88226cf,Towards Understanding Mixture of Experts in Deep Learning,0.856862,"The Mixture-of-Experts (MoE) layer, a sparsely-activated model controlled by
a router, has achieved great success in deep learning. However, the
understanding of such architecture remains elusive. In this paper, we formally
study how the MoE layer improves the performance of neural network learning and
why the mixture model will not collapse into a single model. Our empirical
results suggest that the cluster structure of the underlying problem and the
non-linearity of the expert are pivotal to the success of MoE. To further
understand this, we consider a challenging classification problem with
intrinsic cluster structures, which is hard to learn using a single expert. Yet
with the MoE layer, by choosing the experts as two-layer nonlinear
convolutional neural networks (CNNs), we show that the problem can be learned
successfully. Furthermore, our theory shows that the router can learn the
cluster-center features, which helps divide the input complex problem into
simpler linear classification sub-problems that individual experts can conquer.
To our knowledge, this is the first result towards formally understanding the
mechanism of the MoE layer for deep learning.",https://github.com/TheophileBlard/french-sentiment-analysis-with-bert,-1
f716f270-6298-4fc9-8537-4b13635ca1d9,"Multi-view Tracking, Re-ID, and Social Network Analysis of a Flock of Visually Similar Birds in an Outdoor Aviary",0.168642,"The ability to capture detailed interactions among individuals in a social
group is foundational to our study of animal behavior and neuroscience. Recent
advances in deep learning and computer vision are driving rapid progress in
methods that can record the actions and interactions of multiple individuals
simultaneously. Many social species, such as birds, however, live deeply
embedded in a three-dimensional world. This world introduces additional
perceptual challenges such as occlusions, orientation-dependent appearance,
large variation in apparent size, and poor sensor coverage for 3D
reconstruction, that are not encountered by applications studying animals that
move and interact only on 2D planes. Here we introduce a system for studying
the behavioral dynamics of a group of songbirds as they move throughout a 3D
aviary. We study the complexities that arise when tracking a group of closely
interacting animals in three dimensions and introduce a novel dataset for
evaluating multi-view trackers. Finally, we analyze captured ethogram data and
demonstrate that social context affects the distribution of sequential
interactions between birds in the aviary.",None,-1
09654c07-794b-44d7-b576-ba3c3f6ef34c,Data Augmentation by Selecting Mixed Classes Considering Distance Between Classes,0.0982838,"Data augmentation is an essential technique for improving recognition
accuracy in object recognition using deep learning. Methods that generate mixed
data from multiple data sets, such as mixup, can acquire new diversity that is
not included in the training data, and thus contribute significantly to
accuracy improvement. However, since the data selected for mixing are randomly
sampled throughout the training process, there are cases where appropriate
classes or data are not selected. In this study, we propose a data augmentation
method that calculates the distance between classes based on class
probabilities and can select data from suitable classes to be mixed in the
training process. Mixture data is dynamically adjusted according to the
training trend of each class to facilitate training. The proposed method is
applied in combination with conventional methods for generating mixed data.
Evaluation experiments show that the proposed method improves recognition
performance on general and long-tailed image recognition datasets.",None,9497
e69bb05f-b3fb-4ca9-9167-b286a746f075,A Fast Post-Training Pruning Framework for Transformers,0.615454,"Pruning is an effective way to reduce the huge inference cost of Transformer
models. However, prior work on pruning Transformers requires retraining the
models. This can add high training cost and high complexity to model
deployment, making it difficult to use in many practical situations. To address
this, we propose a fast post-training pruning framework for Transformers that
does not require any retraining. Given a resource constraint and a sample
dataset, our framework automatically prunes the Transformer model using
structured sparsity methods. To retain high accuracy without retraining, we
introduce three novel techniques: (i) a lightweight mask search algorithm that
finds which heads and filters to prune based on the Fisher information; (ii)
mask rearrangement that complements the search algorithm; and (iii) mask tuning
that reconstructs the output activations for each layer. We apply our method to
BERT-base and DistilBERT, and we evaluate its effectiveness on GLUE and SQuAD
benchmarks. Our framework achieves up to 2.0x reduction in FLOPs and 1.56x
speedup in inference latency, while maintaining < 1% loss in accuracy.
Importantly, our framework prunes Transformers in less than 3 minutes on a
single GPU, which is over two orders of magnitude faster than existing pruning
approaches that retrain the models.",https://github.com/WoosukKwon/retraining-free-pruning,-1
81fbe560-e352-4f56-b959-e98c2f5ae5fc,BSAL: A Framework of Bi-component Structure and Attribute Learning for Link Prediction,0.378012,"Given the ubiquitous existence of graph-structured data, learning the
representations of nodes for the downstream tasks ranging from node
classification, link prediction to graph classification is of crucial
importance. Regarding missing link inference of diverse networks, we revisit
the link prediction techniques and identify the importance of both the
structural and attribute information. However, the available techniques either
heavily count on the network topology which is spurious in practice or cannot
integrate graph topology and features properly. To bridge the gap, we propose a
bicomponent structural and attribute learning framework (BSAL) that is designed
to adaptively leverage information from topology and feature spaces.
Specifically, BSAL constructs a semantic topology via the node attributes and
then gets the embeddings regarding the semantic view, which provides a flexible
and easy-to-implement solution to adaptively incorporate the information
carried by the node attributes. Then the semantic embedding together with
topology embedding is fused together using an attention mechanism for the final
prediction. Extensive experiments show the superior performance of our proposal
and it significantly outperforms baselines on diverse research benchmarks.",https://github.com/BishengLi0327/BSAL,-1
b33261a9-e3d0-4fe7-a7fe-2d062fedbe37,FaiRR: Faithful and Robust Deductive Reasoning over Natural Language,0.54836,"Transformers have been shown to be able to perform deductive reasoning on a
logical rulebase containing rules and statements written in natural language.
Recent works show that such models can also produce the reasoning steps (i.e.,
the proof graph) that emulate the model's logical reasoning process. Currently,
these black-box models generate both the proof graph and intermediate
inferences within the same model and thus may be unfaithful. In this work, we
frame the deductive logical reasoning task by defining three modular
components: rule selection, fact selection, and knowledge composition. The rule
and fact selection steps select the candidate rule and facts to be used and
then the knowledge composition combines them to generate new inferences. This
ensures model faithfulness by assured causal relation from the proof step to
the inference reasoning. To test our framework, we propose FaiRR (Faithful and
Robust Reasoner) where the above three components are independently modeled by
transformers. We observe that FaiRR is robust to novel language perturbations,
and is faster at inference than previous works on existing reasoning datasets.
Additionally, in contrast to black-box generative models, the errors made by
FaiRR are more interpretable due to the modular approach.",https://github.com/INK-USC/FaiRR,-1
88903b21-1ef0-456e-87c4-01e821854da8,Edge Augmentation for Large-Scale Sketch Recognition without Sketches,0.191737,"This work addresses scaling up the sketch classification task into a large
number of categories. Collecting sketches for training is a slow and tedious
process that has so far precluded any attempts to large-scale sketch
recognition. We overcome the lack of training sketch data by exploiting labeled
collections of natural images that are easier to obtain. To bridge the domain
gap we present a novel augmentation technique that is tailored to the task of
learning sketch recognition from a training set of natural images.
Randomization is introduced in the parameters of edge detection and edge
selection. Natural images are translated to a pseudo-novel domain called
""randomized Binary Thin Edges"" (rBTE), which is used as a training domain
instead of natural images. The ability to scale up is demonstrated by training
CNN-based sketch recognition of more than 2.5 times larger number of categories
than used previously. For this purpose, a dataset of natural images from 874
categories is constructed by combining a number of popular computer vision
datasets. The categories are selected to be suitable for sketch recognition. To
estimate the performance, a subset of 393 categories with sketches is also
collected.",https://github.com/NikosEfth/im2rbte,-1
b1858f6b-161a-4aa5-9d1f-56fff05221cc,A Moral- and Event- Centric Inspection of Gender Bias in Fairy Tales at A Large Scale,0.283024,"Fairy tales are a common resource for young children to learn a language or
understand how a society works. However, gender bias, e.g., stereotypical
gender roles, in this literature may cause harm and skew children's world view.
Instead of decades of qualitative and manual analysis of gender bias in fairy
tales, we computationally analyze gender bias in a fairy tale dataset
containing 624 fairy tales from 7 different cultures. We specifically examine
gender difference in terms of moral foundations, which are measures of human
morality, and events, which reveal human activities associated with each
character. We find that the number of male characters is two times that of
female characters, showing a disproportionate gender representation. Our
analysis further reveal stereotypical portrayals of both male and female
characters in terms of moral foundations and events. Female characters turn out
more associated with care-, loyalty- and sanctity- related moral words, while
male characters are more associated with fairness- and authority- related moral
words. Female characters' events are often about emotion (e.g., weep),
appearance (e.g., comb), household (e.g., bake), etc.; while male characters'
events are more about profession (e.g., hunt), violence (e.g., destroy),
justice (e.g., judge), etc. Gender bias in terms of moral foundations shows an
obvious difference across cultures. For example, female characters are more
associated with care and sanctity in high uncertainty-avoidance cultures which
are less open to changes and unpredictability. Based on the results, we propose
implications for children's literature and early literacy research.",https://github.com/medianeuroscience/emfdscore,-1
746908ee-c33d-46fd-bb68-766e1b3ef0e9,Describing Differences between Text Distributions with Natural Language,0.801211,"How do two distributions of texts differ? Humans are slow at answering this,
since discovering patterns might require tediously reading through hundreds of
samples. We propose to automatically summarize the differences by ""learning a
natural language hypothesis"": given two distributions $D_{0}$ and $D_{1}$, we
search for a description that is more often true for $D_{1}$, e.g., ""is
military-related."" To tackle this problem, we fine-tune GPT-3 to propose
descriptions with the prompt: ""[samples of $D_{0}$] + [samples of $D_{1}$] +
the difference between them is_____."" We then re-rank the descriptions by
checking how often they hold on a larger set of samples with a learned
verifier. On a benchmark of 54 real-world binary classification tasks, while
GPT-3 Curie (13B) only generates a description similar to human annotation 7%
of the time, the performance reaches 61% with fine-tuning and re-ranking, and
our best system using GPT-3 Davinci (175B) reaches 76%. We apply our system to
describe distribution shifts, debug dataset shortcuts, summarize unknown tasks,
and label text clusters, and present analyses based on automatically generated
descriptions.",None,-1
a76906de-e45e-40c7-b258-c6a28f74cf17,Action Recognition for American Sign Language,0.20595,"In this research, we present our findings to recognize American Sign Language
from series of hand gestures. While most researches in literature focus only on
static handshapes, our work target dynamic hand gestures. Since dynamic signs
dataset are very few, we collect an initial dataset of 150 videos for 10 signs
and an extension of 225 videos for 15 signs. We apply transfer learning models
in combination with deep neural networks and background subtraction for videos
in different temporal settings. Our primarily results show that we can get an
accuracy of $0.86$ and $0.71$ using DenseNet201, LSTM with video sequence of 12
frames accordingly.",None,-1
3532890e-314a-4f70-8646-bfcf27e86c08,A Contrastive Framework for Neural Text Generation,0.919322,"Text generation is of great importance to many natural language processing
applications. However, maximization-based decoding methods (e.g. beam search)
of neural language models often lead to degenerate solutions -- the generated
text is unnatural and contains undesirable repetitions. Existing approaches
introduce stochasticity via sampling or modify training objectives to decrease
probabilities of certain tokens (e.g., unlikelihood training). However, they
often lead to solutions that lack coherence. In this work, we show that an
underlying reason for model degeneration is the anisotropic distribution of
token representations. We present a contrastive solution: (i) SimCTG, a
contrastive training objective to calibrate the model's representation space,
and (ii) a decoding method -- contrastive search -- to encourage diversity
while maintaining coherence in the generated text. Extensive experiments and
analyses on three benchmarks from two languages demonstrate that our proposed
approach significantly outperforms current state-of-the-art text generation
methods as evaluated by both human and automatic metrics.",https://github.com/yxuansu/SimCTG,-1
f7343a7f-4bef-4280-bbfc-89c03bd90426,Lyapunov function approach for approximation algorithm design and analysis: with applications in submodular maximization,0.44145,"We propose a two-phase systematical framework for approximation algorithm
design and analysis via Lyapunov function. The first phase consists of using
Lyapunov function as an input and outputs a continuous-time approximation
algorithm with a provable approximation ratio. The second phase then converts
this continuous-time algorithm to a discrete-time algorithm with almost the
same approximation ratio along with provable time complexity. One distinctive
feature of our framework is that we only need to know the parametric form of
the Lyapunov function whose complete specification will not be decided until
the end of the first phase by maximizing the approximation ratio of the
continuous-time algorithm. Some immediate benefits of the Lyapunov function
approach include: (i) unifying many existing algorithms; (ii) providing a
guideline to design and analyze new algorithms; and (iii) offering new
perspectives to potentially improve existing algorithms. We use various
submodular maximization problems as running examples to illustrate our
framework.",None,-1
500806a0-eb85-4b9a-bb88-0406c9f30e22,NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis,0.956993,"Sentiment analysis is one of the most widely studied applications in NLP, but
most work focuses on languages with large amounts of data. We introduce the
first large-scale human-annotated Twitter sentiment dataset for the four most
widely spoken languages in Nigeria (Hausa, Igbo, Nigerian-Pidgin, and
Yor\`ub\'a ) consisting of around 30,000 annotated tweets per language (and
14,000 for Nigerian-Pidgin), including a significant fraction of code-mixed
tweets. We propose text collection, filtering, processing and labeling methods
that enable us to create datasets for these low-resource languages. We evaluate
a rangeof pre-trained models and transfer strategies on the dataset. We find
that language-specific models and language-adaptivefine-tuning generally
perform best. We release the datasets, trained models, sentiment lexicons, and
code to incentivizeresearch on sentiment analysis in under-represented
languages.",https://github.com/hausanlp/NaijaSenti,-1
c3834383-45f3-4d3a-8767-1ceaa5d47872,Ontology Design Facilitating Wikibase Integration -- and a Worked Example for Historical Data,0.208851,"Wikibase -- which is the software underlying Wikidata -- is a powerful
platform for knowledge graph creation and management. However, it has been
developed with a crowd-sourced knowledge graph creation scenario in mind, which
in particular means that it has not been designed for use case scenarios in
which a tightly controlled high-quality schema, in the form of an ontology, is
to be imposed, and indeed, independently developed ontologies do not
necessarily map seamlessly to the Wikibase approach. In this paper, we provide
the key ingredients needed in order to combine traditional ontology modeling
with use of the Wikibase platform, namely a set of \emph{axiom} patterns that
bridge the paradigm gap, together with usage instructions and a worked example
for historical data.",https://gitlab.cs.ksu.edu/daselab/wikibase-ontology-design-library,-1
9513c5a0-0076-4372-ad79-7ac38967b309,Democratizing Neural Machine Translation with OPUS-MT,0.11469,"This paper presents the OPUS ecosystem with a focus on the development of
open machine translation models and tools, and their integration into end-user
applications, development platforms and professional workflows. We discuss our
on-going mission of increasing language coverage and translation quality, and
also describe on-going work on the development of modular translation models
and speed-optimized compact solutions for real-time translation on regular
desktops and small devices.",None,-1
474e5e74-06a4-4e23-be09-463c71e5c245,SparsePose: Sparse-View Camera Pose Regression and Refinement,0.93294,"Camera pose estimation is a key step in standard 3D reconstruction pipelines
that operate on a dense set of images of a single object or scene. However,
methods for pose estimation often fail when only a few images are available
because they rely on the ability to robustly identify and match visual features
between image pairs. While these methods can work robustly with dense camera
views, capturing a large set of images can be time-consuming or impractical. We
propose SparsePose for recovering accurate camera poses given a sparse set of
wide-baseline images (fewer than 10). The method learns to regress initial
camera poses and then iteratively refine them after training on a large-scale
dataset of objects (Co3D: Common Objects in 3D). SparsePose significantly
outperforms conventional and learning-based baselines in recovering accurate
camera rotations and translations. We also demonstrate our pipeline for
high-fidelity 3D reconstruction using only 5-9 images of an object.",None,-1
1194c593-a224-483d-b869-8e01c571bc44,"Reflectance-Guided, Contrast-Accumulated Histogram Equalization",0.0717411,"Existing image enhancement methods fall short of expectations because with
them it is difficult to improve global and local image contrast simultaneously.
To address this problem, we propose a histogram equalization-based method that
adapts to the data-dependent requirements of brightness enhancement and
improves the visibility of details without losing the global contrast. This
method incorporates the spatial information provided by image context in
density estimation for discriminative histogram equalization. To minimize the
adverse effect of non-uniform illumination, we propose defining spatial
information on the basis of image reflectance estimated with edge preserving
smoothing. Our method works particularly well for determining how the
background brightness should be adaptively adjusted and for revealing useful
image details hidden in the dark.",None,-1
dbb4112f-dde0-4ab8-a045-a484be13ed4d,Cross-Enhancement Transformer for Action Segmentation,0.329097,"Temporal convolutions have been the paradigm of choice in action
segmentation, which enhances long-term receptive fields by increasing
convolution layers. However, high layers cause the loss of local information
necessary for frame recognition. To solve the above problem, a novel
encoder-decoder structure is proposed in this paper, called Cross-Enhancement
Transformer. Our approach can be effective learning of temporal structure
representation with interactive self-attention mechanism. Concatenated each
layer convolutional feature maps in encoder with a set of features in decoder
produced via self-attention. Therefore, local and global information are used
in a series of frame actions simultaneously. In addition, a new loss function
is proposed to enhance the training process that penalizes over-segmentation
errors. Experiments show that our framework performs state-of-the-art on three
challenging datasets: 50Salads, Georgia Tech Egocentric Activities and the
Breakfast dataset.",None,-1
3c91e5f3-6677-4ef6-a6b2-3fbe1b9254f0,FairStyle: Debiasing StyleGAN2 with Style Channel Manipulations,0.487823,"Recent advances in generative adversarial networks have shown that it is
possible to generate high-resolution and hyperrealistic images. However, the
images produced by GANs are only as fair and representative as the datasets on
which they are trained. In this paper, we propose a method for directly
modifying a pre-trained StyleGAN2 model that can be used to generate a balanced
set of images with respect to one (e.g., eyeglasses) or more attributes (e.g.,
gender and eyeglasses). Our method takes advantage of the style space of the
StyleGAN2 model to perform disentangled control of the target attributes to be
debiased. Our method does not require training additional models and directly
debiases the GAN model, paving the way for its use in various downstream
applications. Our experiments show that our method successfully debiases the
GAN model within a few minutes without compromising the quality of the
generated images. To promote fair generative models, we share the code and
debiased models at http://catlab-team.github.io/fairstyle.",http://catlab-team.github.io/fairstyle,-1
e70aeb20-95a0-4b6e-83d5-d6441b2466af,Thin-Plate Spline Motion Model for Image Animation,0.99312,"Image animation brings life to the static object in the source image
according to the driving video. Recent works attempt to perform motion transfer
on arbitrary objects through unsupervised methods without using a priori
knowledge. However, it remains a significant challenge for current unsupervised
methods when there is a large pose gap between the objects in the source and
driving images. In this paper, a new end-to-end unsupervised motion transfer
framework is proposed to overcome such issue. Firstly, we propose thin-plate
spline motion estimation to produce a more flexible optical flow, which warps
the feature maps of the source image to the feature domain of the driving
image. Secondly, in order to restore the missing regions more realistically, we
leverage multi-resolution occlusion masks to achieve more effective feature
fusion. Finally, additional auxiliary loss functions are designed to ensure
that there is a clear division of labor in the network modules, encouraging the
network to generate high-quality images. Our method can animate a variety of
objects, including talking faces, human bodies, and pixel animations.
Experiments demonstrate that our method performs better on most benchmarks than
the state of the art with visible improvements in pose-related metrics.",https://github.com/yoyo-nb/Thin-Plate-Spline-Motion-Model,-1
83008a05-3ca4-4c63-94b7-384d5bc47094,Why is Winoground Hard? Investigating Failures in Visuolinguistic Compositionality,0.903804,"Recent visuolinguistic pre-trained models show promising progress on various
end tasks such as image retrieval and video captioning. Yet, they fail
miserably on the recently proposed Winoground dataset, which challenges models
to match paired images and English captions, with items constructed to overlap
lexically but differ in meaning (e.g., ""there is a mug in some grass"" vs.
""there is some grass in a mug""). By annotating the dataset using new
fine-grained tags, we show that solving the Winoground task requires not just
compositional language understanding, but a host of other abilities like
commonsense reasoning or locating small, out-of-focus objects in low-resolution
images. In this paper, we identify the dataset's main challenges through a
suite of experiments on related tasks (probing task, image retrieval task),
data augmentation, and manual inspection of the dataset. Our analysis suggests
that a main challenge in visuolinguistic models may lie in fusing visual and
textual representations, rather than in compositional language understanding.
We release our annotation and code at
https://github.com/ajd12342/why-winoground-hard .",https://github.com/ajd12342/why-winoground-hard,-1
940c059b-0f4d-4643-adb7-76caed4def65,"Who Pays? Personalization, Bossiness and the Cost of Fairness",0.211116,"Fairness-aware recommender systems that have a provider-side fairness concern
seek to ensure that protected group(s) of providers have a fair opportunity to
promote their items or products. There is a ``cost of fairness'' borne by the
consumer side of the interaction when such a solution is implemented. This
consumer-side cost raises its own questions of fairness, particularly when
personalization is used to control the impact of the fairness constraint. In
adopting a personalized approach to the fairness objective, researchers may be
opening their systems up to strategic behavior on the part of users. This type
of incentive has been studied in the computational social choice literature
under the terminology of ``bossiness''. The concern is that a bossy user may be
able to shift the cost of fairness to others, improving their own outcomes and
worsening those for others. This position paper introduces the concept of
bossiness, shows its application in fairness-aware recommendation and discusses
strategies for reducing this strategic incentive.",None,-1
542665b7-aaba-422d-8699-266f83d524b5,Anytime-Lidar: Deadline-aware 3D Object Detection,0.135511,"In this work, we present a novel scheduling framework enabling anytime
perception for deep neural network (DNN) based 3D object detection pipelines.
We focus on computationally expensive region proposal network (RPN) and
per-category multi-head detector components, which are common in 3D object
detection pipelines, and make them deadline-aware. We propose a scheduling
algorithm, which intelligently selects the subset of the components to make
effective time and accuracy trade-off on the fly. We minimize accuracy loss of
skipping some of the neural network sub-components by projecting previously
detected objects onto the current scene through estimations. We apply our
approach to a state-of-art 3D object detection network, PointPillars, and
evaluate its performance on Jetson Xavier AGX using nuScenes dataset. Compared
to the baselines, our approach significantly improve the network's accuracy
under various deadline constraints.",https://github.com/open-mmlab/OpenPCDet,-1
b7019aaf-3ac2-42a2-8f29-900559e2b5e5,Collective Relevance Labeling for Passage Retrieval,0.384779,"Deep learning for Information Retrieval (IR) requires a large amount of
high-quality query-document relevance labels, but such labels are inherently
sparse. Label smoothing redistributes some observed probability mass over
unobserved instances, often uniformly, uninformed of the true distribution. In
contrast, we propose knowledge distillation for informed labeling, without
incurring high computation overheads at evaluation time. Our contribution is
designing a simple but efficient teacher model which utilizes collective
knowledge, to outperform state-of-the-arts distilled from a more complex
teacher model. Specifically, we train up to x8 faster than the state-of-the-art
teacher, while distilling the rankings better. Our code is publicly available
at https://github.com/jihyukkim-nlp/CollectiveKD",https://github.com/jihyukkim-nlp/CollectiveKD,-1
a7aa2806-4616-4fb6-821c-e7a1e9f2c9e2,ExAIS: Executable AI Semantics,0.434321,"Neural networks can be regarded as a new programming paradigm, i.e., instead
of building ever-more complex programs through (often informal) logical
reasoning in the programmers' mind, complex 'AI' systems are built by
optimising generic neural network models with big data. In this new paradigm,
AI frameworks such as TensorFlow and PyTorch play a key role, which is as
essential as the compiler for traditional programs. It is known that the lack
of a proper semantics for programming languages (such as C), i.e., a
correctness specification for compilers, has contributed to many problematic
program behaviours and security issues. While it is in general hard to have a
correctness specification for compilers due to the high complexity of
programming languages and their rapid evolution, we have a unique opportunity
to do it right this time for neural networks (which have a limited set of
functions, and most of them have stable semantics). In this work, we report our
effort on providing a correctness specification of neural network frameworks
such as TensorFlow. We specify the semantics of almost all TensorFlow layers in
the logical programming language Prolog. We demonstrate the usefulness of the
semantics through two applications. One is a fuzzing engine for TensorFlow,
which features a strong oracle and a systematic way of generating valid neural
networks. The other is a model validation approach which enables consistent bug
reporting for TensorFlow models.",None,-1
91016dbd-841f-4c59-bef3-8722ded91e26,Trustworthy Autonomous Systems (TAS): Engaging TAS experts in curriculum design,0.624536,"Recent advances in artificial intelligence, specifically machine learning,
contributed positively to enhancing the autonomous systems industry, along with
introducing social, technical, legal and ethical challenges to make them
trustworthy. Although Trustworthy Autonomous Systems (TAS) is an established
and growing research direction that has been discussed in multiple disciplines,
e.g., Artificial Intelligence, Human-Computer Interaction, Law, and Psychology.
The impact of TAS on education curricula and required skills for future TAS
engineers has rarely been discussed in the literature. This study brings
together the collective insights from a number of TAS leading experts to
highlight significant challenges for curriculum design and potential TAS
required skills posed by the rapid emergence of TAS. Our analysis is of
interest not only to the TAS education community but also to other researchers,
as it offers ways to guide future research toward operationalising TAS
education.",None,-1
39a788bf-7bfa-480e-acb5-be8e99103f54,An Overview of Structural Coverage Metrics for Testing Neural Networks,0.402777,"Deep neural network (DNN) models, including those used in safety-critical
domains, need to be thoroughly tested to ensure that they can reliably perform
well in different scenarios. In this article, we provide an overview of
structural coverage metrics for testing DNN models, including neuron coverage
(NC), k-multisection neuron coverage (kMNC), top-k neuron coverage (TKNC),
neuron boundary coverage (NBC), strong neuron activation coverage (SNAC) and
modified condition/decision coverage (MC/DC). We evaluate the metrics on
realistic DNN models used for perception tasks (including LeNet-1, LeNet-4,
LeNet-5, and ResNet20) as well as on networks used in autonomy (TaxiNet). We
also provide a tool, DNNCov, which can measure the testing coverage for all
these metrics. DNNCov outputs an informative coverage report to enable
researchers and practitioners to assess the adequacy of DNN testing, compare
different coverage measures, and to more conveniently inspect the model's
internals during testing.",https://github.com/DNNCov/DNNCov,-1
c01ebe93-e254-4fe9-ba56-bb624bd5e9ed,Transforming Gait: Video-Based Spatiotemporal Gait Analysis,0.709089,"Human pose estimation from monocular video is a rapidly advancing field that
offers great promise to human movement science and rehabilitation. This
potential is tempered by the smaller body of work ensuring the outputs are
clinically meaningful and properly calibrated. Gait analysis, typically
performed in a dedicated lab, produces precise measurements including
kinematics and step timing. Using over 7000 monocular video from an
instrumented gait analysis lab, we trained a neural network to map 3D joint
trajectories and the height of individuals onto interpretable biomechanical
outputs including gait cycle timing and sagittal plane joint kinematics and
spatiotemporal trajectories. This task specific layer produces accurate
estimates of the timing of foot contact and foot off events. After parsing the
kinematic outputs into individual gait cycles, it also enables accurate
cycle-by-cycle estimates of cadence, step time, double and single support time,
walking speed and step length.",https://github.com/open-mmlab/mmpose,-1
9efe9995-107c-4fc0-b8b5-7b88f394925b,DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides,0.748379,"In the clinic, resected tissue samples are stained with Hematoxylin-and-Eosin
(H&E) and/or Immunhistochemistry (IHC) stains and presented to the pathologists
on glass slides or as digital scans for diagnosis and assessment of disease
progression. Cell-level quantification, e.g. in IHC protein expression scoring,
can be extremely inefficient and subjective. We present DeepLIIF
(https://deepliif.org), a first free online platform for efficient and
reproducible IHC scoring. DeepLIIF outperforms current state-of-the-art
approaches (relying on manual error-prone annotations) by virtually restaining
clinical IHC slides with more informative multiplex immunofluorescence
staining. Our DeepLIIF cloud-native platform supports (1) more than 150
proprietary/non-proprietary input formats via the Bio-Formats standard, (2)
interactive adjustment, visualization, and downloading of the IHC
quantification results and the accompanying restained images, (3) consumption
of an exposed workflow API programmatically or through interactive plugins for
open source whole slide image viewers such as QuPath/ImageJ, and (4) auto
scaling to efficiently scale GPU resources based on user demand.",https://github.com/nadeemlab/DeepLIIF,-1
550b8930-a30b-4a62-8d45-a899b7d8a64d,Mukayese: Turkish NLP Strikes Back,0.308904,"Having sufficient resources for language X lifts it from the under-resourced
languages class, but not necessarily from the under-researched class. In this
paper, we address the problem of the absence of organized benchmarks in the
Turkish language. We demonstrate that languages such as Turkish are left behind
the state-of-the-art in NLP applications. As a solution, we present Mukayese, a
set of NLP benchmarks for the Turkish language that contains several NLP tasks.
We work on one or more datasets for each benchmark and present two or more
baselines. Moreover, we present four new benchmarking datasets in Turkish for
language modeling, sentence segmentation, and spell checking. All datasets and
baselines are available under: https://github.com/alisafaya/mukayese",https://github.com/alisafaya/mukayese,-1
6692d910-faab-46ab-b76f-ac6559d35244,Breaking Bad News in the Era of Artificial Intelligence and Algorithmic Medicine: An Exploration of Disclosure and its Ethical Justification using the Hedonic Calculus,0.626236,"An appropriate ethical framework around the use of Artificial Intelligence
(AI) in healthcare has become a key desirable with the increasingly widespread
deployment of this technology. Advances in AI hold the promise of improving the
precision of outcome prediction at the level of the individual. However, the
addition of these technologies to patient-clinician interactions, as with any
complex human interaction, has potential pitfalls. While physicians have always
had to carefully consider the ethical background and implications of their
actions, detailed deliberations around fast-moving technological progress may
not have kept up. We use a common but key challenge in healthcare interactions,
the disclosure of bad news (likely imminent death), to illustrate how the
philosophical framework of the 'Felicific Calculus' developed in the 18th
century by Jeremy Bentham, may have a timely quasi-quantitative application in
the age of AI. We show how this ethical algorithm can be used to assess, across
seven mutually exclusive and exhaustive domains, whether an AI-supported action
can be morally justified.",None,-1
dc7d52ee-adb0-499a-8f0f-536ce9e9a472,Object-centric and memory-guided normality reconstruction for video anomaly detection,0.137219,"This paper addresses video anomaly detection problem for videosurveillance.
Due to the inherent rarity and heterogeneity of abnormal events, the problem is
viewed as a normality modeling strategy, in which our model learns
object-centric normal patterns without seeing anomalous samples during
training. The main contributions consist in coupling pretrained object-level
action features prototypes with a cosine distance-based anomaly estimation
function, therefore extending previous methods by introducing additional
constraints to the mainstream reconstruction-based strategy. Our framework
leverages both appearance and motion information to learn object-level behavior
and captures prototypical patterns within a memory module. Experiments on
several well-known datasets demonstrate the effectiveness of our method as it
outperforms current state-of-the-art on most relevant spatio-temporal
evaluation metrics.",None,-1
1628a6c0-1d9f-4558-a8ae-056a42b3676a,Label Sleuth: From Unlabeled Text to a Classifier in a Few Hours,0.424159,"Text classification can be useful in many real-world scenarios, saving a lot
of time for end users. However, building a custom classifier typically requires
coding skills and ML knowledge, which poses a significant barrier for many
potential users. To lift this barrier, we introduce Label Sleuth, a free open
source system for labeling and creating text classifiers. This system is unique
for (a) being a no-code system, making NLP accessible to non-experts, (b)
guiding users through the entire labeling process until they obtain a custom
classifier, making the process efficient -- from cold start to classifier in a
few hours, and (c) being open for configuration and extension by developers. By
open sourcing Label Sleuth we hope to build a community of users and developers
that will broaden the utilization of NLP models.",https://github.com/heartexlabs/label-studio,9733
5bdf465f-27c0-497a-9400-8e0a5d7e280c,Box2Seg: Learning Semantics of 3D Point Clouds with Box-Level Supervision,0.46582,"Learning dense point-wise semantics from unstructured 3D point clouds with
fewer labels, although a realistic problem, has been under-explored in
literature. While existing weakly supervised methods can effectively learn
semantics with only a small fraction of point-level annotations, we find that
the vanilla bounding box-level annotation is also informative for semantic
segmentation of large-scale 3D point clouds. In this paper, we introduce a
neural architecture, termed Box2Seg, to learn point-level semantics of 3D point
clouds with bounding box-level supervision. The key to our approach is to
generate accurate pseudo labels by exploring the geometric and topological
structure inside and outside each bounding box. Specifically, an
attention-based self-training (AST) technique and Point Class Activation
Mapping (PCAM) are utilized to estimate pseudo-labels. The network is further
trained and refined with pseudo labels. Experiments on two large-scale
benchmarks including S3DIS and ScanNet demonstrate the competitive performance
of the proposed method. In particular, the proposed network can be trained with
cheap, or even off-the-shelf bounding box-level annotations and subcloud-level
tags.",None,-1
4d3a4386-66e5-4624-950f-5e5a4cbba998,An Empirical Study on Disentanglement of Negative-free Contrastive Learning,0.432771,"Negative-free contrastive learning methods have attracted a lot of attention
with simplicity and impressive performances for large-scale pretraining.
However, its disentanglement property remains unexplored. In this paper, we
examine negative-free contrastive learning methods to study the disentanglement
property empirically. We find that existing disentanglement metrics fail to
make meaningful measurements for high-dimensional representation models, so we
propose a new disentanglement metric based on Mutual Information between latent
representations and data factors. With this proposed metric, we benchmark the
disentanglement property of negative-free contrastive learning on both popular
synthetic datasets and a real-world dataset CelebA. Our study shows that the
investigated methods can learn a well-disentangled subset of representation. As
far as we know, we are the first to extend the study of disentangled
representation learning to high-dimensional representation space and introduce
negative-free contrastive learning methods into this area. The source code of
this paper is available at
\url{https://github.com/noahcao/disentanglement_lib_med}.",https://github.com/noahcao/disentanglement_lib_med,-1
bbd6ba64-dad1-4a8d-9622-0a752b511b57,Uncertainty-aware deep learning methods for robust diabetic retinopathy classification,0.766631,"Automatic classification of diabetic retinopathy from retinal images has been
widely studied using deep neural networks with impressive results. However,
there is a clinical need for estimation of the uncertainty in the
classifications, a shortcoming of modern neural networks. Recently, approximate
Bayesian deep learning methods have been proposed for the task but the studies
have only considered the binary referable/non-referable diabetic retinopathy
classification applied to benchmark datasets. We present novel results by
systematically investigating a clinical dataset and a clinically relevant
5-class classification scheme, in addition to benchmark datasets and the binary
classification scheme. Moreover, we derive a connection between uncertainty
measures and classifier risk, from which we develop a new uncertainty measure.
We observe that the previously proposed entropy-based uncertainty measure
generalizes to the clinical dataset on the binary classification scheme but not
on the 5-class scheme, whereas our new uncertainty measure generalizes to the
latter case.",None,-1
bfa3f7d4-55a5-4041-811d-92c8fa47fcaa,Consultation Checklists: Standardising the Human Evaluation of Medical Note Generation,0.241696,"Evaluating automatically generated text is generally hard due to the
inherently subjective nature of many aspects of the output quality. This
difficulty is compounded in automatic consultation note generation by differing
opinions between medical experts both about which patient statements should be
included in generated notes and about their respective importance in arriving
at a diagnosis. Previous real-world evaluations of note-generation systems saw
substantial disagreement between expert evaluators. In this paper we propose a
protocol that aims to increase objectivity by grounding evaluations in
Consultation Checklists, which are created in a preliminary step and then used
as a common point of reference during quality assessment. We observed good
levels of inter-annotator agreement in a first evaluation study using the
protocol; further, using Consultation Checklists produced in the study as
reference for automatic metrics such as ROUGE or BERTScore improves their
correlation with human judgements compared to using the original human note.",None,-1
830213b7-3d8e-4077-994d-638b1a52c5f0,Hierarchical Conditional Variational Autoencoder Based Acoustic Anomaly Detection,0.172549,"This paper aims to develop an acoustic signal-based unsupervised anomaly
detection method for automatic machine monitoring. Existing approaches such as
deep autoencoder (DAE), variational autoencoder (VAE), conditional variational
autoencoder (CVAE) etc. have limited representation capabilities in the latent
space and, hence, poor anomaly detection performance. Different models have to
be trained for each different kind of machines to accurately perform the
anomaly detection task. To solve this issue, we propose a new method named as
hierarchical conditional variational autoencoder (HCVAE). This method utilizes
available taxonomic hierarchical knowledge about industrial facility to refine
the latent space representation. This knowledge helps model to improve the
anomaly detection performance as well. We demonstrated the generalization
capability of a single HCVAE model for different types of machines by using
appropriate conditions. Additionally, to show the practicability of the
proposed approach, (i) we evaluated HCVAE model on different domain and (ii) we
checked the effect of partial hierarchical knowledge. Our results show that
HCVAE method validates both of these points, and it outperforms the baseline
system on anomaly detection task by utmost 15 % on the AUC score metric.",None,-1
74703289-fef4-4dd0-8323-48d864e38538,Learning English with Peppa Pig,0.287925,"Recent computational models of the acquisition of spoken language via
grounding in perception exploit associations between the spoken and visual
modalities and learn to represent speech and visual data in a joint vector
space. A major unresolved issue from the point of ecological validity is the
training data, typically consisting of images or videos paired with spoken
descriptions of what is depicted. Such a setup guarantees an unrealistically
strong correlation between speech and the visual data. In the real world the
coupling between the linguistic and the visual modality is loose, and often
confounded by correlations with non-semantic aspects of the speech signal. Here
we address this shortcoming by using a dataset based on the children's cartoon
Peppa Pig. We train a simple bi-modal architecture on the portion of the data
consisting of dialog between characters, and evaluate on segments containing
descriptive narrations. Despite the weak and confounded signal in this training
data our model succeeds at learning aspects of the visual semantics of spoken
language.",https://github.com/gchrupala/peppa,-1
0faa3edf-4ae9-4e9d-a26e-3c33ac519993,Multi Task Learning For Zero Shot Performance Prediction of Multilingual Models,0.342084,"Massively Multilingual Transformer based Language Models have been observed
to be surprisingly effective on zero-shot transfer across languages, though the
performance varies from language to language depending on the pivot language(s)
used for fine-tuning. In this work, we build upon some of the existing
techniques for predicting the zero-shot performance on a task, by modeling it
as a multi-task learning problem. We jointly train predictive models for
different tasks which helps us build more accurate predictors for tasks where
we have test data in very few languages to measure the actual performance of
the model. Our approach also lends us the ability to perform a much more robust
feature selection and identify a common set of features that influence
zero-shot performance across a variety of tasks.",https://github.com/hichamjanati/mutar,4767
f33545cd-10de-4c2c-98aa-39dd38db3ccb,Neural Activation Patterns (NAPs): Visual Explainability of Learned Concepts,0.38801,"A key to deciphering the inner workings of neural networks is understanding
what a model has learned. Promising methods for discovering learned features
are based on analyzing activation values, whereby current techniques focus on
analyzing high activation values to reveal interesting features on a neuron
level. However, analyzing high activation values limits layer-level concept
discovery. We present a method that instead takes into account the entire
activation distribution. By extracting similar activation profiles within the
high-dimensional activation space of a neural network layer, we find groups of
inputs that are treated similarly. These input groups represent neural
activation patterns (NAPs) and can be used to visualize and interpret learned
layer concepts. We release a framework with which NAPs can be extracted from
pre-trained models and provide a visual introspection tool that can be used to
analyze NAPs. We tested our method with a variety of networks and show how it
complements existing methods for analyzing neural network activation values.",None,-1
e5a2fbb2-3512-451e-bff5-4734762f7af8,Scaling Laws Under the Microscope: Predicting Transformer Performance from Small Scale Experiments,0.230123,"Neural scaling laws define a predictable relationship between a model's
parameter count and its performance after training in the form of a power law.
However, most research to date has not explicitly investigated whether scaling
laws can be used to accelerate model development. In this work, we perform such
an empirical investigation across a wide range of language understanding tasks,
starting from models with as few as 10K parameters, and evaluate downstream
performance across 9 language understanding tasks. We find that scaling laws
emerge at finetuning time in some NLP tasks, and that they can also be
exploited for debugging convergence when training large models. Moreover, for
tasks where scaling laws exist, they can be used to predict the performance of
larger models, which enables effective model selection. However, revealing
scaling laws requires careful hyperparameter tuning and multiple runs for the
purpose of uncertainty estimation, which incurs additional overhead, partially
offsetting the computational benefits.",None,-1
d4d36e37-3fac-4970-9a64-9bbec6d92ca5,Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection,0.887628,"In some scenarios, classifier requires detecting out-of-distribution samples
far from its training data. With desirable characteristics, reconstruction
autoencoder-based methods deal with this problem by using input reconstruction
error as a metric of novelty vs. normality. We formulate the essence of such
approach as a quadruplet domain translation with an intrinsic bias to only
query for a proxy of conditional data uncertainty. Accordingly, an improvement
direction is formalized as maximumly compressing the autoencoder's latent space
while ensuring its reconstructive power for acting as a described domain
translator. From it, strategies are introduced including semantic
reconstruction, data certainty decomposition and normalized L2 distance to
substantially improve original methods, which together establish
state-of-the-art performance on various benchmarks, e.g., the FPR@95%TPR of
CIFAR-100 vs. TinyImagenet-crop on Wide-ResNet is 0.2%. Importantly, our method
works without any additional data, hard-to-implement structure, time-consuming
pipeline, and even harming the classification accuracy of known classes.",https://github.com/xxx,-1
ebb4ccb3-fcda-46a6-b985-6e5aed85ba05,Statistical guarantees for sparse deep learning,0.53075,"Neural networks are becoming increasingly popular in applications, but our
mathematical understanding of their potential and limitations is still limited.
In this paper, we further this understanding by developing statistical
guarantees for sparse deep learning. In contrast to previous work, we consider
different types of sparsity, such as few active connections, few active nodes,
and other norm-based types of sparsity. Moreover, our theories cover important
aspects that previous theories have neglected, such as multiple outputs,
regularization, and l2-loss. The guarantees have a mild dependence on network
widths and depths, which means that they support the application of sparse but
wide and deep networks from a statistical perspective. Some of the concepts and
tools that we use in our derivations are uncommon in deep learning and, hence,
might be of additional interest.",None,-1
4b9719cf-801e-4942-9516-6a68ac9260e0,Inkorrect: Online Handwriting Spelling Correction,0.506327,"We introduce Inkorrect, a data- and label-efficient approach for online
handwriting (Digital Ink) spelling correction - DISC. Unlike previous work, the
proposed method does not require multiple samples from the same writer, or
access to character level segmentation. We show that existing automatic
evaluation metrics do not fully capture and are not correlated with the human
perception of the quality of the spelling correction, and propose new ones that
correlate with human perception. We additionally surface an interesting
phenomenon: a trade-off between the similarity and recognizability of the
spell-corrected inks. We further create a family of models corresponding to
different points on the Pareto frontier between those two axes. We show that
Inkorrect's Pareto frontier dominates the points that correspond to prior work.",None,-1
8282a19d-b809-4c5d-bc22-13c8c21492cc,CamoFormer: Masked Separable Attention for Camouflaged Object Detection,0.623977,"How to identify and segment camouflaged objects from the background is
challenging. Inspired by the multi-head self-attention in Transformers, we
present a simple masked separable attention (MSA) for camouflaged object
detection. We first separate the multi-head self-attention into three parts,
which are responsible for distinguishing the camouflaged objects from the
background using different mask strategies. Furthermore, we propose to capture
high-resolution semantic representations progressively based on a simple
top-down decoder with the proposed MSA to attain precise segmentation results.
These structures plus a backbone encoder form a new model, dubbed CamoFormer.
Extensive experiments show that CamoFormer surpasses all existing
state-of-the-art methods on three widely-used camouflaged object detection
benchmarks. There are on average around 5% relative improvements over previous
methods in terms of S-measure and weighted F-measure.",https://github.com/HVision-NKU/CamoFormer,-1
3c2306a9-354a-4dd0-9037-708ea5bcbd19,Discriminator-Cooperated Feature Map Distillation for GAN Compression,0.184085,"Despite excellent performance in image generation, Generative Adversarial
Networks (GANs) are notorious for its requirements of enormous storage and
intensive computation. As an awesome ''performance maker'', knowledge
distillation is demonstrated to be particularly efficacious in exploring
low-priced GANs. In this paper, we investigate the irreplaceability of teacher
discriminator and present an inventive discriminator-cooperated distillation,
abbreviated as DCD, towards refining better feature maps from the generator. In
contrast to conventional pixel-to-pixel match methods in feature map
distillation, our DCD utilizes teacher discriminator as a transformation to
drive intermediate results of the student generator to be perceptually close to
corresponding outputs of the teacher generator. Furthermore, in order to
mitigate mode collapse in GAN compression, we construct a collaborative
adversarial training paradigm where the teacher discriminator is from scratch
established to co-train with student generator in company with our DCD. Our DCD
shows superior results compared with existing GAN compression methods. For
instance, after reducing over 40x MACs and 80x parameters of CycleGAN, we well
decrease FID metric from 61.53 to 48.24 while the current SoTA method merely
has 51.92. This work's source code has been made accessible at
https://github.com/poopit/DCD-official.",https://github.com/poopit/DCD-official,-1
9be675ea-6d0f-4618-a5fe-900d28df1d13,CQR-SQL: Conversational Question Reformulation Enhanced Context-Dependent Text-to-SQL Parsers,0.539693,"Context-dependent text-to-SQL is the task of translating multi-turn questions
into database-related SQL queries. Existing methods typically focus on making
full use of history context or previously predicted SQL for currently SQL
parsing, while neglecting to explicitly comprehend the schema and
conversational dependency, such as co-reference, ellipsis and user focus
change. In this paper, we propose CQR-SQL, which uses auxiliary Conversational
Question Reformulation (CQR) learning to explicitly exploit schema and decouple
contextual dependency for SQL parsing. Specifically, we first present a schema
enhanced recursive CQR method to produce domain-relevant self-contained
questions. Secondly, we train CQR-SQL models to map the semantics of multi-turn
questions and auxiliary self-contained questions into the same latent space
through schema grounding consistency task and tree-structured SQL parsing
consistency task, which enhances the abilities of SQL parsing by adequately
contextual understanding. At the time of writing, our CQR-SQL achieves new
state-of-the-art results on two context-dependent text-to-SQL benchmarks SParC
and CoSQL.",None,-1
10679ec2-aa79-4f98-a3fd-d99e613d2ce6,Rethinking Graph Convolutional Networks in Knowledge Graph Completion,0.876026,"Graph convolutional networks (GCNs) -- which are effective in modeling graph
structures -- have been increasingly popular in knowledge graph completion
(KGC). GCN-based KGC models first use GCNs to generate expressive entity
representations and then use knowledge graph embedding (KGE) models to capture
the interactions among entities and relations. However, many GCN-based KGC
models fail to outperform state-of-the-art KGE models though introducing
additional computational complexity. This phenomenon motivates us to explore
the real effect of GCNs in KGC. Therefore, in this paper, we build upon
representative GCN-based KGC models and introduce variants to find which factor
of GCNs is critical in KGC. Surprisingly, we observe from experiments that the
graph structure modeling in GCNs does not have a significant impact on the
performance of KGC models, which is in contrast to the common belief. Instead,
the transformations for entity representations are responsible for the
performance improvements. Based on the observation, we propose a simple yet
effective framework named LTE-KGE, which equips existing KGE models with
linearly transformed entity embeddings. Experiments demonstrate that LTE-KGE
models lead to similar performance improvements with GCN-based KGC methods,
while being more computationally efficient. These results suggest that existing
GCNs are unnecessary for KGC, and novel GCN-based KGC models should count on
more ablation studies to validate their effectiveness. The code of all the
experiments is available on GitHub at https://github.com/MIRALab-USTC/GCN4KGC.",https://github.com/MIRALab-USTC/GCN4KGC,2225
04eeac76-33f7-4b7e-834a-d14aef58b9f0,Efficient Feedback and Partial Credit Grading for Proof Blocks Problems,0.121118,"Proof Blocks is a software tool that allows students to practice writing
mathematical proofs by dragging and dropping lines instead of writing proofs
from scratch. Proof Blocks offers the capability of assigning partial credit
and providing solution quality feedback to students. This is done by computing
the edit distance from a student's submission to some predefined set of
solutions. In this work, we propose an algorithm for the edit distance problem
that significantly outperforms the baseline procedure of exhaustively
enumerating over the entire search space. Our algorithm relies on a reduction
to the minimum vertex cover problem. We benchmark our algorithm on thousands of
student submissions from multiple courses, showing that the baseline algorithm
is intractable, and that our proposed algorithm is critical to enable classroom
deployment. Our new algorithm has also been used for problems in many other
domains where the solution space can be modeled as a DAG, including but not
limited to Parsons Problems for writing code, helping students understand
packet ordering in networking protocols, and helping students sketch solution
steps for physics problems. Integrated into multiple learning management
systems, the algorithm serves thousands of students each year.",None,-1
2ce4fa10-7507-4b12-b50a-56945a31b482,Data-Efficient Backdoor Attacks,0.829504,"Recent studies have proven that deep neural networks are vulnerable to
backdoor attacks. Specifically, by mixing a small number of poisoned samples
into the training set, the behavior of the trained model can be maliciously
controlled. Existing attack methods construct such adversaries by randomly
selecting some clean data from the benign set and then embedding a trigger into
them. However, this selection strategy ignores the fact that each poisoned
sample contributes inequally to the backdoor injection, which reduces the
efficiency of poisoning. In this paper, we formulate improving the poisoned
data efficiency by the selection as an optimization problem and propose a
Filtering-and-Updating Strategy (FUS) to solve it. The experimental results on
CIFAR-10 and ImageNet-10 indicate that the proposed method is effective: the
same attack success rate can be achieved with only 47% to 75% of the poisoned
sample volume compared to the random selection strategy. More importantly, the
adversaries selected according to one setting can generalize well to other
settings, exhibiting strong transferability. The prototype code of our method
is now available at https://github.com/xpf/Data-Efficient-Backdoor-Attacks.",https://github.com/xpf/Data-Efﬁcient-Backdoor-Attacks,175520
7382bcf5-7fee-483e-83b0-f46c15c20ce8,MMNet: Muscle motion-guided network for micro-expression recognition,0.754336,"Facial micro-expressions (MEs) are involuntary facial motions revealing
peoples real feelings and play an important role in the early intervention of
mental illness, the national security, and many human-computer interaction
systems. However, existing micro-expression datasets are limited and usually
pose some challenges for training good classifiers. To model the subtle facial
muscle motions, we propose a robust micro-expression recognition (MER)
framework, namely muscle motion-guided network (MMNet). Specifically, a
continuous attention (CA) block is introduced to focus on modeling local subtle
muscle motion patterns with little identity information, which is different
from most previous methods that directly extract features from complete video
frames with much identity information. Besides, we design a position
calibration (PC) module based on the vision transformer. By adding the position
embeddings of the face generated by PC module at the end of the two branches,
the PC module can help to add position information to facial muscle motion
pattern features for the MER. Extensive experiments on three public
micro-expression datasets demonstrate that our approach outperforms
state-of-the-art methods by a large margin.",https://github.com/muse1998/MMNet,-1
4c95bfd6-83ed-4297-8cf5-b37a688e6c50,Real3D-Aug: Point Cloud Augmentation by Placing Real Objects with Occlusion Handling for 3D Detection and Segmentation,0.133501,"Object detection and semantic segmentation with the 3D lidar point cloud data
require expensive annotation. We propose a data augmentation method that takes
advantage of already annotated data multiple times. We propose an augmentation
framework that reuses real data, automatically finds suitable placements in the
scene to be augmented, and handles occlusions explicitly. Due to the usage of
the real data, the scan points of newly inserted objects in augmentation
sustain the physical characteristics of the lidar, such as intensity and
raydrop. The pipeline proves competitive in training top-performing models for
3D object detection and semantic segmentation. The new augmentation provides a
significant performance gain in rare and essential classes, notably 6.65%
average precision gain for ""Hard"" pedestrian class in KITTI object detection or
2.14 mean IoU gain in the SemanticKITTI segmentation challenge over the state
of the art.",https://github.com/ctu-vras/,-1
7b5fb4cc-5f1b-4ab7-845f-64fe524b2ec0,AsPOS: Assamese Part of Speech Tagger using Deep Learning Approach,0.534173,"Part of Speech (POS) tagging is crucial to Natural Language Processing (NLP).
It is a well-studied topic in several resource-rich languages. However, the
development of computational linguistic resources is still in its infancy
despite the existence of numerous languages that are historically and literary
rich. Assamese, an Indian scheduled language, spoken by more than 25 million
people, falls under this category. In this paper, we present a Deep Learning
(DL)-based POS tagger for Assamese. The development process is divided into two
stages. In the first phase, several pre-trained word embeddings are employed to
train several tagging models. This allows us to evaluate the performance of the
word embeddings in the POS tagging task. The top-performing model from the
first phase is employed to annotate another set of new sentences. In the second
phase, the model is trained further using the fresh dataset. Finally, we attain
a tagging accuracy of 86.52% in F1 score. The model may serve as a baseline for
further study on DL-based Assamese POS tagging.",None,-1
33c2bdb9-08ad-4613-b46c-a37812cac3c2,Improving Sentiment Analysis By Emotion Lexicon Approach on Vietnamese Texts,0.304787,"The sentiment analysis task has various applications in practice. In the
sentiment analysis task, words and phrases that represent positive and negative
emotions are important. Finding out the words that represent the emotion from
the text can improve the performance of the classification models for the
sentiment analysis task. In this paper, we propose a methodology that combines
the emotion lexicon with the classification model to enhance the accuracy of
the models. Our experimental results show that the emotion lexicon combined
with the classification model improves the performance of models.",None,-1
014d8d85-0a9a-40e0-bb47-c3f5b61d1266,Promises and Pitfalls of Threshold-based Auto-labeling,0.538742,"Creating large-scale high-quality labeled datasets is a major bottleneck in
supervised machine learning workflows. Threshold-based auto-labeling (TBAL),
where validation data obtained from humans is used to find a confidence
threshold above which the data is machine-labeled, reduces reliance on manual
annotation. TBAL is emerging as a widely-used solution in practice. Given the
long shelf-life and diverse usage of the resulting datasets, understanding when
the data obtained by such auto-labeling systems can be relied on is crucial.
This is the first work to analyze TBAL systems and derive sample complexity
bounds on the amount of human-labeled validation data required for guaranteeing
the quality of machine-labeled data. Our results provide two crucial insights.
First, reasonable chunks of unlabeled data can be automatically and accurately
labeled by seemingly bad models. Second, a hidden downside of TBAL systems is
potentially prohibitive validation data usage. Together, these insights
describe the promise and pitfalls of using such systems. We validate our
theoretical guarantees with extensive experiments on synthetic and real
datasets.",https://github.com/harit7/TBAL,-1
60fd210e-d2a6-4fc1-8511-8bb39ac457b0,Multimodal data matters: language model pre-training over structured and unstructured electronic health records,0.473879,"As two important textual modalities in electronic health records (EHR), both
structured data (clinical codes) and unstructured data (clinical narratives)
have recently been increasingly applied to the healthcare domain. Most existing
EHR-oriented studies, however, either focus on a particular modality or
integrate data from different modalities in a straightforward manner, which
usually treats structured and unstructured data as two independent sources of
information about patient admission and ignore the intrinsic interactions
between them. In fact, the two modalities are documented during the same
encounter where structured data inform the documentation of unstructured data
and vice versa. In this paper, we proposed a Medical Multimodal Pre-trained
Language Model, named MedM-PLM, to learn enhanced EHR representations over
structured and unstructured data and explore the interaction of two modalities.
In MedM-PLM, two Transformer-based neural network components are firstly
adopted to learn representative characteristics from each modality. A
cross-modal module is then introduced to model their interactions. We
pre-trained MedM-PLM on the MIMIC-III dataset and verified the effectiveness of
the model on three downstream clinical tasks, i.e., medication recommendation,
30-day readmission prediction and ICD coding. Extensive experiments demonstrate
the power of MedM-PLM compared with state-of-the-art methods. Further analyses
and visualizations show the robustness of our model, which could potentially
provide more comprehensive interpretations for clinical decision-making.",https://git.openi.org.cn/liusc/3-6-li-usicen-multi-modal-pretrain,-1
95b8d517-5984-462b-b196-01c1a1c68614,Semantic optical fiber communication system,0.572202,"The current optical communication systems minimize bit or symbol errors
without considering the semantic meaning behind digital bits, thus transmitting
a lot of unnecessary information. We propose and experimentally demonstrate a
semantic optical fiber communication (SOFC) system. Instead of encoding
information into bits for transmission, semantic information is extracted from
the source using deep learning. The generated semantic symbols are then
directly transmitted through an optical fiber. Compared with the bit-based
structure, the SOFC system achieved higher information compression and a more
stable performance, especially in the low received optical power regime, and
enhanced the robustness against optical link impairments. This work introduces
an intelligent optical communication system at the human analytical thinking
level, which is a significant step toward a breakthrough in the current optical
communication architecture.",None,-1
bf4ad32c-6289-479e-99db-6f903f3bbf0b,CoNSoLe: Convex Neural Symbolic Learning,0.517945,"Learning the underlying equation from data is a fundamental problem in many
disciplines. Recent advances rely on Neural Networks (NNs) but do not provide
theoretical guarantees in obtaining the exact equations owing to the
non-convexity of NNs. In this paper, we propose Convex Neural Symbolic Learning
(CoNSoLe) to seek convexity under mild conditions. The main idea is to
decompose the recovering process into two steps and convexify each step. In the
first step of searching for right symbols, we convexify the deep Q-learning.
The key is to maintain double convexity for both the negative Q-function and
the negative reward function in each iteration, leading to provable convexity
of the negative optimal Q function to learn the true symbol connections.
Conditioned on the exact searching result, we construct a Locally Convex
equation Learner (LoCaL) neural network to convexify the estimation of symbol
coefficients. With such a design, we quantify a large region with strict
convexity in the loss surface of LoCaL for commonly used physical functions.
Finally, we demonstrate the superior performance of the CoNSoLe framework over
the state-of-the-art on a diverse set of datasets.",None,-1
9eddd61c-0380-4749-95a4-845534ee0377,L3Cube-MahaHate: A Tweet-based Marathi Hate Speech Detection Dataset and BERT models,0.919792,"Social media platforms are used by a large number of people prominently to
express their thoughts and opinions. However, these platforms have contributed
to a substantial amount of hateful and abusive content as well. Therefore, it
is important to curb the spread of hate speech on these platforms. In India,
Marathi is one of the most popular languages used by a wide audience. In this
work, we present L3Cube-MahaHate, the first major Hate Speech Dataset in
Marathi. The dataset is curated from Twitter, annotated manually. Our dataset
consists of over 25000 distinct tweets labeled into four major classes i.e
hate, offensive, profane, and not. We present the approaches used for
collecting and annotating the data and the challenges faced during the process.
Finally, we present baseline classification results using deep learning models
based on CNN, LSTM, and Transformers. We explore mono-lingual and multi-lingual
variants of BERT like MahaBERT, IndicBERT, mBERT, and xlm-RoBERTa and show that
mono-lingual models perform better than their multi-lingual counterparts. The
MahaBERT model provides the best results on L3Cube-MahaHate Corpus. The data
and models are available at https://github.com/l3cube-pune/MarathiNLP .",https://github.com/l3cube-pune/MarathiNLP,-1
b0f45728-7b08-48d3-84bc-76e0bce257f6,Auction-Based Ex-Post-Payment Incentive Mechanism Design for Horizontal Federated Learning with Reputation and Contribution Measurement,0.337991,"Federated learning trains models across devices with distributed data, while
protecting the privacy and obtaining a model similar to that of centralized ML.
A large number of workers with data and computing power are the foundation of
federal learning. However, the inevitable costs prevent self-interested workers
from serving for free. Moreover, due to data isolation, task publishers lack
effective methods to select, evaluate and pay reliable workers with
high-quality data. Therefore, we design an auction-based incentive mechanism
for horizontal federated learning with reputation and contribution measurement.
By designing a reasonable method of measuring contribution, we establish the
reputation of workers, which is easy to decline and difficult to improve.
Through reverse auctions, workers bid for tasks, and the task publisher selects
workers combining reputation and bid price. With the budget constraint, winning
workers are paid based on performance. We proved that our mechanism satisfies
the individual rationality of the honest worker, budget feasibility,
truthfulness, and computational efficiency.",None,-1
d99e72aa-09a7-4c18-a128-392c3c8a178f,Memory-free Online Change-point Detection: A Novel Neural Network Approach,0.747131,"Change-point detection (CPD), which detects abrupt changes in the data
distribution, is recognized as one of the most significant tasks in time series
analysis. Despite the extensive literature on offline CPD, unsupervised online
CPD still suffers from major challenges, including scalability, hyperparameter
tuning, and learning constraints. To mitigate some of these challenges, in this
paper, we propose a novel deep learning approach for unsupervised online CPD
from multi-dimensional time series, named Adaptive LSTM-Autoencoder
Change-Point Detection (ALACPD). ALACPD exploits an LSTM-autoencoder-based
neural network to perform unsupervised online CPD. It continuously adapts to
the incoming samples without keeping the previously received input, thus being
memory-free. We perform an extensive evaluation on several real-world time
series CPD benchmarks. We show that ALACPD, on average, ranks first among
state-of-the-art CPD algorithms in terms of quality of the time series
segmentation, and it is on par with the best performer in terms of the accuracy
of the estimated change-points. The implementation of ALACPD is available
online on Github\footnote{\url{https://github.com/zahraatashgahi/ALACPD}}.",https://github.com/zahraatashgahi/ALACPD,-1
de5afe43-15e3-42cc-b0c5-1a0404f4aa58,RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering,0.500266,"Finding accurate correspondences among different views is the Achilles' heel
of unsupervised Multi-View Stereo (MVS). Existing methods are built upon the
assumption that corresponding pixels share similar photometric features.
However, multi-view images in real scenarios observe non-Lambertian surfaces
and experience occlusions. In this work, we propose a novel approach with
neural rendering (RC-MVSNet) to solve such ambiguity issues of correspondences
among views. Specifically, we impose a depth rendering consistency loss to
constrain the geometry features close to the object surface to alleviate
occlusions. Concurrently, we introduce a reference view synthesis loss to
generate consistent supervision, even for non-Lambertian surfaces. Extensive
experiments on DTU and Tanks\&Temples benchmarks demonstrate that our RC-MVSNet
approach achieves state-of-the-art performance over unsupervised MVS frameworks
and competitive performance to many supervised methods.The code is released at
https://github.com/Boese0601/RC-MVSNet",https://github.com/Boese0601/RC-MVSNet,-1
380cc7d7-f50d-4451-b60b-d15bc25a2160,LargeKernel3D: Scaling up Kernels in 3D Sparse CNNs,0.806713,"Recent advance in 2D CNNs has revealed that large kernels are important.
However, when directly applying large convolutional kernels in 3D CNNs, severe
difficulties are met, where those successful module designs in 2D become
surprisingly ineffective on 3D networks, including the popular depth-wise
convolution. To address this vital challenge, we instead propose the
spatial-wise partition convolution and its large-kernel module. As a result, it
avoids the optimization and efficiency issues of naive 3D large kernels. Our
large-kernel 3D CNN network, LargeKernel3D, yields notable improvement in 3D
tasks of semantic segmentation and object detection. It achieves 73.9% mIoU on
the ScanNetv2 semantic segmentation and 72.8% NDS nuScenes object detection
benchmarks, ranking 1st on the nuScenes LIDAR leaderboard. The performance
further boosts to 74.2% NDS with a simple multi-modal fusion. In addition,
LargeKernel3D can be scaled to 17x17x17 kernel size on Waymo 3D object
detection. For the first time, we show that large kernels are feasible and
essential for 3D visual tasks.",https://github.com/dvlab-research/LargeKernel3D,306651
fa0281c7-59ec-4db8-9f0f-827629b828f0,GRiT: A Generative Region-to-text Transformer for Object Understanding,0.997571,"This paper presents a Generative RegIon-to-Text transformer, GRiT, for object
understanding. The spirit of GRiT is to formulate object understanding as
<region, text> pairs, where region locates objects and text describes objects.
For example, the text in object detection denotes class names while that in
dense captioning refers to descriptive sentences. Specifically, GRiT consists
of a visual encoder to extract image features, a foreground object extractor to
localize objects, and a text decoder to generate open-set object descriptions.
With the same model architecture, GRiT can understand objects via not only
simple nouns, but also rich descriptive sentences including object attributes
or actions. Experimentally, we apply GRiT to object detection and dense
captioning tasks. GRiT achieves 60.4 AP on COCO 2017 test-dev for object
detection and 15.5 mAP on Visual Genome for dense captioning. Code is available
at https://github.com/JialianW/GRiT",https://github.com/JialianW/GRiT,-1
1975baeb-d65f-45f1-8fec-63388da2fde7,Exploration of the possibility of infusing Social Media Trends into generating NFT Recommendations,0.459618,"Recommendations Systems have been identified to be one of the integral
elements of driving sales in e-commerce sites. The utilization of opinion
mining data extracted from trends has been attempted to improve the
recommendations that can be provided by baseline methods in this research when
user-click data is lacking or is difficult to be collected due to privacy
concerns.
  Utilizing social trends to influence the recommendations generated for a set
of unique items has been explored with the use of a suggested scoring
mechanism. Embracing concepts from decentralized networks that are expected to
change how users interact via the internet over the next couple of decades, the
suggested Recommendations System attempts to make use of multiple sources of
information, applying coherent information retrieval techniques to extract
probable trending items.
  The proposed Recommendations Architecture in the research presents a method
to integrate social trends with recommendations to produce promising outputs.",None,-1
edab5509-eb91-492a-bf0e-73c5752baa15,Robust $Q$-learning Algorithm for Markov Decision Processes under Wasserstein Uncertainty,0.885303,"We present a novel $Q$-learning algorithm to solve distributionally robust
Markov decision problems, where the corresponding ambiguity set of transition
probabilities for the underlying Markov decision process is a Wasserstein ball
around a (possibly estimated) reference measure. We prove convergence of the
presented algorithm and provide several examples also using real data to
illustrate both the tractability of our algorithm as well as the benefits of
considering distributional robustness when solving stochastic optimal control
problems, in particular when the estimated distributions turn out to be
misspecified in practice.",https://github.com/juliansester/Wasserstein-Q-learning,-1
9eb1045c-724a-4b5c-a6f5-2c1d139058e5,GeoSegNet: Point Cloud Semantic Segmentation via Geometric Encoder-Decoder Modeling,0.247484,"Semantic segmentation of point clouds, aiming to assign each point a semantic
category, is critical to 3D scene understanding.Despite of significant advances
in recent years, most of existing methods still suffer from either the
object-level misclassification or the boundary-level ambiguity. In this paper,
we present a robust semantic segmentation network by deeply exploring the
geometry of point clouds, dubbed GeoSegNet. Our GeoSegNet consists of a
multi-geometry based encoder and a boundary-guided decoder. In the encoder, we
develop a new residual geometry module from multi-geometry perspectives to
extract object-level features. In the decoder, we introduce a contrastive
boundary learning module to enhance the geometric representation of boundary
points. Benefiting from the geometric encoder-decoder modeling, our GeoSegNet
can infer the segmentation of objects effectively while making the
intersections (boundaries) of two or more objects clear. Experiments show
obvious improvements of our method over its competitors in terms of the overall
segmentation accuracy and object boundary clearness. Code is available at
https://github.com/Chen-yuiyui/GeoSegNet.",https://github.com/Chen-yuiyui/GeoSegNet,-1
1b89ad2a-1527-4c79-af30-ed1e75acdfee,Chunk-based Nearest Neighbor Machine Translation,0.837577,"Semi-parametric models, which augment generation with retrieval, have led to
impressive results in language modeling and machine translation, due to their
ability to retrieve fine-grained information from a datastore of examples. One
of the most prominent approaches, $k$NN-MT, exhibits strong domain adaptation
capabilities by retrieving tokens from domain-specific datastores
\citep{khandelwal2020nearest}. However, $k$NN-MT requires an expensive
retrieval operation for every single generated token, leading to a very low
decoding speed (around 8 times slower than a parametric model). In this paper,
we introduce a \textit{chunk-based} $k$NN-MT model which retrieves chunks of
tokens from the datastore, instead of a single token. We propose several
strategies for incorporating the retrieved chunks into the generation process,
and for selecting the steps at which the model needs to search for neighbors in
the datastore. Experiments on machine translation in two settings, static and
``on-the-fly'' domain adaptation, show that the chunk-based $k$NN-MT model
leads to significant speed-ups (up to 4 times) with only a small drop in
translation quality.",https://github.com/deep-spin/chunk-based_knn-mt,-1
1acccb0b-93eb-4771-aea2-227bf82b7b5d,SSformer: A Lightweight Transformer for Semantic Segmentation,0.212154,"It is well believed that Transformer performs better in semantic segmentation
compared to convolutional neural networks. Nevertheless, the original Vision
Transformer may lack of inductive biases of local neighborhoods and possess a
high time complexity. Recently, Swin Transformer sets a new record in various
vision tasks by using hierarchical architecture and shifted windows while being
more efficient. However, as Swin Transformer is specifically designed for image
classification, it may achieve suboptimal performance on dense prediction-based
segmentation task. Further, simply combing Swin Transformer with existing
methods would lead to the boost of model size and parameters for the final
segmentation model. In this paper, we rethink the Swin Transformer for semantic
segmentation, and design a lightweight yet effective transformer model, called
SSformer. In this model, considering the inherent hierarchical design of Swin
Transformer, we propose a decoder to aggregate information from different
layers, thus obtaining both local and global attentions. Experimental results
show the proposed SSformer yields comparable mIoU performance with
state-of-the-art models, while maintaining a smaller model size and lower
compute.",https://github.com/shiwt03/SSformer,4373
9fabc5dd-2441-4100-8c47-8d1697cb97c6,SmartBrush: Text and Shape Guided Object Inpainting with Diffusion Model,0.873921,"Generic image inpainting aims to complete a corrupted image by borrowing
surrounding information, which barely generates novel content. By contrast,
multi-modal inpainting provides more flexible and useful controls on the
inpainted content, \eg, a text prompt can be used to describe an object with
richer attributes, and a mask can be used to constrain the shape of the
inpainted object rather than being only considered as a missing area. We
propose a new diffusion-based model named SmartBrush for completing a missing
region with an object using both text and shape-guidance. While previous work
such as DALLE-2 and Stable Diffusion can do text-guided inapinting they do not
support shape guidance and tend to modify background texture surrounding the
generated object. Our model incorporates both text and shape guidance with
precision control. To preserve the background better, we propose a novel
training and sampling strategy by augmenting the diffusion U-net with
object-mask prediction. Lastly, we introduce a multi-task training strategy by
jointly training inpainting with text-to-image generation to leverage more
training data. We conduct extensive experiments showing that our model
outperforms all baselines in terms of visual quality, mask controllability, and
background preservation.",https://github.com/CompVis/stable-diffusion,-1
3bc98672-f6e1-4502-92ef-50d001b8c2d7,Consent as a Foundation for Responsible Autonomy,0.692958,"This paper focuses on a dynamic aspect of responsible autonomy, namely, to
make intelligent agents be responsible at run time. That is, it considers
settings where decision making by agents impinges upon the outcomes perceived
by other agents. For an agent to act responsibly, it must accommodate the
desires and other attitudes of its users and, through other agents, of their
users.
  The contribution of this paper is twofold. First, it provides a conceptual
analysis of consent, its benefits and misuses, and how understanding consent
can help achieve responsible autonomy. Second, it outlines challenges for AI
(in particular, for agents and multiagent systems) that merit investigation to
form as a basis for modeling consent in multiagent systems and applying consent
to achieve responsible autonomy.",None,31895
142d3b66-481f-4d57-946c-9b733e3d4e07,InstructPix2Pix: Learning to Follow Image Editing Instructions,1.0,"We propose a method for editing images from human instructions: given an
input image and a written instruction that tells the model what to do, our
model follows these instructions to edit the image. To obtain training data for
this problem, we combine the knowledge of two large pretrained models -- a
language model (GPT-3) and a text-to-image model (Stable Diffusion) -- to
generate a large dataset of image editing examples. Our conditional diffusion
model, InstructPix2Pix, is trained on our generated data, and generalizes to
real images and user-written instructions at inference time. Since it performs
edits in the forward pass and does not require per example fine-tuning or
inversion, our model edits images quickly, in a matter of seconds. We show
compelling editing results for a diverse collection of input images and written
instructions.",None,-1
9d288137-dc71-40fd-a8d2-0e0eb6657e75,Modeling Temporal-Modal Entity Graph for Procedural Multimodal Machine Comprehension,0.232142,"Procedural Multimodal Documents (PMDs) organize textual instructions and
corresponding images step by step. Comprehending PMDs and inducing their
representations for the downstream reasoning tasks is designated as Procedural
MultiModal Machine Comprehension (M3C). In this study, we approach Procedural
M3C at a fine-grained level (compared with existing explorations at a document
or sentence level), that is, entity. With delicate consideration, we model
entity both in its temporal and cross-modal relation and propose a novel
Temporal-Modal Entity Graph (TMEG). Specifically, graph structure is formulated
to capture textual and visual entities and trace their temporal-modal
evolution. In addition, a graph aggregation module is introduced to conduct
graph encoding and reasoning. Comprehensive experiments across three Procedural
M3C tasks are conducted on a traditional dataset RecipeQA and our new dataset
CraftQA, which can better evaluate the generalization of TMEG.",None,-1
6753d340-f144-4892-a1db-5abd890b68a1,A Robust Bias Mitigation Procedure Based on the Stereotype Content Model,0.270163,"The Stereotype Content model (SCM) states that we tend to perceive minority
groups as cold, incompetent or both. In this paper we adapt existing work to
demonstrate that the Stereotype Content model holds for contextualised word
embeddings, then use these results to evaluate a fine-tuning process designed
to drive a language model away from stereotyped portrayals of minority groups.
We find the SCM terms are better able to capture bias than demographic agnostic
terms related to pleasantness. Further, we were able to reduce the presence of
stereotypes in the model through a simple fine-tuning procedure that required
minimal human and computer resources, without harming downstream performance.
We present this work as a prototype of a debiasing procedure that aims to
remove the need for a priori knowledge of the specifics of bias in the model.",https://github.com/MxEddie/Demagnosticdebias,-1
27c09d40-1d10-425a-92ea-0751cdbbaefb,Free-HeadGAN: Neural Talking Head Synthesis with Explicit Gaze Control,0.385174,"We present Free-HeadGAN, a person-generic neural talking head synthesis
system. We show that modeling faces with sparse 3D facial landmarks are
sufficient for achieving state-of-the-art generative performance, without
relying on strong statistical priors of the face, such as 3D Morphable Models.
Apart from 3D pose and facial expressions, our method is capable of fully
transferring the eye gaze, from a driving actor to a source identity. Our
complete pipeline consists of three components: a canonical 3D key-point
estimator that regresses 3D pose and expression-related deformations, a gaze
estimation network and a generator that is built upon the architecture of
HeadGAN. We further experiment with an extension of our generator to
accommodate few-shot learning using an attention mechanism, in case more than
one source images are available. Compared to the latest models for reenactment
and motion transfer, our system achieves higher photo-realism combined with
superior identity preservation, while offering explicit gaze control.",None,34367
995229c9-7a36-442a-816c-ccc053b6f01b,Learning Appearance-motion Normality for Video Anomaly Detection,0.849839,"Video anomaly detection is a challenging task in the computer vision
community. Most single task-based methods do not consider the independence of
unique spatial and temporal patterns, while two-stream structures lack the
exploration of the correlations. In this paper, we propose spatial-temporal
memories augmented two-stream auto-encoder framework, which learns the
appearance normality and motion normality independently and explores the
correlations via adversarial learning. Specifically, we first design two proxy
tasks to train the two-stream structure to extract appearance and motion
features in isolation. Then, the prototypical features are recorded in the
corresponding spatial and temporal memory pools. Finally, the encoding-decoding
network performs adversarial learning with the discriminator to explore the
correlations between spatial and temporal patterns. Experimental results show
that our framework outperforms the state-of-the-art methods, achieving AUCs of
98.1% and 89.8% on UCSD Ped2 and CUHK Avenue datasets.",None,-1
11226cc6-ecb7-4b6e-af22-c92049c6fccc,Evaluation Beyond Task Performance: Analyzing Concepts in AlphaZero in Hex,0.346767,"AlphaZero, an approach to reinforcement learning that couples neural networks
and Monte Carlo tree search (MCTS), has produced state-of-the-art strategies
for traditional board games like chess, Go, shogi, and Hex. While researchers
and game commentators have suggested that AlphaZero uses concepts that humans
consider important, it is unclear how these concepts are captured in the
network. We investigate AlphaZero's internal representations in the game of Hex
using two evaluation techniques from natural language processing (NLP): model
probing and behavioral tests. In doing so, we introduce new evaluation tools to
the RL community and illustrate how evaluations other than task performance can
be used to provide a more complete picture of a model's strengths and
weaknesses. Our analyses in the game of Hex reveal interesting patterns and
generate some testable hypotheses about how such models learn in general. For
example, we find that MCTS discovers concepts before the neural network learns
to encode them. We also find that concepts related to short-term end-game
planning are best encoded in the final layers of the model, whereas concepts
related to long-term planning are encoded in the middle layers of the model.",https://github.com/jzf2101/alphatology,10423
d143cc96-7803-43d7-a062-804e22db87c7,Beyond calibration: estimating the grouping loss of modern neural networks,0.313612,"The ability to ensure that a classifier gives reliable confidence scores is
essential to ensure informed decision-making. To this end, recent work has
focused on miscalibration, i.e., the over or under confidence of model scores.
Yet calibration is not enough: even a perfectly calibrated classifier with the
best possible accuracy can have confidence scores that are far from the true
posterior probabilities. This is due to the grouping loss, created by samples
with the same confidence scores but different true posterior probabilities.
Proper scoring rule theory shows that given the calibration loss, the missing
piece to characterize individual errors is the grouping loss. While there are
many estimators of the calibration loss, none exists for the grouping loss in
standard settings. Here, we propose an estimator to approximate the grouping
loss. We show that modern neural network architectures in vision and NLP
exhibit grouping loss, notably in distribution shifts settings, which
highlights the importance of pre-production validation.",https://github.com/aperezlebel/beyond_calibration,-1
547c11b7-c739-4a2d-93a6-9a0f5a7ddbc7,Perspective Reconstruction of Human Faces by Joint Mesh and Landmark Regression,0.474619,"Even though 3D face reconstruction has achieved impressive progress, most
orthogonal projection-based face reconstruction methods can not achieve
accurate and consistent reconstruction results when the face is very close to
the camera due to the distortion under the perspective projection. In this
paper, we propose to simultaneously reconstruct 3D face mesh in the world space
and predict 2D face landmarks on the image plane to address the problem of
perspective 3D face reconstruction. Based on the predicted 3D vertices and 2D
landmarks, the 6DoF (6 Degrees of Freedom) face pose can be easily estimated by
the PnP solver to represent perspective projection. Our approach achieves 1st
place on the leader-board of the ECCV 2022 WCPA challenge and our model is
visually robust under different identities, expressions and poses. The training
code and models are released to facilitate future research.",https://github.com/deepinsight/insightface/tree/master/reconstruction/jmlr,-1
2a3abecc-9139-4579-b6f5-012332b8f2bc,Consistency driven Sequential Transformers Attention Model for Partially Observable Scenes,0.177354,"Most hard attention models initially observe a complete scene to locate and
sense informative glimpses, and predict class-label of a scene based on
glimpses. However, in many applications (e.g., aerial imaging), observing an
entire scene is not always feasible due to the limited time and resources
available for acquisition. In this paper, we develop a Sequential Transformers
Attention Model (STAM) that only partially observes a complete image and
predicts informative glimpse locations solely based on past glimpses. We design
our agent using DeiT-distilled and train it with a one-step actor-critic
algorithm. Furthermore, to improve classification performance, we introduce a
novel training objective, which enforces consistency between the class
distribution predicted by a teacher model from a complete image and the class
distribution predicted by our agent using glimpses. When the agent senses only
4% of the total image area, the inclusion of the proposed consistency loss in
our training objective yields 3% and 8% higher accuracy on ImageNet and fMoW
datasets, respectively. Moreover, our agent outperforms previous
state-of-the-art by observing nearly 27% and 42% fewer pixels in glimpses on
ImageNet and fMoW.",https://github.com/samrudhdhirangrej/STAM-Sequential-Transformers-Attention-Model,4005
6c919b6c-3aef-4757-9b9e-dba906cffcc0,CILDA: Contrastive Data Augmentation using Intermediate Layer Knowledge Distillation,0.325531,"Knowledge distillation (KD) is an efficient framework for compressing
large-scale pre-trained language models. Recent years have seen a surge of
research aiming to improve KD by leveraging Contrastive Learning, Intermediate
Layer Distillation, Data Augmentation, and Adversarial Training. In this work,
we propose a learning based data augmentation technique tailored for knowledge
distillation, called CILDA. To the best of our knowledge, this is the first
time that intermediate layer representations of the main task are used in
improving the quality of augmented samples. More precisely, we introduce an
augmentation technique for KD based on intermediate layer matching using
contrastive loss to improve masked adversarial data augmentation. CILDA
outperforms existing state-of-the-art KD approaches on the GLUE benchmark, as
well as in an out-of-domain evaluation.",None,-1
a4657055-d354-4de4-925a-de1ccbba1097,RECALL: Rehearsal-free Continual Learning for Object Classification,0.0352349,"Convolutional neural networks show remarkable results in classification but
struggle with learning new things on the fly. We present a novel rehearsal-free
approach, where a deep neural network is continually learning new unseen object
categories without saving any data of prior sequences. Our approach is called
RECALL, as the network recalls categories by calculating logits for old
categories before training new ones. These are then used during training to
avoid changing the old categories. For each new sequence, a new head is added
to accommodate the new categories. To mitigate forgetting, we present a
regularization strategy where we replace the classification with a regression.
Moreover, for the known categories, we propose a Mahalanobis loss that includes
the variances to account for the changing densities between known and unknown
categories. Finally, we present a novel dataset for continual learning,
especially suited for object recognition on a mobile robot (HOWS-CL-25),
including 150,795 synthetic images of 25 household object categories. Our
approach RECALL outperforms the current state of the art on CORe50 and
iCIFAR-100 and reaches the best performance on HOWS-CL-25.",https://github.com/DLR-RM/RECALL,-1
9a3e208b-b0d8-4ca6-8983-2a0e0c951e47,Natural Language Deduction through Search over Statement Compositions,0.592454,"In settings from fact-checking to question answering, we frequently want to
know whether a collection of evidence (premises) entails a hypothesis. Existing
methods primarily focus on the end-to-end discriminative version of this task,
but less work has treated the generative version in which a model searches over
the space of statements entailed by the premises to constructively derive the
hypothesis. We propose a system for doing this kind of deductive reasoning in
natural language by decomposing the task into separate steps coordinated by a
search procedure, producing a tree of intermediate conclusions that faithfully
reflects the system's reasoning process. Our experiments on the EntailmentBank
dataset (Dalvi et al., 2021) demonstrate that the proposed system can
successfully prove true statements while rejecting false ones. Moreover, it
produces natural language explanations with a 17% absolute higher step validity
than those produced by an end-to-end T5 model.",None,-1
52dd073f-7873-4beb-b1e5-508d34ebebee,Generate-and-Retrieve: use your predictions to improve retrieval for semantic parsing,0.39433,"A common recent approach to semantic parsing augments sequence-to-sequence
models by retrieving and appending a set of training samples, called exemplars.
The effectiveness of this recipe is limited by the ability to retrieve
informative exemplars that help produce the correct parse, which is especially
challenging in low-resource settings. Existing retrieval is commonly based on
similarity of query and exemplar inputs. We propose GandR, a retrieval
procedure that retrieves exemplars for which outputs are also similar.
GandRfirst generates a preliminary prediction with input-based retrieval. Then,
it retrieves exemplars with outputs similar to the preliminary prediction which
are used to generate a final prediction. GandR sets the state of the art on
multiple low-resource semantic parsing tasks.",https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511,-1
a00333da-e8c5-4436-aa3c-440e712ded7e,An End-to-End Dialogue Summarization System for Sales Calls,0.337177,"Summarizing sales calls is a routine task performed manually by salespeople.
We present a production system which combines generative models fine-tuned for
customer-agent setting, with a human-in-the-loop user experience for an
interactive summary curation process. We address challenging aspects of
dialogue summarization task in a real-world setting including long input
dialogues, content validation, lack of labeled data and quality evaluation. We
show how GPT-3 can be leveraged as an offline data labeler to handle training
data scarcity and accommodate privacy constraints in an industrial setting.
Experiments show significant improvements by our models in tackling the
summarization and content validation tasks on public datasets.",https://github.com/google-research/google-research/tree/master/rouge,-1
ec8f8433-73b4-4d80-859c-800b5e8d0606,BLASER: A Text-Free Speech-to-Speech Translation Evaluation Metric,0.770012,"End-to-End speech-to-speech translation (S2ST) is generally evaluated with
text-based metrics. This means that generated speech has to be automatically
transcribed, making the evaluation dependent on the availability and quality of
automatic speech recognition (ASR) systems. In this paper, we propose a
text-free evaluation metric for end-to-end S2ST, named BLASER, to avoid the
dependency on ASR systems. BLASER leverages a multilingual multimodal encoder
to directly encode the speech segments for source input, translation output and
reference into a shared embedding space and computes a score of the translation
quality that can be used as a proxy to human evaluation. To evaluate our
approach, we construct training and evaluation sets from more than 40k human
annotations covering seven language directions. The best results of BLASER are
achieved by training with supervision from human rating scores. We show that
when evaluated at the sentence level, BLASER correlates significantly better
with human judgment compared to ASR-dependent metrics including ASR-SENTBLEU in
all translation directions and ASR-COMET in five of them. Our analysis shows
combining speech and text as inputs to BLASER does not increase the correlation
with human scores, but best correlations are achieved when using speech, which
motivates the goal of our research. Moreover, we show that using ASR for
references is detrimental for text-based metrics.",https://github.com/facebookresearch/stopes,-1
a0abac83-c20f-4704-bb52-932fb441761e,Scaling Up Probabilistic Circuits by Latent Variable Distillation,0.881855,"Probabilistic Circuits (PCs) are a unified framework for tractable
probabilistic models that support efficient computation of various
probabilistic queries (e.g., marginal probabilities). One key challenge is to
scale PCs to model large and high-dimensional real-world datasets: we observe
that as the number of parameters in PCs increases, their performance
immediately plateaus. This phenomenon suggests that the existing optimizers
fail to exploit the full expressive power of large PCs. We propose to overcome
such bottleneck by latent variable distillation: we leverage the less tractable
but more expressive deep generative models to provide extra supervision over
the latent variables of PCs. Specifically, we extract information from
Transformer-based generative models to assign values to latent variables of
PCs, providing guidance to PC optimizers. Experiments on both image and
language modeling benchmarks (e.g., ImageNet and WikiText-2) show that latent
variable distillation substantially boosts the performance of large PCs
compared to their counterparts without latent variable distillation. In
particular, on the image modeling benchmarks, PCs achieve competitive
performance against some of the widely-used deep generative models, including
variational autoencoders and flow-based models, opening up new avenues for
tractable generative modeling.",https://github.com/facebookresearch/mae,-1
fb94653d-31cf-4d76-86a2-50792fa5370a,Scaling Laws Beyond Backpropagation,0.155408,"Alternatives to backpropagation have long been studied to better understand
how biological brains may learn. Recently, they have also garnered interest as
a way to train neural networks more efficiently. By relaxing constraints
inherent to backpropagation (e.g., symmetric feedforward and feedback weights,
sequential updates), these methods enable promising prospects, such as local
learning. However, the tradeoffs between different methods in terms of final
task performance, convergence speed, and ultimately compute and data
requirements are rarely outlined. In this work, we use scaling laws to study
the ability of Direct Feedback Alignment~(DFA) to train causal decoder-only
Transformers efficiently. Scaling laws provide an overview of the tradeoffs
implied by a modeling decision, up to extrapolating how it might transfer to
increasingly large models. We find that DFA fails to offer more efficient
scaling than backpropagation: there is never a regime for which the degradation
in loss incurred by using DFA is worth the potential reduction in compute
budget. Our finding comes at variance with previous beliefs in the alternative
training methods community, and highlights the need for holistic empirical
approaches to better understand modeling decisions.",None,-1
918beab3-c176-4332-b44e-c144f6b54f53,Changing the Representation: Examining Language Representation for Neural Sign Language Production,0.636322,"Neural Sign Language Production (SLP) aims to automatically translate from
spoken language sentences to sign language videos. Historically the SLP task
has been broken into two steps; Firstly, translating from a spoken language
sentence to a gloss sequence and secondly, producing a sign language video
given a sequence of glosses. In this paper we apply Natural Language Processing
techniques to the first step of the SLP pipeline. We use language models such
as BERT and Word2Vec to create better sentence level embeddings, and apply
several tokenization techniques, demonstrating how these improve performance on
the low resource translation task of Text to Gloss. We introduce Text to
HamNoSys (T2H) translation, and show the advantages of using a phonetic
representation for sign language translation rather than a sign level gloss
representation. Furthermore, we use HamNoSys to extract the hand shape of a
sign and use this as additional supervision during training, further increasing
the performance on T2H. Assembling best practise, we achieve a BLEU-4 score of
26.99 on the MineDGS dataset and 25.09 on PHOENIX14T, two new state-of-the-art
baselines.",None,-1
7df731bb-b228-427d-a318-f6b9b5d44a02,A Conditional Perspective on the Logic of Iterated Belief Contraction,0.140021,"In this article, we consider iteration principles for contraction, with the
goal of identifying properties for contractions that respect conditional
beliefs. Therefore, we investigate and evaluate four groups of iteration
principles for contraction which consider the dynamics of conditional beliefs.
For all these principles, we provide semantic characterization theorems and
provide formulations by postulates which highlight how the change of beliefs
and of conditional beliefs is constrained, whenever that is possible. The first
group is similar to the syntactic Darwiche-Pearl postulates. As a second group,
we consider semantic postulates for iteration of contraction by Chopra, Ghose,
Meyer and Wong, and by Konieczny and Pino P\'erez, respectively, and we provide
novel syntactic counterparts. Third, we propose a contraction analogue of the
independence condition by Jin and Thielscher. For the fourth group, we consider
natural and moderate contraction by Nayak. Methodically, we make use of
conditionals for contractions, so-called contractionals and furthermore, we
propose and employ the novel notion of $ \alpha $-equivalence for formulating
some of the new postulates.",None,-1
69574bb4-ce05-4822-a06d-02114c2a44e4,VolRecon: Volume Rendering of Signed Ray Distance Functions for Generalizable Multi-View Reconstruction,0.804549,"The success of the Neural Radiance Fields (NeRF) in novel view synthesis has
inspired researchers to propose neural implicit scene reconstruction. However,
most existing neural implicit reconstruction methods optimize per-scene
parameters and therefore lack generalizability to new scenes. We introduce
VolRecon, a novel generalizable implicit reconstruction method with Signed Ray
Distance Function (SRDF). To reconstruct the scene with fine details and little
noise, VolRecon combines projection features aggregated from multi-view
features, and volume features interpolated from a coarse global feature volume.
Using a ray transformer, we compute SRDF values of sampled points on a ray and
then render color and depth. On DTU dataset, VolRecon outperforms SparseNeuS by
about 30% in sparse view reconstruction and achieves comparable accuracy as
MVSNet in full view reconstruction. Furthermore, our approach exhibits good
generalization performance on the large-scale ETH3D benchmark.",https://github.com/IVRL/VolRecon/,-1
256307fa-eff6-44c5-aeda-bc2ae5ce9cf4,Good Visual Guidance Makes A Better Extractor: Hierarchical Visual Prefix for Multimodal Entity and Relation Extraction,0.594096,"Multimodal named entity recognition and relation extraction (MNER and MRE) is
a fundamental and crucial branch in information extraction. However, existing
approaches for MNER and MRE usually suffer from error sensitivity when
irrelevant object images incorporated in texts. To deal with these issues, we
propose a novel Hierarchical Visual Prefix fusion NeTwork (HVPNeT) for
visual-enhanced entity and relation extraction, aiming to achieve more
effective and robust performance. Specifically, we regard visual representation
as pluggable visual prefix to guide the textual representation for error
insensitive forecasting decision. We further propose a dynamic gated
aggregation strategy to achieve hierarchical multi-scaled visual features as
visual prefix for fusion. Extensive experiments on three benchmark datasets
demonstrate the effectiveness of our method, and achieve state-of-the-art
performance. Code is available in https://github.com/zjunlp/HVPNeT.",https://github.com/zjunlp/HVPNeT,-1
388ca18f-953e-4ed8-a062-5666cb5df8f6,An Accelerator for Rule Induction in Fuzzy Rough Theory,0.561441,"Rule-based classifier, that extract a subset of induced rules to efficiently
learn/mine while preserving the discernibility information, plays a crucial
role in human-explainable artificial intelligence. However, in this era of big
data, rule induction on the whole datasets is computationally intensive. So
far, to the best of our knowledge, no known method focusing on accelerating
rule induction has been reported. This is first study to consider the
acceleration technique to reduce the scale of computation in rule induction. We
propose an accelerator for rule induction based on fuzzy rough theory; the
accelerator can avoid redundant computation and accelerate the building of a
rule classifier. First, a rule induction method based on consistence degree,
called Consistence-based Value Reduction (CVR), is proposed and used as basis
to accelerate. Second, we introduce a compacted search space termed Key Set,
which only contains the key instances required to update the induced rule, to
conduct value reduction. The monotonicity of Key Set ensures the feasibility of
our accelerator. Third, a rule-induction accelerator is designed based on Key
Set, and it is theoretically guaranteed to display the same results as the
unaccelerated version. Specifically, the rank preservation property of Key Set
ensures consistency between the rule induction achieved by the accelerator and
the unaccelerated method. Finally, extensive experiments demonstrate that the
proposed accelerator can perform remarkably faster than the unaccelerated
rule-based classifier methods, especially on datasets with numerous instances.",https://github.com/RUC-DWBI-ML/A-CVRC,15039
68c58731-d46b-4680-af60-efa9b7c7b722,WeCheck: Strong Factual Consistency Checker via Weakly Supervised Learning,0.0703281,"A crucial issue of current text generation models is that they often
uncontrollably generate factually inconsistent text with respective of their
inputs. Limited by the lack of annotated data, existing works in evaluating
factual consistency directly transfer the reasoning ability of models trained
on other data-rich upstream tasks like question answering (QA) and natural
language inference (NLI) without any further adaptation. As a result, they
perform poorly on the real generated text and are biased heavily by their
single-source upstream tasks. To alleviate this problem, we propose a weakly
supervised framework that aggregates multiple resources to train a precise and
efficient factual metric, namely WeCheck. WeCheck first utilizes a generative
model to accurately label a real generated sample by aggregating its weak
labels, which are inferred from multiple resources. Then, we train the target
metric model with the weak supervision while taking noises into consideration.
Comprehensive experiments on a variety of tasks demonstrate the strong
performance of WeCheck, which achieves a 3.4\% absolute improvement over
previous state-of-the-art methods on TRUE benchmark on average.",None,-1
a33cc11b-a876-4f2c-98c3-5f64ba4b0530,Artificial Intelligence and Auction Design,0.94418,"Motivated by online advertising auctions, we study auction design in repeated
auctions played by simple Artificial Intelligence algorithms (Q-learning). We
find that first-price auctions with no additional feedback lead to
tacit-collusive outcomes (bids lower than values), while second-price auctions
do not. We show that the difference is driven by the incentive in first-price
auctions to outbid opponents by just one bid increment. This facilitates
re-coordination on low bids after a phase of experimentation. We also show that
providing information about lowest bid to win, as introduced by Google at the
time of switch to first-price auctions, increases competitiveness of auctions.",None,-1
1b8bad16-ec45-49f2-b3c7-e7cc74350e21,Learning Prototype via Placeholder for Zero-shot Recognition,0.0937207,"Zero-shot learning (ZSL) aims to recognize unseen classes by exploiting
semantic descriptions shared between seen classes and unseen classes. Current
methods show that it is effective to learn visual-semantic alignment by
projecting semantic embeddings into the visual space as class prototypes.
However, such a projection function is only concerned with seen classes. When
applied to unseen classes, the prototypes often perform suboptimally due to
domain shift. In this paper, we propose to learn prototypes via placeholders,
termed LPL, to eliminate the domain shift between seen and unseen classes.
Specifically, we combine seen classes to hallucinate new classes which play as
placeholders of the unseen classes in the visual and semantic space. Placed
between seen classes, the placeholders encourage prototypes of seen classes to
be highly dispersed. And more space is spared for the insertion of
well-separated unseen ones. Empirically, well-separated prototypes help
counteract visual-semantic misalignment caused by domain shift. Furthermore, we
exploit a novel semantic-oriented fine-tuning to guarantee the semantic
reliability of placeholders. Extensive experiments on five benchmark datasets
demonstrate the significant performance gain of LPL over the state-of-the-art
methods. Code is available at https://github.com/zaiquanyang/LPL.",https://github.com/zaiquanyang/LPL,-1
142bd7e5-0df5-40b0-80eb-230722fb8809,Hierarchical Attention Network for Explainable Depression Detection on Twitter Aided by Metaphor Concept Mappings,0.589872,"Automatic depression detection on Twitter can help individuals privately and
conveniently understand their mental health status in the early stages before
seeing mental health professionals. Most existing black-box-like deep learning
methods for depression detection largely focused on improving classification
performance. However, explaining model decisions is imperative in health
research because decision-making can often be high-stakes and life-and-death.
Reliable automatic diagnosis of mental health problems including depression
should be supported by credible explanations justifying models' predictions. In
this work, we propose a novel explainable model for depression detection on
Twitter. It comprises a novel encoder combining hierarchical attention
mechanisms and feed-forward neural networks. To support psycholinguistic
studies, our model leverages metaphorical concept mappings as input. Thus, it
not only detects depressed individuals, but also identifies features of such
users' tweets and associated metaphor concept mappings.",None,55352
b795ccce-a342-4d29-ae7e-8bece7a4b944,Towards a Sentiment-Aware Conversational Agent,0.29994,"In this paper, we propose an end-to-end sentiment-aware conversational agent
based on two models: a reply sentiment prediction model, which leverages the
context of the dialogue to predict an appropriate sentiment for the agent to
express in its reply; and a text generation model, which is conditioned on the
predicted sentiment and the context of the dialogue, to produce a reply that is
both context and sentiment appropriate. Additionally, we propose to use a
sentiment classification model to evaluate the sentiment expressed by the agent
during the development of the model. This allows us to evaluate the agent in an
automatic way. Both automatic and human evaluation results show that explicitly
guiding the text generation model with a pre-defined set of sentences leads to
clear improvements, both regarding the expressed sentiment and the quality of
the generated text.",None,-1
ea7be224-8075-4885-aa3c-57227ba236fc,Benchmarking Self-Supervised Learning on Diverse Pathology Datasets,0.878163,"Computational pathology can lead to saving human lives, but models are
annotation hungry and pathology images are notoriously expensive to annotate.
Self-supervised learning has shown to be an effective method for utilizing
unlabeled data, and its application to pathology could greatly benefit its
downstream tasks. Yet, there are no principled studies that compare SSL methods
and discuss how to adapt them for pathology. To address this need, we execute
the largest-scale study of SSL pre-training on pathology image data, to date.
Our study is conducted using 4 representative SSL methods on diverse downstream
tasks. We establish that large-scale domain-aligned pre-training in pathology
consistently out-performs ImageNet pre-training in standard SSL settings such
as linear and fine-tuning evaluations, as well as in low-label regimes.
Moreover, we propose a set of domain-specific techniques that we experimentally
show leads to a performance boost. Lastly, for the first time, we apply SSL to
the challenging task of nuclei instance segmentation and show large and
consistent performance improvements under diverse settings.",https://lunit-io.github.io/research/publications/pathology_ssl,-1
346efdbf-8b34-4ad2-ab2e-988277de99f6,Kernel Attention Transformer (KAT) for Histopathology Whole Slide Image Classification,0.547919,"Transformer has been widely used in histopathology whole slide image (WSI)
classification for the purpose of tumor grading, prognosis analysis, etc.
However, the design of token-wise self-attention and positional embedding
strategy in the common Transformer limits the effectiveness and efficiency in
the application to gigapixel histopathology images. In this paper, we propose a
kernel attention Transformer (KAT) for histopathology WSI classification. The
information transmission of the tokens is achieved by cross-attention between
the tokens and a set of kernels related to a set of positional anchors on the
WSI. Compared to the common Transformer structure, the proposed KAT can better
describe the hierarchical context information of the local regions of the WSI
and meanwhile maintains a lower computational complexity. The proposed method
was evaluated on a gastric dataset with 2040 WSIs and an endometrial dataset
with 2560 WSIs, and was compared with 6 state-of-the-art methods. The
experimental results have demonstrated the proposed KAT is effective and
efficient in the task of histopathology WSI classification and is superior to
the state-of-the-art methods. The code is available at
https://github.com/zhengyushan/kat.",https://github.com/zhengyushan/kat,-1
441dfcb5-ce68-43af-add5-4f0222ca658d,MTet: Multi-domain Translation for English and Vietnamese,0.253422,"We introduce MTet, the largest publicly available parallel corpus for
English-Vietnamese translation. MTet consists of 4.2M high-quality training
sentence pairs and a multi-domain test set refined by the Vietnamese research
community. Combining with previous works on English-Vietnamese translation, we
grow the existing parallel dataset to 6.2M sentence pairs. We also release the
first pretrained model EnViT5 for English and Vietnamese languages. Combining
both resources, our model significantly outperforms previous state-of-the-art
results by up to 2 points in translation BLEU score, while being 1.6 times
smaller.",https://github.com/stefan-it/nmt-en-vi,-1
5436fe13-e37f-436b-b5c3-0dfe6dea4f7c,NAFSSR: Stereo Image Super-Resolution Using NAFNet,0.938019,"Stereo image super-resolution aims at enhancing the quality of
super-resolution results by utilizing the complementary information provided by
binocular systems. To obtain reasonable performance, most methods focus on
finely designing modules, loss functions, and etc. to exploit information from
another viewpoint. This has the side effect of increasing system complexity,
making it difficult for researchers to evaluate new ideas and compare methods.
This paper inherits a strong and simple image restoration model, NAFNet, for
single-view feature extraction and extends it by adding cross attention modules
to fuse features between views to adapt to binocular scenarios. The proposed
baseline for stereo image super-resolution is noted as NAFSSR. Furthermore,
training/testing strategies are proposed to fully exploit the performance of
NAFSSR. Extensive experiments demonstrate the effectiveness of our method. In
particular, NAFSSR outperforms the state-of-the-art methods on the KITTI 2012,
KITTI 2015, Middlebury, and Flickr1024 datasets. With NAFSSR, we won 1st place
in the NTIRE 2022 Stereo Image Super-resolution Challenge. Codes and models
will be released at https://github.com/megvii-research/NAFNet.",https://github.com/megvii-research/NAFNet,-1
a61f1267-548a-4f08-a932-cacaf23c8e08,A Holistic Framework for Analyzing the COVID-19 Vaccine Debate,0.821673,"The Covid-19 pandemic has led to infodemic of low quality information leading
to poor health decisions. Combating the outcomes of this infodemic is not only
a question of identifying false claims, but also reasoning about the decisions
individuals make. In this work we propose a holistic analysis framework
connecting stance and reason analysis, and fine-grained entity level moral
sentiment analysis. We study how to model the dependencies between the
different level of analysis and incorporate human insights into the learning
process. Experiments show that our framework provides reliable predictions even
in the low-supervision settings.",https://gitlab.com/mlpacheco/covid-moral-foundations,-1
ca481c33-ffec-49ae-8776-bb2ee4792294,FairDistillation: Mitigating Stereotyping in Language Models,0.226542,"Large pre-trained language models are successfully being used in a variety of
tasks, across many languages. With this ever-increasing usage, the risk of
harmful side effects also rises, for example by reproducing and reinforcing
stereotypes. However, detecting and mitigating these harms is difficult to do
in general and becomes computationally expensive when tackling multiple
languages or when considering different biases. To address this, we present
FairDistillation: a cross-lingual method based on knowledge distillation to
construct smaller language models while controlling for specific biases. We
found that our distillation method does not negatively affect the downstream
performance on most tasks and successfully mitigates stereotyping and
representational harms. We demonstrate that FairDistillation can create fairer
language models at a considerably lower cost than alternative approaches.",None,-1
2636afb9-ae11-45fe-bf9d-accc4f81a500,Universal Conditional Masked Language Pre-training for Neural Machine Translation,0.46641,"Pre-trained sequence-to-sequence models have significantly improved Neural
Machine Translation (NMT). Different from prior works where pre-trained models
usually adopt an unidirectional decoder, this paper demonstrates that
pre-training a sequence-to-sequence model but with a bidirectional decoder can
produce notable performance gains for both Autoregressive and
Non-autoregressive NMT. Specifically, we propose CeMAT, a conditional masked
language model pre-trained on large-scale bilingual and monolingual corpora in
many languages. We also introduce two simple but effective methods to enhance
the CeMAT, aligned code-switching & masking and dynamic dual-masking. We
conduct extensive experiments and show that our CeMAT can achieve significant
performance improvement for all scenarios from low- to extremely high-resource
languages, i.e., up to +14.4 BLEU on low resource and +7.9 BLEU improvements on
average for Autoregressive NMT. For Non-autoregressive NMT, we demonstrate it
can also produce consistent performance gains, i.e., up to +5.3 BLEU. To the
best of our knowledge, this is the first work to pre-train a unified model for
fine-tuning on both NMT tasks. Code, data, and pre-trained models are available
at https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/CeMAT.",https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/CeMAT,19622
ce71dc41-ea60-412e-b33c-4e300ea6b7d8,Semi-Supervised Formality Style Transfer with Consistency Training,0.750027,"Formality style transfer (FST) is a task that involves paraphrasing an
informal sentence into a formal one without altering its meaning. To address
the data-scarcity problem of existing parallel datasets, previous studies tend
to adopt a cycle-reconstruction scheme to utilize additional unlabeled data,
where the FST model mainly benefits from target-side unlabeled sentences. In
this work, we propose a simple yet effective semi-supervised framework to
better utilize source-side unlabeled sentences based on consistency training.
Specifically, our approach augments pseudo-parallel data obtained from a
source-side informal sentence by enforcing the model to generate similar
outputs for its perturbed version. Moreover, we empirically examined the
effects of various data perturbation methods and propose effective data
filtering strategies to improve our framework. Experimental results on the
GYAFC benchmark demonstrate that our approach can achieve state-of-the-art
results, even with less than 40% of the parallel data.",https://github.com/Aolius/semi-fst,-1
550b9abe-ea5d-41a2-9fd5-7c2c9ffeaca0,PartSLIP: Low-Shot Part Segmentation for 3D Point Clouds via Pretrained Image-Language Models,0.986813,"Generalizable 3D part segmentation is important but challenging in vision and
robotics. Training deep models via conventional supervised methods requires
large-scale 3D datasets with fine-grained part annotations, which are costly to
collect. This paper explores an alternative way for low-shot part segmentation
of 3D point clouds by leveraging a pretrained image-language model, GLIP, which
achieves superior performance on open-vocabulary 2D detection. We transfer the
rich knowledge from 2D to 3D through GLIP-based part detection on point cloud
rendering and a novel 2D-to-3D label lifting algorithm. We also utilize
multi-view 3D priors and few-shot prompt tuning to boost performance
significantly. Extensive evaluation on PartNet and PartNet-Mobility datasets
shows that our method enables excellent zero-shot 3D part segmentation. Our
few-shot version not only outperforms existing few-shot approaches by a large
margin but also achieves highly competitive results compared to the fully
supervised counterpart. Furthermore, we demonstrate that our method can be
directly applied to iPhone-scanned point clouds without significant domain
gaps.",None,-1
ad70d2cd-3e4c-4737-9fc0-d9861eca2c2b,Generative Design Ideation: A Natural Language Generation Approach,0.332314,"This paper aims to explore a generative approach for knowledge-based design
ideation by applying the latest pre-trained language models in artificial
intelligence (AI). Specifically, a method of fine-tuning the generative
pre-trained transformer using the USPTO patent database is proposed. The
AI-generated ideas are not only in concise and understandable language but also
able to synthesize the target design with external knowledge sources with
controllable knowledge distance. The method is tested in a case study of
rolling toy design and the results show good performance in generating ideas of
varied novelty with near-field and far-field source knowledge.",None,-1
aa477ff8-eb51-478e-8328-97e604ed93dd,TraClets: Harnessing the power of computer vision for trajectory classification,0.0789057,"Due to the advent of new mobile devices and tracking sensors in recent years,
huge amounts of data are being produced every day. Therefore, novel
methodologies need to emerge that dive through this vast sea of information and
generate insights and meaningful information. To this end, researchers have
developed several trajectory classification algorithms over the years that are
able to annotate tracking data. Similarly, in this research, a novel
methodology is presented that exploits image representations of trajectories,
called TraClets, in order to classify trajectories in an intuitive humans way,
through computer vision techniques. Several real-world datasets are used to
evaluate the proposed approach and compare its classification performance to
other state-of-the-art trajectory classification algorithms. Experimental
results demonstrate that TraClets achieves a classification performance that is
comparable to, or in most cases, better than the state-of-the-art, acting as a
universal, high-accuracy approach for trajectory classification.",None,-1
e5219e19-e64a-41fe-8fa2-8f0b29894cb4,Lighting (In)consistency of Paint by Text,0.389544,"Whereas generative adversarial networks are capable of synthesizing highly
realistic images of faces, cats, landscapes, or almost any other single
category, paint-by-text synthesis engines can -- from a single text prompt --
synthesize realistic images of seemingly endless categories with arbitrary
configurations and combinations. This powerful technology poses new challenges
to the photo-forensic community. Motivated by the fact that paint by text is
not based on explicit geometric or physical models, and the human visual
system's general insensitivity to lighting inconsistencies, we provide an
initial exploration of the lighting consistency of DALL-E-2 synthesized images
to determine if physics-based forensic analyses will prove fruitful in
detecting this new breed of synthetic media.",None,-1
41743d50-809c-49d1-ae4b-e3084a763964,Revisiting initial sets in abstract argumentation,0.248192,"We revisit the notion of initial sets by Xu and Cayrol, i.e., non-empty
minimal admissible sets in abstract argumentation frameworks. Initial sets are
a simple concept for analysing conflicts in an abstract argumentation framework
and to explain why certain arguments can be accepted. We contribute with new
insights on the structure of initial sets and devise a simple non-deterministic
construction principle for any admissible set, based on iterative selection of
initial sets of the original framework and its induced reducts. In particular,
we characterise many existing admissibility-based semantics via this
construction principle, thus providing a constructive explanation on the
structure of extensions. We also investigate certain problems related to
initial sets with respect to their computational complexity.",None,-1
314c83c9-5da8-4a9c-acfb-85a9b13c1ed1,A multi-task semi-supervised framework for Text2Graph & Graph2Text,0.0716135,"The Artificial Intelligence industry regularly develops applications that
mostly rely on Knowledge Bases, a data repository about specific, or general,
domains, usually represented in a graph shape. Similar to other databases, they
face two main challenges: information ingestion and information retrieval. We
approach these challenges by jointly learning graph extraction from text and
text generation from graphs. The proposed solution, a T5 architecture, is
trained in a multi-task semi-supervised environment, with our collected
non-parallel data, following a cycle training regime. Experiments on WebNLG
dataset show that our approach surpasses unsupervised state-of-the-art results
in text-to-graph and graph-to-text. More relevantly, our framework is more
consistent across seen and unseen domains than supervised models. The resulting
model can be easily trained in any new domain with non-parallel data, by simply
adding text and graphs about it, in our cycle framework.",https://github.com/uridr/GTWiki,-1
10c0f8d8-9879-4ae6-9af9-d75215dcd57e,DeepStruct: Pretraining of Language Models for Structure Prediction,0.471784,"We introduce a method for improving the structural understanding abilities of
language models. Unlike previous approaches that finetune the models with
task-specific augmentation, we pretrain language models on a collection of
task-agnostic corpora to generate structures from text. Our structure
pretraining enables zero-shot transfer of the learned knowledge that models
have about the structure tasks. We study the performance of this approach on 28
datasets, spanning 10 structure prediction tasks including open information
extraction, joint entity and relation extraction, named entity recognition,
relation classification, semantic role labeling, event extraction, coreference
resolution, factual probe, intent detection, and dialogue state tracking. We
further enhance the pretraining with the task-specific training sets. We show
that a 10B parameter language model transfers non-trivially to most tasks and
obtains state-of-the-art performance on 21 of 28 datasets that we evaluate.",https://github.com/cgraywang/deepstruct,40265
70f5806a-35af-427f-b03b-fe4168a4ff77,Egocentric Human-Object Interaction Detection Exploiting Synthetic Data,0.762107,"We consider the problem of detecting Egocentric HumanObject Interactions
(EHOIs) in industrial contexts. Since collecting and labeling large amounts of
real images is challenging, we propose a pipeline and a tool to generate
photo-realistic synthetic First Person Vision (FPV) images automatically
labeled for EHOI detection in a specific industrial scenario. To tackle the
problem of EHOI detection, we propose a method that detects the hands, the
objects in the scene, and determines which objects are currently involved in an
interaction. We compare the performance of our method with a set of
state-of-the-art baselines. Results show that using a synthetic dataset
improves the performance of an EHOI detection system, especially when few real
data are available. To encourage research on this topic, we publicly release
the proposed dataset at the following url:
https://iplab.dmi.unict.it/EHOI_SYNTH/.",https://github.com/cocodataset/cocoapi,-1
ff80e544-faf5-4972-86d0-497802ba57a1,Long-Tail Prediction Uncertainty Aware Trajectory Planning for Self-driving Vehicles,0.666931,"A typical trajectory planner of autonomous driving commonly relies on
predicting the future behavior of surrounding obstacles. Recently, deep
learning technology has been widely adopted to design prediction models due to
their impressive performance. However, such models may fail in the ""long-tail""
driving cases where the training data is sparse or unavailable, leading to
planner failures. To this end, this work proposes a trajectory planner to
consider the prediction model uncertainty arising from insufficient data for
safer performance. Firstly, an ensemble network structure estimates the
prediction model's uncertainty due to insufficient training data. Then a
trajectory planner is designed to consider the worst-case arising from
prediction uncertainty. The results show that the proposed method can improve
the safety of trajectory planning under the prediction uncertainty caused by
insufficient data. At the same time, with sufficient data, the framework will
not lead to overly conservative results. This technology helps to improve the
safety and reliability of autonomous vehicles under the long-tail data
distribution of the real world.",None,-1
87bf588c-124f-485b-a69e-cdee8a83a8cc,A Mental-Model Centric Landscape of Human-AI Symbiosis,0.247504,"There has been significant recent interest in developing AI agents capable of
effectively interacting and teaming with humans. While each of these works try
to tackle a problem quite central to the problem of human-AI interaction, they
tend to rely on myopic formulations that obscure the possible inter-relatedness
and complementarity of many of these works. The human-aware AI framework was a
recent effort to provide a unified account for human-AI interaction by casting
them in terms of their relationship to various mental models. Unfortunately,
the current accounts of human-aware AI are insufficient to explain the
landscape of the work doing in the space of human-AI interaction due to their
focus on limited settings. In this paper, we aim to correct this shortcoming by
introducing a significantly general version of human-aware AI interaction
scheme, called generalized human-aware interaction (GHAI), that talks about
(mental) models of six types. Through this paper, we will see how this new
framework allows us to capture the various works done in the space of human-AI
interaction and identify the fundamental behavioral patterns supported by these
works. We will also use this framework to identify potential gaps in the
current literature and suggest future research directions to address these
shortcomings.",None,-1
6dd50c40-bcc5-4151-a1fb-e4f84cd97c03,Normalizing Flows for Human Pose Anomaly Detection,0.701968,"Video anomaly detection is an ill-posed problem because it relies on many
parameters such as appearance, pose, camera angle, background, and more. We
distill the problem to anomaly detection of human pose, thus decreasing the
risk of nuisance parameters such as appearance affecting the result. Focusing
on pose alone also has the side benefit of reducing bias against distinct
minority groups. Our model works directly on human pose graph sequences and is
exceptionally lightweight (~1K parameters), capable of running on any machine
able to run the pose estimation with negligible additional resources. We
leverage the highly compact pose representation in a normalizing flows
framework, which we extend to tackle the unique characteristics of
spatio-temporal pose data and show its advantages in this use case. The
algorithm is quite general and can handle training data of only normal examples
as well as a supervised setting that consists of labeled normal and abnormal
examples. We report state-of-the-art results on two anomaly detection
benchmarks - the unsupervised ShanghaiTech dataset and the recent supervised
UBnormal dataset.",https://github.com/orhir/STG-NF,-1
adf5be7a-f21e-433d-8f08-27e10a049be8,Measuring Data,0.368616,"We identify the task of measuring data to quantitatively characterize the
composition of machine learning data and datasets. Similar to an object's
height, width, and volume, data measurements quantify different attributes of
data along common dimensions that support comparison. Several lines of research
have proposed what we refer to as measurements, with differing terminology; we
bring some of this work together, particularly in fields of computer vision and
language, and build from it to motivate measuring data as a critical component
of responsible AI development. Measuring data aids in systematically building
and analyzing machine learning (ML) data towards specific goals and gaining
better control of what modern ML systems will learn. We conclude with a
discussion of the many avenues of future work, the limitations of data
measurements, and how to leverage these measurement approaches in research and
practice.",None,-1
ee934b78-18f0-432f-9f88-a4cdf933ca65,PG3: Policy-Guided Planning for Generalized Policy Generation,0.375199,"A longstanding objective in classical planning is to synthesize policies that
generalize across multiple problems from the same domain. In this work, we
study generalized policy search-based methods with a focus on the score
function used to guide the search over policies. We demonstrate limitations of
two score functions and propose a new approach that overcomes these
limitations. The main idea behind our approach, Policy-Guided Planning for
Generalized Policy Generation (PG3), is that a candidate policy should be used
to guide planning on training problems as a mechanism for evaluating that
candidate. Theoretical results in a simplified setting give conditions under
which PG3 is optimal or admissible. We then study a specific instantiation of
policy search where planning problems are PDDL-based and policies are lifted
decision lists. Empirical results in six domains confirm that PG3 learns
generalized policies more efficiently and effectively than several baselines.
Code: https://github.com/ryangpeixu/pg3",https://github.com/ryangpeixu/pg3,-1
2afec887-ee35-4512-b96d-5da1a87ff98b,Adapting to Latent Subgroup Shifts via Concepts and Proxies,0.454264,"We address the problem of unsupervised domain adaptation when the source
domain differs from the target domain because of a shift in the distribution of
a latent subgroup. When this subgroup confounds all observed data, neither
covariate shift nor label shift assumptions apply. We show that the optimal
target predictor can be non-parametrically identified with the help of concept
and proxy variables available only in the source domain, and unlabeled data
from the target. The identification results are constructive, immediately
suggesting an algorithm for estimating the optimal predictor in the target. For
continuous observations, when this algorithm becomes impractical, we propose a
latent variable model specific to the data generation process at hand. We show
how the approach degrades as the size of the shift changes, and verify that it
outperforms both covariate and label shift adjustment.",None,-1
538c9be1-3eb8-4aaf-b630-1eb05185eb97,Generating Authentic Adversarial Examples beyond Meaning-preserving with Doubly Round-trip Translation,0.532949,"Generating adversarial examples for Neural Machine Translation (NMT) with
single Round-Trip Translation (RTT) has achieved promising results by releasing
the meaning-preserving restriction. However, a potential pitfall for this
approach is that we cannot decide whether the generated examples are
adversarial to the target NMT model or the auxiliary backward one, as the
reconstruction error through the RTT can be related to either. To remedy this
problem, we propose a new criterion for NMT adversarial examples based on the
Doubly Round-Trip Translation (DRTT). Specifically, apart from the
source-target-source RTT, we also consider the target-source-target one, which
is utilized to pick out the authentic adversarial examples for the target NMT
model. Additionally, to enhance the robustness of the NMT model, we introduce
the masked language models to construct bilingual adversarial pairs based on
DRTT, which are used to train the NMT model directly. Extensive experiments on
both the clean and noisy test sets (including the artificial and natural noise)
show that our approach substantially improves the robustness of NMT models.",https://github.com/lisasiyu/DRTT,-1
12772d86-c5bb-4164-8003-ca75ed66337b,Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,0.668811,"Previous knowledge graph embedding approaches usually map entities to
representations and utilize score functions to predict the target entities, yet
they typically struggle to reason rare or emerging unseen entities. In this
paper, we propose kNN-KGE, a new knowledge graph embedding approach with
pre-trained language models, by linearly interpolating its entity distribution
with k-nearest neighbors. We compute the nearest neighbors based on the
distance in the entity embedding space from the knowledge store. Our approach
can allow rare or emerging entities to be memorized explicitly rather than
implicitly in model parameters. Experimental results demonstrate that our
approach can improve inductive and transductive link prediction results and
yield better performance for low-resource settings with only a few triples,
which might be easier to reason via explicit memory. Code is available at
https://github.com/zjunlp/KNN-KG.",https://github.com/zjunlp/KNN-KG,-1
5fac2e2d-0c81-4db1-a1b8-aeb3d43abcd0,Optimizing Camera Placements for Overlapped Coverage with 3D Camera Projections,0.0716476,"This paper proposes a method to compute camera 6Dof poses to achieve a user
defined coverage. The camera placement problem is modeled as a combinatorial
optimization where given the maximum number of cameras, a camera set is
selected from a larger pool of possible camera poses. We propose to minimize
the squared error between the desired and the achieved coverage, and formulate
the non-linear cost function as a mixed integer linear programming problem. A
camera lens model is utilized to project the cameras view on a 3D voxel map to
compute a coverage score which makes the optimization problem in real
environments tractable. Experimental results in two real retail store
environments demonstrate the better performance of the proposed formulation in
terms of coverage and overlap for triangulation compared to existing methods.",None,-1
47affddc-98b6-4be5-af69-0031e422e073,Russian SuperGLUE 1.1: Revising the Lessons not Learned by Russian NLP models,0.0205492,"In the last year, new neural architectures and multilingual pre-trained
models have been released for Russian, which led to performance evaluation
problems across a range of language understanding tasks.
  This paper presents Russian SuperGLUE 1.1, an updated benchmark styled after
GLUE for Russian NLP models. The new version includes a number of technical,
user experience and methodological improvements, including fixes of the
benchmark vulnerabilities unresolved in the previous version: novel and
improved tests for understanding the meaning of a word in context (RUSSE) along
with reading comprehension and common sense reasoning (DaNetQA, RuCoS, MuSeRC).
Together with the release of the updated datasets, we improve the benchmark
toolkit based on \texttt{jiant} framework for consistent training and
evaluation of NLP-models of various architectures which now supports the most
recent models for Russian. Finally, we provide the integration of Russian
SuperGLUE with a framework for industrial evaluation of the open-source models,
MOROCCO (MOdel ResOurCe COmparison), in which the models are evaluated
according to the weighted average metric over all tasks, the inference speed,
and the occupied amount of RAM. Russian SuperGLUE is publicly available at
https://russiansuperglue.com/.",https://github.com/sberbank-ai/ru-gpts/tree/master,-1
b63c18f2-0441-49d9-96c7-4891fb70500e,Detecting Emerging Technologies and their Evolution using Deep Learning and Weak Signal Analysis,0.506184,"Emerging technologies can have major economic impacts and affect strategic
stability. Yet, early identification of emerging technologies remains
challenging. In order to identify emerging technologies in a timely and
reliable manner, a comprehensive examination of relevant scientific and
technological (S&T) trends and their related references is required. This
examination is generally done by domain experts and requires significant
amounts of time and effort to gain insights. The use of domain experts to
identify emerging technologies from S&T trends may limit the capacity to
analyse large volumes of information and introduce subjectivity in the
assessments. Decision support systems are required to provide accurate and
reliable evidence-based indicators through constant and continuous monitoring
of the environment and help identify signals of emerging technologies that
could alter security and economic prosperity. For example, the research field
of hypersonics has recently witnessed several advancements having profound
technological, commercial, and national security implications. In this work, we
present a multi-layer quantitative approach able to identify future signs from
scientific publications on hypersonics by leveraging deep learning and weak
signal analysis. The proposed framework can help strategic planners and domain
experts better identify and monitor emerging technology trends.",None,-1
6219b719-c23a-4f1b-9813-baa46419af54,Model-Free Opponent Shaping,0.585135,"In general-sum games, the interaction of self-interested learning agents
commonly leads to collectively worst-case outcomes, such as defect-defect in
the iterated prisoner's dilemma (IPD). To overcome this, some methods, such as
Learning with Opponent-Learning Awareness (LOLA), shape their opponents'
learning process. However, these methods are myopic since only a small number
of steps can be anticipated, are asymmetric since they treat other agents as
naive learners, and require the use of higher-order derivatives, which are
calculated through white-box access to an opponent's differentiable learning
algorithm. To address these issues, we propose Model-Free Opponent Shaping
(M-FOS). M-FOS learns in a meta-game in which each meta-step is an episode of
the underlying inner game. The meta-state consists of the inner policies, and
the meta-policy produces a new inner policy to be used in the next episode.
M-FOS then uses generic model-free optimisation methods to learn meta-policies
that accomplish long-horizon opponent shaping. Empirically, M-FOS
near-optimally exploits naive learners and other, more sophisticated algorithms
from the literature. For example, to the best of our knowledge, it is the first
method to learn the well-known Zero-Determinant (ZD) extortion strategy in the
IPD. In the same settings, M-FOS leads to socially optimal outcomes under
meta-self-play. Finally, we show that M-FOS can be scaled to high-dimensional
settings.",https://github.com/luchris429/Model-Free-Opponent-Shaping,-1
79969bf1-70d6-41f3-93d6-714977313f8e,Stubborn: A Strong Baseline for Indoor Object Navigation,0.852072,"We present a strong baseline that surpasses the performance of previously
published methods on the Habitat Challenge task of navigating to a target
object in indoor environments. Our method is motivated from primary failure
modes of prior state-of-the-art: poor exploration, inaccurate object
identification, and agent getting trapped due to imprecise map construction. We
make three contributions to mitigate these issues: (i) First, we show that
existing map-based methods fail to effectively use semantic clues for
exploration. We present a semantic-agnostic exploration strategy (called
Stubborn) without any learning that surprisingly outperforms prior work. (ii)
We propose a strategy for integrating temporal information to improve object
identification. (iii) Lastly, due to inaccurate depth observation the agent
often gets trapped in small regions. We develop a multi-scale collision map for
obstacle identification that mitigates this issue.",https://github.com/Improbable-AI/Stubborn,-1
f5eeed21-818b-4443-a55e-f1c4fc89509b,Speeding Up Action Recognition Using Dynamic Accumulation of Residuals in Compressed Domain,0.182805,"With the widespread use of installed cameras, video-based monitoring
approaches have seized considerable attention for different purposes like
assisted living. Temporal redundancy and the sheer size of raw videos are the
two most common problematic issues related to video processing algorithms. Most
of the existing methods mainly focused on increasing accuracy by exploring
consecutive frames, which is laborious and cannot be considered for real-time
applications. Since videos are mostly stored and transmitted in compressed
format, these kinds of videos are available on many devices. Compressed videos
contain a multitude of beneficial information, such as motion vectors and
quantized coefficients. Proper use of this available information can greatly
improve the video understanding methods' performance. This paper presents an
approach for using residual data, available in compressed videos directly,
which can be obtained by a light partially decoding procedure. In addition, a
method for accumulating similar residuals is proposed, which dramatically
reduces the number of processed frames for action recognition. Applying neural
networks exclusively for accumulated residuals in the compressed domain
accelerates performance, while the classification results are highly
competitive with raw video approaches.",None,-1
6904dc81-193d-49e0-8d8c-11bf22372a82,MotionSC: Data Set and Network for Real-Time Semantic Mapping in Dynamic Environments,0.484447,"This work addresses a gap in semantic scene completion (SSC) data by creating
a novel outdoor data set with accurate and complete dynamic scenes. Our data
set is formed from randomly sampled views of the world at each time step, which
supervises generalizability to complete scenes without occlusions or traces. We
create SSC baselines from state-of-the-art open source networks and construct a
benchmark real-time dense local semantic mapping algorithm, MotionSC, by
leveraging recent 3D deep learning architectures to enhance SSC with temporal
information. Our network shows that the proposed data set can quantify and
supervise accurate scene completion in the presence of dynamic objects, which
can lead to the development of improved dynamic mapping algorithms. All
software is available at https://github.com/UMich-CURLY/3DMapping.",https://github.com/UMich-CURLY/3DMapping,-1
8811ce7d-69da-4bd6-b62f-4f1506ffa36d,Can Visual Context Improve Automatic Speech Recognition for an Embodied Agent?,0.282516,"The usage of automatic speech recognition (ASR) systems are becoming
omnipresent ranging from personal assistant to chatbots, home, and industrial
automation systems, etc. Modern robots are also equipped with ASR capabilities
for interacting with humans as speech is the most natural interaction modality.
However, ASR in robots faces additional challenges as compared to a personal
assistant. Being an embodied agent, a robot must recognize the physical
entities around it and therefore reliably recognize the speech containing the
description of such entities. However, current ASR systems are often unable to
do so due to limitations in ASR training, such as generic datasets and
open-vocabulary modeling. Also, adverse conditions during inference, such as
noise, accented, and far-field speech makes the transcription inaccurate. In
this work, we present a method to incorporate a robot's visual information into
an ASR system and improve the recognition of a spoken utterance containing a
visible entity. Specifically, we propose a new decoder biasing technique to
incorporate the visual context while ensuring the ASR output does not degrade
for incorrect context. We achieve a 59% relative reduction in WER from an
unmodified ASR system.",https://github.com/mozilla/TTS,-1
f918f1f5-1144-47c2-aba8-70b166b0beca,EpiGNN: Exploring Spatial Transmission with Graph Neural Network for Regional Epidemic Forecasting,0.497115,"Epidemic forecasting is the key to effective control of epidemic transmission
and helps the world mitigate the crisis that threatens public health. To better
understand the transmission and evolution of epidemics, we propose EpiGNN, a
graph neural network-based model for epidemic forecasting. Specifically, we
design a transmission risk encoding module to characterize local and global
spatial effects of regions in epidemic processes and incorporate them into the
model. Meanwhile, we develop a Region-Aware Graph Learner (RAGL) that takes
transmission risk, geographical dependencies, and temporal information into
account to better explore spatial-temporal dependencies and makes regions aware
of related regions' epidemic situations. The RAGL can also combine with
external resources, such as human mobility, to further improve prediction
performance. Comprehensive experiments on five real-world epidemic-related
datasets (including influenza and COVID-19) demonstrate the effectiveness of
our proposed method and show that EpiGNN outperforms state-of-the-art baselines
by 9.48% in RMSE.",https://github.com/Xiefeng69/EpiGNN,-1
86c5b040-0cbf-4016-a2d8-4d47e24d5606,"AugShuffleNet: Communicate More, Compute Less",0.0848053,"As a remarkable compact model, ShuffleNetV2 offers a good example to design
efficient ConvNets but its limit is rarely noticed. In this paper, we rethink
the design pattern of ShuffleNetV2 and find that the channel-wise redundancy
problem still constrains the efficiency improvement of Shuffle block in the
wider ShuffleNetV2. To resolve this issue, we propose another augmented variant
of shuffle block in the form of bottleneck-like structure and more implicit
short connections. To verify the effectiveness of this building block, we
further build a more powerful and efficient model family, termed as
AugShuffleNets. Evaluated on the CIFAR-10 and CIFAR-100 datasets, AugShuffleNet
consistently outperforms ShuffleNetV2 in terms of accuracy with less
computational cost and fewer parameter count.",None,-1
7fc2296a-40e2-4cdc-a29d-a5e3a8d5db00,Pseudo-labelling and Meta Reweighting Learning for Image Aesthetic Quality Assessment,0.112689,"In the tasks of image aesthetic quality evaluation, it is difficult to reach
both the high score area and low score area due to the normal distribution of
aesthetic datasets. To reduce the error in labeling and solve the problem of
normal data distribution, we propose a new aesthetic mixed dataset with
classification and regression called AMD-CR, and we train a meta reweighting
network to reweight the loss of training data differently. In addition, we
provide a training strategy acccording to different stages, based on pseudo
labels of the binary classification task, and then we use it for aesthetic
training acccording to different stages in classification and regression tasks.
In the construction of the network structure, we construct an aesthetic
adaptive block (AAB) structure that can adapt to any size of the input images.
Besides, we also use the efficient channel attention (ECA) to strengthen the
feature extracting ability of each task. The experimental result shows that our
method improves 0.1112 compared with the conventional methods in SROCC. The
method can also help to find best aesthetic path planning for unmanned aerial
vehicles (UAV) and vehicles.",None,-1
586edef8-718b-449e-acf3-7752810a8f4c,Building a Role Specified Open-Domain Dialogue System Leveraging Large-Scale Language Models,0.991265,"Recent open-domain dialogue models have brought numerous breakthroughs.
However, building a chat system is not scalable since it often requires a
considerable volume of human-human dialogue data, especially when enforcing
features such as persona, style, or safety. In this work, we study the
challenge of imposing roles on open-domain dialogue systems, with the goal of
making the systems maintain consistent roles while conversing naturally with
humans. To accomplish this, the system must satisfy a role specification that
includes certain conditions on the stated features as well as a system policy
on whether or not certain types of utterances are allowed. For this, we propose
an efficient data collection framework leveraging in-context few-shot learning
of large-scale language models for building role-satisfying dialogue dataset
from scratch. We then compare various architectures for open-domain dialogue
systems in terms of meeting role specifications while maintaining
conversational abilities. Automatic and human evaluations show that our models
return few out-of-bounds utterances, keeping competitive performance on general
metrics. We release a Korean dialogue dataset we built for further research.",https://github.com/naver-ai/carecall-corpus,-1
f16b640b-e135-48b7-a93f-0cce5e538aa5,Wav2Vec-Aug: Improved self-supervised training with limited data,0.345182,"Self-supervised learning (SSL) of speech representations has received much
attention over the last few years but most work has focused on languages and
domains with an abundance of unlabeled data. However, for many languages there
is a shortage even in the unlabeled data which limits the effectiveness of SSL.
In this work, we focus on the problem of applying SSL to domains with limited
available data by leveraging data augmentation for Wav2Vec 2.0 pretraining.
Further, we propose improvements to each component of the model which result in
a combined relative word error rate (WER) improvement of up to 13% compared to
Wav2Vec 2.0 on Librispeech test-clean / other.",https://github.com/facebookresearch/WavAugment,-1
24874699-eda5-4a44-ae5f-d3bf28be6195,Ray3D: ray-based 3D human pose estimation for monocular absolute 3D localization,0.776092,"In this paper, we propose a novel monocular ray-based 3D (Ray3D) absolute
human pose estimation with calibrated camera. Accurate and generalizable
absolute 3D human pose estimation from monocular 2D pose input is an ill-posed
problem. To address this challenge, we convert the input from pixel space to 3D
normalized rays. This conversion makes our approach robust to camera intrinsic
parameter changes. To deal with the in-the-wild camera extrinsic parameter
variations, Ray3D explicitly takes the camera extrinsic parameters as an input
and jointly models the distribution between the 3D pose rays and camera
extrinsic parameters. This novel network design is the key to the outstanding
generalizability of Ray3D approach. To have a comprehensive understanding of
how the camera intrinsic and extrinsic parameter variations affect the accuracy
of absolute 3D key-point localization, we conduct in-depth systematic
experiments on three single person 3D benchmarks as well as one synthetic
benchmark. These experiments demonstrate that our method significantly
outperforms existing state-of-the-art models. Our code and the synthetic
dataset are available at https://github.com/YxZhxn/Ray3D .",https://github.com/YxZhxn/Ray3D,-1
d3e4ee1b-6c68-4906-b5d3-ef7b907924da,WAVPROMPT: Towards Few-Shot Spoken Language Understanding with Frozen Language Models,0.184424,"Large-scale auto-regressive language models pretrained on massive text have
demonstrated their impressive ability to perform new natural language tasks
with only a few text examples, without the need for fine-tuning. Recent studies
further show that such a few-shot learning ability can be extended to the
text-image setting by training an encoder to encode the images into embeddings
functioning like the text embeddings of the language model. Interested in
exploring the possibility of transferring the few-shot learning ability to the
audio-text setting, we propose a novel speech understanding framework,
WavPrompt, where we finetune a wav2vec model to generate a sequence of audio
embeddings understood by the language model. We show that WavPrompt is a
few-shot learner that can perform speech understanding tasks better than a
naive text baseline. We conduct detailed ablation studies on different
components and hyperparameters to empirically identify the best model
configuration. In addition, we conduct a non-speech understanding experiment to
show WavPrompt can extract more information than just the transcriptions. Code
is available at https://github.com/Hertin/WavPrompt",https://github.com/Hertin/WavPrompt,-1
60ae8c31-2f0c-43b5-ad55-e15c5e80e86a,A Temporal-Pattern Backdoor Attack to Deep Reinforcement Learning,0.416355,"Deep reinforcement learning (DRL) has made significant achievements in many
real-world applications. But these real-world applications typically can only
provide partial observations for making decisions due to occlusions and noisy
sensors. However, partial state observability can be used to hide malicious
behaviors for backdoors. In this paper, we explore the sequential nature of DRL
and propose a novel temporal-pattern backdoor attack to DRL, whose trigger is a
set of temporal constraints on a sequence of observations rather than a single
observation, and effect can be kept in a controllable duration rather than in
the instant. We validate our proposed backdoor attack to a typical job
scheduling task in cloud computing. Numerous experimental results show that our
backdoor can achieve excellent effectiveness, stealthiness, and sustainability.
Our backdoor's average clean data accuracy and attack success rate can reach
97.8% and 97.5%, respectively.",https://github.com/EboYu/DRLBackdoor,-1
1734ac26-8790-4215-9801-9f7504dbad73,Pixel is All You Need: Adversarial Trajectory-Ensemble Active Learning for Salient Object Detection,0.068232,"Although weakly-supervised techniques can reduce the labeling effort, it is
unclear whether a saliency model trained with weakly-supervised data (e.g.,
point annotation) can achieve the equivalent performance of its
fully-supervised version. This paper attempts to answer this unexplored
question by proving a hypothesis: there is a point-labeled dataset where
saliency models trained on it can achieve equivalent performance when trained
on the densely annotated dataset. To prove this conjecture, we proposed a novel
yet effective adversarial trajectory-ensemble active learning (ATAL). Our
contributions are three-fold: 1) Our proposed adversarial attack triggering
uncertainty can conquer the overconfidence of existing active learning methods
and accurately locate these uncertain pixels. {2)} Our proposed
trajectory-ensemble uncertainty estimation method maintains the advantages of
the ensemble networks while significantly reducing the computational cost. {3)}
Our proposed relationship-aware diversity sampling algorithm can conquer
oversampling while boosting performance. Experimental results show that our
ATAL can find such a point-labeled dataset, where a saliency model trained on
it obtained $97\%$ -- $99\%$ performance of its fully-supervised version with
only ten annotated points per image.",None,14647
8bfcc3b1-9625-4745-adc7-9fb98f982d0b,Using Linguistic Typology to Enrich Multilingual Lexicons: the Case of Lexical Gaps in Kinship,0.536722,"This paper describes a method to enrich lexical resources with content
relating to linguistic diversity, based on knowledge from the field of lexical
typology. We capture the phenomenon of diversity through the notions of lexical
gap and language-specific word and use a systematic method to infer gaps
semi-automatically on a large scale. As a first result obtained for the domain
of kinship terminology, known to be very diverse throughout the world, we
publish a lexico-semantic resource consisting of 198 domain concepts, 1,911
words, and 37,370 gaps covering 699 languages. We see potential in the use of
resources such as ours for the improvement of a variety of cross-lingual NLP
tasks, which we demonstrate through a downstream application for the evaluation
of machine translation systems.",https://github.com/kbatsuren/KinDiv,-1
a822d14e-482b-4da4-9668-185e3848c5a7,Outliers Dimensions that Disrupt Transformers Are Driven by Frequency,0.768856,"While Transformer-based language models are generally very robust to pruning,
there is the recently discovered outlier phenomenon: disabling only 48 out of
110M parameters in BERT-base drops its performance by nearly 30% on MNLI. We
replicate the original evidence for the outlier phenomenon and we link it to
the geometry of the embedding space. We find that in both BERT and RoBERTa the
magnitude of hidden state coefficients corresponding to outlier dimensions
correlates with the frequency of encoded tokens in pre-training data, and it
also contributes to the ""vertical"" self-attention pattern enabling the model to
focus on the special tokens. This explains the drop in performance from
disabling the outliers, and it suggests that to decrease anisotropicity in
future models we need pre-training schemas that would better take into account
the skewed token distributions.",https://github.com/gpucce/outliersvsfreq/,-1
5cdb7db5-8850-4d26-91b5-d54edb289edb,Constrained Optimization with Dynamic Bound-scaling for Effective NLPBackdoor Defense,0.822469,"We develop a novel optimization method for NLPbackdoor inversion. We leverage
a dynamically reducing temperature coefficient in the softmax function to
provide changing loss landscapes to the optimizer such that the process
gradually focuses on the ground truth trigger, which is denoted as a one-hot
value in a convex hull. Our method also features a temperature rollback
mechanism to step away from local optimals, exploiting the observation that
local optimals can be easily deter-mined in NLP trigger inversion (while not in
general optimization). We evaluate the technique on over 1600 models (with
roughly half of them having injected backdoors) on 3 prevailing NLP tasks, with
4 different backdoor attacks and 7 architectures. Our results show that the
technique is able to effectively and efficiently detect and remove backdoors,
outperforming 4 baseline methods.",None,-1
4fde5a6d-22bb-40d6-9620-84ef6e589fa5,Object-wise Masked Autoencoders for Fast Pre-training,0.332349,"Self-supervised pre-training for images without labels has recently achieved
promising performance in image classification. The success of transformer-based
methods, ViT and MAE, draws the community's attention to the design of backbone
architecture and self-supervised task. In this work, we show that current
masked image encoding models learn the underlying relationship between all
objects in the whole scene, instead of a single object representation.
Therefore, those methods bring a lot of compute time for self-supervised
pre-training. To solve this issue, we introduce a novel object selection and
division strategy to drop non-object patches for learning object-wise
representations by selective reconstruction with interested region masks. We
refer to this method ObjMAE. Extensive experiments on four commonly-used
datasets demonstrate the effectiveness of our model in reducing the compute
cost by 72% while achieving competitive performance. Furthermore, we
investigate the inter-object and intra-object relationship and find that the
latter is crucial for self-supervised pre-training.",https://github.com/facebookresearch/clevr-dataset-gen,-1
541ee0e1-c310-49d8-a59a-05e4b7ef3b5b,Proceedings of the 2nd International Workshop on Reading Music Systems,0.533495,"The International Workshop on Reading Music Systems (WoRMS) is a workshop
that tries to connect researchers who develop systems for reading music, such
as in the field of Optical Music Recognition, with other researchers and
practitioners that could benefit from such systems, like librarians or
musicologists.
  The relevant topics of interest for the workshop include, but are not limited
to: Music reading systems; Optical music recognition; Datasets and performance
evaluation; Image processing on music scores; Writer identification; Authoring,
editing, storing and presentation systems for music scores; Multi-modal
systems; Novel input-methods for music to produce written music; Web-based
Music Information Retrieval services; Applications and projects; Use-cases
related to written music.
  These are the proceedings of the 2nd International Workshop on Reading Music
Systems, held in Delft on the 2nd of November 2019.",None,-1
52cb5838-0a7e-493a-a358-081f977d5052,Logical Reasoning with Span-Level Predictions for Interpretable and Robust NLI Models,0.148122,"Current Natural Language Inference (NLI) models achieve impressive results,
sometimes outperforming humans when evaluating on in-distribution test sets.
However, as these models are known to learn from annotation artefacts and
dataset biases, it is unclear to what extent the models are learning the task
of NLI instead of learning from shallow heuristics in their training data. We
address this issue by introducing a logical reasoning framework for NLI,
creating highly transparent model decisions that are based on logical rules.
Unlike prior work, we show that improved interpretability can be achieved
without decreasing the predictive accuracy. We almost fully retain performance
on SNLI, while also identifying the exact hypothesis spans that are responsible
for each model prediction. Using the e-SNLI human explanations, we verify that
our model makes sensible decisions at a span level, despite not using any span
labels during training. We can further improve model performance and span-level
decisions by using the e-SNLI explanations during training. Finally, our model
is more robust in a reduced data setting. When training with only 1,000
examples, out-of-distribution performance improves on the MNLI matched and
mismatched validation sets by 13% and 16% relative to the baseline. Training
with fewer observations yields further improvements, both in-distribution and
out-of-distribution.",https://github.com/joestacey/snli_logic,-1
b63f4ba4-b7f4-4d59-9079-5633570b8c65,Mitigating Artifacts in Real-World Video Super-Resolution Models,0.568923,"The recurrent structure is a prevalent framework for the task of video
super-resolution, which models the temporal dependency between frames via
hidden states. When applied to real-world scenarios with unknown and complex
degradations, hidden states tend to contain unpleasant artifacts and propagate
them to restored frames. In this circumstance, our analyses show that such
artifacts can be largely alleviated when the hidden state is replaced with a
cleaner counterpart. Based on the observations, we propose a Hidden State
Attention (HSA) module to mitigate artifacts in real-world video
super-resolution. Specifically, we first adopt various cheap filters to produce
a hidden state pool. For example, Gaussian blur filters are for smoothing
artifacts while sharpening filters are for enhancing details. To aggregate a
new hidden state that contains fewer artifacts from the hidden state pool, we
devise a Selective Cross Attention (SCA) module, in which the attention between
input features and each hidden state is calculated. Equipped with HSA, our
proposed method, namely FastRealVSR, is able to achieve 2x speedup while
obtaining better performance than Real-BasicVSR. Codes will be available at
https://github.com/TencentARC/FastRealVSR",https://github.com/TencentARC/FastRealVSR,-1
75ae2874-4fe4-4ca1-abcf-cbd2ec793ef7,A Benchmark dataset for predictive maintenance,0.553488,"The paper describes the MetroPT data set, an outcome of a eXplainable
Predictive Maintenance (XPM) project with an urban metro public transportation
service in Porto, Portugal. The data was collected in 2022 that aimed to
evaluate machine learning methods for online anomaly detection and failure
prediction. By capturing several analogic sensor signals (pressure,
temperature, current consumption), digital signals (control signals, discrete
signals), and GPS information (latitude, longitude, and speed), we provide a
dataset that can be easily used to evaluate online machine learning methods.
This dataset contains some interesting characteristics and can be a good
benchmark for predictive maintenance models.",None,-1
ae1e60a1-fd8e-40f3-83a4-9ab8ddcbaa0a,NamedMask: Distilling Segmenters from Complementary Foundation Models,0.45153,"The goal of this work is to segment and name regions of images without access
to pixel-level labels during training. To tackle this task, we construct
segmenters by distilling the complementary strengths of two foundation models.
The first, CLIP (Radford et al. 2021), exhibits the ability to assign names to
image content but lacks an accessible representation of object structure. The
second, DINO (Caron et al. 2021), captures the spatial extent of objects but
has no knowledge of object names. Our method, termed NamedMask, begins by using
CLIP to construct category-specific archives of images. These images are
pseudo-labelled with a category-agnostic salient object detector bootstrapped
from DINO, then refined by category-specific segmenters using the CLIP archive
labels. Thanks to the high quality of the refined masks, we show that a
standard segmentation architecture trained on these archives with appropriate
data augmentation achieves impressive semantic segmentation abilities for both
single-object and multi-object images. As a result, our proposed NamedMask
performs favourably against a range of prior work on five benchmarks including
the VOC2012, COCO and large-scale ImageNet-S datasets.",https://www.robots.ox.ac.uk/~vgg/research/namedmask,-1
601fa20a-feaf-4e00-903c-c079c4dfa074,Open-domain Question Answering via Chain of Reasoning over Heterogeneous Knowledge,0.39421,"We propose a novel open-domain question answering (ODQA) framework for
answering single/multi-hop questions across heterogeneous knowledge sources.
The key novelty of our method is the introduction of the intermediary modules
into the current retriever-reader pipeline. Unlike previous methods that solely
rely on the retriever for gathering all evidence in isolation, our intermediary
performs a chain of reasoning over the retrieved set. Specifically, our method
links the retrieved evidence with its related global context into graphs and
organizes them into a candidate list of evidence chains. Built upon pretrained
language models, our system achieves competitive performance on two ODQA
datasets, OTT-QA and NQ, against tables and passages from Wikipedia. In
particular, our model substantially outperforms the previous state-of-the-art
on OTT-QA with an exact match score of 47.3 (45 % relative gain).",https://github.com/Mayer123/UDT-QA,-1
b0ad29c2-950e-433b-a27f-602639ec1568,BudgetLongformer: Can we Cheaply Pretrain a SotA Legal Language Model From Scratch?,0.285958,"Pretrained transformer models have achieved state-of-the-art results in many
tasks and benchmarks recently. Many state-of-the-art Language Models (LMs),
however, do not scale well above the threshold of 512 input tokens. In
specialized domains though (such as legal, scientific or biomedical), models
often need to process very long text (sometimes well above 10000 tokens). Even
though many efficient transformers have been proposed (such as Longformer,
BigBird or FNet), so far, only very few such efficient models are available for
specialized domains. Additionally, since the pretraining process is extremely
costly in general - but even more so as the sequence length increases - it is
often only in reach of large research labs. One way of making pretraining
cheaper is the Replaced Token Detection (RTD) task, by providing more signal
during training, since the loss can be computed over all tokens. In this work,
we train Longformer models with the efficient RTD task on legal data to
showcase that pretraining efficient LMs is possible using much less compute. We
evaluate the trained models on challenging summarization tasks requiring the
model to summarize long texts to show to what extent the models can achieve
good performance on downstream tasks. We find that both the small and base
models outperform their baselines on the in-domain BillSum and out-of-domain
PubMed tasks in their respective parameter range. We publish our code and
models for research purposes.",https://github.com/coastalcph/lex-gl,-1
937e72d2-26ce-4d9c-b6e7-2af2bdca00c8,Towards an Automatic Diagnosis of Peripheral and Central Palsy Using Machine Learning on Facial Features,0.231406,"Central palsy is a form of facial paralysis that requires urgent medical
attention and has to be differentiated from other, similar conditions such as
peripheral palsy. To aid in fast and accurate diagnosis of this condition, we
propose a machine learning approach to automatically classify peripheral and
central facial palsy. The Palda dataset is used, which contains 103 peripheral
palsy images, 40 central palsy, and 60 healthy people. Experiments are run on
five machine learning algorithms. The best performing algorithms were found to
be the SVM (total accuracy of 85.1%) and the Gaussian naive Bayes (80.7%). The
lowest false negative rate on central palsy was achieved by the naive Bayes
approach (80% compared to 70%). This condition could prove to be the most
severe, and thus its sensitivity is another good way to compare algorithms. By
extrapolation, a dataset size of 334 total pictures is estimated to achieve a
central palsy sensitivity of 95%. All code used for these machine learning
experiments is freely available online at https://github.com/cvvletter/palsy.",https://github.com/cvvletter/palsy,-1
14a4291b-e57c-450d-bac1-c4f402359ecc,Geometric Features Informed Multi-person Human-object Interaction Recognition in Videos,0.327975,"Human-Object Interaction (HOI) recognition in videos is important for
analyzing human activity. Most existing work focusing on visual features
usually suffer from occlusion in the real-world scenarios. Such a problem will
be further complicated when multiple people and objects are involved in HOIs.
Consider that geometric features such as human pose and object position provide
meaningful information to understand HOIs, we argue to combine the benefits of
both visual and geometric features in HOI recognition, and propose a novel
Two-level Geometric feature-informed Graph Convolutional Network (2G-GCN). The
geometric-level graph models the interdependency between geometric features of
humans and objects, while the fusion-level graph further fuses them with visual
features of humans and objects. To demonstrate the novelty and effectiveness of
our method in challenging scenarios, we propose a new multi-person HOI dataset
(MPHOI-72). Extensive experiments on MPHOI-72 (multi-person HOI), CAD-120
(single-human HOI) and Bimanual Actions (two-hand HOI) datasets demonstrate our
superior performance compared to state-of-the-arts.",https://github.com/tanqiu98/2G-GCN,6272
140ca47d-51a5-4d2b-9db5-e78aaea207a5,Tencent's Multilingual Machine Translation System for WMT22 Large-Scale African Languages,0.590783,"This paper describes Tencent's multilingual machine translation systems for
the WMT22 shared task on Large-Scale Machine Translation Evaluation for African
Languages. We participated in the $\mathbf{constrained}$ translation track in
which only the data and pretrained models provided by the organizer are
allowed. The task is challenging due to three problems, including the absence
of training data for some to-be-evaluated language pairs, the uneven
optimization of language pairs caused by data imbalance, and the curse of
multilinguality. To address these problems, we adopt data augmentation,
distributionally robust optimization, and language family grouping,
respectively, to develop our multilingual neural machine translation (MNMT)
models. Our submissions won the $\mathbf{1st\ place}$ on the blind test sets in
terms of the automatic evaluation metrics. Codes, models, and detailed
competition results are available at
https://github.com/wxjiao/WMT2022-Large-Scale-African.",https://github.com/wxjiao/,-1
c9f298bc-ca76-4953-bb54-09926e5d2dbc,You Only Derive Once (YODO): Automatic Differentiation for Efficient Sensitivity Analysis in Bayesian Networks,0.281696,"Sensitivity analysis measures the influence of a Bayesian network's
parameters on a quantity of interest defined by the network, such as the
probability of a variable taking a specific value. In particular, the so-called
sensitivity value measures the quantity of interest's partial derivative with
respect to the network's conditional probabilities. However, finding such
values in large networks with thousands of parameters can become
computationally very expensive. We propose to use automatic differentiation
combined with exact inference to obtain all sensitivity values in a single
pass. Our method first marginalizes the whole network once using e.g. variable
elimination and then backpropagates this operation to obtain the gradient with
respect to all input parameters. We demonstrate our routines by ranking all
parameters by importance on a Bayesian network modeling humanitarian crises and
disasters, and then show the method's efficiency by scaling it to huge networks
with up to 100'000 parameters. An implementation of the methods using the
popular machine learning library PyTorch is freely available.",https://github.com/rballester/yodo,-1
faa9a032-4a47-41cc-ac5e-527c0de24b78,Improving Mandarin Speech Recogntion with Block-augmented Transformer,0.361389,"Recently Convolution-augmented Transformer (Conformer) has shown promising
results in Automatic Speech Recognition (ASR), outperforming the previous best
published Transformer Transducer. In this work, we believe that the output
information of each block in the encoder and decoder is not completely
inclusive, in other words, their output information may be complementary. We
study how to take advantage of the complementary information of each block in a
parameter-efficient way, and it is expected that this may lead to more robust
performance. Therefore we propose the Block-augmented Transformer for speech
recognition, named Blockformer. We have implemented two block ensemble methods:
the base Weighted Sum of the Blocks Output (Base-WSBO), and the
Squeeze-and-Excitation module to Weighted Sum of the Blocks Output (SE-WSBO).
Experiments have proved that the Blockformer significantly outperforms the
state-of-the-art Conformer-based models on AISHELL-1, our model achieves a CER
of 4.29\% without using a language model and 4.05\% with an external language
model on the testset.",https://github.com/Mininglamp-Technology/ASR-BlockFormer,-1
60f99a52-39db-4b7f-bd40-d51af45aeebe,Unsupervised Non-transferable Text Classification,0.185904,"Training a good deep learning model requires substantial data and computing
resources, which makes the resulting neural model a valuable intellectual
property. To prevent the neural network from being undesirably exploited,
non-transferable learning has been proposed to reduce the model generalization
ability in specific target domains. However, existing approaches require
labeled data for the target domain which can be difficult to obtain.
Furthermore, they do not have the mechanism to still recover the model's
ability to access the target domain. In this paper, we propose a novel
unsupervised non-transferable learning method for the text classification task
that does not require annotated target domain data. We further introduce a
secret key component in our approach for recovering the access to the target
domain, where we design both an explicit and an implicit method for doing so.
Extensive experiments demonstrate the effectiveness of our approach.",https://github.com/ChaosCodes/UNTL,-1
d1a30245-3de5-4fe6-8bac-6233882131c7,Fine-grained Category Discovery under Coarse-grained supervision with Hierarchical Weighted Self-contrastive Learning,0.798809,"Novel category discovery aims at adapting models trained on known categories
to novel categories. Previous works only focus on the scenario where known and
novel categories are of the same granularity. In this paper, we investigate a
new practical scenario called Fine-grained Category Discovery under
Coarse-grained supervision (FCDC). FCDC aims at discovering fine-grained
categories with only coarse-grained labeled data, which can adapt models to
categories of different granularity from known ones and reduce significant
labeling cost. It is also a challenging task since supervised training on
coarse-grained categories tends to focus on inter-class distance (distance
between coarse-grained classes) but ignore intra-class distance (distance
between fine-grained sub-classes) which is essential for separating
fine-grained categories. Considering most current methods cannot transfer
knowledge from coarse-grained level to fine-grained level, we propose a
hierarchical weighted self-contrastive network by building a novel weighted
self-contrastive module and combining it with supervised learning in a
hierarchical manner. Extensive experiments on public datasets show both
effectiveness and efficiency of our model over compared methods. Code and data
are available at https://github.com/Lackel/Hierarchical_Weighted_SCL.",https://github.com/Lackel/Hierarchical_Weighted_SCL,-1
9a1b1eea-73ff-44f6-b736-1b424ac44ae8,Transformer-Based Named Entity Recognition for French Using Adversarial Adaptation to Similar Domain Corpora,0.549094,"Named Entity Recognition (NER) involves the identification and classification
of named entities in unstructured text into predefined classes. NER in
languages with limited resources, like French, is still an open problem due to
the lack of large, robust, labelled datasets. In this paper, we propose a
transformer-based NER approach for French using adversarial adaptation to
similar domain or general corpora for improved feature extraction and better
generalization. We evaluate our approach on three labelled datasets and show
that our adaptation framework outperforms the corresponding non-adaptive models
for various combinations of transformer models, source datasets and target
corpora.",None,-1
d11579b3-fc21-4516-a5b1-3155b8dbbbdb,KATSum: Knowledge-aware Abstractive Text Summarization,0.0702935,"Text Summarization is recognised as one of the NLP downstream tasks and it
has been extensively investigated in recent years. It can assist people with
perceiving the information rapidly from the Internet, including news articles,
social posts, videos, etc. Most existing research works attempt to develop
summarization models to produce a better output. However, advent limitations of
most existing models emerge, including unfaithfulness and factual errors. In
this paper, we propose a novel model, named as Knowledge-aware Abstractive Text
Summarization, which leverages the advantages offered by Knowledge Graph to
enhance the standard Seq2Seq model. On top of that, the Knowledge Graph
triplets are extracted from the source text and utilised to provide keywords
with relational information, producing coherent and factually errorless
summaries. We conduct extensive experiments by using real-world data sets. The
results reveal that the proposed framework can effectively utilise the
information from Knowledge Graph and significantly reduce the factual errors in
the summary.",None,-1
7da2d6b1-294b-4fc0-a7da-5f0322397525,LwPosr: Lightweight Efficient Fine-Grained Head Pose Estimation,0.425235,"This paper presents a lightweight network for head pose estimation (HPE)
task. While previous approaches rely on convolutional neural networks, the
proposed network \textit{LwPosr} uses mixture of depthwise separable
convolutional (DSC) and transformer encoder layers which are structured in two
streams and three stages to provide fine-grained regression for predicting head
poses. The quantitative and qualitative demonstration is provided to show that
the proposed network is able to learn head poses efficiently while using less
parameter space. Extensive ablations are conducted using three open-source
datasets namely 300W-LP, AFLW2000, and BIWI datasets. To our knowledge, (1)
\textit{LwPosr} is the lightest network proposed for estimating head poses
compared to both keypoints-based and keypoints-free approaches; (2) it sets a
benchmark for both overperforming the previous lightweight network on mean
absolute error and on reducing number of parameters; (3) it is first of its
kind to use mixture of DSCs and transformer encoders for HPE. This approach is
suitable for mobile devices which require lightweight networks.",None,-1
082b69dc-5440-4c8a-af26-b87c3c7b58e8,Extending Process Discovery with Model Complexity Optimization and Cyclic States Identification: Application to Healthcare Processes,0.0467913,"Within Process mining, discovery techniques had made it possible to construct
business process models automatically from event logs. However, results often
do not achieve the balance between model complexity and its fitting accuracy,
so there is a need for manual model adjusting. The paper presents an approach
to process mining providing semi-automatic support to model optimization based
on the combined assessment of the model complexity and fitness. To balance
between the two ingredients, a model simplification approach is proposed, which
essentially abstracts the raw model at the desired granularity. Additionally,
we introduce a concept of meta-states, a cycle collapsing in the model, which
can potentially simplify the model and interpret it. We aim to demonstrate the
capabilities of the technological solution using three datasets from different
applications in the healthcare domain. They are remote monitoring process for
patients with arterial hypertension and workflows of healthcare workers during
the COVID-19 pandemic. A case study also investigates the use of various
complexity measures and different ways of solution application providing
insights on better practices in improving interpretability and
complexity/fitness balance in process models.",None,12
a26040c9-8c65-410c-b6ee-4d5611fa2816,Hybrid Reinforced Medical Report Generation with M-Linear Attention and Repetition Penalty,0.145095,"To reduce doctors' workload, deep-learning-based automatic medical report
generation has recently attracted more and more research efforts, where deep
convolutional neural networks (CNNs) are employed to encode the input images,
and recurrent neural networks (RNNs) are used to decode the visual features
into medical reports automatically. However, these state-of-the-art methods
mainly suffer from three shortcomings: (i) incomprehensive optimization, (ii)
low-order and unidimensional attention mechanisms, and (iii) repeated
generation. In this article, we propose a hybrid reinforced medical report
generation method with m-linear attention and repetition penalty mechanism
(HReMRG-MR) to overcome these problems. Specifically, a hybrid reward with
different weights is employed to remedy the limitations of single-metric-based
rewards. We also propose a search algorithm with linear complexity to
approximate the best weight combination. Furthermore, we use m-linear attention
modules to explore high-order feature interactions and to achieve multi-modal
reasoning, while a repetition penalty applies penalties to repeated terms
during the model's training process. Extensive experimental studies on two
public datasets show that HReMRG-MR greatly outperforms the state-of-the-art
baselines in terms of all metrics. We also conducted a series of ablation
experiments to prove the effectiveness of all our proposed components. We also
performed a reward search toy experiment to give evidence that our proposed
search approach can significantly reduce the search time while approximating
the best performance.",None,-1
6017263e-b40d-413c-a15d-d1a936810fb6,Linear Array Network for Low-light Image Enhancement,0.163402,"Convolution neural networks (CNNs) based methods have dominated the low-light
image enhancement tasks due to their outstanding performance. However, the
convolution operation is based on a local sliding window mechanism, which is
difficult to construct the long-range dependencies of the feature maps.
Meanwhile, the self-attention based global relationship aggregation methods
have been widely used in computer vision, but these methods are difficult to
handle high-resolution images because of the high computational complexity. To
solve this problem, this paper proposes a Linear Array Self-attention (LASA)
mechanism, which uses only two 2-D feature encodings to construct 3-D global
weights and then refines feature maps generated by convolution layers. Based on
LASA, Linear Array Network (LAN) is proposed, which is superior to the existing
state-of-the-art (SOTA) methods in both RGB and RAW based low-light enhancement
tasks with a smaller amount of parameters. The code is released in
https://github.com/cuiziteng/LASA_enhancement.",https://github.com/cuiziteng/LASA,-1
1ae53a9d-d6b9-4896-b5a5-c2c9c4658336,A case for using rotation invariant features in state of the art feature matchers,0.893859,"The aim of this paper is to demonstrate that a state of the art feature
matcher (LoFTR) can be made more robust to rotations by simply replacing the
backbone CNN with a steerable CNN which is equivariant to translations and
image rotations. It is experimentally shown that this boost is obtained without
reducing performance on ordinary illumination and viewpoint matching sequences.",https://github.com/georg-/se2-loftr,8663
f2e7c547-e386-4675-9afd-446cda5a10f1,DoWhy-GCM: An extension of DoWhy for causal inference in graphical causal models,0.569239,"We introduce DoWhy-GCM, an extension of the DoWhy Python library, that
leverages graphical causal models. Unlike existing causality libraries, which
mainly focus on effect estimation questions, with DoWhy-GCM, users can ask a
wide range of additional causal questions, such as identifying the root causes
of outliers and distributional changes, causal structure learning, attributing
causal influences, and diagnosis of causal structures. To this end, DoWhy-GCM
users first model cause-effect relations between variables in a system under
study through a graphical causal model, fit the causal mechanisms of variables
next, and then ask the causal question. All these steps take only a few lines
of code in DoWhy-GCM.
  The library is available at https://github.com/py-why/dowhy.",https://github.com/py-why/dowhy,-1
62b492d6-71bd-4b80-9acc-31e82eb7a223,Thinking the Fusion Strategy of Multi-reference Face Reenactment,0.120944,"In recent advances of deep generative models, face reenactment -manipulating
and controlling human face, including their head movement-has drawn much
attention for its wide range of applicability. Despite its strong
expressiveness, it is inevitable that the models fail to reconstruct or
accurately generate unseen side of the face of a given single reference image.
Most of existing methods alleviate this problem by learning appearances of
human faces from large amount of data and generate realistic texture at
inference time. Rather than completely relying on what generative models learn,
we show that simple extension by using multiple reference images significantly
improves generation quality. We show this by 1) conducting the reconstruction
task on publicly available dataset, 2) conducting facial motion transfer on our
original dataset which consists of multi-person's head movement video
sequences, and 3) using a newly proposed evaluation metric to validate that our
method achieves better quantitative results.",None,-1
1a7a4a11-955a-4a76-8bed-fcc083699044,How to Fine-Tune Vision Models with SGD,0.414509,"SGD and AdamW are the two most used optimizers for fine-tuning large neural
networks in computer vision. When the two methods perform the same, SGD is
preferable because it uses less memory (12 bytes/parameter with momentum and 8
bytes/parameter without) than AdamW (16 bytes/parameter). However, on a suite
of downstream tasks, especially those with distribution shifts, we find that
fine-tuning with AdamW performs substantially better than SGD on modern Vision
Transformer and ConvNeXt models. We find that large gaps in performance between
SGD and AdamW occur when the fine-tuning gradients in the first ""embedding""
layer are much larger than in the rest of the model. Our analysis suggests an
easy fix that works consistently across datasets and models: freezing the
embedding layer (less than 1% of the parameters) leads to SGD with or without
momentum performing slightly better than AdamW while using less memory (e.g.,
on ViT-L, SGD uses 33% less GPU memory). Our insights result in
state-of-the-art accuracies on five popular distribution shift benchmarks:
WILDS-FMoW, WILDS-Camelyon, BREEDS-Living-17, Waterbirds, and DomainNet.",None,4318
9fa9cf93-8a77-4710-88dd-b99688c3b4ef,An Extreme-Adaptive Time Series Prediction Model Based on Probability-Enhanced LSTM Neural Networks,0.277467,"Forecasting time series with extreme events has been a challenging and
prevalent research topic, especially when the time series data are affected by
complicated uncertain factors, such as is the case in hydrologic prediction.
Diverse traditional and deep learning models have been applied to discover the
nonlinear relationships and recognize the complex patterns in these types of
data. However, existing methods usually ignore the negative influence of
imbalanced data, or severe events, on model training. Moreover, methods are
usually evaluated on a small number of generally well-behaved time series,
which does not show their ability to generalize. To tackle these issues, we
propose a novel probability-enhanced neural network model, called NEC+, which
concurrently learns extreme and normal prediction functions and a way to choose
among them via selective back propagation. We evaluate the proposed model on
the difficult 3-day ahead hourly water level prediction task applied to 9
reservoirs in California. Experimental results demonstrate that the proposed
model significantly outperforms state-of-the-art baselines and exhibits
superior generalization ability on data with diverse distributions.",https://github.com/davidanastasiu/NECPlus,-1
37470a62-4931-4322-bb3d-f5a7ed2b0fcd,Differentiable Point-Based Radiance Fields for Efficient View Synthesis,0.556855,"We propose a differentiable rendering algorithm for efficient novel view
synthesis. By departing from volume-based representations in favor of a learned
point representation, we improve on existing methods more than an order of
magnitude in memory and runtime, both in training and inference. The method
begins with a uniformly-sampled random point cloud and learns per-point
position and view-dependent appearance, using a differentiable splat-based
renderer to evolve the model to match a set of input images. Our method is up
to 300x faster than NeRF in both training and inference, with only a marginal
sacrifice in quality, while using less than 10~MB of memory for a static scene.
For dynamic scenes, our method trains two orders of magnitude faster than
STNeRF and renders at near interactive rate, while maintaining high image
quality and temporal coherence even without imposing any temporal-coherency
regularizers.",None,97412
fe9ccf6e-56ca-40d8-91c4-5a7095640fe8,RerrFact: Reduced Evidence Retrieval Representations for Scientific Claim Verification,0.490597,"Exponential growth in digital information outlets and the race to publish has
made scientific misinformation more prevalent than ever. However, the task to
fact-verify a given scientific claim is not straightforward even for
researchers. Scientific claim verification requires in-depth knowledge and
great labor from domain experts to substantiate supporting and refuting
evidence from credible scientific sources. The SciFact dataset and
corresponding task provide a benchmarking leaderboard to the community to
develop automatic scientific claim verification systems via extracting and
assimilating relevant evidence rationales from source abstracts. In this work,
we propose a modular approach that sequentially carries out binary
classification for every prediction subtask as in the SciFact leaderboard. Our
simple classifier-based approach uses reduced abstract representations to
retrieve relevant abstracts. These are further used to train the relevant
rationale-selection model. Finally, we carry out two-step stance predictions
that first differentiate non-relevant rationales and then identify supporting
or refuting rationales for a given claim. Experimentally, our system RerrFact
with no fine-tuning, simple design, and a fraction of model parameters fairs
competitively on the leaderboard against large-scale, modular, and joint
modeling approaches. We make our codebase available at
https://github.com/ashishrana160796/RerrFact.",https://github.com/ashishrana160796/RerrFact,-1
215d3a98-25b0-43cf-b38d-89a08051c05d,Speech Emotion Recognition using Self-Supervised Features,0.997567,"Self-supervised pre-trained features have consistently delivered state-of-art
results in the field of natural language processing (NLP); however, their
merits in the field of speech emotion recognition (SER) still need further
investigation. In this paper we introduce a modular End-to- End (E2E) SER
system based on an Upstream + Downstream architecture paradigm, which allows
easy use/integration of a large variety of self-supervised features. Several
SER experiments for predicting categorical emotion classes from the IEMOCAP
dataset are performed. These experiments investigate interactions among
fine-tuning of self-supervised feature models, aggregation of frame-level
features into utterance-level features and back-end classification networks.
The proposed monomodal speechonly based system not only achieves SOTA results,
but also brings light to the possibility of powerful and well finetuned
self-supervised acoustic features that reach results similar to the results
achieved by SOTA multimodal systems using both Speech and Text modalities.",None,-1
a5d1c956-9b14-4399-8f65-b8c5ec128ffe,DFNet: Enhance Absolute Pose Regression with Direct Feature Matching,0.807341,"We introduce a camera relocalization pipeline that combines absolute pose
regression (APR) and direct feature matching. By incorporating
exposure-adaptive novel view synthesis, our method successfully addresses
photometric distortions in outdoor environments that existing photometric-based
methods fail to handle. With domain-invariant feature matching, our solution
improves pose regression accuracy using semi-supervised learning on unlabeled
data. In particular, the pipeline consists of two components: Novel View
Synthesizer and DFNet. The former synthesizes novel views compensating for
changes in exposure and the latter regresses camera poses and extracts robust
features that close the domain gap between real images and synthetic ones.
Furthermore, we introduce an online synthetic data generation scheme. We show
that these approaches effectively enhance camera pose estimation both in indoor
and outdoor scenes. Hence, our method achieves a state-of-the-art accuracy by
outperforming existing single-image APR methods by as much as 56%, comparable
to 3D structure-based methods.",None,-1
ebbc6dfa-47f7-4977-b611-b83fd0b498c6,Knowledge Distillation with the Reused Teacher Classifier,0.997165,"Knowledge distillation aims to compress a powerful yet cumbersome teacher
model into a lightweight student model without much sacrifice of performance.
For this purpose, various approaches have been proposed over the past few
years, generally with elaborately designed knowledge representations, which in
turn increase the difficulty of model development and interpretation. In
contrast, we empirically show that a simple knowledge distillation technique is
enough to significantly narrow down the teacher-student performance gap. We
directly reuse the discriminative classifier from the pre-trained teacher model
for student inference and train a student encoder through feature alignment
with a single $\ell_2$ loss. In this way, the student model is able to achieve
exactly the same performance as the teacher model provided that their extracted
features are perfectly aligned. An additional projector is developed to help
the student encoder match with the teacher classifier, which renders our
technique applicable to various teacher and student architectures. Extensive
experiments demonstrate that our technique achieves state-of-the-art results at
the modest cost of compression ratio due to the added projector.",https://github.com/Rorozhl/CA-MKD,-1
1bb9af51-0d48-43f7-b55b-c691b2af8722,Fine-grained Czech News Article Dataset: An Interdisciplinary Approach to Trustworthiness Analysis,0.24042,"We present the Verifee Dataset: a novel dataset of news articles with
fine-grained trustworthiness annotations. We develop a detailed methodology
that assesses the texts based on their parameters encompassing editorial
transparency, journalist conventions, and objective reporting while penalizing
manipulative techniques. We bring aboard a diverse set of researchers from
social, media, and computer sciences to overcome barriers and limited framing
of this interdisciplinary problem. We collect over $10,000$ unique articles
from almost $60$ Czech online news sources. These are categorized into one of
the $4$ classes across the credibility spectrum we propose, raging from
entirely trustworthy articles all the way to the manipulative ones. We produce
detailed statistics and study trends emerging throughout the set. Lastly, we
fine-tune multiple popular sequence-to-sequence language models using our
dataset on the trustworthiness classification task and report the best testing
F-1 score of $0.52$. We open-source the dataset, annotation methodology, and
annotators' instructions in full length at https://verifee.ai/research to
enable easy build-up work. We believe similar methods can help prevent
disinformation and educate in the realm of media literacy.",https://verifee.ai/research,351
778f3c43-91b7-45a2-a632-9f932c45e7e6,Enhanced Bi-directional Motion Estimation for Video Frame Interpolation,0.83706,"We present a novel simple yet effective algorithm for motion-based video
frame interpolation. Existing motion-based interpolation methods typically rely
on a pre-trained optical flow model or a U-Net based pyramid network for motion
estimation, which either suffer from large model size or limited capacity in
handling complex and large motion cases. In this work, by carefully integrating
intermediateoriented forward-warping, lightweight feature encoder, and
correlation volume into a pyramid recurrent framework, we derive a compact
model to simultaneously estimate the bidirectional motion between input frames.
It is 15 times smaller in size than PWC-Net, yet enables more reliable and
flexible handling of challenging motion cases. Based on estimated
bi-directional motion, we forward-warp input frames and their context features
to intermediate frame, and employ a synthesis network to estimate the
intermediate frame from warped representations. Our method achieves excellent
performance on a broad range of video frame interpolation benchmarks. Code and
trained models are available at \url{https://github.com/srcn-ivl/EBME}.",https://github.com/srcn-ivl/EBME,-1
62eead94-c98a-42b3-8921-18a26f7b8037,ImplantFormer: Vision Transformer based Implant Position Regression Using Dental CBCT Data,0.596685,"Implant prosthesis is the most appropriate treatment for dentition defect or
dentition loss, which usually involves a surgical guide design process to
decide the implant position. However, such design heavily relies on the
subjective experiences of dentists. In this paper, a transformer-based Implant
Position Regression Network, ImplantFormer, is proposed to automatically
predict the implant position based on the oral CBCT data. We creatively propose
to predict the implant position using the 2D axial view of the tooth crown area
and fit a centerline of the implant to obtain the actual implant position at
the tooth root. Convolutional stem and decoder are designed to coarsely extract
image features before the operation of patch embedding and integrate
multi-level feature maps for robust prediction, respectively. As both
long-range relationship and local features are involved, our approach can
better represent global information and achieves better location performance.
Extensive experiments on a dental implant dataset through five-fold
cross-validation demonstrated that the proposed ImplantFormer achieves superior
performance than existing methods.",None,-1
da8374c0-2b58-459c-9193-6f575a5b0776,Bridging Pre-trained Language Models and Hand-crafted Features for Unsupervised POS Tagging,0.437164,"In recent years, large-scale pre-trained language models (PLMs) have made
extraordinary progress in most NLP tasks. But, in the unsupervised POS tagging
task, works utilizing PLMs are few and fail to achieve state-of-the-art (SOTA)
performance. The recent SOTA performance is yielded by a Guassian HMM variant
proposed by He et al. (2018). However, as a generative model, HMM makes very
strong independence assumptions, making it very challenging to incorporate
contexualized word representations from PLMs. In this work, we for the first
time propose a neural conditional random field autoencoder (CRF-AE) model for
unsupervised POS tagging. The discriminative encoder of CRF-AE can
straightforwardly incorporate ELMo word representations. Moreover, inspired by
feature-rich HMM, we reintroduce hand-crafted features into the decoder of
CRF-AE. Finally, experiments clearly show that our model outperforms previous
state-of-the-art models by a large margin on Penn Treebank and multilingual
Universal Dependencies treebank v2.0.",https://github.com/Jacob-Zhou/FeatureCRFAE,-1
0885fd8a-854a-4f90-8869-3621562bcda3,Large Language Models are few(1)-shot Table Reasoners,0.794004,"Recent literature has shown that large language models (LLMs) are generally
excellent few-shot reasoners to solve text reasoning tasks. However, the
capability of LLMs on table reasoning tasks is yet to be explored. In this
paper, we aim at understanding how well LLMs can perform table-related tasks
with few-shot in-context learning. Specifically, we evaluated LLMs on popular
table QA and fact verification datasets like WikiTableQuestion, FetaQA,
TabFact, and FEVEROUS and found that LLMs are competent at complex reasoning
over table structures, though these models are not pre-trained on any table
corpus. When combined with `chain of thoughts' prompting, LLMs can achieve very
strong performance with only a 1-shot demonstration, even on par with some SoTA
models. We show that LLMs are even more competent at generating comprehensive
long-form answers on FetaQA than tuned T5-large. We further manually studied
the reasoning chains elicited from LLMs and found that these reasoning chains
are highly consistent with the underlying semantic form. We believe that LLMs
can serve as a simple yet generic baseline for future research. The code and
data are released in https://github.com/wenhuchen/TableCoT.",https://github.com/wenhuchen/TableCoT,-1
421ec993-fc1a-4686-be80-4fd63d967f77,Weakly Supervised 3D Multi-person Pose Estimation for Large-scale Scenes based on Monocular Camera and Single LiDAR,0.896511,"Depth estimation is usually ill-posed and ambiguous for monocular
camera-based 3D multi-person pose estimation. Since LiDAR can capture accurate
depth information in long-range scenes, it can benefit both the global
localization of individuals and the 3D pose estimation by providing rich
geometry features. Motivated by this, we propose a monocular camera and single
LiDAR-based method for 3D multi-person pose estimation in large-scale scenes,
which is easy to deploy and insensitive to light. Specifically, we design an
effective fusion strategy to take advantage of multi-modal input data,
including images and point cloud, and make full use of temporal information to
guide the network to learn natural and coherent human motions. Without relying
on any 3D pose annotations, our method exploits the inherent geometry
constraints of point cloud for self-supervision and utilizes 2D keypoints on
images for weak supervision. Extensive experiments on public datasets and our
newly collected dataset demonstrate the superiority and generalization
capability of our proposed method.",https://github.com/4DVLab/FusionPose.git,-1
2e6741c2-b9b4-4c47-8d62-3cbd627cf4b3,MotionBERT: A Unified Perspective on Learning Human Motion Representations,0.809985,"We present a unified perspective on tackling various human-centric video
tasks by learning human motion representations from large-scale and
heterogeneous data resources. Specifically, we propose a pretraining stage in
which a motion encoder is trained to recover the underlying 3D motion from
noisy partial 2D observations. The motion representations acquired in this way
incorporate geometric, kinematic, and physical knowledge about human motion,
which can be easily transferred to multiple downstream tasks. We implement the
motion encoder with a Dual-stream Spatio-temporal Transformer (DSTformer)
neural network. It could capture long-range spatio-temporal relationships among
the skeletal joints comprehensively and adaptively, exemplified by the lowest
3D pose estimation error so far when trained from scratch. Furthermore, our
proposed framework achieves state-of-the-art performance on all three
downstream tasks by simply finetuning the pretrained motion encoder with a
simple regression head (1-2 layers), which demonstrates the versatility of the
learned motion representations. Code and models are available at
https://motionbert.github.io/",https://motionbert.github.io/,-1
de83b9ca-3372-439c-874f-9299823ba4dc,Reinforcement Learning with Prior Policy Guidance for Motion Planning of Dual-Arm Free-Floating Space Robot,0.948033,"Reinforcement learning methods as a promising technique have achieved
superior results in the motion planning of free-floating space robots. However,
due to the increase in planning dimension and the intensification of system
dynamics coupling, the motion planning of dual-arm free-floating space robots
remains an open challenge. In particular, the current study cannot handle the
task of capturing a non-cooperative object due to the lack of the pose
constraint of the end-effectors. To address the problem, we propose a novel
algorithm, EfficientLPT, to facilitate RL-based methods to improve planning
accuracy efficiently. Our core contributions are constructing a mixed policy
with prior knowledge guidance and introducing infinite norm to build a more
reasonable reward function. Furthermore, our method successfully captures a
rotating object with different spinning speeds.",None,-1
34bba560-6413-4dd8-b4e8-5b755684977b,Grounding Aleatoric Uncertainty for Unsupervised Environment Design,0.492585,"Adaptive curricula in reinforcement learning (RL) have proven effective for
producing policies robust to discrepancies between the train and test
environment. Recently, the Unsupervised Environment Design (UED) framework
generalized RL curricula to generating sequences of entire environments,
leading to new methods with robust minimax regret properties. Problematically,
in partially-observable or stochastic settings, optimal policies may depend on
the ground-truth distribution over aleatoric parameters of the environment in
the intended deployment setting, while curriculum learning necessarily shifts
the training distribution. We formalize this phenomenon as curriculum-induced
covariate shift (CICS), and describe how its occurrence in aleatoric parameters
can lead to suboptimal policies. Directly sampling these parameters from the
ground-truth distribution avoids the issue, but thwarts curriculum learning. We
propose SAMPLR, a minimax regret UED method that optimizes the ground-truth
utility function, even when the underlying training data is biased due to CICS.
We prove, and validate on challenging domains, that our approach preserves
optimality under the ground-truth distribution, while promoting robustness
across the full range of environment settings.",https://github.com/facebookresearch/nle,18829
18cca175-259b-4b36-903e-567d205bcac3,Task-Induced Representation Learning,0.17262,"In this work, we evaluate the effectiveness of representation learning
approaches for decision making in visually complex environments. Representation
learning is essential for effective reinforcement learning (RL) from
high-dimensional inputs. Unsupervised representation learning approaches based
on reconstruction, prediction or contrastive learning have shown substantial
learning efficiency gains. Yet, they have mostly been evaluated in clean
laboratory or simulated settings. In contrast, real environments are visually
complex and contain substantial amounts of clutter and distractors.
Unsupervised representations will learn to model such distractors, potentially
impairing the agent's learning efficiency. In contrast, an alternative class of
approaches, which we call task-induced representation learning, leverages task
information such as rewards or demonstrations from prior tasks to focus on
task-relevant parts of the scene and ignore distractors. We investigate the
effectiveness of unsupervised and task-induced representation learning
approaches on four visually complex environments, from Distracting DMControl to
the CARLA driving simulator. For both, RL and imitation learning, we find that
representation learning generally improves sample efficiency on unseen tasks
even in visually complex scenes and that task-induced representations can
double learning efficiency compared to unsupervised alternatives. Code is
available at https://clvrai.com/tarp.",https://github.com/xxx,98
b3a9f9db-b88c-4ab1-91aa-1c03f14b28f3,LISA: Learning Implicit Shape and Appearance of Hands,0.727271,"This paper proposes a do-it-all neural model of human hands, named LISA. The
model can capture accurate hand shape and appearance, generalize to arbitrary
hand subjects, provide dense surface correspondences, be reconstructed from
images in the wild and easily animated. We train LISA by minimizing the shape
and appearance losses on a large set of multi-view RGB image sequences
annotated with coarse 3D poses of the hand skeleton. For a 3D point in the hand
local coordinate, our model predicts the color and the signed distance with
respect to each hand bone independently, and then combines the per-bone
predictions using predicted skinning weights. The shape, color and pose
representations are disentangled by design, allowing to estimate or animate
only selected parameters. We experimentally demonstrate that LISA can
accurately reconstruct a dynamic hand from monocular or multi-view sequences,
achieving a noticeably higher quality of reconstructed hand shapes compared to
baseline approaches. Project page:
https://www.iri.upc.edu/people/ecorona/lisa/.",https://www.iri.upc.edu/people/ecorona/lisa/,-1
72c4b64b-c295-495a-9f93-924f405cc0d5,MS-PS: A Multi-Scale Network for Photometric Stereo With a New Comprehensive Training Dataset,0.262171,"The photometric stereo (PS) problem consists in reconstructing the 3D-surface
of an object, thanks to a set of photographs taken under different lighting
directions. In this paper, we propose a multi-scale architecture for PS which,
combined with a new dataset, yields state-of-the-art results. Our proposed
architecture is flexible: it permits to consider a variable number of images as
well as variable image size without loss of performance. In addition, we define
a set of constraints to allow the generation of a relevant synthetic dataset to
train convolutional neural networks for the PS problem. Our proposed dataset is
much larger than pre-existing ones, and contains many objects with challenging
materials having anisotropic reflectance (e.g. metals, glass). We show on
publicly available benchmarks that the combination of both these contributions
drastically improves the accuracy of the estimated normal field, in comparison
with previous state-of-the-art methods.",None,-1
0afc3560-1a16-47e8-b96a-c552005af16d,Implicit Two-Tower Policies,0.307883,"We present a new class of structured reinforcement learning
policy-architectures, Implicit Two-Tower (ITT) policies, where the actions are
chosen based on the attention scores of their learnable latent representations
with those of the input states. By explicitly disentangling action from state
processing in the policy stack, we achieve two main goals: substantial
computational gains and better performance. Our architectures are compatible
with both: discrete and continuous action spaces. By conducting tests on 15
environments from OpenAI Gym and DeepMind Control Suite, we show that
ITT-architectures are particularly suited for blackbox/evolutionary
optimization and the corresponding policy training algorithms outperform their
vanilla unstructured implicit counterparts as well as commonly used explicit
policies. We complement our analysis by showing how techniques such as hashing
and lazy tower updates, critically relying on the two-tower structure of ITTs,
can be applied to obtain additional computational improvements.",https://anonymous.4open.science/r/itt-9881/README.md,17269
9f7b2106-b114-433b-9755-5ba22b693893,Intelligent Painter: Picture Composition With Resampling Diffusion Model,0.364044,"Have you ever thought that you can be an intelligent painter? This means that
you can paint a picture with a few expected objects in mind, or with a
desirable scene. This is different from normal inpainting approaches for which
the location of specific objects cannot be determined. In this paper, we
present an intelligent painter that generate a person's imaginary scene in one
go, given explicit hints. We propose a resampling strategy for Denoising
Diffusion Probabilistic Model (DDPM) to intelligently compose unconditional
harmonized pictures according to the input subjects at specific locations. By
exploiting the diffusion property, we resample efficiently to produce realistic
pictures. Experimental results show that our resampling method favors the
semantic meaning of the generated output efficiently and generates less blurry
output. Quantitative analysis of image quality assessment shows that our method
produces higher perceptual quality images compared with the state-of-the-art
methods.",https://github.com/vinesmsuic/ipainter-diffusion,-1
c55bcb9f-13b2-4ce2-a4d1-0bbae572c991,Robust Lottery Tickets for Pre-trained Language Models,0.823306,"Recent works on Lottery Ticket Hypothesis have shown that pre-trained
language models (PLMs) contain smaller matching subnetworks(winning tickets)
which are capable of reaching accuracy comparable to the original models.
However, these tickets are proved to be notrobust to adversarial examples, and
even worse than their PLM counterparts. To address this problem, we propose a
novel method based on learning binary weight masks to identify robust tickets
hidden in the original PLMs. Since the loss is not differentiable for the
binary mask, we assign the hard concrete distribution to the masks and
encourage their sparsity using a smoothing approximation of L0
regularization.Furthermore, we design an adversarial loss objective to guide
the search for robust tickets and ensure that the tickets perform well bothin
accuracy and robustness. Experimental results show the significant improvement
of the proposed method over previous work on adversarial robustness evaluation.",https://github.com/ruizheng20/robust_ticket,-1
ee779ab3-a9f8-4d2b-8892-2edb2195d8da,Training Debiased Subnetworks with Contrastive Weight Pruning,0.663245,"Neural networks are often biased to spuriously correlated features that
provide misleading statistical evidence that does not generalize. This raises
an interesting question: ``Does an optimal unbiased functional subnetwork exist
in a severely biased network? If so, how to extract such subnetwork?"" While
empirical evidence has been accumulated about the existence of such unbiased
subnetworks, these observations are mainly based on the guidance of
ground-truth unbiased samples. Thus, it is unexplored how to discover the
optimal subnetworks with biased training datasets in practice. To address this,
here we first present our theoretical insight that alerts potential limitations
of existing algorithms in exploring unbiased subnetworks in the presence of
strong spurious correlations. We then further elucidate the importance of
bias-conflicting samples on structure learning. Motivated by these
observations, we propose a Debiased Contrastive Weight Pruning (DCWP)
algorithm, which probes unbiased subnetworks without expensive group
annotations. Experimental results demonstrate that our approach significantly
outperforms state-of-the-art debiasing methods despite its considerable
reduction in the number of parameters.",None,-1
7135a12e-cf3b-4307-b866-482b2048740d,Typography-MNIST (TMNIST): an MNIST-Style Image Dataset to Categorize Glyphs and Font-Styles,0.112835,"We present Typography-MNIST (TMNIST), a dataset comprising of 565,292
MNIST-style grayscale images representing 1,812 unique glyphs in varied styles
of 1,355 Google-fonts. The glyph-list contains common characters from over 150
of the modern and historical language scripts with symbol sets, and each
font-style represents varying subsets of the total unique glyphs. The dataset
has been developed as part of the CognitiveType project which aims to develop
eye-tracking tools for real-time mapping of type to cognition and to create
computational tools that allow for the easy design of typefaces with cognitive
properties such as readability. The dataset and scripts to generate MNIST-style
images for glyphs in different font styles are freely available at
https://github.com/aiskunks/CognitiveType.",https://github.com/aiskunks/CognitiveType,-1
12525f26-4b36-49c2-a7d9-a5fca8deb9d3,Towards a Deep Multi-layered Dialectal Language Analysis: A Case Study of African-American English,0.0823328,"Currently, natural language processing (NLP) models proliferate language
discrimination leading to potentially harmful societal impacts as a result of
biased outcomes. For example, part-of-speech taggers trained on Mainstream
American English (MAE) produce non-interpretable results when applied to
African American English (AAE) as a result of language features not seen during
training. In this work, we incorporate a human-in-the-loop paradigm to gain a
better understanding of AAE speakers' behavior and their language use, and
highlight the need for dialectal language inclusivity so that native AAE
speakers can extensively interact with NLP systems while reducing feelings of
disenfranchisement.",https://github.com/ianozsvald/ark-tweet-nlp-python,-1
d9d20b64-0271-44db-a0ba-261c6cbb0ee0,MDFEND: Multi-domain Fake News Detection,0.998453,"Fake news spread widely on social media in various domains, which lead to
real-world threats in many aspects like politics, disasters, and finance. Most
existing approaches focus on single-domain fake news detection (SFND), which
leads to unsatisfying performance when these methods are applied to
multi-domain fake news detection. As an emerging field, multi-domain fake news
detection (MFND) is increasingly attracting attention. However, data
distributions, such as word frequency and propagation patterns, vary from
domain to domain, namely domain shift. Facing the challenge of serious domain
shift, existing fake news detection techniques perform poorly for multi-domain
scenarios. Therefore, it is demanding to design a specialized model for MFND.
In this paper, we first design a benchmark of fake news dataset for MFND with
domain label annotated, namely Weibo21, which consists of 4,488 fake news and
4,640 real news from 9 different domains. We further propose an effective
Multi-domain Fake News Detection Model (MDFEND) by utilizing a domain gate to
aggregate multiple representations extracted by a mixture of experts. The
experiments show that MDFEND can significantly improve the performance of
multi-domain fake news detection. Our dataset and code are available at
https://github.com/kennqiang/MDFEND-Weibo21.",None,-1
633f1ad6-86b8-4274-832d-a26b112b2781,Optimizing Fiducial Marker Placement for Improved Visual Localization,0.308416,"Adding fiducial markers to a scene is a well-known strategy for making visual
localization algorithms more robust. Traditionally, these marker locations are
selected by humans who are familiar with visual localization techniques. This
paper explores the problem of automatic marker placement within a scene.
Specifically, given a predetermined set of markers and a scene model, we
compute optimized marker positions within the scene that can improve accuracy
in visual localization. Our main contribution is a novel framework for modeling
camera localizability that incorporates both natural scene features and
artificial fiducial markers added to the scene. We present optimized marker
placement (OMP), a greedy algorithm that is based on the camera localizability
framework. We have also designed a simulation framework for testing marker
placement algorithms on 3D models and images generated from synthetic scenes.
We have evaluated OMP within this testbed and demonstrate an improvement in the
localization rate by up to 20 percent on four different scenes.",https://github.com/doublestrong/OMP,-1
7b973cde-7b92-42e5-9702-279012140b33,Momentum Decoding: Open-ended Text Generation As Graph Exploration,0.0582321,"Open-ended text generation with autoregressive language models (LMs) is one
of the core tasks in natural language processing. However, maximization-based
decoding methods (e.g., greedy/beam search) often lead to the degeneration
problem, i.e., the generated text is unnatural and contains undesirable
repetitions. Existing solutions to this problem either introduce randomness
prone to incoherence or require a look-ahead mechanism that demands extra
computational overhead. In this study, we formulate open-ended text generation
from a new perspective, i.e., we view it as an exploration process within a
directed graph. Thereby, we understand the phenomenon of degeneration as
circular loops within the directed graph. Based on our formulation, we propose
a novel decoding method -- \textit{momentum decoding} -- which encourages the
LM to \textit{greedily} explore new nodes outside the current graph. Meanwhile,
it also allows the LM to return to the existing nodes with a momentum
downgraded by a pre-defined resistance function. We extensively test our
approach on three benchmarks from different domains through automatic and human
evaluations. The results show that momentum decoding performs comparably with
the current state of the art while enjoying notably improved inference speed
and computation FLOPs. Furthermore, we conduct a detailed analysis to reveal
the merits and inner workings of our approach. Our codes and other related
resources are publicly available at
https://github.com/gmftbyGMFTBY/MomentumDecoding.",https://github.com/gmftbyGMFTBY/,-1
99a8f148-9970-4492-bf11-5a6a553de5ea,Visual Knowledge Discovery with Artificial Intelligence: Challenges and Future Directions,0.333024,"This volume is devoted to the emerging field of Integrated Visual Knowledge
Discovery that combines advances in Artificial Intelligence/Machine Learning
(AI/ML) and Visualization/Visual Analytics. Chapters included are extended
versions of the selected AI and Visual Analytics papers and related symposia at
the recent International Information Visualization Conferences (IV2019 and
IV2020). AI/ML face a long-standing challenge of explaining models to humans.
Models explanation is fundamentally human activity, not only an algorithmic
one. In this chapter we aim to present challenges and future directions within
the field of Visual Analytics, Visual Knowledge Discovery and AI/ML, and to
discuss the role of visualization in visual AI/ML. In addition, we describe
progress in emerging Full 2D ML, natural language processing, and AI/ML in
multidimensional data aided by visual means.",None,-1
182b66c6-e1ac-4ea4-ad2f-a2a5fcf74658,JAMES: Normalizing Job Titles with Multi-Aspect Graph Embeddings and Reasoning,0.272866,"In online job marketplaces, it is important to establish a well-defined job
title taxonomy for various downstream tasks (e.g., job recommendation, users'
career analysis, and turnover prediction). Job Title Normalization (JTN) is
such a cleaning step to classify user-created non-standard job titles into
normalized ones. However, solving the JTN problem is non-trivial with
challenges: (1) semantic similarity of different job titles, (2) non-normalized
user-created job titles, and (3) large-scale and long-tailed job titles in
real-world applications. To this end, we propose a novel solution, named JAMES,
that constructs three unique embeddings (i.e., graph, contextual, and
syntactic) of a target job title to effectively capture its various traits. We
further propose a multi-aspect co-attention mechanism to attentively combine
these embeddings, and employ neural logical reasoning representations to
collaboratively estimate similarities between messy job titles and normalized
job titles in a reasoning space. To evaluate JAMES, we conduct comprehensive
experiments against ten competing models on a large-scale real-world dataset
with over 350,000 job titles. Our experimental results show that JAMES
significantly outperforms the best baseline by 10.06% in Precision@10 and by
17.52% in NDCG@10, respectively.",None,13066
aaaa9d7e-655d-4326-9ed1-ac678155bddc,MSP-Former: Multi-Scale Projection Transformer for Single Image Desnowing,0.52258,"Snow removal causes challenges due to its characteristic of complex
degradations. To this end, targeted treatment of multi-scale snow degradations
is critical for the network to learn effective snow removal. In order to handle
the diverse scenes, we propose a multi-scale projection transformer
(MSP-Former), which understands and covers a variety of snow degradation
features in a multi-path manner, and integrates comprehensive scene context
information for clean reconstruction via self-attention operation. For the
local details of various snow degradations, the local capture module is
introduced in parallel to assist in the rebuilding of a clean image. Such
design achieves the SOTA performance on three desnowing benchmark datasets
while costing the low parameters and computational complexity, providing a
guarantee of practicality.",None,-1
f2b348df-d8b7-421e-a368-ba4622cdc01b,Overlap-guided Gaussian Mixture Models for Point Cloud Registration,0.436437,"Probabilistic 3D point cloud registration methods have shown competitive
performance in overcoming noise, outliers, and density variations. However,
registering point cloud pairs in the case of partial overlap is still a
challenge. This paper proposes a novel overlap-guided probabilistic
registration approach that computes the optimal transformation from matched
Gaussian Mixture Model (GMM) parameters. We reformulate the registration
problem as the problem of aligning two Gaussian mixtures such that a
statistical discrepancy measure between the two corresponding mixtures is
minimized. We introduce a Transformer-based detection module to detect
overlapping regions, and represent the input point clouds using GMMs by guiding
their alignment through overlap scores computed by this detection module.
Experiments show that our method achieves superior registration accuracy and
efficiency than state-of-the-art methods when handling point clouds with
partial overlap and different densities on synthetic and real-world datasets.
https://github.com/gfmei/ogmm",https://github.com/gfmei/ogmm,-1
ed84bdb8-115c-42fc-8575-e86a37187ac1,Probing Pre-Trained Language Models for Cross-Cultural Differences in Values,0.997702,"Language embeds information about social, cultural, and political values
people hold. Prior work has explored social and potentially harmful biases
encoded in Pre-Trained Language models (PTLMs). However, there has been no
systematic study investigating how values embedded in these models vary across
cultures. In this paper, we introduce probes to study which values across
cultures are embedded in these models, and whether they align with existing
theories and cross-cultural value surveys. We find that PTLMs capture
differences in values across cultures, but those only weakly align with
established value surveys. We discuss implications of using mis-aligned models
in cross-cultural settings, as well as ways of aligning PTLMs with value
surveys.",None,-1
fe15aa11-21c6-43b6-8c12-e1b5c9169295,VIDM: Video Implicit Diffusion Models,0.927319,"Diffusion models have emerged as a powerful generative method for
synthesizing high-quality and diverse set of images. In this paper, we propose
a video generation method based on diffusion models, where the effects of
motion are modeled in an implicit condition manner, i.e. one can sample
plausible video motions according to the latent feature of frames. We improve
the quality of the generated videos by proposing multiple strategies such as
sampling space truncation, robustness penalty, and positional group
normalization. Various experiments are conducted on datasets consisting of
videos with different resolutions and different number of frames. Results show
that the proposed method outperforms the state-of-the-art generative
adversarial network-based methods by a significant margin in terms of FVD
scores as well as perceptible visual quality.",None,-1
90452690-cec6-4261-9ee9-cd3354238d3d,A Multi-Task Benchmark for Korean Legal Language Understanding and Judgement Prediction,0.985451,"The recent advances of deep learning have dramatically changed how machine
learning, especially in the domain of natural language processing, can be
applied to legal domain. However, this shift to the data-driven approaches
calls for larger and more diverse datasets, which are nevertheless still small
in number, especially in non-English languages. Here we present the first
large-scale benchmark of Korean legal AI datasets, LBOX OPEN, that consists of
one legal corpus, two classification tasks, two legal judgement prediction
(LJP) tasks, and one summarization task. The legal corpus consists of 147k
Korean precedents (259M tokens), of which 63k are sentenced in last 4 years and
96k are from the first and the second level courts in which factual issues are
reviewed. The two classification tasks are case names (11.3k) and statutes
(2.8k) prediction from the factual description of individual cases. The LJP
tasks consist of (1) 10.5k criminal examples where the model is asked to
predict fine amount, imprisonment with labor, and imprisonment without labor
ranges for the given facts, and (2) 4.7k civil examples where the inputs are
facts and claim for relief and outputs are the degrees of claim acceptance. The
summarization task consists of the Supreme Court precedents and the
corresponding summaries (20k). We also release realistic variants of the
datasets by extending the domain (1) to infrequent case categories in case name
(31k examples) and statute (17.7k) classification tasks, and (2) to long input
sequences in the summarization task (51k). Finally, we release LCUBE, the first
Korean legal language model trained on the legal corpus from this study. Given
the uniqueness of the Law of South Korea and the diversity of the legal tasks
covered in this work, we believe that LBOX OPEN contributes to the
multilinguality of global legal research. LBOX OPEN and LCUBE will be publicly
available.",https://github.com/lbox-kr/lbox-open,-1
7187240a-904b-442b-a6a8-10ba8a6b4328,GazeNeRF: 3D-Aware Gaze Redirection with Neural Radiance Fields,0.832094,"We propose GazeNeRF, a 3D-aware method for the task of gaze redirection.
Existing gaze redirection methods operate on 2D images and struggle to generate
3D consistent results. Instead, we build on the intuition that the face region
and eyeballs are separate 3D structures that move in a coordinated yet
independent fashion. Our method leverages recent advancements in conditional
image-based neural radiance fields and proposes a two-stream architecture that
predicts volumetric features for the face and eye regions separately. Rigidly
transforming the eye features via a 3D rotation matrix provides fine-grained
control over the desired gaze angle. The final, redirected image is then
attained via differentiable volume compositing. Our experiments show that this
architecture outperforms naively conditioned NeRF baselines as well as previous
state-of-the-art 2D gaze redirection methods in terms of redirection accuracy
and identity preservation.",https://github.com/zllrunning/face-parsing.PyTorch,-1
9a729348-906e-429b-adf3-59a8f1ce6549,Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task,0.983318,"Language models show a surprising range of capabilities, but the source of
their apparent competence is unclear. Do these networks just memorize a
collection of surface statistics, or do they rely on internal representations
of the process that generates the sequences they see? We investigate this
question by applying a variant of the GPT model to the task of predicting legal
moves in a simple board game, Othello. Although the network has no a priori
knowledge of the game or its rules, we uncover evidence of an emergent
nonlinear internal representation of the board state. Interventional
experiments indicate this representation can be used to control the output of
the network and create ""latent saliency maps"" that can help explain predictions
in human terms.",None,-1
5aa2747d-27af-4a51-b099-ff52cfb2edfc,Refining neural network predictions using background knowledge,0.284347,"Recent work has shown logical background knowledge can be used in learning
systems to compensate for a lack of labeled training data. Many methods work by
creating a loss function that encodes this knowledge. However, often the logic
is discarded after training, even if it is still useful at test time. Instead,
we ensure neural network predictions satisfy the knowledge by refining the
predictions with an extra computation step. We introduce differentiable
refinement functions that find a corrected prediction close to the original
prediction. We study how to effectively and efficiently compute these
refinement functions. Using a new algorithm called Iterative Local Refinement
(ILR), we combine refinement functions to find refined predictions for logical
formulas of any complexity. ILR finds refinements on complex SAT formulas in
significantly fewer iterations and frequently finds solutions where gradient
descent can not. Finally, ILR produces competitive results in the MNIST
addition task.",https://github.com/DanieleAlessandro/IterativeLocalRefinement,-1
e3aca4a2-2a0e-494a-832d-d89de9f71419,Understanding Influence Functions and Datamodels via Harmonic Analysis,0.799181,"Influence functions estimate effect of individual data points on predictions
of the model on test data and were adapted to deep learning in Koh and Liang
[2017]. They have been used for detecting data poisoning, detecting helpful and
harmful examples, influence of groups of datapoints, etc. Recently, Ilyas et
al. [2022] introduced a linear regression method they termed datamodels to
predict the effect of training points on outputs on test data. The current
paper seeks to provide a better theoretical understanding of such interesting
empirical phenomena. The primary tool is harmonic analysis and the idea of
noise stability. Contributions include: (a) Exact characterization of the
learnt datamodel in terms of Fourier coefficients. (b) An efficient method to
estimate the residual error and quality of the optimum linear datamodel without
having to train the datamodel. (c) New insights into when influences of groups
of datapoints may or may not add up linearly.",https://github.com/libffcv/ffcv/,-1
a67cdc68-ef5c-4f3c-8d17-ed2bc2447d2f,Instance-Specific Feature Propagation for Referring Segmentation,0.486951,"Referring segmentation aims to generate a segmentation mask for the target
instance indicated by a natural language expression. There are typically two
kinds of existing methods: one-stage methods that directly perform segmentation
on the fused vision and language features; and two-stage methods that first
utilize an instance segmentation model for instance proposal and then select
one of these instances via matching them with language features. In this work,
we propose a novel framework that simultaneously detects the target-of-interest
via feature propagation and generates a fine-grained segmentation mask. In our
framework, each instance is represented by an Instance-Specific Feature (ISF),
and the target-of-referring is identified by exchanging information among all
ISFs using our proposed Feature Propagation Module (FPM). Our instance-aware
approach learns the relationship among all objects, which helps to better
locate the target-of-interest than one-stage methods. Comparing to two-stage
methods, our approach collaboratively and interactively utilizes both vision
and language information for synchronous identification and segmentation. In
the experimental tests, our method outperforms previous state-of-the-art
methods on all three RefCOCO series datasets.",None,-1
ef5d304a-42a7-435e-83fb-5555327f12b7,Structured Local Radiance Fields for Human Avatar Modeling,0.693802,"It is extremely challenging to create an animatable clothed human avatar from
RGB videos, especially for loose clothes due to the difficulties in motion
modeling. To address this problem, we introduce a novel representation on the
basis of recent neural scene rendering techniques. The core of our
representation is a set of structured local radiance fields, which are anchored
to the pre-defined nodes sampled on a statistical human body template. These
local radiance fields not only leverage the flexibility of implicit
representation in shape and appearance modeling, but also factorize cloth
deformations into skeleton motions, node residual translations and the dynamic
detail variations inside each individual radiance field. To learn our
representation from RGB data and facilitate pose generalization, we propose to
learn the node translations and the detail variations in a conditional
generative latent space. Overall, our method enables automatic construction of
animatable human avatars for various types of clothes without the need for
scanning subject-specific templates, and can generate realistic images with
dynamic details for novel poses. Experiment show that our method outperforms
state-of-the-art methods both qualitatively and quantitatively.",https://github.com/zju3dv/EasyMocap,-1
6030d998-995f-4872-a637-1212d6b6cb18,First Competitive Ant Colony Scheme for the CARP,0.458344,"This paper addresses the Capacitated Arc Routing Problem (CARP) using an Ant
Colony Optimization scheme. Ant Colony schemes can compute solutions for medium
scale instances of VRP. The proposed Ant Colony is dedicated to large-scale
instances of CARP with more than 140 nodes and 190 arcs to service. The Ant
Colony scheme is coupled with a local search procedure and provides high
quality solutions. The benchmarks we carried out prove possible to obtain
solutions as profitable as CARPET ones can be obtained using such scheme when a
sufficient number of iterations is devoted to the ants. It competes with the
Genetic Algorithm of Lacomme et al. regarding solution quality but it is more
time consuming on large scale instances. The method has been intensively
benchmarked on the well-known instances of Eglese, DeArmon and the last ones of
Belenguer and Benavent. This research report is a step forward CARP resolution
by Ant Colony proving ant schemes can compete with Taboo search methods and
Genetic Algorithms",None,-1
2abf45d1-2f1b-4b57-97ec-1aeae74ce57d,GaIA: Graphical Information Gain based Attention Network for Weakly Supervised Point Cloud Semantic Segmentation,0.735116,"While point cloud semantic segmentation is a significant task in 3D scene
understanding, this task demands a time-consuming process of fully annotating
labels. To address this problem, recent studies adopt a weakly supervised
learning approach under the sparse annotation. Different from the existing
studies, this study aims to reduce the epistemic uncertainty measured by the
entropy for a precise semantic segmentation. We propose the graphical
information gain based attention network called GaIA, which alleviates the
entropy of each point based on the reliable information. The graphical
information gain discriminates the reliable point by employing relative entropy
between target point and its neighborhoods. We further introduce anchor-based
additive angular margin loss, ArcPoint. The ArcPoint optimizes the unlabeled
points containing high entropy towards semantically similar classes of the
labeled points on hypersphere space. Experimental results on S3DIS and
ScanNet-v2 datasets demonstrate our framework outperforms the existing weakly
supervised methods. We have released GaIA at https://github.com/Karel911/GaIA.",https://github.com/Karel911/GaIA,-1
79448034-1d13-4aa9-99ee-449e035d0344,Best-$k$ Search Algorithm for Neural Text Generation,0.0761536,"Modern natural language generation paradigms require a good decoding strategy
to obtain quality sequences out of the model. Beam search yields high-quality
but low diversity outputs; stochastic approaches suffer from high variance and
sometimes low quality, but the outputs tend to be more natural and creative. In
this work, we propose a deterministic search algorithm balancing both quality
and diversity. We first investigate the vanilla best-first search (BFS)
algorithm and then propose the Best-$k$ Search algorithm. Inspired by BFS, we
greedily expand the top $k$ nodes, instead of only the first node, to boost
efficiency and diversity. Upweighting recently discovered nodes accompanied by
heap pruning ensures the completeness of the search procedure. Experiments on
four NLG tasks, including question generation, commonsense generation, text
summarization, and translation, show that best-$k$ search yields more diverse
and natural outputs compared to strong baselines, while our approach maintains
high text quality. The proposed algorithm is parameter-free, lightweight,
efficient, and easy to use.",None,-1
be3074d8-125e-4e56-9b8f-30457885c5d1,BIOWISH: Biometric Recognition using Wearable Inertial Sensors detecting Heart Activity,0.415197,"Wearable devices are increasingly used, thanks to the wide set of
applications that can be deployed exploiting their ability to monitor physical
activity and health-related parameters. Their usage has been recently proposed
to perform biometric recognition, leveraging on the uniqueness of the recorded
traits to generate discriminative identifiers. Most of the studies conducted on
this topic have considered signals derived from cardiac activity, detecting it
mainly using electrical measurements thorugh electrocardiography, or optical
recordings employing photoplethysmography. In this paper we instead propose a
BIOmetric recognition approach using Wearable Inertial Sensors detecting Heart
activity (BIOWISH). In more detail, we investigate the feasibility of
exploiting mechanical measurements obtained through seismocardiography and
gyrocardiography to recognize a person. Several feature extractors and
classifiers, including deep learning techniques relying on transfer learning
and siamese training, are employed to derive distinctive characteristics from
the considered signals, and differentiate between legitimate and impostor
subjects. An multi-session database, comprising acquisitions taken from
subjects performing different activities, is employed to perform experimental
tests simulating a verification system. The obtained results testify that
identifiers derived from measurements of chest vibrations, collected by
wearable inertial sensors, could be employed to guarantee high recognition
performance, even when considering short-time recordings.",None,-1
24d3d2b9-42bf-47bc-99aa-660ed981f2f2,Using Context-to-Vector with Graph Retrofitting to Improve Word Embeddings,0.80125,"Although contextualized embeddings generated from large-scale pre-trained
models perform well in many tasks, traditional static embeddings (e.g.,
Skip-gram, Word2Vec) still play an important role in low-resource and
lightweight settings due to their low computational cost, ease of deployment,
and stability. In this paper, we aim to improve word embeddings by 1)
incorporating more contextual information from existing pre-trained models into
the Skip-gram framework, which we call Context-to-Vec; 2) proposing a
post-processing retrofitting method for static embeddings independent of
training by employing priori synonym knowledge and weighted vector
distribution. Through extrinsic and intrinsic tasks, our methods are well
proven to outperform the baselines by a large margin.",https://github.com/binbinjiang/Context2Vector,70015
07043207-6a7e-4449-b4da-5f80c59d69c6,Controlling Bias Exposure for Fair Interpretable Predictions,0.799448,"Recent work on reducing bias in NLP models usually focuses on protecting or
isolating information related to a sensitive attribute (like gender or race).
However, when sensitive information is semantically entangled with the task
information of the input, e.g., gender information is predictive for a
profession, a fair trade-off between task performance and bias mitigation is
difficult to achieve. Existing approaches perform this trade-off by eliminating
bias information from the latent space, lacking control over how much bias is
necessarily required to be removed. We argue that a favorable debiasing method
should use sensitive information 'fairly', rather than blindly eliminating it
(Caliskan et al., 2017; Sun et al., 2019; Bogen et al., 2020). In this work, we
provide a novel debiasing algorithm by adjusting the predictive model's belief
to (1) ignore the sensitive information if it is not useful for the task; (2)
use sensitive information minimally as necessary for the prediction (while also
incurring a penalty). Experimental results on two text classification tasks
(influenced by gender) and an open-ended generation task (influenced by race)
indicate that our model achieves a desirable trade-off between debiasing and
task performance along with producing debiased rationales as evidence.",https://github.com/ZexueHe/interpretable_debiasing,30843
30ae4fe8-ba8d-419d-ae2a-0e843e6802a7,The Conceptual VAE,0.170641,"In this report we present a new model of concepts, based on the framework of
variational autoencoders, which is designed to have attractive properties such
as factored conceptual domains, and at the same time be learnable from data.
The model is inspired by, and closely related to, the Beta-VAE model of
concepts, but is designed to be more closely connected with language, so that
the names of concepts form part of the graphical model. We provide evidence
that our model -- which we call the Conceptual VAE -- is able to learn
interpretable conceptual representations from simple images of coloured shapes
together with the corresponding concept labels. We also show how the model can
be used as a concept classifier, and how it can be adapted to learn from fewer
labels per instance. Finally, we formally relate our model to Gardenfors'
theory of conceptual spaces, showing how the Gaussians we use to represent
concepts can be formalised in terms of ""fuzzy concepts"" in such a space.",None,-1
c9773292-a30d-4b1b-936c-01202c64338c,A Library Perspective on Nearly-Unsupervised Information Extraction Workflows in Digital Libraries,0.140516,"Information extraction can support novel and effective access paths for
digital libraries. Nevertheless, designing reliable extraction workflows can be
cost-intensive in practice. On the one hand, suitable extraction methods rely
on domain-specific training data. On the other hand, unsupervised and open
extraction methods usually produce not-canonicalized extraction results. This
paper tackles the question how digital libraries can handle such extractions
and if their quality is sufficient in practice. We focus on unsupervised
extraction workflows by analyzing them in case studies in the domains of
encyclopedias (Wikipedia), pharmacy and political sciences. We report on
opportunities and limitations. Finally we discuss best practices for
unsupervised extraction workflows.",None,-1
67c4de12-a718-41d8-a4e4-48423cad0369,Storehouse: a Reinforcement Learning Environment for Optimizing Warehouse Management,0.374434,"Warehouse Management Systems have been evolving and improving thanks to new
Data Intelligence techniques. However, many current optimizations have been
applied to specific cases or are in great need of manual interaction. Here is
where Reinforcement Learning techniques come into play, providing
automatization and adaptability to current optimization policies. In this
paper, we present Storehouse, a customizable environment that generalizes the
definition of warehouse simulations for Reinforcement Learning. We also
validate this environment against state-of-the-art reinforcement learning
algorithms and compare these results to human and random policies.",https://github.com/JulenCestero/storehouse,-1
52b410a2-a8cf-4401-9ec1-48dae1412722,READ: Large-Scale Neural Scene Rendering for Autonomous Driving,0.626653,"Synthesizing free-view photo-realistic images is an important task in
multimedia. With the development of advanced driver assistance systems~(ADAS)
and their applications in autonomous vehicles, experimenting with different
scenarios becomes a challenge. Although the photo-realistic street scenes can
be synthesized by image-to-image translation methods, which cannot produce
coherent scenes due to the lack of 3D information. In this paper, a large-scale
neural rendering method is proposed to synthesize the autonomous driving
scene~(READ), which makes it possible to synthesize large-scale driving
scenarios on a PC through a variety of sampling schemes. In order to represent
driving scenarios, we propose an {\omega} rendering network to learn neural
descriptors from sparse point clouds. Our model can not only synthesize
realistic driving scenes but also stitch and edit driving scenes. Experiments
show that our model performs well in large-scale driving scenarios.",https://github.com/JOP-Lee/READ-Large-Scale-Neural-,-1
84671fe5-e948-49fc-b58e-9c9925872971,3D Pose Based Feedback for Physical Exercises,0.901406,"Unsupervised self-rehabilitation exercises and physical training can cause
serious injuries if performed incorrectly. We introduce a learning-based
framework that identifies the mistakes made by a user and proposes corrective
measures for easier and safer individual training. Our framework does not rely
on hard-coded, heuristic rules. Instead, it learns them from data, which
facilitates its adaptation to specific user needs. To this end, we use a Graph
Convolutional Network (GCN) architecture acting on the user's pose sequence to
model the relationship between the body joints trajectories. To evaluate our
approach, we introduce a dataset with 3 different physical exercises. Our
approach yields 90.9% mistake identification accuracy and successfully corrects
94.2% of the mistakes.",None,-1
63c94076-9488-45e7-88dc-b1d22ec31ef0,Spatio-Temporal Dynamic Graph Relation Learning for Urban Metro Flow Prediction,0.847838,"Urban metro flow prediction is of great value for metro operation scheduling,
passenger flow management and personal travel planning. However, it faces two
main challenges. First, different metro stations, e.g. transfer stations and
non-transfer stations, have unique traffic patterns. Second, it is challenging
to model complex spatio-temporal dynamic relation of metro stations. To address
these challenges, we develop a spatio-temporal dynamic graph relational
learning model (STDGRL) to predict urban metro station flow. First, we propose
a spatio-temporal node embedding representation module to capture the traffic
patterns of different stations. Second, we employ a dynamic graph relationship
learning module to learn dynamic spatial relationships between metro stations
without a predefined graph adjacency matrix. Finally, we provide a
transformer-based long-term relationship prediction module for long-term metro
flow prediction. Extensive experiments are conducted based on metro data in
Beijing, Shanghai, Chongqing and Hangzhou. Experimental results show the
advantages of our method beyond 11 baselines for urban metro flow prediction.",None,-1
9d29d27e-054e-4ef5-95d0-81a7f689a12a,Improving the Faithfulness of Abstractive Summarization via Entity Coverage Control,0.739434,"Abstractive summarization systems leveraging pre-training language models
have achieved superior results on benchmark datasets. However, such models have
been shown to be more prone to hallucinate facts that are unfaithful to the
input context. In this paper, we propose a method to remedy entity-level
extrinsic hallucinations with Entity Coverage Control (ECC). We first compute
entity coverage precision and prepend the corresponding control code for each
training example, which implicitly guides the model to recognize faithfulness
contents in the training phase. We further extend our method via intermediate
fine-tuning on large but noisy data extracted from Wikipedia to unlock
zero-shot summarization. We show that the proposed method leads to more
faithful and salient abstractive summarization in supervised fine-tuning and
zero-shot settings according to our experimental results on three benchmark
datasets XSum, Pubmed, and SAMSum of very different domains and styles.",None,-1
c6a880b1-1032-4c49-86f4-96408e6ad99c,High-Resource Methodological Bias in Low-Resource Investigations,0.160063,"The central bottleneck for low-resource NLP is typically regarded to be the
quantity of accessible data, overlooking the contribution of data quality. This
is particularly seen in the development and evaluation of low-resource systems
via down sampling of high-resource language data. In this work we investigate
the validity of this approach, and we specifically focus on two well-known NLP
tasks for our empirical investigations: POS-tagging and machine translation. We
show that down sampling from a high-resource language results in datasets with
different properties than the low-resource datasets, impacting the model
performance for both POS-tagging and machine translation. Based on these
results we conclude that naive down sampling of datasets results in a biased
view of how well these systems work in a low-resource scenario.",https://github.com/flairNLP/flair/,-1
3c1aa7a0-1886-49f7-914f-cdbdbf3dbb86,Getting Quechua Closer to Final Users through Knowledge Graphs,0.0805089,"Quechua language and Quechua knowledge gather millions of people around the
world, especially in several countries in South America. Unfortunately, there
are only a few resources available to Quechua communities, and they are mainly
stored in PDF format. In this paper, the Quechua Knowledge Graph is envisioned
and generated as an effort to get Quechua closer to the Quechua communities,
researchers, and technology developers. Currently, there are 553636 triples
stored in the Quechua Knowledge Graph, which is accessible on the Web,
retrievable by machines, and curated by users. To showcase the deployment of
the Quechua Knowledge Graph, use cases and future work are described.",None,-1
ac6be3b9-f92e-4b66-b50d-74abba392ca6,ConvFinQA: Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering,0.75274,"With the recent advance in large pre-trained language models, researchers
have achieved record performances in NLP tasks that mostly focus on language
pattern matching. The community is experiencing the shift of the challenge from
how to model language to the imitation of complex reasoning abilities like
human beings. In this work, we investigate the application domain of finance
that involves real-world, complex numerical reasoning. We propose a new
large-scale dataset, ConvFinQA, aiming to study the chain of numerical
reasoning in conversational question answering. Our dataset poses great
challenge in modeling long-range, complex numerical reasoning paths in
real-world conversations. We conduct comprehensive experiments and analyses
with both the neural symbolic methods and the prompting-based methods, to
provide insights into the reasoning mechanisms of these two divisions. We
believe our new dataset should serve as a valuable resource to push forward the
exploration of real-world, complex reasoning tasks as the next research focus.
Our dataset and code is publicly available at
https://github.com/czyssrs/ConvFinQA.",https://github.com/czyssrs/ConvFinQA,-1
759f3a87-2151-49db-bed0-8193a28636f0,TSAM: A Two-Stream Attention Model for Causal Emotion Entailment,0.582973,"Causal Emotion Entailment (CEE) aims to discover the potential causes behind
an emotion in a conversational utterance. Previous works formalize CEE as
independent utterance pair classification problems, with emotion and speaker
information neglected. From a new perspective, this paper considers CEE in a
joint framework. We classify multiple utterances synchronously to capture the
correlations between utterances in a global view and propose a Two-Stream
Attention Model (TSAM) to effectively model the speaker's emotional influences
in the conversational history. Specifically, the TSAM comprises three modules:
Emotion Attention Network (EAN), Speaker Attention Network (SAN), and
interaction module. The EAN and SAN incorporate emotion and speaker information
in parallel, and the subsequent interaction module effectively interchanges
relevant information between the EAN and SAN via a mutual BiAffine
transformation. Extensive experimental results demonstrate that our model
achieves new State-Of-The-Art (SOTA) performance and outperforms baselines
remarkably.",https://github.com/huggingface/transformers,-1
76107a35-a90b-4bf1-8f46-91d10c2f1e33,Analysing the effectiveness of a generative model for semi-supervised medical image segmentation,0.162557,"Image segmentation is important in medical imaging, providing valuable,
quantitative information for clinical decision-making in diagnosis, therapy,
and intervention. The state-of-the-art in automated segmentation remains
supervised learning, employing discriminative models such as U-Net. However,
training these models requires access to large amounts of manually labelled
data which is often difficult to obtain in real medical applications. In such
settings, semi-supervised learning (SSL) attempts to leverage the abundance of
unlabelled data to obtain more robust and reliable models. Recently, generative
models have been proposed for semantic segmentation, as they make an attractive
choice for SSL. Their ability to capture the joint distribution over input
images and output label maps provides a natural way to incorporate information
from unlabelled images. This paper analyses whether deep generative models such
as the SemanticGAN are truly viable alternatives to tackle challenging medical
image segmentation problems. To that end, we thoroughly evaluate the
segmentation performance, robustness, and potential subgroup disparities of
discriminative and generative segmentation methods when applied to large-scale,
publicly available chest X-ray datasets.",None,-1
330e73da-5eff-4347-b8f4-0ad61913bb9b,"""splink"" is happy and ""phrouth"" is scary: Emotion Intensity Analysis for Nonsense Words",0.307358,"People associate affective meanings to words - ""death"" is scary and sad while
""party"" is connotated with surprise and joy. This raises the question if the
association is purely a product of the learned affective imports inherent to
semantic meanings, or is also an effect of other features of words, e.g.,
morphological and phonological patterns. We approach this question with an
annotation-based analysis leveraging nonsense words. Specifically, we conduct a
best-worst scaling crowdsourcing study in which participants assign intensity
scores for joy, sadness, anger, disgust, fear, and surprise to 272 non-sense
words and, for comparison of the results to previous work, to 68 real words.
Based on this resource, we develop character-level and phonology-based
intensity regressors. We evaluate them on both nonsense words and real words
(making use of the NRC emotion intensity lexicon of 7493 words), across six
emotion categories. The analysis of our data reveals that some phonetic
patterns show clear differences between emotion intensities. For instance, s as
a first phoneme contributes to joy, sh to surprise, p as last phoneme more to
disgust than to anger and fear. In the modelling experiments, a regressor
trained on real words from the NRC emotion intensity lexicon shows a higher
performance (r = 0.17) than regressors that aim at learning the emotion
connotation purely from nonsense words. We conclude that humans do associate
affective meaning to words based on surface patterns, but also based on
similarities to existing words (""juy"" to ""joy"", or ""flike"" to ""like"").",https://github.com/syhw/speech_embeddings,-1
3204f043-1038-4fe4-918c-e30ab2d68760,MOSRA: Joint Mean Opinion Score and Room Acoustics Speech Quality Assessment,0.337584,"The acoustic environment can degrade speech quality during communication
(e.g., video call, remote presentation, outside voice recording), and its
impact is often unknown. Objective metrics for speech quality have proven
challenging to develop given the multi-dimensionality of factors that affect
speech quality and the difficulty of collecting labeled data. Hypothesizing the
impact of acoustics on speech quality, this paper presents MOSRA: a
non-intrusive multi-dimensional speech quality metric that can predict room
acoustics parameters (SNR, STI, T60, DRR, and C50) alongside the overall mean
opinion score (MOS) for speech quality. By explicitly optimizing the model to
learn these room acoustics parameters, we can extract more informative features
and improve the generalization for the MOS task when the training data is
limited. Furthermore, we also show that this joint training method enhances the
blind estimation of room acoustics, improving the performance of current
state-of-the-art models. An additional side-effect of this joint prediction is
the improvement in the explainability of the predictions, which is a valuable
feature for many applications.",None,-1
aaee2448-a2b3-4ee6-8f75-7849faabbf6f,"An exploratory experiment on Hindi, Bengali hate-speech detection and transfer learning using neural networks",0.160976,"This work presents our approach to train a neural network to detect
hate-speech texts in Hindi and Bengali. We also explore how transfer learning
can be applied to learning these languages, given that they have the same
origin and thus, are similar to some extend. Even though the whole experiment
was conducted with low computational power, the obtained result is comparable
to the results of other, more expensive, models. Furthermore, since the
training data in use is relatively small and the two languages are almost
entirely unknown to us, this work can be generalized as an effort to demystify
lost or alien languages that no human is capable of understanding.",None,-1
8579846f-a8fd-47c7-9c93-7333eff78f5d,PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech Representations,0.215639,"While self-supervised speech representation learning (SSL) models serve a
variety of downstream tasks, these models have been observed to overfit to the
domain from which the unlabelled data originates. To alleviate this issue, we
propose PADA (Pruning Assisted Domain Adaptation) and zero out redundant
weights from models pre-trained on large amounts of out-of-domain (OOD) data.
Intuitively, this helps to make space for the target-domain ASR finetuning. The
redundant weights can be identified through various pruning strategies which
have been discussed in detail as a part of this work. Specifically, we
investigate the effect of the recently discovered Task-Agnostic and Task-Aware
pruning on PADA and propose a new pruning paradigm based on the latter, which
we call Cross-Domain Task-Aware Pruning (CD-TAW). CD-TAW obtains the initial
pruning mask from a well fine-tuned OOD model, which makes it starkly different
from the rest of the pruning strategies discussed in the paper. Our proposed
CD-TAW methodology achieves up to 20.6% relative WER improvement over our
baseline when fine-tuned on a 2-hour subset of Switchboard data without
language model (LM) decoding. Furthermore, we conduct a detailed analysis to
highlight the key design choices of our proposed method.",https://github.com/Speech-Lab-IITM/PADA,-1
4eba4a26-51a1-4071-9d8c-92de2c57d4a0,Towards Trustworthy Multi-label Sewer Defect Classification via Evidential Deep Learning,0.656177,"An automatic vision-based sewer inspection plays a key role of sewage system
in a modern city. Recent advances focus on utilizing deep learning model to
realize the sewer inspection system, benefiting from the capability of
data-driven feature representation. However, the inherent uncertainty of sewer
defects is ignored, resulting in the missed detection of serious unknown sewer
defect categories. In this paper, we propose a trustworthy multi-label sewer
defect classification (TMSDC) method, which can quantify the uncertainty of
sewer defect prediction via evidential deep learning. Meanwhile, a novel expert
base rate assignment (EBRA) is proposed to introduce the expert knowledge for
describing reliable evidences in practical situations. Experimental results
demonstrate the effectiveness of TMSDC and the superior capability of
uncertainty estimation is achieved on the latest public benchmark.",None,-1
c04f1f8e-743d-47d5-b31c-7e43f2cf69c5,Multi-Granularity Prediction for Scene Text Recognition,0.687028,"Scene text recognition (STR) has been an active research topic in computer
vision for years. To tackle this challenging problem, numerous innovative
methods have been successively proposed and incorporating linguistic knowledge
into STR models has recently become a prominent trend. In this work, we first
draw inspiration from the recent progress in Vision Transformer (ViT) to
construct a conceptually simple yet powerful vision STR model, which is built
upon ViT and outperforms previous state-of-the-art models for scene text
recognition, including both pure vision models and language-augmented methods.
To integrate linguistic knowledge, we further propose a Multi-Granularity
Prediction strategy to inject information from the language modality into the
model in an implicit way, i.e. , subword representations (BPE and WordPiece)
widely-used in NLP are introduced into the output space, in addition to the
conventional character level representation, while no independent language
model (LM) is adopted. The resultant algorithm (termed MGP-STR) is able to push
the performance envelop of STR to an even higher level. Specifically, it
achieves an average recognition accuracy of 93.35% on standard benchmarks. Code
is available at
https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/MGP-STR.",None,-1
8481af7d-e8df-4264-944e-51a11b8a26fe,On the Role of Bidirectionality in Language Model Pre-Training,0.557968,"Prior work on language model pre-training has explored different
architectures and learning objectives, but differences in data, hyperparameters
and evaluation make a principled comparison difficult. In this work, we focus
on bidirectionality as a key factor that differentiates existing approaches,
and present a comprehensive study of its role in next token prediction, text
infilling, zero-shot priming and fine-tuning. We propose a new framework that
generalizes prior approaches, including fully unidirectional models like GPT,
fully bidirectional models like BERT, and hybrid models like CM3 and prefix LM.
Our framework distinguishes between two notions of bidirectionality
(bidirectional context and bidirectional attention) and allows us to control
each of them separately. We find that the optimal configuration is largely
application-dependent (e.g., bidirectional attention is beneficial for
fine-tuning and infilling, but harmful for next token prediction and zero-shot
priming). We train models with up to 6.7B parameters, and find differences to
remain consistent at scale. While prior work on scaling has focused on
left-to-right autoregressive models, our results suggest that this approach
comes with some trade-offs, and it might be worthwhile to develop very large
bidirectional models.",None,-1
a444ff8d-be3d-4e0e-939f-261cc4fe1cb9,Uplifting Message Passing Neural Network with Graph Original Information,0.0408806,"Message passing neural networks (MPNNs) learn the representation of
graph-structured data based on graph original information, including node
features and graph structures, and have shown astonishing improvement in node
classification tasks. However, the expressive power of MPNNs is upper bounded
by the first-order Weisfeiler-Leman test and its accuracy still has room for
improvement. This work studies how to improve MPNNs' expressiveness and
generalizability by fully exploiting graph original information both
theoretically and empirically. It further proposes a new GNN model called INGNN
(INformation-enhanced Graph Neural Network) that leverages the insights to
improve node classification performance. Extensive experiments on both
synthetic and real datasets demonstrate the superiority (average rank 1.78) of
our INGNN compared with state-of-the-art methods.",None,-1
2afc570d-1c86-41dc-8733-d2516880ab29,Guided Depth Super-Resolution by Deep Anisotropic Diffusion,0.892782,"Performing super-resolution of a depth image using the guidance from an RGB
image is a problem that concerns several fields, such as robotics, medical
imaging, and remote sensing. While deep learning methods have achieved good
results in this problem, recent work highlighted the value of combining modern
methods with more formal frameworks. In this work, we propose a novel approach
which combines guided anisotropic diffusion with a deep convolutional network
and advances the state of the art for guided depth super-resolution. The edge
transferring/enhancing properties of the diffusion are boosted by the
contextual reasoning capabilities of modern networks, and a strict adjustment
step guarantees perfect adherence to the source image. We achieve unprecedented
results in three commonly used benchmarks for guided depth super-resolution.
The performance gain compared to other methods is the largest at larger scales,
such as x32 scaling. Code
(https://github.com/prs-eth/Diffusion-Super-Resolution) for the proposed method
is available to promote reproducibility of our results.",https://github.com/prs-eth/Diffusion-Super-Resolution,-1
4daa5155-ec34-4299-bef5-3fa59a4d72e8,A Semantic Framework for Neural-Symbolic Computing,0.112222,"Two approaches to AI, neural networks and symbolic systems, have been proven
very successful for an array of AI problems. However, neither has been able to
achieve the general reasoning ability required for human-like intelligence. It
has been argued that this is due to inherent weaknesses in each approach.
Luckily, these weaknesses appear to be complementary, with symbolic systems
being adept at the kinds of things neural networks have trouble with and
vice-versa. The field of neural-symbolic AI attempts to exploit this asymmetry
by combining neural networks and symbolic AI into integrated systems. Often
this has been done by encoding symbolic knowledge into neural networks.
Unfortunately, although many different methods for this have been proposed,
there is no common definition of an encoding to compare them. We seek to
rectify this problem by introducing a semantic framework for neural-symbolic
AI, which is then shown to be general enough to account for a large family of
neural-symbolic systems. We provide a number of examples and proofs of the
application of the framework to the neural encoding of various forms of
knowledge representation and neural network. These, at first sight disparate
approaches, are all shown to fall within the framework's formal definition of
what we call semantic encoding for neural-symbolic AI.",None,-1
ac5d9c97-f78f-4310-8464-0436d9e2f11f,Representation Learning with Diffusion Models,0.163101,"Diffusion models (DMs) have achieved state-of-the-art results for image
synthesis tasks as well as density estimation. Applied in the latent space of a
powerful pretrained autoencoder (LDM), their immense computational requirements
can be significantly reduced without sacrificing sampling quality. However, DMs
and LDMs lack a semantically meaningful representation space as the diffusion
process gradually destroys information in the latent variables. We introduce a
framework for learning such representations with diffusion models (LRDM). To
that end, a LDM is conditioned on the representation extracted from the clean
image by a separate encoder. In particular, the DM and the representation
encoder are trained jointly in order to learn rich representations specific to
the generative denoising process. By introducing a tractable representation
prior, we can efficiently sample from the representation distribution for
unconditional image synthesis without training of any additional model. We
demonstrate that i) competitive image generation results can be achieved with
image-parameterized LDMs, ii) LRDMs are capable of learning semantically
meaningful representations, allowing for faithful image reconstructions and
semantic interpolations. Our implementation is available at
https://github.com/jeremiastraub/diffusion.",https://github.com/jeremiastraub/diﬀusion,-1
c8df3495-e001-4021-8b5f-fd99748f233f,FedQAS: Privacy-aware machine reading comprehension with federated learning,0.414064,"Machine reading comprehension (MRC) of text data is one important task in
Natural Language Understanding. It is a complex NLP problem with a lot of
ongoing research fueled by the release of the Stanford Question Answering
Dataset (SQuAD) and Conversational Question Answering (CoQA). It is considered
to be an effort to teach computers how to ""understand"" a text, and then to be
able to answer questions about it using deep learning. However, until now
large-scale training on private text data and knowledge sharing has been
missing for this NLP task. Hence, we present FedQAS, a privacy-preserving
machine reading system capable of leveraging large-scale private data without
the need to pool those datasets in a central location. The proposed approach
combines transformer models and federated learning technologies. The system is
developed using the FEDn framework and deployed as a proof-of-concept alliance
initiative. FedQAS is flexible, language-agnostic, and allows intuitive
participation and execution of local model training. In addition, we present
the architecture and implementation of the system, as well as provide a
reference evaluation based on the SQUAD dataset, to showcase how it overcomes
data privacy issues and enables knowledge sharing between alliance members in a
Federated learning setting.",https://github.com/aitmlouk/FEDn-client-FedQAS-tf.git,-1
42e9aa9b-f1ed-432a-846e-c3c142786a71,Event knowledge in large language models: the gap between the impossible and the unlikely,0.927765,"Word co-occurrence patterns in language corpora contain a surprising amount
of conceptual knowledge. Large language models (LLMs), trained to predict words
in context, leverage these patterns to achieve impressive performance on
diverse semantic tasks requiring world knowledge. An important but understudied
question about LLMs' semantic abilities is whether they acquire generalized
knowledge of common events. Here, we test whether five pre-trained LLMs (from
2018's BERT to 2023's MPT) assign higher likelihood to plausible descriptions
of agent-patient interactions than to minimally different implausible versions
of the same event. Using three curated sets of minimal sentence pairs (total
n=1,215), we found that pre-trained LLMs possess substantial event knowledge,
outperforming other distributional language models. In particular, they almost
always assign higher likelihood to possible vs. impossible events (The teacher
bought the laptop vs. The laptop bought the teacher). However, LLMs show less
consistent preferences for likely vs. unlikely events (The nanny tutored the
boy vs. The boy tutored the nanny). In follow-up analyses, we show that (i) LLM
scores are driven by both plausibility and surface-level sentence features,
(ii) LLM scores generalize well across syntactic variants (active vs. passive
constructions) but less well across semantic variants (synonymous sentences),
(iii) some LLM errors mirror human judgment ambiguity, and (iv) sentence
plausibility serves as an organizing dimension in internal LLM representations.
Overall, our results show that important aspects of event knowledge naturally
emerge from distributional linguistic patterns, but also highlight a gap
between representations of possible/impossible and likely/unlikely events.",https://github.com/carina-kauf/lm-event-knowledge,-1
a626725b-1245-4480-bfe2-952e27b07a79,Meta-Learning Adversarial Bandits,0.235794,"We study online learning with bandit feedback across multiple tasks, with the
goal of improving average performance across tasks if they are similar
according to some natural task-similarity measure. As the first to target the
adversarial setting, we design a unified meta-algorithm that yields
setting-specific guarantees for two important cases: multi-armed bandits (MAB)
and bandit linear optimization (BLO). For MAB, the meta-algorithm tunes the
initialization, step-size, and entropy parameter of the Tsallis-entropy
generalization of the well-known Exp3 method, with the task-averaged regret
provably improving if the entropy of the distribution over estimated
optima-in-hindsight is small. For BLO, we learn the initialization, step-size,
and boundary-offset of online mirror descent (OMD) with self-concordant barrier
regularizers, showing that task-averaged regret varies directly with a measure
induced by these functions on the interior of the action space. Our adaptive
guarantees rely on proving that unregularized follow-the-leader combined with
multiplicative weights is enough to online learn a non-smooth and non-convex
sequence of affine functions of Bregman divergences that upper-bound the regret
of OMD.",None,-1
7d41d2a9-794e-4eb2-9570-5ea99d17a150,AutoAttention: Automatic Field Pair Selection for Attention in User Behavior Modeling,0.358099,"In Click-through rate (CTR) prediction models, a user's interest is usually
represented as a fixed-length vector based on her history behaviors. Recently,
several methods are proposed to learn an attentive weight for each user
behavior and conduct weighted sum pooling. However, these methods only manually
select several fields from the target item side as the query to interact with
the behaviors, neglecting the other target item fields, as well as user and
context fields. Directly including all these fields in the attention may
introduce noise and deteriorate the performance. In this paper, we propose a
novel model named AutoAttention, which includes all item/user/context side
fields as the query, and assigns a learnable weight for each field pair between
behavior fields and query fields. Pruning on these field pairs via these
learnable weights lead to automatic field pair selection, so as to identify and
remove noisy field pairs. Though including more fields, the computation cost of
AutoAttention is still low due to using a simple attention function and field
pair selection. Extensive experiments on the public dataset and Tencent's
production dataset demonstrate the effectiveness of the proposed approach.",https://github.com/waydrow/AutoAttention,-1
3e8f57b9-41f0-4b67-baaa-4f0732805d6a,Czech Dataset for Cross-lingual Subjectivity Classification,0.431071,"In this paper, we introduce a new Czech subjectivity dataset of 10k manually
annotated subjective and objective sentences from movie reviews and
descriptions. Our prime motivation is to provide a reliable dataset that can be
used with the existing English dataset as a benchmark to test the ability of
pre-trained multilingual models to transfer knowledge between Czech and English
and vice versa. Two annotators annotated the dataset reaching 0.83 of the
Cohen's \k{appa} inter-annotator agreement. To the best of our knowledge, this
is the first subjectivity dataset for the Czech language. We also created an
additional dataset that consists of 200k automatically labeled sentences. Both
datasets are freely available for research purposes. Furthermore, we fine-tune
five pre-trained BERT-like models to set a monolingual baseline for the new
dataset and we achieve 93.56% of accuracy. We fine-tune models on the existing
English dataset for which we obtained results that are on par with the current
state-of-the-art results. Finally, we perform zero-shot cross-lingual
subjectivity classification between Czech and English to verify the usability
of our dataset as the cross-lingual benchmark. We compare and discuss the
cross-lingual and monolingual results and the ability of multilingual models to
transfer knowledge between languages.",https://github.com/pauli31/czech-subjectivity-dataset,3078
bfed2527-6b64-445c-ade1-66764a1ccef3,Learned Digital Back-Propagation for Dual-Polarization Dispersion Managed Systems,0.111187,"Digital back-propagation (DBP) and learned DBP (LDBP) are proposed for
nonlinearity mitigation in WDM dual-polarization dispersion-managed systems.
LDBP achieves Q-factor improvement of 1.8 dB and 1.2 dB, respectively, over
linear equalization and a variant of DBP adapted to DM systems.",None,-1
ae842b0e-42a4-4cd2-961f-3df250facb12,Where to go: Agent Guidance with Deep Reinforcement Learning in A City-Scale Online Ride-Hailing Service,0.195602,"Online ride-hailing services have become a prevalent transportation system
across the world. In this paper, we study a challenging problem of how to
direct vacant taxis around a city such that supplies and demands can be
balanced in online ride-hailing services. We design a new reward scheme that
considers multiple performance metrics of online ride-hailing services. We also
propose a novel deep reinforcement learning method named Deep-Q-Network with
Action Mask (AM-DQN) masking off unnecessary actions in various locations such
that agents can learn much faster and more efficiently. We conduct extensive
experiments using a city-scale dataset from Chicago. Several popular heuristic
and learning methods are also implemented as baselines for comparison. The
results of the experiments show that the AM-DQN attains the best performances
of all methods with respect to average failure rate, average waiting time for
customers, and average idle search time for vacant taxis.",None,-1
92c97088-fb82-4cb2-9937-fcdf4dcd8904,SwinUNet3D -- A Hierarchical Architecture for Deep Traffic Prediction using Shifted Window Transformers,0.358019,"Traffic forecasting is an important element of mobility management, an
important key that drives the logistics industry. Over the years, lots of work
have been done in Traffic forecasting using time series as well as
spatiotemporal dynamic forecasting. In this paper, we explore the use of vision
transformer in a UNet setting. We completely remove all convolution-based
building blocks in UNet, while using 3D shifted window transformer in both
encoder and decoder branches. In addition, we experiment with the use of
feature mixing just before patch encoding to control the inter-relationship of
the feature while avoiding contraction of the depth dimension of our
spatiotemporal input. The proposed network is tested on the data provided by
Traffic Map Movie Forecasting Challenge 2021(Traffic4cast2021), held in the
competition track of Neural Information Processing Systems (NeurIPS).
Traffic4cast2021 task is to predict an hour (6 frames) of traffic conditions
(volume and average speed)from one hour of given traffic state (12 frames
averaged in 5 minutes time span). Source code is available online at
https://github.com/bojesomo/Traffic4Cast2021-SwinUNet3D.",https://github.com/bojesomo/Trafﬁc4Cast2021-SwinUNet3D,-1
10967893-6eb9-4ef7-8ff4-2093aaf33e2c,TINYCD: A (Not So) Deep Learning Model For Change Detection,0.838808,"In this paper, we present a lightweight and effective change detection model,
called TinyCD. This model has been designed to be faster and smaller than
current state-of-the-art change detection models due to industrial needs.
Despite being from 13 to 140 times smaller than the compared change detection
models, and exposing at least a third of the computational complexity, our
model outperforms the current state-of-the-art models by at least $1\%$ on both
F1 score and IoU on the LEVIR-CD dataset, and more than $8\%$ on the WHU-CD
dataset. To reach these results, TinyCD uses a Siamese U-Net architecture
exploiting low-level features in a globally temporal and locally spatial way.
In addition, it adopts a new strategy to mix features in the space-time domain
both to merge the embeddings obtained from the Siamese backbones, and, coupled
with an MLP block, it forms a novel space-semantic attention mechanism, the Mix
and Attention Mask Block (MAMB). Source code, models and results are available
here: https://github.com/AndreaCodegoni/Tiny_model_4_CD",https://github.com/AndreaCodegoni/Tiny_model_4_CD,82
d26346b9-2cf8-4996-af1b-5e7f7e93bb8c,Modeling Dual Read/Write Paths for Simultaneous Machine Translation,0.689124,"Simultaneous machine translation (SiMT) outputs translation while reading
source sentence and hence requires a policy to decide whether to wait for the
next source word (READ) or generate a target word (WRITE), the actions of which
form a read/write path. Although the read/write path is essential to SiMT
performance, no direct supervision is given to the path in the existing
methods. In this paper, we propose a method of dual-path SiMT which introduces
duality constraints to direct the read/write path. According to duality
constraints, the read/write path in source-to-target and target-to-source SiMT
models can be mapped to each other. As a result, the two SiMT models can be
optimized jointly by forcing their read/write paths to satisfy the mapping.
Experiments on En-Vi and De-En tasks show that our method can outperform strong
baselines under all latency.",https://github.com/ictnlp/,-1
b3a3b2e7-c6c3-4ca8-98a7-e7b1789d71a0,Domain-aware Self-supervised Pre-training for Label-Efficient Meme Analysis,0.352656,"Existing self-supervised learning strategies are constrained to either a
limited set of objectives or generic downstream tasks that predominantly target
uni-modal applications. This has isolated progress for imperative multi-modal
applications that are diverse in terms of complexity and domain-affinity, such
as meme analysis. Here, we introduce two self-supervised pre-training methods,
namely Ext-PIE-Net and MM-SimCLR that (i) employ off-the-shelf multi-modal
hate-speech data during pre-training and (ii) perform self-supervised learning
by incorporating multiple specialized pretext tasks, effectively catering to
the required complex multi-modal representation learning for meme analysis. We
experiment with different self-supervision strategies, including potential
variants that could help learn rich cross-modality representations and evaluate
using popular linear probing on the Hateful Memes task. The proposed solutions
strongly compete with the fully supervised baseline via label-efficient
training while distinctly outperforming them on all three tasks of the Memotion
challenge with 0.18%, 23.64%, and 0.93% performance gain, respectively.
Further, we demonstrate the generalizability of the proposed solutions by
reporting competitive performance on the HarMeme task. Finally, we empirically
establish the quality of the learned representations by analyzing task-specific
learning, using fewer labeled training samples, and arguing that the complexity
of the self-supervision strategy and downstream task at hand are correlated.
Our efforts highlight the requirement of better multi-modal self-supervision
methods involving specialized pretext tasks for efficient fine-tuning and
generalizable performance.",None,-1
d7d9e24d-54d4-4049-8486-abfaf819225e,MSI: Maximize Support-Set Information for Few-Shot Segmentation,0.0831723,"FSS(Few-shot segmentation) aims to segment a target class using a small
number of labeled images(support set). To extract information relevant to the
target class, a dominant approach in best-performing FSS methods removes
background features using a support mask. We observe that this feature excision
through a limiting support mask introduces an information bottleneck in several
challenging FSS cases, e.g., for small targets and/or inaccurate target
boundaries. To this end, we present a novel method(MSI), which maximizes the
support-set information by exploiting two complementary sources of features to
generate super correlation maps. We validate the effectiveness of our approach
by instantiating it into three recent and strong FSS methods. Experimental
results on several publicly available FSS benchmarks show that our proposed
method consistently improves performance by visible margins and leads to faster
convergence. Our code and trained models are available at:
https://github.com/moonsh/MSI-Maximize-Support-Set-Information",https://github.com/moonsh/MSI-Maximize-Support-Set-Information,-1
42235e75-cac0-43cc-b980-7bac63154079,Modelling Commonsense Properties using Pre-Trained Bi-Encoders,0.214022,"Grasping the commonsense properties of everyday concepts is an important
prerequisite to language understanding. While contextualised language models
are reportedly capable of predicting such commonsense properties with
human-level accuracy, we argue that such results have been inflated because of
the high similarity between training and test concepts. This means that models
which capture concept similarity can perform well, even if they do not capture
any knowledge of the commonsense properties themselves. In settings where there
is no overlap between the properties that are considered during training and
testing, we find that the empirical performance of standard language models
drops dramatically. To address this, we study the possibility of fine-tuning
language models to explicitly model concepts and their properties. In
particular, we train separate concept and property encoders on two types of
readily available data: extracted hyponym-hypernym pairs and generic sentences.
Our experimental results show that the resulting encoders allow us to predict
commonsense properties with much higher accuracy than is possible by directly
fine-tuning language models. We also present experimental results for the
related task of unsupervised hypernym discovery.",https://github.com/amitgajbhiye/biencoder_concept_property,-1
177cdf62-b7e0-4412-a094-742c5bc4fc96,Epistemic AI platform accelerates innovation by connecting biomedical knowledge,0.0678157,"Epistemic AI accelerates biomedical discovery by finding hidden connections
in the network of biomedical knowledge. The Epistemic AI web-based software
platform embodies the concept of knowledge mapping, an interactive process that
relies on a knowledge graph in combination with natural language processing
(NLP), information retrieval, relevance feedback, and network analysis.
Knowledge mapping reduces information overload, prevents costly mistakes, and
minimizes missed opportunities in the research process. The platform combines
state-of-the-art methods for information extraction with machine learning,
artificial intelligence and network analysis. Starting from a single biological
entity, such as a gene or disease, users may: a) construct a map of connections
to that entity, b) map an entire domain of interest, and c) gain insight into
large biological networks of knowledge. Knowledge maps provide clarity and
organization, simplifying the day-to-day research processes.",None,-1
bc9d5bf3-6beb-48f2-80d8-1b22328e5906,LEBP -- Language Expectation & Binding Policy: A Two-Stream Framework for Embodied Vision-and-Language Interaction Task Learning Agents,0.360943,"People always desire an embodied agent that can perform a task by
understanding language instruction. Moreover, they also want to monitor and
expect agents to understand commands the way they expected. But, how to build
such an embodied agent is still unclear. Recently, people can explore this
problem with the Vision-and-Language Interaction benchmark ALFRED, which
requires an agent to perform complicated daily household tasks following
natural language instructions in unseen scenes. In this paper, we propose LEBP
-- Language Expectation and Binding Policy Module to tackle the ALFRED. The
LEBP contains a two-stream process: 1) It first conducts a language expectation
module to generate an expectation describing how to perform tasks by
understanding the language instruction. The expectation consists of a sequence
of sub-steps for the task (e.g., Pick an apple). The expectation allows people
to access and check the understanding results of instructions before the agent
takes actual actions, in case the task might go wrong. 2) Then, it uses the
binding policy module to bind sub-steps in expectation to actual actions to
specific scenarios. Actual actions include navigation and object manipulation.
Experimental results suggest our approach achieves comparable performance to
currently published SOTA methods and can avoid large decay from seen scenarios
to unseen scenarios.",None,-1
b0354b72-bc7c-4c45-ac3a-d320c19a1d3f,Combining Static and Contextualised Multilingual Embeddings,0.162167,"Static and contextual multilingual embeddings have complementary strengths.
Static embeddings, while less expressive than contextual language models, can
be more straightforwardly aligned across multiple languages. We combine the
strengths of static and contextual models to improve multilingual
representations. We extract static embeddings for 40 languages from XLM-R,
validate those embeddings with cross-lingual word retrieval, and then align
them using VecMap. This results in high-quality, highly multilingual static
embeddings. Then we apply a novel continued pre-training approach to XLM-R,
leveraging the high quality alignment of our static embeddings to better align
the representation space of XLM-R. We show positive results for multiple
complex semantic tasks. We release the static embeddings and the continued
pre-training code. Unlike most previous work, our continued pre-training
approach does not require parallel text.",https://github.com/KathyHaem/combining-static-contextual,-1
05d8a73d-4867-400c-9e78-4d5c10cc46a1,Bipartite-play Dialogue Collection for Practical Automatic Evaluation of Dialogue Systems,0.120327,"Automation of dialogue system evaluation is a driving force for the efficient
development of dialogue systems. This paper introduces the bipartite-play
method, a dialogue collection method for automating dialogue system evaluation.
It addresses the limitations of existing dialogue collection methods: (i)
inability to compare with systems that are not publicly available, and (ii)
vulnerability to cheating by intentionally selecting systems to be compared.
Experimental results show that the automatic evaluation using the
bipartite-play method mitigates these two drawbacks and correlates as strongly
with human subjectivity as existing methods.",None,933
eb7f806e-8168-4901-869e-8c606912a686,Disentangled Latent Transformer for Interpretable Monocular Height Estimation,0.450925,"Monocular height estimation (MHE) from remote sensing imagery has high
potential in generating 3D city models efficiently for a quick response to
natural disasters. Most existing works pursue higher performance. However,
there is little research exploring the interpretability of MHE networks. In
this paper, we target at exploring how deep neural networks predict height from
a single monocular image. Towards a comprehensive understanding of MHE
networks, we propose to interpret them from multiple levels: 1) Neurons:
unit-level dissection. Exploring the semantic and height selectivity of the
learned internal deep representations; 2) Instances: object-level
interpretation. Studying the effects of different semantic classes, scales, and
spatial contexts on height estimation; 3) Attribution: pixel-level analysis.
Understanding which input pixels are important for the height estimation. Based
on the multi-level interpretation, a disentangled latent Transformer network is
proposed towards a more compact, reliable, and explainable deep model for
monocular height estimation. Furthermore, a novel unsupervised semantic
segmentation task based on height estimation is first introduced in this work.
Additionally, we also construct a new dataset for joint semantic segmentation
and height estimation. Our work provides novel insights for both understanding
and designing MHE models.",https://github.com/ShadowXZT/DLT-Height-Estimation.pytorch,-1
3ff6da70-d4c8-4a18-a326-7f2b3d73449d,Visually-Augmented Language Modeling,0.70736,"Human language is grounded on multimodal knowledge including visual knowledge
like colors, sizes, and shapes. However, current large-scale pre-trained
language models rely on text-only self-supervised training with massive text
data, which precludes them from utilizing relevant visual information when
necessary. To address this, we propose a novel pre-training framework, named
VaLM, to Visually-augment text tokens with retrieved relevant images for
Language Modeling. Specifically, VaLM builds on a novel latent text-image
alignment method via an image retrieval module to fetch corresponding images
given a textual context. With the visually-augmented context, VaLM uses a
visual knowledge fusion layer to enable multimodal grounded language modeling
by attending to both text context and visual knowledge in images. We evaluate
VaLM on various visual knowledge-intensive commonsense reasoning tasks, which
require visual information to excel. The experimental results illustrate that
VaLM outperforms all strong language-only and vision-language baselines with
substantial gains in reasoning object commonsense including color, size, and
shape. Our code is available at https://github.com/Victorwz/VaLM.",https://github.com/Victorwz/VaLM,-1
2d5757a1-d9f5-47eb-ae83-c4f0baf9c9ba,Saga: A Platform for Continuous Construction and Serving of Knowledge At Scale,0.522143,"We introduce Saga, a next-generation knowledge construction and serving
platform for powering knowledge-based applications at industrial scale. Saga
follows a hybrid batch-incremental design to continuously integrate billions of
facts about real-world entities and construct a central knowledge graph that
supports multiple production use cases with diverse requirements around data
freshness, accuracy, and availability. In this paper, we discuss the unique
challenges associated with knowledge graph construction at industrial scale,
and review the main components of Saga and how they address these challenges.
Finally, we share lessons-learned from a wide array of production use cases
powered by Saga.",None,3350
3ed0b6e3-079e-4377-bf0a-5d8234832c11,Common Pets in 3D: Dynamic New-View Synthesis of Real-Life Deformable Categories,0.404387,"Obtaining photorealistic reconstructions of objects from sparse views is
inherently ambiguous and can only be achieved by learning suitable
reconstruction priors. Earlier works on sparse rigid object reconstruction
successfully learned such priors from large datasets such as CO3D. In this
paper, we extend this approach to dynamic objects. We use cats and dogs as a
representative example and introduce Common Pets in 3D (CoP3D), a collection of
crowd-sourced videos showing around 4,200 distinct pets. CoP3D is one of the
first large-scale datasets for benchmarking non-rigid 3D reconstruction ""in the
wild"". We also propose Tracker-NeRF, a method for learning 4D reconstruction
from our dataset. At test time, given a small number of video frames of an
unseen object, Tracker-NeRF predicts the trajectories of its 3D points and
generates new views, interpolating viewpoint and time. Results on CoP3D reveal
significantly better non-rigid new-view synthesis performance than existing
baselines.",None,-1
28c593b8-d071-4a0c-8211-82ee1e5bdefa,Pretraining with Artificial Language: Studying Transferable Knowledge in Language Models,0.580953,"We investigate what kind of structural knowledge learned in neural network
encoders is transferable to processing natural language. We design artificial
languages with structural properties that mimic natural language, pretrain
encoders on the data, and see how much performance the encoder exhibits on
downstream tasks in natural language. Our experimental results show that
pretraining with an artificial language with a nesting dependency structure
provides some knowledge transferable to natural language. A follow-up probing
analysis indicates that its success in the transfer is related to the amount of
encoded contextual information and what is transferred is the knowledge of
position-aware context dependence of language. Our results provide insights
into how neural network encoders process human languages and the source of
cross-lingual transferability of recent multilingual language models.",https://github.com/moses-smt/mosesdecoder,-1
2608764e-cde2-4c15-9c7c-e5dfd4fe4f9c,Improving Sample Efficiency of Value Based Models Using Attention and Vision Transformers,0.195881,"Much of recent Deep Reinforcement Learning success is owed to the neural
architecture's potential to learn and use effective internal representations of
the world. While many current algorithms access a simulator to train with a
large amount of data, in realistic settings, including while playing games that
may be played against people, collecting experience can be quite costly. In
this paper, we introduce a deep reinforcement learning architecture whose
purpose is to increase sample efficiency without sacrificing performance. We
design this architecture by incorporating advances achieved in recent years in
the field of Natural Language Processing and Computer Vision. Specifically, we
propose a visually attentive model that uses transformers to learn a
self-attention mechanism on the feature maps of the state representation, while
simultaneously optimizing return. We demonstrate empirically that this
architecture improves sample complexity for several Atari environments, while
also achieving better performance in some of the games.",None,-1
621159f8-77d5-4859-8cc6-a948a553213f,imitation: Clean Imitation Learning Implementations,0.396492,"imitation provides open-source implementations of imitation and reward
learning algorithms in PyTorch. We include three inverse reinforcement learning
(IRL) algorithms, three imitation learning algorithms and a preference
comparison algorithm. The implementations have been benchmarked against
previous results, and automated tests cover 98% of the code. Moreover, the
algorithms are implemented in a modular fashion, making it simple to develop
novel algorithms in the framework. Our source code, including documentation and
examples, is available at https://github.com/HumanCompatibleAI/imitation",https://github.com/HumanCompatibleAI/imitation,-1
ab0255e7-b25b-40f3-bed2-1d241ca2c607,CASE: Aligning Coarse-to-Fine Cognition and Affection for Empathetic Response Generation,0.537378,"Empathetic conversation is psychologically supposed to be the result of
conscious alignment and interaction between the cognition and affection of
empathy. However, existing empathetic dialogue models usually consider only the
affective aspect or treat cognition and affection in isolation, which limits
the capability of empathetic response generation. In this work, we propose the
CASE model for empathetic dialogue generation. It first builds upon a
commonsense cognition graph and an emotional concept graph and then aligns the
user's cognition and affection at both the coarse-grained and fine-grained
levels. Through automatic and manual evaluation, we demonstrate that CASE
outperforms state-of-the-art baselines of empathetic dialogues and can generate
more empathetic and informative responses.",https://github.com/jfzhouyoo/CASE,-1
d98ff4c6-f00c-4960-99ad-3788b27cb924,Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling,0.598862,"Recent studies in using deep reinforcement learning (DRL) to solve Job-shop
scheduling problems (JSSP) focus on construction heuristics. However, their
performance is still far from optimality, mainly because the underlying graph
representation scheme is unsuitable for modelling partial solutions at each
construction step. This paper proposes a novel DRL-guided improvement heuristic
for solving JSSP, where graph representation is employed to encode complete
solutions. We design a Graph Neural-Network-based representation scheme,
consisting of two modules to effectively capture the information of dynamic
topology and different types of nodes in graphs encountered during the
improvement process. To speed up solution evaluation during improvement, we
present a novel message-passing mechanism that can evaluate multiple solutions
simultaneously. We prove that the computational complexity of our method scales
linearly with problem size. Experiments on classic benchmarks show that the
improvement policy learned by our method outperforms state-of-the-art DRL-based
methods by a large margin.",https://github.com/zcaicaros/L2S,-1
c855fed3-0038-42ea-affd-e0028d0fe859,Investigating Bias with a Synthetic Data Generator: Empirical Evidence and Philosophical Interpretation,0.168872,"Machine learning applications are becoming increasingly pervasive in our
society. Since these decision-making systems rely on data-driven learning, risk
is that they will systematically spread the bias embedded in data. In this
paper, we propose to analyze biases by introducing a framework for generating
synthetic data with specific types of bias and their combinations. We delve
into the nature of these biases discussing their relationship to moral and
justice frameworks. Finally, we exploit our proposed synthetic data generator
to perform experiments on different scenarios, with various bias combinations.
We thus analyze the impact of biases on performance and fairness metrics both
in non-mitigated and mitigated machine learning models.",https://github.com/rcrupiISP/ISParity,-1
4cdbd97c-94a7-420d-8490-aba0ae48b771,A Machine With Human-Like Memory Systems,0.0386783,"Inspired by the cognitive science theory, we explicitly model an agent with
both semantic and episodic memory systems, and show that it is better than
having just one of the two memory systems. In order to show this, we have
designed and released our own challenging environment, ""the Room"", compatible
with OpenAI Gym, where an agent has to properly learn how to encode, store, and
retrieve memories to maximize its rewards. The Room environment allows for a
hybrid intelligence setup where machines and humans can collaborate. We show
that two agents collaborating with each other results in better performance
than one agent acting alone. We have open-sourced our code and models at
https://github.com/tae898/explicit-memory.",https://github.com/tae898/explicit-memory,-1
9fe3963a-4857-4fd6-ac16-746331aea548,Symbolic image detection using scene and knowledge graphs,0.0905231,"Sometimes the meaning conveyed by images goes beyond the list of objects they
contain; instead, images may express a powerful message to affect the viewers'
minds. Inferring this message requires reasoning about the relationships
between the objects, and general common-sense knowledge about the components.
In this paper, we use a scene graph, a graph representation of an image, to
capture visual components. In addition, we generate a knowledge graph using
facts extracted from ConceptNet to reason about objects and attributes. To
detect the symbols, we propose a neural network framework named SKG-Sym. The
framework first generates the representations of the scene graph of the image
and its knowledge graph using Graph Convolution Network. The framework then
fuses the representations and uses an MLP to classify them. We extend the
network further to use an attention mechanism which learn the importance of the
graph representations. We evaluate our methods on a dataset of advertisements,
and compare it with baseline symbolism classification methods (ResNet and VGG).
Results show that our methods outperform ResNet in terms of F-score and the
attention-based mechanism is competitive with VGG while it has much lower model
complexity.",https://github.com/NasrinKalanat/SKG-Sym,-1
26caa5c9-b50a-4647-8575-4e1713ef7a15,Motion Sensitive Contrastive Learning for Self-supervised Video Representation,0.459931,"Contrastive learning has shown great potential in video representation
learning. However, existing approaches fail to sufficiently exploit short-term
motion dynamics, which are crucial to various down-stream video understanding
tasks. In this paper, we propose Motion Sensitive Contrastive Learning (MSCL)
that injects the motion information captured by optical flows into RGB frames
to strengthen feature learning. To achieve this, in addition to clip-level
global contrastive learning, we develop Local Motion Contrastive Learning
(LMCL) with frame-level contrastive objectives across the two modalities.
Moreover, we introduce Flow Rotation Augmentation (FRA) to generate extra
motion-shuffled negative samples and Motion Differential Sampling (MDS) to
accurately screen training samples. Extensive experiments on standard
benchmarks validate the effectiveness of the proposed method. With the
commonly-used 3D ResNet-18 as the backbone, we achieve the top-1 accuracies of
91.5\% on UCF101 and 50.3\% on Something-Something v2 for video classification,
and a 65.6\% Top-1 Recall on UCF101 for video retrieval, notably improving the
state-of-the-art.",None,-1
578cd393-dba6-4c06-88dc-4a8f09fbaff8,Cross-Modal Mutual Learning for Cued Speech Recognition,0.500924,"Automatic Cued Speech Recognition (ACSR) provides an intelligent
human-machine interface for visual communications, where the Cued Speech (CS)
system utilizes lip movements and hand gestures to code spoken language for
hearing-impaired people. Previous ACSR approaches often utilize direct feature
concatenation as the main fusion paradigm. However, the asynchronous modalities
i.e., lip, hand shape and hand position) in CS may cause interference for
feature concatenation. To address this challenge, we propose a transformer
based cross-modal mutual learning framework to prompt multi-modal interaction.
Compared with the vanilla self-attention, our model forces modality-specific
information of different modalities to pass through a modality-invariant
codebook, collating linguistic representations for tokens of each modality.
Then the shared linguistic knowledge is used to re-synchronize multi-modal
sequences. Moreover, we establish a novel large-scale multi-speaker CS dataset
for Mandarin Chinese. To our knowledge, this is the first work on ACSR for
Mandarin Chinese. Extensive experiments are conducted for different languages
i.e., Chinese, French, and British English). Results demonstrate that our model
exhibits superior recognition performance to the state-of-the-art by a large
margin.",None,-1
3658edac-0c1b-4d82-8577-da8405c42d45,Bi-Noising Diffusion: Towards Conditional Diffusion Models with Generative Restoration Priors,0.0671218,"Conditional diffusion probabilistic models can model the distribution of
natural images and can generate diverse and realistic samples based on given
conditions. However, oftentimes their results can be unrealistic with
observable color shifts and textures. We believe that this issue results from
the divergence between the probabilistic distribution learned by the model and
the distribution of natural images. The delicate conditions gradually enlarge
the divergence during each sampling timestep. To address this issue, we
introduce a new method that brings the predicted samples to the training data
manifold using a pretrained unconditional diffusion model. The unconditional
model acts as a regularizer and reduces the divergence introduced by the
conditional model at each sampling step. We perform comprehensive experiments
to demonstrate the effectiveness of our approach on super-resolution,
colorization, turbulence removal, and image-deraining tasks. The improvements
obtained by our method suggest that the priors can be incorporated as a general
plugin for improving conditional diffusion models.",None,-1
2e450d49-d3b4-4698-93de-0e1e4cc51250,GazeOnce: Real-Time Multi-Person Gaze Estimation,0.904979,"Appearance-based gaze estimation aims to predict the 3D eye gaze direction
from a single image. While recent deep learning-based approaches have
demonstrated excellent performance, they usually assume one calibrated face in
each input image and cannot output multi-person gaze in real time. However,
simultaneous gaze estimation for multiple people in the wild is necessary for
real-world applications. In this paper, we propose the first one-stage
end-to-end gaze estimation method, GazeOnce, which is capable of simultaneously
predicting gaze directions for multiple faces (>10) in an image. In addition,
we design a sophisticated data generation pipeline and propose a new dataset,
MPSGaze, which contains full images of multiple people with 3D gaze ground
truth. Experimental results demonstrate that our unified framework not only
offers a faster speed, but also provides a lower gaze estimation error compared
with state-of-the-art methods. This technique can be useful in real-time
applications with multiple users.",None,2832
90774a69-84a8-476f-b363-7057b864a328,Improved Universal Sentence Embeddings with Prompt-based Contrastive Learning and Energy-based Learning,0.64335,"Contrastive learning has been demonstrated to be effective in enhancing
pre-trained language models (PLMs) to derive superior universal sentence
embeddings. However, existing contrastive methods still have two limitations.
Firstly, previous works may acquire poor performance under domain shift
settings, thus hindering the application of sentence representations in
practice. We attribute this low performance to the over-parameterization of
PLMs with millions of parameters. To alleviate it, we propose PromCSE
(Prompt-based Contrastive Learning for Sentence Embeddings), which only trains
small-scale \emph{Soft Prompt} (i.e., a set of trainable vectors) while keeping
PLMs fixed. Secondly, the commonly used NT-Xent loss function of contrastive
learning does not fully exploit hard negatives in supervised learning settings.
To this end, we propose to integrate an Energy-based Hinge loss to enhance the
pairwise discriminative power, inspired by the connection between the NT-Xent
loss and the Energy-based Learning paradigm. Empirical results on seven
standard semantic textual similarity (STS) tasks and a domain-shifted STS task
both show the effectiveness of our method compared with the current
state-of-the-art sentence embedding models. Our code is publicly avaliable at
https://github.com/YJiangcm/PromCSE",https://github.com/YJiangcm/PromCSE,-1
fcf526fe-41ad-4a50-ac0f-45bab206e39c,Dual-Pixel Raindrop Removal,0.167805,"Removing raindrops in images has been addressed as a significant task for
various computer vision applications. In this paper, we propose the first
method using a Dual-Pixel (DP) sensor to better address the raindrop removal.
Our key observation is that raindrops attached to a glass window yield
noticeable disparities in DP's left-half and right-half images, while almost no
disparity exists for in-focus backgrounds. Therefore, DP disparities can be
utilized for robust raindrop detection. The DP disparities also brings the
advantage that the occluded background regions by raindrops are shifted between
the left-half and the right-half images. Therefore, fusing the information from
the left-half and the right-half images can lead to more accurate background
texture recovery. Based on the above motivation, we propose a DP Raindrop
Removal Network (DPRRN) consisting of DP raindrop detection and DP fused
raindrop removal. To efficiently generate a large amount of training data, we
also propose a novel pipeline to add synthetic raindrops to real-world
background DP images. Experimental results on synthetic and real-world datasets
demonstrate that our DPRRN outperforms existing state-of-the-art methods,
especially showing better robustness to real-world situations. Our source code
and datasets are available at http://www.ok.sc.e.titech.ac.jp/res/SIR/.",http://www.ok.sc.e.titech.ac.jp/res/SIR/,-1
14d1856b-efb0-4fc5-96ad-fa912b72d4f3,Improving Subgraph Representation Learning via Multi-View Augmentation,0.0694903,"Subgraph representation learning based on Graph Neural Network (GNN) has
exhibited broad applications in scientific advancements, such as predictions of
molecular structure-property relationships and collective cellular function. In
particular, graph augmentation techniques have shown promising results in
improving graph-based and node-based classification tasks. Still, they have
rarely been explored in the existing GNN-based subgraph representation learning
studies. In this study, we develop a novel multi-view augmentation mechanism to
improve subgraph representation learning models and thus the accuracy of
downstream prediction tasks. Our augmentation technique creates multiple
variants of subgraphs and embeds these variants into the original graph to
achieve highly improved training efficiency, scalability, and accuracy.
Benchmark experiments on several real-world biological and physiological
datasets demonstrate the superiority of our proposed multi-view augmentation
techniques in subgraph representation learning.",None,-1
2b68985d-934a-4ea6-97cd-fbdacbf0222f,Variable Functioning and Its Application to Large Scale Steel Frame Design Optimization,0.117122,"To solve complex real-world problems, heuristics and concept-based approaches
can be used in order to incorporate information into the problem. In this
study, a concept-based approach called variable functioning Fx is introduced to
reduce the optimization variables and narrow down the search space. In this
method, the relationships among one or more subset of variables are defined
with functions using information prior to optimization; thus, instead of
modifying the variables in the search process, the function variables are
optimized. By using problem structure analysis technique and engineering expert
knowledge, the $Fx$ method is used to enhance the steel frame design
optimization process as a complex real-world problem. The proposed approach is
coupled with particle swarm optimization and differential evolution algorithms
and used for three case studies. The algorithms are applied to optimize the
case studies by considering the relationships among column cross-section areas.
The results show that $Fx$ can significantly improve both the convergence rate
and the final design of a frame structure, even if it is only used for seeding.",None,204281
fe1d8d54-cad7-4fb8-ba1c-3839d7848e73,Multi-Target Active Object Tracking with Monte Carlo Tree Search and Target Motion Modeling,0.207798,"In this work, we are dedicated to multi-target active object tracking (AOT),
where there are multiple targets as well as multiple cameras in the
environment. The goal is maximize the overall target coverage of all cameras.
Previous work makes a strong assumption that each camera is fixed in a location
and only allowed to rotate, which limits its application. In this work, we
relax the setting by allowing all cameras to both move along the boundary lines
and rotate. In our setting, the action space becomes much larger, which leads
to much higher computational complexity to identify the optimal action. To this
end, we propose to leverage the action selection from multi-agent reinforcement
learning (MARL) network to prune the search tree of Monte Carlo Tree Search
(MCTS) method, so as to find the optimal action more efficiently. Besides, we
model the motion of the targets to predict the future position of the targets,
which makes a better estimation of the future environment state in the MCTS
process. We establish a multi-target 2D environment to simulate the sports
games, and experimental results demonstrate that our method can effectively
improve the target coverage.",None,-1
23c394aa-5646-4190-9d95-9f5684793cb1,MACSum: Controllable Summarization with Mixed Attributes,0.304397,"Controllable summarization allows users to generate customized summaries with
specified attributes. However, due to the lack of designated annotations of
controlled summaries, existing works have to craft pseudo datasets by adapting
generic summarization benchmarks. Furthermore, most research focuses on
controlling single attributes individually (e.g., a short summary or a highly
abstractive summary) rather than controlling a mix of attributes together
(e.g., a short and highly abstractive summary). In this paper, we propose
MACSum, the first human-annotated summarization dataset for controlling mixed
attributes. It contains source texts from two domains, news articles and
dialogues, with human-annotated summaries controlled by five designed
attributes (Length, Extractiveness, Specificity, Topic, and Speaker). We
propose two simple and effective parameter-efficient approaches for the new
task of mixed controllable summarization based on hard prompt tuning and soft
prefix tuning. Results and analysis demonstrate that hard prompt models yield
the best performance on all metrics and human evaluations. However,
mixed-attribute control is still challenging for summarization tasks. Our
dataset and code are available at https://github.com/psunlpgroup/MACSum.",https://github.com/psunlpgroup/MACSum,35424
52876021-920b-4db9-9387-b476a0e87c35,"Improving Human-AI Partnerships in Child Welfare: Understanding Worker Practices, Challenges, and Desires for Algorithmic Decision Support",0.980745,"AI-based decision support tools (ADS) are increasingly used to augment human
decision-making in high-stakes, social contexts. As public sector agencies
begin to adopt ADS, it is critical that we understand workers' experiences with
these systems in practice. In this paper, we present findings from a series of
interviews and contextual inquiries at a child welfare agency, to understand
how they currently make AI-assisted child maltreatment screening decisions.
Overall, we observe how workers' reliance upon the ADS is guided by (1) their
knowledge of rich, contextual information beyond what the AI model captures,
(2) their beliefs about the ADS's capabilities and limitations relative to
their own, (3) organizational pressures and incentives around the use of the
ADS, and (4) awareness of misalignments between algorithmic predictions and
their own decision-making objectives. Drawing upon these findings, we discuss
design implications towards supporting more effective human-AI decision-making.",None,-1
47dde95c-6cee-4202-9ac9-46e3fdcce8d1,Diffusion-SDF: Conditional Generative Modeling of Signed Distance Functions,0.996129,"Probabilistic diffusion models have achieved state-of-the-art results for
image synthesis, inpainting, and text-to-image tasks. However, they are still
in the early stages of generating complex 3D shapes. This work proposes
Diffusion-SDF, a generative model for shape completion, single-view
reconstruction, and reconstruction of real-scanned point clouds. We use neural
signed distance functions (SDFs) as our 3D representation to parameterize the
geometry of various signals (e.g., point clouds, 2D images) through neural
networks. Neural SDFs are implicit functions and diffusing them amounts to
learning the reversal of their neural network weights, which we solve using a
custom modulation module. Extensive experiments show that our method is capable
of both realistic unconditional generation and conditional generation from
partial inputs. This work expands the domain of diffusion models from learning
2D, explicit representations, to 3D, implicit representations.",https://light.princeton.edu/,-1
0b714eef-4372-407b-b9a9-a8652f856a71,TransLIST: A Transformer-Based Linguistically Informed Sanskrit Tokenizer,0.588846,"Sanskrit Word Segmentation (SWS) is essential in making digitized texts
available and in deploying downstream tasks. It is, however, non-trivial
because of the sandhi phenomenon that modifies the characters at the word
boundaries, and needs special treatment. Existing lexicon driven approaches for
SWS make use of Sanskrit Heritage Reader, a lexicon-driven shallow parser, to
generate the complete candidate solution space, over which various methods are
applied to produce the most valid solution. However, these approaches fail
while encountering out-of-vocabulary tokens. On the other hand, purely
engineering methods for SWS have made use of recent advances in deep learning,
but cannot make use of the latent word information on availability.
  To mitigate the shortcomings of both families of approaches, we propose
Transformer based Linguistically Informed Sanskrit Tokenizer (TransLIST)
consisting of (1) a module that encodes the character input along with
latent-word information, which takes into account the sandhi phenomenon
specific to SWS and is apt to work with partial or no candidate solutions, (2)
a novel soft-masked attention to prioritize potential candidate words and (3) a
novel path ranking algorithm to rectify the corrupted predictions. Experiments
on the benchmark datasets for SWS show that TransLIST outperforms the current
state-of-the-art system by an average 7.2 points absolute gain in terms of
perfect match (PM) metric. The codebase and datasets are publicly available at
https://github.com/rsingha108/TransLIST",https://github.com/rsingha108/TransLIST,-1
7c8ed9b8-0db1-40de-a623-5bfe51c54466,"Heroes, Villains, and Victims, and GPT-3: Automated Extraction of Character Roles Without Training Data",0.94628,"This paper shows how to use large-scale pre-trained language models to
extract character roles from narrative texts without training data. Queried
with a zero-shot question-answering prompt, GPT-3 can identify the hero,
villain, and victim in diverse domains: newspaper articles, movie plot
summaries, and political speeches.",None,-1
4f67c92f-0dc7-4d6c-8f22-d41729985569,Online Continual Learning for Embedded Devices,0.956598,"Real-time on-device continual learning is needed for new applications such as
home robots, user personalization on smartphones, and augmented/virtual reality
headsets. However, this setting poses unique challenges: embedded devices have
limited memory and compute capacity and conventional machine learning models
suffer from catastrophic forgetting when updated on non-stationary data
streams. While several online continual learning models have been developed,
their effectiveness for embedded applications has not been rigorously studied.
In this paper, we first identify criteria that online continual learners must
meet to effectively perform real-time, on-device learning. We then study the
efficacy of several online continual learning methods when used with mobile
neural networks. We measure their performance, memory usage, compute
requirements, and ability to generalize to out-of-domain inputs.",https://github.com/tyler-hayes/Embedded-CL,-1
a65d371d-e97c-40df-82f6-df7401b7bd85,Omnifont Persian OCR System Using Primitives,0.715982,"In this paper, we introduce a model-based omnifont Persian OCR system. The
system uses a set of 8 primitive elements as structural features for
recognition. First, the scanned document is preprocessed. After normalizing the
preprocessed image, text rows and sub-words are separated and then thinned.
After recognition of dots in sub-words, strokes are extracted and primitive
elements of each sub-word are recognized using the strokes. Finally, the
primitives are compared with a predefined set of character identification
vectors in order to identify sub-word characters. The separation and
recognition steps of the system are concurrent, eliminating unavoidable errors
of independent separation of letters. The system has been tested on documents
with 14 standard Persian fonts in 6 sizes. The achieved precision is 97.06%.",None,-1
2db12a48-7410-4767-aa1b-eeb25ac95c30,Graph Neural Networks and Representation Embedding for Table Extraction in PDF Documents,0.229122,"Tables are widely used in several types of documents since they can bring
important information in a structured way. In scientific papers, tables can sum
up novel discoveries and summarize experimental results, making the research
comparable and easily understandable by scholars. Several methods perform table
analysis working on document images, losing useful information during the
conversion from the PDF files since OCR tools can be prone to recognition
errors, in particular for text inside tables. The main contribution of this
work is to tackle the problem of table extraction, exploiting Graph Neural
Networks. Node features are enriched with suitably designed representation
embeddings. These representations help to better distinguish not only tables
from the other parts of the paper, but also table cells from table headers. We
experimentally evaluated the proposed approach on a new dataset obtained by
merging the information provided in the PubLayNet and PubTables-1M datasets.",None,2625
982f8927-b36a-46a5-808d-e91191071e85,Visual Attention Emerges from Recurrent Sparse Reconstruction,0.091522,"Visual attention helps achieve robust perception under noise, corruption, and
distribution shifts in human vision, which are areas where modern neural
networks still fall short. We present VARS, Visual Attention from Recurrent
Sparse reconstruction, a new attention formulation built on two prominent
features of the human visual attention mechanism: recurrency and sparsity.
Related features are grouped together via recurrent connections between
neurons, with salient objects emerging via sparse regularization. VARS adopts
an attractor network with recurrent connections that converges toward a stable
pattern over time. Network layers are represented as ordinary differential
equations (ODEs), formulating attention as a recurrent attractor network that
equivalently optimizes the sparse reconstruction of input using a dictionary of
""templates"" encoding underlying patterns of data. We show that self-attention
is a special case of VARS with a single-step optimization and no sparsity
constraint. VARS can be readily used as a replacement for self-attention in
popular vision transformers, consistently improving their robustness across
various benchmarks. Code is released on GitHub (https://github.com/bfshi/VARS).",https://github.com/bfshi/VARS,-1
f7bf7dbc-3029-40ca-a654-966068c77df3,Local Directional Gradient Pattern: A Local Descriptor for Face Recognition,0.915713,"In this paper a local pattern descriptor in high order derivative space is
proposed for face recognition. The proposed local directional gradient pattern
(LDGP) is a 1D local micropattern computed by encoding the relationships
between the higher order derivatives of the reference pixel in four distinct
directions. The proposed descriptor identifies the relationship between the
high order derivatives of the referenced pixel in four different directions to
compute the micropattern which corresponds to the local feature. Proposed
descriptor considerably reduces the length of the micropattern which
consequently reduces the extraction time and matching time while maintaining
the recognition rate. Results of the extensive experiments conducted on
benchmark databases AT&T, Extended Yale B and CMU-PIE show that the proposed
descriptor significantly reduces the extraction as well as matching time while
the recognition rate is almost similar to the existing state of the art
methods.",None,-1
fe13e4b7-7a2e-4185-be21-8cbdae7c23d7,"Learning When to Say ""I Don't Know""",0.20728,"We propose a new Reject Option Classification technique to identify and
remove regions of uncertainty in the decision space for a given neural
classifier and dataset. Such existing formulations employ a learned rejection
(remove)/selection (keep) function and require either a known cost for
rejecting examples or strong constraints on the accuracy or coverage of the
selected examples. We consider an alternative formulation by instead analyzing
the complementary reject region and employing a validation set to learn
per-class softmax thresholds. The goal is to maximize the accuracy of the
selected examples subject to a natural randomness allowance on the rejected
examples (rejecting more incorrect than correct predictions). We provide
results showing the benefits of the proposed method over na\""ively thresholding
calibrated/uncalibrated softmax scores with 2-D points, imagery, and text
classification datasets using state-of-the-art pretrained models. Source code
is available at https://github.com/osu-cvl/learning-idk.",https://github.com/osu-cvl/learning-idk,-1
7f509986-dcd2-421a-988a-7da85697ebc1,MetaASSIST: Robust Dialogue State Tracking with Meta Learning,0.22356,"Existing dialogue datasets contain lots of noise in their state annotations.
Such noise can hurt model training and ultimately lead to poor generalization
performance. A general framework named ASSIST has recently been proposed to
train robust dialogue state tracking (DST) models. It introduces an auxiliary
model to generate pseudo labels for the noisy training set. These pseudo labels
are combined with vanilla labels by a common fixed weighting parameter to train
the primary DST model. Notwithstanding the improvements of ASSIST on DST,
tuning the weighting parameter is challenging. Moreover, a single parameter
shared by all slots and all instances may be suboptimal. To overcome these
limitations, we propose a meta learning-based framework MetaASSIST to
adaptively learn the weighting parameter. Specifically, we propose three
schemes with varying degrees of flexibility, ranging from slot-wise to both
slot-wise and instance-wise, to convert the weighting parameter into learnable
functions. These functions are trained in a meta-learning manner by taking the
validation set as meta data. Experimental results demonstrate that all three
schemes can achieve competitive performance. Most impressively, we achieve a
state-of-the-art joint goal accuracy of 80.10% on MultiWOZ 2.4.",https://github.com/smartyfh/,-1
fd25600f-8c7f-44ff-a678-b3bcef6a6238,Learning to Imitate Object Interactions from Internet Videos,0.693131,"We study the problem of imitating object interactions from Internet videos.
This requires understanding the hand-object interactions in 4D, spatially in 3D
and over time, which is challenging due to mutual hand-object occlusions. In
this paper we make two main contributions: (1) a novel reconstruction technique
RHOV (Reconstructing Hands and Objects from Videos), which reconstructs 4D
trajectories of both the hand and the object using 2D image cues and temporal
smoothness constraints; (2) a system for imitating object interactions in a
physics simulator with reinforcement learning. We apply our reconstruction
technique to 100 challenging Internet videos. We further show that we can
successfully imitate a range of different object interactions in a physics
simulator. Our object-centric approach is not limited to human-like
end-effectors and can learn to imitate object interactions using different
embodiments, like a robotic arm with a parallel jaw gripper.",None,-1
53e80dd4-074f-496c-b5e1-1facedd09039,How stable are Transferability Metrics evaluations?,0.709996,"Transferability metrics is a maturing field with increasing interest, which
aims at providing heuristics for selecting the most suitable source models to
transfer to a given target dataset, without fine-tuning them all. However,
existing works rely on custom experimental setups which differ across papers,
leading to inconsistent conclusions about which transferability metrics work
best. In this paper we conduct a large-scale study by systematically
constructing a broad range of 715k experimental setup variations. We discover
that even small variations to an experimental setup lead to different
conclusions about the superiority of a transferability metric over another.
Then we propose better evaluations by aggregating across many experiments,
enabling to reach more stable conclusions. As a result, we reveal the
superiority of LogME at selecting good source datasets to transfer from in a
semantic segmentation scenario, NLEEP at selecting good source architectures in
an image classification scenario, and GBC at determining which target task
benefits most from a given source model. Yet, no single transferability metric
works best in all scenarios.",https://github.com/google-research/google-research/tree/master/stable transfer,-1
311d07c0-c14d-4b41-a70a-4eff9a28d8ec,Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations,0.656546,"Although large language models can be prompted for both zero- and few-shot
learning, performance drops significantly when no demonstrations are available.
In this paper, we introduce Z-ICL, a new zero-shot method that closes the gap
by constructing pseudo-demonstrations for a given test input using a raw text
corpus. Concretely, pseudo-demonstrations are constructed by (1) finding the
nearest neighbors to the test input from the corpus and pairing them with
random task labels, and (2) applying a set of techniques to reduce the amount
of direct copying the model does from the resulting demonstrations. Evaluation
on nine classification datasets shows that Z-ICL outperforms previous zero-shot
methods by a significant margin, and is on par with in-context learning with
labeled training data in the few-shot setting. Overall, Z-ICL provides a
significantly higher estimate of the zero-shot performance levels of a model,
and supports future efforts to develop better pseudo-demonstrations that
further improve zero-shot results.",https://github.com/alrope123/z-icl,-1
668f3c13-8606-4e2d-b167-87129a1537e9,Analysis of Smooth Pursuit Assessment in Virtual Reality and Concussion Detection using BiLSTM,0.0183219,"The sport-related concussion (SRC) battery relies heavily upon subjective
symptom reporting in order to determine the diagnosis of a concussion.
Unfortunately, athletes with SRC may return-to-play (RTP) too soon if they are
untruthful of their symptoms. It is critical to provide accurate assessments
that can overcome underreporting to prevent further injury. To lower the risk
of injury, a more robust and precise method for detecting concussion is needed
to produce reliable and objective results. In this paper, we propose a novel
approach to detect SRC using long short-term memory (LSTM) recurrent neural
network (RNN) architectures from oculomotor data. In particular, we propose a
new error metric that incorporates mean squared error in different proportions.
The experimental results on the smooth pursuit test of the VR-VOMS dataset
suggest that the proposed approach can predict concussion symptoms with higher
accuracy compared to symptom provocation on the vestibular ocular motor
screening (VOMS).",None,-1
6687be60-089c-47e2-9f56-0a55eac4d225,Meta-Learning Regrasping Strategies for Physical-Agnostic Objects,0.414441,"Grasping inhomogeneous objects in real-world applications remains a
challenging task due to the unknown physical properties such as mass
distribution and coefficient of friction. In this study, we propose a
meta-learning algorithm called ConDex, which incorporates Conditional Neural
Processes (CNP) with DexNet-2.0 to autonomously discern the underlying physical
properties of objects using depth images. ConDex efficiently acquires physical
embeddings from limited trials, enabling precise grasping point estimation.
Furthermore, ConDex is capable of updating the predicted grasping quality
iteratively from new trials in an online fashion. To the best of our knowledge,
we are the first who generate two object datasets focusing on inhomogeneous
physical properties with varying mass distributions and friction coefficients.
Extensive evaluations in simulation demonstrate ConDex's superior performance
over DexNet-2.0 and existing meta-learning-based grasping pipelines.
Furthermore, ConDex shows robust generalization to previously unseen real-world
objects despite training solely in the simulation. The synthetic and real-world
datasets will be published as well.",None,-1
5c89214d-d45b-41dd-84a4-c6363d086f27,Estimating Soft Labels for Out-of-Domain Intent Detection,0.909282,"Out-of-Domain (OOD) intent detection is important for practical dialog
systems. To alleviate the issue of lacking OOD training samples, some works
propose synthesizing pseudo OOD samples and directly assigning one-hot OOD
labels to these pseudo samples. However, these one-hot labels introduce noises
to the training process because some hard pseudo OOD samples may coincide with
In-Domain (IND) intents. In this paper, we propose an adaptive soft pseudo
labeling (ASoul) method that can estimate soft labels for pseudo OOD samples
when training OOD detectors. Semantic connections between pseudo OOD samples
and IND intents are captured using an embedding graph. A co-training framework
is further introduced to produce resulting soft labels following the smoothness
assumption, i.e., close samples are likely to have similar labels. Extensive
experiments on three benchmark datasets show that ASoul consistently improves
the OOD detection performance and outperforms various competitive baselines.",None,-1
bc48f9a2-c6d7-4551-9116-19a118ad9532,Multi-View Document Representation Learning for Open-Domain Dense Retrieval,0.783766,"Dense retrieval has achieved impressive advances in first-stage retrieval
from a large-scale document collection, which is built on bi-encoder
architecture to produce single vector representation of query and document.
However, a document can usually answer multiple potential queries from
different views. So the single vector representation of a document is hard to
match with multi-view queries, and faces a semantic mismatch problem. This
paper proposes a multi-view document representation learning framework, aiming
to produce multi-view embeddings to represent documents and enforce them to
align with different queries. First, we propose a simple yet effective method
of generating multiple embeddings through viewers. Second, to prevent
multi-view embeddings from collapsing to the same one, we further propose a
global-local loss with annealed temperature to encourage the multiple viewers
to better align with different potential queries. Experiments show our method
outperforms recent works and achieves state-of-the-art results.",None,-1
a8c7c584-547b-48db-9c7a-ede85eb41525,A Multi-label Continual Learning Framework to Scale Deep Learning Approaches for Packaging Equipment Monitoring,0.336297,"Continual Learning aims to learn from a stream of tasks, being able to
remember at the same time both new and old tasks. While many approaches were
proposed for single-class classification, multi-label classification in the
continual scenario remains a challenging problem. For the first time, we study
multi-label classification in the Domain Incremental Learning scenario.
Moreover, we propose an efficient approach that has a logarithmic complexity
with regard to the number of tasks, and can be applied also in the Class
Incremental Learning scenario. We validate our approach on a real-world
multi-label Alarm Forecasting problem from the packaging industry. For the sake
of reproducibility, the dataset and the code used for the experiments are
publicly available.",https://github.com/dallepezze/bat-ocdm,-1
81db2284-6160-45ed-91c2-6b1b8caa3f86,Computing Programs for Generalized Planning as Heuristic Search,0.365877,"Although heuristic search is one of the most successful approaches to
classical planning, this planning paradigm does not apply straightforwardly to
Generalized Planning (GP). This paper adapts the planning as heuristic search
paradigm to the particularities of GP, and presents the first native heuristic
search approach to GP. First, the paper defines a program-based solution space
for GP that is independent of the number of planning instances in a GP problem,
and the size of these instances. Second, the paper defines the BFGP algorithm
for GP, that implements a best-first search in our program-based solution
space, and that is guided by different evaluation and heuristic functions.",None,-1
87db8b62-1fba-47d8-b005-9bac6a875660,RDU: A Region-based Approach to Form-style Document Understanding,0.105833,"Key Information Extraction (KIE) is aimed at extracting structured
information (e.g. key-value pairs) from form-style documents (e.g. invoices),
which makes an important step towards intelligent document understanding.
Previous approaches generally tackle KIE by sequence tagging, which faces
difficulty to process non-flatten sequences, especially for table-text mixed
documents. These approaches also suffer from the trouble of pre-defining a
fixed set of labels for each type of documents, as well as the label imbalance
issue. In this work, we assume Optical Character Recognition (OCR) has been
applied to input documents, and reformulate the KIE task as a region prediction
problem in the two-dimensional (2D) space given a target field. Following this
new setup, we develop a new KIE model named Region-based Document Understanding
(RDU) that takes as input the text content and corresponding coordinates of a
document, and tries to predict the result by localizing a bounding-box-like
region. Our RDU first applies a layout-aware BERT equipped with a soft layout
attention masking and bias mechanism to incorporate layout information into the
representations. Then, a list of candidate regions is generated from the
representations via a Region Proposal Module inspired by computer vision models
widely applied for object detection. Finally, a Region Categorization Module
and a Region Selection Module are adopted to judge whether a proposed region is
valid and select the one with the largest probability from all proposed regions
respectively. Experiments on four types of form-style documents show that our
proposed method can achieve impressive results. In addition, our RDU model can
be trained with different document types seamlessly, which is especially
helpful over low-resource documents.",None,-1
0d8f4b79-9e44-4046-8fb2-9f2ee09f426d,A Simple Hash-Based Early Exiting Approach For Language Understanding and Generation,0.610134,"Early exiting allows instances to exit at different layers according to the
estimation of difficulty. Previous works usually adopt heuristic metrics such
as the entropy of internal outputs to measure instance difficulty, which
suffers from generalization and threshold-tuning. In contrast, learning to
exit, or learning to predict instance difficulty is a more appealing way.
Though some effort has been devoted to employing such ""learn-to-exit"" modules,
it is still unknown whether and how well the instance difficulty can be
learned. As a response, we first conduct experiments on the learnability of
instance difficulty, which demonstrates that modern neural models perform
poorly on predicting instance difficulty. Based on this observation, we propose
a simple-yet-effective Hash-based Early Exiting approach (HashEE) that replaces
the learn-to-exit modules with hash functions to assign each token to a fixed
exiting layer. Different from previous methods, HashEE requires no internal
classifiers nor extra parameters, and therefore is more efficient. Experimental
results on classification, regression, and generation tasks demonstrate that
HashEE can achieve higher performance with fewer FLOPs and inference time
compared with previous state-of-the-art early exiting methods.",https://github.com/txsun1997/HashEE,21857
a1656c56-9ffb-4e4f-a9db-4b2dc9fc325b,Overview of Test Coverage Criteria for Test Case Generation from Finite State Machines Modelled as Directed Graphs,0.210364,"Test Coverage criteria are an essential concept for test engineers when
generating the test cases from a System Under Test model. They are routinely
used in test case generation for user interfaces, middleware, and back-end
system parts for software, electronics, or Internet of Things (IoT) systems.
Test Coverage criteria define the number of actions or combinations by which a
system is tested, informally determining a potential ""strength"" of a test set.
As no previous study summarized all commonly used test coverage criteria for
Finite State Machines and comprehensively discussed them regarding their
subsumption, equivalence, or non-comparability, this paper provides this
overview. In this study, 14 most common test coverage criteria and seven of
their synonyms for Finite State Machines defined via a directed graph are
summarized and compared. The results give researchers and industry testing
engineers a helpful overview when setting a software-based or IoT system test
strategy.",None,-1
6f3b4ae3-6688-4205-a681-495d14fbc8aa,TANGO: Text-driven Photorealistic and Robust 3D Stylization via Lighting Decomposition,0.531379,"Creation of 3D content by stylization is a promising yet challenging problem
in computer vision and graphics research. In this work, we focus on stylizing
photorealistic appearance renderings of a given surface mesh of arbitrary
topology. Motivated by the recent surge of cross-modal supervision of the
Contrastive Language-Image Pre-training (CLIP) model, we propose TANGO, which
transfers the appearance style of a given 3D shape according to a text prompt
in a photorealistic manner. Technically, we propose to disentangle the
appearance style as the spatially varying bidirectional reflectance
distribution function, the local geometric variation, and the lighting
condition, which are jointly optimized, via supervision of the CLIP loss, by a
spherical Gaussians based differentiable renderer. As such, TANGO enables
photorealistic 3D style transfer by automatically predicting reflectance
effects even for bare, low-quality meshes, without training on a task-specific
dataset. Extensive experiments show that TANGO outperforms existing methods of
text-driven 3D style transfer in terms of photorealistic quality, consistency
of 3D geometry, and robustness when stylizing low-quality meshes. Our codes and
results are available at our project webpage https://cyw-3d.github.io/tango/.",https://cyw-3d.github.io/tango,-1
832c1732-0950-493a-a613-560eacbedbac,FlowFormer: A Transformer Architecture for Optical Flow,0.999999,"We introduce optical Flow transFormer, dubbed as FlowFormer, a
transformer-based neural network architecture for learning optical flow.
FlowFormer tokenizes the 4D cost volume built from an image pair, encodes the
cost tokens into a cost memory with alternate-group transformer (AGT) layers in
a novel latent space, and decodes the cost memory via a recurrent transformer
decoder with dynamic positional cost queries. On the Sintel benchmark,
FlowFormer achieves 1.159 and 2.088 average end-point-error (AEPE) on the clean
and final pass, a 16.5% and 15.5% error reduction from the best published
result (1.388 and 2.47). Besides, FlowFormer also achieves strong
generalization performance. Without being trained on Sintel, FlowFormer
achieves 1.01 AEPE on the clean pass of Sintel training set, outperforming the
best published result (1.29) by 21.7%.",None,-1
a5d8caae-2b24-4197-8b16-b4cef8532dd1,Localized Vision-Language Matching for Open-vocabulary Object Detection,0.614434,"In this work, we propose an open-vocabulary object detection method that,
based on image-caption pairs, learns to detect novel object classes along with
a given set of known classes. It is a two-stage training approach that first
uses a location-guided image-caption matching technique to learn class labels
for both novel and known classes in a weakly-supervised manner and second
specializes the model for the object detection task using known class
annotations. We show that a simple language model fits better than a large
contextualized language model for detecting novel objects. Moreover, we
introduce a consistency-regularization technique to better exploit
image-caption pair information. Our method compares favorably to existing
open-vocabulary detection approaches while being data-efficient. Source code is
available at https://github.com/lmb-freiburg/locov .",https://github.com/lmb-freiburg/locov,-1
2b3726f0-7b0e-4e91-85b7-332e24e504a1,Improving Automatic Speech Recognition for Non-Native English with Transfer Learning and Language Model Decoding,0.518345,"ASR systems designed for native English (L1) usually underperform on
non-native English (L2). To address this performance gap, \textbf{(i)} we
extend our previous work to investigate fine-tuning of a pre-trained wav2vec
2.0 model \cite{baevski2020wav2vec,xu2021self} under a rich set of L1 and L2
training conditions. We further \textbf{(ii)} incorporate language model
decoding in the ASR system, along with the fine-tuning method. Quantifying
gains acquired from each of these two approaches separately and an error
analysis allows us to identify different sources of improvement within our
models. We find that while the large self-trained wav2vec 2.0 may be
internalizing sufficient decoding knowledge for clean L1 speech
\cite{xu2021self}, this does not hold for L2 speech and accounts for the
utility of employing language model decoding on L2 data.",https://github.com/UBC-NLP/L2ASR,-1
e08cec6c-62c7-4416-9f59-7e01d91964bf,Label Semantics for Few Shot Named Entity Recognition,0.969235,"We study the problem of few shot learning for named entity recognition.
Specifically, we leverage the semantic information in the names of the labels
as a way of giving the model additional signal and enriched priors. We propose
a neural architecture that consists of two BERT encoders, one to encode the
document and its tokens and another one to encode each of the labels in natural
language format. Our model learns to match the representations of named
entities computed by the first encoder with label representations computed by
the second encoder. The label semantics signal is shown to support improved
state-of-the-art results in multiple few shot NER benchmarks and on-par
performance in standard benchmarks. Our model is especially effective in low
resource settings.",None,-1
efd69a82-4f4d-4486-8c9f-684344001294,Unsupervised Homography Estimation with Coplanarity-Aware GAN,0.473362,"Estimating homography from an image pair is a fundamental problem in image
alignment. Unsupervised learning methods have received increasing attention in
this field due to their promising performance and label-free training. However,
existing methods do not explicitly consider the problem of plane-induced
parallax, which will make the predicted homography compromised on multiple
planes. In this work, we propose a novel method HomoGAN to guide unsupervised
homography estimation to focus on the dominant plane. First, a multi-scale
transformer network is designed to predict homography from the feature pyramids
of input images in a coarse-to-fine fashion. Moreover, we propose an
unsupervised GAN to impose coplanarity constraint on the predicted homography,
which is realized by using a generator to predict a mask of aligned regions,
and then a discriminator to check if two masked feature maps are induced by a
single homography. To validate the effectiveness of HomoGAN and its components,
we conduct extensive experiments on a large-scale dataset, and the results show
that our matching error is 22% lower than the previous SOTA method. Code is
available at https://github.com/megvii-research/HomoGAN.",https://github.com/megvii-research/HomoGAN,-1
09083b19-34bf-4db9-8f21-b21134e71225,Fine-Grained Object Classification via Self-Supervised Pose Alignment,0.823612,"Semantic patterns of fine-grained objects are determined by subtle appearance
difference of local parts, which thus inspires a number of part-based methods.
However, due to uncontrollable object poses in images, distinctive details
carried by local regions can be spatially distributed or even self-occluded,
leading to a large variation on object representation. For discounting pose
variations, this paper proposes to learn a novel graph based object
representation to reveal a global configuration of local parts for
self-supervised pose alignment across classes, which is employed as an
auxiliary feature regularization on a deep representation learning
network.Moreover, a coarse-to-fine supervision together with the proposed
pose-insensitive constraint on shallow-to-deep sub-networks encourages
discriminative features in a curriculum learning manner. We evaluate our method
on three popular fine-grained object classification benchmarks, consistently
achieving the state-of-the-art performance. Source codes are available at
https://github.com/yangxh11/P2P-Net.",https://github.com/yangxh11/P2P-Net,15319
57fd8608-eb53-408a-80dd-35851c654e2e,UnCommonSense: Informative Negative Knowledge about Everyday Concepts,0.732947,"Commonsense knowledge about everyday concepts is an important asset for AI
applications, such as question answering and chatbots. Recently, we have seen
an increasing interest in the construction of structured commonsense knowledge
bases (CSKBs). An important part of human commonsense is about properties that
do not apply to concepts, yet existing CSKBs only store positive statements.
Moreover, since CSKBs operate under the open-world assumption, absent
statements are considered to have unknown truth rather than being invalid. This
paper presents the UNCOMMONSENSE framework for materializing informative
negative commonsense statements. Given a target concept, comparable concepts
are identified in the CSKB, for which a local closed-world assumption is
postulated. This way, positive statements about comparable concepts that are
absent for the target concept become seeds for negative statement candidates.
The large set of candidates is then scrutinized, pruned and ranked by
informativeness. Intrinsic and extrinsic evaluations show that our method
significantly outperforms the state-of-the-art. A large dataset of informative
negations is released as a resource for future research.",https://github.com/tsafavi/NegatER,-1
746769e9-8317-47a6-aaa9-fc85e1d53fc0,Scalar is Not Enough: Vectorization-based Unbiased Learning to Rank,0.363983,"Unbiased learning to rank (ULTR) aims to train an unbiased ranking model from
biased user click logs. Most of the current ULTR methods are based on the
examination hypothesis (EH), which assumes that the click probability can be
factorized into two scalar functions, one related to ranking features and the
other related to bias factors. Unfortunately, the interactions among features,
bias factors and clicks are complicated in practice, and usually cannot be
factorized in this independent way. Fitting click data with EH could lead to
model misspecification and bring the approximation error.
  In this paper, we propose a vector-based EH and formulate the click
probability as a dot product of two vector functions. This solution is complete
due to its universality in fitting arbitrary click functions. Based on it, we
propose a novel model named Vectorization to adaptively learn the relevance
embeddings and sort documents by projecting embeddings onto a base vector.
Extensive experiments show that our method significantly outperforms the
state-of-the-art ULTR methods on complex real clicks as well as simple
simulated clicks.",https://github.com/Keytoyze/Vectorization,-1
54debd43-e7b0-47ce-b287-13c4c4737ffe,OSSGAN: Open-Set Semi-Supervised Image Generation,0.20587,"We introduce a challenging training scheme of conditional GANs, called
open-set semi-supervised image generation, where the training dataset consists
of two parts: (i) labeled data and (ii) unlabeled data with samples belonging
to one of the labeled data classes, namely, a closed-set, and samples not
belonging to any of the labeled data classes, namely, an open-set. Unlike the
existing semi-supervised image generation task, where unlabeled data only
contain closed-set samples, our task is more general and lowers the data
collection cost in practice by allowing open-set samples to appear. Thanks to
entropy regularization, the classifier that is trained on labeled data is able
to quantify sample-wise importance to the training of cGAN as confidence,
allowing us to use all samples in unlabeled data. We design OSSGAN, which
provides decision clues to the discriminator on the basis of whether an
unlabeled image belongs to one or none of the classes of interest, smoothly
integrating labeled and unlabeled data during training. The results of
experiments on Tiny ImageNet and ImageNet show notable improvements over
supervised BigGAN and semi-supervised methods. Our code is available at
https://github.com/raven38/OSSGAN.",https://github.com/raven38/OSSGAN,-1
00a54375-9e35-4244-8e4f-751aae56de85,Continual Feature Selection: Spurious Features in Continual Learning,0.176659,"Continual Learning (CL) is the research field addressing learning without
forgetting when the data distribution is not static. This paper studies
spurious features' influence on continual learning algorithms. We show that
continual learning algorithms solve tasks by selecting features that are not
generalizable. Our experiments highlight that continual learning algorithms
face two related problems: (1) spurious features and (2) local spurious
features. The first one is due to a covariate shift between training and
testing data, while the second is due to the limited access to data at each
training step. We study (1) through a consistent set of continual learning
experiments varying spurious correlation amount and data distribution support.
We show that (2) is a major cause of performance decrease in continual learning
along with catastrophic forgetting. This paper presents a different way of
understanding performance decrease in continual learning by highlighting the
influence of (local) spurious features in algorithms capabilities.",https://github.com/facebookresearch/DomainBed,-1
be2920bb-e9d5-4e1d-9a63-91573c2f1b7b,RF-Next: Efficient Receptive Field Search for Convolutional Neural Networks,0.729292,"Temporal/spatial receptive fields of models play an important role in
sequential/spatial tasks. Large receptive fields facilitate long-term
relations, while small receptive fields help to capture the local details.
Existing methods construct models with hand-designed receptive fields in
layers. Can we effectively search for receptive field combinations to replace
hand-designed patterns? To answer this question, we propose to find better
receptive field combinations through a global-to-local search scheme. Our
search scheme exploits both global search to find the coarse combinations and
local search to get the refined receptive field combinations further. The
global search finds possible coarse combinations other than human-designed
patterns. On top of the global search, we propose an expectation-guided
iterative local search scheme to refine combinations effectively. Our RF-Next
models, plugging receptive field search to various models, boost the
performance on many tasks, e.g., temporal action segmentation, object
detection, instance segmentation, and speech synthesis. The source code is
publicly available on http://mmcheng.net/rfnext.",http://mmcheng.net/rfnext,-1
3412999f-6dea-4e7c-b80c-c681f2ee2f51,Minimising Biasing Word Errors for Contextual ASR with the Tree-Constrained Pointer Generator,0.524051,"Contextual knowledge is essential for reducing speech recognition errors on
high-valued long-tail words. This paper proposes a novel tree-constrained
pointer generator (TCPGen) component that enables end-to-end ASR models to bias
towards a list of long-tail words obtained using external contextual
information. With only a small overhead in memory use and computation cost,
TCPGen can structure thousands of biasing words efficiently into a symbolic
prefix-tree and creates a neural shortcut between the tree and the final ASR
output to facilitate the recognition of the biasing words. To enhance TCPGen,
we further propose a novel minimum biasing word error (MBWE) loss that directly
optimises biasing word errors during training, along with a biasing-word-driven
language model discounting (BLMD) method during the test. All contextual ASR
systems were evaluated on the public Librispeech audiobook corpus and the data
from the dialogue state tracking challenges (DSTC) with the biasing lists
extracted from the dialogue-system ontology. Consistent word error rate (WER)
reductions were achieved with TCPGen, which were particularly significant on
the biasing words with around 40\% relative reductions in the recognition error
rates. MBWE and BLMD further improved the effectiveness of TCPGen and achieved
more significant WER reductions on the biasing words. TCPGen also achieved
zero-shot learning of words not in the audio training set with large WER
reductions on the out-of-vocabulary words in the biasing list.",None,-1
aa427bf2-716d-467f-9597-95b4243f7851,FlowEval: A Consensus-Based Dialogue Evaluation Framework Using Segment Act Flows,0.0847335,"Despite recent progress in open-domain dialogue evaluation, how to develop
automatic metrics remains an open problem. We explore the potential of dialogue
evaluation featuring dialog act information, which was hardly explicitly
modeled in previous methods. However, defined at the utterance level in
general, dialog act is of coarse granularity, as an utterance can contain
multiple segments possessing different functions. Hence, we propose segment
act, an extension of dialog act from utterance level to segment level, and
crowdsource a large-scale dataset for it. To utilize segment act flows,
sequences of segment acts, for evaluation, we develop the first consensus-based
dialogue evaluation framework, FlowEval. This framework provides a
reference-free approach for dialog evaluation by finding pseudo-references.
Extensive experiments against strong baselines on three benchmark datasets
demonstrate the effectiveness and other desirable characteristics of our
FlowEval, pointing out a potential path for better dialogue evaluation.",None,-1
905f157f-3672-4f4f-a244-eefadfc45657,Disentangling Visual Embeddings for Attributes and Objects,0.658334,"We study the problem of compositional zero-shot learning for object-attribute
recognition. Prior works use visual features extracted with a backbone network,
pre-trained for object classification and thus do not capture the subtly
distinct features associated with attributes. To overcome this challenge, these
studies employ supervision from the linguistic space, and use pre-trained word
embeddings to better separate and compose attribute-object pairs for
recognition. Analogous to linguistic embedding space, which already has unique
and agnostic embeddings for object and attribute, we shift the focus back to
the visual space and propose a novel architecture that can disentangle
attribute and object features in the visual space. We use visual decomposed
features to hallucinate embeddings that are representative for the seen and
novel compositions to better regularize the learning of our model. Extensive
experiments show that our method outperforms existing work with significant
margin on three datasets: MIT-States, UT-Zappos, and a new benchmark created
based on VAW. The code, models, and dataset splits are publicly available at
https://github.com/nirat1606/OADis.",https://github.com/nirat1606/OADis,-1
a596a2cc-b165-41cb-8a40-6537264a26c6,Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control,0.298995,"Artificial Intelligence (AI) is one of the most transformative technologies
of the 21st century. The extent and scope of future AI capabilities remain a
key uncertainty, with widespread disagreement on timelines and potential
impacts. As nations and technology companies race toward greater complexity and
autonomy in AI systems, there are concerns over the extent of integration and
oversight of opaque AI decision processes. This is especially true in the
subfield of machine learning (ML), where systems learn to optimize objectives
without human assistance. Objectives can be imperfectly specified or executed
in an unexpected or potentially harmful way. This becomes more concerning as
systems increase in power and autonomy, where an abrupt capability jump could
result in unexpected shifts in power dynamics or even catastrophic failures.
This study presents a hierarchical complex systems framework to model AI risk
and provide a template for alternative futures analysis. Survey data were
collected from domain experts in the public and private sectors to classify AI
impact and likelihood. The results show increased uncertainty over the powerful
AI agent scenario, confidence in multiagent environments, and increased concern
over AI alignment failures and influence-seeking behavior.",None,-1
9598a803-0bdc-44f8-ac43-89e9d8f911a0,TSM: Measuring the Enticement of Honeyfiles with Natural Language Processing,0.406512,"Honeyfile deployment is a useful breach detection method in cyber deception
that can also inform defenders about the intent and interests of intruders and
malicious insiders. A key property of a honeyfile, enticement, is the extent to
which the file can attract an intruder to interact with it. We introduce a
novel metric, Topic Semantic Matching (TSM), which uses topic modelling to
represent files in the repository and semantic matching in an embedding vector
space to compare honeyfile text and topic words robustly. We also present a
honeyfile corpus created with different Natural Language Processing (NLP)
methods. Experiments show that TSM is effective in inter-corpus comparisons and
is a promising tool to measure the enticement of honeyfiles. TSM is the first
measure to use NLP techniques to quantify the enticement of honeyfile content
that compares the essential topical content of local contexts to honeyfiles and
is robust to paraphrasing.",https://github.com/RoelTim/tsm-honeyfile-nlp-enticement,-1
19f9a8f2-418d-416c-bf70-53ac808867d5,Deep Surrogate Assisted Generation of Environments,0.795734,"Recent progress in reinforcement learning (RL) has started producing
generally capable agents that can solve a distribution of complex environments.
These agents are typically tested on fixed, human-authored environments. On the
other hand, quality diversity (QD) optimization has been proven to be an
effective component of environment generation algorithms, which can generate
collections of high-quality environments that are diverse in the resulting
agent behaviors. However, these algorithms require potentially expensive
simulations of agents on newly generated environments. We propose Deep
Surrogate Assisted Generation of Environments (DSAGE), a sample-efficient QD
environment generation algorithm that maintains a deep surrogate model for
predicting agent behaviors in new environments. Results in two benchmark
domains show that DSAGE significantly outperforms existing QD environment
generation algorithms in discovering collections of environments that elicit
diverse behaviors of a state-of-the-art RL agent and a planning agent. Our
source code and videos are available at https://dsagepaper.github.io/.",https://dsagepaper.github.io/,3297
a2f2fc30-06f8-4253-9051-54a8ac19d71f,Few-shot Query-Focused Summarization with Prefix-Merging,0.375631,"Query-focused summarization has been considered as an important extension for
text summarization. It aims to generate a concise highlight for a given query.
Different from text summarization, query-focused summarization has long been
plagued by the problem of lacking high-quality large-scale datasets. In this
paper, we investigate the idea that whether we can integrate and transfer the
knowledge of text summarization and question answering to assist the few-shot
learning in query-focused summarization. Here, we propose prefix-merging, a
prefix-based pretraining strategy for few-shot learning in query-focused
summarization. Drawn inspiration from prefix-tuning, we are allowed to
integrate the task knowledge from text summarization and question answering
into a properly designed prefix and apply the merged prefix to query-focused
summarization. With only a small amount of trainable parameters, prefix-merging
outperforms fine-tuning on query-focused summarization. We further discuss the
influence of different prefix designs and propose a visualized explanation for
how prefix-merging works.",None,-1
92bb712c-441b-4d64-b4d1-bd3979751234,Faces: AI Blitz XIII Solutions,0.176362,"AI Blitz XIII Faces challenge hosted on www.aicrowd.com platform consisted of
five problems: Sentiment Classification, Age Prediction, Mask Prediction, Face
Recognition, and Face De-Blurring. Our team GLaDOS took second place. Here we
present our solutions and results. Code implementation:
https://github.com/ndrwmlnk/ai-blitz-xiii",https://github.com/ndrwmlnk/ai-blitz-xiii,-1
7d71e67c-fde9-4e61-a9dc-03f33b601922,On Adversarial Robustness of Deep Image Deblurring,0.534022,"Recent approaches employ deep learning-based solutions for the recovery of a
sharp image from its blurry observation. This paper introduces adversarial
attacks against deep learning-based image deblurring methods and evaluates the
robustness of these neural networks to untargeted and targeted attacks. We
demonstrate that imperceptible distortion can significantly degrade the
performance of state-of-the-art deblurring networks, even producing drastically
different content in the output, indicating the strong need to include
adversarially robust training not only in classification but also for image
recovery.",None,-1
4a10cc68-1367-4844-915e-e3ff9e493094,Advanced Conditional Variational Autoencoders (A-CVAE): Towards interpreting open-domain conversation generation via disentangling latent feature representation,0.0115328,"Currently end-to-end deep learning based open-domain dialogue systems remain
black box models, making it easy to generate irrelevant contents with
data-driven models. Specifically, latent variables are highly entangled with
different semantics in the latent space due to the lack of priori knowledge to
guide the training. To address this problem, this paper proposes to harness the
generative model with a priori knowledge through a cognitive approach involving
mesoscopic scale feature disentanglement. Particularly, the model integrates
the macro-level guided-category knowledge and micro-level open-domain dialogue
data for the training, leveraging the priori knowledge into the latent space,
which enables the model to disentangle the latent variables within the
mesoscopic scale. Besides, we propose a new metric for open-domain dialogues,
which can objectively evaluate the interpretability of the latent space
distribution. Finally, we validate our model on different datasets and
experimentally demonstrate that our model is able to generate higher quality
and more interpretable dialogues than other models.",None,-1
5e08d467-3b8d-44ce-96b5-2b92d708ba70,D2-TPred: Discontinuous Dependency for Trajectory Prediction under Traffic Lights,0.321212,"A profound understanding of inter-agent relationships and motion behaviors is
important to achieve high-quality planning when navigating in complex
scenarios, especially at urban traffic intersections. We present a trajectory
prediction approach with respect to traffic lights, D2-TPred, which uses a
spatial dynamic interaction graph (SDG) and a behavior dependency graph (BDG)
to handle the problem of discontinuous dependency in the spatial-temporal
space. Specifically, the SDG is used to capture spatial interactions by
reconstructing sub-graphs for different agents with dynamic and changeable
characteristics during each frame. The BDG is used to infer motion tendency by
modeling the implicit dependency of the current state on priors behaviors,
especially the discontinuous motions corresponding to acceleration,
deceleration, or turning direction. Moreover, we present a new dataset for
vehicle trajectory prediction under traffic lights called VTP-TL. Our
experimental results show that our model achieves more than {20.45% and 20.78%
}improvement in terms of ADE and FDE, respectively, on VTP-TL as compared to
other trajectory prediction algorithms. The dataset and code are available at:
https://github.com/VTP-TL/D2-TPred.",https://github.com/VTP-TL/D2-TPred,-1
2909748d-765e-4e4d-9018-bc63a46bc9b7,StyLandGAN: A StyleGAN based Landscape Image Synthesis using Depth-map,0.0238567,"Despite recent success in conditional image synthesis, prevalent input
conditions such as semantics and edges are not clear enough to express `Linear
(Ridges)' and `Planar (Scale)' representations. To address this problem, we
propose a novel framework StyLandGAN, which synthesizes desired landscape
images using a depth map which has higher expressive power. Our StyleLandGAN is
extended from the unconditional generation model to accept input conditions. We
also propose a '2-phase inference' pipeline which generates diverse depth maps
and shifts local parts so that it can easily reflect user's intend. As a
comparison, we modified the existing semantic image synthesis models to accept
a depth map as well. Experimental results show that our method is superior to
existing methods in quality, diversity, and depth-accuracy.",None,966
2c1ddc8d-c413-4499-b61c-b78e5edba5ef,On the Super-exponential Quantum Speedup of Equivariant Quantum Machine Learning Algorithms with SU($d$) Symmetry,0.822274,"We introduce a framework of the equivariant convolutional algorithms which is
tailored for a number of machine-learning tasks on physical systems with
arbitrary SU($d$) symmetries. It allows us to enhance a natural model of
quantum computation--permutational quantum computing (PQC) [Quantum Inf.
Comput., 10, 470-497 (2010)] --and defines a more powerful model: PQC+. While
PQC was shown to be effectively classically simulatable, we exhibit a problem
which can be efficiently solved on PQC+ machine, whereas the best known
classical algorithms runs in $O(n!n^2)$ time, thus providing strong evidence
against PQC+ being classically simulatable. We further discuss practical
quantum machine learning algorithms which can be carried out in the paradigm of
PQC+.",None,13616
ee7b4483-d108-4df8-aaca-728499c13985,Adaptive Frequency Learning in Two-branch Face Forgery Detection,0.065017,"Face forgery has attracted increasing attention in recent applications of
computer vision. Existing detection techniques using the two-branch framework
benefit a lot from a frequency perspective, yet are restricted by their fixed
frequency decomposition and transform. In this paper, we propose to Adaptively
learn Frequency information in the two-branch Detection framework, dubbed AFD.
To be specific, we automatically learn decomposition in the frequency domain by
introducing heterogeneity constraints, and propose an attention-based module to
adaptively incorporate frequency features into spatial clues. Then we liberate
our network from the fixed frequency transforms, and achieve better performance
with our data- and task-dependent transform layers. Extensive experiments show
that AFD generally outperforms.",https://github.com/timesler/facenet-pytorch,-1
5741e92f-ea8e-4700-9fc4-21b16438fa97,Disentangling Uncertainty in Machine Translation Evaluation,0.445006,"Trainable evaluation metrics for machine translation (MT) exhibit strong
correlation with human judgements, but they are often hard to interpret and
might produce unreliable scores under noisy or out-of-domain data. Recent work
has attempted to mitigate this with simple uncertainty quantification
techniques (Monte Carlo dropout and deep ensembles), however these techniques
(as we show) are limited in several ways -- for example, they are unable to
distinguish between different kinds of uncertainty, and they are time and
memory consuming. In this paper, we propose more powerful and efficient
uncertainty predictors for MT evaluation, and we assess their ability to target
different sources of aleatoric and epistemic uncertainty. To this end, we
develop and compare training objectives for the COMET metric to enhance it with
an uncertainty prediction output, including heteroscedastic regression,
divergence minimization, and direct uncertainty prediction. Our experiments
show improved results on uncertainty prediction for the WMT metrics task
datasets, with a substantial reduction in computational costs. Moreover, they
demonstrate the ability of these predictors to address specific uncertainty
causes in MT evaluation, such as low quality references and out-of-domain data.",https://github.com/deep-spin/uncertainties_MT_eval,-1
4b54842d-8ecf-47c0-a68f-621cf2e40e13,Connecting Neural Response measurements & Computational Models of language: a non-comprehensive guide,0.253465,"Understanding the neural basis of language comprehension in the brain has
been a long-standing goal of various scientific research programs. Recent
advances in language modelling and in neuroimaging methodology promise
potential improvements in both the investigation of language's neurobiology and
in the building of better and more human-like language models. This survey
traces a line from early research linking Event Related Potentials and
complexity measures derived from simple language models to contemporary studies
employing Artificial Neural Network models trained on large corpora in
combination with neural response recordings from multiple modalities using
naturalistic stimuli.",None,-1
9b9d2764-d22b-4691-809f-4f97400070a8,IDANI: Inference-time Domain Adaptation via Neuron-level Interventions,0.459322,"Large pre-trained models are usually fine-tuned on downstream task data, and
tested on unseen data. When the train and test data come from different
domains, the model is likely to struggle, as it is not adapted to the test
domain. We propose a new approach for domain adaptation (DA), using
neuron-level interventions: We modify the representation of each test example
in specific neurons, resulting in a counterfactual example from the source
domain, which the model is more familiar with. The modified example is then fed
back into the model. While most other DA methods are applied during training
time, ours is applied during inference only, making it more efficient and
applicable. Our experiments show that our method improves performance on unseen
domains.",https://github.com/technion-cs-nlp/idani,-1
08ae0cce-e7f8-4989-a519-4be4d05c41aa,Scalable Multi-view Clustering with Graph Filtering,0.431922,"With the explosive growth of multi-source data, multi-view clustering has
attracted great attention in recent years. Most existing multi-view methods
operate in raw feature space and heavily depend on the quality of original
feature representation. Moreover, they are often designed for feature data and
ignore the rich topology structure information. Accordingly, in this paper, we
propose a generic framework to cluster both attribute and graph data with
heterogeneous features. It is capable of exploring the interplay between
feature and structure. Specifically, we first adopt graph filtering technique
to eliminate high-frequency noise to achieve a clustering-friendly smooth
representation. To handle the scalability challenge, we develop a novel
sampling strategy to improve the quality of anchors. Extensive experiments on
attribute and graph benchmarks demonstrate the superiority of our approach with
respect to state-of-the-art approaches.",https://github.com/EricliuLiang/SMC,-1
351af28b-2e47-4c4f-99a2-f337f3e4db12,Detecting Text Formality: A Study of Text Classification Approaches,0.00968947,"Formality is one of the important characteristics of text documents. The
automatic detection of the formality level of a text is potentially beneficial
for various natural language processing tasks. Before, two large-scale datasets
were introduced for multiple languages featuring formality annotation -- GYAFC
and X-FORMAL. However, they were primarily used for the training of style
transfer models. At the same time, the detection of text formality on its own
may also be a useful application. This work proposes the first to our knowledge
systematic study of formality detection methods based on statistical,
neural-based, and Transformer-based machine learning methods and delivers the
best-performing models for public usage. We conducted three types of
experiments -- monolingual, multilingual, and cross-lingual. The study shows
the overcome of Char BiLSTM model over Transformer-based ones for the
monolingual and multilingual formality classification task, while
Transformer-based classifiers are more stable to cross-lingual knowledge
transfer.",https://github.com/s-nlp/formality,-1
094078ac-a67f-4156-b25c-a77a57b9cdb8,Different Tunes Played with Equal Skill: Exploring a Unified Optimization Subspace for Delta Tuning,0.0395259,"Delta tuning (DET, also known as parameter-efficient tuning) is deemed as the
new paradigm for using pre-trained language models (PLMs). Up to now, various
DETs with distinct design elements have been proposed, achieving performance on
par with fine-tuning. However, the mechanisms behind the above success are
still under-explored, especially the connections among various DETs. To fathom
the mystery, we hypothesize that the adaptations of different DETs could all be
reparameterized as low-dimensional optimizations in a unified optimization
subspace, which could be found by jointly decomposing independent solutions of
different DETs. Then we explore the connections among different DETs by
conducting optimization within the subspace. In experiments, we find that, for
a certain DET, conducting optimization simply in the subspace could achieve
comparable performance to its original space, and the found solution in the
subspace could be transferred to another DET and achieve non-trivial
performance. We also visualize the performance landscape of the subspace and
find that there exists a substantial region where different DETs all perform
well. Finally, we extend our analysis and show the strong connections between
fine-tuning and DETs.",https://github.com/thunlp/Unified-DeltaTuning,-1
a9d63375-1f72-4d2a-8251-0a59a5f646c7,Knowledge-Guided Exploration in Deep Reinforcement Learning,0.12583,"This paper proposes a new method to drastically speed up deep reinforcement
learning (deep RL) training for problems that have the property of state-action
permissibility (SAP). Two types of permissibility are defined under SAP. The
first type says that after an action $a_t$ is performed in a state $s_t$ and
the agent has reached the new state $s_{t+1}$, the agent can decide whether
$a_t$ is permissible or not permissible in $s_t$. The second type says that
even without performing $a_t$ in $s_t$, the agent can already decide whether
$a_t$ is permissible or not in $s_t$. An action is not permissible in a state
if the action can never lead to an optimal solution and thus should not be
tried (over and over again). We incorporate the proposed SAP property and
encode action permissibility knowledge into two state-of-the-art deep RL
algorithms to guide their state-action exploration together with a virtual
stopping strategy. Results show that the SAP-based guidance can markedly speed
up RL training.",https://github.com/yanpanlau/DDPG-Keras-Torcs,-1
7ad63ac5-5e2b-4244-8f48-7c9dac4e5401,Equilibrium Aggregation: Encoding Sets via Optimization,0.211275,"Processing sets or other unordered, potentially variable-sized inputs in
neural networks is usually handled by aggregating a number of input tensors
into a single representation. While a number of aggregation methods already
exist from simple sum pooling to multi-head attention, they are limited in
their representational power both from theoretical and empirical perspectives.
On the search of a principally more powerful aggregation strategy, we propose
an optimization-based method called Equilibrium Aggregation. We show that many
existing aggregation methods can be recovered as special cases of Equilibrium
Aggregation and that it is provably more efficient in some important cases.
Equilibrium Aggregation can be used as a drop-in replacement in many existing
architectures and applications. We validate its efficiency on three different
tasks: median estimation, class counting, and molecular property prediction. In
all experiments, Equilibrium Aggregation achieves higher performance than the
other aggregation techniques we test.",http://github.com/google/jax,-1
0ff06539-b776-4056-969a-cd7f45c50040,Taylor Genetic Programming for Symbolic Regression,0.379777,"Genetic programming (GP) is a commonly used approach to solve symbolic
regression (SR) problems. Compared with the machine learning or deep learning
methods that depend on the pre-defined model and the training dataset for
solving SR problems, GP is more focused on finding the solution in a search
space. Although GP has good performance on large-scale benchmarks, it randomly
transforms individuals to search results without taking advantage of the
characteristics of the dataset. So, the search process of GP is usually slow,
and the final results could be unstable.To guide GP by these characteristics,
we propose a new method for SR, called Taylor genetic programming (TaylorGP)
(Code and appendix at https://kgae-cup.github.io/TaylorGP/). TaylorGP leverages
a Taylor polynomial to approximate the symbolic equation that fits the dataset.
It also utilizes the Taylor polynomial to extract the features of the symbolic
equation: low order polynomial discrimination, variable separability, boundary,
monotonic, and parity. GP is enhanced by these Taylor polynomial techniques.
Experiments are conducted on three kinds of benchmarks: classical SR, machine
learning, and physics. The experimental results show that TaylorGP not only has
higher accuracy than the nine baseline methods, but also is faster in finding
stable results.",https://kgae-cup.github.io/TaylorGP/,2208
d4e6ff64-f750-4349-b86b-94ab36b6cae9,RNNCTPs: A Neural Symbolic Reasoning Method Using Dynamic Knowledge Partitioning Technology,0.117683,"Although traditional symbolic reasoning methods are highly interpretable,
their application in knowledge graph link prediction is limited due to their
low computational efficiency. In this paper, we propose a new neural symbolic
reasoning method: RNNCTPs, which improves computational efficiency by
re-filtering the knowledge selection of Conditional Theorem Provers (CTPs), and
is less sensitive to the embedding size parameter. RNNCTPs are divided into
relation selectors and predictors. The relation selectors are trained
efficiently and interpretably, so that the whole model can dynamically generate
knowledge for the inference of the predictor. In all four datasets, the method
shows competitive performance against traditional methods on the link
prediction task, and can have higher applicability to the selection of datasets
relative to CTPs.",None,-1
961c933a-4ea9-4e32-a41f-ec6f466dcc61,Pathway to Future Symbiotic Creativity,0.0242748,"This report presents a comprehensive view of our vision on the development
path of the human-machine symbiotic art creation. We propose a classification
of the creative system with a hierarchy of 5 classes, showing the pathway of
creativity evolving from a mimic-human artist (Turing Artists) to a Machine
artist in its own right. We begin with an overview of the limitations of the
Turing Artists then focus on the top two-level systems, Machine Artists,
emphasizing machine-human communication in art creation. In art creation, it is
necessary for machines to understand humans' mental states, including desires,
appreciation, and emotions, humans also need to understand machines' creative
capabilities and limitations. The rapid development of immersive environment
and further evolution into the new concept of metaverse enable symbiotic art
creation through unprecedented flexibility of bi-directional communication
between artists and art manifestation environments. By examining the latest
sensor and XR technologies, we illustrate the novel way for art data collection
to constitute the base of a new form of human-machine bidirectional
communication and understanding in art creation. Based on such communication
and understanding mechanisms, we propose a novel framework for building future
Machine artists, which comes with the philosophy that a human-compatible AI
system should be based on the ""human-in-the-loop"" principle rather than the
traditional ""end-to-end"" dogma. By proposing a new form of inverse
reinforcement learning model, we outline the platform design of machine
artists, demonstrate its functions and showcase some examples of technologies
we have developed. We also provide a systematic exposition of the ecosystem for
AI-based symbiotic art form and community with an economic model built on NFT
technology. Ethical issues for the development of machine artists are also
discussed.",None,-1
96e2c774-2480-4836-ac2e-71d8e42bda0a,Interactive Concept Bottleneck Models,0.98592,"Concept bottleneck models (CBMs) are interpretable neural networks that first
predict labels for human-interpretable concepts relevant to the prediction
task, and then predict the final label based on the concept label predictions.
We extend CBMs to interactive prediction settings where the model can query a
human collaborator for the label to some concepts. We develop an interaction
policy that, at prediction time, chooses which concepts to request a label for
so as to maximally improve the final prediction. We demonstrate that a simple
policy combining concept prediction uncertainty and influence of the concept on
the final prediction achieves strong performance and outperforms static
approaches as well as active feature acquisition methods proposed in the
literature. We show that the interactive CBM can achieve accuracy gains of
5-10% with only 5 interactions over competitive baselines on the Caltech-UCSD
Birds, CheXpert and OAI datasets.",https://github.com/google-research/google-research/tree/master/interactive_cbms,-1
647a9f1d-f494-4025-b2f9-7a6dae25ce84,Data Splits and Metrics for Method Benchmarking on Surgical Action Triplet Datasets,0.846434,"In addition to generating data and annotations, devising sensible data
splitting strategies and evaluation metrics is essential for the creation of a
benchmark dataset. This practice ensures consensus on the usage of the data,
homogeneous assessment, and uniform comparison of research methods on the
dataset. This study focuses on CholecT50, which is a 50 video surgical dataset
that formalizes surgical activities as triplets of <instrument, verb, target>.
In this paper, we introduce the standard splits for the CholecT50 and CholecT45
datasets and show how they compare with existing use of the dataset. CholecT45
is the first public release of 45 videos of CholecT50 dataset. We also develop
a metrics library, ivtmetrics, for model evaluation on surgical triplets.
Furthermore, we conduct a benchmark study by reproducing baseline methods in
the most predominantly used deep learning frameworks (PyTorch and TensorFlow)
to evaluate them using the proposed data splits and metrics and release them
publicly to support future research. The proposed data splits and evaluation
metrics will enable global tracking of research progress on the dataset and
facilitate optimal model selection for further deployment.",https://github.com/CAMMA-public,-1
b56ea3e6-0e30-4f4a-ae89-e912c783ba23,Automatic Semantic Modeling for Structural Data Source with the Prior Knowledge from Knowledge Base,0.203854,"A critical step in sharing semantic content online is to map the structural
data source to a public domain ontology. This problem is denoted as the
Relational-To-Ontology Mapping Problem (Rel2Onto). A huge effort and expertise
are required for manually modeling the semantics of data. Therefore, an
automatic approach for learning the semantics of a data source is desirable.
Most of the existing work studies the semantic annotation of source attributes.
However, although critical, the research for automatically inferring the
relationships between attributes is very limited. In this paper, we propose a
novel method for semantically annotating structured data sources using machine
learning, graph matching and modified frequent subgraph mining to amend the
candidate model. In our work, Knowledge graph is used as prior knowledge. Our
evaluation shows that our approach outperforms two state-of-the-art solutions
in tricky cases where only a few semantic models are known.",https://github.com/Zaiwen/ModelCorrection,-1
978f0187-d03b-42c3-a378-c58ab0d8556e,Learning Control Admissibility Models with Graph Neural Networks for Multi-Agent Navigation,0.862066,"Deep reinforcement learning in continuous domains focuses on learning control
policies that map states to distributions over actions that ideally concentrate
on the optimal choices in each step. In multi-agent navigation problems, the
optimal actions depend heavily on the agents' density. Their interaction
patterns grow exponentially with respect to such density, making it hard for
learning-based methods to generalize. We propose to switch the learning
objectives from predicting the optimal actions to predicting sets of admissible
actions, which we call control admissibility models (CAMs), such that they can
be easily composed and used for online inference for an arbitrary number of
agents. We design CAMs using graph neural networks and develop training methods
that optimize the CAMs in the standard model-free setting, with the additional
benefit of eliminating the need for reward engineering typically required to
balance collision avoidance and goal-reaching requirements. We evaluate the
proposed approach in multi-agent navigation environments. We show that the CAM
models can be trained in environments with only a few agents and be easily
composed for deployment in dense environments with hundreds of agents,
achieving better performance than state-of-the-art methods.",None,-1
2e639c47-e224-496b-949e-1c140dc1efb3,News Summarization and Evaluation in the Era of GPT-3,0.999999,"The recent success of prompting large language models like GPT-3 has led to a
paradigm shift in NLP research. In this paper, we study its impact on text
summarization, focusing on the classic benchmark domain of news summarization.
First, we investigate how GPT-3 compares against fine-tuned models trained on
large summarization datasets. We show that not only do humans overwhelmingly
prefer GPT-3 summaries, prompted using only a task description, but these also
do not suffer from common dataset-specific issues such as poor factuality.
Next, we study what this means for evaluation, particularly the role of gold
standard test sets. Our experiments show that both reference-based and
reference-free automatic metrics cannot reliably evaluate GPT-3 summaries.
Finally, we evaluate models on a setting beyond generic summarization,
specifically keyword-based summarization, and show how dominant fine-tuning
approaches compare to prompting.
  To support further research, we release: (a) a corpus of 10K generated
summaries from fine-tuned and prompt-based models across 4 standard
summarization benchmarks, (b) 1K human preference judgments comparing different
systems for generic- and keyword-based summarization.",None,5490
3bc519cf-2ef9-4969-9c17-eba31097cac1,Semantic Similarity Computing Model Based on Multi Model Fine-Grained Nonlinear Fusion,0.764845,"Natural language processing (NLP) task has achieved excellent performance in
many fields, including semantic understanding, automatic summarization, image
recognition and so on. However, most of the neural network models for NLP
extract the text in a fine-grained way, which is not conducive to grasp the
meaning of the text from a global perspective. To alleviate the problem, the
combination of the traditional statistical method and deep learning model as
well as a novel model based on multi model nonlinear fusion are proposed in
this paper. The model uses the Jaccard coefficient based on part of speech,
Term Frequency-Inverse Document Frequency (TF-IDF) and word2vec-CNN algorithm
to measure the similarity of sentences respectively. According to the
calculation accuracy of each model, the normalized weight coefficient is
obtained and the calculation results are compared. The weighted vector is input
into the fully connected neural network to give the final classification
results. As a result, the statistical sentence similarity evaluation algorithm
reduces the granularity of feature extraction, so it can grasp the sentence
features globally. Experimental results show that the matching of sentence
similarity calculation method based on multi model nonlinear fusion is 84%, and
the F1 value of the model is 75%.",None,18646
825c28be-3800-4770-a8e4-92cc6027c61d,SceneRF: Self-Supervised Monocular 3D Scene Reconstruction with Radiance Fields,0.93809,"3D reconstruction from a single 2D image was extensively covered in the
literature but relies on depth supervision at training time, which limits its
applicability. To relax the dependence to depth we propose SceneRF, a
self-supervised monocular scene reconstruction method using only posed image
sequences for training. Fueled by the recent progress in neural radiance fields
(NeRF) we optimize a radiance field though with explicit depth optimization and
a novel probabilistic sampling strategy to efficiently handle large scenes. At
inference, a single input image suffices to hallucinate novel depth views which
are fused together to obtain 3D scene reconstruction. Thorough experiments
demonstrate that we outperform all baselines for novel depth views synthesis
and scene reconstruction, on indoor BundleFusion and outdoor SemanticKITTI.
Code is available at https://astra-vision.github.io/SceneRF .",https://astra-vision.github.io/SceneRF,-1
29e63dd7-976f-4c57-8977-1fd23b2c1c18,Can Large Language Models Truly Understand Prompts? A Case Study with Negated Prompts,0.455361,"Previous work has shown that there exists a scaling law between the size of
Language Models (LMs) and their zero-shot performance on different downstream
NLP tasks. In this work, we show that this phenomenon does not hold when
evaluating large LMs on tasks with negated prompts, but instead shows an
inverse scaling law. We evaluate 9 different tasks with negated prompts on (1)
pretrained LMs (OPT & GPT-3) of varying sizes (125M - 175B), (2) LMs further
pretrained to generalize to novel prompts (InstructGPT), (3) LMs provided with
few-shot examples, and (4) LMs fine-tuned specifically on negated prompts; all
LM types perform worse on negated prompts as they scale and show a huge
performance gap between the human performance when comparing the average score
on both original and negated prompts. By highlighting a critical limitation of
existing LMs and methods, we urge the community to develop new approaches of
developing LMs that actually follow the given instructions. We provide the code
and the datasets to explore negated prompts at
https://github.com/joeljang/negated-prompts-for-llms",None,6400
a49083ab-b42e-47a2-8dff-0865b034da64,Iterative Next Boundary Detection for Instance Segmentation of Tree Rings in Microscopy Images of Shrub Cross Sections,0.496928,"We address the problem of detecting tree rings in microscopy images of shrub
cross sections. This can be regarded as a special case of the instance
segmentation task with several unique challenges such as the concentric
circular ring shape of the objects and high precision requirements that result
in inadequate performance of existing methods. We propose a new iterative
method which we term Iterative Next Boundary Detection (INBD). It intuitively
models the natural growth direction, starting from the center of the shrub
cross section and detecting the next ring boundary in each iteration step. In
our experiments, INBD shows superior performance to generic instance
segmentation methods and is the only one with a built-in notion of
chronological order. Our dataset and source code are available at
http://github.com/alexander-g/INBD.",http://github.com/alexander-g/INBD,-1
5fa194dc-3296-44d6-afa8-cb1ee83d31fc,Discovering Bugs in Vision Models using Off-the-shelf Image Generation and Captioning,0.507345,"Automatically discovering failures in vision models under real-world settings
remains an open challenge. This work demonstrates how off-the-shelf,
large-scale, image-to-text and text-to-image models, trained on vast amounts of
data, can be leveraged to automatically find such failures. In essence, a
conditional text-to-image generative model is used to generate large amounts of
synthetic, yet realistic, inputs given a ground-truth label. Misclassified
inputs are clustered and a captioning model is used to describe each cluster.
Each cluster's description is used in turn to generate more inputs and assess
whether specific clusters induce more failures than expected. We use this
pipeline to demonstrate that we can effectively interrogate classifiers trained
on ImageNet to find specific failure cases and discover spurious correlations.
We also show that we can scale the approach to generate adversarial datasets
targeting specific classifier architectures. This work serves as a
proof-of-concept demonstrating the utility of large-scale generative models to
automatically discover bugs in vision models in an open-ended manner. We also
describe a number of limitations and pitfalls related to this approach.",None,-1
147957e6-df5c-45df-b8f4-92b590ea733f,Social Network Mining (SNM): A Definition of Relation between the Resources and SNA,0.258111,"Social Network Mining (SNM) has become one of the main themes in big data
agenda. As a resultant network, we can extract social network from different
sources of information, but the information sources were growing dynamically
require a flexible approach. To determine the appropriate approach needs the
data engineering in order to get the behavior associated with the data. Each
social network has the resources and the information source, but the
relationship between resources and information sources requires explanation.
This paper aimed to address the behavior of the resource as a part of social
network analysis (SNA) in the growth of social networks by using the
statistical calculations to explain the evolutionary mechanisms. To represent
the analysis unit of the SNA, this paper only considers the degree of a vertex,
where it is the core of all the analysis in the SNA and it is basic for
defining the relation between resources and SNA in SNM. There is a strong
effect on the growth of the resources of social networks. In total, the
behavior of resources has positive effects. Thus, different information sources
behave similarly and have relations with SNA.",None,-1
59f8418d-b6d4-42fe-a4f7-4783cc88a048,Deep Learning Opacity in Scientific Discovery,0.673327,"Philosophers have recently focused on critical, epistemological challenges
that arise from the opacity of deep neural networks. One might conclude from
this literature that doing good science with opaque models is exceptionally
challenging, if not impossible. Yet, this is hard to square with the recent
boom in optimism for AI in science alongside a flood of recent scientific
breakthroughs driven by AI methods. In this paper, I argue that the disconnect
between philosophical pessimism and scientific optimism is driven by a failure
to examine how AI is actually used in science. I show that, in order to
understand the epistemic justification for AI-powered breakthroughs,
philosophers must examine the role played by deep learning as part of a wider
process of discovery. The philosophical distinction between the 'context of
discovery' and the 'context of justification' is helpful in this regard. I
demonstrate the importance of attending to this distinction with two cases
drawn from the scientific literature, and show that epistemic opacity need not
diminish AI's capacity to lead scientists to significant and justifiable
breakthroughs.",None,-1
90e1c798-05af-4841-aece-b3368e8a5ce7,A Dense Material Segmentation Dataset for Indoor and Outdoor Scene Parsing,0.317593,"A key algorithm for understanding the world is material segmentation, which
assigns a label (metal, glass, etc.) to each pixel. We find that a model
trained on existing data underperforms in some settings and propose to address
this with a large-scale dataset of 3.2 million dense segments on 44,560 indoor
and outdoor images, which is 23x more segments than existing data. Our data
covers a more diverse set of scenes, objects, viewpoints and materials, and
contains a more fair distribution of skin types. We show that a model trained
on our data outperforms a state-of-the-art model across datasets and
viewpoints. We propose a large-scale scene parsing benchmark and baseline of
0.729 per-pixel accuracy, 0.585 mean class accuracy and 0.420 mean IoU across
46 materials.",https://github.com/apple/ml-dms-dataset,-1
20095cc6-89a4-4c41-b506-418a66e4eb41,Data-Driven Mitigation of Adversarial Text Perturbation,0.418859,"Social networks have become an indispensable part of our lives, with billions
of people producing ever-increasing amounts of text. At such scales, content
policies and their enforcement become paramount. To automate moderation,
questionable content is detected by Natural Language Processing (NLP)
classifiers. However, high-performance classifiers are hampered by misspellings
and adversarial text perturbations. In this paper, we classify intentional and
unintentional adversarial text perturbation into ten types and propose a
deobfuscation pipeline to make NLP models robust to such perturbations. We
propose Continuous Word2Vec (CW2V), our data-driven method to learn word
embeddings that ensures that perturbations of words have embeddings similar to
those of the original words. We show that CW2V embeddings are generally more
robust to text perturbations than embeddings based on character ngrams. Our
robust classification pipeline combines deobfuscation and classification, using
proposed defense methods and word embeddings to classify whether Facebook posts
are requesting engagement such as likes. Our pipeline results in engagement
bait classification that goes from 0.70 to 0.67 AUC with adversarial text
perturbation, while character ngram-based word embedding methods result in
downstream classification that goes from 0.76 to 0.64.",https://github.com/pytorch/captum,-1
311e3dea-db3d-4e4c-82cd-a5c9caad02d1,Measuring the Impact of (Psycho-)Linguistic and Readability Features and Their Spill Over Effects on the Prediction of Eye Movement Patterns,0.862106,"There is a growing interest in the combined use of NLP and machine learning
methods to predict gaze patterns during naturalistic reading. While promising
results have been obtained through the use of transformer-based language
models, little work has been undertaken to relate the performance of such
models to general text characteristics. In this paper we report on experiments
with two eye-tracking corpora of naturalistic reading and two language models
(BERT and GPT-2). In all experiments, we test effects of a broad spectrum of
features for predicting human reading behavior that fall into five categories
(syntactic complexity, lexical richness, register-based multiword combinations,
readability and psycholinguistic word properties). Our experiments show that
both the features included and the architecture of the transformer-based
language models play a role in predicting multiple eye-tracking measures during
naturalistic reading. We also report the results of experiments aimed at
determining the relative importance of features from different groups using
SP-LIME.",None,-1
18ebf9d7-e340-4938-adb5-aba6bcec09ad,Tools and Practices for Responsible AI Engineering,0.612201,"Responsible Artificial Intelligence (AI) - the practice of developing,
evaluating, and maintaining accurate AI systems that also exhibit essential
properties such as robustness and explainability - represents a multifaceted
challenge that often stretches standard machine learning tooling, frameworks,
and testing methods beyond their limits. In this paper, we present two new
software libraries - hydra-zen and the rAI-toolbox - that address critical
needs for responsible AI engineering. hydra-zen dramatically simplifies the
process of making complex AI applications configurable, and their behaviors
reproducible. The rAI-toolbox is designed to enable methods for evaluating and
enhancing the robustness of AI-models in a way that is scalable and that
composes naturally with other popular ML frameworks. We describe the design
principles and methodologies that make these tools effective, including the use
of property-based testing to bolster the reliability of the tools themselves.
Finally, we demonstrate the composability and flexibility of the tools by
showing how various use cases from adversarial robustness and explainable AI
can be concisely implemented with familiar APIs.",https://github.com/mit-ll-responsible-ai/,4156
599ac3eb-e2fa-45ea-aab8-be99a9c51d21,Test-time image-to-image translation ensembling improves out-of-distribution generalization in histopathology,0.533482,"Histopathology whole slide images (WSIs) can reveal significant
inter-hospital variability such as illumination, color or optical artifacts.
These variations, caused by the use of different scanning protocols across
medical centers (staining, scanner), can strongly harm algorithms
generalization on unseen protocols. This motivates development of new methods
to limit such drop of performances. In this paper, to enhance robustness on
unseen target protocols, we propose a new test-time data augmentation based on
multi domain image-to-image translation. It allows to project images from
unseen protocol into each source domain before classifying them and ensembling
the predictions. This test-time augmentation method results in a significant
boost of performances for domain generalization. To demonstrate its
effectiveness, our method has been evaluated on 2 different histopathology
tasks where it outperforms conventional domain generalization, standard H&E
specific color augmentation/normalization and standard test-time augmentation
techniques. Our code is publicly available at
https://gitlab.com/vitadx/articles/test-time-i2i-translation-ensembling.",https://gitlab.com/vitadx/articles/test-time-i2i-translation-ensembling,-1
ef8b1cb8-fe55-4ccd-beef-5ad9b16f4205,BanglaNLG and BanglaT5: Benchmarks and Resources for Evaluating Low-Resource Natural Language Generation in Bangla,0.326943,"This work presents BanglaNLG, a comprehensive benchmark for evaluating
natural language generation (NLG) models in Bangla, a widely spoken yet
low-resource language. We aggregate six challenging conditional text generation
tasks under the BanglaNLG benchmark, introducing a new dataset on dialogue
generation in the process. Furthermore, using a clean corpus of 27.5 GB of
Bangla data, we pretrain BanglaT5, a sequence-to-sequence Transformer language
model for Bangla. BanglaT5 achieves state-of-the-art performance in all of
these tasks, outperforming several multilingual models by up to 9% absolute
gain and 32% relative gain. We are making the new dialogue dataset and the
BanglaT5 model publicly available at https://github.com/csebuetnlp/BanglaNLG in
the hope of advancing future research on Bangla NLG.",https://github.com/csebuetnlp/BanglaNLG,-1
0a5fc900-1ee0-4911-aff2-8ce6f35bd11b,Bi-SimCut: A Simple Strategy for Boosting Neural Machine Translation,0.692525,"We introduce Bi-SimCut: a simple but effective training strategy to boost
neural machine translation (NMT) performance. It consists of two procedures:
bidirectional pretraining and unidirectional finetuning. Both procedures
utilize SimCut, a simple regularization method that forces the consistency
between the output distributions of the original and the cutoff sentence pairs.
Without leveraging extra dataset via back-translation or integrating
large-scale pretrained model, Bi-SimCut achieves strong translation performance
across five translation benchmarks (data sizes range from 160K to 20.2M): BLEU
scores of 31.16 for en -> de and 38.37 for de -> en on the IWSLT14 dataset,
30.78 for en -> de and 35.15 for de -> en on the WMT14 dataset, and 27.17 for
zh -> en on the WMT17 dataset. SimCut is not a new method, but a version of
Cutoff (Shen et al., 2020) simplified and adapted for NMT, and it could be
considered as a perturbation-based method. Given the universality and
simplicity of SimCut and Bi-SimCut, we believe they can serve as strong
baselines for future NMT research.",https://github.com/gpengzhi/Bi-SimCut,-1
3e712872-2591-492e-b74d-850de9deb383,Robust (Controlled) Table-to-Text Generation with Structure-Aware Equivariance Learning,0.485203,"Controlled table-to-text generation seeks to generate natural language
descriptions for highlighted subparts of a table. Previous SOTA systems still
employ a sequence-to-sequence generation method, which merely captures the
table as a linear structure and is brittle when table layouts change. We seek
to go beyond this paradigm by (1) effectively expressing the relations of
content pieces in the table, and (2) making our model robust to
content-invariant structural transformations. Accordingly, we propose an
equivariance learning framework, which encodes tables with a structure-aware
self-attention mechanism. This prunes the full self-attention structure into an
order-invariant graph attention that captures the connected graph structure of
cells belonging to the same row or column, and it differentiates between
relevant cells and irrelevant cells from the structural perspective. Our
framework also modifies the positional encoding mechanism to preserve the
relative position of tokens in the same cell but enforce position invariance
among different cells. Our technology is free to be plugged into existing
table-to-text generation models, and has improved T5-based models to offer
better performance on ToTTo and HiTab. Moreover, on a harder version of ToTTo,
we preserve promising performance, while previous SOTA systems, even with
transformation-based data augmentation, have seen significant performance
drops. Our code is available at https://github.com/luka-group/Lattice.",https://github.com/luka-group/Lattice,-1
265fc7d5-8b3e-4526-8b07-4578135fd712,Few Shot Generative Model Adaption via Relaxed Spatial Structural Alignment,0.872701,"Training a generative adversarial network (GAN) with limited data has been a
challenging task. A feasible solution is to start with a GAN well-trained on a
large scale source domain and adapt it to the target domain with a few samples,
termed as few shot generative model adaption. However, existing methods are
prone to model overfitting and collapse in extremely few shot setting (less
than 10). To solve this problem, we propose a relaxed spatial structural
alignment method to calibrate the target generative models during the adaption.
We design a cross-domain spatial structural consistency loss comprising the
self-correlation and disturbance correlation consistency loss. It helps align
the spatial structural information between the synthesis image pairs of the
source and target domains. To relax the cross-domain alignment, we compress the
original latent space of generative models to a subspace. Image pairs generated
from the subspace are pulled closer. Qualitative and quantitative experiments
show that our method consistently surpasses the state-of-the-art methods in few
shot setting.",https://github.com/StevenShaw1999/RSSA,18126
04a9acd4-f7e5-44c5-9787-fe77f54e16df,3D Random Occlusion and Multi-Layer Projection for Deep Multi-Camera Pedestrian Localization,0.617571,"Although deep-learning based methods for monocular pedestrian detection have
made great progress, they are still vulnerable to heavy occlusions. Using
multi-view information fusion is a potential solution but has limited
applications, due to the lack of annotated training samples in existing
multi-view datasets, which increases the risk of overfitting. To address this
problem, a data augmentation method is proposed to randomly generate 3D
cylinder occlusions, on the ground plane, which are of the average size of
pedestrians and projected to multiple views, to relieve the impact of
overfitting in the training. Moreover, the feature map of each view is
projected to multiple parallel planes at different heights, by using
homographies, which allows the CNNs to fully utilize the features across the
height of each pedestrian to infer the locations of pedestrians on the ground
plane. The proposed 3DROM method has a greatly improved performance in
comparison with the state-of-the-art deep-learning based methods for multi-view
pedestrian detection.",https://github.com/xjtlu-cvlab/3DROM,5075
b2d28eb0-8834-45c3-992a-7d9e03a6c4fe,Evaluating and Inducing Personality in Pre-trained Language Models,0.826481,"Standardized and quantified evaluation of machine behaviors is a crux of
understanding LLMs. In this study, we draw inspiration from psychometric
studies by leveraging human personality theory as a tool for studying machine
behaviors. Originating as a philosophical quest for human behaviors, the study
of personality delves into how individuals differ in thinking, feeling, and
behaving. Toward building and understanding human-like social machines, we are
motivated to ask: Can we assess machine behaviors by leveraging human
psychometric tests in a principled and quantitative manner? If so, can we
induce a specific personality in LLMs? To answer these questions, we introduce
the Machine Personality Inventory (MPI) tool for studying machine behaviors;
MPI follows standardized personality tests, built upon the Big Five Personality
Factors (Big Five) theory and personality assessment inventories. By
systematically evaluating LLMs with MPI, we provide the first piece of evidence
demonstrating the efficacy of MPI in studying LLMs behaviors. We further devise
a Personality Prompting (P^2) method to induce LLMs with specific personalities
in a controllable way, capable of producing diverse and verifiable behaviors.
We hope this work sheds light on future studies by adopting personality as the
essential indicator for various downstream tasks, and could further motivate
research into equally intriguing human-like machine behaviors.",None,-1
499ef5c4-5bf7-4108-bb3a-75d020cdaf2f,Anomaly detection optimization using big data and deep learning to reduce false-positive,0.561707,"Anomaly-based Intrusion Detection System (IDS) has been a hot research topic
because of its ability to detect new threats rather than only memorized
signatures threats of signature-based IDS. Especially after the availability of
advanced technologies that increase the number of hacking tools and increase
the risk impact of an attack. The problem of any anomaly-based model is its
high false-positive rate. The high false-positive rate is the reason why
anomaly IDS is not commonly applied in practice. Because anomaly-based models
classify an unseen pattern as a threat where it may be normal but not included
in the training dataset. This type of problem is called overfitting where the
model is not able to generalize. Optimizing Anomaly-based models by having a
big training dataset that includes all possible normal cases may be an optimal
solution but could not be applied in practice. Although we can increase the
number of training samples to include much more normal cases, still we need a
model that has more ability to generalize. In this research paper, we propose
applying deep model instead of traditional models because it has more ability
to generalize. Thus, we will obtain less false-positive by using big data and
deep model. We made a comparison between machine learning and deep learning
algorithms in the optimization of anomaly-based IDS by decreasing the
false-positive rate. We did an experiment on the NSL-KDD benchmark and compared
our results with one of the best used classifiers in traditional learning in
IDS optimization. The experiment shows 10% lower false-positive by using deep
learning instead of traditional learning.",None,-1
905efe13-dd93-43fc-91dc-3dedcef55fc0,Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models,0.858371,"Motivations for methods in explainable artificial intelligence (XAI) often
include detecting, quantifying and mitigating bias, and contributing to making
machine learning models fairer. However, exactly how an XAI method can help in
combating biases is often left unspecified. In this paper, we briefly review
trends in explainability and fairness in NLP research, identify the current
practices in which explainability methods are applied to detect and mitigate
bias, and investigate the barriers preventing XAI methods from being used more
widely in tackling fairness issues.",None,-1
a7410371-6c2b-4fc4-918e-02f51f7b8a09,Concept Graph Neural Networks for Surgical Video Understanding,0.585931,"We constantly integrate our knowledge and understanding of the world to
enhance our interpretation of what we see.
  This ability is crucial in application domains which entail reasoning about
multiple entities and concepts, such as AI-augmented surgery. In this paper, we
propose a novel way of integrating conceptual knowledge into temporal analysis
tasks via temporal concept graph networks. In the proposed networks, a global
knowledge graph is incorporated into the temporal analysis of surgical
instances, learning the meaning of concepts and relations as they apply to the
data. We demonstrate our results in surgical video data for tasks such as
verification of critical view of safety, as well as estimation of Parkland
grading scale. The results show that our method improves the recognition and
detection of complex benchmarks as well as enables other analytic applications
of interest.",https://github.com/CAMMA-public/ivtmetrics,-1
453b79a8-5350-4a5d-bec1-df55f936dc5f,"Strategy Complexity of Point Payoff, Mean Payoff and Total Payoff Objectives in Countable MDPs",0.191728,"We study countably infinite Markov decision processes (MDPs) with real-valued
transition rewards. Every infinite run induces the following sequences of
payoffs: 1. Point payoff (the sequence of directly seen transition rewards), 2.
Mean payoff (the sequence of the sums of all rewards so far, divided by the
number of steps), and 3. Total payoff (the sequence of the sums of all rewards
so far). For each payoff type, the objective is to maximize the probability
that the $\liminf$ is non-negative. We establish the complete picture of the
strategy complexity of these objectives, i.e., how much memory is necessary and
sufficient for $\varepsilon$-optimal (resp. optimal) strategies. Some cases can
be won with memoryless deterministic strategies, while others require a step
counter, a reward counter, or both.",None,-1
8f94b4f0-eddc-4141-93a8-f30956aaa191,ComFact: A Benchmark for Linking Contextual Commonsense Knowledge,0.924804,"Understanding rich narratives, such as dialogues and stories, often requires
natural language processing systems to access relevant knowledge from
commonsense knowledge graphs. However, these systems typically retrieve facts
from KGs using simple heuristics that disregard the complex challenges of
identifying situationally-relevant commonsense knowledge (e.g.,
contextualization, implicitness, ambiguity).
  In this work, we propose the new task of commonsense fact linking, where
models are given contexts and trained to identify situationally-relevant
commonsense knowledge from KGs. Our novel benchmark, ComFact, contains ~293k
in-context relevance annotations for commonsense triplets across four
stylistically diverse dialogue and storytelling datasets. Experimental results
confirm that heuristic fact linking approaches are imprecise knowledge
extractors. Learned fact linking models demonstrate across-the-board
performance improvements (~34.6% F1) over these heuristics. Furthermore,
improved knowledge retrieval yielded average downstream improvements of 9.8%
for a dialogue response generation task. However, fact linking models still
significantly underperform humans, suggesting our benchmark is a promising
testbed for research in commonsense augmentation of NLP systems.",https://github.com/Silin159/ComFact,-1
7eed49f1-8fba-4ebb-8388-0d262b5b4c83,ROMA: Run-Time Object Detection To Maximize Real-Time Accuracy,0.126995,"This paper analyzes the effects of dynamically varying video contents and
detection latency on the real-time detection accuracy of a detector and
proposes a new run-time accuracy variation model, ROMA, based on the findings
from the analysis. ROMA is designed to select an optimal detector out of a set
of detectors in real time without label information to maximize real-time
object detection accuracy. ROMA utilizing four YOLOv4 detectors on an NVIDIA
Jetson Nano shows real-time accuracy improvements by 4 to 37% for a scenario of
dynamically varying video contents and detection latency consisting of MOT17Det
and MOT20Det datasets, compared to individual YOLOv4 detectors and two
state-of-the-art runtime techniques.",None,-1
307b54bb-43af-4943-b22e-5ba9020a6be3,Diversity Enhanced Table-to-Text Generation via Type Control,0.271898,"Generating natural language statements to convey logical inferences from
tabular data (i.e., Logical NLG) is a process with one input and a variety of
valid outputs. This characteristic underscores the need for a method to produce
a diverse set of valid outputs, presenting different perspectives of the input
data. We propose a simple yet effective diversity-enhancing scheme that builds
upon an inherent property of the statements, their logic-types, by using a
type-controlled table-to-text generation model. We demonstrate, through
extensive automatic and human evaluations over the two publicly available
Logical NLG datasets, that our proposed method both facilitates the ability to
effectively control the generated statement type, and produces results superior
to the strongest baselines in terms of quality and factuality-diversity
trade-off.",None,8174
d5b94a73-a8ae-4727-ac36-3c5998d901ce,A Balanced Data Approach for Evaluating Cross-Lingual Transfer: Mapping the Linguistic Blood Bank,0.527381,"We show that the choice of pretraining languages affects downstream
cross-lingual transfer for BERT-based models. We inspect zero-shot performance
in balanced data conditions to mitigate data size confounds, classifying
pretraining languages that improve downstream performance as donors, and
languages that are improved in zero-shot performance as recipients. We develop
a method of quadratic time complexity in the number of languages to estimate
these relations, instead of an exponential exhaustive computation of all
possible combinations. We find that our method is effective on a diverse set of
languages spanning different linguistic features and two downstream tasks. Our
findings can inform developers of large-scale multilingual language models in
choosing better pretraining configurations.",https://github.com/SLAB-NLP/linguistic-blood-bank,-1
3d57336e-2f0e-405c-8d11-43ddd5fa561a,Deep Learning Reproducibility and Explainable AI (XAI),0.217851,"The nondeterminism of Deep Learning (DL) training algorithms and its
influence on the explainability of neural network (NN) models are investigated
in this work with the help of image classification examples. To discuss the
issue, two convolutional neural networks (CNN) have been trained and their
results compared. The comparison serves the exploration of the feasibility of
creating deterministic, robust DL models and deterministic explainable
artificial intelligence (XAI) in practice. Successes and limitation of all here
carried out efforts are described in detail. The source code of the attained
deterministic models has been listed in this work. Reproducibility is indexed
as a development-phase-component of the Model Governance Framework, proposed by
the EU within their excellence in AI approach. Furthermore, reproducibility is
a requirement for establishing causality for the interpretation of model
results and building of trust towards the overwhelming expansion of AI systems
applications. Problems that have to be solved on the way to reproducibility and
ways to deal with some of them, are examined in this work.",None,-1
6d738a39-5a7c-4a15-9fb6-d80b7a90f8d0,Will we run out of data? An analysis of the limits of scaling datasets in Machine Learning,0.708538,"We analyze the growth of dataset sizes used in machine learning for natural
language processing and computer vision, and extrapolate these using two
methods; using the historical growth rate and estimating the compute-optimal
dataset size for future predicted compute budgets. We investigate the growth in
data usage by estimating the total stock of unlabeled data available on the
internet over the coming decades. Our analysis indicates that the stock of
high-quality language data will be exhausted soon; likely before 2026. By
contrast, the stock of low-quality language data and image data will be
exhausted only much later; between 2030 and 2050 (for low-quality language) and
between 2030 and 2060 (for images). Our work suggests that the current trend of
ever-growing ML models that rely on enormous datasets might slow down if data
efficiency is not drastically improved or new sources of data become available.",https://github.com/epoch-research/data-stock,-1
31e4d9f1-923f-4b3d-8699-95f9ffca54ce,RbA: Segmenting Unknown Regions Rejected by All,0.97515,"Standard semantic segmentation models owe their success to curated datasets
with a fixed set of semantic categories, without contemplating the possibility
of identifying unknown objects from novel categories. Existing methods in
outlier detection suffer from a lack of smoothness and objectness in their
predictions, due to limitations of the per-pixel classification paradigm.
Furthermore, additional training for detecting outliers harms the performance
of known classes. In this paper, we explore another paradigm with region-level
classification to better segment unknown objects. We show that the object
queries in mask classification tend to behave like one \vs all classifiers.
Based on this finding, we propose a novel outlier scoring function called RbA
by defining the event of being an outlier as being rejected by all known
classes. Our extensive experiments show that mask classification improves the
performance of the existing outlier detection methods, and the best results are
achieved with the proposed RbA. We also propose an objective to optimize RbA
using minimal outlier supervision. Further fine-tuning with outliers improves
the unknown performance, and unlike previous methods, it does not degrade the
inlier performance.",None,-1
7b2745bf-3e24-42c9-b03c-27448fcaa9d0,Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence,0.715379,"The logical negation property (LNP), which implies generating different
predictions for semantically opposite inputs, is an important property that a
trustworthy language model must satisfy. However, much recent evidence shows
that large-size pre-trained language models (PLMs) do not satisfy this
property. In this paper, we perform experiments using probing tasks to assess
PLM's LNP understanding. Unlike previous studies that only examined negation
expressions, we expand the boundary of the investigation to lexical semantics.
Through experiments, we observe that PLMs violate the LNP frequently. To
alleviate the issue, we propose a novel intermediate training task, names
meaning-matching, designed to directly learn a meaning-text correspondence,
instead of relying on the distributional hypothesis. Through multiple
experiments, we find that the task enables PLMs to learn lexical semantic
information. Also, through fine-tuning experiments on 7 GLUE tasks, we confirm
that it is a safe intermediate task that guarantees a similar or better
performance of downstream tasks. Finally, we observe that our proposed approach
outperforms our previous counterparts despite its time and resource efficiency.",https://github.com/MJ-Jang/beyond-distributional,-1
8a44c4ee-8c74-4f75-acbf-dc75e9382121,Using Multi-Encoder Fusion Strategies to Improve Personalized Response Selection,0.44463,"Personalized response selection systems are generally grounded on persona.
However, there exists a co-relation between persona and empathy, which is not
explored well in these systems. Also, faithfulness to the conversation context
plunges when a contradictory or an off-topic response is selected. This paper
attempts to address these issues by proposing a suite of fusion strategies that
capture the interaction between persona, emotion, and entailment information of
the utterances. Ablation studies on the Persona-Chat dataset show that
incorporating emotion and entailment improves the accuracy of response
selection. We combine our fusion strategies and concept-flow encoding to train
a BERT-based model which outperforms the previous methods by margins larger
than 2.3 % on original personas and 1.9 % on revised personas in terms of
hits@1 (top-1 accuracy), achieving a new state-of-the-art performance on the
Persona-Chat dataset.",https://github.com/allenai/allennlp-models,-1
32a7df36-97dc-40b1-8134-edbb55c6fff3,A Simple but Effective Pluggable Entity Lookup Table for Pre-trained Language Models,0.287998,"Pre-trained language models (PLMs) cannot well recall rich factual knowledge
of entities exhibited in large-scale corpora, especially those rare entities.
In this paper, we propose to build a simple but effective Pluggable Entity
Lookup Table (PELT) on demand by aggregating the entity's output
representations of multiple occurrences in the corpora. PELT can be compatibly
plugged as inputs to infuse supplemental entity knowledge into PLMs. Compared
to previous knowledge-enhanced PLMs, PELT only requires 0.2%-5% pre-computation
with capability of acquiring knowledge from out-of-domain corpora for domain
adaptation scenario. The experiments on knowledge-related tasks demonstrate
that our method, PELT, can flexibly and effectively transfer entity knowledge
from related corpora into PLMs with different architectures.",https://github.com/thunlp/PELT,-1
807ebd9c-b0e7-4b2b-84f6-707e00661ab7,Learning One Abstract Bit at a Time Through Self-Invented Experiments Encoded as Neural Networks,0.0618876,"There are two important things in science: (A) Finding answers to given
questions, and (B) Coming up with good questions. Our artificial scientists not
only learn to answer given questions, but also continually invent new
questions, by proposing hypotheses to be verified or falsified through
potentially complex and time-consuming experiments, including thought
experiments akin to those of mathematicians. While an artificial scientist
expands its knowledge, it remains biased towards the simplest, least costly
experiments that still have surprising outcomes, until they become boring. We
present an empirical analysis of the automatic generation of interesting
experiments. In the first setting, we investigate self-invented experiments in
a reinforcement-providing environment and show that they lead to effective
exploration. In the second setting, pure thought experiments are implemented as
the weights of recurrent neural networks generated by a neural experiment
generator. Initially interesting thought experiments may become boring over
time.",None,-1
7125af32-8e82-4cf4-b63a-84bb1584ccd8,ANNA: Enhanced Language Representation for Question Answering,0.127614,"Pre-trained language models have brought significant improvements in
performance in a variety of natural language processing tasks. Most existing
models performing state-of-the-art results have shown their approaches in the
separate perspectives of data processing, pre-training tasks, neural network
modeling, or fine-tuning. In this paper, we demonstrate how the approaches
affect performance individually, and that the language model performs the best
results on a specific question answering task when those approaches are jointly
considered in pre-training models. In particular, we propose an extended
pre-training task, and a new neighbor-aware mechanism that attends neighboring
tokens more to capture the richness of context for pre-training language
modeling. Our best model achieves new state-of-the-art results of 95.7\% F1 and
90.6\% EM on SQuAD 1.1 and also outperforms existing pre-trained language
models such as RoBERTa, ALBERT, ELECTRA, and XLNet on the SQuAD 2.0 benchmark.",None,-1
1e3e426f-1a9d-45a3-b2df-a8ee3f8d62a0,FLAG: Flow-based 3D Avatar Generation from Sparse Observations,0.894228,"To represent people in mixed reality applications for collaboration and
communication, we need to generate realistic and faithful avatar poses.
However, the signal streams that can be applied for this task from head-mounted
devices (HMDs) are typically limited to head pose and hand pose estimates.
While these signals are valuable, they are an incomplete representation of the
human body, making it challenging to generate a faithful full-body avatar. We
address this challenge by developing a flow-based generative model of the 3D
human body from sparse observations, wherein we learn not only a conditional
distribution of 3D human pose, but also a probabilistic mapping from
observations to the latent space from which we can generate a plausible pose
along with uncertainty estimates for the joints. We show that our approach is
not only a strong predictive model, but can also act as an efficient pose prior
in different optimization settings where a good initial latent code plays a
major role.",https://microsoft.github.io/flag,-1
668e9b79-d94f-4513-9b4e-cbb4ba14d8f8,NeReF: Neural Refractive Field for Fluid Surface Reconstruction and Implicit Representation,0.45294,"Existing neural reconstruction schemes such as Neural Radiance Field (NeRF)
are largely focused on modeling opaque objects. We present a novel neural
refractive field(NeReF) to recover wavefront of transparent fluids by
simultaneously estimating the surface position and normal of the fluid front.
Unlike prior arts that treat the reconstruction target as a single layer of the
surface, NeReF is specifically formulated to recover a volumetric normal field
with its corresponding density field. A query ray will be refracted by NeReF
according to its accumulated refractive point and normal, and we employ the
correspondences and uniqueness of refracted ray for NeReF optimization. We show
NeReF, as a global optimization scheme, can more robustly tackle refraction
distortions detrimental to traditional methods for correspondence matching.
Furthermore, the continuous NeReF representation of wavefront enables view
synthesis as well as normal integration. We validate our approach on both
synthetic and real data and show it is particularly suitable for sparse
multi-view acquisition. We hence build a small light field array and experiment
on various surface shapes to demonstrate high fidelity NeReF reconstruction.",None,-1
a450c1e9-5fde-49cb-b9ed-204e6bdacb4e,ESCM$^2$: Entire Space Counterfactual Multi-Task Model for Post-Click Conversion Rate Estimation,0.97627,"Accurate estimation of post-click conversion rate is critical for building
recommender systems, which has long been confronted with sample selection bias
and data sparsity issues. Methods in the Entire Space Multi-task Model (ESMM)
family leverage the sequential pattern of user actions, i.e.
$impression\rightarrow click \rightarrow conversion$ to address data sparsity
issue. However, they still fail to ensure the unbiasedness of CVR estimates. In
this paper, we theoretically demonstrate that ESMM suffers from the following
two problems: (1) Inherent Estimation Bias (IEB), where the estimated CVR of
ESMM is inherently higher than the ground truth; (2) Potential Independence
Priority (PIP) for CTCVR estimation, where there is a risk that the ESMM
overlooks the causality from click to conversion. To this end, we devise a
principled approach named Entire Space Counterfactual Multi-task Modelling
(ESCM$^2$), which employs a counterfactual risk miminizer as a regularizer in
ESMM to address both IEB and PIP issues simultaneously. Extensive experiments
on offline datasets and online environments demonstrate that our proposed
ESCM$^2$ can largely mitigate the inherent IEB and PIP issues and achieve
better performance than baseline models.",https://github.com/PaddlePaddle/PaddleRec/tree/master/models/multitask,-1
b4949ef8-6b58-4a1e-8726-da9e0d430d58,Referee: Reference-Free Sentence Summarization with Sharper Controllability through Symbolic Knowledge Distillation,0.447913,"We present Referee, a novel framework for sentence summarization that can be
trained reference-free (i.e., requiring no gold summaries for supervision),
while allowing direct control for compression ratio. Our work is the first to
demonstrate that reference-free, controlled sentence summarization is feasible
via the conceptual framework of Symbolic Knowledge Distillation (West et al.,
2022), where latent knowledge in pre-trained language models is distilled via
explicit examples sampled from the teacher models, further purified with three
types of filters: length, fidelity, and Information Bottleneck. Moreover, we
uniquely propose iterative distillation of knowledge, where student models from
the previous iteration of distillation serve as teacher models in the next
iteration. Starting off from a relatively modest set of GPT3-generated
summaries, we demonstrate how iterative knowledge distillation can lead to
considerably smaller, but better summarizers with sharper controllability. A
useful by-product of this iterative distillation process is a high-quality
dataset of sentence-summary pairs with varying degrees of compression ratios.
Empirical results demonstrate that the final student models vastly outperform
the much larger GPT3-Instruct model in terms of the controllability of
compression ratios, without compromising the quality of resulting
summarization.",https://github.com/msclar/referee,-1
48e2af5f-b5c4-477f-b491-02dcb7189395,VALHALLA: Visual Hallucination for Machine Translation,0.908053,"Designing better machine translation systems by considering auxiliary inputs
such as images has attracted much attention in recent years. While existing
methods show promising performance over the conventional text-only translation
systems, they typically require paired text and image as input during
inference, which limits their applicability to real-world scenarios. In this
paper, we introduce a visual hallucination framework, called VALHALLA, which
requires only source sentences at inference time and instead uses hallucinated
visual representations for multimodal machine translation. In particular, given
a source sentence an autoregressive hallucination transformer is used to
predict a discrete visual representation from the input text, and the combined
text and hallucinated representations are utilized to obtain the target
translation. We train the hallucination transformer jointly with the
translation transformer using standard backpropagation with cross-entropy
losses while being guided by an additional loss that encourages consistency
between predictions using either ground-truth or hallucinated visual
representations. Extensive experiments on three standard translation datasets
with a diverse set of language pairs demonstrate the effectiveness of our
approach over both text-only baselines and state-of-the-art methods. Project
page: http://www.svcl.ucsd.edu/projects/valhalla.",http://www.svcl.ucsd.edu/projects/valhalla,-1
0fd8e45e-d551-43b8-bc5a-a85d2dd1d157,Flattening-Net: Deep Regular 2D Representation for 3D Point Cloud Analysis,0.59808,"Point clouds are characterized by irregularity and unstructuredness, which
pose challenges in efficient data exploitation and discriminative feature
extraction. In this paper, we present an unsupervised deep neural architecture
called Flattening-Net to represent irregular 3D point clouds of arbitrary
geometry and topology as a completely regular 2D point geometry image (PGI)
structure, in which coordinates of spatial points are captured in colors of
image pixels. \mr{Intuitively, Flattening-Net implicitly approximates a locally
smooth 3D-to-2D surface flattening process while effectively preserving
neighborhood consistency.} \mr{As a generic representation modality, PGI
inherently encodes the intrinsic property of the underlying manifold structure
and facilitates surface-style point feature aggregation.} To demonstrate its
potential, we construct a unified learning framework directly operating on PGIs
to achieve \mr{diverse types of high-level and low-level} downstream
applications driven by specific task networks, including classification,
segmentation, reconstruction, and upsampling. Extensive experiments demonstrate
that our methods perform favorably against the current state-of-the-art
competitors. We will make the code and data publicly available at
https://github.com/keeganhk/Flattening-Net.",https://github.com/keeganhk/Flattening-Net,9714
9244ef98-899c-47be-9056-95f777a91080,Gold Doesn't Always Glitter: Spectral Removal of Linear and Nonlinear Guarded Attribute Information,0.671592,"We describe a simple and effective method (Spectral Attribute removaL; SAL)
to remove private or guarded information from neural representations. Our
method uses matrix decomposition to project the input representations into
directions with reduced covariance with the guarded information rather than
maximal covariance as factorization methods normally use. We begin with linear
information removal and proceed to generalize our algorithm to the case of
nonlinear information removal using kernels. Our experiments demonstrate that
our algorithm retains better main task performance after removing the guarded
information compared to previous work. In addition, our experiments demonstrate
that we need a relatively small amount of guarded attribute data to remove
information about these attributes, which lowers the exposure to sensitive data
and is more suitable for low-resource scenarios. Code is available at
https://github.com/jasonshaoshun/SAL.",https://github.com/jasonshaoshun/SAL,-1
838b60c3-21e6-46ab-9dfb-180340828a16,Towards Self-Supervised Learning of Global and Object-Centric Representations,0.238074,"Self-supervision allows learning meaningful representations of natural
images, which usually contain one central object. How well does it transfer to
multi-entity scenes? We discuss key aspects of learning structured
object-centric representations with self-supervision and validate our insights
through several experiments on the CLEVR dataset. Regarding the architecture,
we confirm the importance of competition for attention-based object discovery,
where each image patch is exclusively attended by one object. For training, we
show that contrastive losses equipped with matching can be applied directly in
a latent space, avoiding pixel-based reconstruction. However, such an
optimization objective is sensitive to false negatives (recurring objects) and
false positives (matching errors). Careful consideration is thus required
around data augmentation and negative sample selection.",https://github.com/baldassarreFe/iclr-osc-22,-1
ee317e08-ef11-4090-bfa1-ccacfbc33fe6,Improving Policy Learning via Language Dynamics Distillation,0.397633,"Recent work has shown that augmenting environments with language descriptions
improves policy learning. However, for environments with complex language
abstractions, learning how to ground language to observations is difficult due
to sparse, delayed rewards. We propose Language Dynamics Distillation (LDD),
which pretrains a model to predict environment dynamics given demonstrations
with language descriptions, and then fine-tunes these language-aware pretrained
representations via reinforcement learning (RL). In this way, the model is
trained to both maximize expected reward and retain knowledge about how
language relates to environment dynamics. On SILG, a benchmark of five tasks
with language descriptions that evaluate distinct generalization challenges on
unseen environments (NetHack, ALFWorld, RTFM, Messenger, and Touchdown), LDD
outperforms tabula-rasa RL, VAE pretraining, and methods that learn from
unlabeled demonstrations in inverse RL and reward shaping with pretrained
experts. In our analyses, we show that language descriptions in demonstrations
improve sample-efficiency and generalization across environments, and that
dynamics modelling with expert demonstrations is more effective than with
non-experts.",https://github.com/vzhong/language-dynamics-distillation,-1
144ade57-96fb-4ee5-971d-82505756f001,Modeling Multi-interest News Sequence for News Recommendation,0.0508147,"A session-based news recommender system recommends the next news to a user by
modeling the potential interests embedded in a sequence of news read/clicked by
her/him in a session. Generally, a user's interests are diverse, namely there
are multiple interests corresponding to different types of news, e.g., news of
distinct topics, within a session. %Modeling such multiple interests is
critical for precise news recommendation. However, most of existing methods
typically overlook such important characteristic and thus fail to distinguish
and model the potential multiple interests of a user, impeding accurate
recommendation of the next piece of news. Therefore, this paper proposes
multi-interest news sequence (MINS) model for news recommendation. In MINS, a
news encoder based on self-attention is devised on learn an informative
embedding for each piece of news, and then a novel parallel interest network is
devised to extract the potential multiple interests embedded in the news
sequence in preparation for the subsequent next-news recommendations. The
experimental results on a real-world dataset demonstrate that our model can
achieve better performance than the state-of-the-art compared models.",https://github.com/whonor/MINS,-1
a5b88d15-9753-4a7c-8cee-8924424732d2,F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models,0.996434,"We present F-VLM, a simple open-vocabulary object detection method built upon
Frozen Vision and Language Models. F-VLM simplifies the current multi-stage
training pipeline by eliminating the need for knowledge distillation or
detection-tailored pretraining. Surprisingly, we observe that a frozen VLM: 1)
retains the locality-sensitive features necessary for detection, and 2) is a
strong region classifier. We finetune only the detector head and combine the
detector and VLM outputs for each region at inference time. F-VLM shows
compelling scaling behavior and achieves +6.5 mask AP improvement over the
previous state of the art on novel categories of LVIS open-vocabulary detection
benchmark. In addition, we demonstrate very competitive results on COCO
open-vocabulary detection benchmark and cross-dataset transfer detection, in
addition to significant training speed-up and compute savings. Code will be
released at the https://sites.google.com/view/f-vlm/home",https://github.com/facebookresearch/detectron2,-1
1259f461-e3ec-4ff4-9b43-f0a69172b844,Putting AI Ethics into Practice: The Hourglass Model of Organizational AI Governance,0.543743,"The organizational use of artificial intelligence (AI) has rapidly spread
across various sectors. Alongside the awareness of the benefits brought by AI,
there is a growing consensus on the necessity of tackling the risks and
potential harms, such as bias and discrimination, brought about by advanced AI
technologies. A multitude of AI ethics principles have been proposed to tackle
these risks, but the outlines of organizational processes and practices for
ensuring socially responsible AI development are in a nascent state. To address
the paucity of comprehensive governance models, we present an AI governance
framework, the hourglass model of organizational AI governance, which targets
organizations that develop and use AI systems. The framework is designed to
help organizations deploying AI systems translate ethical AI principles into
practice and align their AI systems and processes with the forthcoming European
AI Act. The hourglass framework includes governance requirements at the
environmental, organizational, and AI system levels. At the AI system level, we
connect governance requirements to AI system life cycles to ensure governance
throughout the system's life span. The governance model highlights the systemic
nature of AI governance and opens new research avenues into its practical
implementation, the mechanisms that connect different AI governance layers, and
the dynamics between the AI governance actors. The model also offers a starting
point for organizational decision-makers to consider the governance components
needed to ensure social acceptability, mitigate risks, and realize the
potential of AI.",None,-1
8e7576a2-1147-4daa-bd45-29efbc5704de,Beyond English-Centric Bitexts for Better Multilingual Language Representation Learning,0.691008,"In this paper, we elaborate upon recipes for building multilingual
representation models that are not only competitive with existing
state-of-the-art models but are also more parameter efficient, thereby
promoting better adoption in resource-constrained scenarios and practical
applications. We show that going beyond English-centric bitexts, coupled with a
novel sampling strategy aimed at reducing under-utilization of training data,
substantially boosts performance across model sizes for both Electra and MLM
pre-training objectives. We introduce XY-LENT: X-Y bitext enhanced Language
ENcodings using Transformers which not only achieves state-of-the-art
performance over 5 cross-lingual tasks within all model size bands, is also
competitive across bands. Our XY-LENT XL variant outperforms XLM-RXXL and
exhibits competitive performance with mT5 XXL while being 5x and 6x smaller
respectively. We then show that our proposed method helps ameliorate the curse
of multilinguality, with the XY-LENT XL achieving 99.3% GLUE performance and
98.5% SQuAD 2.0 performance compared to a SoTA English only model in the same
size band. We then analyze our models performance on extremely low resource
languages and posit that scaling alone may not be sufficient for improving the
performance in this scenario",None,-1
5b40bdcd-7799-409d-b565-5ff5ba5d9b51,Natural Language Specifications in Proof Assistants,0.0651355,"Interactive proof assistants are computer programs carefully constructed to
check a human-designed proof of a mathematical claim with high confidence in
the implementation. However, this only validates truth of a formal claim, which
may have been mistranslated from a claim made in natural language. This is
especially problematic when using proof assistants to formally verify the
correctness of software with respect to a natural language specification. The
translation from informal to formal remains a challenging, time-consuming
process that is difficult to audit for correctness. This paper argues that it
is possible to build support for natural language specifications within
existing proof assistants, in a way that complements the principles used to
establish trust and auditability in proof assistants themselves.",None,-1
a5e2b5f3-70a6-4831-a06d-83a7f8b29749,Guiding Attention using Partial-Order Relationships for Image Captioning,0.245772,"The use of attention models for automated image captioning has enabled many
systems to produce accurate and meaningful descriptions for images. Over the
years, many novel approaches have been proposed to enhance the attention
process using different feature representations. In this paper, we extend this
approach by creating a guided attention network mechanism, that exploits the
relationship between the visual scene and text-descriptions using spatial
features from the image, high-level information from the topics, and temporal
context from caption generation, which are embedded together in an ordered
embedding space. A pairwise ranking objective is used for training this
embedding space which allows similar images, topics and captions in the shared
semantic space to maintain a partial order in the visual-semantic hierarchy and
hence, helps the model to produce more visually accurate captions. The
experimental results based on MSCOCO dataset shows the competitiveness of our
approach, with many state-of-the-art models on various evaluation metrics.",None,-1
e4e1dfbc-ba39-4e21-b33d-60e3def1534b,Tables to LaTeX: structure and content extraction from scientific tables,0.283651,"Scientific documents contain tables that list important information in a
concise fashion. Structure and content extraction from tables embedded within
PDF research documents is a very challenging task due to the existence of
visual features like spanning cells and content features like mathematical
symbols and equations. Most existing table structure identification methods
tend to ignore these academic writing features. In this paper, we adapt the
transformer-based language modeling paradigm for scientific table structure and
content extraction. Specifically, the proposed model converts a tabular image
to its corresponding LaTeX source code. Overall, we outperform the current
state-of-the-art baselines and achieve an exact match accuracy of 70.35 and
49.69% on table structure and content extraction, respectively. Further
analysis demonstrates that the proposed models efficiently identify the number
of rows and columns, the alphanumeric characters, the LaTeX tokens, and
symbols.",https://tinyurl.com/ydbw9asp,-1
2fb23e8b-104c-4522-a849-71f84ad115ec,Search to Pass Messages for Temporal Knowledge Graph Completion,0.60653,"Completing missing facts is a fundamental task for temporal knowledge graphs
(TKGs). Recently, graph neural network (GNN) based methods, which can
simultaneously explore topological and temporal information, have become the
state-of-the-art (SOTA) to complete TKGs. However, these studies are based on
hand-designed architectures and fail to explore the diverse topological and
temporal properties of TKG. To address this issue, we propose to use neural
architecture search (NAS) to design data-specific message passing architecture
for TKG completion. In particular, we develop a generalized framework to
explore topological and temporal information in TKGs. Based on this framework,
we design an expressive search space to fully capture various properties of
different TKGs. Meanwhile, we adopt a search algorithm, which trains a supernet
structure by sampling single path for efficient search with less cost. We
further conduct extensive experiments on three benchmark datasets. The results
show that the searched architectures by our method achieve the SOTA
performances. Besides, the searched models can also implicitly reveal diverse
properties in different TKGs. Our code is released in
https://github.com/striderdu/SPA.",https://github.com/striderdu/SPA,9577
77b19317-aa5d-449d-9655-aaa6ab8fee09,A Variational Hierarchical Model for Neural Cross-Lingual Summarization,0.895683,"The goal of the cross-lingual summarization (CLS) is to convert a document in
one language (e.g., English) to a summary in another one (e.g., Chinese).
Essentially, the CLS task is the combination of machine translation (MT) and
monolingual summarization (MS), and thus there exists the hierarchical
relationship between MT\&MS and CLS. Existing studies on CLS mainly focus on
utilizing pipeline methods or jointly training an end-to-end model through an
auxiliary MT or MS objective. However, it is very challenging for the model to
directly conduct CLS as it requires both the abilities to translate and
summarize. To address this issue, we propose a hierarchical model for the CLS
task, based on the conditional variational auto-encoder. The hierarchical model
contains two kinds of latent variables at the local and global levels,
respectively. At the local level, there are two latent variables, one for
translation and the other for summarization. As for the global level, there is
another latent variable for cross-lingual summarization conditioned on the two
local-level variables. Experiments on two language directions (English-Chinese)
verify the effectiveness and superiority of the proposed approach. In addition,
we show that our model is able to generate better cross-lingual summaries than
comparison models in the few-shot setting.",https://github.com/XL2248/VHM,-1
48f86cfd-0178-48ff-b9c7-a4edde57d61f,Knowledge Sharing via Domain Adaptation in Customs Fraud Detection,0.634039,"Knowledge of the changing traffic is critical in risk management. Customs
offices worldwide have traditionally relied on local resources to accumulate
knowledge and detect tax fraud. This naturally poses countries with weak
infrastructure to become tax havens of potentially illicit trades. The current
paper proposes DAS, a memory bank platform to facilitate knowledge sharing
across multi-national customs administrations to support each other. We propose
a domain adaptation method to share transferable knowledge of frauds as
prototypes while safeguarding the local trade information. Data encompassing
over 8 million import declarations have been used to test the feasibility of
this new system, which shows that participating countries may benefit up to
2-11 times in fraud detection with the help of shared knowledge. We discuss
implications for substantial tax revenue potential and strengthened policy
against illicit trades.",None,-1
3e6f33d4-d399-4963-afaa-a429b195cc11,On the Robustness of Dialogue History Representation in Conversational Question Answering: A Comprehensive Study and a New Prompt-based Method,0.465233,"Most works on modeling the conversation history in Conversational Question
Answering (CQA) report a single main result on a common CQA benchmark. While
existing models show impressive results on CQA leaderboards, it remains unclear
whether they are robust to shifts in setting (sometimes to more realistic
ones), training data size (e.g. from large to small sets) and domain. In this
work, we design and conduct the first large-scale robustness study of history
modeling approaches for CQA. We find that high benchmark scores do not
necessarily translate to strong robustness, and that various methods can
perform extremely differently under different settings. Equipped with the
insights from our study, we design a novel prompt-based history modeling
approach, and demonstrate its strong robustness across various settings. Our
approach is inspired by existing methods that highlight historic answers in the
passage. However, instead of highlighting by modifying the passage token
embeddings, we add textual prompts directly in the passage text. Our approach
is simple, easy-to-plug into practically any model, and highly effective, thus
we recommend it as a starting point for future model developers. We also hope
that our study and insights will raise awareness to the importance of
robustness-focused evaluation, in addition to obtaining high leaderboard
scores, leading to better CQA systems.",https://github.com/zorikg/MarCQAp,-1
a482421f-ac67-490f-9578-fb8cbe8e0162,The Phenomenon of Policy Churn,0.480338,"We identify and study the phenomenon of policy churn, that is, the rapid
change of the greedy policy in value-based reinforcement learning. Policy churn
operates at a surprisingly rapid pace, changing the greedy action in a large
fraction of states within a handful of learning updates (in a typical deep RL
set-up such as DQN on Atari). We characterise the phenomenon empirically,
verifying that it is not limited to specific algorithm or environment
properties. A number of ablations help whittle down the plausible explanations
on why churn occurs to just a handful, all related to deep learning. Finally,
we hypothesise that policy churn is a beneficial but overlooked form of
implicit exploration that casts $\epsilon$-greedy exploration in a fresh light,
namely that $\epsilon$-noise plays a much smaller role than expected.",https://github.com/deepmind/deepmind-research/tree/master/tandem_dqn,-1
a566c86d-17c3-42df-84ac-ac9b8885d812,Unsupervised Domain Adaptation Based on the Predictive Uncertainty of Models,0.454371,"Unsupervised domain adaptation (UDA) aims to improve the prediction
performance in the target domain under distribution shifts from the source
domain. The key principle of UDA is to minimize the divergence between the
source and the target domains. To follow this principle, many methods employ a
domain discriminator to match the feature distributions. Some recent methods
evaluate the discrepancy between two predictions on target samples to detect
those that deviate from the source distribution. However, their performance is
limited because they either match the marginal distributions or measure the
divergence conservatively. In this paper, we present a novel UDA method that
learns domain-invariant features that minimize the domain divergence. We
propose model uncertainty as a measure of the domain divergence. Our UDA method
based on model uncertainty (MUDA) adopts a Bayesian framework and provides an
efficient way to evaluate model uncertainty by means of Monte Carlo dropout
sampling. Empirical results on image recognition tasks show that our method is
superior to existing state-of-the-art methods. We also extend MUDA to
multi-source domain adaptation problems.",https://github.com/joonholee-research/MUDA,-1
07a9f5c1-8d3d-4cb0-98f5-0e6c4c2a37a7,I Know What You Do Not Know: Knowledge Graph Embedding via Co-distillation Learning,0.680076,"Knowledge graph (KG) embedding seeks to learn vector representations for
entities and relations. Conventional models reason over graph structures, but
they suffer from the issues of graph incompleteness and long-tail entities.
Recent studies have used pre-trained language models to learn embeddings based
on the textual information of entities and relations, but they cannot take
advantage of graph structures. In the paper, we show empirically that these two
kinds of features are complementary for KG embedding. To this end, we propose
CoLE, a Co-distillation Learning method for KG Embedding that exploits the
complementarity of graph structures and text information. Its graph embedding
model employs Transformer to reconstruct the representation of an entity from
its neighborhood subgraph. Its text embedding model uses a pre-trained language
model to generate entity representations from the soft prompts of their names,
descriptions, and relational neighbors. To let the two model promote each
other, we propose co-distillation learning that allows them to distill
selective knowledge from each other's prediction logits. In our co-distillation
learning, each model serves as both a teacher and a student. Experiments on
benchmark datasets demonstrate that the two models outperform their related
baselines, and the ensemble method CoLE with co-distillation learning advances
the state-of-the-art of KG embedding.",https://github.com/nju-websoft/CoLE,11617
f893b09c-f526-4d28-8508-4572a4e72def,Transformer-based Approaches for Legal Text Processing,0.234913,"In this paper, we introduce our approaches using Transformer-based models for
different problems of the COLIEE 2021 automatic legal text processing
competition. Automated processing of legal documents is a challenging task
because of the characteristics of legal documents as well as the limitation of
the amount of data. With our detailed experiments, we found that
Transformer-based pretrained language models can perform well with automated
legal text processing problems with appropriate approaches. We describe in
detail the processing steps for each task such as problem formulation, data
processing and augmentation, pretraining, finetuning. In addition, we introduce
to the community two pretrained models that take advantage of parallel
translations in legal domain, NFSP and NMSP. In which, NFSP achieves the
state-of-the-art result in Task 5 of the competition. Although the paper
focuses on technical reporting, the novelty of its approaches can also be an
useful reference in automated legal document processing using Transformer-based
models.",None,-1
900e2723-856a-467e-8057-13af8bd3de23,A Hierarchical Interactive Network for Joint Span-based Aspect-Sentiment Analysis,0.408954,"Recently, some span-based methods have achieved encouraging performances for
joint aspect-sentiment analysis, which first extract aspects (aspect
extraction) by detecting aspect boundaries and then classify the span-level
sentiments (sentiment classification). However, most existing approaches either
sequentially extract task-specific features, leading to insufficient feature
interactions, or they encode aspect features and sentiment features in a
parallel manner, implying that feature representation in each task is largely
independent of each other except for input sharing. Both of them ignore the
internal correlations between the aspect extraction and sentiment
classification. To solve this problem, we novelly propose a hierarchical
interactive network (HI-ASA) to model two-way interactions between two tasks
appropriately, where the hierarchical interactions involve two steps:
shallow-level interaction and deep-level interaction. First, we utilize
cross-stitch mechanism to combine the different task-specific features
selectively as the input to ensure proper two-way interactions. Second, the
mutual information technique is applied to mutually constrain learning between
two tasks in the output layer, thus the aspect input and the sentiment input
are capable of encoding features of the other task via backpropagation.
Extensive experiments on three real-world datasets demonstrate HI-ASA's
superiority over baselines.",https://github.com/cwei01/HI-ASA,-1
c59930cf-8a0d-437f-8066-a68598bbfc4b,Gradient-based Uncertainty for Monocular Depth Estimation,0.808156,"In monocular depth estimation, disturbances in the image context, like moving
objects or reflecting materials, can easily lead to erroneous predictions. For
that reason, uncertainty estimates for each pixel are necessary, in particular
for safety-critical applications such as automated driving. We propose a post
hoc uncertainty estimation approach for an already trained and thus fixed depth
estimation model, represented by a deep neural network. The uncertainty is
estimated with the gradients which are extracted with an auxiliary loss
function. To avoid relying on ground-truth information for the loss definition,
we present an auxiliary loss function based on the correspondence of the depth
prediction for an image and its horizontally flipped counterpart. Our approach
achieves state-of-the-art uncertainty estimation results on the KITTI and NYU
Depth V2 benchmarks without the need to retrain the neural network. Models and
code are publicly available at https://github.com/jhornauer/GrUMoDepth.",https://github.com/jhornauer/GrUMoDepth,-1
3fdc6efd-84b7-4f62-bdff-a77694a18188,Training Language Models with Memory Augmentation,0.935083,"Recent work has improved language models (LMs) remarkably by equipping them
with a non-parametric memory component. However, most existing approaches only
introduce mem-ories at testing time or represent them using a separately
trained encoder, resulting in suboptimal training of the language model. In
this work, we present TRIME, a novel yet simple training approach designed for
training LMs with memory augmentation. Our approach uses a training objective
that directly takes in-batch examples as accessible memory. We also present new
methods for memory construction and data batching, which are used for adapting
to different sets of memories--local, long-term, and external memory--at
testing time. We evaluate TRIME on multiple language modeling and machine
translation benchmarks and show that it is able to achieve significant
improvements across all the settings. Concretely, TRIME reduces the perplexity
from 18.70 to 15.37 on WIKITEXT-103, by effectively leveraging a large memory
set from the training corpus. Compared to standard LM training, TRIME adds
negligible computational overhead and is compatible with different neural
architectures, making it a versatile solution for training memory-augmented
LMs.",https://github.com/princeton-nlp/TRIME,49836
e6d4d305-e2ed-4b0e-a434-cfc655f4c034,Knowledge Transfer For On-Device Speech Emotion Recognition with Neural Structured Learning,0.155407,"Speech emotion recognition (SER) has been a popular research topic in
human-computer interaction (HCI). As edge devices are rapidly springing up,
applying SER to edge devices is promising for a huge number of HCI
applications. Although deep learning has been investigated to improve the
performance of SER by training complex models, the memory space and
computational capability of edge devices represents a constraint for embedding
deep learning models. We propose a neural structured learning (NSL) framework
through building synthesized graphs. An SER model is trained on a source
dataset and used to build graphs on a target dataset. A relatively lightweight
model is then trained with the speech samples and graphs together as the input.
Our experiments demonstrate that training a lightweight SER model on the target
dataset with speech samples and graphs can not only produce small SER models,
but also enhance the model performance compared to models with speech samples
only and those using classic transfer learning strategies.",https://github.com/glam-imperial/NSL-SER,-1
fef69058-fc01-4078-a071-198850ef4d80,Improving Zero-Shot Event Extraction via Sentence Simplification,0.348123,"The success of sites such as ACLED and Our World in Data have demonstrated
the massive utility of extracting events in structured formats from large
volumes of textual data in the form of news, social media, blogs and discussion
forums. Event extraction can provide a window into ongoing geopolitical crises
and yield actionable intelligence. With the proliferation of large pretrained
language models, Machine Reading Comprehension (MRC) has emerged as a new
paradigm for event extraction in recent times. In this approach, event argument
extraction is framed as an extractive question-answering task. One of the key
advantages of the MRC-based approach is its ability to perform zero-shot
extraction. However, the problem of long-range dependencies, i.e., large
lexical distance between trigger and argument words and the difficulty of
processing syntactically complex sentences plague MRC-based approaches. In this
paper, we present a general approach to improve the performance of MRC-based
event extraction by performing unsupervised sentence simplification guided by
the MRC model itself. We evaluate our approach on the ICEWS geopolitical event
extraction dataset, with specific attention to `Actor' and `Target' argument
roles. We show how such context simplification can improve the performance of
MRC-based event extraction by more than 5% for actor extraction and more than
10% for target extraction.",https://github.com/allenai/allennlp-models/blob/main/allennlp_models/rc/models/transformer_qa.py,-1
1976db2a-b140-4f4d-95d9-dcc4288a1f03,Diverse Imagenet Models Transfer Better,0.711708,"A commonly accepted hypothesis is that models with higher accuracy on
Imagenet perform better on other downstream tasks, leading to much research
dedicated to optimizing Imagenet accuracy. Recently this hypothesis has been
challenged by evidence showing that self-supervised models transfer better than
their supervised counterparts, despite their inferior Imagenet accuracy. This
calls for identifying the additional factors, on top of Imagenet accuracy, that
make models transferable. In this work we show that high diversity of the
features learnt by the model promotes transferability jointly with Imagenet
accuracy. Encouraged by the recent transferability results of self-supervised
models, we propose a method that combines self-supervised and supervised
pretraining to generate models with both high diversity and high accuracy, and
as a result high transferability. We demonstrate our results on several
architectures and multiple downstream tasks, including both single-label and
multi-label classification.",None,14108
edabe391-e692-4280-8ca3-404d0c0270c5,DepthFake: a depth-based strategy for detecting Deepfake videos,0.0996557,"Fake content has grown at an incredible rate over the past few years. The
spread of social media and online platforms makes their dissemination on a
large scale increasingly accessible by malicious actors. In parallel, due to
the growing diffusion of fake image generation methods, many Deep
Learning-based detection techniques have been proposed. Most of those methods
rely on extracting salient features from RGB images to detect through a binary
classifier if the image is fake or real. In this paper, we proposed DepthFake,
a study on how to improve classical RGB-based approaches with depth-maps. The
depth information is extracted from RGB images with recent monocular depth
estimation techniques. Here, we demonstrate the effective contribution of
depth-maps to the deepfake detection task on robust pre-trained architectures.
The proposed RGBD approach is in fact able to achieve an average improvement of
3.20% and up to 11.7% for some deepfake attacks with respect to standard RGB
architectures over the FaceForensic++ dataset.",None,-1
e0e0cd8d-10f3-4170-8e48-2813d75b8b86,Anticipation-Free Training for Simultaneous Machine Translation,0.246442,"Simultaneous machine translation (SimulMT) speeds up the translation process
by starting to translate before the source sentence is completely available. It
is difficult due to limited context and word order difference between
languages. Existing methods increase latency or introduce adaptive read-write
policies for SimulMT models to handle local reordering and improve translation
quality. However, the long-distance reordering would make the SimulMT models
learn translation mistakenly. Specifically, the model may be forced to predict
target tokens when the corresponding source tokens have not been read. This
leads to aggressive anticipation during inference, resulting in the
hallucination phenomenon. To mitigate this problem, we propose a new framework
that decompose the translation process into the monotonic translation step and
the reordering step, and we model the latter by the auxiliary sorting network
(ASN). The ASN rearranges the hidden states to match the order in the target
language, so that the SimulMT model could learn to translate more reasonably.
The entire model is optimized end-to-end and does not rely on external aligners
or data. During inference, ASN is removed to achieve streaming. Experiments
show the proposed framework could outperform previous methods with less
latency.",https://github.com/George0828Zhang/sinkhorn-simultrans,-1
55db59b8-28e4-42d0-85ac-0306f209fdbd,Evaluating Human-Language Model Interaction,0.951541,"Many real-world applications of language models (LMs), such as writing
assistance and code autocomplete, involve human-LM interaction. However, most
benchmarks are non-interactive in that a model produces output without human
involvement. To evaluate human-LM interaction, we develop a new framework,
Human-AI Language-based Interaction Evaluation (HALIE), that defines the
components of interactive systems and dimensions to consider when designing
evaluation metrics. Compared to standard, non-interactive evaluation, HALIE
captures (i) the interactive process, not only the final output; (ii) the
first-person subjective experience, not just a third-party assessment; and
(iii) notions of preference beyond quality (e.g., enjoyment and ownership). We
then design five tasks to cover different forms of interaction: social
dialogue, question answering, crossword puzzles, summarization, and metaphor
generation. With four state-of-the-art LMs (three variants of OpenAI's GPT-3
and AI21 Labs' Jurassic-1), we find that better non-interactive performance
does not always translate to better human-LM interaction. In particular, we
highlight three cases where the results from non-interactive and interactive
metrics diverge and underscore the importance of human-LM interaction for LM
evaluation.",https://github.com/stanford-crfm/halie,-1
c8852bbd-b02e-446d-acf3-a49b08469e7d,Motion-aware Dynamic Graph Neural Network for Video Compressive Sensing,0.205459,"Video snapshot compressive imaging (SCI) utilizes a 2D detector to capture
sequential video frames and compresses them into a single measurement. Various
reconstruction methods have been developed to recover the high-speed video
frames from the snapshot measurement. However, most existing reconstruction
methods are incapable of capturing long-range spatial and temporal
dependencies, which are critical for video processing. In this paper, we
propose a flexible and robust approach based on graph neural network (GNN) to
efficiently model non-local interactions between pixels in space as well as
time regardless of the distance. Specifically, we develop a motion-aware
dynamic GNN for better video representation, i.e., represent each pixel as the
aggregation of relative nodes under the guidance of frame-by-frame motions,
which consists of motion-aware dynamic sampling, cross-scale node sampling and
graph aggregation. Extensive results on both simulation and real data
demonstrate both the effectiveness and efficiency of the proposed approach, and
the visualization clearly illustrates the intrinsic dynamic sampling operations
of our proposed model for boosting the video SCI reconstruction results. The
code and models will be released to the public.",None,-1
a5dc7dc7-3ef5-4d44-874d-fbc29da71c9e,LETS-GZSL: A Latent Embedding Model for Time Series Generalized Zero Shot Learning,0.158585,"One of the recent developments in deep learning is generalized zero-shot
learning (GZSL), which aims to recognize objects from both seen and unseen
classes, when only the labeled examples from seen classes are provided. Over
the past couple of years, GZSL has picked up traction and several models have
been proposed to solve this problem. Whereas an extensive amount of research on
GZSL has been carried out in fields such as computer vision and natural
language processing, no such research has been carried out to deal with time
series data. GZSL is used for applications such as detecting abnormalities from
ECG and EEG data and identifying unseen classes from sensor, spectrograph and
other devices' data. In this regard, we propose a Latent Embedding for Time
Series - GZSL (LETS-GZSL) model that can solve the problem of GZSL for time
series classification (TSC). We utilize an embedding-based approach and combine
it with attribute vectors to predict the final class labels. We report our
results on the widely popular UCR archive datasets. Our framework is able to
achieve a harmonic mean value of at least 55% on most of the datasets except
when the number of unseen classes is greater than 3 or the amount of data is
very low (less than 100 training examples).",None,-1
273b4935-46f0-4515-a2cc-9e497b78024f,Mingling Foresight with Imagination: Model-Based Cooperative Multi-Agent Reinforcement Learning,0.142556,"Recently, model-based agents have achieved better performance than model-free
ones using the same computational budget and training time in single-agent
environments. However, due to the complexity of multi-agent systems, it is
tough to learn the model of the environment. The significant compounding error
may hinder the learning process when model-based methods are applied to
multi-agent tasks. This paper proposes an implicit model-based multi-agent
reinforcement learning method based on value decomposition methods. Under this
method, agents can interact with the learned virtual environment and evaluate
the current state value according to imagined future states in the latent
space, making agents have the foresight. Our approach can be applied to any
multi-agent value decomposition method. The experimental results show that our
method improves the sample efficiency in different partially observable Markov
decision process domains.",None,-1
ff4ad3b0-30a0-4656-aef8-1144345ff616,Data-driven Feature Tracking for Event Cameras,0.957945,"Because of their high temporal resolution, increased resilience to motion
blur, and very sparse output, event cameras have been shown to be ideal for
low-latency and low-bandwidth feature tracking, even in challenging scenarios.
Existing feature tracking methods for event cameras are either handcrafted or
derived from first principles but require extensive parameter tuning, are
sensitive to noise, and do not generalize to different scenarios due to
unmodeled effects. To tackle these deficiencies, we introduce the first
data-driven feature tracker for event cameras, which leverages low-latency
events to track features detected in a grayscale frame. We achieve robust
performance via a novel frame attention module, which shares information across
feature tracks. By directly transferring zero-shot from synthetic to real data,
our data-driven tracker outperforms existing approaches in relative feature age
by up to 120% while also achieving the lowest latency. This performance gap is
further increased to 130% by adapting our tracker to real data with a novel
self-supervision strategy.",https://github.com/uzh-rpg/deep_ev_tracker,-1
d04ff02f-6e4c-48a1-99c2-202f4db50b56,Enabling Multimodal Generation on CLIP via Vision-Language Knowledge Distillation,0.922059,"The recent large-scale vision-language pre-training (VLP) of dual-stream
architectures (e.g., CLIP) with a tremendous amount of image-text pair data,
has shown its superiority on various multimodal alignment tasks. Despite its
success, the resulting models are not capable of multimodal generative tasks
due to the weak text encoder. To tackle this problem, we propose to augment the
dual-stream VLP model with a textual pre-trained language model (PLM) via
vision-language knowledge distillation (VLKD), enabling the capability for
multimodal generation. VLKD is pretty data- and computation-efficient compared
to the pre-training from scratch. Experimental results show that the resulting
model has strong zero-shot performance on multimodal generation tasks, such as
open-ended visual question answering and image captioning. For example, it
achieves 44.5% zero-shot accuracy on the VQAv2 dataset, surpassing the previous
state-of-the-art zero-shot model with $7\times$ fewer parameters. Furthermore,
the original textual language understanding and generation ability of the PLM
is maintained after VLKD, which makes our model versatile for both multimodal
and unimodal tasks.",None,-1
71671215-c49d-4e4f-bef8-0dcb518c43a0,Large-Field Contextual Feature Learning for Glass Detection,0.773657,"Glass is very common in our daily life. Existing computer vision systems
neglect it and thus may have severe consequences, e.g., a robot may crash into
a glass wall. However, sensing the presence of glass is not straightforward.
The key challenge is that arbitrary objects/scenes can appear behind the glass.
In this paper, we propose an important problem of detecting glass surfaces from
a single RGB image. To address this problem, we construct the first large-scale
glass detection dataset (GDD) and propose a novel glass detection network,
called GDNet-B, which explores abundant contextual cues in a large
field-of-view via a novel large-field contextual feature integration (LCFI)
module and integrates both high-level and low-level boundary features with a
boundary feature enhancement (BFE) module. Extensive experiments demonstrate
that our GDNet-B achieves satisfying glass detection results on the images
within and beyond the GDD testing set. We further validate the effectiveness
and generalization capability of our proposed GDNet-B by applying it to other
vision tasks, including mirror segmentation and salient object detection.
Finally, we show the potential applications of glass detection and discuss
possible future research directions.",None,-1
9193e6b2-08bb-483d-b6c5-7edfe9b44863,Double Retrieval and Ranking for Accurate Question Answering,0.632121,"Recent work has shown that an answer verification step introduced in
Transformer-based answer selection models can significantly improve the state
of the art in Question Answering. This step is performed by aggregating the
embeddings of top $k$ answer candidates to support the verification of a target
answer. Although the approach is intuitive and sound still shows two
limitations: (i) the supporting candidates are ranked only according to the
relevancy with the question and not with the answer, and (ii) the support
provided by the other answer candidates is suboptimal as these are retrieved
independently of the target answer. In this paper, we address both drawbacks by
proposing (i) a double reranking model, which, for each target answer, selects
the best support; and (ii) a second neural retrieval stage designed to encode
question and answer pair as the query, which finds more specific verification
information. The results on three well-known datasets for AS2 show consistent
and significant improvement of the state of the art.",https://github.com/pytorch/fairseq,-1
b1ce890f-bbca-4839-9d5d-d2a662da8d75,Interpretable Multimodal Emotion Recognition using Hybrid Fusion of Speech and Image Data,0.495376,"This paper proposes a multimodal emotion recognition system based on hybrid
fusion that classifies the emotions depicted by speech utterances and
corresponding images into discrete classes. A new interpretability technique
has been developed to identify the important speech & image features leading to
the prediction of particular emotion classes. The proposed system's
architecture has been determined through intensive ablation studies. It fuses
the speech & image features and then combines speech, image, and intermediate
fusion outputs. The proposed interpretability technique incorporates the divide
& conquer approach to compute shapely values denoting each speech & image
feature's importance. We have also constructed a large-scale dataset (IIT-R
SIER dataset), consisting of speech utterances, corresponding images, and class
labels, i.e., 'anger,' 'happy,' 'hate,' and 'sad.' The proposed system has
achieved 83.29% accuracy for emotion recognition. The enhanced performance of
the proposed system advocates the importance of utilizing complementary
information from multiple modalities for emotion recognition.",https://github.com/MIntelligence-Group/SpeechImg EmoRec,-1
0b9518d8-df88-4ffa-9ac8-016900182703,Controlling the Focus of Pretrained Language Generation Models,0.146238,"The finetuning of pretrained transformer-based language generation models are
typically conducted in an end-to-end manner, where the model learns to attend
to relevant parts of the input by itself. However, there does not exist a
mechanism to directly control the model's focus. This work aims to develop a
control mechanism by which a user can select spans of context as ""highlights""
for the model to focus on, and generate relevant output. To achieve this goal,
we augment a pretrained model with trainable ""focus vectors"" that are directly
applied to the model's embeddings, while the model itself is kept fixed. These
vectors, trained on automatic annotations derived from attribution methods, act
as indicators for context importance. We test our approach on two core
generation tasks: dialogue response generation and abstractive summarization.
We also collect evaluation data where the highlight-generation pairs are
annotated by humans. Our experiments show that the trained focus vectors are
effective in steering the model to generate outputs that are relevant to
user-selected highlights.",https://github.com/Question406/LearningToFocus,28783
50d7aae0-fa74-49a7-bf95-373f98e3a3bc,Readability Controllable Biomedical Document Summarization,0.99587,"Different from general documents, it is recognised that the ease with which
people can understand a biomedical text is eminently varied, owing to the
highly technical nature of biomedical documents and the variance of readers'
domain knowledge. However, existing biomedical document summarization systems
have paid little attention to readability control, leaving users with summaries
that are incompatible with their levels of expertise. In recognition of this
urgent demand, we introduce a new task of readability controllable
summarization for biomedical documents, which aims to recognise users'
readability demands and generate summaries that better suit their needs:
technical summaries for experts and plain language summaries (PLS) for laymen.
To establish this task, we construct a corpus consisting of biomedical papers
with technical summaries and PLSs written by the authors, and benchmark
multiple advanced controllable abstractive and extractive summarization models
based on pre-trained language models (PLMs) with prevalent controlling and
generation techniques. Moreover, we propose a novel masked language model (MLM)
based metric and its variant to effectively evaluate the readability
discrepancy between lay and technical summaries. Experimental results from
automated and human evaluations show that though current control techniques
allow for a certain degree of readability adjustment during generation, the
performance of existing controllable summarization methods is far from
desirable in this task.",None,-1
f61b012b-310e-4abd-aa3c-c9ea545fa957,Exemplar Free Class Agnostic Counting,0.819298,"We tackle the task of Class Agnostic Counting, which aims to count objects in
a novel object category at test time without any access to labeled training
data for that category. All previous class agnostic counting methods cannot
work in a fully automated setting, and require computationally expensive test
time adaptation. To address these challenges, we propose a visual counter which
operates in a fully automated setting and does not require any test time
adaptation. Our proposed approach first identifies exemplars from repeating
objects in an image, and then counts the repeating objects. We propose a novel
region proposal network for identifying the exemplars. After identifying the
exemplars, we obtain the corresponding count by using a density estimation
based Visual Counter. We evaluate our proposed approach on FSC-147 dataset, and
show that it achieves superior performance compared to the existing approaches.",None,-1
302f9631-01e5-4395-93dd-f55a8b23f6d8,Rethinking the Role of Scale for In-Context Learning: An Interpretability-based Case Study at 66 Billion Scale,0.763926,"Language models have been shown to perform better with an increase in scale
on a wide variety of tasks via the in-context learning paradigm. In this paper,
we investigate the hypothesis that the ability of a large language model to
in-context learn-perform a task is not uniformly spread across all of its
underlying components. Using a 66 billion parameter language model (OPT-66B)
across a diverse set of 14 downstream tasks, we find this is indeed the case:
$\sim$70% of attention heads and $\sim$20% of feed forward networks can be
removed with minimal decline in task performance. We find substantial overlap
in the set of attention heads (un)important for in-context learning across
tasks and number of in-context examples. We also address our hypothesis through
a task-agnostic lens, finding that a small set of attention heads in OPT-66B
score highly on their ability to perform primitive induction operations
associated with in-context learning, namely, prefix matching and copying. These
induction heads overlap with task-specific important heads, reinforcing
arguments by Olsson et al. (arXiv:2209.11895) regarding induction head
generality to more sophisticated behaviors associated with in-context learning.
Overall, our study provides several insights that indicate large language
models may be under-trained for in-context learning and opens up questions on
how to pre-train language models to more effectively perform in-context
learning.",github.com/amazon-science/llm-interpret,42346
db1cf5f2-c01c-4767-a1c4-2db5af3dc0ac,Sobolev Training for Implicit Neural Representations with Approximated Image Derivatives,0.122892,"Recently, Implicit Neural Representations (INRs) parameterized by neural
networks have emerged as a powerful and promising tool to represent different
kinds of signals due to its continuous, differentiable properties, showing
superiorities to classical discretized representations. However, the training
of neural networks for INRs only utilizes input-output pairs, and the
derivatives of the target output with respect to the input, which can be
accessed in some cases, are usually ignored. In this paper, we propose a
training paradigm for INRs whose target output is image pixels, to encode image
derivatives in addition to image values in the neural network. Specifically, we
use finite differences to approximate image derivatives. We show how the
training paradigm can be leveraged to solve typical INRs problems, i.e., image
regression and inverse rendering, and demonstrate this training paradigm can
improve the data-efficiency and generalization capabilities of INRs. The code
of our method is available at
\url{https://github.com/megvii-research/Sobolev_INRs}.",https://github.com/megvii-research/Sobolev_INRs,-1
6010196d-b335-489e-89de-31a62eb66bb1,Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence,0.961656,"AI researchers have posited Dungeons and Dragons (D&D) as a challenge problem
to test systems on various language-related capabilities. In this paper, we
frame D&D specifically as a dialogue system challenge, where the tasks are to
both generate the next conversational turn in the game and predict the state of
the game given the dialogue history. We create a gameplay dataset consisting of
nearly 900 games, with a total of 7,000 players, 800,000 dialogue turns,
500,000 dice rolls, and 58 million words. We automatically annotate the data
with partial state information about the game play. We train a large language
model (LM) to generate the next game turn, conditioning it on different
information. The LM can respond as a particular character or as the player who
runs the game--i.e., the Dungeon Master (DM). It is trained to produce dialogue
that is either in-character (roleplaying in the fictional world) or
out-of-character (discussing rules or strategy). We perform a human evaluation
to determine what factors make the generated output plausible and interesting.
We further perform an automatic evaluation to determine how well the model can
predict the game state given the history and examine how well tracking the game
state improves its ability to produce plausible conversational output.",https://www.cis.upenn.edu/~ccb/dnd-data.html,-1
3408f368-a629-4d16-bde8-2b1572d04c3b,Sequence-aware multimodal page classification of Brazilian legal documents,0.202749,"The Brazilian Supreme Court receives tens of thousands of cases each
semester. Court employees spend thousands of hours to execute the initial
analysis and classification of those cases -- which takes effort away from
posterior, more complex stages of the case management workflow. In this paper,
we explore multimodal classification of documents from Brazil's Supreme Court.
We train and evaluate our methods on a novel multimodal dataset of 6,510
lawsuits (339,478 pages) with manual annotation assigning each page to one of
six classes. Each lawsuit is an ordered sequence of pages, which are stored
both as an image and as a corresponding text extracted through optical
character recognition. We first train two unimodal classifiers: a ResNet
pre-trained on ImageNet is fine-tuned on the images, and a convolutional
network with filters of multiple kernel sizes is trained from scratch on
document texts. We use them as extractors of visual and textual features, which
are then combined through our proposed Fusion Module. Our Fusion Module can
handle missing textual or visual input by using learned embeddings for missing
data. Moreover, we experiment with bi-directional Long Short-Term Memory
(biLSTM) networks and linear-chain conditional random fields to model the
sequential nature of the pages. The multimodal approaches outperform both
textual and visual classifiers, especially when leveraging the sequential
nature of the pages.",https://github.com/peluz/victor-visual-text,733
5a51f404-3bc2-4eb4-8d32-35a2ced7559e,Learning logic programs by combining programs,0.62766,"The goal of inductive logic programming is to induce a logic program (a set
of logical rules) that generalises training examples. Inducing programs with
many rules and literals is a major challenge. To tackle this challenge, we
introduce an approach where we learn small non-separable programs and combine
them. We implement our approach in a constraint-driven ILP system. Our approach
can learn optimal and recursive programs and perform predicate invention. Our
experiments on multiple domains, including game playing and program synthesis,
show that our approach can drastically outperform existing approaches in terms
of predictive accuracies and learning times, sometimes reducing learning times
from over an hour to a few seconds.",https://github.com/logic-and-learning-lab/ecai23-combo,-1
245e591f-903b-45d7-b6a3-bbd25451f338,MINER: Improving Out-of-Vocabulary Named Entity Recognition from an Information Theoretic Perspective,0.999153,"NER model has achieved promising performance on standard NER benchmarks.
However, recent studies show that previous approaches may over-rely on entity
mention information, resulting in poor performance on out-of-vocabulary (OOV)
entity recognition. In this work, we propose MINER, a novel NER learning
framework, to remedy this issue from an information-theoretic perspective. The
proposed approach contains two mutual information-based training objectives: i)
generalizing information maximization, which enhances representation via deep
understanding of context and entity surface forms; ii) superfluous information
minimization, which discourages representation from rote memorizing entity
names or exploiting biased cues in data. Experiments on various settings and
datasets demonstrate that it achieves better performance in predicting OOV
entities.",https://github.com/BeyonderXX/MINER,-1
801ae3dc-1d4a-4cad-80e0-5de52ffa9ea1,Let Me Check the Examples: Enhancing Demonstration Learning via Explicit Imitation,0.0661498,"Demonstration learning aims to guide the prompt prediction via providing
answered demonstrations in the few shot settings. Despite achieving promising
results, existing work only concatenates the answered examples as
demonstrations to the prompt template (including the raw context) without any
additional operation, neglecting the prompt-demonstration dependencies.
Besides, prior research found that randomly replacing the labels of
demonstrations marginally hurts performance, illustrating that the model could
not properly learn the knowledge brought by the demonstrations. Inspired by the
human learning process, in this paper, we introduce Imitation DEMOnstration
Learning (Imitation-Demo) to strengthen demonstration learning via explicitly
imitating human review behaviour, which includes: (1) contrastive learning
mechanism to concentrate on the similar demonstrations. (2) demonstration-label
re-prediction method to consolidate known knowledge. Experiment results show
that our proposed method achieves state-of-the-art performance on 11 out of 14
classification corpora. Further studies also prove that Imitation-Demo
strengthen the association between prompt and demonstrations, which could
provide the basis for exploring how demonstration learning works.",https://github.com/huggingface/transformers,-1
32b24315-9605-4dc1-b9a5-bd7ec134cfac,Anomaly Attribution with Likelihood Compensation,0.273365,"This paper addresses the task of explaining anomalous predictions of a
black-box regression model. When using a black-box model, such as one to
predict building energy consumption from many sensor measurements, we often
have a situation where some observed samples may significantly deviate from
their prediction. It may be due to a sub-optimal black-box model, or simply
because those samples are outliers. In either case, one would ideally want to
compute a ``responsibility score'' indicative of the extent to which an input
variable is responsible for the anomalous output. In this work, we formalize
this task as a statistical inverse problem: Given model deviation from the
expected value, infer the responsibility score of each of the input variables.
We propose a new method called likelihood compensation (LC), which is founded
on the likelihood principle and computes a correction to each input variable.
To the best of our knowledge, this is the first principled framework that
computes a responsibility score for real valued anomalous model deviations. We
apply our approach to a real-world building energy prediction task and confirm
its utility based on expert feedback.",None,12371
2eb7835b-6fff-45c9-a695-30f32030cd5b,NICO++: Towards Better Benchmarking for Domain Generalization,0.941617,"Despite the remarkable performance that modern deep neural networks have
achieved on independent and identically distributed (I.I.D.) data, they can
crash under distribution shifts. Most current evaluation methods for domain
generalization (DG) adopt the leave-one-out strategy as a compromise on the
limited number of domains. We propose a large-scale benchmark with extensive
labeled domains named NICO++ along with more rational evaluation methods for
comprehensively evaluating DG algorithms. To evaluate DG datasets, we propose
two metrics to quantify covariate shift and concept shift, respectively. Two
novel generalization bounds from the perspective of data construction are
proposed to prove that limited concept shift and significant covariate shift
favor the evaluation capability for generalization. Through extensive
experiments, NICO++ shows its superior evaluation capability compared with
current DG datasets and its contribution in alleviating unfairness caused by
the leak of oracle knowledge in model selection.",https://github.com/xxgege/NICO-plus,51525
86230e6d-df16-4015-bfe2-dc32e20c35e9,ParticleNeRF: A Particle-Based Encoding for Online Neural Radiance Fields,0.47641,"While existing Neural Radiance Fields (NeRFs) for dynamic scenes are offline
methods with an emphasis on visual fidelity, our paper addresses the online use
case that prioritises real-time adaptability. We present ParticleNeRF, a new
approach that dynamically adapts to changes in the scene geometry by learning
an up-to-date representation online, every 200ms. ParticleNeRF achieves this
using a novel particle-based parametric encoding. We couple features to
particles in space and backpropagate the photometric reconstruction loss into
the particles' position gradients, which are then interpreted as velocity
vectors. Governed by a lightweight physics system to handle collisions, this
lets the features move freely with the changing scene geometry. We demonstrate
ParticleNeRF on various dynamic scenes containing translating, rotating,
articulated, and deformable objects. ParticleNeRF is the first online dynamic
NeRF and achieves fast adaptability with better visual fidelity than
brute-force online InstantNGP and other baseline approaches on dynamic scenes
with online constraints. Videos of our system can be found at our project
website https://sites.google.com/view/particlenerf.",None,-1
8016080a-7ef1-43ce-b0de-b593ad9954fa,Unified Semantic Typing with Meaningful Label Inference,0.864046,"Semantic typing aims at classifying tokens or spans of interest in a textual
context into semantic categories such as relations, entity types, and event
types. The inferred labels of semantic categories meaningfully interpret how
machines understand components of text. In this paper, we present UniST, a
unified framework for semantic typing that captures label semantics by
projecting both inputs and labels into a joint semantic embedding space. To
formulate different lexical and relational semantic typing tasks as a unified
task, we incorporate task descriptions to be jointly encoded with the input,
allowing UniST to be adapted to different tasks without introducing
task-specific model components. UniST optimizes a margin ranking loss such that
the semantic relatedness of the input and labels is reflected from their
embedding similarity. Our experiments demonstrate that UniST achieves strong
performance across three semantic typing tasks: entity typing, relation
classification and event typing. Meanwhile, UniST effectively transfers
semantic knowledge of labels and substantially improves generalizability on
inferring rarely seen and unseen types. In addition, multiple semantic typing
tasks can be jointly trained within the unified framework, leading to a single
compact multi-tasking model that performs comparably to dedicated single-task
models, while offering even better transferability.",https://github.com/luka-group/UniST,-1
ea3bf5d1-5c78-418d-8568-9c33fc9fd184,Bridging the Gap between Artificial Intelligence and Artificial General Intelligence: A Ten Commandment Framework for Human-Like Intelligence,0.141859,"The field of artificial intelligence has seen explosive growth and
exponential success. The last phase of development showcased deep learnings
ability to solve a variety of difficult problems across a multitude of domains.
Many of these networks met and exceeded human benchmarks by becoming experts in
the domains in which they are trained. Though the successes of artificial
intelligence have begun to overshadow its failures, there is still much that
separates current artificial intelligence tools from becoming the exceptional
general learners that humans are. In this paper, we identify the ten
commandments upon which human intelligence is systematically and hierarchically
built. We believe these commandments work collectively to serve as the
essential ingredients that lead to the emergence of higher-order cognition and
intelligence. This paper discusses a computational framework that could house
these ten commandments and suggests new architectural modifications that could
lead to the development of smarter, more explainable, and generalizable
artificial systems inspired by a neuromorphic approach.",None,-1
149f5652-6dc8-44d1-a17b-438d181273df,IoV Scenario: Implementation of a Bandwidth Aware Algorithm in Wireless Network Communication Mode,0.396833,"The wireless network communication mode represented by the Internet of
vehicles (IoV) has been widely used. However, due to the limitations of
traditional network architecture, resource scheduling in wireless network
environment is still facing great challenges. This paper focuses on the
allocation of bandwidth resources in the virtual network environment. This
paper proposes a bandwidth aware multi domain virtual network embedding
algorithm (BA-VNE). The algorithm is mainly aimed at the problem that users
need a lot of bandwidth in wireless communication mode, and solves the problem
of bandwidth resource allocation from the perspective of virtual network
embedding (VNE). In order to improve the performance of the algorithm, we
introduce particle swarm optimization (PSO) algorithm to optimize the
performance of the algorithm. In order to verify the effectiveness of the
algorithm, we have carried out simulation experiments from link bandwidth,
mapping cost and virtual network request (VNR) acceptance rate. The final
results show that the proposed algorithm is better than other representative
algorithms in the above indicators.",None,74924
84df5505-bb87-408e-b79e-99d7ac92bf40,Generative Multiplane Images: Making a 2D GAN 3D-Aware,0.814304,"What is really needed to make an existing 2D GAN 3D-aware? To answer this
question, we modify a classical GAN, i.e., StyleGANv2, as little as possible.
We find that only two modifications are absolutely necessary: 1) a multiplane
image style generator branch which produces a set of alpha maps conditioned on
their depth; 2) a pose-conditioned discriminator. We refer to the generated
output as a 'generative multiplane image' (GMPI) and emphasize that its
renderings are not only high-quality but also guaranteed to be view-consistent,
which makes GMPIs different from many prior works. Importantly, the number of
alpha maps can be dynamically adjusted and can differ between training and
inference, alleviating memory concerns and enabling fast training of GMPIs in
less than half a day at a resolution of $1024^2$. Our findings are consistent
across three challenging and common high-resolution datasets, including FFHQ,
AFHQv2, and MetFaces.",https://github.com/apple/ml-gmpi,-1
963f98ef-29f9-4815-ac5d-e1f896dbe30a,TrustAL: Trustworthy Active Learning using Knowledge Distillation,0.259605,"Active learning can be defined as iterations of data labeling, model
training, and data acquisition, until sufficient labels are acquired. A
traditional view of data acquisition is that, through iterations, knowledge
from human labels and models is implicitly distilled to monotonically increase
the accuracy and label consistency. Under this assumption, the most recently
trained model is a good surrogate for the current labeled data, from which data
acquisition is requested based on uncertainty/diversity. Our contribution is
debunking this myth and proposing a new objective for distillation. First, we
found example forgetting, which indicates the loss of knowledge learned across
iterations. Second, for this reason, the last model is no longer the best
teacher -- For mitigating such forgotten knowledge, we select one of its
predecessor models as a teacher, by our proposed notion of ""consistency"". We
show that this novel distillation is distinctive in the following three
aspects; First, consistency ensures to avoid forgetting labels. Second,
consistency improves both uncertainty/diversity of labeled data. Lastly,
consistency redeems defective labels produced by human annotators.",https://github.com/huggingface/transformers,-1
4e35eaff-af48-45ca-a5dd-a00be9fc1619,RITA: Boost Driving Simulators with Realistic Interactive Traffic Flow,0.271687,"High-quality traffic flow generation is the core module in building
simulators for autonomous driving. However, the majority of available
simulators are incapable of replicating traffic patterns that accurately
reflect the various features of real-world data while also simulating
human-like reactive responses to the tested autopilot driving strategies.
Taking one step forward to addressing such a problem, we propose Realistic
Interactive TrAffic flow (RITA) as an integrated component of existing driving
simulators to provide high-quality traffic flow for the evaluation and
optimization of the tested driving strategies. RITA is developed with
consideration of three key features, i.e., fidelity, diversity, and
controllability, and consists of two core modules called RITABackend and
RITAKit. RITABackend is built to support vehicle-wise control and provide
traffic generation models from real-world datasets, while RITAKit is developed
with easy-to-use interfaces for controllable traffic generation via
RITABackend. We demonstrate RITA's capacity to create diversified and
high-fidelity traffic simulations in several highly interactive highway
scenarios. The experimental findings demonstrate that our produced RITA traffic
flows exhibit all three key features, hence enhancing the completeness of
driving strategy evaluation. Moreover, we showcase the possibility for further
improvement of baseline strategies through online fine-tuning with RITA traffic
flows.",None,-1
94be1ef0-3ad8-4e21-83e3-ce60ba182656,Automatic Chain of Thought Prompting in Large Language Models,0.952796,"Large language models (LLMs) can perform complex reasoning by generating
intermediate reasoning steps. Providing these steps for prompting
demonstrations is called chain-of-thought (CoT) prompting. CoT prompting has
two major paradigms. One leverages a simple prompt like ""Let's think step by
step"" to facilitate step-by-step thinking before answering a question. The
other uses a few manual demonstrations one by one, each composed of a question
and a reasoning chain that leads to an answer. The superior performance of the
second paradigm hinges on the hand-crafting of task-specific demonstrations one
by one. We show that such manual efforts may be eliminated by leveraging LLMs
with the ""Let's think step by step"" prompt to generate reasoning chains for
demonstrations one by one, i.e., let's think not just step by step, but also
one by one. However, these generated chains often come with mistakes. To
mitigate the effect of such mistakes, we find that diversity matters for
automatically constructing demonstrations. We propose an automatic CoT
prompting method: Auto-CoT. It samples questions with diversity and generates
reasoning chains to construct demonstrations. On ten public benchmark reasoning
tasks with GPT-3, Auto-CoT consistently matches or exceeds the performance of
the CoT paradigm that requires manual designs of demonstrations. Code is
available at https://github.com/amazon-research/auto-cot",None,-1
0fb8c7dc-1299-490b-a1ec-da4b859e0bad,Exhaustivity and anti-exhaustivity in the RSA framework: Testing the effect of prior beliefs,0.318134,"During communication, the interpretation of utterances is sensitive to a
listener's probabilistic prior beliefs, something which is captured by one
currently influential model of pragmatics, the Rational Speech Act (RSA)
framework. In this paper we focus on cases when this sensitivity to priors
leads to counterintuitive predictions of the framework. Our domain of interest
is exhaustivity effects, whereby a sentence such as ""Mary came"" is understood
to mean that only Mary came. We show that in the baseline RSA model, under
certain conditions, anti-exhaustive readings are predicted (e.g., ""Mary came""
would be used to convey that both Mary and Peter came). The specific question
we ask is the following: should exhaustive interpretations be derived as purely
pragmatic inferences (as in the classical Gricean view, endorsed in the
baseline RSA model), or should they rather be generated by an encapsulated
semantic mechanism (as argued in some of the recent formal literature)? To
answer this question, we provide a detailed theoretical analysis of different
RSA models and evaluate them against data obtained in a new study which tested
the effects of prior beliefs on both production and comprehension, improving on
previous empirical work. We found no anti-exhaustivity effects, but observed
that message choice is sensitive to priors, as predicted by the RSA framework
overall. The best models turn out to be those which include an encapsulated
exhaustivity mechanism (as other studies concluded on the basis of very
different data). We conclude that, on the one hand, in the division of labor
between semantics and pragmatics, semantics plays a larger role than is often
thought, but, on the other hand, the tradeoff between informativity and cost
which characterizes all RSA models does play a central role for genuine
pragmatic effects.",https://github.com/Alex-Cremers/RSA-Exh-Priors,-1
db974a13-9201-4bff-ac73-d528828ea891,Improving Rare Word Recognition with LM-aware MWER Training,0.807174,"Language models (LMs) significantly improve the recognition accuracy of
end-to-end (E2E) models on words rarely seen during training, when used in
either the shallow fusion or the rescoring setups. In this work, we introduce
LMs in the learning of hybrid autoregressive transducer (HAT) models in the
discriminative training framework, to mitigate the training versus inference
gap regarding the use of LMs. For the shallow fusion setup, we use LMs during
both hypotheses generation and loss computation, and the LM-aware MWER-trained
model achieves 10\% relative improvement over the model trained with standard
MWER on voice search test sets containing rare words. For the rescoring setup,
we learn a small neural module to generate per-token fusion weights in a
data-dependent manner. This model achieves the same rescoring WER as regular
MWER-trained model, but without the need for sweeping fusion weights.",None,-1
5ebe8324-2625-42ac-8465-8930b761ccf2,HyperSound: Generating Implicit Neural Representations of Audio Signals with Hypernetworks,0.534684,"Implicit neural representations (INRs) are a rapidly growing research field,
which provides alternative ways to represent multimedia signals. Recent
applications of INRs include image super-resolution, compression of
high-dimensional signals, or 3D rendering. However, these solutions usually
focus on visual data, and adapting them to the audio domain is not trivial.
Moreover, it requires a separately trained model for every data sample. To
address this limitation, we propose HyperSound, a meta-learning method
leveraging hypernetworks to produce INRs for audio signals unseen at training
time. We show that our approach can reconstruct sound waves with quality
comparable to other state-of-the-art models.",None,-1
a041a771-e6cb-4e41-a633-84910a8eb5e3,RSCFed: Random Sampling Consensus Federated Semi-supervised Learning,0.835094,"Federated semi-supervised learning (FSSL) aims to derive a global model by
training fully-labeled and fully-unlabeled clients or training partially
labeled clients. The existing approaches work well when local clients have
independent and identically distributed (IID) data but fail to generalize to a
more practical FSSL setting, i.e., Non-IID setting. In this paper, we present a
Random Sampling Consensus Federated learning, namely RSCFed, by considering the
uneven reliability among models from fully-labeled clients, fully-unlabeled
clients or partially labeled clients. Our key motivation is that given models
with large deviations from either labeled clients or unlabeled clients, the
consensus could be reached by performing random sub-sampling over clients. To
achieve it, instead of directly aggregating local models, we first distill
several sub-consensus models by random sub-sampling over clients and then
aggregating the sub-consensus models to the global model. To enhance the
robustness of sub-consensus models, we also develop a novel distance-reweighted
model aggregation method. Experimental results show that our method outperforms
state-of-the-art methods on three benchmarked datasets, including both natural
and medical images. The code is available at
https://github.com/XMed-Lab/RSCFed.",https://github.com/XMed-Lab/RSCFed,-1
df171a4c-e48f-4cf1-8a9b-f67bbda24ce8,Semi-supervised Predictive Clustering Trees for (Hierarchical) Multi-label Classification,0.518091,"Semi-supervised learning (SSL) is a common approach to learning predictive
models using not only labeled examples, but also unlabeled examples. While SSL
for the simple tasks of classification and regression has received a lot of
attention from the research community, this is not properly investigated for
complex prediction tasks with structurally dependent variables. This is the
case of multi-label classification and hierarchical multi-label classification
tasks, which may require additional information, possibly coming from the
underlying distribution in the descriptive space provided by unlabeled
examples, to better face the challenging task of predicting simultaneously
multiple class labels.
  In this paper, we investigate this aspect and propose a (hierarchical)
multi-label classification method based on semi-supervised learning of
predictive clustering trees. We also extend the method towards ensemble
learning and propose a method based on the random forest approach. Extensive
experimental evaluation conducted on 23 datasets shows significant advantages
of the proposed method and its extension with respect to their supervised
counterparts. Moreover, the method preserves interpretability and reduces the
time complexity of classical tree-based models.",https://github.com/knowledge-technologies/clus,-1
38d31900-02e2-46a8-8fba-2ab667a75c70,Tackling Background Distraction in Video Object Segmentation,0.51607,"Semi-supervised video object segmentation (VOS) aims to densely track certain
designated objects in videos. One of the main challenges in this task is the
existence of background distractors that appear similar to the target objects.
We propose three novel strategies to suppress such distractors: 1) a
spatio-temporally diversified template construction scheme to obtain
generalized properties of the target objects; 2) a learnable distance-scoring
function to exclude spatially-distant distractors by exploiting the temporal
consistency between two consecutive frames; 3) swap-and-attach augmentation to
force each object to have unique features by providing training samples
containing entangled objects. On all public benchmark datasets, our model
achieves a comparable performance to contemporary state-of-the-art approaches,
even with real-time performance. Qualitative results also demonstrate the
superiority of our approach over existing methods. We believe our approach will
be widely used for future VOS research.",https://github.com/suhwan-cho/TBD,-1
e4efda48-99f9-4568-95de-f4e52ce7d323,MoViDNN: A Mobile Platform for Evaluating Video Quality Enhancement with Deep Neural Networks,0.0857231,"Deep neural network (DNN) based approaches have been intensively studied to
improve video quality thanks to their fast advancement in recent years. These
approaches are designed mainly for desktop devices due to their high
computational cost. However, with the increasing performance of mobile devices
in recent years, it became possible to execute DNN based approaches in mobile
devices. Despite having the required computational power, utilizing DNNs to
improve the video quality for mobile devices is still an active research area.
In this paper, we propose an open-source mobile platform, namely MoViDNN, to
evaluate DNN based video quality enhancement methods, such as super-resolution,
denoising, and deblocking. Our proposed platform can be used to evaluate the
DNN based approaches both objectively and subjectively. For objective
evaluation, we report common metrics such as execution time, PSNR, and SSIM.
For subjective evaluation, Mean Score Opinion (MOS) is reported. The proposed
platform is available publicly at https://github.com/cd-athena/MoViDNN",https://github.com/cd-athena/MoViDNN,-1
9d8cf0b0-1c6c-45c0-9a84-d9c5b0d2ee9a,ILASR: Privacy-Preserving Incremental Learning for Automatic Speech Recognition at Production Scale,0.2987,"Incremental learning is one paradigm to enable model building and updating at
scale with streaming data. For end-to-end automatic speech recognition (ASR)
tasks, the absence of human annotated labels along with the need for privacy
preserving policies for model building makes it a daunting challenge. Motivated
by these challenges, in this paper we use a cloud based framework for
production systems to demonstrate insights from privacy preserving incremental
learning for automatic speech recognition (ILASR). By privacy preserving, we
mean, usage of ephemeral data which are not human annotated. This system is a
step forward for production levelASR models for incremental/continual learning
that offers near real-time test-bed for experimentation in the cloud for
end-to-end ASR, while adhering to privacy-preserving policies. We show that the
proposed system can improve the production models significantly(3%) over a new
time period of six months even in the absence of human annotated labels with
varying levels of weak supervision and large batch sizes in incremental
learning. This improvement is 20% over test sets with new words and phrases in
the new time period. We demonstrate the effectiveness of model building in a
privacy-preserving incremental fashion for ASR while further exploring the
utility of having an effective teacher model and use of large batch sizes.",None,-1
44175900-888c-451d-9254-fc46a6ffae20,Ranking-Enhanced Unsupervised Sentence Representation Learning,0.708646,"Unsupervised sentence representation learning has progressed through
contrastive learning and data augmentation methods such as dropout masking.
Despite this progress, sentence encoders are still limited to using only an
input sentence when predicting its semantic vector. In this work, we show that
the semantic meaning of a sentence is also determined by nearest-neighbor
sentences that are similar to the input sentence. Based on this finding, we
propose a novel unsupervised sentence encoder, RankEncoder. RankEncoder
predicts the semantic vector of an input sentence by leveraging its
relationship with other sentences in an external corpus, as well as the input
sentence itself. We evaluate RankEncoder on semantic textual benchmark
datasets. From the experimental results, we verify that 1) RankEncoder achieves
80.07% Spearman's correlation, a 1.1% absolute improvement compared to the
previous state-of-the-art performance, 2) RankEncoder is universally applicable
to existing unsupervised sentence embedding methods, and 3) RankEncoder is
specifically effective for predicting the similarity scores of similar sentence
pairs.",https://github.com/yeonsw/RankEncoder.git,-1
79fb0456-9589-4f9c-93de-5a791f4b71cf,A Symbolic Approach for Counterfactual Explanations,0.316111,"In this paper titled A Symbolic Approach for Counterfactual Explanations we
propose a novel symbolic approach to provide counterfactual explanations for a
classifier predictions. Contrary to most explanation approaches where the goal
is to understand which and to what extent parts of the data helped to give a
prediction, counterfactual explanations indicate which features must be changed
in the data in order to change this classifier prediction. Our approach is
symbolic in the sense that it is based on encoding the decision function of a
classifier in an equivalent CNF formula. In this approach, counterfactual
explanations are seen as the Minimal Correction Subsets (MCS), a well-known
concept in knowledge base reparation. Hence, this approach takes advantage of
the strengths of already existing and proven solutions for the generation of
MCS. Our preliminary experimental studies on Bayesian classifiers show the
potential of this approach on several datasets.",None,-1
b9453be4-fda3-4293-b9b5-4f8604cf6c4d,ViGAT: Bottom-up event recognition and explanation in video using factorized graph attention network,0.391036,"In this paper a pure-attention bottom-up approach, called ViGAT, that
utilizes an object detector together with a Vision Transformer (ViT) backbone
network to derive object and frame features, and a head network to process
these features for the task of event recognition and explanation in video, is
proposed. The ViGAT head consists of graph attention network (GAT) blocks
factorized along the spatial and temporal dimensions in order to capture
effectively both local and long-term dependencies between objects or frames.
Moreover, using the weighted in-degrees (WiDs) derived from the adjacency
matrices at the various GAT blocks, we show that the proposed architecture can
identify the most salient objects and frames that explain the decision of the
network. A comprehensive evaluation study is performed, demonstrating that the
proposed approach provides state-of-the-art results on three large, publicly
available video datasets (FCVID, Mini-Kinetics, ActivityNet).",https://github.com/bmezaris/ViGAT,-1
71e1fa56-9c51-4eaa-bcc5-304f77601b89,NFLAT: Non-Flat-Lattice Transformer for Chinese Named Entity Recognition,0.864484,"Recently, Flat-LAttice Transformer (FLAT) has achieved great success in
Chinese Named Entity Recognition (NER). FLAT performs lexical enhancement by
constructing flat lattices, which mitigates the difficulties posed by blurred
word boundaries and the lack of word semantics. In FLAT, the positions of
starting and ending characters are used to connect a matching word. However,
this method is likely to match more words when dealing with long texts,
resulting in long input sequences. Therefore, it significantly increases the
memory and computational costs of the self-attention module. To deal with this
issue, we advocate a novel lexical enhancement method, InterFormer, that
effectively reduces the amount of computational and memory costs by
constructing non-flat lattices. Furthermore, with InterFormer as the backbone,
we implement NFLAT for Chinese NER. NFLAT decouples lexicon fusion and context
feature encoding. Compared with FLAT, it reduces unnecessary attention
calculations in ""word-character"" and ""word-word"". This reduces the memory usage
by about 50% and can use more extensive lexicons or higher batches for network
training. The experimental results obtained on several well-known benchmarks
demonstrate the superiority of the proposed method over the state-of-the-art
hybrid (character-word) models.",None,-1
26632efa-4be2-4642-86cc-22c740821fdd,Causal Balancing for Domain Generalization,0.471673,"While machine learning models rapidly advance the state-of-the-art on various
real-world tasks, out-of-domain (OOD) generalization remains a challenging
problem given the vulnerability of these models to spurious correlations. We
propose a balanced mini-batch sampling strategy to transform a biased data
distribution into a spurious-free balanced distribution, based on the
invariance of the underlying causal mechanisms for the data generation process.
We argue that the Bayes optimal classifiers trained on such balanced
distribution are minimax optimal across a diverse enough environment space. We
also provide an identifiability guarantee of the latent variable model of the
proposed data generation process, when utilizing enough train environments.
Experiments are conducted on DomainBed, demonstrating empirically that our
method obtains the best performance across 20 baselines reported on the
benchmark.",https://github.com/WANGXinyiLinda/causal-balancing-for-domain-generalization,17592
6384f6ab-c5e5-425f-8885-85bc5ecec25c,StoryTrans: Non-Parallel Story Author-Style Transfer with Discourse Representations and Content Enhancing,0.100808,"Non-parallel text style transfer is an important task in natural language
generation. However, previous studies concentrate on the token or sentence
level, such as sentence sentiment and formality transfer, but neglect long
style transfer at the discourse level. Long texts usually involve more
complicated author linguistic preferences such as discourse structures than
sentences. In this paper, we formulate the task of non-parallel story
author-style transfer, which requires transferring an input story into a
specified author style while maintaining source semantics. To tackle this
problem, we propose a generation model, named StoryTrans, which leverages
discourse representations to capture source content information and transfer
them to target styles with learnable style embeddings. We use an additional
training objective to disentangle stylistic features from the learned discourse
representation to prevent the model from degenerating to an auto-encoder.
Moreover, to enhance content preservation, we design a mask-and-fill framework
to explicitly fuse style-specific keywords of source texts into generation.
Furthermore, we constructed new datasets for this task in Chinese and English,
respectively. Extensive experiments show that our model outperforms strong
baselines in overall performance of style transfer and content preservation.",https://github.com/Xuekai-Zhu/storytrans_public,-1
8d94e121-269e-47f1-b5d2-03e97c3635fd,Robust Monocular Localization of Drones by Adapting Domain Maps to Depth Prediction Inaccuracies,0.171273,"We present a novel monocular localization framework by jointly training deep
learning-based depth prediction and Bayesian filtering-based pose reasoning.
The proposed cross-modal framework significantly outperforms deep learning-only
predictions with respect to model scalability and tolerance to environmental
variations. Specifically, we show little-to-no degradation of pose accuracy
even with extremely poor depth estimates from a lightweight depth predictor.
Our framework also maintains high pose accuracy in extreme lighting variations
compared to standard deep learning, even without explicit domain adaptation. By
openly representing the map and intermediate feature maps (such as depth
estimates), our framework also allows for faster updates and reusing
intermediate predictions for other tasks, such as obstacle avoidance, resulting
in much higher resource efficiency.",None,-1
e6f3ad58-6e2c-4f2a-aee0-d1f8837fc127,Read before Generate! Faithful Long Form Question Answering with Machine Reading,0.633893,"Long-form question answering (LFQA) aims to generate a paragraph-length
answer for a given question. While current work on LFQA using large pre-trained
model for generation are effective at producing fluent and somewhat relevant
content, one primary challenge lies in how to generate a faithful answer that
has less hallucinated content. We propose a new end-to-end framework that
jointly models answer generation and machine reading. The key idea is to
augment the generation model with fine-grained, answer-related salient
information which can be viewed as an emphasis on faithful facts.
State-of-the-art results on two LFQA datasets, ELI5 and MS MARCO, demonstrate
the effectiveness of our method, in comparison with strong baselines on
automatic and human evaluation metrics. A detailed analysis further proves the
competency of our methods in generating fluent, relevant, and more faithful
answers.",https://github.com/facebookresearch/faiss,-1
829586c3-736a-4172-9bd1-24ac7fb187f0,Build-a-Bot: Teaching Conversational AI Using a Transformer-Based Intent Recognition and Question Answering Architecture,0.137616,"As artificial intelligence (AI) becomes a prominent part of modern life, AI
literacy is becoming important for all citizens, not just those in technology
careers. Previous research in AI education materials has largely focused on the
introduction of terminology as well as AI use cases and ethics, but few allow
students to learn by creating their own machine learning models. Therefore,
there is a need for enriching AI educational tools with more adaptable and
flexible platforms for interested educators with any level of technical
experience to utilize within their teaching material. As such, we propose the
development of an open-source tool (Build-a-Bot) for students and teachers to
not only create their own transformer-based chatbots based on their own course
material, but also learn the fundamentals of AI through the model creation
process. The primary concern of this paper is the creation of an interface for
students to learn the principles of artificial intelligence by using a natural
language pipeline to train a customized model to answer questions based on
their own school curriculums. The model uses contexts given by their
instructor, such as chapters of a textbook, to answer questions and is deployed
on an interactive chatbot/voice agent. The pipeline teaches students data
collection, data augmentation, intent recognition, and question answering by
having them work through each of these processes while creating their AI agent,
diverging from previous chatbot work where students and teachers use the bots
as black-boxes with no abilities for customization or the bots lack AI
capabilities, with the majority of dialogue scripts being rule-based. In
addition, our tool is designed to make each step of this pipeline intuitive for
students at a middle-school level. Further work primarily lies in providing our
tool to schools and seeking student and teacher evaluations.",None,-1
a9578a4c-f344-482d-9831-1a464f2a944b,AI-Aided Integrated Terrestrial and Non-Terrestrial 6G Solutions for Sustainable Maritime Networking,0.816944,"The maritime industry is experiencing a technological revolution that affects
shipbuilding, operation of both seagoing and inland vessels, cargo management,
and working practices in harbors. This ongoing transformation is driven by the
ambition to make the ecosystem more sustainable and cost-efficient.
Digitalization and automation help achieve these goals by transforming shipping
and cruising into a much more cost- and energy-efficient, and decarbonized
industry segment. The key enablers in these processes are always-available
connectivity and content delivery services, which can not only aid shipping
companies in improving their operational efficiency and reducing carbon
emissions but also contribute to enhanced crew welfare and passenger
experience. Due to recent advancements in integrating high-capacity and
ultra-reliable terrestrial and non-terrestrial networking technologies,
ubiquitous maritime connectivity is becoming a reality. To cope with the
increased complexity of managing these integrated systems, this article
advocates the use of artificial intelligence and machine learning-based
approaches to meet the service requirements and energy efficiency targets in
various maritime communications scenarios.",None,-1
036cb429-955d-4793-96fe-4458909ae53f,Fruit Quality Assessment with Densely Connected Convolutional Neural Network,0.649101,"Accurate recognition of food items along with quality assessment is of
paramount importance in the agricultural industry. Such automated systems can
speed up the wheel of the food processing sector and save tons of manual labor.
In this connection, the recent advancement of Deep learning-based architectures
has introduced a wide variety of solutions offering remarkable performance in
several classification tasks. In this work, we have exploited the concept of
Densely Connected Convolutional Neural Networks (DenseNets) for fruit quality
assessment. The feature propagation towards the deeper layers has enabled the
network to tackle the vanishing gradient problems and ensured the reuse of
features to learn meaningful insights. Evaluating on a dataset of 19,526 images
containing six fruits having three quality grades for each, the proposed
pipeline achieved a remarkable accuracy of 99.67%. The robustness of the model
was further tested for fruit classification and quality assessment tasks where
the model produced a similar performance, which makes it suitable for real-life
applications.",None,-1
818ce70b-3ed8-446e-9d65-43d0ae9d193e,Leveraging Off-the-shelf Diffusion Model for Multi-attribute Fashion Image Manipulation,0.80541,"Fashion attribute editing is a task that aims to convert the semantic
attributes of a given fashion image while preserving the irrelevant regions.
Previous works typically employ conditional GANs where the generator explicitly
learns the target attributes and directly execute the conversion. These
approaches, however, are neither scalable nor generic as they operate only with
few limited attributes and a separate generator is required for each dataset or
attribute set. Inspired by the recent advancement of diffusion models, we
explore the classifier-guided diffusion that leverages the off-the-shelf
diffusion model pretrained on general visual semantics such as Imagenet. In
order to achieve a generic editing pipeline, we pose this as multi-attribute
image manipulation task, where the attribute ranges from item category, fabric,
pattern to collar and neckline. We empirically show that conventional methods
fail in our challenging setting, and study efficient adaptation scheme that
involves recently introduced attention-pooling technique to obtain a
multi-attribute classifier guidance. Based on this, we present a mask-free
fashion attribute editing framework that leverages the classifier logits and
the cross-attention map for manipulation. We empirically demonstrate that our
framework achieves convincing sample quality and attribute alignments.",None,-1
ae0dfc58-2cd5-4e14-a0a2-a55fb103e0fe,C-MORE: Pretraining to Answer Open-Domain Questions by Consulting Millions of References,0.2847,"We consider the problem of pretraining a two-stage open-domain question
answering (QA) system (retriever + reader) with strong transfer capabilities.
The key challenge is how to construct a large amount of high-quality
question-answer-context triplets without task-specific annotations.
Specifically, the triplets should align well with downstream tasks by: (i)
covering a wide range of domains (for open-domain applications), (ii) linking a
question to its semantically relevant context with supporting evidence (for
training the retriever), and (iii) identifying the correct answer in the
context (for training the reader). Previous pretraining approaches generally
fall short of one or more of these requirements. In this work, we automatically
construct a large-scale corpus that meets all three criteria by consulting
millions of references cited within Wikipedia. The well-aligned pretraining
signals benefit both the retriever and the reader significantly. Our pretrained
retriever leads to 2%-10% absolute gains in top-20 accuracy. And with our
pretrained reader, the entire system improves by up to 4% in exact match.",https://github.com/xiangyue9607/C-MORE,-1
d61b91c4-6509-4a98-8681-edca3294596d,Robots-Dont-Cry: Understanding Falsely Anthropomorphic Utterances in Dialog Systems,0.592743,"Dialog systems are often designed or trained to output human-like responses.
However, some responses may be impossible for a machine to truthfully say (e.g.
""that movie made me cry""). Highly anthropomorphic responses might make users
uncomfortable or implicitly deceive them into thinking they are interacting
with a human. We collect human ratings on the feasibility of approximately 900
two-turn dialogs sampled from 9 diverse data sources. Ratings are for two
hypothetical machine embodiments: a futuristic humanoid robot and a digital
assistant. We find that for some data-sources commonly used to train dialog
systems, 20-30% of utterances are not viewed as possible for a machine. Rating
is marginally affected by machine embodiment. We explore qualitative and
quantitative reasons for these ratings. Finally, we build classifiers and
explore how modeling configuration might affect output permissibly, and discuss
implications for building less falsely anthropomorphic dialog systems.",https://github.com/DNGros/Robots-Dont-Cry,-1
236d588e-9b8b-4077-b6db-9d676fb36d8a,Super-Resolution and Image Re-projection for Iris Recognition,0.0213704,"Several recent works have addressed the ability of deep learning to disclose
rich, hierarchical and discriminative models for the most diverse purposes.
Specifically in the super-resolution field, Convolutional Neural Networks
(CNNs) using different deep learning approaches attempt to recover realistic
texture and fine grained details from low resolution images. In this work we
explore the viability of these approaches for iris Super-Resolution (SR) in an
iris recognition environment. For this, we test different architectures with
and without a so called image re-projection to reduce artifacts applying it to
different iris databases to verify the viability of the different CNNs for iris
super-resolution. Results show that CNNs and image re-projection can improve
the results specially for the accuracy of recognition systems using a complete
different training database performing the transfer learning successfully.",None,5281
ee58fa7c-18dc-4355-a893-83a6e4b467d0,Fake Hilsa Fish Detection Using Machine Vision,0.011909,"Hilsa is the national fish of Bangladesh. Bangladesh is earning a lot of
foreign currency by exporting this fish. Unfortunately, in recent days, some
unscrupulous businessmen are selling fake Hilsa fishes to gain profit. The
Sardines and Sardinella are the most sold in the market as Hilsa. The
government agency of Bangladesh, namely Bangladesh Food Safety Authority said
that these fake Hilsa fish contain high levels of cadmium and lead which are
detrimental for humans. In this research, we have proposed a method that can
readily identify original Hilsa fish and fake Hilsa fish. Based on the research
available on online literature, we are the first to do research on identifying
original Hilsa fish. We have collected more than 16,000 images of original and
counterfeit Hilsa fish. To classify these images, we have used several deep
learning-based models. Then, the performance has been compared between them.
Among those models, DenseNet201 achieved the highest accuracy of 97.02%.",None,-1
85eef442-94dd-4418-8bde-1d7b52ee173d,CitySpec: An Intelligent Assistant System for Requirement Specification in Smart Cities,0.473595,"An increasing number of monitoring systems have been developed in smart
cities to ensure that real-time operations of a city satisfy safety and
performance requirements. However, many existing city requirements are written
in English with missing, inaccurate, or ambiguous information. There is a high
demand for assisting city policy makers in converting human-specified
requirements to machine-understandable formal specifications for monitoring
systems. To tackle this limitation, we build CitySpec, the first intelligent
assistant system for requirement specification in smart cities. To create
CitySpec, we first collect over 1,500 real-world city requirements across
different domains from over 100 cities and extract city-specific knowledge to
generate a dataset of city vocabulary with 3,061 words. We also build a
translation model and enhance it through requirement synthesis and develop a
novel online learning framework with validation under uncertainty. The
evaluation results on real-world city requirements show that CitySpec increases
the sentence-level accuracy of requirement specification from 59.02% to 86.64%,
and has strong adaptability to a new city and a new domain (e.g., F1 score for
requirements in Seattle increases from 77.6% to 93.75% with online learning).",None,-1
56358f29-650c-402a-ad9a-c27a7185695b,Towards Summary Candidates Fusion,0.848198,"Sequence-to-sequence deep neural models fine-tuned for abstractive
summarization can achieve great performance on datasets with enough human
annotations. Yet, it has been shown that they have not reached their full
potential, with a wide gap between the top beam search output and the oracle
beam. Recently, re-ranking methods have been proposed, to learn to select a
better summary candidate. However, such methods are limited by the summary
quality aspects captured by the first-stage candidates. To bypass this
limitation, we propose a new paradigm in second-stage abstractive summarization
called SummaFusion that fuses several summary candidates to produce a novel
abstractive second-stage summary. Our method works well on several
summarization datasets, improving both the ROUGE scores and qualitative
properties of fused summaries. It is especially good when the candidates to
fuse are worse, such as in the few-shot setup where we set a new
state-of-the-art. We will make our code and checkpoints available at
https://github.com/ntunlp/SummaFusion/.",https://github.com/ntunlp/SummaFusion/,-1
58f59309-74ca-4d85-a196-100ffd60493d,TAD: Transfer Learning-based Multi-Adversarial Detection of Evasion Attacks against Network Intrusion Detection Systems,0.772581,"Nowadays, intrusion detection systems based on deep learning deliver
state-of-the-art performance. However, recent research has shown that specially
crafted perturbations, called adversarial examples, are capable of
significantly reducing the performance of these intrusion detection systems.
The objective of this paper is to design an efficient transfer learning-based
adversarial detector and then to assess the effectiveness of using multiple
strategically placed adversarial detectors compared to a single adversarial
detector for intrusion detection systems. In our experiments, we implement
existing state-of-the-art models for intrusion detection. We then attack those
models with a set of chosen evasion attacks. In an attempt to detect those
adversarial attacks, we design and implement multiple transfer learning-based
adversarial detectors, each receiving a subset of the information passed
through the IDS. By combining their respective decisions, we illustrate that
combining multiple detectors can further improve the detectability of
adversarial traffic compared to a single detector in the case of a parallel IDS
design.",None,-1
5cec3085-322f-4cb0-9961-6113b2faff1a,Out of Distribution Detection via Neural Network Anchoring,0.136589,"Our goal in this paper is to exploit heteroscedastic temperature scaling as a
calibration strategy for out of distribution (OOD) detection.
Heteroscedasticity here refers to the fact that the optimal temperature
parameter for each sample can be different, as opposed to conventional
approaches that use the same value for the entire distribution. To enable this,
we propose a new training strategy called anchoring that can estimate
appropriate temperature values for each sample, leading to state-of-the-art OOD
detection performance across several benchmarks. Using NTK theory, we show that
this temperature function estimate is closely linked to the epistemic
uncertainty of the classifier, which explains its behavior. In contrast to some
of the best-performing OOD detection approaches, our method does not require
exposure to additional outlier datasets, custom calibration objectives, or
model ensembling. Through empirical studies with different OOD detection
settings -- far OOD, near OOD, and semantically coherent OOD - we establish a
highly effective OOD detection approach. Code to reproduce our results is
available at github.com/LLNL/AMP",https://github.com/LLNL/AMP,-1
d6366757-6b64-41a7-8304-5a9abbc9bd3b,UWC: Unit-wise Calibration Towards Rapid Network Compression,0.0889593,"This paper introduces a post-training quantization~(PTQ) method achieving
highly efficient Convolutional Neural Network~ (CNN) quantization with high
performance. Previous PTQ methods usually reduce compression error via
performing layer-by-layer parameters calibration. However, with lower
representational ability of extremely compressed parameters (e.g., the
bit-width goes less than 4), it is hard to eliminate all the layer-wise errors.
This work addresses this issue via proposing a unit-wise feature reconstruction
algorithm based on an observation of second order Taylor series expansion of
the unit-wise error. It indicates that leveraging the interaction between
adjacent layers' parameters could compensate layer-wise errors better. In this
paper, we define several adjacent layers as a Basic-Unit, and present a
unit-wise post-training algorithm which can minimize quantization error. This
method achieves near-original accuracy on ImageNet and COCO when quantizing
FP32 models to INT4 and INT3.",None,-1
99fb1cdf-92a8-45cd-bc52-f5d521911d22,Robustness of Explanation Methods for NLP Models,0.108609,"Explanation methods have emerged as an important tool to highlight the
features responsible for the predictions of neural networks. There is mounting
evidence that many explanation methods are rather unreliable and susceptible to
malicious manipulations. In this paper, we particularly aim to understand the
robustness of explanation methods in the context of text modality. We provide
initial insights and results towards devising a successful adversarial attack
against text explanations. To our knowledge, this is the first attempt to
evaluate the adversarial robustness of an explanation method. Our experiments
show the explanation method can be largely disturbed for up to 86% of the
tested samples with small changes in the input sentence and its semantics.",None,-1
134bdada-a62b-4a91-bf19-950f201de7d5,DECK: Behavioral Tests to Improve Interpretability and Generalizability of BERT Models Detecting Depression from Text,0.0678724,"Models that accurately detect depression from text are important tools for
addressing the post-pandemic mental health crisis. BERT-based classifiers'
promising performance and the off-the-shelf availability make them great
candidates for this task. However, these models are known to suffer from
performance inconsistencies and poor generalization. In this paper, we
introduce the DECK (DEpression ChecKlist), depression-specific model
behavioural tests that allow better interpretability and improve
generalizability of BERT classifiers in depression domain. We create 23 tests
to evaluate BERT, RoBERTa and ALBERT depression classifiers on three datasets,
two Twitter-based and one clinical interview-based. Our evaluation shows that
these models: 1) are robust to certain gender-sensitive variations in text; 2)
rely on the important depressive language marker of the increased use of first
person pronouns; 3) fail to detect some other depression symptoms like suicidal
ideation. We also demonstrate that DECK tests can be used to incorporate
symptom-specific information in the training data and consistently improve
generalizability of all three BERT models, with an out-of-distribution F1-score
increase of up to 53.93%.",https://github.com/gauravchhabra/nlp-twitter-sentiment-analysis-project,-1
f308d051-ea73-46ac-9467-067ceeb703c2,A Walk in the Park: Learning to Walk in 20 Minutes With Model-Free Reinforcement Learning,0.784893,"Deep reinforcement learning is a promising approach to learning policies in
uncontrolled environments that do not require domain knowledge. Unfortunately,
due to sample inefficiency, deep RL applications have primarily focused on
simulated environments. In this work, we demonstrate that the recent
advancements in machine learning algorithms and libraries combined with a
carefully tuned robot controller lead to learning quadruped locomotion in only
20 minutes in the real world. We evaluate our approach on several indoor and
outdoor terrains which are known to be challenging for classical model-based
controllers. We observe the robot to be able to learn walking gait consistently
on all of these terrains. Finally, we evaluate our design decisions in a
simulated environment.",None,-1
d20a19c3-9851-4fbd-8c34-d4e9b43b23e3,Technology Ethics in Action: Critical and Interdisciplinary Perspectives,0.0611125,"This special issue interrogates the meaning and impacts of ""tech ethics"": the
embedding of ethics into digital technology research, development, use, and
governance. In response to concerns about the social harms associated with
digital technologies, many individuals and institutions have articulated the
need for a greater emphasis on ethics in digital technology. Yet as more groups
embrace the concept of ethics, critical discourses have emerged questioning
whose ethics are being centered, whether ""ethics"" is the appropriate frame for
improving technology, and what it means to develop ""ethical"" technology in
practice. This interdisciplinary issue takes up these questions, interrogating
the relationships among ethics, technology, and society in action. This special
issue engages with the normative and contested notions of ethics itself, how
ethics has been integrated with technology across domains, and potential paths
forward to support more just and egalitarian technology. Rather than starting
from philosophical theories, the authors in this issue orient their articles
around the real-world discourses and impacts of tech ethics--i.e., tech ethics
in action.",None,-1
aa88c883-5c6a-42eb-a5c9-2cb089a14a07,Reconstructing Action-Conditioned Human-Object Interactions Using Commonsense Knowledge Priors,0.778976,"We present a method for inferring diverse 3D models of human-object
interactions from images. Reasoning about how humans interact with objects in
complex scenes from a single 2D image is a challenging task given ambiguities
arising from the loss of information through projection. In addition, modeling
3D interactions requires the generalization ability towards diverse object
categories and interaction types. We propose an action-conditioned modeling of
interactions that allows us to infer diverse 3D arrangements of humans and
objects without supervision on contact regions or 3D scene geometry. Our method
extracts high-level commonsense knowledge from large language models (such as
GPT-3), and applies them to perform 3D reasoning of human-object interactions.
Our key insight is priors extracted from large language models can help in
reasoning about human-object contacts from textural prompts only. We
quantitatively evaluate the inferred 3D models on a large human-object
interaction dataset and show how our method leads to better 3D reconstructions.
We further qualitatively evaluate the effectiveness of our method on real
images and demonstrate its generalizability towards interaction types and
object categories.",https://github.com/open-mmlab/mmpose,-1
28cc2f77-a7c2-40a1-bce4-877f6c9fc5ff,"On the interplay of adversarial robustness and architecture components: patches, convolution and attention",0.30133,"In recent years novel architecture components for image classification have
been developed, starting with attention and patches used in transformers. While
prior works have analyzed the influence of some aspects of architecture
components on the robustness to adversarial attacks, in particular for vision
transformers, the understanding of the main factors is still limited. We
compare several (non)-robust classifiers with different architectures and study
their properties, including the effect of adversarial training on the
interpretability of the learnt features and robustness to unseen threat models.
An ablation from ResNet to ConvNeXt reveals key architectural changes leading
to almost $10\%$ higher $\ell_\infty$-robustness.",https://github.com/libffcv/ffcv-imagenet,-1
8ca2baad-f6f8-4701-850b-9b12947ee440,ContraReg: Contrastive Learning of Multi-modality Unsupervised Deformable Image Registration,0.694703,"Establishing voxelwise semantic correspondence across distinct imaging
modalities is a foundational yet formidable computer vision task. Current
multi-modality registration techniques maximize hand-crafted inter-domain
similarity functions, are limited in modeling nonlinear intensity-relationships
and deformations, and may require significant re-engineering or underperform on
new tasks, datasets, and domain pairs. This work presents ContraReg, an
unsupervised contrastive representation learning approach to multi-modality
deformable registration. By projecting learned multi-scale local patch features
onto a jointly learned inter-domain embedding space, ContraReg obtains
representations useful for non-rigid multi-modality alignment. Experimentally,
ContraReg achieves accurate and robust results with smooth and invertible
deformations across a series of baselines and ablations on a neonatal T1-T2
brain MRI registration task with all methods validated over a wide range of
deformation regularization strengths.",None,-1
8d9f4245-d097-483d-882b-50e45c1aaf3e,Write It Like You See It: Detectable Differences in Clinical Notes By Race Lead To Differential Model Recommendations,0.834701,"Clinical notes are becoming an increasingly important data source for machine
learning (ML) applications in healthcare. Prior research has shown that
deploying ML models can perpetuate existing biases against racial minorities,
as bias can be implicitly embedded in data. In this study, we investigate the
level of implicit race information available to ML models and human experts and
the implications of model-detectable differences in clinical notes. Our work
makes three key contributions. First, we find that models can identify patient
self-reported race from clinical notes even when the notes are stripped of
explicit indicators of race. Second, we determine that human experts are not
able to accurately predict patient race from the same redacted clinical notes.
Finally, we demonstrate the potential harm of this implicit information in a
simulation study, and show that models trained on these race-redacted clinical
notes can still perpetuate existing biases in clinical treatment decisions.",None,-1
14b05fa6-b5e2-4daa-802d-fa59a755f957,Prediction of GPU Failures Under Deep Learning Workloads,0.0914078,"Graphics processing units (GPUs) are the de facto standard for processing
deep learning (DL) tasks. Meanwhile, GPU failures, which are inevitable, cause
severe consequences in DL tasks: they disrupt distributed trainings, crash
inference services, and result in service level agreement violations. To
mitigate the problem caused by GPU failures, we propose to predict failures by
using ML models. This paper is the first to study prediction models of GPU
failures under large-scale production deep learning workloads. As a starting
point, we evaluate classic prediction models and observe that predictions of
these models are both inaccurate and unstable. To improve the precision and
stability of predictions, we propose several techniques, including parallel and
cascade model-ensemble mechanisms and a sliding training method. We evaluate
the performances of our various techniques on a four-month production dataset
including 350 million entries. The results show that our proposed techniques
improve the prediction precision from 46.3\% to 84.0\%.",None,27020
700cd16a-d8ac-4199-8123-cf8a90f98ab9,Detecting the Role of an Entity in Harmful Memes: Techniques and Their Limitations,0.245924,"Harmful or abusive online content has been increasing over time, raising
concerns for social media platforms, government agencies, and policymakers.
Such harmful or abusive content can have major negative impact on society,
e.g., cyberbullying can lead to suicides, rumors about COVID-19 can cause
vaccine hesitance, promotion of fake cures for COVID-19 can cause health harms
and deaths. The content that is posted and shared online can be textual,
visual, or a combination of both, e.g., in a meme. Here, we describe our
experiments in detecting the roles of the entities (hero, villain, victim) in
harmful memes, which is part of the CONSTRAINT-2022 shared task, as well as our
system for the task. We further provide a comparative analysis of different
experimental settings (i.e., unimodal, multimodal, attention, and
augmentation). For reproducibility, we make our experimental code publicly
available. \url{https://github.com/robi56/harmful_memes_block_fusion}",https://github.com/robi56/harmful_memes_block_fusion,-1
279bb0f9-8728-41d0-b4a0-11e130ddaa89,Robust Disentangled Variational Speech Representation Learning for Zero-shot Voice Conversion,0.962868,"Traditional studies on voice conversion (VC) have made progress with parallel
training data and known speakers. Good voice conversion quality is obtained by
exploring better alignment modules or expressive mapping functions. In this
study, we investigate zero-shot VC from a novel perspective of self-supervised
disentangled speech representation learning. Specifically, we achieve the
disentanglement by balancing the information flow between global speaker
representation and time-varying content representation in a sequential
variational autoencoder (VAE). A zero-shot voice conversion is performed by
feeding an arbitrary speaker embedding and content embeddings to the VAE
decoder. Besides that, an on-the-fly data augmentation training strategy is
applied to make the learned representation noise invariant. On TIMIT and VCTK
datasets, we achieve state-of-the-art performance on both objective evaluation,
i.e., speaker verification (SV) on speaker embedding and content embedding, and
subjective evaluation, i.e., voice naturalness and similarity, and remains to
be robust even with noisy source/target utterances.",https://jlian2.github.io/Robust-Voice-Style-Transfer,-1
bcc1667d-cabd-4552-a435-1fdf5a6e5642,Hybrid-Regressive Neural Machine Translation,0.637648,"In this work, we empirically confirm that non-autoregressive translation with
an iterative refinement mechanism (IR-NAT) suffers from poor acceleration
robustness because it is more sensitive to decoding batch size and computing
device setting than autoregressive translation (AT). Inspired by it, we attempt
to investigate how to combine the strengths of autoregressive and
non-autoregressive translation paradigms better. To this end, we demonstrate
through synthetic experiments that prompting a small number of AT's predictions
can promote one-shot non-autoregressive translation to achieve the equivalent
performance of IR-NAT. Following this line, we propose a new two-stage
translation prototype called hybrid-regressive translation (HRT). Specifically,
HRT first generates discontinuous sequences via autoregression (e.g., make a
prediction every k tokens, k>1) and then fills in all previously skipped tokens
at once in a non-autoregressive manner. We also propose a bag of techniques to
effectively and efficiently train HRT without adding any model parameters. HRT
achieves the state-of-the-art BLEU score of 28.49 on the WMT En-De task and is
at least 1.5x faster than AT, regardless of batch size and device. In addition,
another bonus of HRT is that it successfully inherits the good characteristics
of AT in the deep-encoder-shallow-decoder architecture. Concretely, compared to
the vanilla HRT with a 6-layer encoder and 6-layer decoder, the inference speed
of HRT with a 12-layer encoder and 1-layer decoder is further doubled on both
GPU and CPU without BLEU loss.",None,-1
35043258-95df-465c-aeb6-7168bcefa654,Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue,0.761775,"Video-grounded Dialogue (VGD) aims to decode an answer sentence to a question
regarding a given video and dialogue context. Despite the recent success of
multi-modal reasoning to generate answer sentences, existing dialogue systems
still suffer from a text hallucination problem, which denotes indiscriminate
text-copying from input texts without an understanding of the question. This is
due to learning spurious correlations from the fact that answer sentences in
the dataset usually include the words of input texts, thus the VGD system
excessively relies on copying words from input texts by hoping those words to
overlap with ground-truth texts. Hence, we design Text Hallucination Mitigating
(THAM) framework, which incorporates Text Hallucination Regularization (THR)
loss derived from the proposed information-theoretic text hallucination
measurement approach. Applying THAM with current dialogue systems validates the
effectiveness on VGD benchmarks (i.e., AVSD@DSTC7 and AVSD@DSTC8) and shows
enhanced interpretability.",https://github.com/dialogtekgeek/DSTC8-AVSD_ofﬁcial,-1
74fd7fa4-397c-456f-b18e-c8bfee8e002a,Pseudo Polynomial-Time Top-k Algorithms for d-DNNF Circuits,0.500213,"We are interested in computing $k$ most preferred models of a given d-DNNF
circuit $C$, where the preference relation is based on an algebraic structure
called a monotone, totally ordered, semigroup $(K, \otimes, <)$. In our
setting, every literal in $C$ has a value in $K$ and the value of an assignment
is an element of $K$ obtained by aggregating using $\otimes$ the values of the
corresponding literals. We present an algorithm that computes $k$ models of $C$
among those having the largest values w.r.t. $<$, and show that this algorithm
runs in time polynomial in $k$ and in the size of $C$. We also present a pseudo
polynomial-time algorithm for deriving the top-$k$ values that can be reached,
provided that an additional (but not very demanding) requirement on the
semigroup is satisfied. Under the same assumption, we present a pseudo
polynomial-time algorithm that transforms $C$ into a d-DNNF circuit $C'$
satisfied exactly by the models of $C$ having a value among the top-$k$ ones.
Finally, focusing on the semigroup $(\mathbb{N}, +, <)$, we compare on a large
number of instances the performances of our compilation-based algorithm for
computing $k$ top solutions with those of an algorithm tackling the same
problem, but based on a partial weighted MaxSAT solver.",https://gitlab.inria.fr/jdusart/winston,-1
16a6b8db-d396-4de3-b169-a3ab023a164d,Predicting Customer Lifetime Value in Free-to-Play Games,0.457857,"As game companies increasingly embrace a service-oriented business model, the
need for predictive models of players becomes more pressing. Multiple
activities, such as user acquisition, live game operations or game design need
to be supported with information about the choices made by the players and the
choices they could make in the future. This is especially true in the context
of free-to-play games, where the absence of a pay wall and the erratic nature
of the players' playing and spending behavior make predictions about the
revenue and allocation of budget and resources extremely challenging. In this
chapter we will present an overview of customer lifetime value modeling across
different fields, we will introduce the challenges specific to free-to-play
games across different platforms and genres and we will discuss the
state-of-the-art solutions with practical examples and references to existing
implementations.",https://github.com/CamDavidsonPilon/lifetimes,-1
edbbc7d2-a978-4361-b158-845e52f277d0,Learning to Estimate Shapley Values with Vision Transformers,0.61673,"Transformers have become a default architecture in computer vision, but
understanding what drives their predictions remains a challenging problem.
Current explanation approaches rely on attention values or input gradients, but
these provide a limited view of a model's dependencies. Shapley values offer a
theoretically sound alternative, but their computational cost makes them
impractical for large, high-dimensional models. In this work, we aim to make
Shapley values practical for vision transformers (ViTs). To do so, we first
leverage an attention masking approach to evaluate ViTs with partial
information, and we then develop a procedure to generate Shapley value
explanations via a separate, learned explainer model. Our experiments compare
Shapley values to many baseline methods (e.g., attention rollout, GradCAM,
LRP), and we find that our approach provides more accurate explanations than
existing methods for ViTs.",https://github.com/suinleelab/vit-shapley,-1
0dd5136e-aaae-4aab-b0b7-977b098bc38e,Interacting Hand-Object Pose Estimation via Dense Mutual Attention,0.64656,"3D hand-object pose estimation is the key to the success of many computer
vision applications. The main focus of this task is to effectively model the
interaction between the hand and an object. To this end, existing works either
rely on interaction constraints in a computationally-expensive iterative
optimization, or consider only a sparse correlation between sampled hand and
object keypoints. In contrast, we propose a novel dense mutual attention
mechanism that is able to model fine-grained dependencies between the hand and
the object. Specifically, we first construct the hand and object graphs
according to their mesh structures. For each hand node, we aggregate features
from every object node by the learned attention and vice versa for each object
node. Thanks to such dense mutual attention, our method is able to produce
physically plausible poses with high quality and real-time inference speed.
Extensive quantitative and qualitative experiments on large benchmark datasets
show that our method outperforms state-of-the-art methods. The code is
available at https://github.com/rongakowang/DenseMutualAttention.git.",https://github.com/rongakowang/DenseMutualAttention.git,24
adf30368-8a10-4f0a-b71e-51ab69655a6d,A unified 3D framework for Organs at Risk Localization and Segmentation for Radiation Therapy Planning,0.452145,"Automatic localization and segmentation of organs-at-risk (OAR) in CT are
essential pre-processing steps in medical image analysis tasks, such as
radiation therapy planning. For instance, the segmentation of OAR surrounding
tumors enables the maximization of radiation to the tumor area without
compromising the healthy tissues. However, the current medical workflow
requires manual delineation of OAR, which is prone to errors and is
annotator-dependent. In this work, we aim to introduce a unified 3D pipeline
for OAR localization-segmentation rather than novel localization or
segmentation architectures. To the best of our knowledge, our proposed
framework fully enables the exploitation of 3D context information inherent in
medical imaging. In the first step, a 3D multi-variate regression network
predicts organs' centroids and bounding boxes. Secondly, 3D organ-specific
segmentation networks are leveraged to generate a multi-organ segmentation map.
Our method achieved an overall Dice score of $0.9260\pm 0.18 \%$ on the
VISCERAL dataset containing CT scans with varying fields of view and multiple
organs.",None,-1
0e62bd34-f2d8-4fe8-a66a-aa6e894e2de9,SQuId: Measuring Speech Naturalness in Many Languages,0.798448,"Much of text-to-speech research relies on human evaluation, which incurs
heavy costs and slows down the development process. The problem is particularly
acute in heavily multilingual applications, where recruiting and polling judges
can take weeks. We introduce SQuId (Speech Quality Identification), a
multilingual naturalness prediction model trained on over a million ratings and
tested in 65 locales-the largest effort of this type to date. The main insight
is that training one model on many locales consistently outperforms mono-locale
baselines. We present our task, the model, and show that it outperforms a
competitive baseline based on w2v-BERT and VoiceMOS by 50.0%. We then
demonstrate the effectiveness of cross-locale transfer during fine-tuning and
highlight its effect on zero-shot locales, i.e., locales for which there is no
fine-tuning data. Through a series of analyses, we highlight the role of
non-linguistic effects such as sound artifacts in cross-locale transfer.
Finally, we present the effect of our design decision, e.g., model size,
pre-training diversity, and language rebalancing with several ablation
experiments.",None,10439
eb1bcb9e-65e7-4fda-a2ef-03c9cbc3e96b,Phenomenological Causality,0.338203,"Discussions on causal relations in real life often consider variables for
which the definition of causality is unclear since the notion of interventions
on the respective variables is obscure. Asking 'what qualifies an action for
being an intervention on the variable X' raises the question whether the action
impacted all other variables only through X or directly, which implicitly
refers to a causal model.
  To avoid this known circularity, we instead suggest a notion of
'phenomenological causality' whose basic concept is a set of elementary
actions. Then the causal structure is defined such that elementary actions
change only the causal mechanism at one node (e.g. one of the causal
conditionals in the Markov factorization). This way, the Principle of
Independent Mechanisms becomes the defining property of causal structure in
domains where causality is a more abstract phenomenon rather than being an
objective fact relying on hard-wired causal links between tangible objects. We
describe this phenomenological approach to causality for toy and hypothetical
real-world examples and argue that it is consistent with the causal Markov
condition when the system under consideration interacts with other variables
that control the elementary actions.",None,-1
dadc71e5-9fcb-4457-a505-94d393e428b9,Do ever larger octopi still amplify reporting biases? Evidence from judgments of typical colour,0.178424,"Language models (LMs) trained on raw texts have no direct access to the
physical world. Gordon and Van Durme (2013) point out that LMs can thus suffer
from reporting bias: texts rarely report on common facts, instead focusing on
the unusual aspects of a situation. If LMs are only trained on text corpora and
naively memorise local co-occurrence statistics, they thus naturally would
learn a biased view of the physical world. While prior studies have repeatedly
verified that LMs of smaller scales (e.g., RoBERTa, GPT-2) amplify reporting
bias, it remains unknown whether such trends continue when models are scaled
up. We investigate reporting bias from the perspective of colour in larger
language models (LLMs) such as PaLM and GPT-3. Specifically, we query LLMs for
the typical colour of objects, which is one simple type of perceptually
grounded physical common sense. Surprisingly, we find that LLMs significantly
outperform smaller LMs in determining an object's typical colour and more
closely track human judgments, instead of overfitting to surface patterns
stored in texts. This suggests that very large models of language alone are
able to overcome certain types of reporting bias that are characterized by
local co-occurrences.",https://github.com/google-research/language/tree/master/language/octopus-llm,-1
a514b3af-a9ae-4ce3-93d6-9780ace33b43,Splicing ViT Features for Semantic Appearance Transfer,0.990579,"We present a method for semantically transferring the visual appearance of
one natural image to another. Specifically, our goal is to generate an image in
which objects in a source structure image are ""painted"" with the visual
appearance of their semantically related objects in a target appearance image.
Our method works by training a generator given only a single
structure/appearance image pair as input. To integrate semantic information
into our framework - a pivotal component in tackling this task - our key idea
is to leverage a pre-trained and fixed Vision Transformer (ViT) model which
serves as an external semantic prior. Specifically, we derive novel
representations of structure and appearance extracted from deep ViT features,
untwisting them from the learned self-attention modules. We then establish an
objective function that splices the desired structure and appearance
representations, interweaving them together in the space of ViT features. Our
framework, which we term ""Splice"", does not involve adversarial training, nor
does it require any additional input information such as semantic segmentation
or correspondences, and can generate high-resolution results, e.g., work in HD.
We demonstrate high quality results on a variety of in-the-wild image pairs,
under significant variations in the number of objects, their pose and
appearance.",https://splice-vit.github.io,-1
7ffb1890-8f82-496d-ac34-42b11cc33271,A Multi-View Learning Approach to Enhance Automatic 12-Lead ECG Diagnosis Performance,0.071123,"The performances of commonly used electrocardiogram (ECG) diagnosis models
have recently improved with the introduction of deep learning (DL). However,
the impact of various combinations of multiple DL components and/or the role of
data augmentation techniques on the diagnosis have not been sufficiently
investigated. This study proposes an ensemble-based multi-view learning
approach with an ECG augmentation technique to achieve a higher performance
than traditional automatic 12-lead ECG diagnosis methods. The data analysis
results show that the proposed model reports an F1 score of 0.840, which
outperforms existing state-ofthe-art methods in the literature.",None,-1
372d9e52-cf6b-4006-87a9-52df9baafaaf,Sequence-to-Sequence Models for Extracting Information from Registration and Legal Documents,0.0346789,"A typical information extraction pipeline consists of token- or span-level
classification models coupled with a series of pre- and post-processing
scripts. In a production pipeline, requirements often change, with classes
being added and removed, which leads to nontrivial modifications to the source
code and the possible introduction of bugs. In this work, we evaluate
sequence-to-sequence models as an alternative to token-level classification
methods for information extraction of legal and registration documents. We
finetune models that jointly extract the information and generate the output
already in a structured format. Post-processing steps are learned during
training, thus eliminating the need for rule-based methods and simplifying the
pipeline. Furthermore, we propose a novel method to align the output with the
input text, thus facilitating system inspection and auditing. Our experiments
on four real-world datasets show that the proposed method is an alternative to
classical pipelines.",None,10818
4fe5bfa0-b997-4c45-ad8e-2cb0c67aaa1f,SOTIF Entropy: Online SOTIF Risk Quantification and Mitigation for Autonomous Driving,0.337696,"Autonomous driving confronts great challenges in complex traffic scenarios,
where the risk of Safety of the Intended Functionality (SOTIF) can be triggered
by the dynamic operational environment and system insufficiencies. The SOTIF
risk is reflected not only intuitively in the collision risk with objects
outside the autonomous vehicles (AVs), but also inherently in the performance
limitation risk of the implemented algorithms themselves. How to minimize the
SOTIF risk for autonomous driving is currently a critical, difficult, and
unresolved issue. Therefore, this paper proposes the ""Self-Surveillance and
Self-Adaption System"" as a systematic approach to online minimize the SOTIF
risk, which aims to provide a systematic solution for monitoring,
quantification, and mitigation of inherent and external risks. The core of this
system is the risk monitoring of the implemented artificial intelligence
algorithms within the AV. As a demonstration of the Self-Surveillance and
Self-Adaption System, the risk monitoring of the perception algorithm, i.e.,
YOLOv5 is highlighted. Moreover, the inherent perception algorithm risk and
external collision risk are jointly quantified via SOTIF entropy, which is then
propagated downstream to the decision-making module and mitigated. Finally,
several challenging scenarios are demonstrated, and the Hardware-in-the-Loop
experiments are conducted to verify the efficiency and effectiveness of the
system. The results demonstrate that the Self-Surveillance and Self-Adaption
System enables dependable online monitoring, quantification, and mitigation of
SOTIF risk in real-time critical traffic environments.",https://github.com/MarkDana/RealtimeConeDetection,-1
3b8f3a22-9832-4dad-a42c-cbb6cfeaeaa9,GBSVM: Granular-ball Support Vector Machine,0.890357,"GBSVM (Granular-ball Support Vector Machine) is a significant attempt to
construct a classifier using the coarse-to-fine granularity of a granular-ball
as input, rather than a single data point. It is the first classifier whose
input contains no points. However, the existing model has some errors, and its
dual model has not been derived. As a result, the current algorithm cannot be
implemented or applied. To address these problems, this paper has fixed the
errors of the original model of the existing GBSVM, and derived its dual model.
Furthermore, a particle swarm optimization algorithm is designed to solve the
dual model. The sequential minimal optimization algorithm is also carefully
designed to solve the dual model. The solution is faster and more stable than
the particle swarm optimization based version. The experimental results on the
UCI benchmark datasets demonstrate that GBSVM has good robustness and
efficiency. All codes have been released in the open source library at
http://www.cquptshuyinxia.com/GBSVM.html or https://github.com/syxiaa/GBSVM.",https://github.com/syxiaa/GBSVM,-1
7c76c621-ffb6-411e-a029-aab359535938,"Evaluating State of the Art, Forecasting Ensembles- and Meta-learning Strategies for Model Fusion",0.402565,"Techniques of hybridisation and ensemble learning are popular model fusion
techniques for improving the predictive power of forecasting methods. With
limited research that instigates combining these two promising approaches, this
paper focuses on the utility of the Exponential-Smoothing-Recurrent Neural
Network (ES-RNN) in the pool of base models for different ensembles. We compare
against some state of the art ensembling techniques and arithmetic model
averaging as a benchmark. We experiment with the M4 forecasting data set of
100,000 time-series, and the results show that the Feature-based Forecast Model
Averaging (FFORMA), on average, is the best technique for late data fusion with
the ES-RNN. However, considering the M4's Daily subset of data, stacking was
the only successful ensemble at dealing with the case where all base model
performances are similar. Our experimental results indicate that we attain
state of the art forecasting results compared to N-BEATS as a benchmark. We
conclude that model averaging is a more robust ensemble than model selection
and stacking strategies. Further, the results show that gradient boosting is
superior for implementing ensemble learning strategies.",https://github.com/Pieter-Cawood/FFORMA-ESRNN,-1
c27f8835-f831-4129-b770-f0cec1e7a102,Estimating the Entropy of Linguistic Distributions,0.280566,"Shannon entropy is often a quantity of interest to linguists studying the
communicative capacity of human language. However, entropy must typically be
estimated from observed data because researchers do not have access to the
underlying probability distribution that gives rise to these data. While
entropy estimation is a well-studied problem in other fields, there is not yet
a comprehensive exploration of the efficacy of entropy estimators for use with
linguistic data. In this work, we fill this void, studying the empirical
effectiveness of different entropy estimators for linguistic distributions. In
a replication of two recent information-theoretic linguistic studies, we find
evidence that the reported effect size is over-estimated due to over-reliance
on poor entropy estimators. Finally, we end our paper with concrete
recommendations for entropy estimation depending on distribution type and data
availability.",https://github.com/aryamanarora/entropy-estimation,-1
4b2c1ced-5949-4e3b-a4e4-a94fa510fbf0,Weighted Contrastive Hashing,0.210731,"The development of unsupervised hashing is advanced by the recent popular
contrastive learning paradigm. However, previous contrastive learning-based
works have been hampered by (1) insufficient data similarity mining based on
global-only image representations, and (2) the hash code semantic loss caused
by the data augmentation. In this paper, we propose a novel method, namely
Weighted Contrative Hashing (WCH), to take a step towards solving these two
problems. We introduce a novel mutual attention module to alleviate the problem
of information asymmetry in network features caused by the missing image
structure during contrative augmentation. Furthermore, we explore the
fine-grained semantic relations between images, i.e., we divide the images into
multiple patches and calculate similarities between patches. The aggregated
weighted similarities, which reflect the deep image relations, are distilled to
facilitate the hash codes learning with a distillation loss, so as to obtain
better retrieval performance. Extensive experiments show that the proposed WCH
significantly outperforms existing unsupervised hashing methods on three
benchmark datasets.",http://github.com/RosieYuu/WCH,-1
57a7912f-5fe4-4085-960d-66a851c12eef,Gradient-Guided Importance Sampling for Learning Binary Energy-Based Models,0.864665,"Learning energy-based models (EBMs) is known to be difficult especially on
discrete data where gradient-based learning strategies cannot be applied
directly. Although ratio matching is a sound method to learn discrete EBMs, it
suffers from expensive computation and excessive memory requirements, thereby
resulting in difficulties in learning EBMs on high-dimensional data. Motivated
by these limitations, in this study, we propose ratio matching with
gradient-guided importance sampling (RMwGGIS). Particularly, we use the
gradient of the energy function w.r.t. the discrete data space to approximately
construct the provably optimal proposal distribution, which is subsequently
used by importance sampling to efficiently estimate the original ratio matching
objective. We perform experiments on density modeling over synthetic discrete
data, graph generation, and training Ising models to evaluate our proposed
method. The experimental results demonstrate that our method can significantly
alleviate the limitations of ratio matching, perform more effectively in
practice, and scale to high-dimensional problems. Our implementation is
available at https://github.com/divelab/RMwGGIS.",https://github.com/divelab/RMwGGIS,-1
c0ae58b4-9e97-4a9e-84bd-0759f05613bb,TERMinator: A system for scientific texts processing,0.0642775,"This paper is devoted to the extraction of entities and semantic relations
between them from scientific texts, where we consider scientific terms as
entities. In this paper, we present a dataset that includes annotations for two
tasks and develop a system called TERMinator for the study of the influence of
language models on term recognition and comparison of different approaches for
relation extraction. Experiments show that language models pre-trained on the
target language are not always show the best performance. Also adding some
heuristic approaches may improve the overall quality of the particular task.
The developed tool and the annotated corpus are publicly available at
https://github.com/iis-research-team/terminator and may be useful for other
researchers.",https://github.com/iis-research-team/terminator,-1
00fa8add-a0a5-42d2-9128-3402e170410c,DigNet: Digging Clues from Local-Global Interactive Graph for Aspect-level Sentiment Classification,0.746621,"In aspect-level sentiment classification (ASC), state-of-the-art models
encode either syntax graph or relation graph to capture the local syntactic
information or global relational information. Despite the advantages of syntax
and relation graphs, they have respective shortages which are neglected,
limiting the representation power in the graph modeling process. To resolve
their limitations, we design a novel local-global interactive graph, which
marries their advantages by stitching the two graphs via interactive edges. To
model this local-global interactive graph, we propose a novel neural network
termed DigNet, whose core module is the stacked local-global interactive (LGI)
layers performing two processes: intra-graph message passing and cross-graph
message passing. In this way, the local syntactic and global relational
information can be reconciled as a whole in understanding the aspect-level
sentiment. Concretely, we design two variants of local-global interactive
graphs with different kinds of interactive edges and three variants of LGI
layers. We conduct experiments on several public benchmark datasets and the
results show that we outperform previous best scores by 3\%, 2.32\%, and 6.33\%
in terms of Macro-F1 on Lap14, Res14, and Res15 datasets, respectively,
confirming the effectiveness and superiority of the proposed local-global
interactive graph and DigNet.",None,-1
24cc29be-2823-4fe7-8a94-1e11e651450e,BioTABQA: Instruction Learning for Biomedical Table Question Answering,0.780816,"Table Question Answering (TQA) is an important but under-explored task. Most
of the existing QA datasets are in unstructured text format and only few of
them use tables as the context. To the best of our knowledge, none of TQA
datasets exist in the biomedical domain where tables are frequently used to
present information. In this paper, we first curate a table question answering
dataset, BioTABQA, using 22 templates and the context from a biomedical
textbook on differential diagnosis. BioTABQA can not only be used to teach a
model how to answer questions from tables but also evaluate how a model
generalizes to unseen questions, an important scenario for biomedical
applications. To achieve the generalization evaluation, we divide the templates
into 17 training and 5 cross-task evaluations. Then, we develop two baselines
using single and multi-tasks learning on BioTABQA. Furthermore, we explore
instructional learning, a recent technique showing impressive generalizing
performance. Experimental results show that our instruction-tuned model
outperforms single and multi-task baselines on an average by ~23% and ~6%
across various evaluation settings, and more importantly, instruction-tuned
model outperforms baselines by ~5% on cross-tasks.",None,14059
00d3c6c3-e96f-4e86-a26a-9b649d2d1a88,Preserving Semantics in Textual Adversarial Attacks,0.250709,"The growth of hateful online content, or hate speech, has been associated
with a global increase in violent crimes against minorities [23]. Harmful
online content can be produced easily, automatically and anonymously. Even
though, some form of auto-detection is already achieved through text
classifiers in NLP, they can be fooled by adversarial attacks. To strengthen
existing systems and stay ahead of attackers, we need better adversarial
attacks. In this paper, we show that up to 70% of adversarial examples
generated by adversarial attacks should be discarded because they do not
preserve semantics. We address this core weakness and propose a new, fully
supervised sentence embedding technique called Semantics-Preserving-Encoder
(SPE). Our method outperforms existing sentence encoders used in adversarial
attacks by achieving 1.2x - 5.1x better real attack success rate. We release
our code as a plugin that can be used in any existing adversarial attack to
improve its quality and speed up its execution.",https://github.com/DavidHerel/semantics-preserving-encoder,-1
ceb1021e-e003-4dac-a254-42a1931b71f4,Treewidth-aware Reductions of Normal ASP to SAT -- Is Normal ASP Harder than SAT after All?,0.973945,"Answer Set Programming (ASP) is a paradigm for modeling and solving problems
for knowledge representation and reasoning. There are plenty of results
dedicated to studying the hardness of (fragments of) ASP. So far, these studies
resulted in characterizations in terms of computational complexity as well as
in fine-grained insights presented in form of dichotomy-style results, lower
bounds when translating to other formalisms like propositional satisfiability
(SAT), and even detailed parameterized complexity landscapes. A generic
parameter in parameterized complexity originating from graph theory is the
so-called treewidth, which in a sense captures structural density of a program.
Recently, there was an increase in the number of treewidth-based solvers
related to SAT. While there are translations from (normal) ASP to SAT, no
reduction that preserves treewidth or at least keeps track of the treewidth
increase is known. In this paper we propose a novel reduction from normal ASP
to SAT that is aware of the treewidth, and guarantees that a slight increase of
treewidth is indeed sufficient. Further, we show a new result establishing
that, when considering treewidth, already the fragment of normal ASP is
slightly harder than SAT (under reasonable assumptions in computational
complexity). This also confirms that our reduction probably cannot be
significantly improved and that the slight increase of treewidth is
unavoidable. Finally, we present an empirical study of our novel reduction from
normal ASP to SAT, where we compare treewidth upper bounds that are obtained
via known decomposition heuristics. Overall, our reduction works better with
these heuristics than existing translations.",https://github.com/hmarkus/asp2sat translator,-1
5a9c2df0-3c67-44b8-9f79-d93af780e5a9,Multilingual Normalization of Temporal Expressions with Masked Language Models,0.543047,"The detection and normalization of temporal expressions is an important task
and preprocessing step for many applications. However, prior work on
normalization is rule-based, which severely limits the applicability in
real-world multilingual settings, due to the costly creation of new rules. We
propose a novel neural method for normalizing temporal expressions based on
masked language modeling. Our multilingual method outperforms prior rule-based
systems in many languages, and in particular, for low-resource languages with
performance improvements of up to 33 F1 on average compared to the state of the
art.",https://github.com/boschresearch/temporal-tagging-eacl,-1
0dbc5027-3050-4aa0-a3c0-87fefbba77f3,VLSP 2021 - ViMRC Challenge: Vietnamese Machine Reading Comprehension,0.909546,"One of the emerging research trends in natural language understanding is
machine reading comprehension (MRC) which is the task to find answers to human
questions based on textual data. Existing Vietnamese datasets for MRC research
concentrate solely on answerable questions. However, in reality, questions can
be unanswerable for which the correct answer is not stated in the given textual
data. To address the weakness, we provide the research community with a
benchmark dataset named UIT-ViQuAD 2.0 for evaluating the MRC task and question
answering systems for the Vietnamese language. We use UIT-ViQuAD 2.0 as a
benchmark dataset for the challenge on Vietnamese MRC at the Eighth Workshop on
Vietnamese Language and Speech Processing (VLSP 2021). This task attracted 77
participant teams from 34 universities and other organizations. In this
article, we present details of the organization of the challenge, an overview
of the methods employed by shared-task participants, and the results. The
highest performances are 77.24% in F1-score and 67.43% in Exact Match on the
private test set. The Vietnamese MRC systems proposed by the top 3 teams use
XLM-RoBERTa, a powerful pre-trained language model based on the transformer
architecture. The UIT-ViQuAD 2.0 dataset motivates researchers to further
explore the Vietnamese machine reading comprehension task and related tasks
such as question answering, question generation, and natural language
inference.",https://github.com/google-research/bert/blob/master/run_squad.py,2352
54a62b35-00ae-4f07-8e2d-bf067140bcb0,On Improving Summarization Factual Consistency from Natural Language Feedback,0.804394,"Despite the recent progress in language generation models, their outputs may
not always meet user expectations. In this work, we study whether informational
feedback in natural language can be leveraged to improve generation quality and
user preference alignment. To this end, we consider factual consistency in
summarization, the quality that the summary should only contain information
supported by the input documents, as the user-expected preference. We collect a
high-quality dataset, DeFacto, containing human demonstrations and
informational natural language feedback consisting of corrective instructions,
edited summaries, and explanations with respect to the factual consistency of
the summary. Using our dataset, we study three natural language generation
tasks: (1) editing a summary by following the human feedback, (2) generating
human feedback for editing the original summary, and (3) revising the initial
summary to correct factual errors by generating both the human feedback and
edited summary. We show that DeFacto can provide factually consistent
human-edited summaries and further insights into summarization factual
consistency thanks to its informational natural language feedback. We further
demonstrate that fine-tuned language models can leverage our dataset to improve
the summary factual consistency, while large language models lack the zero-shot
learning ability in our proposed tasks that require controllable text
generation.",https://github.com/microsoft/DeFacto,-1
73d13cf2-2beb-478a-a9c1-d6716c4cf3cd,Adaptive Risk-Tendency: Nano Drone Navigation in Cluttered Environments with Distributional Reinforcement Learning,0.228407,"Enabling the capability of assessing risk and making risk-aware decisions is
essential to applying reinforcement learning to safety-critical robots like
drones. In this paper, we investigate a specific case where a nano quadcopter
robot learns to navigate an apriori-unknown cluttered environment under partial
observability. We present a distributional reinforcement learning framework to
generate adaptive risk-tendency policies. Specifically, we propose to use lower
tail conditional variance of the learnt return distribution as intrinsic
uncertainty estimation, and use exponentially weighted average forecasting
(EWAF) to adapt the risk-tendency in accordance with the estimated uncertainty.
In simulation and real-world empirical results, we show that (1) the most
effective risk-tendency vary across states, (2) the agent with adaptive
risk-tendency achieves superior performance compared to risk-neutral policy or
risk-averse policy baselines.",None,-1
8d847d3a-c340-42f2-8652-a59851b00310,Dialog Inpainting: Turning Documents into Dialogs,0.899513,"Many important questions (e.g. ""How to eat healthier?"") require conversation
to establish context and explore in depth. However, conversational question
answering (ConvQA) systems have long been stymied by scarce training data that
is expensive to collect. To address this problem, we propose a new technique
for synthetically generating diverse and high-quality dialog data: dialog
inpainting. Our approach takes the text of any document and transforms it into
a two-person dialog between the writer and an imagined reader: we treat
sentences from the article as utterances spoken by the writer, and then use a
dialog inpainter to predict what the imagined reader asked or said in between
each of the writer's utterances. By applying this approach to passages from
Wikipedia and the web, we produce WikiDialog and WebDialog, two datasets
totalling 19 million diverse information-seeking dialogs -- 1,000x larger than
the largest existing ConvQA dataset. Furthermore, human raters judge the answer
adequacy and conversationality of WikiDialog to be as good or better than
existing manually-collected datasets. Using our inpainted data to pre-train
ConvQA retrieval systems, we significantly advance state-of-the-art across
three benchmarks (QReCC, OR-QuAC, TREC CAsT) yielding up to 40% relative gains
on standard evaluation metrics.",https://github.com/google-research/dialog-inpainting,-1
359dc1c1-2973-4600-a89c-17f72c7c7891,Towards Two-view 6D Object Pose Estimation: A Comparative Study on Fusion Strategy,0.110275,"Current RGB-based 6D object pose estimation methods have achieved noticeable
performance on datasets and real world applications. However, predicting 6D
pose from single 2D image features is susceptible to disturbance from changing
of environment and textureless or resemblant object surfaces. Hence, RGB-based
methods generally achieve less competitive results than RGBD-based methods,
which deploy both image features and 3D structure features. To narrow down this
performance gap, this paper proposes a framework for 6D object pose estimation
that learns implicit 3D information from 2 RGB images. Combining the learned 3D
information and 2D image features, we establish more stable correspondence
between the scene and the object models. To seek for the methods best utilizing
3D information from RGB inputs, we conduct an investigation on three different
approaches, including Early- Fusion, Mid-Fusion, and Late-Fusion. We ascertain
the Mid- Fusion approach is the best approach to restore the most precise 3D
keypoints useful for object pose estimation. The experiments show that our
method outperforms state-of-the-art RGB-based methods, and achieves comparable
results with RGBD-based methods.",None,19514
0d7975aa-7bbc-4b3c-914c-fcc94c0315f8,Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality,0.999972,"We present a novel task and dataset for evaluating the ability of vision and
language models to conduct visio-linguistic compositional reasoning, which we
call Winoground. Given two images and two captions, the goal is to match them
correctly - but crucially, both captions contain a completely identical set of
words, only in a different order. The dataset was carefully hand-curated by
expert annotators and is labeled with a rich set of fine-grained tags to assist
in analyzing model performance. We probe a diverse range of state-of-the-art
vision and language models and find that, surprisingly, none of them do much
better than chance. Evidently, these models are not as skilled at
visio-linguistic compositional reasoning as we might have hoped. We perform an
extensive analysis to obtain insights into how future work might try to
mitigate these models' shortcomings. We aim for Winoground to serve as a useful
evaluation set for advancing the state of the art and driving further progress
in the field. The dataset is available at
https://huggingface.co/datasets/facebook/winoground.",None,20526
1dd7c115-4890-431b-aea5-d833149b7ec0,Applying a Generic Sequence-to-Sequence Model for Simple and Effective Keyphrase Generation,0.106235,"In recent years, a number of keyphrase generation (KPG) approaches were
proposed consisting of complex model architectures, dedicated training
paradigms and decoding strategies. In this work, we opt for simplicity and show
how a commonly used seq2seq language model, BART, can be easily adapted to
generate keyphrases from the text in a single batch computation using a simple
training procedure. Empirical results on five benchmarks show that our approach
is as good as the existing state-of-the-art KPG systems, but using a much
simpler and easy to deploy framework.",https://github.com/memray/OpenNMT-kpg-release,3252
3f49102d-2037-47f3-a083-807d83751d8a,Reliable Detection of Doppelgängers based on Deep Face Representations,0.0221728,"Doppelg\""angers (or lookalikes) usually yield an increased probability of
false matches in a facial recognition system, as opposed to random face image
pairs selected for non-mated comparison trials. In this work, we assess the
impact of doppelg\""angers on the HDA Doppelg\""anger and Disguised Faces in The
Wild databases using a state-of-the-art face recognition system. It is found
that doppelg\""anger image pairs yield very high similarity scores resulting in
a significant increase of false match rates. Further, we propose a
doppelg\""anger detection method which distinguishes doppelg\""angers from mated
comparison trials by analysing differences in deep representations obtained
from face image pairs. The proposed detection system employs a machine
learning-based classifier, which is trained with generated doppelg\""anger image
pairs utilising face morphing techniques. Experimental evaluations conducted on
the HDA Doppelg\""anger and Look-Alike Face databases reveal a detection equal
error rate of approximately 2.7% for the task of separating mated
authentication attempts from doppelg\""angers.",None,-1
811d4774-fc07-4ff3-a6aa-0aac8f3f0bf4,Modeling Emergent Lexicon Formation with a Self-Reinforcing Stochastic Process,0.118322,"We introduce FiLex, a self-reinforcing stochastic process which models finite
lexicons in emergent language experiments. The central property of FiLex is
that it is a self-reinforcing process, parallel to the intuition that the more
a word is used in a language, the more its use will continue. As a theoretical
model, FiLex serves as a way to both explain and predict the behavior of the
emergent language system. We empirically test FiLex's ability to capture the
relationship between the emergent language's hyperparameters and the lexicon's
Shannon entropy.",https://github.com/brendon-boldt/filex-emergent-language,-1
7ed23a2c-4e04-4bc9-8335-06e12be4fb4f,Lagrangian Manifold Monte Carlo on Monge Patches,0.494666,"The efficiency of Markov Chain Monte Carlo (MCMC) depends on how the
underlying geometry of the problem is taken into account. For distributions
with strongly varying curvature, Riemannian metrics help in efficient
exploration of the target distribution. Unfortunately, they have significant
computational overhead due to e.g. repeated inversion of the metric tensor, and
current geometric MCMC methods using the Fisher information matrix to induce
the manifold are in practice slow. We propose a new alternative Riemannian
metric for MCMC, by embedding the target distribution into a higher-dimensional
Euclidean space as a Monge patch and using the induced metric determined by
direct geometric reasoning. Our metric only requires first-order gradient
information and has fast inverse and determinants, and allows reducing the
computational complexity of individual iterations from cubic to quadratic in
the problem dimensionality. We demonstrate how Lagrangian Monte Carlo in this
metric efficiently explores the target distributions.",https://github.com/mahaa2/EmbeddedLMC,-1
1b1ad592-7ffc-4d5e-abee-88caad768d64,Demystifying Prompts in Language Models via Perplexity Estimation,0.953758,"Language models can be prompted to perform a wide variety of zero- and
few-shot learning problems. However, performance varies significantly with the
choice of prompt, and we do not yet understand why this happens or how to pick
the best prompts. In this work, we analyze the factors that contribute to this
variance and establish a new empirical hypothesis: the performance of a prompt
is coupled with the extent to which the model is familiar with the language it
contains. Over a wide range of tasks, we show that the lower the perplexity of
the prompt is, the better the prompt is able to perform the task. As a result,
we devise a method for creating prompts: (1) automatically extend a small seed
set of manually written prompts by paraphrasing using GPT3 and backtranslation
and (2) choose the lowest perplexity prompts to get significant gains in
performance.",https://github.com/bigscience-workshop/promptsource,104111
9185d88d-e8a4-4f09-84ac-0b712dfa2fcb,Reuse your features: unifying retrieval and feature-metric alignment,0.150453,"We propose a compact pipeline to unify all the steps of Visual Localization:
image retrieval, candidate re-ranking and initial pose estimation, and camera
pose refinement. Our key assumption is that the deep features used for these
individual tasks share common characteristics, so we should reuse them in all
the procedures of the pipeline. Our DRAN (Deep Retrieval and image Alignment
Network) is able to extract global descriptors for efficient image retrieval,
use intermediate hierarchical features to re-rank the retrieval list and
produce an initial pose guess, which is finally refined by means of a
feature-metric optimization based on learned deep multi-scale dense features.
DRAN is the first single network able to produce the features for the three
steps of visual localization. DRAN achieves competitive performance in terms of
robustness and accuracy under challenging conditions in public benchmarks,
outperforming other unified approaches and consuming lower computational and
memory cost than its counterparts using multiple networks. Code and models will
be publicly available at https://github.com/jmorlana/DRAN.",https://github.com/jmorlana/DRAN,-1
48f5a57a-72e8-4621-9fc3-d3bf3c3979e5,Exploiting Unlabeled Data for Target-Oriented Opinion Words Extraction,0.215185,"Target-oriented Opinion Words Extraction (TOWE) is a fine-grained sentiment
analysis task that aims to extract the corresponding opinion words of a given
opinion target from the sentence. Recently, deep learning approaches have made
remarkable progress on this task. Nevertheless, the TOWE task still suffers
from the scarcity of training data due to the expensive data annotation
process. Limited labeled data increase the risk of distribution shift between
test data and training data. In this paper, we propose exploiting massive
unlabeled data to reduce the risk by increasing the exposure of the model to
varying distribution shifts. Specifically, we propose a novel Multi-Grained
Consistency Regularization (MGCR) method to make use of unlabeled data and
design two filters specifically for TOWE to filter noisy data at different
granularity. Extensive experimental results on four TOWE benchmark datasets
indicate the superiority of MGCR compared with current state-of-the-art
methods. The in-depth analysis also demonstrates the effectiveness of the
different-granularity filters. Our codes are available at
https://github.com/TOWESSL/TOWESSL.",https://github.com/TOWESSL/TOWESSL,-1
c4d734b8-da77-4bbb-a637-5b5223200a12,Unsupervised 4D LiDAR Moving Object Segmentation in Stationary Settings with Multivariate Occupancy Time Series,0.607655,"In this work, we address the problem of unsupervised moving object
segmentation (MOS) in 4D LiDAR data recorded from a stationary sensor, where no
ground truth annotations are involved. Deep learning-based state-of-the-art
methods for LiDAR MOS strongly depend on annotated ground truth data, which is
expensive to obtain and scarce in existence. To close this gap in the
stationary setting, we propose a novel 4D LiDAR representation based on
multivariate time series that relaxes the problem of unsupervised MOS to a time
series clustering problem. More specifically, we propose modeling the change in
occupancy of a voxel by a multivariate occupancy time series (MOTS), which
captures spatio-temporal occupancy changes on the voxel level and its
surrounding neighborhood. To perform unsupervised MOS, we train a neural
network in a self-supervised manner to encode MOTS into voxel-level feature
representations, which can be partitioned by a clustering algorithm into moving
or stationary. Experiments on stationary scenes from the Raw KITTI dataset show
that our fully unsupervised approach achieves performance that is comparable to
that of supervised state-of-the-art approaches.",https://github.com/thkreutz/umosmots,-1
65f8c301-4fcd-4cfd-8029-98ef64a82f0e,Best of Both Worlds Model Selection,0.19768,"We study the problem of model selection in bandit scenarios in the presence
of nested policy classes, with the goal of obtaining simultaneous adversarial
and stochastic (""best of both worlds"") high-probability regret guarantees. Our
approach requires that each base learner comes with a candidate regret bound
that may or may not hold, while our meta algorithm plays each base learner
according to a schedule that keeps the base learner's candidate regret bounds
balanced until they are detected to violate their guarantees. We develop
careful mis-specification tests specifically designed to blend the above model
selection criterion with the ability to leverage the (potentially benign)
nature of the environment. We recover the model selection guarantees of the
CORRAL algorithm for adversarial environments, but with the additional benefit
of achieving high probability regret bounds, specifically in the case of nested
adversarial linear bandits. More importantly, our model selection results also
hold simultaneously in stochastic environments under gap assumptions. These are
the first theoretical results that achieve best of both world (stochastic and
adversarial) guarantees while performing model selection in (linear) bandit
scenarios.",None,-1
e8e06637-9588-49a2-a659-4c9aad7ea5eb,Plausible May Not Be Faithful: Probing Object Hallucination in Vision-Language Pre-training,0.45366,"Large-scale vision-language pre-trained (VLP) models are prone to hallucinate
non-existent visual objects when generating text based on visual information.
In this paper, we systematically study the object hallucination problem from
three aspects. First, we examine recent state-of-the-art VLP models, showing
that they still hallucinate frequently, and models achieving better scores on
standard metrics (e.g., CIDEr) could be more unfaithful. Second, we investigate
how different types of image encoding in VLP influence hallucination, including
region-based, grid-based, and patch-based. Surprisingly, we find that
patch-based features perform the best and smaller patch resolution yields a
non-trivial reduction in object hallucination. Third, we decouple various VLP
objectives and demonstrate that token-level image-text alignment and controlled
generation are crucial to reducing hallucination. Based on that, we propose a
simple yet effective VLP loss named ObjMLM to further mitigate object
hallucination. Results show that it reduces object hallucination by up to 17.4%
when tested on two benchmarks (COCO Caption for in-domain and NoCaps for
out-of-domain evaluation).",https://github.com/wenliangdai/VLP-Object-Hallucination,-1
24a64b6c-e196-45a0-81b7-66990166e8a4,Revisiting Neural Scaling Laws in Language and Vision,0.722463,"The remarkable progress in deep learning in recent years is largely driven by
improvements in scale, where bigger models are trained on larger datasets for
longer schedules. To predict the benefit of scale empirically, we argue for a
more rigorous methodology based on the extrapolation loss, instead of reporting
the best-fitting (interpolating) parameters. We then present a recipe for
estimating scaling law parameters reliably from learning curves. We demonstrate
that it extrapolates more accurately than previous methods in a wide range of
architecture families across several domains, including image classification,
neural machine translation (NMT) and language modeling, in addition to tasks
from the BIG-Bench evaluation benchmark. Finally, we release a benchmark
dataset comprising of 90 evaluation tasks to facilitate research in this
domain.",https://github.com/google-research/revisiting_neural_scaling_laws,-1
a7cc4f16-1ac4-47cc-a7d4-c76de47f3100,Alignment-Uniformity aware Representation Learning for Zero-shot Video Classification,0.311788,"Most methods tackle zero-shot video classification by aligning
visual-semantic representations within seen classes, which limits
generalization to unseen classes. To enhance model generalizability, this paper
presents an end-to-end framework that preserves alignment and uniformity
properties for representations on both seen and unseen classes. Specifically,
we formulate a supervised contrastive loss to simultaneously align
visual-semantic features (i.e., alignment) and encourage the learned features
to distribute uniformly (i.e., uniformity). Unlike existing methods that only
consider the alignment, we propose uniformity to preserve maximal-info of
existing features, which improves the probability that unobserved features fall
around observed data. Further, we synthesize features of unseen classes by
proposing a class generator that interpolates and extrapolates the features of
seen classes. Besides, we introduce two metrics, closeness and dispersion, to
quantify the two properties and serve as new measurements of model
generalizability. Experiments show that our method significantly outperforms
SoTA by relative improvements of 28.1% on UCF101 and 27.0% on HMDB51. Code is
available.",https://github.com/ShipuLoveMili/CVPR2022-AURL,-1
74df8a5f-ed03-4d7a-91aa-2aa5a89e7e4d,Abstraction-Refinement for Hierarchical Probabilistic Models,0.345516,"Markov decision processes are a ubiquitous formalism for modelling systems
with non-deterministic and probabilistic behavior. Verification of these models
is subject to the famous state space explosion problem. We alleviate this
problem by exploiting a hierarchical structure with repetitive parts. This
structure not only occurs naturally in robotics, but also in probabilistic
programs describing, e.g., network protocols. Such programs often repeatedly
call a subroutine with similar behavior. In this paper, we focus on a local
case, in which the subroutines have a limited effect on the overall system
state. The key ideas to accelerate analysis of such programs are (1) to treat
the behavior of the subroutine as uncertain and only remove this uncertainty by
a detailed analysis if needed, and (2) to abstract similar subroutines into a
parametric template, and then analyse this template. These two ideas are
embedded into an abstraction-refinement loop that analyses hierarchical MDPs. A
prototypical implementation shows the efficacy of the approach.",None,-1
238737e5-eaf8-4922-a9a8-93f04ba71a6b,Sufficient Statistic Memory Approximate Message Passing,0.838186,"Approximate message passing (AMP) type algorithms have been widely used in
the signal reconstruction of certain large random linear systems. A key feature
of the AMP-type algorithms is that their dynamics can be correctly described by
state evolution. However, state evolution does not necessarily guarantee the
convergence of iterative algorithms. To solve the convergence problem of
AMP-type algorithms in principle, this paper proposes a memory AMP (MAMP) under
a sufficient statistic condition, named sufficient statistic MAMP (SS-MAMP). We
show that the covariance matrices of SS-MAMP are L-banded and convergent. Given
an arbitrary MAMP, we can construct the SS-MAMP by damping, which not only
ensures the convergence, but also preserves the orthogonality, i.e., its
dynamics can be correctly described by state evolution.",None,-1
f7714a45-667f-48c5-b683-55e30cb8f7b3,Dexterous Imitation Made Easy: A Learning-Based Framework for Efficient Dexterous Manipulation,0.898629,"Optimizing behaviors for dexterous manipulation has been a longstanding
challenge in robotics, with a variety of methods from model-based control to
model-free reinforcement learning having been previously explored in
literature. Perhaps one of the most powerful techniques to learn complex
manipulation strategies is imitation learning. However, collecting and learning
from demonstrations in dexterous manipulation is quite challenging. The
complex, high-dimensional action-space involved with multi-finger control often
leads to poor sample efficiency of learning-based methods. In this work, we
propose 'Dexterous Imitation Made Easy' (DIME) a new imitation learning
framework for dexterous manipulation. DIME only requires a single RGB camera to
observe a human operator and teleoperate our robotic hand. Once demonstrations
are collected, DIME employs standard imitation learning methods to train
dexterous manipulation policies. On both simulation and real robot benchmarks
we demonstrate that DIME can be used to solve complex, in-hand manipulation
tasks such as 'flipping', 'spinning', and 'rotating' objects with the Allegro
hand. Our framework along with pre-collected demonstrations is publicly
available at https://nyu-robot-learning.github.io/dime.",https://nyu-robot-learning.github.io/dime,-1
c204860d-870d-4c05-8834-68a4dfc96ba6,Hitchhiker's Guide to Super-Resolution: Introduction and Recent Advances,0.676772,"With the advent of Deep Learning (DL), Super-Resolution (SR) has also become
a thriving research area. However, despite promising results, the field still
faces challenges that require further research e.g., allowing flexible
upsampling, more effective loss functions, and better evaluation metrics. We
review the domain of SR in light of recent advances, and examine
state-of-the-art models such as diffusion (DDPM) and transformer-based SR
models. We present a critical discussion on contemporary strategies used in SR,
and identify promising yet unexplored research directions. We complement
previous surveys by incorporating the latest developments in the field such as
uncertainty-driven losses, wavelet networks, neural architecture search, novel
normalization methods, and the latests evaluation techniques. We also include
several visualizations for the models and methods throughout each chapter in
order to facilitate a global understanding of the trends in the field. This
review is ultimately aimed at helping researchers to push the boundaries of DL
applied to SR.",None,-1
f575b10d-1ee5-4829-a070-c5419d4f78f6,Assembly101: A Large-Scale Multi-View Video Dataset for Understanding Procedural Activities,0.999974,"Assembly101 is a new procedural activity dataset featuring 4321 videos of
people assembling and disassembling 101 ""take-apart"" toy vehicles. Participants
work without fixed instructions, and the sequences feature rich and natural
variations in action ordering, mistakes, and corrections. Assembly101 is the
first multi-view action dataset, with simultaneous static (8) and egocentric
(4) recordings. Sequences are annotated with more than 100K coarse and 1M
fine-grained action segments, and 18M 3D hand poses. We benchmark on three
action understanding tasks: recognition, anticipation and temporal
segmentation. Additionally, we propose a novel task of detecting mistakes. The
unique recording format and rich set of annotations allow us to investigate
generalization to new toys, cross-view transfer, long-tailed distributions, and
pose vs. appearance. We envision that Assembly101 will serve as a new challenge
to investigate various activity understanding problems.",https://assembly-101.github.io/,-1
6ac01f2f-c450-4814-8304-f563e9996bda,A Dataless FaceSwap Detection Approach Using Synthetic Images,0.0712002,"Face swapping technology used to create ""Deepfakes"" has advanced
significantly over the past few years and now enables us to create realistic
facial manipulations. Current deep learning algorithms to detect deepfakes have
shown promising results, however, they require large amounts of training data,
and as we show they are biased towards a particular ethnicity. We propose a
deepfake detection methodology that eliminates the need for any real data by
making use of synthetically generated data using StyleGAN3. This not only
performs at par with the traditional training methodology of using real data
but it shows better generalization capabilities when finetuned with a small
amount of real data. Furthermore, this also reduces biases created by facial
image datasets that might have sparse data from particular ethnicities.",https://github.com/anubhav1997/youneednodataset,-1
e08d1e7b-f626-4c9c-804d-3f7cdc03509b,Polysemanticity and Capacity in Neural Networks,0.664065,"Individual neurons in neural networks often represent a mixture of unrelated
features. This phenomenon, called polysemanticity, can make interpreting neural
networks more difficult and so we aim to understand its causes. We propose
doing so through the lens of feature \emph{capacity}, which is the fractional
dimension each feature consumes in the embedding space. We show that in a toy
model the optimal capacity allocation tends to monosemantically represent the
most important features, polysemantically represent less important features (in
proportion to their impact on the loss), and entirely ignore the least
important features. Polysemanticity is more prevalent when the inputs have
higher kurtosis or sparsity and more prevalent in some architectures than
others. Given an optimal allocation of capacity, we go on to study the geometry
of the embedding space. We find a block-semi-orthogonal structure, with
differing block sizes in different models, highlighting the impact of model
architecture on the interpretability of its neurons.",None,-1
9a8f7ddf-ed0d-4eda-9ded-6b175f40313c,Post-hoc analysis of Arabic transformer models,0.0182287,"Arabic is a Semitic language which is widely spoken with many dialects. Given
the success of pre-trained language models, many transformer models trained on
Arabic and its dialects have surfaced. While there have been an extrinsic
evaluation of these models with respect to downstream NLP tasks, no work has
been carried out to analyze and compare their internal representations. We
probe how linguistic information is encoded in the transformer models, trained
on different Arabic dialects. We perform a layer and neuron analysis on the
models using morphological tagging tasks for different dialects of Arabic and a
dialectal identification task. Our analysis enlightens interesting findings
such as: i) word morphology is learned at the lower and middle layers, ii)
while syntactic dependencies are predominantly captured at the higher layers,
iii) despite a large overlap in their vocabulary, the MSA-based models fail to
capture the nuances of Arabic dialects, iv) we found that neurons in embedding
layers are polysemous in nature, while the neurons in middle layers are
exclusive to specific properties",None,-1
cd4bb8aa-eda2-4cb3-8c35-56cfddc1d3b6,MatteFormer: Transformer-Based Image Matting via Prior-Tokens,0.953863,"In this paper, we propose a transformer-based image matting model called
MatteFormer, which takes full advantage of trimap information in the
transformer block. Our method first introduces a prior-token which is a global
representation of each trimap region (e.g. foreground, background and unknown).
These prior-tokens are used as global priors and participate in the
self-attention mechanism of each block. Each stage of the encoder is composed
of PAST (Prior-Attentive Swin Transformer) block, which is based on the Swin
Transformer block, but differs in a couple of aspects: 1) It has PA-WSA
(Prior-Attentive Window Self-Attention) layer, performing self-attention not
only with spatial-tokens but also with prior-tokens. 2) It has prior-memory
which saves prior-tokens accumulatively from the previous blocks and transfers
them to the next block. We evaluate our MatteFormer on the commonly used image
matting datasets: Composition-1k and Distinctions-646. Experiment results show
that our proposed method achieves state-of-the-art performance with a large
margin. Our codes are available at https://github.com/webtoon/matteformer.",https://github.com/webtoon/matteformer,-1
135155b2-74a0-45aa-9ad8-a700769bc8d1,Open Domain Multi-document Summarization: A Comprehensive Study of Model Brittleness under Retrieval,0.578017,"Multi-document summarization (MDS) assumes a set of topic-related documents
are provided as input. In practice, this document set is not always available;
it would need to be retrieved given an information need, i.e. a question or
topic statement, a setting we dub ""open-domain"" MDS. We study this more
challenging setting by formalizing the task and bootstrapping it using existing
datasets, retrievers and summarizers. Via extensive automatic and human
evaluation, we determine: (1) state-of-the-art summarizers suffer large
reductions in performance when applied to open-domain MDS, (2) additional
training in the open-domain setting can reduce this sensitivity to imperfect
retrieval, and (3) summarizers are insensitive to the retrieval of duplicate
documents and the order of retrieved documents, but highly sensitive to other
errors, like the retrieval of irrelevant documents. Based on our results, we
provide practical guidelines to enable future work on open-domain MDS, e.g. how
to choose the number of retrieved documents to summarize. Our results suggest
that new retrieval and summarization methods and annotated resources for
training and evaluation are necessary for further progress in the open-domain
setting.",https://github.com/allenai/open-mds,13874
8d29d107-fb38-4e60-b20d-9f7b4b1908c5,Systematic Evaluation of Predictive Fairness,0.170699,"Mitigating bias in training on biased datasets is an important open problem.
Several techniques have been proposed, however the typical evaluation regime is
very limited, considering very narrow data conditions. For instance, the effect
of target class imbalance and stereotyping is under-studied. To address this
gap, we examine the performance of various debiasing methods across multiple
tasks, spanning binary classification (Twitter sentiment), multi-class
classification (profession prediction), and regression (valence prediction).
Through extensive experimentation, we find that data conditions have a strong
influence on relative model performance, and that general conclusions cannot be
drawn about method efficacy when evaluating only on standard datasets, as is
current practice in fairness research.",https://github.com/HanXudong/Systematic_Evaluation_of_Predictive_Fairness,-1
771af564-1f55-4264-a941-90dc101de501,Exploring Extreme Parameter Compression for Pre-trained Language Models,0.26565,"Recent work explored the potential of large-scale Transformer-based
pre-trained models, especially Pre-trained Language Models (PLMs) in natural
language processing. This raises many concerns from various perspectives, e.g.,
financial costs and carbon emissions. Compressing PLMs like BERT with
negligible performance loss for faster inference and cheaper deployment has
attracted much attention. In this work, we aim to explore larger compression
ratios for PLMs, among which tensor decomposition is a potential but
under-investigated one. Two decomposition and reconstruction protocols are
further proposed to improve the effectiveness and efficiency during
compression. Our compressed BERT with ${1}/{7}$ parameters in Transformer
layers performs on-par with, sometimes slightly better than the original BERT
in GLUE benchmark. A tiny version achieves $96.7\%$ performance of BERT-base
with $ {1}/{48} $ encoder parameters (i.e., less than 2M parameters excluding
the embedding layer) and $2.7 \times$ faster on inference. To show that the
proposed method is orthogonal to existing compression methods like knowledge
distillation, we also explore the benefit of the proposed method on a distilled
BERT.",None,-1
06695a10-f218-4468-bcbe-c57e63eb4406,RBP-Pose: Residual Bounding Box Projection for Category-Level Pose Estimation,0.978366,"Category-level object pose estimation aims to predict the 6D pose as well as
the 3D metric size of arbitrary objects from a known set of categories. Recent
methods harness shape prior adaptation to map the observed point cloud into the
canonical space and apply Umeyama algorithm to recover the pose and size.
However, their shape prior integration strategy boosts pose estimation
indirectly, which leads to insufficient pose-sensitive feature extraction and
slow inference speed. To tackle this problem, in this paper, we propose a novel
geometry-guided Residual Object Bounding Box Projection network RBP-Pose that
jointly predicts object pose and residual vectors describing the displacements
from the shape-prior-indicated object surface projections on the bounding box
towards the real surface projections. Such definition of residual vectors is
inherently zero-mean and relatively small, and explicitly encapsulates spatial
cues of the 3D object for robust and accurate pose regression. We enforce
geometry-aware consistency terms to align the predicted pose and residual
vectors to further boost performance.",https://github.com/lolrudy/RBP_Pose,22417
8f50998e-a81e-431f-8f63-b8dc352c841c,Complexity of Representations in Deep Learning,0.146039,"Deep neural networks use multiple layers of functions to map an object
represented by an input vector progressively to different representations, and
with sufficient training, eventually to a single score for each class that is
the output of the final decision function. Ideally, in this output space, the
objects of different classes achieve maximum separation. Motivated by the need
to better understand the inner working of a deep neural network, we analyze the
effectiveness of the learned representations in separating the classes from a
data complexity perspective. Using a simple complexity measure, a popular
benchmarking task, and a well-known architecture design, we show how the data
complexity evolves through the network, how it changes during training, and how
it is impacted by the network design and the availability of training samples.
We discuss the implications of the observations and the potentials for further
studies.",https://github.com/osmr/imgclsmob/tree/master/pytorch,-1
3129d255-6a82-43fe-ada0-fe52edf0ff15,"Paraphrasing, textual entailment, and semantic similarity above word level",0.108878,"This dissertation explores the linguistic and computational aspects of the
meaning relations that can hold between two or more complex linguistic
expressions (phrases, clauses, sentences, paragraphs). In particular, it
focuses on Paraphrasing, Textual Entailment, Contradiction, and Semantic
Similarity.
  In Part I: ""Similarity at the Level of Words and Phrases"", I study the
Distributional Hypothesis (DH) and explore several different methodologies for
quantifying semantic similarity at the levels of words and short phrases.
  In Part II: ""Paraphrase Typology and Paraphrase Identification"", I focus on
the meaning relation of paraphrasing and the empirical task of automated
Paraphrase Identification (PI).
  In Part III: ""Paraphrasing, Textual Entailment, and Semantic Similarity"", I
present a novel direction in the research on textual meaning relations,
resulting from joint research carried out on on paraphrasing, textual
entailment, contradiction, and semantic similarity.",None,12
7488956b-3ade-4cc3-ae69-68eeaccf4382,PoseGU: 3D Human Pose Estimation with Novel Human Pose Generator and Unbiased Learning,0.265801,"3D pose estimation has recently gained substantial interests in computer
vision domain. Existing 3D pose estimation methods have a strong reliance on
large size well-annotated 3D pose datasets, and they suffer poor model
generalization on unseen poses due to limited diversity of 3D poses in training
sets. In this work, we propose PoseGU, a novel human pose generator that
generates diverse poses with access only to a small size of seed samples, while
equipping the Counterfactual Risk Minimization to pursue an unbiased evaluation
objective. Extensive experiments demonstrate PoseGU outforms almost all the
state-of-the-art 3D human pose methods under consideration over three popular
benchmark datasets. Empirical analysis also proves PoseGU generates 3D poses
with improved data diversity and better generalization ability.",None,-1
6685a24a-885d-45dd-8295-c49b2d920b0d,LED: Lexicon-Enlightened Dense Retriever for Large-Scale Retrieval,0.623964,"Retrieval models based on dense representations in semantic space have become
an indispensable branch for first-stage retrieval. These retrievers benefit
from surging advances in representation learning towards compressive global
sequence-level embeddings. However, they are prone to overlook local salient
phrases and entity mentions in texts, which usually play pivot roles in
first-stage retrieval. To mitigate this weakness, we propose to make a dense
retriever align a well-performing lexicon-aware representation model. The
alignment is achieved by weakened knowledge distillations to enlighten the
retriever via two aspects -- 1) a lexicon-augmented contrastive objective to
challenge the dense encoder and 2) a pair-wise rank-consistent regularization
to make dense model's behavior incline to the other. We evaluate our model on
three public benchmarks, which shows that with a comparable lexicon-aware
retriever as the teacher, our proposed dense one can bring consistent and
significant improvements, and even outdo its teacher. In addition, we found our
improvement on the dense retriever is complementary to the standard ranker
distillation, which can further lift state-of-the-art performance.",None,-1
7bd05783-875e-4fd6-8097-1268dab49cf0,QuantFace: Towards Lightweight Face Recognition by Synthetic Data Low-bit Quantization,0.874404,"Deep learning-based face recognition models follow the common trend in deep
neural networks by utilizing full-precision floating-point networks with high
computational costs. Deploying such networks in use-cases constrained by
computational requirements is often infeasible due to the large memory required
by the full-precision model. Previous compact face recognition approaches
proposed to design special compact architectures and train them from scratch
using real training data, which may not be available in a real-world scenario
due to privacy concerns. We present in this work the QuantFace solution based
on low-bit precision format model quantization. QuantFace reduces the required
computational cost of the existing face recognition models without the need for
designing a particular architecture or accessing real training data. QuantFace
introduces privacy-friendly synthetic face data to the quantization process to
mitigate potential privacy concerns and issues related to the accessibility to
real training data. Through extensive evaluation experiments on seven
benchmarks and four network architectures, we demonstrate that QuantFace can
successfully reduce the model size up to 5x while maintaining, to a large
degree, the verification performance of the full-precision model without
accessing real training datasets.",None,-1
65e11499-3413-4945-8221-3a6a50b6c6dc,Handling sign language transcription system with the computer-friendly numerical multilabels,0.158244,"This paper presents our recent developments in the automatic processing of
sign language corpora using the Hamburg Sign Language Annotation System
(HamNoSys). We designed an automated tool to convert HamNoSys annotations into
numerical labels for defined initial features of body and hand positions. Our
proposed numerical multilabels greatly simplify annotations' structure without
significant loss of gloss meaning. These numerical multilabels can potentially
be used to feed the machine learning models, which would accelerate the
development of vision-based sign language recognition. In addition, this tool
can assist experts in the annotation process and help identify semantic errors.
The code and sample annotations are publicly available at
\url{https://github.com/hearai/parse-hamnosys}.",https://github.com/hearai/parse-hamnosys,-1
68298ffa-37fc-44b9-a11e-b43f590c6b97,Linear programming word problems formulation using EnsembleCRF NER labeler and T5 text generator with data augmentations,0.306079,"We propose an ensemble approach to predict the labels in linear programming
word problems. The entity identification and the meaning representation are two
types of tasks to be solved in the NL4Opt competition. We propose the
ensembleCRF method to identify the named entities for the first task. We found
that single models didn't improve for the given task in our analysis. A set of
prediction models predict the entities. The generated results are combined to
form a consensus result in the ensembleCRF method. We present an ensemble text
generator to produce the representation sentences for the second task. We
thought of dividing the problem into multiple small tasks due to the overflow
in the output. A single model generates different representations based on the
prompt. All the generated text is combined to form an ensemble and produce a
mathematical meaning of a linear programming problem.",None,-1
e0424d87-1a38-43c5-8dd6-ea32ff7849a5,Does Wikidata Support Analogical Reasoning?,0.0460714,"Analogical reasoning methods have been built over various resources,
including commonsense knowledge bases, lexical resources, language models, or
their combination. While the wide coverage of knowledge about entities and
events make Wikidata a promising resource for analogical reasoning across
situations and domains, Wikidata has not been employed for this task yet. In
this paper, we investigate whether the knowledge in Wikidata supports
analogical reasoning. Specifically, we study whether relational knowledge is
modeled consistently in Wikidata, observing that relevant relational
information is typically missing or modeled in an inconsistent way. Our further
experiments show that Wikidata can be used to create data for analogy
classification, but this requires much manual effort. To facilitate future work
that can support analogies, we discuss key desiderata, and devise a set of
metrics to guide an automatic method for extracting analogies from Wikidata.",None,-1
2ee0c17c-6565-4e34-ae78-776839364468,Event-based Monocular Dense Depth Estimation with Recurrent Transformers,0.701452,"Event cameras, offering high temporal resolutions and high dynamic ranges,
have brought a new perspective to address common challenges (e.g., motion blur
and low light) in monocular depth estimation. However, how to effectively
exploit the sparse spatial information and rich temporal cues from asynchronous
events remains a challenging endeavor. To this end, we propose a novel
event-based monocular depth estimator with recurrent transformers, namely
EReFormer, which is the first pure transformer with a recursive mechanism to
process continuous event streams. Technically, for spatial modeling, a novel
transformer-based encoder-decoder with a spatial transformer fusion module is
presented, having better global context information modeling capabilities than
CNN-based methods. For temporal modeling, we design a gate recurrent vision
transformer unit that introduces a recursive mechanism into transformers,
improving temporal modeling capabilities while alleviating the expensive GPU
memory cost. The experimental results show that our EReFormer outperforms
state-of-the-art methods by a margin on both synthetic and real-world datasets.
We hope that our work will attract further research to develop stunning
transformers in the event-based vision community. Our open-source code can be
found in the supplemental material.",None,-1
0bc973f9-79cc-4f59-96ae-5e31e878bb3d,Adapters for Enhanced Modeling of Multilingual Knowledge and Text,0.692198,"Large language models appear to learn facts from the large text corpora they
are trained on. Such facts are encoded implicitly within their many parameters,
making it difficult to verify or manipulate what knowledge has been learned.
Language models have recently been extended to multilingual language models
(MLLMs), enabling knowledge to be learned across hundreds of languages.
Meanwhile, knowledge graphs contain facts in an explicit triple format, which
require careful and costly curation and are only available in a few
high-resource languages, restricting their research and application. To address
these issues, we propose to enhance MLLMs with knowledge from multilingual
knowledge graphs (MLKGs) so as to tackle language and knowledge graph tasks
across many languages, including low-resource ones. Specifically, we introduce
a lightweight adapter set to enhance MLLMs with cross-lingual entity alignment
and facts from MLKGs for many languages. Experiments on common benchmarks show
that such enhancement benefits both MLLMs and MLKGs, achieving: (1) comparable
or improved performance for knowledge graph completion and entity alignment
relative to baselines, especially for low-resource languages (for which
knowledge graphs are unavailable); and (2) improved MLLM performance on
language understanding tasks that require multilingual factual knowledge; all
while maintaining performance on other general language tasks.",https://github.com/yifan-h/Multilingual_Space,-1
432df95c-f39f-40bd-8dd9-199eaae25241,Score-Guided Intermediate Layer Optimization: Fast Langevin Mixing for Inverse Problems,0.26817,"We prove fast mixing and characterize the stationary distribution of the
Langevin Algorithm for inverting random weighted DNN generators. This result
extends the work of Hand and Voroninski from efficient inversion to efficient
posterior sampling. In practice, to allow for increased expressivity, we
propose to do posterior sampling in the latent space of a pre-trained
generative model. To achieve that, we train a score-based model in the latent
space of a StyleGAN-2 and we use it to solve inverse problems. Our framework,
Score-Guided Intermediate Layer Optimization (SGILO), extends prior work by
replacing the sparsity regularization with a generative prior in the
intermediate layer. Experimentally, we obtain significant improvements over the
previous state-of-the-art, especially in the low measurement regime.",None,-1
539047f9-7fda-44b1-aba0-735b71b9afe4,Mediators: Conversational Agents Explaining NLP Model Behavior,0.651645,"The human-centric explainable artificial intelligence (HCXAI) community has
raised the need for framing the explanation process as a conversation between
human and machine. In this position paper, we establish desiderata for
Mediators, text-based conversational agents which are capable of explaining the
behavior of neural models interactively using natural language. From the
perspective of natural language processing (NLP) research, we engineer a
blueprint of such a Mediator for the task of sentiment analysis and assess how
far along current research is on the path towards dialogue-based explanations.",None,-1
51cabbe3-d806-44be-a6b2-d1c6805ac2bf,Generative Cooperative Learning for Unsupervised Video Anomaly Detection,0.980096,"Video anomaly detection is well investigated in weakly-supervised and
one-class classification (OCC) settings. However, unsupervised video anomaly
detection methods are quite sparse, likely because anomalies are less frequent
in occurrence and usually not well-defined, which when coupled with the absence
of ground truth supervision, could adversely affect the performance of the
learning algorithms. This problem is challenging yet rewarding as it can
completely eradicate the costs of obtaining laborious annotations and enable
such systems to be deployed without human intervention. To this end, we propose
a novel unsupervised Generative Cooperative Learning (GCL) approach for video
anomaly detection that exploits the low frequency of anomalies towards building
a cross-supervision between a generator and a discriminator. In essence, both
networks get trained in a cooperative fashion, thereby allowing unsupervised
learning. We conduct extensive experiments on two large-scale video anomaly
detection datasets, UCF crime, and ShanghaiTech. Consistent improvement over
the existing state-of-the-art unsupervised and OCC methods corroborate the
effectiveness of our approach.",None,-1
13506174-90db-42a8-8d10-4d3bd3dfd8a2,Explaining Causal Models with Argumentation: the Case of Bi-variate Reinforcement,0.0662542,"Causal models are playing an increasingly important role in machine learning,
particularly in the realm of explainable AI. We introduce a conceptualisation
for generating argumentation frameworks (AFs) from causal models for the
purpose of forging explanations for the models' outputs. The conceptualisation
is based on reinterpreting desirable properties of semantics of AFs as
explanation moulds, which are means for characterising the relations in the
causal model argumentatively. We demonstrate our methodology by reinterpreting
the property of bi-variate reinforcement as an explanation mould to forge
bipolar AFs as explanations for the outputs of causal models. We perform a
theoretical evaluation of these argumentative explanations, examining whether
they satisfy a range of desirable explanatory and argumentative properties.",None,12536
6d1fbc16-17b2-4ac0-9936-06d27f4822cb,BioBART: Pretraining and Evaluation of A Biomedical Generative Language Model,0.668824,"Pretrained language models have served as important backbones for natural
language processing. Recently, in-domain pretraining has been shown to benefit
various domain-specific downstream tasks. In the biomedical domain, natural
language generation (NLG) tasks are of critical importance, while understudied.
Approaching natural language understanding (NLU) tasks as NLG achieves
satisfying performance in the general domain through constrained language
generation or language prompting. We emphasize the lack of in-domain generative
language models and the unsystematic generative downstream benchmarks in the
biomedical domain, hindering the development of the research community. In this
work, we introduce the generative language model BioBART that adapts BART to
the biomedical domain. We collate various biomedical language generation tasks
including dialogue, summarization, entity linking, and named entity
recognition. BioBART pretrained on PubMed abstracts has enhanced performance
compared to BART and set strong baselines on several tasks. Furthermore, we
conduct ablation studies on the pretraining tasks for BioBART and find that
sentence permutation has negative effects on downstream tasks.",https://github.com/GanjinZero/BioBART,-1
c7acec7c-0024-4f6f-9424-9cce792342b0,Attribution and Obfuscation of Neural Text Authorship: A Data Mining Perspective,0.959124,"Two interlocking research questions of growing interest and importance in
privacy research are Authorship Attribution (AA) and Authorship Obfuscation
(AO). Given an artifact, especially a text t in question, an AA solution aims
to accurately attribute t to its true author out of many candidate authors
while an AO solution aims to modify t to hide its true authorship.
Traditionally, the notion of authorship and its accompanying privacy concern is
only toward human authors. However, in recent years, due to the explosive
advancements in Neural Text Generation (NTG) techniques in NLP, capable of
synthesizing human-quality open-ended texts (so-called ""neural texts""), one has
to now consider authorships by humans, machines, or their combination. Due to
the implications and potential threats of neural texts when used maliciously,
it has become critical to understand the limitations of traditional AA/AO
solutions and develop novel AA/AO solutions in dealing with neural texts. In
this survey, therefore, we make a comprehensive review of recent literature on
the attribution and obfuscation of neural text authorship from a Data Mining
perspective, and share our view on their limitations and promising research
directions.",None,-1
98ad6ba6-4c40-4195-9a6a-e6c3a74f4f36,Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models,0.754037,"Pre-trained language models (LMs) are shown to easily generate toxic
language. In this work, we systematically explore domain-adaptive training to
reduce the toxicity of language models. We conduct this study on three
dimensions: training corpus, model size, and parameter efficiency. For the
training corpus, we propose to leverage the generative power of LMs and
generate nontoxic datasets for domain-adaptive training, which mitigates the
exposure bias and is shown to be more data-efficient than using a curated
pre-training corpus. We demonstrate that the self-generation method
consistently outperforms the existing baselines across various model sizes on
both automatic and human evaluations, even when it uses a 1/3 smaller training
corpus. We then comprehensively study detoxifying LMs with parameter sizes
ranging from 126M up to 530B (3x larger than GPT-3), a scale that has never
been studied before. We find that i) large LMs have similar toxicity levels as
smaller ones given the same pre-training corpus, and ii) large LMs require more
endeavor to detoxify. We also explore parameter-efficient training methods for
detoxification. We demonstrate that adding and training adapter-only layers in
LMs not only saves a lot of parameters but also achieves a better trade-off
between toxicity and perplexity than whole model adaptation for the large-scale
models.",https://github.com/NVIDIA/Megatron-LM/,-1
40842168-cba8-4e27-984d-2c26b861722c,"Towards Automated Document Revision: Grammatical Error Correction, Fluency Edits, and Beyond",0.884681,"Natural language processing technology has rapidly improved automated
grammatical error correction tasks, and the community begins to explore
document-level revision as one of the next challenges. To go beyond
sentence-level automated grammatical error correction to NLP-based
document-level revision assistant, there are two major obstacles: (1) there are
few public corpora with document-level revisions being annotated by
professional editors, and (2) it is not feasible to elicit all possible
references and evaluate the quality of revision with such references because
there are infinite possibilities of revision. This paper tackles these
challenges. First, we introduce a new document-revision corpus, TETRA, where
professional editors revised academic papers sampled from the ACL anthology
which contain few trivial grammatical errors that enable us to focus more on
document- and paragraph-level edits such as coherence and consistency. Second,
we explore reference-less and interpretable methods for meta-evaluation that
can detect quality improvements by document revision. We show the uniqueness of
TETRA compared with existing document revision corpora and demonstrate that a
fine-tuned pre-trained language model can discriminate the quality of documents
after revision even when the difference is subtle. This promising result will
encourage the community to further explore automated document revision models
and metrics in future.",https://github.com/chemicaltree/tetra,-1
399d97fd-771e-4e17-9d1c-5f32d8928330,Progressively Generating Better Initial Guesses Towards Next Stages for High-Quality Human Motion Prediction,0.936725,"This paper presents a high-quality human motion prediction method that
accurately predicts future human poses given observed ones. Our method is based
on the observation that a good initial guess of the future poses is very
helpful in improving the forecasting accuracy. This motivates us to propose a
novel two-stage prediction framework, including an init-prediction network that
just computes the good guess and then a formal-prediction network that predicts
the target future poses based on the guess. More importantly, we extend this
idea further and design a multi-stage prediction framework where each stage
predicts initial guess for the next stage, which brings more performance gain.
To fulfill the prediction task at each stage, we propose a network comprising
Spatial Dense Graph Convolutional Networks (S-DGCN) and Temporal Dense Graph
Convolutional Networks (T-DGCN). Alternatively executing the two networks helps
extract spatiotemporal features over the global receptive field of the whole
pose sequence. All the above design choices cooperating together make our
method outperform previous approaches by large margins: 6%-7% on Human3.6M,
5%-10% on CMU-MoCap, and 13%-16% on 3DPW.",https://github.com/705062791/PGBIG,-1
26b6ac59-0dcd-4a0e-af68-d4f9a8118180,Generalized Probabilistic U-Net for medical image segementation,0.242389,"We propose the Generalized Probabilistic U-Net, which extends the
Probabilistic U-Net by allowing more general forms of the Gaussian distribution
as the latent space distribution that can better approximate the uncertainty in
the reference segmentations. We study the effect the choice of latent space
distribution has on capturing the uncertainty in the reference segmentations
using the LIDC-IDRI dataset. We show that the choice of distribution affects
the sample diversity of the predictions and their overlap with respect to the
reference segmentations. For the LIDC-IDRI dataset, we show that using a
mixture of Gaussians results in a statistically significant improvement in the
generalized energy distance (GED) metric with respect to the standard
Probabilistic U-Net. We have made our implementation available at
https://github.com/ishaanb92/GeneralizedProbabilisticUNet",https://github.com/ishaanb92/GeneralizedProbabilisticUNet,5946
b33d51ac-7827-49e1-8adf-ec445c85a954,Improving Image Clustering through Sample Ranking and Its Application to remote--sensing images,0.0852847,"Image clustering is a very useful technique that is widely applied to various
areas, including remote sensing. Recently, visual representations by
self-supervised learning have greatly improved the performance of image
clustering. To further improve the well-trained clustering models, this paper
proposes a novel method by first ranking samples within each cluster based on
the confidence in their belonging to the current cluster and then using the
ranking to formulate a weighted cross-entropy loss to train the model. For
ranking the samples, we developed a method for computing the likelihood of
samples belonging to the current clusters based on whether they are situated in
densely populated neighborhoods, while for training the model, we give a
strategy for weighting the ranked samples. We present extensive experimental
results that demonstrate that the new technique can be used to improve the
State-of-the-Art image clustering models, achieving accuracy performance gains
ranging from $2.1\%$ to $15.9\%$. Performing our method on a variety of
datasets from remote sensing, we show that our method can be effectively
applied to remote--sensing images.",https://github.com/qlilx/ICSR,-1
3940a9db-9dd1-499b-94ab-101e0188241a,Safe and Robust Experience Sharing for Deterministic Policy Gradient Algorithms,0.242476,"Learning in high dimensional continuous tasks is challenging, mainly when the
experience replay memory is very limited. We introduce a simple yet effective
experience sharing mechanism for deterministic policies in continuous action
domains for the future off-policy deep reinforcement learning applications in
which the allocated memory for the experience replay buffer is limited. To
overcome the extrapolation error induced by learning from other agents'
experiences, we facilitate our algorithm with a novel off-policy correction
technique without any action probability estimates. We test the effectiveness
of our method in challenging OpenAI Gym continuous control tasks and conclude
that it can achieve a safe experience sharing across multiple agents and
exhibits a robust performance when the replay memory is strictly limited.",https://github.com/baturaysaglam/DASE,644
7fe23e5f-6af7-4872-a224-ead91756ce26,Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results,0.305368,"ImageNet serves as the primary dataset for evaluating the quality of
computer-vision models. The common practice today is training each architecture
with a tailor-made scheme, designed and tuned by an expert. In this paper, we
present a unified scheme for training any backbone on ImageNet. The scheme,
named USI (Unified Scheme for ImageNet), is based on knowledge distillation and
modern tricks. It requires no adjustments or hyper-parameters tuning between
different models, and is efficient in terms of training times. We test USI on a
wide variety of architectures, including CNNs, Transformers, Mobile-oriented
and MLP-only. On all models tested, USI outperforms previous state-of-the-art
results. Hence, we are able to transform training on ImageNet from an
expert-oriented task to an automatic seamless routine. Since USI accepts any
backbone and trains it to top results, it also enables to perform methodical
comparisons, and identify the most efficient backbones along the speed-accuracy
Pareto curve. Implementation is available
at:https://github.com/Alibaba-MIIL/Solving_ImageNet",https://github.com/Alibaba-MIIL/Solving_ImageNet,-1
4e003d6c-507c-4cb7-bed4-455a983234da,Clustering Text Using Attention,0.0342092,"Clustering Text has been an important problem in the domain of Natural
Language Processing. While there are techniques to cluster text based on using
conventional clustering techniques on top of contextual or non-contextual
vector space representations, it still remains a prevalent area of research
possible to various improvements in performance and implementation of these
techniques. This paper discusses a novel technique to cluster text using
attention mechanisms. Attention Mechanisms have proven to be highly effective
in various NLP tasks in recent times. This paper extends the idea of attention
mechanism in clustering space and sheds some light on a whole new area of
research",https://github.com/singh-l/CTUA,-1
9d446686-eb21-4152-981f-00ef028b3361,General Incremental Learning with Domain-aware Categorical Representations,0.63111,"Continual learning is an important problem for achieving human-level
intelligence in real-world applications as an agent must continuously
accumulate knowledge in response to streaming data/tasks. In this work, we
consider a general and yet under-explored incremental learning problem in which
both the class distribution and class-specific domain distribution change over
time. In addition to the typical challenges in class incremental learning, this
setting also faces the intra-class stability-plasticity dilemma and intra-class
domain imbalance problems. To address above issues, we develop a novel
domain-aware continual learning method based on the EM framework. Specifically,
we introduce a flexible class representation based on the von Mises-Fisher
mixture model to capture the intra-class structure, using an
expansion-and-reduction strategy to dynamically increase the number of
components according to the class complexity. Moreover, we design a bi-level
balanced memory to cope with data imbalances within and across classes, which
combines with a distillation loss to achieve better inter- and intra-class
stability-plasticity trade-off. We conduct exhaustive experiments on three
benchmarks: iDigits, iDomainNet and iCIFAR-20. The results show that our
approach consistently outperforms previous methods by a significant margin,
demonstrating its superiority.",None,-1
0f4f313b-6417-45bc-98b8-843446ca4e65,Multi-Class Segmentation from Aerial Views using Recursive Noise Diffusion,0.540464,"Semantic segmentation from aerial views is a crucial task for autonomous
drones, as they rely on precise and accurate segmentation to navigate safely
and efficiently. However, aerial images present unique challenges such as
diverse viewpoints, extreme scale variations, and high scene complexity. In
this paper, we propose an end-to-end multi-class semantic segmentation
diffusion model that addresses these challenges. We introduce recursive
denoising to allow information to propagate through the denoising process, as
well as a hierarchical multi-scale approach that complements the diffusion
process. Our method achieves competitive results on the UAVid dataset and
state-of-the-art performance on the Vaihingen Building segmentation benchmark.
Being the first iteration of this method, it shows great promise for future
improvements.",https://github.com/benediktkol/recursive-noise-diffusion,-1
f649e4ed-3192-4104-8acd-d77894f4a6d3,Transfer Language Selection for Zero-Shot Cross-Lingual Abusive Language Detection,0.802509,"We study the selection of transfer languages for automatic abusive language
detection. Instead of preparing a dataset for every language, we demonstrate
the effectiveness of cross-lingual transfer learning for zero-shot abusive
language detection. This way we can use existing data from higher-resource
languages to build better detection systems for low-resource languages. Our
datasets are from seven different languages from three language families. We
measure the distance between the languages using several language similarity
measures, especially by quantifying the World Atlas of Language Structures. We
show that there is a correlation between linguistic similarity and classifier
performance. This discovery allows us to choose an optimal transfer language
for zero shot abusive language detection.",None,-1
f38ef1b2-971d-4e9e-bca6-1774f6627e1a,Object-Guided Day-Night Visual Localization in Urban Scenes,0.436467,"We introduce Object-Guided Localization (OGuL) based on a novel method of
local-feature matching. Direct matching of local features is sensitive to
significant changes in illumination. In contrast, object detection often
survives severe changes in lighting conditions. The proposed method first
detects semantic objects and establishes correspondences of those objects
between images. Object correspondences provide local coarse alignment of the
images in the form of a planar homography. These homographies are consequently
used to guide the matching of local features. Experiments on standard urban
localization datasets (Aachen, Extended-CMU-Season, RobotCar-Season) show that
OGuL significantly improves localization results with as simple local features
as SIFT, and its performance competes with the state-of-the-art CNN-based
methods trained for day-to-night localization.",None,-1
2abd93f0-0e93-4503-a3d9-b4b0b1229a8e,Efficient Long Sequence Modeling via State Space Augmented Transformer,0.809395,"Transformer models have achieved superior performance in various natural
language processing tasks. However, the quadratic computational cost of the
attention mechanism limits its practicality for long sequences. There are
existing attention variants that improve the computational efficiency, but they
have limited ability to effectively compute global information. In parallel to
Transformer models, state space models (SSMs) are tailored for long sequences,
but they are not flexible enough to capture complicated local information. We
propose SPADE, short for $\underline{\textbf{S}}$tate
s$\underline{\textbf{P}}$ace
$\underline{\textbf{A}}$ugmente$\underline{\textbf{D}}$
Transform$\underline{\textbf{E}}$r. Specifically, we augment a SSM into the
bottom layer of SPADE, and we employ efficient local attention methods for the
other layers. The SSM augments global information, which complements the lack
of long-range dependency issue in local attention methods. Experimental results
on the Long Range Arena benchmark and language modeling tasks demonstrate the
effectiveness of the proposed method. To further demonstrate the scalability of
SPADE, we pre-train large encoder-decoder models and present fine-tuning
results on natural language understanding and natural language generation
tasks.",https://github.com/microsoft/EfficientLongSequenceModeling,82331
9c73aaa2-6902-4875-a777-9e046f7fcef1,Confidence Based Bidirectional Global Context Aware Training Framework for Neural Machine Translation,0.644137,"Most dominant neural machine translation (NMT) models are restricted to make
predictions only according to the local context of preceding words in a
left-to-right manner. Although many previous studies try to incorporate global
information into NMT models, there still exist limitations on how to
effectively exploit bidirectional global context. In this paper, we propose a
Confidence Based Bidirectional Global Context Aware (CBBGCA) training framework
for NMT, where the NMT model is jointly trained with an auxiliary conditional
masked language model (CMLM). The training consists of two stages: (1)
multi-task joint training; (2) confidence based knowledge distillation. At the
first stage, by sharing encoder parameters, the NMT model is additionally
supervised by the signal from the CMLM decoder that contains bidirectional
global contexts. Moreover, at the second stage, using the CMLM as teacher, we
further pertinently incorporate bidirectional global context to the NMT model
on its unconfidently-predicted target words via knowledge distillation.
Experimental results show that our proposed CBBGCA training framework
significantly improves the NMT model by +1.02, +1.30 and +0.57 BLEU scores on
three large-scale translation datasets, namely WMT'14 English-to-German, WMT'19
Chinese-to-English and WMT'14 English-to-French, respectively.",None,-1
094a2ff3-8d3c-49e7-bf1b-209f2e486f44,Scaling Back-Translation with Domain Text Generation for Sign Language Gloss Translation,0.832176,"Sign language gloss translation aims to translate the sign glosses into
spoken language texts, which is challenging due to the scarcity of labeled
gloss-text parallel data. Back translation (BT), which generates
pseudo-parallel data by translating in-domain spoken language texts into sign
glosses, has been applied to alleviate the data scarcity problem. However, the
lack of large-scale high-quality domain spoken language text data limits the
effect of BT. In this paper, to overcome the limitation, we propose a Prompt
based domain text Generation (PGEN) approach to produce the large-scale
in-domain spoken language text data. Specifically, PGEN randomly concatenates
sentences from the original in-domain spoken language text data as prompts to
induce a pre-trained language model (i.e., GPT-2) to generate spoken language
texts in a similar style. Experimental results on three benchmarks of sign
language gloss translation in varied languages demonstrate that BT with spoken
language texts generated by PGEN significantly outperforms the compared
methods. In addition, as the scale of spoken language texts generated by PGEN
increases, the BT technique can achieve further improvements, demonstrating the
effectiveness of our approach. We release the code and data for facilitating
future research in this field.",https://github.com/Atrewin/PGen,-1
3ae5f6a8-20c5-4381-b050-4ae1bbcca4ec,Masked Generative Distillation,0.960241,"Knowledge distillation has been applied to various tasks successfully. The
current distillation algorithm usually improves students' performance by
imitating the output of the teacher. This paper shows that teachers can also
improve students' representation power by guiding students' feature recovery.
From this point of view, we propose Masked Generative Distillation (MGD), which
is simple: we mask random pixels of the student's feature and force it to
generate the teacher's full feature through a simple block. MGD is a truly
general feature-based distillation method, which can be utilized on various
tasks, including image classification, object detection, semantic segmentation
and instance segmentation. We experiment on different models with extensive
datasets and the results show that all the students achieve excellent
improvements. Notably, we boost ResNet-18 from 69.90% to 71.69% ImageNet top-1
accuracy, RetinaNet with ResNet-50 backbone from 37.4 to 41.0 Boundingbox mAP,
SOLO based on ResNet-50 from 33.1 to 36.2 Mask mAP and DeepLabV3 based on
ResNet-18 from 73.20 to 76.02 mIoU. Our codes are available at
https://github.com/yzd-v/MGD.",https://github.com/yzd-v/MGD,5005
6a8cb041-0354-4272-88ff-6e097d96e381,Classification of Hyperspectral Images Using SVM with Shape-adaptive Reconstruction and Smoothed Total Variation,0.56087,"In this work, a novel algorithm called SVM with Shape-adaptive Reconstruction
and Smoothed Total Variation (SaR-SVM-STV) is introduced to classify
hyperspectral images, which makes full use of spatial and spectral information.
The Shape-adaptive Reconstruction (SaR) is introduced to preprocess each pixel
based on the Pearson Correlation between pixels in its shape-adaptive (SA)
region. Support Vector Machines (SVMs) are trained to estimate the pixel-wise
probability maps of each class. Then the Smoothed Total Variation (STV) model
is applied to denoise and generate the final classification map. Experiments
show that SaR-SVM-STV outperforms the SVM-STV method with a few training
labels, demonstrating the significance of reconstructing hyperspectral images
before classification.",https://github.com/ckn3/SA-Recon,-1
16385572-8a8c-4de7-9d12-fa0ab238b479,"""The Pedestrian next to the Lamppost"" Adaptive Object Graphs for Better Instantaneous Mapping",0.205182,"Estimating a semantically segmented bird's-eye-view (BEV) map from a single
image has become a popular technique for autonomous control and navigation.
However, they show an increase in localization error with distance from the
camera. While such an increase in error is entirely expected - localization is
harder at distance - much of the drop in performance can be attributed to the
cues used by current texture-based models, in particular, they make heavy use
of object-ground intersections (such as shadows), which become increasingly
sparse and uncertain for distant objects. In this work, we address these
shortcomings in BEV-mapping by learning the spatial relationship between
objects in a scene. We propose a graph neural network which predicts BEV
objects from a monocular image by spatially reasoning about an object within
the context of other objects. Our approach sets a new state-of-the-art in BEV
estimation from monocular images across three large-scale datasets, including a
50% relative improvement for objects on nuScenes.",None,19337
8754d3b8-80d7-4ab0-8bf1-d4594480ef3a,A Learning-Based Trajectory Planning of Multiple UAVs for AoI Minimization in IoT Networks,0.476605,"Many emerging Internet of Things (IoT) applications rely on information
collected by sensor nodes where the freshness of information is an important
criterion. \textit{Age of Information} (AoI) is a metric that quantifies
information timeliness, i.e., the freshness of the received information or
status update. This work considers a setup of deployed sensors in an IoT
network, where multiple unmanned aerial vehicles (UAVs) serve as mobile relay
nodes between the sensors and the base station. We formulate an optimization
problem to jointly plan the UAVs' trajectory, while minimizing the AoI of the
received messages. This ensures that the received information at the base
station is as fresh as possible. The complex optimization problem is
efficiently solved using a deep reinforcement learning (DRL) algorithm. In
particular, we propose a deep Q-network, which works as a function
approximation to estimate the state-action value function. The proposed scheme
is quick to converge and results in a lower AoI than the random walk scheme.
Our proposed algorithm reduces the average age by approximately $25\%$ and
requires down to $50\%$ less energy when compared to the baseline scheme.",None,-1
bbcc5cd3-5ffc-4f97-9877-c190ce7dd333,Deep Learning on a Healthy Data Diet: Finding Important Examples for Fairness,0.830497,"Data-driven predictive solutions predominant in commercial applications tend
to suffer from biases and stereotypes, which raises equity concerns. Prediction
models may discover, use, or amplify spurious correlations based on gender or
other protected personal characteristics, thus discriminating against
marginalized groups. Mitigating gender bias has become an important research
focus in natural language processing (NLP) and is an area where annotated
corpora are available. Data augmentation reduces gender bias by adding
counterfactual examples to the training dataset. In this work, we show that
some of the examples in the augmented dataset can be not important or even
harmful for fairness. We hence propose a general method for pruning both the
factual and counterfactual examples to maximize the model's fairness as
measured by the demographic parity, equality of opportunity, and equality of
odds. The fairness achieved by our method surpasses that of data augmentation
on three text classification datasets, using no more than half of the examples
in the augmented dataset. Our experiments are conducted using models of varying
sizes and pre-training settings.",https://github.com/Garrett-R/gender bender,-1
63c95fdc-2bbd-474d-8235-240f1ac2c87c,Learning Uncertainty with Artificial Neural Networks for Improved Predictive Process Monitoring,0.513304,"The inability of artificial neural networks to assess the uncertainty of
their predictions is an impediment to their widespread use. We distinguish two
types of learnable uncertainty: model uncertainty due to a lack of training
data and noise-induced observational uncertainty. Bayesian neural networks use
solid mathematical foundations to learn the model uncertainties of their
predictions. The observational uncertainty can be calculated by adding one
layer to these networks and augmenting their loss functions. Our contribution
is to apply these uncertainty concepts to predictive process monitoring tasks
to train uncertainty-based models to predict the remaining time and outcomes.
Our experiments show that uncertainty estimates allow more and less accurate
predictions to be differentiated and confidence intervals to be constructed in
both regression and classification tasks. These conclusions remain true even in
early stages of running processes. Moreover, the deployed techniques are fast
and produce more accurate predictions. The learned uncertainty could increase
users' confidence in their process prediction systems, promote better
cooperation between humans and these systems, and enable earlier
implementations with smaller datasets.",None,-1
b279b77e-2626-407e-a5ce-39983f4c79b9,Does Your Model Classify Entities Reasonably? Diagnosing and Mitigating Spurious Correlations in Entity Typing,0.790389,"Entity typing aims at predicting one or more words that describe the type(s)
of a specific mention in a sentence. Due to shortcuts from surface patterns to
annotated entity labels and biased training, existing entity typing models are
subject to the problem of spurious correlations. To comprehensively investigate
the faithfulness and reliability of entity typing methods, we first
systematically define distinct kinds of model biases that are reflected mainly
from spurious correlations. Particularly, we identify six types of existing
model biases, including mention-context bias, lexical overlapping bias, named
entity bias, pronoun bias, dependency bias, and overgeneralization bias. To
mitigate model biases, we then introduce a counterfactual data augmentation
method. By augmenting the original training set with their debiased
counterparts, models are forced to fully comprehend sentences and discover the
fundamental cues for entity typing, rather than relying on spurious
correlations for shortcuts. Experimental results on the UFET dataset show our
counterfactual data augmentation approach helps improve generalization of
different entity typing models with consistently better performance on both the
original and debiased test sets.",https://github.com/luka-group/DiagnoseET,-1
677ffa08-c755-4e01-81a4-d23084e4a054,Task-Aware Asynchronous Multi-Task Model with Class Incremental Contrastive Learning for Surgical Scene Understanding,0.217537,"Purpose: Surgery scene understanding with tool-tissue interaction recognition
and automatic report generation can play an important role in intra-operative
guidance, decision-making and postoperative analysis in robotic surgery.
However, domain shifts between different surgeries with inter and intra-patient
variation and novel instruments' appearance degrade the performance of model
prediction. Moreover, it requires output from multiple models, which can be
computationally expensive and affect real-time performance.
  Methodology: A multi-task learning (MTL) model is proposed for surgical
report generation and tool-tissue interaction prediction that deals with domain
shift problems. The model forms of shared feature extractor, mesh-transformer
branch for captioning and graph attention branch for tool-tissue interaction
prediction. The shared feature extractor employs class incremental contrastive
learning (CICL) to tackle intensity shift and novel class appearance in the
target domain. We design Laplacian of Gaussian (LoG) based curriculum learning
into both shared and task-specific branches to enhance model learning. We
incorporate a task-aware asynchronous MTL optimization technique to fine-tune
the shared weights and converge both tasks optimally.
  Results: The proposed MTL model trained using task-aware optimization and
fine-tuning techniques reported a balanced performance (BLEU score of 0.4049
for scene captioning and accuracy of 0.3508 for interaction detection) for both
tasks on the target domain and performed on-par with single-task models in
domain adaptation.
  Conclusion: The proposed multi-task model was able to adapt to domain shifts,
incorporate novel instruments in the target domain, and perform tool-tissue
interaction detection and report generation on par with single-task models.",https://github.com/lalithjets/Domain-adaptation-in-MTL,-1
77f96f24-fbb9-417f-85de-debb33d81d91,Multimodal learning with graphs,0.808843,"Artificial intelligence for graphs has achieved remarkable success in
modeling complex systems, ranging from dynamic networks in biology to
interacting particle systems in physics. However, the increasingly
heterogeneous graph datasets call for multimodal methods that can combine
different inductive biases: the set of assumptions that algorithms use to make
predictions for inputs they have not encountered during training. Learning on
multimodal datasets presents fundamental challenges because the inductive
biases can vary by data modality and graphs might not be explicitly given in
the input. To address these challenges, multimodal graph AI methods combine
different modalities while leveraging cross-modal dependencies using graphs.
Diverse datasets are combined using graphs and fed into sophisticated
multimodal architectures, specified as image-intensive, knowledge-grounded and
language-intensive models. Using this categorization, we introduce a blueprint
for multimodal graph learning, use it to study existing methods and provide
guidelines to design new models.",https://yashaektefaie.github.io/mgl,-1
24be0d41-b9a5-4148-a3f0-8b094fc833c9,A Novel Approach for Neuromorphic Vision Data Compression based on Deep Belief Network,0.116124,"A neuromorphic camera is an image sensor that emulates the human eyes
capturing only changes in local brightness levels. They are widely known as
event cameras, silicon retinas or dynamic vision sensors (DVS). DVS records
asynchronous per-pixel brightness changes, resulting in a stream of events that
encode the brightness change's time, location, and polarity. DVS consumes
little power and can capture a wider dynamic range with no motion blur and
higher temporal resolution than conventional frame-based cameras. Although this
method of event capture results in a lower bit rate than traditional video
capture, it is further compressible. This paper proposes a novel deep
learning-based compression scheme for event data. Using a deep belief network
(DBN), the high dimensional event data is reduced into a latent representation
and later encoded using an entropy-based coding technique. The proposed scheme
is among the first to incorporate deep learning for event compression. It
achieves a high compression ratio while maintaining good reconstruction quality
outperforming state-of-the-art event data coders and other lossless benchmark
techniques.",None,-1
1f21e844-0b9e-4f6b-9a51-a883f4ee33c5,Spatial Transformer Network on Skeleton-based Gait Recognition,0.885097,"Skeleton-based gait recognition models usually suffer from the robustness
problem, as the Rank-1 accuracy varies from 90\% in normal walking cases to
70\% in walking with coats cases. In this work, we propose a state-of-the-art
robust skeleton-based gait recognition model called Gait-TR, which is based on
the combination of spatial transformer frameworks and temporal convolutional
networks. Gait-TR achieves substantial improvements over other skeleton-based
gait models with higher accuracy and better robustness on the well-known gait
dataset CASIA-B. Particularly in walking with coats cases, Gait-TR get a 90\%
Rank-1 gait recognition accuracy rate, which is higher than the best result of
silhouette-based models, which usually have higher accuracy than the
silhouette-based gait recognition models. Moreover, our experiment on CASIA-B
shows that the spatial transformer can extract gait features from the human
skeleton better than the widely used graph convolutional network.",None,17341
59366048-b341-47ce-89ec-89227f27a667,Object Localization under Single Coarse Point Supervision,0.604999,"Point-based object localization (POL), which pursues high-performance object
sensing under low-cost data annotation, has attracted increased attention.
However, the point annotation mode inevitably introduces semantic variance for
the inconsistency of annotated points. Existing POL methods heavily reply on
accurate key-point annotations which are difficult to define. In this study, we
propose a POL method using coarse point annotations, relaxing the supervision
signals from accurate key points to freely spotted points. To this end, we
propose a coarse point refinement (CPR) approach, which to our best knowledge
is the first attempt to alleviate semantic variance from the perspective of
algorithm. CPR constructs point bags, selects semantic-correlated points, and
produces semantic center points through multiple instance learning (MIL). In
this way, CPR defines a weakly supervised evolution procedure, which ensures
training high-performance object localizer under coarse point supervision.
Experimental results on COCO, DOTA and our proposed SeaPerson dataset validate
the effectiveness of the CPR approach. The dataset and code will be available
at https://github.com/ucas-vg/PointTinyBenchmark/.",https://github.com/ucas-vg/PointTinyBenchmark/,-1
7e921b30-f125-4ef2-a606-989ac4a8eb20,MCTNet: A Multi-Scale CNN-Transformer Network for Change Detection in Optical Remote Sensing Images,0.308145,"For the task of change detection (CD) in remote sensing images, deep
convolution neural networks (CNNs)-based methods have recently aggregated
transformer modules to improve the capability of global feature extraction.
However, they suffer degraded CD performance on small changed areas due to the
simple single-scale integration of deep CNNs and transformer modules. To
address this issue, we propose a hybrid network based on multi-scale
CNN-transformer structure, termed MCTNet, where the multi-scale global and
local information are exploited to enhance the robustness of the CD performance
on changed areas with different sizes. Especially, we design the ConvTrans
block to adaptively aggregate global features from transformer modules and
local features from CNN layers, which provides abundant global-local features
with different scales. Experimental results demonstrate that our MCTNet
achieves better detection performance than existing state-of-the-art CD
methods.",None,-1
cfe09e2f-4b83-4586-8d07-f0ce1d750d32,Space-based gravitational wave signal detection and extraction with deep neural network,0.730964,"Space-based gravitational wave (GW) detectors will be able to observe signals
from sources that are otherwise nearly impossible from current ground-based
detection. Consequently, the well established signal detection method, matched
filtering, will require a complex template bank, leading to a computational
cost that is too expensive in practice. Here, we develop a high-accuracy GW
signal detection and extraction method for all space-based GW sources. As a
proof of concept, we show that a science-driven and uniform multi-stage
self-attention-based deep neural network can identify synthetic signals that
are submerged in Gaussian noise. Our method exhibits a detection rate exceeding
99% in identifying signals from various sources, with the signal-to-noise ratio
at 50, at a false alarm rate of 1%. while obtaining at least 95% similarity
compared with target signals. We further demonstrate the interpretability and
strong generalization behavior for several extended scenarios.",https://github.com/AI-HPC-Research-Team/space_signal_detection_1,-1
e77924b6-9db9-435a-9dd2-1e0cc063d64d,Combating high variance in Data-Scarce Implicit Hate Speech Classification,0.129885,"Hate speech classification has been a long-standing problem in natural
language processing. However, even though there are numerous hate speech
detection methods, they usually overlook a lot of hateful statements due to
them being implicit in nature. Developing datasets to aid in the task of
implicit hate speech classification comes with its own challenges; difficulties
are nuances in language, varying definitions of what constitutes hate speech,
and the labor-intensive process of annotating such data. This had led to a
scarcity of data available to train and test such systems, which gives rise to
high variance problems when parameter-heavy transformer-based models are used
to address the problem. In this paper, we explore various optimization and
regularization techniques and develop a novel RoBERTa-based model that achieves
state-of-the-art performance.",None,-1
51adfcd5-cd09-4cc6-bd29-79374aa7a529,Explaining Chest X-ray Pathologies in Natural Language,0.431648,"Most deep learning algorithms lack explanations for their predictions, which
limits their deployment in clinical practice. Approaches to improve
explainability, especially in medical imaging, have often been shown to convey
limited information, be overly reassuring, or lack robustness. In this work, we
introduce the task of generating natural language explanations (NLEs) to
justify predictions made on medical images. NLEs are human-friendly and
comprehensive, and enable the training of intrinsically explainable models. To
this goal, we introduce MIMIC-NLE, the first, large-scale, medical imaging
dataset with NLEs. It contains over 38,000 NLEs, which explain the presence of
various thoracic pathologies and chest X-ray findings. We propose a general
approach to solve the task and evaluate several architectures on this dataset,
including via clinician assessment.",https://github.com/maximek3/MIMIC-NLE,-1
cebeac50-5704-4fc6-b18b-3e4951b911b5,Reward Learning with Trees: Methods and Evaluation,0.0557825,"Recent efforts to learn reward functions from human feedback have tended to
use deep neural networks, whose lack of transparency hampers our ability to
explain agent behaviour or verify alignment. We explore the merits of learning
intrinsically interpretable tree models instead. We develop a recently proposed
method for learning reward trees from preference labels, and show it to be
broadly competitive with neural networks on challenging high-dimensional tasks,
with good robustness to limited or corrupted data. Having found that reward
tree learning can be done effectively in complex settings, we then consider why
it should be used, demonstrating that the interpretable reward structure gives
significant scope for traceability, verification and explanation.",None,-1
a86cd6e8-969f-4b59-b2ba-fe3e4021e3cc,3DALL-E: Integrating Text-to-Image AI in 3D Design Workflows,0.986412,"Text-to-image AI are capable of generating novel images for inspiration, but
their applications for 3D design workflows and how designers can build 3D
models using AI-provided inspiration have not yet been explored. To investigate
this, we integrated DALL-E, GPT-3, and CLIP within a CAD software in 3DALL-E, a
plugin that generates 2D image inspiration for 3D design. 3DALL-E allows users
to construct text and image prompts based on what they are modeling. In a study
with 13 designers, we found that designers saw great potential in 3DALL-E
within their workflows and could use text-to-image AI to produce reference
images, prevent design fixation, and inspire design considerations. We
elaborate on prompting patterns observed across 3D modeling tasks and provide
measures of prompt complexity observed across participants. From our findings,
we discuss how 3DALL-E can merge with existing generative design workflows and
propose prompt bibliographies as a form of human-AI design history.",None,-1
b3354071-36a2-49f8-aee5-24243d1886c7,Transformer Based Multi-Grained Features for Unsupervised Person Re-Identification,0.612505,"Multi-grained features extracted from convolutional neural networks (CNNs)
have demonstrated their strong discrimination ability in supervised person
re-identification (Re-ID) tasks. Inspired by them, this work investigates the
way of extracting multi-grained features from a pure transformer network to
address the unsupervised Re-ID problem that is label-free but much more
challenging. To this end, we build a dual-branch network architecture based
upon a modified Vision Transformer (ViT). The local tokens output in each
branch are reshaped and then uniformly partitioned into multiple stripes to
generate part-level features, while the global tokens of two branches are
averaged to produce a global feature. Further, based upon offline-online
associated camera-aware proxies (O2CAP) that is a top-performing unsupervised
Re-ID method, we define offline and online contrastive learning losses with
respect to both global and part-level features to conduct unsupervised
learning. Extensive experiments on three person Re-ID datasets show that the
proposed method outperforms state-of-the-art unsupervised methods by a
considerable margin, greatly mitigating the gap to supervised counterparts.
Code will be available soon at https://github.com/RikoLi/WACV23-workshop-TMGF.",https://github.com/RikoLi/WACV23-workshop-TMGF,-1
82a86ddf-d5cc-4013-87e7-6cb54aa4d037,Adversarial and Random Transformations for Robust Domain Adaptation and Generalization,0.252622,"Data augmentation has been widely used to improve generalization in training
deep neural networks. Recent works show that using worst-case transformations
or adversarial augmentation strategies can significantly improve the accuracy
and robustness. However, due to the non-differentiable properties of image
transformations, searching algorithms such as reinforcement learning or
evolution strategy have to be applied, which are not computationally practical
for large scale problems. In this work, we show that by simply applying
consistency training with random data augmentation, state-of-the-art results on
domain adaptation (DA) and generalization (DG) can be obtained. To further
improve the accuracy and robustness with adversarial examples, we propose a
differentiable adversarial data augmentation method based on spatial
transformer networks (STN). The combined adversarial and random transformations
based method outperforms the state-of-the-art on multiple DA and DG benchmark
datasets. Besides, the proposed method shows desirable robustness to
corruption, which is also validated on commonly used datasets.",None,-1
ac68960e-7ab4-4676-82cf-ea61ec77e9a9,Music-driven Dance Regeneration with Controllable Key Pose Constraints,0.167237,"In this paper, we propose a novel framework for music-driven dance motion
synthesis with controllable key pose constraint. In contrast to methods that
generate dance motion sequences only based on music without any other
controllable conditions, this work targets on synthesizing high-quality dance
motion driven by music as well as customized poses performed by users. Our
model involves two single-modal transformer encoders for music and motion
representations and a cross-modal transformer decoder for dance motions
generation. The cross-modal transformer decoder achieves the capability of
synthesizing smooth dance motion sequences, which keeps a consistency with key
poses at corresponding positions, by introducing the local neighbor position
embedding. Such mechanism makes the decoder more sensitive to key poses and the
corresponding positions. Our dance synthesis model achieves satisfactory
performance both on quantitative and qualitative evaluations with extensive
experiments, which demonstrates the effectiveness of our proposed method.",None,-1
6c7b6f8e-d84d-487e-af23-dd616f17f5a9,Private Quantiles Estimation in the Presence of Atoms,0.597973,"We consider the differentially private estimation of multiple quantiles (MQ)
of a distribution from a dataset, a key building block in modern data analysis.
We apply the recent non-smoothed Inverse Sensitivity (IS) mechanism to this
specific problem. We establish that the resulting method is closely related to
the recently published ad hoc algorithm JointExp. In particular, they share the
same computational complexity and a similar efficiency. We prove the
statistical consistency of these two algorithms for continuous distributions.
Furthermore, we demonstrate both theoretically and empirically that this method
suffers from an important lack of performance in the case of peaked
distributions, which can degrade up to a potentially catastrophic impact in the
presence of atoms. Its smoothed version (i.e. by applying a max kernel to its
output density) would solve this problem, but remains an open challenge to
implement. As a proxy, we propose a simple and numerically efficient method
called Heuristically Smoothed JointExp (HSJointExp), which is endowed with
performance guarantees for a broad class of distributions and achieves results
that are orders of magnitude better on problematic datasets.",https://github.com/opendp/smartnoise-core,-1
d95ac121-0654-4a76-b5bf-15d869214f5e,A Novel Viewport-Adaptive Motion Compensation Technique for Fisheye Video,0.126104,"Although fisheye cameras are in high demand in many application areas due to
their large field of view, many image and video signal processing tasks such as
motion compensation suffer from the introduced strong radial distortions. A
recently proposed projection-based approach takes the fisheye projection into
account to improve fisheye motion compensation. However, the approach does not
consider the large field of view of fisheye lenses that requires the
consideration of different motion planes in 3D space. We propose a novel
viewport-adaptive motion compensation technique that applies the motion vectors
in different perspective viewports in order to realize these motion planes.
Thereby, some pixels are mapped to so-called virtual image planes and require
special treatment to obtain reliable mappings between the perspective viewports
and the original fisheye image. While the state-of-the-art ultra wide-angle
compensation is sufficiently accurate, we propose a virtual image plane
compensation that leads to perfect mappings. All in all, we achieve average
gains of +2.40 dB in terms of PSNR compared to the state of the art in fisheye
motion compensation.",None,-1
06b57b08-805d-4457-9e64-fe9cff4b4f08,Deep Model-Based Super-Resolution with Non-uniform Blur,0.450162,"We propose a state-of-the-art method for super-resolution with non-uniform
blur. Single-image super-resolution methods seek to restore a high-resolution
image from blurred, subsampled, and noisy measurements. Despite their
impressive performance, existing techniques usually assume a uniform blur
kernel. Hence, these techniques do not generalize well to the more general case
of non-uniform blur. Instead, in this paper, we address the more realistic and
computationally challenging case of spatially-varying blur. To this end, we
first propose a fast deep plug-and-play algorithm, based on linearized ADMM
splitting techniques, which can solve the super-resolution problem with
spatially-varying blur. Second, we unfold our iterative algorithm into a single
network and train it end-to-end. In this way, we overcome the intricacy of
manually tuning the parameters involved in the optimization scheme. Our
algorithm presents remarkable performance and generalizes well after a single
training to a large family of spatially-varying blur kernels, noise levels and
scale factors.",https://github.com/claroche-r/DMBSR,471
7241c99e-dd2b-482b-bce7-05f6ad984e7b,Indiscriminate Poisoning Attacks on Unsupervised Contrastive Learning,0.529104,"Indiscriminate data poisoning attacks are quite effective against supervised
learning. However, not much is known about their impact on unsupervised
contrastive learning (CL). This paper is the first to consider indiscriminate
poisoning attacks of contrastive learning. We propose Contrastive Poisoning
(CP), the first effective such attack on CL. We empirically show that
Contrastive Poisoning, not only drastically reduces the performance of CL
algorithms, but also attacks supervised learning models, making it the most
generalizable indiscriminate poisoning attack. We also show that CL algorithms
with a momentum encoder are more robust to indiscriminate poisoning, and
propose a new countermeasure based on matrix completion. Code is available at:
https://github.com/kaiwenzha/contrastive-poisoning.",https://github.com/kaiwenzha/contrastive-poisoning,-1
d4e3d63e-a340-42b2-9b8b-a3ceceb05a11,"When a sentence does not introduce a discourse entity, Transformer-based models still sometimes refer to it",0.5956,"Understanding longer narratives or participating in conversations requires
tracking of discourse entities that have been mentioned. Indefinite noun
phrases (NPs), such as 'a dog', frequently introduce discourse entities but
this behavior is modulated by sentential operators such as negation. For
example, 'a dog' in 'Arthur doesn't own a dog' does not introduce a discourse
entity due to the presence of negation. In this work, we adapt the
psycholinguistic assessment of language models paradigm to higher-level
linguistic phenomena and introduce an English evaluation suite that targets the
knowledge of the interactions between sentential operators and indefinite NPs.
We use this evaluation suite for a fine-grained investigation of the entity
tracking abilities of the Transformer-based models GPT-2 and GPT-3. We find
that while the models are to a certain extent sensitive to the interactions we
investigate, they are all challenged by the presence of multiple NPs and their
behavior is not systematic, which suggests that even models at the scale of
GPT-3 do not fully acquire basic entity tracking abilities.",https://github.com/sebschu/discourse-entity-lm,-1
2333e970-ed85-46cc-b23e-276322900f3a,ActionFormer: Localizing Moments of Actions with Transformers,0.991771,"Self-attention based Transformer models have demonstrated impressive results
for image classification and object detection, and more recently for video
understanding. Inspired by this success, we investigate the application of
Transformer networks for temporal action localization in videos. To this end,
we present ActionFormer -- a simple yet powerful model to identify actions in
time and recognize their categories in a single shot, without using action
proposals or relying on pre-defined anchor windows. ActionFormer combines a
multiscale feature representation with local self-attention, and uses a
light-weighted decoder to classify every moment in time and estimate the
corresponding action boundaries. We show that this orchestrated design results
in major improvements upon prior works. Without bells and whistles,
ActionFormer achieves 71.0% mAP at tIoU=0.5 on THUMOS14, outperforming the best
prior model by 14.1 absolute percentage points. Further, ActionFormer
demonstrates strong results on ActivityNet 1.3 (36.6% average mAP) and
EPIC-Kitchens 100 (+13.5% average mAP over prior works). Our code is available
at http://github.com/happyharrycn/actionformer_release.",https://github.com/happyharrycn/actionformer_release,-1
f7c364e4-4ef1-4af8-a646-19f6a0d2a20f,Holistic Transformer: A Joint Neural Network for Trajectory Prediction and Decision-Making of Autonomous Vehicles,0.453538,"Trajectory prediction and behavioral decision-making are two important tasks
for autonomous vehicles that require good understanding of the environmental
context; behavioral decisions are better made by referring to the outputs of
trajectory predictions. However, most current solutions perform these two tasks
separately. Therefore, a joint neural network that combines multiple cues is
proposed and named as the holistic transformer to predict trajectories and make
behavioral decisions simultaneously. To better explore the intrinsic
relationships between cues, the network uses existing knowledge and adopts
three kinds of attention mechanisms: the sparse multi-head type for reducing
noise impact, feature selection sparse type for optimally using partial prior
knowledge, and multi-head with sigmoid activation type for optimally using
posteriori knowledge. Compared with other trajectory prediction models, the
proposed model has better comprehensive performance and good interpretability.
Perceptual noise robustness experiments demonstrate that the proposed model has
good noise robustness. Thus, simultaneous trajectory prediction and behavioral
decision-making combining multiple cues can reduce computational costs and
enhance semantic relationships between scenes and agents.",None,-1
2218f765-2f60-4919-bb4e-d255acac5501,Temporal Attention Unit: Towards Efficient Spatiotemporal Predictive Learning,0.941447,"Spatiotemporal predictive learning aims to generate future frames by learning
from historical frames. In this paper, we investigate existing methods and
present a general framework of spatiotemporal predictive learning, in which the
spatial encoder and decoder capture intra-frame features and the middle
temporal module catches inter-frame correlations. While the mainstream methods
employ recurrent units to capture long-term temporal dependencies, they suffer
from low computational efficiency due to their unparallelizable architectures.
To parallelize the temporal module, we propose the Temporal Attention Unit
(TAU), which decomposes the temporal attention into intra-frame statical
attention and inter-frame dynamical attention. Moreover, while the mean squared
error loss focuses on intra-frame errors, we introduce a novel differential
divergence regularization to take inter-frame variations into account.
Extensive experiments demonstrate that the proposed method enables the derived
model to achieve competitive performance on various spatiotemporal prediction
benchmarks.",None,-1
83b6fd79-60e9-4f75-b797-4b2bad4c96c0,Unsupervised Face Morphing Attack Detection via Self-paced Anomaly Detection,0.688597,"The supervised-learning-based morphing attack detection (MAD) solutions
achieve outstanding success in dealing with attacks from known morphing
techniques and known data sources. However, given variations in the morphing
attacks, the performance of supervised MAD solutions drops significantly due to
the insufficient diversity and quantity of the existing MAD datasets. To
address this concern, we propose a completely unsupervised MAD solution via
self-paced anomaly detection (SPL-MAD) by leveraging the existing large-scale
face recognition (FR) datasets and the unsupervised nature of convolutional
autoencoders. Using general FR datasets that might contain unintentionally and
unlabeled manipulated samples to train an autoencoder can lead to a diverse
reconstruction behavior of attack and bona fide samples. We analyze this
behavior empirically to provide a solid theoretical ground for designing our
unsupervised MAD solution. This also results in proposing to integrate our
adapted modified self-paced learning paradigm to enhance the reconstruction
error separability between the bona fide and attack samples in a completely
unsupervised manner. Our experimental results on a diverse set of MAD
evaluation datasets show that the proposed unsupervised SPL-MAD solution
outperforms the overall performance of a wide range of supervised MAD solutions
and provides higher generalizability on unknown attacks.",https://github.com/meilfang/SPL-MAD,-1
fa0a7fa4-210f-42d9-8fc1-05ab69e9061d,Motif-topology and Reward-learning improved Spiking Neural Network for Efficient Multi-sensory Integration,0.518163,"Network architectures and learning principles are key in forming complex
functions in artificial neural networks (ANNs) and spiking neural networks
(SNNs). SNNs are considered the new-generation artificial networks by
incorporating more biological features than ANNs, including dynamic spiking
neurons, functionally specified architectures, and efficient learning
paradigms. In this paper, we propose a Motif-topology and Reward-learning
improved SNN (MR-SNN) for efficient multi-sensory integration. MR-SNN contains
13 types of 3-node Motif topologies which are first extracted from independent
single-sensory learning paradigms and then integrated for multi-sensory
classification. The experimental results showed higher accuracy and stronger
robustness of the proposed MR-SNN than other conventional SNNs without using
Motifs. Furthermore, the proposed reward learning paradigm was biologically
plausible and can better explain the cognitive McGurk effect caused by
incongruent visual and auditory sensory signals.",https://github.com/thomasaimondy/Motif-SNN,-1
0c81eba3-d9ac-4f27-97a3-b40031c9b65a,Semi-Supervised Learning of Optical Flow by Flow Supervisor,0.552894,"A training pipeline for optical flow CNNs consists of a pretraining stage on
a synthetic dataset followed by a fine tuning stage on a target dataset.
However, obtaining ground truth flows from a target video requires a tremendous
effort. This paper proposes a practical fine tuning method to adapt a
pretrained model to a target dataset without ground truth flows, which has not
been explored extensively. Specifically, we propose a flow supervisor for
self-supervision, which consists of parameter separation and a student output
connection. This design is aimed at stable convergence and better accuracy over
conventional self-supervision methods which are unstable on the fine tuning
task. Experimental results show the effectiveness of our method compared to
different self-supervision methods for semi-supervised learning. In addition,
we achieve meaningful improvements over state-of-the-art optical flow models on
Sintel and KITTI benchmarks by exploiting additional unlabeled datasets. Code
is available at https://github.com/iwbn/flow-supervisor.",https://github.com/iwbn/flow-supervisor,-1
fa06160f-9af8-4e41-8148-c440aa9fb887,Bi-level Doubly Variational Learning for Energy-based Latent Variable Models,0.445303,"Energy-based latent variable models (EBLVMs) are more expressive than
conventional energy-based models. However, its potential on visual tasks are
limited by its training process based on maximum likelihood estimate that
requires sampling from two intractable distributions. In this paper, we propose
Bi-level doubly variational learning (BiDVL), which is based on a new bi-level
optimization framework and two tractable variational distributions to
facilitate learning EBLVMs. Particularly, we lead a decoupled EBLVM consisting
of a marginal energy-based distribution and a structural posterior to handle
the difficulties when learning deep EBLVMs on images. By choosing a symmetric
KL divergence in the lower level of our framework, a compact BiDVL for visual
tasks can be obtained. Our model achieves impressive image generation
performance over related works. It also demonstrates the significant capacity
of testing image reconstruction and out-of-distribution detection.",None,-1
94babbc1-7e89-4dff-bb5e-65776f6cb809,"Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks",0.555441,"Human language offers a powerful window into our thoughts -- we tell stories,
give explanations, and express our beliefs and goals through words. Abundant
evidence also suggests that language plays a developmental role in structuring
our learning. Here, we ask: how much of human-like thinking can be captured by
learning statistical patterns in language alone? We first contribute a new
challenge benchmark for comparing humans and distributional large language
models (LLMs). Our benchmark contains two problem-solving domains (planning and
explanation generation) and is designed to require generalization to new,
out-of-distribution problems expressed in language. We find that humans are far
more robust than LLMs on this benchmark. Next, we propose a hybrid
Parse-and-Solve model, which augments distributional LLMs with a structured
symbolic reasoning module. We find that this model shows more robust adaptation
to out-of-distribution planning problems, demonstrating the promise of hybrid
AI models for more human-like reasoning.",https://github.com/collinskatie/structured,-1
4f50b1ea-3406-46d2-a021-6bd8635d31c5,Chord-Conditioned Melody Harmonization with Controllable Harmonicity,0.383318,"Melody harmonization has long been closely associated with chorales composed
by Johann Sebastian Bach. Previous works rarely emphasised chorale generation
conditioned on chord progressions, and there has been a lack of focus on
assistive compositional tools. In this paper, we first designed a music
representation that encoded chord symbols for chord conditioning, and then
proposed DeepChoir, a melody harmonization system that can generate a four-part
chorale for a given melody conditioned on a chord progression. With
controllable harmonicity, users can control the extent of harmonicity for
generated chorales. Experimental results reveal the effectiveness of the music
representation and the controllability of DeepChoir.",https://github.com/sander-wood/deepchoir,-1
dfd1f2eb-7166-4676-8668-5ace01a3b18b,RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust Correspondence Field Estimation and Pose Optimization,0.870943,"6-DoF object pose estimation from a monocular image is challenging, and a
post-refinement procedure is generally needed for high-precision estimation. In
this paper, we propose a framework based on a recurrent neural network (RNN)
for object pose refinement, which is robust to erroneous initial poses and
occlusions. During the recurrent iterations, object pose refinement is
formulated as a non-linear least squares problem based on the estimated
correspondence field (between a rendered image and the observed image). The
problem is then solved by a differentiable Levenberg-Marquardt (LM) algorithm
enabling end-to-end training. The correspondence field estimation and pose
refinement are conducted alternatively in each iteration to recover the object
poses. Furthermore, to improve the robustness to occlusion, we introduce a
consistency-check mechanism based on the learned descriptors of the 3D model
and observed 2D images, which downweights the unreliable correspondences during
pose optimization. Extensive experiments on LINEMOD, Occlusion-LINEMOD, and
YCB-Video datasets validate the effectiveness of our method and demonstrate
state-of-the-art performance.",https://github.com/DecaYale/RNNPose,-1
1ef821f7-1e8e-4753-9041-abb577295e56,Bio-inspired Min-Nets Improve the Performance and Robustness of Deep Networks,0.387023,"Min-Nets are inspired by end-stopped cortical cells with units that output
the minimum of two learned filters. We insert such Min-units into
state-of-the-art deep networks, such as the popular ResNet and DenseNet, and
show that the resulting Min-Nets perform better on the Cifar-10 benchmark.
Moreover, we show that Min-Nets are more robust against JPEG compression
artifacts. We argue that the minimum operation is the simplest way of
implementing an AND operation on pairs of filters and that such AND operations
introduce a bias that is appropriate given the statistics of natural images.",https://github.com/pgruening/bio_inspired_min_nets_improve_the_performance_and_robustness_of_deep_networks,7477
4f522be2-5fd7-4f1c-9190-c551af5cadd5,Language Agnostic Code-Mixing Data Augmentation by Predicting Linguistic Patterns,0.206554,"In this work, we focus on intrasentential code-mixing and propose several
different Synthetic Code-Mixing (SCM) data augmentation methods that outperform
the baseline on downstream sentiment analysis tasks across various amounts of
labeled gold data. Most importantly, our proposed methods demonstrate that
strategically replacing parts of sentences in the matrix language with a
constant mask significantly improves classification accuracy, motivating
further linguistic insights into the phenomenon of code-mixing. We test our
data augmentation method in a variety of low-resource and cross-lingual
settings, reaching up to a relative improvement of 7.73% on the extremely
scarce English-Malayalam dataset. We conclude that the code-switch pattern in
code-mixing sentences is also important for the model to learn. Finally, we
propose a language-agnostic SCM algorithm that is cheap yet extremely helpful
for low-resource languages.",None,-1
f4025d4d-3720-4742-8a8c-a72fc543d8c5,Analysis of Randomization Effects on Sim2Real Transfer in Reinforcement Learning for Robotic Manipulation Tasks,0.465506,"Randomization is currently a widely used approach in Sim2Real transfer for
data-driven learning algorithms in robotics. Still, most Sim2Real studies
report results for a specific randomization technique and often on a highly
customized robotic system, making it difficult to evaluate different
randomization approaches systematically. To address this problem, we define an
easy-to-reproduce experimental setup for a robotic reach-and-balance
manipulator task, which can serve as a benchmark for comparison. We compare
four randomization strategies with three randomized parameters both in
simulation and on a real robot. Our results show that more randomization helps
in Sim2Real transfer, yet it can also harm the ability of the algorithm to find
a good policy in simulation. Fully randomized simulations and fine-tuning show
differentiated results and translate better to the real robot than the other
approaches tested.",https://josifovski.github.io/sim2real-randomization-effects/,-1
eec844b5-0a54-4d75-b1c2-d0da37f6174f,Facial Expression Recognition and Image Description Generation in Vietnamese,0.147465,"This paper discusses a facial expression recognition model and a description
generation model to build descriptive sentences for images and facial
expressions of people in images. Our study shows that YOLOv5 achieves better
results than a traditional CNN for all emotions on the KDEF dataset. In
particular, the accuracies of the CNN and YOLOv5 models for emotion recognition
are 0.853 and 0.938, respectively. A model for generating descriptions for
images based on a merged architecture is proposed using VGG16 with the
descriptions encoded over an LSTM model. YOLOv5 is also used to recognize
dominant colors of objects in the images and correct the color words in the
descriptions generated if it is necessary. If the description contains words
referring to a person, we recognize the emotion of the person in the image.
Finally, we combine the results of all models to create sentences that describe
the visual content and the human emotions in the images. Experimental results
on the Flickr8k dataset in Vietnamese achieve BLEU-1, BLEU-2, BLEU-3, BLEU-4
scores of 0.628; 0.425; 0.280; and 0.174, respectively.",https://github.com/pbcquoc/transformer,-1
5f3ef8ff-dd06-4c16-90b8-545d0de0c37f,Semeval-2022 Task 1: CODWOE -- Comparing Dictionaries and Word Embeddings,0.908236,"Word embeddings have advanced the state of the art in NLP across numerous
tasks. Understanding the contents of dense neural representations is of utmost
interest to the computational semantics community. We propose to focus on
relating these opaque word vectors with human-readable definitions, as found in
dictionaries. This problem naturally divides into two subtasks: converting
definitions into embeddings, and converting embeddings into definitions. This
task was conducted in a multilingual setting, using comparable sets of
embeddings trained homogeneously.",https://github.com/pi,-1
e27c8e39-b658-4b71-8aa8-7ad01b052f94,SparCAssist: A Model Risk Assessment Assistant Based on Sparse Generated Counterfactuals,0.38205,"We introduce SparcAssist, a general-purpose risk assessment tool for the
machine learning models trained for language tasks. It evaluates models' risk
by inspecting their behavior on counterfactuals, namely out-of-distribution
instances generated based on the given data instance. The counterfactuals are
generated by replacing tokens in rational subsequences identified by ExPred,
while the replacements are retrieved using HotFlip or
Masked-Language-Model-based algorithms. The main purpose of our system is to
help the human annotators to assess the model's risk on deployment. The
counterfactual instances generated during the assessment are the by-product and
can be used to train more robust NLP models in the future.",None,-1
af0e6a8c-0fe6-410c-8295-28d63e3d097f,A Quantitative Symbolic Approach to Individual Human Reasoning,0.135185,"Cognitive theories for reasoning are about understanding how humans come to
conclusions from a set of premises. Starting from hypothetical thoughts, we are
interested which are the implications behind basic everyday language and how do
we reason with them. A widely studied topic is whether cognitive theories can
account for typical reasoning tasks and be confirmed by own empirical
experiments. This paper takes a different view and we do not propose a theory,
but instead take findings from the literature and show how these, formalized as
cognitive principles within a logical framework, can establish a quantitative
notion of reasoning, which we call plausibility. For this purpose, we employ
techniques from non-monotonic reasoning and computer science, namely, a solving
paradigm called answer set programming (ASP). Finally, we can fruitfully use
plausibility reasoning in ASP to test the effects of an existing experiment and
explain different majority responses.",https://github.com/eadietz/bst2asp,-1
81450877-2e84-4db4-87b0-3767ee36ffe2,SafeText: A Benchmark for Exploring Physical Safety in Language Models,0.976802,"Understanding what constitutes safe text is an important issue in natural
language processing and can often prevent the deployment of models deemed
harmful and unsafe. One such type of safety that has been scarcely studied is
commonsense physical safety, i.e. text that is not explicitly violent and
requires additional commonsense knowledge to comprehend that it leads to
physical harm. We create the first benchmark dataset, SafeText, comprising
real-life scenarios with paired safe and physically unsafe pieces of advice. We
utilize SafeText to empirically study commonsense physical safety across
various models designed for text generation and commonsense reasoning tasks. We
find that state-of-the-art large language models are susceptible to the
generation of unsafe text and have difficulty rejecting unsafe advice. As a
result, we argue for further studies of safety and the assessment of
commonsense physical safety in models before release.",None,-1
f9379902-be87-438d-8880-89b182fa26b2,The Weighting Game: Evaluating Quality of Explainability Methods,0.135545,"The objective of this paper is to assess the quality of explanation heatmaps
for image classification tasks. To assess the quality of explainability
methods, we approach the task through the lens of accuracy and stability.
  In this work, we make the following contributions. Firstly, we introduce the
Weighting Game, which measures how much of a class-guided explanation is
contained within the correct class' segmentation mask. Secondly, we introduce a
metric for explanation stability, using zooming/panning transformations to
measure differences between saliency maps with similar contents.
  Quantitative experiments are produced, using these new metrics, to evaluate
the quality of explanations provided by commonly used CAM methods. The quality
of explanations is also contrasted between different model architectures, with
findings highlighting the need to consider model architecture when choosing an
explainability method.",https://github.com/lassiraa/weighting-game,-1
e92517c1-caa4-4637-9397-29755dce05e1,"GMM-IL: Image Classification using Incrementally Learnt, Independent Probabilistic Models for Small Sample Sizes",0.0321443,"Current deep learning classifiers, carry out supervised learning and store
class discriminatory information in a set of shared network weights. These
weights cannot be easily altered to incrementally learn additional classes,
since the classification weights all require retraining to prevent old class
information from being lost and also require the previous training data to be
present. We present a novel two stage architecture which couples visual feature
learning with probabilistic models to represent each class in the form of a
Gaussian Mixture Model. By using these independent class representations within
our classifier, we outperform a benchmark of an equivalent network with a
Softmax head, obtaining increased accuracy for sample sizes smaller than 12 and
increased weighted F1 score for 3 imbalanced class profiles in that sample
range. When learning new classes our classifier exhibits no catastrophic
forgetting issues and only requires the new classes' training images to be
present. This enables a database of growing classes over time which can be
visually indexed and reasoned over.",None,-1
ba44d0e7-f628-48ae-b0f0-e7b060e14ca5,Overcoming Language Priors in Visual Question Answering via Distinguishing Superficially Similar Instances,0.200449,"Despite the great progress of Visual Question Answering (VQA), current VQA
models heavily rely on the superficial correlation between the question type
and its corresponding frequent answers (i.e., language priors) to make
predictions, without really understanding the input. In this work, we define
the training instances with the same question type but different answers as
\textit{superficially similar instances}, and attribute the language priors to
the confusion of VQA model on such instances. To solve this problem, we propose
a novel training framework that explicitly encourages the VQA model to
distinguish between the superficially similar instances. Specifically, for each
training instance, we first construct a set that contains its superficially
similar counterparts. Then we exploit the proposed distinguishing module to
increase the distance between the instance and its counterparts in the answer
space. In this way, the VQA model is forced to further focus on the other parts
of the input beyond the question type, which helps to overcome the language
priors. Experimental results show that our method achieves the state-of-the-art
performance on VQA-CP v2. Codes are available at
\href{https://github.com/wyk-nku/Distinguishing-VQA.git}{Distinguishing-VQA}.",None,-1
7e9ac318-0098-4784-85f4-89dbdd907dfb,Learning to Break the Loop: Analyzing and Mitigating Repetitions for Neural Text Generation,0.525516,"While large-scale neural language models, such as GPT2 and BART, have
achieved impressive results on various text generation tasks, they tend to get
stuck in undesirable sentence-level loops with maximization-based decoding
algorithms (\textit{e.g.}, greedy search). This phenomenon is counter-intuitive
since there are few consecutive sentence-level repetitions in human corpora
(e.g., 0.02\% in Wikitext-103). To investigate the underlying reasons for
generating consecutive sentence-level repetitions, we study the relationship
between the probabilities of the repetitive tokens and their previous
repetitions in the context. Through our quantitative experiments, we find that
1) Language models have a preference to repeat the previous sentence; 2) The
sentence-level repetitions have a \textit{self-reinforcement effect}: the more
times a sentence is repeated in the context, the higher the probability of
continuing to generate that sentence; 3) The sentences with higher initial
probabilities usually have a stronger self-reinforcement effect. Motivated by
our findings, we propose a simple and effective training method \textbf{DITTO}
(Pseu\underline{D}o-Repet\underline{IT}ion
Penaliza\underline{T}i\underline{O}n), where the model learns to penalize
probabilities of sentence-level repetitions from pseudo repetitive data.
Although our method is motivated by mitigating repetitions, experiments show
that DITTO not only mitigates the repetition issue without sacrificing
perplexity, but also achieves better generation quality. Extensive experiments
on open-ended text generation (Wikitext-103) and text summarization
(CNN/DailyMail) demonstrate the generality and effectiveness of our method.",https://github.com/Jxu-Thu/DITTO,-1
ea1ea9b6-16d1-4934-a394-09a2b0bde4a9,BLIND: Bias Removal With No Demographics,0.661212,"Models trained on real-world data tend to imitate and amplify social biases.
Common methods to mitigate biases require prior information on the types of
biases that should be mitigated (e.g., gender or racial bias) and the social
groups associated with each data sample. In this work, we introduce BLIND, a
method for bias removal with no prior knowledge of the demographics in the
dataset. While training a model on a downstream task, BLIND detects biased
samples using an auxiliary model that predicts the main model's success, and
down-weights those samples during the training process. Experiments with racial
and gender biases in sentiment classification and occupation classification
tasks demonstrate that BLIND mitigates social biases without relying on a
costly demographic annotation process. Our method is competitive with other
methods that require demographic information and sometimes even surpasses them.",https://github.com/technion-cs-nlp/BLIND,-1
35aa6837-bf60-4559-bc69-49a97c93bb9b,Emotion Analysis using Multi-Layered Networks for Graphical Representation of Tweets,0.527191,"Anticipating audience reaction towards a certain piece of text is integral to
several facets of society ranging from politics, research, and commercial
industries. Sentiment analysis (SA) is a useful natural language processing
(NLP) technique that utilizes both lexical/statistical and deep learning
methods to determine whether different sized texts exhibit a positive,
negative, or neutral emotion. However, there is currently a lack of tools that
can be used to analyse groups of independent texts and extract the primary
emotion from the whole set. Therefore, the current paper proposes a novel
algorithm referred to as the Multi-Layered Tweet Analyzer (MLTA) that
graphically models social media text using multi-layered networks (MLNs) in
order to better encode relationships across independent sets of tweets. Graph
structures are capable of capturing meaningful relationships in complex
ecosystems compared to other representation methods. State of the art Graph
Neural Networks (GNNs) are used to extract information from the Tweet-MLN and
make predictions based on the extracted graph features. Results show that not
only does the MLTA predict from a larger set of possible emotions, delivering a
more accurate sentiment compared to the standard positive, negative or neutral,
it also allows for accurate group-level predictions of Twitter data.",None,-1
9865f5b2-6795-43cb-ada0-24a75a7a1822,Amortized Inference for Heterogeneous Reconstruction in Cryo-EM,0.538722,"Cryo-electron microscopy (cryo-EM) is an imaging modality that provides
unique insights into the dynamics of proteins and other building blocks of
life. The algorithmic challenge of jointly estimating the poses, 3D structure,
and conformational heterogeneity of a biomolecule from millions of noisy and
randomly oriented 2D projections in a computationally efficient manner,
however, remains unsolved. Our method, cryoFIRE, performs ab initio
heterogeneous reconstruction with unknown poses in an amortized framework,
thereby avoiding the computationally expensive step of pose search while
enabling the analysis of conformational heterogeneity. Poses and conformation
are jointly estimated by an encoder while a physics-based decoder aggregates
the images into an implicit neural representation of the conformational space.
We show that our method can provide one order of magnitude speedup on datasets
containing millions of images without any loss of accuracy. We validate that
the joint estimation of poses and conformations can be amortized over the size
of the dataset. For the first time, we prove that an amortized method can
extract interpretable dynamic information from experimental datasets.",None,-1
2dac3ad1-78e7-4220-9966-b489f3dad5a3,On the Complexity of Object Detection on Real-world Public Transportation Images for Social Distancing Measurement,0.0156035,"Social distancing in public spaces has become an essential aspect in helping
to reduce the impact of the COVID-19 pandemic. Exploiting recent advances in
machine learning, there have been many studies in the literature implementing
social distancing via object detection through the use of surveillance cameras
in public spaces. However, to date, there has been no study of social distance
measurement on public transport. The public transport setting has some unique
challenges, including some low-resolution images and camera locations that can
lead to the partial occlusion of passengers, which make it challenging to
perform accurate detection. Thus, in this paper, we investigate the challenges
of performing accurate social distance measurement on public transportation. We
benchmark several state-of-the-art object detection algorithms using real-world
footage taken from the London Underground and bus network. The work highlights
the complexity of performing social distancing measurement on images from
current public transportation onboard cameras. Further, exploiting domain
knowledge of expected passenger behaviour, we attempt to improve the quality of
the detections using various strategies and show improvement over using vanilla
object detection alone.",https://github.com/facebookresearch/detectron2,-1
bf427bf7-5fd2-4854-834c-4acb4c104a19,Is a Modular Architecture Enough?,0.805171,"Inspired from human cognition, machine learning systems are gradually
revealing advantages of sparser and more modular architectures. Recent work
demonstrates that not only do some modular architectures generalize well, but
they also lead to better out-of-distribution generalization, scaling
properties, learning speed, and interpretability. A key intuition behind the
success of such systems is that the data generating system for most real-world
settings is considered to consist of sparsely interacting parts, and endowing
models with similar inductive biases will be helpful. However, the field has
been lacking in a rigorous quantitative assessment of such systems because
these real-world data distributions are complex and unknown. In this work, we
provide a thorough assessment of common modular architectures, through the lens
of simple and known modular data distributions. We highlight the benefits of
modularity and sparsity and reveal insights on the challenges faced while
optimizing modular systems. In doing so, we propose evaluation metrics that
highlight the benefits of modularity, the regimes in which these benefits are
substantial, as well as the sub-optimality of current end-to-end learned
modular systems as opposed to their claimed potential.",https://github.com/sarthmit/Mod_Arch,-1
a8784e67-a607-4924-9a35-f18fb6ab6e75,Language Models are Multilingual Chain-of-Thought Reasoners,0.972928,"We evaluate the reasoning abilities of large language models in multilingual
settings. We introduce the Multilingual Grade School Math (MGSM) benchmark, by
manually translating 250 grade-school math problems from the GSM8K dataset
(Cobbe et al., 2021) into ten typologically diverse languages. We find that the
ability to solve MGSM problems via chain-of-thought prompting emerges with
increasing model scale, and that models have strikingly strong multilingual
reasoning abilities, even in underrepresented languages such as Bengali and
Swahili. Finally, we show that the multilingual reasoning abilities of language
models extend to other tasks such as commonsense reasoning and word-in-context
semantic judgment. The MGSM benchmark is publicly available at
https://github.com/google-research/url-nlp.",None,-1
0acb79c0-ef30-4c90-9d2e-f3a831536f7c,PaCo: Parameter-Compositional Multi-Task Reinforcement Learning,0.656791,"The purpose of multi-task reinforcement learning (MTRL) is to train a single
policy that can be applied to a set of different tasks. Sharing parameters
allows us to take advantage of the similarities among tasks. However, the gaps
between contents and difficulties of different tasks bring us challenges on
both which tasks should share the parameters and what parameters should be
shared, as well as the optimization challenges due to parameter sharing. In
this work, we introduce a parameter-compositional approach (PaCo) as an attempt
to address these challenges. In this framework, a policy subspace represented
by a set of parameters is learned. Policies for all the single tasks lie in
this subspace and can be composed by interpolating with the learned set. It
allows not only flexible parameter sharing but also a natural way to improve
training. We demonstrate the state-of-the-art performance on Meta-World
benchmarks, verifying the effectiveness of the proposed approach.",https://github.com/facebookresearch/mtrl,30737
8d71e1a7-95df-4616-a388-363ab09e5d27,Easy Ensemble: Simple Deep Ensemble Learning for Sensor-Based Human Activity Recognition,0.173495,"Sensor-based human activity recognition (HAR) is a paramount technology in
the Internet of Things services. HAR using representation learning, which
automatically learns a feature representation from raw data, is the mainstream
method because it is difficult to interpret relevant information from raw
sensor data to design meaningful features. Ensemble learning is a robust
approach to improve generalization performance; however, deep ensemble learning
requires various procedures, such as data partitioning and training multiple
models, which are time-consuming and computationally expensive. In this study,
we propose Easy Ensemble (EE) for HAR, which enables the easy implementation of
deep ensemble learning in a single model. In addition, we propose input masking
as a method for diversifying the input for EE. Experiments on a benchmark
dataset for HAR demonstrated the effectiveness of EE and input masking and
their characteristics compared with conventional ensemble learning methods.",https://github.com/t-hasegawa-FU/Easy-Ensemble,-1
5f6911af-a8e7-4738-a9ef-56cd60855423,Estimating and Explaining Model Performance When Both Covariates and Labels Shift,0.579429,"Deployed machine learning (ML) models often encounter new user data that
differs from their training data. Therefore, estimating how well a given model
might perform on the new data is an important step toward reliable ML
applications. This is very challenging, however, as the data distribution can
change in flexible ways, and we may not have any labels on the new data, which
is often the case in monitoring settings. In this paper, we propose a new
distribution shift model, Sparse Joint Shift (SJS), which considers the joint
shift of both labels and a few features. This unifies and generalizes several
existing shift models including label shift and sparse covariate shift, where
only marginal feature or label distribution shifts are considered. We describe
mathematical conditions under which SJS is identifiable. We further propose
SEES, an algorithmic framework to characterize the distribution shift under SJS
and to estimate a model's performance on new data without any labels. We
conduct extensive experiments on several real-world datasets with various ML
models. Across different datasets and distribution shifts, SEES achieves
significant (up to an order of magnitude) shift estimation error improvements
over existing approaches.",None,-1
44f319d0-bcf9-4070-b6f9-b08517db571f,Implicit Regularization with Polynomial Growth in Deep Tensor Factorization,0.129844,"We study the implicit regularization effects of deep learning in tensor
factorization. While implicit regularization in deep matrix and 'shallow'
tensor factorization via linear and certain type of non-linear neural networks
promotes low-rank solutions with at most quadratic growth, we show that its
effect in deep tensor factorization grows polynomially with the depth of the
network. This provides a remarkably faithful description of the observed
experimental behaviour. Using numerical experiments, we demonstrate the
benefits of this implicit regularization in yielding a more accurate estimation
and better convergence properties.",None,-1
b6847298-b260-4c53-9fb4-d11abe39d77c,Computational linguistics and Natural Language Processing,0.0619643,"This chapter provides an introduction to computational linguistics methods,
with focus on their applications to the practice and study of translation. It
covers computational models, methods and tools for collection, storage,
indexing and analysis of linguistic data in the context of translation, and
discusses the main methodological issues and challenges in this field. While an
exhaustive review of existing computational linguistics methods and tools is
beyond the scope of this chapter, we describe the most representative
approaches, and illustrate them with descriptions of typical applications.",None,-1
c88cf6a4-93c3-4750-ae5e-7ecbc51de368,Pruning-as-Search: Efficient Neural Architecture Search via Channel Pruning and Structural Reparameterization,0.775762,"Neural architecture search (NAS) and network pruning are widely studied
efficient AI techniques, but not yet perfect. NAS performs exhaustive candidate
architecture search, incurring tremendous search cost. Though (structured)
pruning can simply shrink model dimension, it remains unclear how to decide the
per-layer sparsity automatically and optimally. In this work, we revisit the
problem of layer-width optimization and propose Pruning-as-Search (PaS), an
end-to-end channel pruning method to search out desired sub-network
automatically and efficiently. Specifically, we add a depth-wise binary
convolution to learn pruning policies directly through gradient descent. By
combining the structural reparameterization and PaS, we successfully searched
out a new family of VGG-like and lightweight networks, which enable the
flexibility of arbitrary width with respect to each layer instead of each
stage. Experimental results show that our proposed architecture outperforms
prior arts by around $1.0\%$ top-1 accuracy under similar inference speed on
ImageNet-1000 classification task. Furthermore, we demonstrate the
effectiveness of our width search on complex tasks including instance
segmentation and image translation. Code and models are released.",None,-1
22e1b992-d49d-4ec3-b1b9-f546782d7a83,Black-box Few-shot Knowledge Distillation,0.429478,"Knowledge distillation (KD) is an efficient approach to transfer the
knowledge from a large ""teacher"" network to a smaller ""student"" network.
Traditional KD methods require lots of labeled training samples and a white-box
teacher (parameters are accessible) to train a good student. However, these
resources are not always available in real-world applications. The distillation
process often happens at an external party side where we do not have access to
much data, and the teacher does not disclose its parameters due to security and
privacy concerns. To overcome these challenges, we propose a black-box few-shot
KD method to train the student with few unlabeled training samples and a
black-box teacher. Our main idea is to expand the training set by generating a
diverse set of out-of-distribution synthetic images using MixUp and a
conditional variational auto-encoder. These synthetic images along with their
labels obtained from the teacher are used to train the student. We conduct
extensive experiments to show that our method significantly outperforms recent
SOTA few/zero-shot KD methods on image classification tasks. The code and
models are available at: https://github.com/nphdang/FS-BBT",https://github.com/nphdang/FS-BBT,30421
6553def9-5034-45fb-8372-8925eb3b8151,How Does SimSiam Avoid Collapse Without Negative Samples? A Unified Understanding with Self-supervised Contrastive Learning,0.832809,"To avoid collapse in self-supervised learning (SSL), a contrastive loss is
widely used but often requires a large number of negative samples. Without
negative samples yet achieving competitive performance, a recent work has
attracted significant attention for providing a minimalist simple Siamese
(SimSiam) method to avoid collapse. However, the reason for how it avoids
collapse without negative samples remains not fully clear and our investigation
starts by revisiting the explanatory claims in the original SimSiam. After
refuting their claims, we introduce vector decomposition for analyzing the
collapse based on the gradient analysis of the $l_2$-normalized representation
vector. This yields a unified perspective on how negative samples and SimSiam
alleviate collapse. Such a unified perspective comes timely for understanding
the recent progress in SSL.",None,-1
2533ff1d-9667-416c-9311-70bdf6406b47,Attention Based Neural Networks for Wireless Channel Estimation,0.76809,"In this paper, we deploy the self-attention mechanism to achieve improved
channel estimation for orthogonal frequency-division multiplexing waveforms in
the downlink. Specifically, we propose a new hybrid encoder-decoder structure
(called HA02) for the first time which exploits the attention mechanism to
focus on the most important input information. In particular, we implement a
transformer encoder block as the encoder to achieve the sparsity in the input
features and a residual neural network as the decoder respectively, inspired by
the success of the attention mechanism. Using 3GPP channel models, our
simulations show superior estimation performance compared with other candidate
neural network methods for channel estimation.",None,18255
7364b4ba-8c5a-42a4-a48a-41b5365df5a2,Extracting Impact Model Narratives from Social Services' Text,0.0356024,"Named entity recognition (NER) is an important task in narration extraction.
Narration, as a system of stories, provides insights into how events and
characters in the stories develop over time. This paper proposes an
architecture for NER on a corpus about social purpose organizations. This is
the first NER task specifically targeted at social service entities. We show
how this approach can be used for the sequencing of services and impacted
clients with information extracted from unstructured text. The methodology
outlines steps for extracting ontological representation of entities such as
needs and satisfiers and generating hypotheses to answer queries about impact
models defined by social purpose organizations. We evaluate the model on a
corpus of social service descriptions with empirically calculated score.",None,-1
06070d40-9d96-470b-ade4-9ac9ff97daed,ProQA: Structural Prompt-based Pre-training for Unified Question Answering,0.616363,"Question Answering (QA) is a longstanding challenge in natural language
processing. Existing QA works mostly focus on specific question types,
knowledge domains, or reasoning skills. The specialty in QA research hinders
systems from modeling commonalities between tasks and generalization for wider
applications. To address this issue, we present ProQA, a unified QA paradigm
that solves various tasks through a single model. ProQA takes a unified
structural prompt as the bridge and improves the QA-centric ability by
structural prompt-based pre-training. Through a structurally designed
prompt-based input schema, ProQA concurrently models the knowledge
generalization for all QA tasks while keeping the knowledge customization for
every specific QA task. Furthermore, ProQA is pre-trained with structural
prompt-formatted large-scale synthesized corpus, which empowers the model with
the commonly-required QA ability. Experimental results on 11 QA benchmarks
demonstrate that ProQA consistently boosts performance on both full data
fine-tuning, few-shot learning, and zero-shot testing scenarios. Furthermore,
ProQA exhibits strong ability in both continual learning and transfer learning
by taking the advantages of the structural prompt.",https://github.com/zhongwanjun/ProQA,-1
41f45234-0aa4-49f4-9dab-768a999330cd,DocBed: A Multi-Stage OCR Solution for Documents with Complex Layouts,0.716781,"Digitization of newspapers is of interest for many reasons including
preservation of history, accessibility and search ability, etc. While
digitization of documents such as scientific articles and magazines is
prevalent in literature, one of the main challenges for digitization of
newspaper lies in its complex layout (e.g. articles spanning multiple columns,
text interrupted by images) analysis, which is necessary to preserve human
read-order. This work provides a major breakthrough in the digitization of
newspapers on three fronts: first, releasing a dataset of 3000 fully-annotated,
real-world newspaper images from 21 different U.S. states representing an
extensive variety of complex layouts for document layout analysis; second,
proposing layout segmentation as a precursor to existing optical character
recognition (OCR) engines, where multiple state-of-the-art image segmentation
models and several post-processing methods are explored for document layout
segmentation; third, providing a thorough and structured evaluation protocol
for isolated layout segmentation and end-to-end OCR.",https://github.com/facebookresearch/detectron2,-1
0224d54a-8acd-4fce-a008-a989b2483e6a,Qualia as physical measurements: a mathematical model of qualia and pure concepts,0.664089,"A space of qualia is defined to be a sober topological space whose points are
the qualia and whose open sets are the pure concepts in the sense of Lewis,
carrying additional algebraic structure that conveys the conscious experience
of subjective time and logical abstraction. This structure is analogous to that
of a space of physical measurements. It is conjectured that qualia and
measurements have the same nature, corresponding to fundamental processes via
which classical information is produced and physically stored, and that
therefore the hard problem of consciousness and the measurement problem are two
facets of the same problem. The space of qualia is independent from any
preexisting notions of spacetime and conscious agent, but its structure caters
for a derived geometric model of observer. Intersubjectivity is based on
relating different observers in a way that leads to a logical version of
quantum superposition.",None,-1
76cc1f31-a6db-4ee4-9d16-d653b91fc026,Mapless Navigation of a Hybrid Aerial Underwater Vehicle with Deep Reinforcement Learning Through Environmental Generalization,0.46597,"Previous works showed that Deep-RL can be applied to perform mapless
navigation, including the medium transition of Hybrid Unmanned Aerial
Underwater Vehicles (HUAUVs). This paper presents new approaches based on the
state-of-the-art actor-critic algorithms to address the navigation and medium
transition problems for a HUAUV. We show that a double critic Deep-RL with
Recurrent Neural Networks improves the navigation performance of HUAUVs using
solely range data and relative localization. Our Deep-RL approaches achieved
better navigation and transitioning capabilities with a solid generalization of
learning through distinct simulated scenarios, outperforming previous
approaches.",None,-1
0930e7f6-33da-4f5c-aa3a-e3b0b8f5f47e,Conflict-Based Search for Explainable Multi-Agent Path Finding,0.551247,"In the Multi-Agent Path Finding (MAPF) problem, the goal is to find
non-colliding paths for agents in an environment, such that each agent reaches
its goal from its initial location. In safety-critical applications, a human
supervisor may want to verify that the plan is indeed collision-free. To this
end, a recent work introduces a notion of explainability for MAPF based on a
visualization of the plan as a short sequence of images representing time
segments, where in each time segment the trajectories of the agents are
disjoint. Then, the explainable MAPF problem asks for a set of non-colliding
paths that admits a short-enough explanation. Explainable MAPF adds a new
difficulty to MAPF, in that it is NP-hard with respect to the size of the
environment, and not just the number of agents. Thus, traditional MAPF
algorithms are not equipped to directly handle explainable-MAPF. In this work,
we adapt Conflict Based Search (CBS), a well-studied algorithm for MAPF, to
handle explainable MAPF. We show how to add explainability constraints on top
of the standard CBS tree and its underlying A* search. We examine the
usefulness of this approach and, in particular, the tradeoff between planning
time and explainability.",https://github.com/atb033/multi-agent-path-planning,-1
20f63022-b93f-49e4-b9bb-7f3665c4de1f,CORE: Simple and Effective Session-based Recommendation within Consistent Representation Space,0.93558,"Session-based Recommendation (SBR) refers to the task of predicting the next
item based on short-term user behaviors within an anonymous session. However,
session embedding learned by a non-linear encoder is usually not in the same
representation space as item embeddings, resulting in the inconsistent
prediction issue while recommending items. To address this issue, we propose a
simple and effective framework named CORE, which can unify the representation
space for both the encoding and decoding processes. Firstly, we design a
representation-consistent encoder that takes the linear combination of input
item embeddings as session embedding, guaranteeing that sessions and items are
in the same representation space. Besides, we propose a robust distance
measuring method to prevent overfitting of embeddings in the consistent
representation space. Extensive experiments conducted on five public real-world
datasets demonstrate the effectiveness and efficiency of the proposed method.
The code is available at: https://github.com/RUCAIBox/CORE.",https://github.com/RUCAIBox/CORE,19116
951e4bd5-721d-48c3-8aa5-58083358b0aa,Leveraging Language for Accelerated Learning of Tool Manipulation,0.59889,"Robust and generalized tool manipulation requires an understanding of the
properties and affordances of different tools. We investigate whether
linguistic information about a tool (e.g., its geometry, common uses) can help
control policies adapt faster to new tools for a given task. We obtain diverse
descriptions of various tools in natural language and use pre-trained language
models to generate their feature representations. We then perform
language-conditioned meta-learning to learn policies that can efficiently adapt
to new tools given their corresponding text descriptions. Our results
demonstrate that combining linguistic information and meta-learning
significantly accelerates tool learning in several manipulation tasks including
pushing, lifting, sweeping, and hammering.",None,-1
154476b5-ed35-4eab-9d75-b2200ddc352c,Structured Pruning Learns Compact and Accurate Models,0.999305,"The growing size of neural language models has led to increased attention in
model compression. The two predominant approaches are pruning, which gradually
removes weights from a pre-trained model, and distillation, which trains a
smaller compact model to match a larger one. Pruning methods can significantly
reduce the model size but hardly achieve large speedups as distillation.
However, distillation methods require large amounts of unlabeled data and are
expensive to train. In this work, we propose a task-specific structured pruning
method CoFi (Coarse- and Fine-grained Pruning), which delivers highly
parallelizable subnetworks and matches the distillation methods in both
accuracy and latency, without resorting to any unlabeled data. Our key insight
is to jointly prune coarse-grained (e.g., layers) and fine-grained (e.g., heads
and hidden units) modules, which controls the pruning decision of each
parameter with masks of different granularity. We also devise a layerwise
distillation strategy to transfer knowledge from unpruned to pruned models
during optimization. Our experiments on GLUE and SQuAD datasets show that CoFi
yields models with over 10x speedups with a small accuracy drop, showing its
effectiveness and efficiency compared to previous pruning and distillation
approaches.",https://github.com/princeton-nlp/CoFiPruning,-1
88331ce1-62f7-41e6-ad99-da7759f87d83,SpA-Former: Transformer image shadow detection and removal via spatial attention,0.307232,"In this paper, we propose an end-to-end SpA-Former to recover a shadow-free
image from a single shaded image. Unlike traditional methods that require two
steps for shadow detection and then shadow removal, the SpA-Former unifies
these steps into one, which is a one-stage network capable of directly learning
the mapping function between shadows and no shadows, it does not require a
separate shadow detection. Thus, SpA-former is adaptable to real image
de-shadowing for shadows projected on different semantic regions. SpA-Former
consists of transformer layer and a series of joint Fourier transform residual
blocks and two-wheel joint spatial attention. The network in this paper is able
to handle the task while achieving a very fast processing efficiency.
  Our code is relased on
https://github.com/zhangbaijin/SpA-Former-shadow-removal",https://github.com/zhangbaijin/SpA-Former-shadow-removal,-1
a2a68e70-58f5-4c9c-aee2-bf1a9997b0e9,Hardware-agnostic Computation for Large-scale Knowledge Graph Embeddings,0.287943,"Knowledge graph embedding research has mainly focused on learning continuous
representations of knowledge graphs towards the link prediction problem.
Recently developed frameworks can be effectively applied in research related
applications. Yet, these frameworks do not fulfill many requirements of
real-world applications. As the size of the knowledge graph grows, moving
computation from a commodity computer to a cluster of computers in these
frameworks becomes more challenging. Finding suitable hyperparameter settings
w.r.t. time and computational budgets are left to practitioners. In addition,
the continual learning aspect in knowledge graph embedding frameworks is often
ignored, although continual learning plays an important role in many real-world
(deep) learning-driven applications. Arguably, these limitations explain the
lack of publicly available knowledge graph embedding models for large knowledge
graphs. We developed a framework based on the frameworks DASK, Pytorch
Lightning and Hugging Face to compute embeddings for large-scale knowledge
graphs in a hardware-agnostic manner, which is able to address real-world
challenges pertaining to the scale of real application. We provide an
open-source version of our framework along with a hub of pre-trained models
having more than 11.4 B parameters.",https://github.com/dice-group/dice-embeddings,-1
98f9ae2e-94f6-4951-a221-ade1c957a69d,"Textual Stylistic Variation: Choices, Genres and Individuals",0.202921,"This chapter argues for more informed target metrics for the statistical
processing of stylistic variation in text collections. Much as operationalised
relevance proved a useful goal to strive for in information retrieval, research
in textual stylistics, whether application oriented or philologically inclined,
needs goals formulated in terms of pertinence, relevance, and utility - notions
that agree with reader experience of text. Differences readers are aware of are
mostly based on utility - not on textual characteristics per se. Mostly,
readers report stylistic differences in terms of genres. Genres, while vague
and undefined, are well-established and talked about: very early on, readers
learn to distinguish genres. This chapter discusses variation given by genre,
and contrasts it to variation occasioned by individual choice.",None,-1
90c92e73-6573-445a-9fe4-0cdf4e048983,A Novel Semi-supervised Meta Learning Method for Subject-transfer Brain-computer Interface,0.933001,"Brain-computer interface (BCI) provides a direct communication pathway
between human brain and external devices. Before a new subject could use BCI, a
calibration procedure is usually required. Because the inter- and intra-subject
variances are so large that the models trained by the existing subjects perform
poorly on new subjects. Therefore, effective subject-transfer and calibration
method is essential. In this paper, we propose a semi-supervised meta learning
(SSML) method for subject-transfer learning in BCIs. The proposed SSML learns a
meta model with the existing subjects first, then fine-tunes the model in a
semi-supervised learning manner, i.e. using few labeled and many unlabeled
samples of target subject for calibration. It is significant for BCI
applications where the labeled data are scarce or expensive while unlabeled
data are readily available. To verify the SSML method, three different BCI
paradigms are tested: 1) event-related potential detection; 2) emotion
recognition; and 3) sleep staging. The SSML achieved significant improvements
of over 15% on the first two paradigms and 4.9% on the third. The experimental
results demonstrated the effectiveness and potential of the SSML method in BCI
applications.",None,-1
bac507c6-9f5b-432b-aeb8-abe15eb2f56a,PARSRec: Explainable Personalized Attention-fused Recurrent Sequential Recommendation Using Session Partial Actions,0.254194,"The emerging meta- and multi-verse landscape is yet another step towards the
more prevalent use of already ubiquitous online markets. In such markets,
recommender systems play critical roles by offering items of interest to the
users, thereby narrowing down a vast search space that comprises hundreds of
thousands of products. Recommender systems are usually designed to learn common
user behaviors and rely on them for inference. This approach, while effective,
is oblivious to subtle idiosyncrasies that differentiate humans from each
other. Focusing on this observation, we propose an architecture that relies on
common patterns as well as individual behaviors to tailor its recommendations
for each person. Simulations under a controlled environment show that our
proposed model learns interpretable personalized user behaviors. Our empirical
results on Nielsen Consumer Panel dataset indicate that the proposed approach
achieves up to 27.9% performance improvement compared to the state-of-the-art.",https://github.com/ehgh/PARSRec,-1
234eee63-bccf-4f73-9bb0-a0f77d320042,MAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music Audio Representation Learning,0.849612,"The deep learning community has witnessed an exponentially growing interest
in self-supervised learning (SSL). However, it still remains unexplored how to
build a framework for learning useful representations of raw music waveforms in
a self-supervised manner. In this work, we design Music2Vec, a framework
exploring different SSL algorithmic components and tricks for music audio
recordings. Our model achieves comparable results to the state-of-the-art
(SOTA) music SSL model Jukebox, despite being significantly smaller with less
than 2% of parameters of the latter. The model will be released on
Huggingface(Please refer to: https://huggingface.co/m-a-p/music2vec-v1)",https://huggingface.co/m-a-p/music2vec-v1,-1
e5d5771b-0c43-491d-ab68-55876206128c,Constrained Dynamic Movement Primitives for Safe Learning of Motor Skills,0.744271,"Dynamic movement primitives are widely used for learning skills which can be
demonstrated to a robot by a skilled human or controller. While their
generalization capabilities and simple formulation make them very appealing to
use, they possess no strong guarantees to satisfy operational safety
constraints for a task. In this paper, we present constrained dynamic movement
primitives (CDMP) which can allow for constraint satisfaction in the robot
workspace. We present a formulation of a non-linear optimization to perturb the
DMP forcing weights regressed by locally-weighted regression to admit a Zeroing
Barrier Function (ZBF), which certifies workspace constraint satisfaction. We
demonstrate the proposed CDMP under different constraints on the end-effector
movement such as obstacle avoidance and workspace constraints on a physical
robot. A video showing the implementation of the proposed algorithm using
different manipulators in different environments could be found here
https://youtu.be/hJegJJkJfys.",None,-1
036b758f-c6c1-40a7-9275-1c41c8d3e75d,Socially Intelligent Genetic Agents for the Emergence of Explicit Norms,0.320399,"Norms help regulate a society. Norms may be explicit (represented in
structured form) or implicit. We address the emergence of explicit norms by
developing agents who provide and reason about explanations for norm violations
in deciding sanctions and identifying alternative norms. These agents use a
genetic algorithm to produce norms and reinforcement learning to learn the
values of these norms. We find that applying explanations leads to norms that
provide better cohesion and goal satisfaction for the agents. Our results are
stable for societies with differing attitudes of generosity.",https://github.com/niravajmeri/,31895
a41289c9-be8e-4490-8122-e1d402eefc0d,Monocular Human Digitization via Implicit Re-projection Networks,0.111024,"We present an approach to generating 3D human models from images. The key to
our framework is that we predict double-sided orthographic depth maps and color
images from a single perspective projected image. Our framework consists of
three networks. The first network predicts normal maps to recover geometric
details such as wrinkles in the clothes and facial regions. The second network
predicts shade-removed images for the front and back views by utilizing the
predicted normal maps. The last multi-headed network takes both normal maps and
shade-free images and predicts depth maps while selectively fusing photometric
and geometric information through multi-headed attention gates. Experimental
results demonstrate that our method shows visually plausible results and
competitive performance in terms of various evaluation metrics over
state-of-the-art methods.",None,-1
7f9d10c7-71ba-4c98-b975-9fb711893cd9,Robust PCA Unrolling Network for Super-resolution Vessel Extraction in X-ray Coronary Angiography,0.416418,"Although robust PCA has been increasingly adopted to extract vessels from
X-ray coronary angiography (XCA) images, challenging problems such as
inefficient vessel-sparsity modelling, noisy and dynamic background artefacts,
and high computational cost still remain unsolved. Therefore, we propose a
novel robust PCA unrolling network with sparse feature selection for
super-resolution XCA vessel imaging. Being embedded within a patch-wise
spatiotemporal super-resolution framework that is built upon a pooling layer
and a convolutional long short-term memory network, the proposed network can
not only gradually prune complex vessel-like artefacts and noisy backgrounds in
XCA during network training but also iteratively learn and select the
high-level spatiotemporal semantic information of moving contrast agents
flowing in the XCA-imaged vessels. The experimental results show that the
proposed method significantly outperforms state-of-the-art methods, especially
in the imaging of the vessel network and its distal vessels, by restoring the
intensity and geometry profiles of heterogeneous vessels against complex and
dynamic backgrounds.",None,-1
9a94c941-02a5-4634-b42a-1b07171538f5,Penalized Proximal Policy Optimization for Safe Reinforcement Learning,0.774289,"Safe reinforcement learning aims to learn the optimal policy while satisfying
safety constraints, which is essential in real-world applications. However,
current algorithms still struggle for efficient policy updates with hard
constraint satisfaction. In this paper, we propose Penalized Proximal Policy
Optimization (P3O), which solves the cumbersome constrained policy iteration
via a single minimization of an equivalent unconstrained problem. Specifically,
P3O utilizes a simple-yet-effective penalty function to eliminate cost
constraints and removes the trust-region constraint by the clipped surrogate
objective. We theoretically prove the exactness of the proposed method with a
finite penalty factor and provide a worst-case analysis for approximate error
when evaluated on sample trajectories. Moreover, we extend P3O to more
challenging multi-constraint and multi-agent scenarios which are less studied
in previous work. Extensive experiments show that P3O outperforms
state-of-the-art algorithms with respect to both reward improvement and
constraint satisfaction on a set of constrained locomotive tasks.",https://github.com/openai/safety-starter-agents,-1
91276a66-f285-4175-bf2e-74190901f516,"Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs",0.996026,"The formalization of existing mathematical proofs is a notoriously difficult
process. Despite decades of research on automation and proof assistants,
writing formal proofs remains arduous and only accessible to a few experts.
While previous studies to automate formalization focused on powerful search
algorithms, no attempts were made to take advantage of available informal
proofs. In this work, we introduce Draft, Sketch, and Prove (DSP), a method
that maps informal proofs to formal proof sketches, and uses the sketches to
guide an automated prover by directing its search to easier sub-problems. We
investigate two relevant setups where informal proofs are either written by
humans or generated by a language model. Our experiments and ablation studies
show that large language models are able to produce well-structured formal
sketches that follow the same reasoning steps as the informal proofs. Guiding
an automated prover with these sketches enhances its performance from 20.9% to
39.3% on a collection of mathematical competition problems.",None,-1
d56d4982-fc0f-404e-a197-c75b1511c86b,CascadER: Cross-Modal Cascading for Knowledge Graph Link Prediction,0.466698,"Knowledge graph (KG) link prediction is a fundamental task in artificial
intelligence, with applications in natural language processing, information
retrieval, and biomedicine. Recently, promising results have been achieved by
leveraging cross-modal information in KGs, using ensembles that combine
knowledge graph embeddings (KGEs) and contextual language models (LMs).
However, existing ensembles are either (1) not consistently effective in terms
of ranking accuracy gains or (2) impractically inefficient on larger datasets
due to the combinatorial explosion problem of pairwise ranking with deep
language models. In this paper, we propose a novel tiered ranking architecture
CascadER to maintain the ranking accuracy of full ensembling while improving
efficiency considerably. CascadER uses LMs to rerank the outputs of more
efficient base KGEs, relying on an adaptive subset selection scheme aimed at
invoking the LMs minimally while maximizing accuracy gain over the KGE.
Extensive experiments demonstrate that CascadER improves MRR by up to 9 points
over KGE baselines, setting new state-of-the-art performance on four benchmarks
while improving efficiency by one or more orders of magnitude over competitive
cross-modal baselines. Our empirical analyses reveal that diversity of models
across modalities and preservation of individual models' confidence signals
help explain the effectiveness of CascadER, and suggest promising directions
for cross-modal cascaded architectures. Code and pretrained models are
available at https://github.com/tsafavi/cascader.",None,-1
5c70ccf9-0f01-45b7-a9eb-edd7b7fd55d2,Context-Dependent Anomaly Detection with Knowledge Graph Embedding Models,0.126169,"Increasing the semantic understanding and contextual awareness of machine
learning models is important for improving robustness and reducing
susceptibility to data shifts. In this work, we leverage contextual awareness
for the anomaly detection problem. Although graphed-based anomaly detection has
been widely studied, context-dependent anomaly detection is an open problem and
without much current research. We develop a general framework for converting a
context-dependent anomaly detection problem to a link prediction problem,
allowing well-established techniques from this domain to be applied. We
implement a system based on our framework that utilizes knowledge graph
embedding models and demonstrates the ability to detect outliers using context
provided by a semantic knowledge base. We show that our method can detect
context-dependent anomalies with a high degree of accuracy and show that
current object detectors can detect enough classes to provide the needed
context for good performance within our example domain.",None,-1
19fc0655-f653-4eb5-9f80-9dbefbad4b39,Improving Chinese Spelling Check by Character Pronunciation Prediction: The Effects of Adaptivity and Granularity,0.788199,"Chinese spelling check (CSC) is a fundamental NLP task that detects and
corrects spelling errors in Chinese texts. As most of these spelling errors are
caused by phonetic similarity, effectively modeling the pronunciation of
Chinese characters is a key factor for CSC. In this paper, we consider
introducing an auxiliary task of Chinese pronunciation prediction (CPP) to
improve CSC, and, for the first time, systematically discuss the adaptivity and
granularity of this auxiliary task. We propose SCOPE which builds on top of a
shared encoder two parallel decoders, one for the primary CSC task and the
other for a fine-grained auxiliary CPP task, with a novel adaptive weighting
scheme to balance the two tasks. In addition, we design a delicate iterative
correction strategy for further improvements during inference. Empirical
evaluation shows that SCOPE achieves new state-of-the-art on three CSC
benchmarks, demonstrating the effectiveness and superiority of the auxiliary
CPP task. Comprehensive ablation studies further verify the positive effects of
adaptivity and granularity of the task. Code and data used in this paper are
publicly available at https://github.com/jiahaozhenbang/SCOPE.",https://github.com/jiahaozhenbang/SCOPE,-1
1814982e-30dd-4855-9eb1-2912b25ac308,IISERB Brains at SemEval 2022 Task 6: A Deep-learning Framework to Identify Intended Sarcasm in English,0.0128021,"This paper describes the system architectures and the models submitted by our
team ""IISERBBrains"" to SemEval 2022 Task 6 competition. We contested for all
three sub-tasks floated for the English dataset. On the leader-board, wegot19th
rank out of43 teams for sub-taskA, the 8th rank out of22 teams for sub-task
B,and13th rank out of 16 teams for sub-taskC. Apart from the submitted results
and models, we also report the other models and results that we obtained
through our experiments after organizers published the gold labels of their
evaluation data",https://github.com/manojmahan/,23278
b3cc0139-6269-4755-8fbd-15f6f0eb9bca,Neural Contourlet Network for Monocular 360 Depth Estimation,0.550373,"For a monocular 360 image, depth estimation is a challenging because the
distortion increases along the latitude. To perceive the distortion, existing
methods devote to designing a deep and complex network architecture. In this
paper, we provide a new perspective that constructs an interpretable and sparse
representation for a 360 image. Considering the importance of the geometric
structure in depth estimation, we utilize the contourlet transform to capture
an explicit geometric cue in the spectral domain and integrate it with an
implicit cue in the spatial domain. Specifically, we propose a neural
contourlet network consisting of a convolutional neural network and a
contourlet transform branch. In the encoder stage, we design a spatial-spectral
fusion module to effectively fuse two types of cues. Contrary to the encoder,
we employ the inverse contourlet transform with learned low-pass subbands and
band-pass directional subbands to compose the depth in the decoder. Experiments
on the three popular panoramic image datasets demonstrate that the proposed
approach outperforms the state-of-the-art schemes with faster convergence. Code
is available at
https://github.com/zhijieshen-bjtu/Neural-Contourlet-Network-for-MODE.",None,-1
2cb4b024-ad7b-4ebe-b95d-4e8afe61bd00,Learning Deformable Object Manipulation from Expert Demonstrations,0.572537,"We present a novel Learning from Demonstration (LfD) method, Deformable
Manipulation from Demonstrations (DMfD), to solve deformable manipulation tasks
using states or images as inputs, given expert demonstrations. Our method uses
demonstrations in three different ways, and balances the trade-off between
exploring the environment online and using guidance from experts to explore
high dimensional spaces effectively. We test DMfD on a set of representative
manipulation tasks for a 1-dimensional rope and a 2-dimensional cloth from the
SoftGym suite of tasks, each with state and image observations. Our method
exceeds baseline performance by up to 12.9% for state-based tasks and up to
33.44% on image-based tasks, with comparable or better robustness to
randomness. Additionally, we create two challenging environments for folding a
2D cloth using image-based observations, and set a performance benchmark for
them. We deploy DMfD on a real robot with a minimal loss in normalized
performance during real-world execution compared to simulation (~6%). Source
code is on github.com/uscresl/dmfd",https://github.com/uscresl/dmfd,445
1d67225a-70c6-4576-953f-4c7e164366b6,Multi-domain Unsupervised Image-to-Image Translation with Appearance Adaptive Convolution,0.0631176,"Over the past few years, image-to-image (I2I) translation methods have been
proposed to translate a given image into diverse outputs. Despite the
impressive results, they mainly focus on the I2I translation between two
domains, so the multi-domain I2I translation still remains a challenge. To
address this problem, we propose a novel multi-domain unsupervised
image-to-image translation (MDUIT) framework that leverages the decomposed
content feature and appearance adaptive convolution to translate an image into
a target appearance while preserving the given geometric content. We also
exploit a contrast learning objective, which improves the disentanglement
ability and effectively utilizes multi-domain image data in the training
process by pairing the semantically similar images. This allows our method to
learn the diverse mappings between multiple visual domains with only a single
framework. We show that the proposed method produces visually diverse and
plausible results in multiple domains compared to the state-of-the-art methods.",None,8983
27bac5df-412a-4e75-9f92-def875c1a26a,Editable Indoor Lighting Estimation,0.638021,"We present a method for estimating lighting from a single perspective image
of an indoor scene. Previous methods for predicting indoor illumination usually
focus on either simple, parametric lighting that lack realism, or on richer
representations that are difficult or even impossible to understand or modify
after prediction. We propose a pipeline that estimates a parametric light that
is easy to edit and allows renderings with strong shadows, alongside with a
non-parametric texture with high-frequency information necessary for realistic
rendering of specular objects. Once estimated, the predictions obtained with
our model are interpretable and can easily be modified by an artist/user with a
few mouse clicks. Quantitative and qualitative results show that our approach
makes indoor lighting estimation easier to handle by a casual user, while still
producing competitive results.",None,6586
a8498ce7-9d51-40c7-8fde-534e167a30b5,EUR-Lex-Sum: A Multi- and Cross-lingual Dataset for Long-form Summarization in the Legal Domain,0.929675,"Existing summarization datasets come with two main drawbacks: (1) They tend
to focus on overly exposed domains, such as news articles or wiki-like texts,
and (2) are primarily monolingual, with few multilingual datasets. In this
work, we propose a novel dataset, called EUR-Lex-Sum, based on manually curated
document summaries of legal acts from the European Union law platform
(EUR-Lex). Documents and their respective summaries exist as cross-lingual
paragraph-aligned data in several of the 24 official European languages,
enabling access to various cross-lingual and lower-resourced summarization
setups. We obtain up to 1,500 document/summary pairs per language, including a
subset of 375 cross-lingually aligned legal acts with texts available in all 24
languages. In this work, the data acquisition process is detailed and key
characteristics of the resource are compared to existing summarization
resources. In particular, we illustrate challenging sub-problems and open
questions on the dataset that could help the facilitation of future research in
the direction of domain-specific cross-lingual summarization. Limited by the
extreme length and language diversity of samples, we further conduct
experiments with suitable extractive monolingual and cross-lingual baselines
for future work. Code for the extraction as well as access to our data and
baselines is available online at: https://github.com/achouhan93/eur-lex-sum.",https://github.com/achouhan93/eur-lex-sum,-1
8f09970d-1bc0-4e72-8a85-616b0947e97e,YOLO-FaceV2: A Scale and Occlusion Aware Face Detector,0.711309,"In recent years, face detection algorithms based on deep learning have made
great progress. These algorithms can be generally divided into two categories,
i.e. two-stage detector like Faster R-CNN and one-stage detector like YOLO.
Because of the better balance between accuracy and speed, one-stage detectors
have been widely used in many applications. In this paper, we propose a
real-time face detector based on the one-stage detector YOLOv5, named
YOLO-FaceV2. We design a Receptive Field Enhancement module called RFE to
enhance receptive field of small face, and use NWD Loss to make up for the
sensitivity of IoU to the location deviation of tiny objects. For face
occlusion, we present an attention module named SEAM and introduce Repulsion
Loss to solve it. Moreover, we use a weight function Slide to solve the
imbalance between easy and hard samples and use the information of the
effective receptive field to design the anchor. The experimental results on
WiderFace dataset show that our face detector outperforms YOLO and its variants
can be find in all easy, medium and hard subsets. Source code in
https://github.com/Krasjet-Yu/YOLO-FaceV2",https://github.com/Krasjet-Yu/YOLO-FaceV2,-1
0d15c148-6afc-407c-ac86-564eed8693e9,Towards WinoQueer: Developing a Benchmark for Anti-Queer Bias in Large Language Models,0.667477,"This paper presents exploratory work on whether and to what extent biases
against queer and trans people are encoded in large language models (LLMs) such
as BERT. We also propose a method for reducing these biases in downstream
tasks: finetuning the models on data written by and/or about queer people. To
measure anti-queer bias, we introduce a new benchmark dataset, WinoQueer,
modeled after other bias-detection benchmarks but addressing homophobic and
transphobic biases. We found that BERT shows significant homophobic bias, but
this bias can be mostly mitigated by finetuning BERT on a natural language
corpus written by members of the LGBTQ+ community.",https://github.com/katyfelkner/,1371
72adcbdb-dc81-43cc-b9bb-e5967090718f,Discovering Salient Neurons in Deep NLP Models,0.393679,"While a lot of work has been done in understanding representations learned
within deep NLP models and what knowledge they capture, little attention has
been paid towards individual neurons. We present a technique called as
Linguistic Correlation Analysis to extract salient neurons in the model, with
respect to any extrinsic property - with the goal of understanding how such a
knowledge is preserved within neurons. We carry out a fine-grained analysis to
answer the following questions: (i) can we identify subsets of neurons in the
network that capture specific linguistic properties? (ii) how localized or
distributed neurons are across the network? iii) how redundantly is the
information preserved? iv) how fine-tuning pre-trained models towards
downstream NLP tasks, impacts the learned linguistic knowledge? iv) how do
architectures vary in learning different linguistic properties? Our
data-driven, quantitative analysis illuminates interesting findings: (i) we
found small subsets of neurons that can predict different linguistic tasks, ii)
with neurons capturing basic lexical information (such as suffixation)
localized in lower most layers, iii) while those learning complex concepts
(such as syntactic role) predominantly in middle and higher layers, iii) that
salient linguistic neurons are relocated from higher to lower layers during
transfer learning, as the network preserve the higher layers for task specific
information, iv) we found interesting differences across pre-trained models,
with respect to how linguistic information is preserved within, and v) we found
that concept exhibit similar neuron distribution across different languages in
the multilingual transformer models. Our code is publicly available as part of
the NeuroX toolkit.",None,-1
d99446e9-3e6a-4b20-81fe-9f061d385137,Temporal Attention for Language Models,0.680145,"Pretrained language models based on the transformer architecture have shown
great success in NLP. Textual training data often comes from the web and is
thus tagged with time-specific information, but most language models ignore
this information. They are trained on the textual data alone, limiting their
ability to generalize temporally. In this work, we extend the key component of
the transformer architecture, i.e., the self-attention mechanism, and propose
temporal attention - a time-aware self-attention mechanism. Temporal attention
can be applied to any transformer model and requires the input texts to be
accompanied with their relevant time points. It allows the transformer to
capture this temporal information and create time-specific contextualized word
representations. We leverage these representations for the task of semantic
change detection; we apply our proposed mechanism to BERT and experiment on
three datasets in different languages (English, German, and Latin) that also
vary in time, size, and genre. Our proposed model achieves state-of-the-art
results on all the datasets.",https://github.com/guyrosin/temporal_attention,-1
747b6464-720f-4e26-a34b-a43f23e527a6,Por Qué Não Utiliser Alla Språk? Mixed Training with Gradient Optimization in Few-Shot Cross-Lingual Transfer,0.419309,"The current state-of-the-art for few-shot cross-lingual transfer learning
first trains on abundant labeled data in the source language and then
fine-tunes with a few examples on the target language, termed target-adapting.
Though this has been demonstrated to work on a variety of tasks, in this paper
we show some deficiencies of this approach and propose a one-step mixed
training method that trains on both source and target data with
\textit{stochastic gradient surgery}, a novel gradient-level optimization.
Unlike the previous studies that focus on one language at a time when
target-adapting, we use one model to handle all target languages simultaneously
to avoid excessively language-specific models. Moreover, we discuss the
unreality of utilizing large target development sets for model selection in
previous literature. We further show that our method is both development-free
for target languages, and is also able to escape from overfitting issues. We
conduct a large-scale experiment on 4 diverse NLP tasks across up to 48
languages. Our proposed method achieves state-of-the-art performance on all
tasks and outperforms target-adapting by a large margin, especially for
languages that are linguistically distant from the source language, e.g., 7.36%
F1 absolute gain on average for the NER task, up to 17.60% on Punjabi.",https://github.com/fe1ixxu/Mixed-Gradient-Few-Shot,-1
abf13567-9500-417d-be71-d4a5f214e15c,KnowGL: Knowledge Generation and Linking from Text,0.635611,"We propose KnowGL, a tool that allows converting text into structured
relational data represented as a set of ABox assertions compliant with the TBox
of a given Knowledge Graph (KG), such as Wikidata. We address this problem as a
sequence generation task by leveraging pre-trained sequence-to-sequence
language models, e.g. BART. Given a sentence, we fine-tune such models to
detect pairs of entity mentions and jointly generate a set of facts consisting
of the full set of semantic annotations for a KG, such as entity labels, entity
types, and their relationships. To showcase the capabilities of our tool, we
build a web application consisting of a set of UI widgets that help users to
navigate through the semantic data extracted from a given input text. We make
the KnowGL model available at https://huggingface.co/ibm/knowgl-large.",None,-1
a07f3277-3d8d-4f89-8a42-5e33a20bd122,Explainable Verbal Deception Detection using Transformers,0.064352,"People are regularly confronted with potentially deceptive statements (e.g.,
fake news, misleading product reviews, or lies about activities). Only few
works on automated text-based deception detection have exploited the potential
of deep learning approaches. A critique of deep-learning methods is their lack
of interpretability, preventing us from understanding the underlying
(linguistic) mechanisms involved in deception. However, recent advancements
have made it possible to explain some aspects of such models. This paper
proposes and evaluates six deep-learning models, including combinations of BERT
(and RoBERTa), MultiHead Attention, co-attentions, and transformers. To
understand how the models reach their decisions, we then examine the model's
predictions with LIME. We then zoom in on vocabulary uniqueness and the
correlation of LIWC categories with the outcome class (truthful vs deceptive).
The findings suggest that our transformer-based models can enhance automated
deception detection performances (+2.11% in accuracy) and show significant
differences pertinent to the usage of LIWC features in truthful and deceptive
statements.",None,-1
242c1516-6d7a-4a96-8bd4-9234d78c95c4,The Inverse Problem for Argumentation Gradual Semantics,0.127226,"Gradual semantics with abstract argumentation provide each argument with a
score reflecting its acceptability, i.e. how ""much"" it is attacked by other
arguments. Many different gradual semantics have been proposed in the
literature, each following different principles and producing different
argument rankings. A sub-class of such semantics, the so-called weighted
semantics, takes, in addition to the graph structure, an initial set of weights
over the arguments as input, with these weights affecting the resultant
argument ranking. In this work, we consider the inverse problem over such
weighted semantics. That is, given an argumentation framework and a desired
argument ranking, we ask whether there exist initial weights such that a
particular semantics produces the given ranking. The contribution of this paper
are: (1) an algorithm to answer this problem, (2) a characterisation of the
properties that a gradual semantics must satisfy for the algorithm to operate,
and (3) an empirical evaluation of the proposed algorithm.",https://github.com/jhudsy/,4513
4d98b820-665e-42ef-b401-8760eaa81a63,rPPG-Toolbox: Deep Remote PPG Toolbox,0.746494,"Camera-based physiological measurement is a fast growing field of computer
vision. Remote photoplethysmography (rPPG) utilizes imaging devices (e.g.,
cameras) to measure the peripheral blood volume pulse (BVP) via
photoplethysmography, and enables cardiac measurement via webcams and
smartphones. However, the task is non-trivial with important pre-processing,
modeling, and post-processing steps required to obtain state-of-the-art
results. Replication of results and benchmarking of new models is critical for
scientific progress; however, as with many other applications of deep learning,
reliable codebases are not easy to find or use. We present a comprehensive
toolbox, rPPG-Toolbox, that contains unsupervised and supervised rPPG models
with support for public benchmark datasets, data augmentation, and systematic
evaluation: \url{https://github.com/ubicomplab/rPPG-Toolbox}",https://github.com/ubicomplab/rPPG-Toolbox,-1
aedfb829-3de8-4b76-8068-29e41ec57186,Face2Text revisited: Improved data set and baseline results,0.065329,"Current image description generation models do not transfer well to the task
of describing human faces. To encourage the development of more human-focused
descriptions, we developed a new data set of facial descriptions based on the
CelebA image data set. We describe the properties of this data set, and present
results from a face description generator trained on it, which explores the
feasibility of using transfer learning from VGGFace/ResNet CNNs. Comparisons
are drawn through both automated metrics and human evaluation by 76
English-speaking participants. The descriptions generated by the VGGFace-LSTM +
Attention model are closest to the ground truth according to human evaluation
whilst the ResNet-LSTM + Attention model obtained the highest CIDEr and CIDEr-D
results (1.252 and 0.686 respectively). Together, the new data set and these
experimental results provide data and baselines for future work in this area.",https://github.com/mtanti/face2text-dataset,-1
67584471-72f4-45b0-b639-e259b4877218,A device-interaction model for users with special needs,0.0283666,"Interaction is a fundamental part of using any computer system but it is
still an issue for people with special needs. In order to improve this
situation, this paper describes a new device-interaction model based on
adaptation rules for user models. The aim is the adaptation at the interaction
level, taking into account the interaction device features in order to improve
the usability through the user experience in the education sector. In the
evaluation process, several students from a special education center have
participated. These students have either a physical or sensory disability or
autism. The results are promising enough to consider that this model will be
able to help students with disabilities to interact with a computer system
which will inevitably provide tremendous benefits to their academic and
personal development.",None,-1
5fd3c144-fc1d-49bd-8a33-a21023f94cf8,Incorporating Rivalry in Reinforcement Learning for a Competitive Game,0.0236619,"Recent advances in reinforcement learning with social agents have allowed
such models to achieve human-level performance on specific interaction tasks.
However, most interactive scenarios do not have a version alone as an end goal;
instead, the social impact of these agents when interacting with humans is as
important and largely unexplored. In this regard, this work proposes a novel
reinforcement learning mechanism based on the social impact of rivalry
behavior. Our proposed model aggregates objective and social perception
mechanisms to derive a rivalry score that is used to modulate the learning of
artificial agents. To investigate our proposed model, we design an interactive
game scenario, using the Chef's Hat Card Game, and examine how the rivalry
modulation changes the agent's playing style, and how this impacts the
experience of human players in the game. Our results show that humans can
detect specific social characteristics when playing against rival agents when
compared to common agents, which directly affects the performance of the human
players in subsequent games. We conclude our work by discussing how the
different social and objective features that compose the artificial rivalry
score contribute to our results.",https://github.com/pablovin/ChefsHatGYM,-1
7e9e3095-30aa-434e-8d4d-f10c99b81868,Face segmentation: A comparison between visible and thermal images,0.158039,"Face segmentation is a first step for face biometric systems. In this paper
we present a face segmentation algorithm for thermographic images. This
algorithm is compared with the classic Viola and Jones algorithm used for
visible images. Experimental results reveal that, when segmenting a
multispectral (visible and thermal) face database, the proposed algorithm is
more than 10 times faster, while the accuracy of face segmentation in thermal
images is higher than in case of Viola-Jones",None,-1
8908128c-c437-4ac5-b8b0-ef7bc9205daa,Cross-Lingual Retrieval Augmented Prompt for Low-Resource Languages,0.652001,"Multilingual Pretrained Language Models (MPLMs) have shown their strong
multilinguality in recent empirical cross-lingual transfer studies. In this
paper, we propose the Prompts Augmented by Retrieval Crosslingually (PARC)
pipeline to improve the zero-shot performance on low-resource languages (LRLs)
by augmenting the context with semantically similar sentences retrieved from a
high-resource language (HRL) as prompts. PARC improves the zero-shot
performance on three downstream tasks (binary sentiment classification, topic
categorization and natural language inference) with multilingual parallel test
sets across 10 LRLs covering 6 language families in both unlabeled settings
(+5.1%) and labeled settings (+16.3%). PARC-labeled also outperforms the
finetuning baseline by 3.7%. We find a significant positive correlation between
cross-lingual transfer performance on one side, and the similarity between the
high- and low-resource languages as well as the amount of low-resource
pretraining data on the other side. A robustness analysis suggests that PARC
has the potential to achieve even stronger performance with more powerful
MPLMs.",https://github.com/ercong21/parc,-1
21686820-0fba-4d90-bf4a-b356417d98c7,A Dynamic Graph Interactive Framework with Label-Semantic Injection for Spoken Language Understanding,0.4308,"Multi-intent detection and slot filling joint models are gaining increasing
traction since they are closer to complicated real-world scenarios. However,
existing approaches (1) focus on identifying implicit correlations between
utterances and one-hot encoded labels in both tasks while ignoring explicit
label characteristics; (2) directly incorporate multi-intent information for
each token, which could lead to incorrect slot prediction due to the
introduction of irrelevant intent. In this paper, we propose a framework termed
DGIF, which first leverages the semantic information of labels to give the
model additional signals and enriched priors. Then, a multi-grain interactive
graph is constructed to model correlations between intents and slots.
Specifically, we propose a novel approach to construct the interactive graph
based on the injection of label semantics, which can automatically update the
graph to better alleviate error propagation. Experimental results show that our
framework significantly outperforms existing approaches, obtaining a relative
improvement of 13.7% over the previous best model on the MixATIS dataset in
overall accuracy.",https://github.com/Zhihong-Zhu/DGIF,7453
8a089697-91d4-4067-b71a-6414459f380d,"Enhancing the Robustness, Efficiency, and Diversity of Differentiable Architecture Search",0.0670341,"Differentiable architecture search (DARTS) has attracted much attention due
to its simplicity and significant improvement in efficiency. However, the
excessive accumulation of the skip connection makes it suffer from long-term
weak stability and low robustness. Many works attempt to restrict the
accumulation of skip connections by indicators or manual design, however, these
methods are susceptible to thresholds and human priors. In this work, we
suggest a more subtle and direct approach that removes skip connections from
the operation space. Then, by introducing an adaptive channel allocation
strategy, we redesign the DARTS framework to automatically refill the skip
connections in the evaluation stage, resolving the performance degradation
caused by the absence of skip connections. Our method, dubbed
Adaptive-Channel-Allocation-DARTS (ACA-DRATS), could eliminate the
inconsistency in operation strength and significantly expand the architecture
diversity. We continue to explore smaller search space under our framework, and
offer a direct search on the entire ImageNet dataset. Experiments show that
ACA-DRATS improves the search stability and significantly speeds up DARTS by
more than ten times while yielding higher accuracy.",None,-1
c9f41029-e672-4a76-84c9-1328e7c972c9,META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI,0.521167,"Task-oriented dialogue (TOD) systems have been widely used by mobile phone
intelligent assistants to accomplish tasks such as calendar scheduling or hotel
reservation. Current TOD systems usually focus on multi-turn text/speech
interaction, then they would call back-end APIs designed for TODs to perform
the task. However, this API-based architecture greatly limits the
information-searching capability of intelligent assistants and may even lead to
task failure if TOD-specific APIs are not available or the task is too
complicated to be executed by the provided APIs. In this paper, we propose a
new TOD architecture: GUI-based task-oriented dialogue system (GUI-TOD). A
GUI-TOD system can directly perform GUI operations on real APPs and execute
tasks without invoking TOD-specific backend APIs. Furthermore, we release
META-GUI, a dataset for training a Multi-modal convErsaTional Agent on mobile
GUI. We also propose a multi-model action prediction and response model, which
show promising results on META-GUI. The dataset, codes and leaderboard are
publicly available.",https://x-lance.github.io/,-1
91295552-1030-447d-994a-06fe5130432b,AutoField: Automating Feature Selection in Deep Recommender Systems,0.835652,"Feature quality has an impactful effect on recommendation performance.
Thereby, feature selection is a critical process in developing deep
learning-based recommender systems. Most existing deep recommender systems,
however, focus on designing sophisticated neural networks, while neglecting the
feature selection process. Typically, they just feed all possible features into
their proposed deep architectures, or select important features manually by
human experts. The former leads to non-trivial embedding parameters and extra
inference time, while the latter requires plenty of expert knowledge and human
labor effort. In this work, we propose an AutoML framework that can adaptively
select the essential feature fields in an automatic manner. Specifically, we
first design a differentiable controller network, which is capable of
automatically adjusting the probability of selecting a particular feature
field; then, only selected feature fields are utilized to retrain the deep
recommendation model. Extensive experiments on three benchmark datasets
demonstrate the effectiveness of our framework. We conduct further experiments
to investigate its properties, including the transferability, key components,
and parameter sensitivity.",https://github.com/rixwew/pytorch-fm,-1
a2e7baed-db4a-4af4-aa08-e21a7f12e233,Can domain adaptation make object recognition work for everyone?,0.295872,"Despite the rapid progress in deep visual recognition, modern computer vision
datasets significantly overrepresent the developed world and models trained on
such datasets underperform on images from unseen geographies. We investigate
the effectiveness of unsupervised domain adaptation (UDA) of such models across
geographies at closing this performance gap. To do so, we first curate two
shifts from existing datasets to study the Geographical DA problem, and
discover new challenges beyond data distribution shift: context shift, wherein
object surroundings may change significantly across geographies, and
subpopulation shift, wherein the intra-category distributions may shift. We
demonstrate the inefficacy of standard DA methods at Geographical DA,
highlighting the need for specialized geographical adaptation solutions to
address the challenge of making object recognition work for everyone.",None,-1
862e5f5f-d4ea-4845-98ec-8744228c81a3,Segmentation Enhanced Lameness Detection in Dairy Cows from RGB and Depth Video,0.54291,"Cow lameness is a severe condition that affects the life cycle and life
quality of dairy cows and results in considerable economic losses. Early
lameness detection helps farmers address illnesses early and avoid negative
effects caused by the degeneration of cows' condition. We collected a dataset
of short clips of cows passing through a hallway exiting a milking station and
annotated the degree of lameness of the cows. This paper explores the resulting
dataset and provides a detailed description of the data collection process.
Additionally, we proposed a lameness detection method that leverages
pre-trained neural networks to extract discriminative features from videos and
assign a binary score to each cow indicating its condition: ""healthy"" or
""lame."" We improve this approach by forcing the model to focus on the structure
of the cow, which we achieve by substituting the RGB videos with binary
segmentation masks predicted with a trained segmentation model. This work aims
to encourage research and provide insights into the applicability of computer
vision models for cow lameness detection on farms.",None,-1
bbc5b15f-9b3e-46a4-8d83-214c14b5226a,Learning from One and Only One Shot,0.0619988,"Humans can generalize from only a few examples and from little pre-training
on similar tasks. Yet, machine learning (ML) typically requires large data to
learn or pre-learn to transfer. Inspired by nativism, we directly model basic
human-innate priors in abstract visual tasks e.g., character/doodle
recognition. This yields a white-box model that learns general-appearance
similarity -- how any two images look in general -- by mimicking how humans
naturally ""distort"" an object at first sight. Using simply the nearest-neighbor
classifier on this similarity space, we achieve human-level character
recognition using only 1--10 examples per class and nothing else (no
pre-training). This differs from few-shot learning (FSL) using significant
pre-training. On standard benchmarks MNIST/EMNIST and the Omniglot challenge,
we outperform both neural-network-based and classical ML in the ""tiny-data""
regime, including FSL pre-trained on large data. Our model enables unsupervised
learning too: by learning the non-Euclidean, general-appearance similarity
space in a k-means style, we can generate human-intuitive archetypes as cluster
``centroids''.",None,-1
5d222704-2b99-42e4-b24a-30a32d544cc7,Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks,0.311146,"The field of Natural Language Processing has experienced a dramatic leap in
capabilities with the recent introduction of huge Language Models. Despite this
success, natural language problems that involve several compounded steps are
still practically unlearnable, even by the largest LMs. This complies with
experimental failures for end-to-end learning of composite problems that were
demonstrated in a variety of domains. An effective mitigation is to introduce
intermediate supervision for solving sub-tasks of the compounded problem.
Recently, several works have demonstrated high gains by taking a
straightforward approach for incorporating intermediate supervision in
compounded natural language problems: the sequence-to-sequence LM is fed with
an augmented input, in which the decomposed tasks' labels are simply
concatenated to the original input. In this paper, we prove a positive learning
result that motivates these recent efforts. We show that when concatenating
intermediate supervision to the input and training a sequence-to-sequence model
on this modified input, unlearnable composite problems can become learnable. We
show that this is true for any family of tasks which on the one hand, are
unlearnable, and on the other hand, can be decomposed into a polynomial number
of simple sub-tasks, each of which depends only on O(1) previous sub-task
results. Beyond motivating contemporary empirical efforts for incorporating
intermediate supervision in sequence-to-sequence language models, our positive
theoretical result is the first of its kind in the landscape of results on the
benefits of intermediate supervision for neural-network learning: Until now,
all theoretical results on the subject are negative, i.e., show cases where
learning is impossible without intermediate supervision, while our result is
positive, showing that learning is facilitated in the presence of intermediate
supervision.",None,-1
1d489cc5-a1cb-403c-9abc-6634dd9e4530,Human-Like Navigation Behavior: A Statistical Evaluation Framework,0.0397087,"Recent advancements in deep reinforcement learning have brought forth an
impressive display of highly skilled artificial agents capable of complex
intelligent behavior. In video games, these artificial agents are increasingly
deployed as non-playable characters (NPCs) designed to enhance the experience
of human players. However, while it has been shown that the convincing
human-like behavior of NPCs leads to increased engagement in video games, the
believability of an artificial agent's behavior is most often measured solely
by its proficiency at a given task. Recent work has hinted that proficiency
alone is not sufficient to discern human-like behavior. Motivated by this, we
build a non-parametric two-sample hypothesis test designed to compare the
behaviors of artificial agents to those of human players. We show that the
resulting $p$-value not only aligns with anonymous human judgment of human-like
behavior, but also that it can be used as a measure of similarity.",None,-1
981d037e-b225-42b9-afa0-2e25f6bac308,Nonparametric Masked Language Modeling,0.768225,"Existing language models (LMs) predict tokens with a softmax over a finite
vocabulary, which can make it difficult to predict rare tokens or phrases. We
introduce NPM, the first nonparametric masked language model that replaces this
softmax with a nonparametric distribution over every phrase in a reference
corpus. NPM fills in the [MASK] solely from retrieving a token from a text
corpus. We show that NPM can be efficiently trained with a contrastive
objective and an in-batch approximation to full corpus retrieval. Zero-shot
evaluation on 16 tasks including classification, fact probing and question
answering demonstrates that NPM outperforms significantly larger parametric
models, either with or without a retrieve-and-generate approach. It is
particularly better at dealing with rare patterns (word senses or facts) and
predicting rare or nearly unseen words (e.g., non-Latin script). We release the
model and code at github.com/facebookresearch/NPM.",https://github.com/facebookresearch/NPM,-1
d6f2667d-bc5b-43c3-b949-d138aab1d8bf,NumGLUE: A Suite of Fundamental yet Challenging Mathematical Reasoning Tasks,0.849796,"Given the ubiquitous nature of numbers in text, reasoning with numbers to
perform simple calculations is an important skill of AI systems. While many
datasets and models have been developed to this end, state-of-the-art AI
systems are brittle; failing to perform the underlying mathematical reasoning
when they appear in a slightly different scenario. Drawing inspiration from
GLUE that was proposed in the context of natural language understanding, we
propose NumGLUE, a multi-task benchmark that evaluates the performance of AI
systems on eight different tasks, that at their core require simple arithmetic
understanding. We show that this benchmark is far from being solved with neural
models including state-of-the-art large-scale language models performing
significantly worse than humans (lower by 46.4%). Further, NumGLUE promotes
sharing knowledge across tasks, especially those with limited training data as
evidenced by the superior performance (average gain of 3.4% on each task) when
a model is jointly trained on all the tasks as opposed to task-specific
modeling. Finally, we hope that NumGLUE will encourage systems that perform
robust and general arithmetic reasoning within language, a first step towards
being able to perform more complex mathematical reasoning.",None,-1
96541ecf-0c47-4164-81a9-ba08846eabea,A new band selection approach based on information theory and support vector machine for hyperspectral images reduction and classification,0.278905,"The high dimensionality of hyperspectral images consisting of several bands
often imposes a big computational challenge for image processing. Therefore,
spectral band selection is an essential step for removing the irrelevant, noisy
and redundant bands. Consequently increasing the classification accuracy.
However, identification of useful bands from hundreds or even thousands of
related bands is a nontrivial task. This paper aims at identifying a small set
of highly discriminative bands, for improving computational speed and
prediction accuracy. Hence, we proposed a new strategy based on joint mutual
information to measure the statistical dependence and correlation between the
selected bands and evaluate the relative utility of each one to classification.
The proposed filter approach is compared to an effective reproduced filters
based on mutual information. Simulations results on the hyperpectral image HSI
AVIRIS 92AV3C using the SVM classifier have shown that the effective proposed
algorithm outperforms the reproduced filters strategy performance.
  Keywords-Hyperspectral images, Classification, band Selection, Joint Mutual
Information, dimensionality reduction ,correlation, SVM.",None,-1
f68b0cc0-aa94-4ff5-86cb-6f8c5daeff80,RoPGen: Towards Robust Code Authorship Attribution via Automatic Coding Style Transformation,0.9463,"Source code authorship attribution is an important problem often encountered
in applications such as software forensics, bug fixing, and software quality
analysis. Recent studies show that current source code authorship attribution
methods can be compromised by attackers exploiting adversarial examples and
coding style manipulation. This calls for robust solutions to the problem of
code authorship attribution. In this paper, we initiate the study on making
Deep Learning (DL)-based code authorship attribution robust. We propose an
innovative framework called Robust coding style Patterns Generation (RoPGen),
which essentially learns authors' unique coding style patterns that are hard
for attackers to manipulate or imitate. The key idea is to combine data
augmentation and gradient augmentation at the adversarial training phase. This
effectively increases the diversity of training examples, generates meaningful
perturbations to gradients of deep neural networks, and learns diversified
representations of coding styles. We evaluate the effectiveness of RoPGen using
four datasets of programs written in C, C++, and Java. Experimental results
show that RoPGen can significantly improve the robustness of DL-based code
authorship attribution, by respectively reducing 22.8% and 41.0% of the success
rate of targeted and untargeted attacks on average.",https://github.com/RoPGen/RoPGen,-1
cae98d09-5991-4769-8850-b16c911d449f,Dialogue Strategy Adaptation to New Action Sets Using Multi-dimensional Modelling,0.316139,"A major bottleneck for building statistical spoken dialogue systems for new
domains and applications is the need for large amounts of training data. To
address this problem, we adopt the multi-dimensional approach to dialogue
management and evaluate its potential for transfer learning. Specifically, we
exploit pre-trained task-independent policies to speed up training for an
extended task-specific action set, in which the single summary action for
requesting a slot is replaced by multiple slot-specific request actions. Policy
optimisation and evaluation experiments using an agenda-based user simulator
show that with limited training data, much better performance levels can be
achieved when using the proposed multi-dimensional adaptation method. We
confirm this improvement in a crowd-sourced human user evaluation of our spoken
dialogue system, comparing partially trained policies. The multi-dimensional
system (with adaptation on limited training data in the target scenario)
outperforms the one-dimensional baseline (without adaptation on the same amount
of training data) by 7% perceived success rate.",None,-1
d66f855e-19f2-47d2-a6be-253ff11a58c1,MEKER: Memory Efficient Knowledge Embedding Representation for Link Prediction and Question Answering,0.398163,"Knowledge Graphs (KGs) are symbolically structured storages of facts. The KG
embedding contains concise data used in NLP tasks requiring implicit
information about the real world. Furthermore, the size of KGs that may be
useful in actual NLP assignments is enormous, and creating embedding over it
has memory cost issues. We represent KG as a 3rd-order binary tensor and move
beyond the standard CP decomposition by using a data-specific generalized
version of it. The generalization of the standard CP-ALS algorithm allows
obtaining optimization gradients without a backpropagation mechanism. It
reduces the memory needed in training while providing computational benefits.
We propose a MEKER, a memory-efficient KG embedding model, which yields
SOTA-comparable performance on link prediction tasks and KG-based Question
Answering.",https://github.com/askplatypus/wikidata-simplequestions,-1
96e4bf7e-6e41-4455-8747-9d5e8026c4b0,SEMI-FND: Stacked Ensemble Based Multimodal Inference For Faster Fake News Detection,0.541593,"Fake News Detection (FND) is an essential field in natural language
processing that aims to identify and check the truthfulness of major claims in
a news article to decide the news veracity. FND finds its uses in preventing
social, political and national damage caused due to misrepresentation of facts
which may harm a certain section of society. Further, with the explosive rise
in fake news dissemination over social media, including images and text, it has
become imperative to identify fake news faster and more accurately. To solve
this problem, this work investigates a novel multimodal stacked ensemble-based
approach (SEMIFND) to fake news detection. Focus is also kept on ensuring
faster performance with fewer parameters. Moreover, to improve multimodal
performance, a deep unimodal analysis is done on the image modality to identify
NasNet Mobile as the most appropriate model for the task. For text, an ensemble
of BERT and ELECTRA is used. The approach was evaluated on two datasets:
Twitter MediaEval and Weibo Corpus. The suggested framework offered accuracies
of 85.80% and 86.83% on the Twitter and Weibo datasets respectively. These
reported metrics are found to be superior when compared to similar recent
works. Further, we also report a reduction in the number of parameters used in
training when compared to recent relevant works. SEMI-FND offers an overall
parameter reduction of at least 20% with unimodal parametric reduction on text
being 60%. Therefore, based on the investigations presented, it is concluded
that the application of a stacked ensembling significantly improves FND over
other approaches while also improving speed.",None,-1
eb21ee74-bb89-4509-84cb-ae24e8c439d9,Bangla-Wave: Improving Bangla Automatic Speech Recognition Utilizing N-gram Language Models,0.462242,"Although over 300M around the world speak Bangla, scant work has been done in
improving Bangla voice-to-text transcription due to Bangla being a low-resource
language. However, with the introduction of the Bengali Common Voice 9.0 speech
dataset, Automatic Speech Recognition (ASR) models can now be significantly
improved. With 399hrs of speech recordings, Bengali Common Voice is the largest
and most diversified open-source Bengali speech corpus in the world. In this
paper, we outperform the SOTA pretrained Bengali ASR models by finetuning a
pretrained wav2vec2 model on the common voice dataset. We also demonstrate how
to significantly improve the performance of an ASR model by adding an n-gram
language model as a post-processor. Finally, we do some experiments and
hyperparameter tuning to generate a robust Bangla ASR model that is better than
the existing ASR models.",None,-1
087cb799-4822-44a6-b170-c242d5138b28,"An Exploratory Study of Tweets about the SARS-CoV-2 Omicron Variant: Insights from Sentiment Analysis, Language Interpretation, Source Tracking, Type Classification, and Embedded URL Detection",0.98796,"This paper presents the findings of an exploratory study on the continuously
generating Big Data on Twitter related to the sharing of information, news,
views, opinions, ideas, feedback, and experiences about the COVID-19 pandemic,
with a specific focus on the Omicron variant, which is the globally dominant
variant of SARS-CoV-2 at this time. A total of 12028 tweets about the Omicron
variant were studied, and the specific characteristics of tweets that were
analyzed include - sentiment, language, source, type, and embedded URLs. The
findings of this study are manifold. First, from sentiment analysis, it was
observed that 50.5% of tweets had a neutral emotion. The other emotions - bad,
good, terrible, and great were found in 15.6%, 14.0%, 12.5%, and 7.5% of the
tweets, respectively. Second, the findings of language interpretation showed
that 65.9% of the tweets were posted in English. It was followed by Spanish,
French, Italian, and other languages. Third, the findings from source tracking
showed that Twitter for Android was associated with 35.2% of tweets. It was
followed by Twitter Web App, Twitter for iPhone, Twitter for iPad, and other
sources. Fourth, studying the type of tweets revealed that retweets accounted
for 60.8% of the tweets, it was followed by original tweets and replies that
accounted for 19.8% and 19.4% of the tweets, respectively. Fifth, in terms of
embedded URL analysis, the most common domain embedded in the tweets was found
to be twitter.com, which was followed by biorxiv.org, nature.com, and other
domains. Finally, to support similar research in this field, we have developed
a Twitter dataset that comprises more than 500,000 tweets about the SARS-CoV-2
omicron variant since the first detected case of this variant on November 24,
2021.",None,-1
825381b4-9166-4171-b5f7-00abb81c6d9c,AUC Maximization for Low-Resource Named Entity Recognition,0.34534,"Current work in named entity recognition (NER) uses either cross entropy (CE)
or conditional random fields (CRF) as the objective/loss functions to optimize
the underlying NER model. Both of these traditional objective functions for the
NER problem generally produce adequate performance when the data distribution
is balanced and there are sufficient annotated training examples. But since NER
is inherently an imbalanced tagging problem, the model performance under the
low-resource settings could suffer using these standard objective functions.
Based on recent advances in area under the ROC curve (AUC) maximization, we
propose to optimize the NER model by maximizing the AUC score. We give evidence
that by simply combining two binary-classifiers that maximize the AUC score,
significant performance improvement over traditional loss functions is achieved
under low-resource NER settings. We also conduct extensive experiments to
demonstrate the advantages of our method under the low-resource and
highly-imbalanced data distribution settings. To the best of our knowledge,
this is the first work that brings AUC maximization to the NER setting.
Furthermore, we show that our method is agnostic to different types of NER
embeddings, models and domains. The code to replicate this work will be
provided upon request.",https://github.com/dngu0061/NER-AUC-2T,-1
2d29d91f-6299-4c06-8c83-6e15a700030f,Pyramid Frequency Network with Spatial Attention Residual Refinement Module for Monocular Depth Estimation,0.449916,"Deep-learning-based approaches to depth estimation are rapidly advancing,
offering superior performance over existing methods. To estimate the depth in
real-world scenarios, depth estimation models require the robustness of various
noise environments. In this work, a Pyramid Frequency Network(PFN) with Spatial
Attention Residual Refinement Module(SARRM) is proposed to deal with the weak
robustness of existing deep-learning methods. To reconstruct depth maps with
accurate details, the SARRM constructs a residual fusion method with an
attention mechanism to refine the blur depth. The frequency division strategy
is designed, and the frequency pyramid network is developed to extract features
from multiple frequency bands. With the frequency strategy, PFN achieves better
visual accuracy than state-of-the-art methods in both indoor and outdoor scenes
on Make3D, KITTI depth, and NYUv2 datasets. Additional experiments on the noisy
NYUv2 dataset demonstrate that PFN is more reliable than existing deep-learning
methods in high-noise scenes.",None,-1
3f9b1714-323c-4f4f-ae34-97fbba49f5a9,FvOR: Robust Joint Shape and Pose Optimization for Few-view Object Reconstruction,0.816554,"Reconstructing an accurate 3D object model from a few image observations
remains a challenging problem in computer vision. State-of-the-art approaches
typically assume accurate camera poses as input, which could be difficult to
obtain in realistic settings. In this paper, we present FvOR, a learning-based
object reconstruction method that predicts accurate 3D models given a few
images with noisy input poses. The core of our approach is a fast and robust
multi-view reconstruction algorithm to jointly refine 3D geometry and camera
pose estimation using learnable neural network modules. We provide a thorough
benchmark of state-of-the-art approaches for this problem on ShapeNet. Our
approach achieves best-in-class results. It is also two orders of magnitude
faster than the recent optimization-based approach IDR. Our code is released at
\url{https://github.com/zhenpeiyang/FvOR/}",https://github.com/zhenpeiyang/FvOR/,-1
c3d5513c-a367-4928-adc3-3369abd39783,Draw Your Art Dream: Diverse Digital Art Synthesis with Multimodal Guided Diffusion,0.877174,"Digital art synthesis is receiving increasing attention in the multimedia
community because of engaging the public with art effectively. Current digital
art synthesis methods usually use single-modality inputs as guidance, thereby
limiting the expressiveness of the model and the diversity of generated
results. To solve this problem, we propose the multimodal guided artwork
diffusion (MGAD) model, which is a diffusion-based digital artwork generation
approach that utilizes multimodal prompts as guidance to control the
classifier-free diffusion model. Additionally, the contrastive language-image
pretraining (CLIP) model is used to unify text and image modalities. Extensive
experimental results on the quality and quantity of the generated digital art
paintings confirm the effectiveness of the combination of the diffusion model
and multimodal guidance. Code is available at
https://github.com/haha-lisa/MGAD-multimodal-guided-artwork-diffusion.",https://github.com/haha-lisa/MGAD-multimodal-guided-artwork-diffusion,-1
c38fb8bd-d862-4620-b398-db9fe2469d14,DuAT: Dual-Aggregation Transformer Network for Medical Image Segmentation,0.802303,"Transformer-based models have been widely demonstrated to be successful in
computer vision tasks by modelling long-range dependencies and capturing global
representations. However, they are often dominated by features of large
patterns leading to the loss of local details (e.g., boundaries and small
objects), which are critical in medical image segmentation. To alleviate this
problem, we propose a Dual-Aggregation Transformer Network called DuAT, which
is characterized by two innovative designs, namely, the Global-to-Local Spatial
Aggregation (GLSA) and Selective Boundary Aggregation (SBA) modules. The GLSA
has the ability to aggregate and represent both global and local spatial
features, which are beneficial for locating large and small objects,
respectively. The SBA module is used to aggregate the boundary characteristic
from low-level features and semantic information from high-level features for
better preserving boundary details and locating the re-calibration objects.
Extensive experiments in six benchmark datasets demonstrate that our proposed
model outperforms state-of-the-art methods in the segmentation of skin lesion
images, and polyps in colonoscopy images. In addition, our approach is more
robust than existing methods in various challenging situations such as small
object segmentation and ambiguous object boundaries.",None,-1
2e8260ca-3e0e-4127-978f-87da222e47da,Fine-grained Semantic Alignment Network for Weakly Supervised Temporal Language Grounding,0.573411,"Temporal language grounding (TLG) aims to localize a video segment in an
untrimmed video based on a natural language description. To alleviate the
expensive cost of manual annotations for temporal boundary labels, we are
dedicated to the weakly supervised setting, where only video-level descriptions
are provided for training. Most of the existing weakly supervised methods
generate a candidate segment set and learn cross-modal alignment through a
MIL-based framework. However, the temporal structure of the video as well as
the complicated semantics in the sentence are lost during the learning. In this
work, we propose a novel candidate-free framework: Fine-grained Semantic
Alignment Network (FSAN), for weakly supervised TLG. Instead of view the
sentence and candidate moments as a whole, FSAN learns token-by-clip
cross-modal semantic alignment by an iterative cross-modal interaction module,
generates a fine-grained cross-modal semantic alignment map, and performs
grounding directly on top of the map. Extensive experiments are conducted on
two widely-used benchmarks: ActivityNet-Captions, and DiDeMo, where our FSAN
achieves state-of-the-art performance.",None,-1
0c0ee7f5-64c8-45c4-9da4-69894eb1d3e5,Does Simultaneous Speech Translation need Simultaneous Models?,0.793159,"In simultaneous speech translation (SimulST), finding the best trade-off
between high translation quality and low latency is a challenging task. To meet
the latency constraints posed by the different application scenarios, multiple
dedicated SimulST models are usually trained and maintained, generating high
computational costs. In this paper, motivated by the increased social and
environmental impact caused by these costs, we investigate whether a single
model trained offline can serve not only the offline but also the simultaneous
task without the need for any additional training or adaptation. Experiments on
en->{de, es} indicate that, aside from facilitating the adoption of
well-established offline techniques and architectures without affecting
latency, the offline solution achieves similar or better translation quality
compared to the same model trained in simultaneous settings, as well as being
competitive with the SimulST state of the art.",https://github.com/hlt-mt/,9038
eadbc875-ebef-4dc6-8b40-918f8c9056db,The Case for Perspective in Multimodal Datasets,0.0441681,"This paper argues in favor of the adoption of annotation practices for
multimodal datasets that recognize and represent the inherently perspectivized
nature of multimodal communication. To support our claim, we present a set of
annotation experiments in which FrameNet annotation is applied to the Multi30k
and the Flickr 30k Entities datasets. We assess the cosine similarity between
the semantic representations derived from the annotation of both pictures and
captions for frames. Our findings indicate that: (i) frame semantic similarity
between captions of the same picture produced in different languages is
sensitive to whether the caption is a translation of another caption or not,
and (ii) picture annotation for semantic frames is sensitive to whether the
image is annotated in presence of a caption or not.",None,-1
2e5fba52-cba9-43f5-91b5-231ae7ff3f84,DKM: Dense Kernelized Feature Matching for Geometry Estimation,0.655523,"Feature matching is a challenging computer vision task that involves finding
correspondences between two images of a 3D scene. In this paper we consider the
dense approach instead of the more common sparse paradigm, thus striving to
find all correspondences. Perhaps counter-intuitively, dense methods have
previously shown inferior performance to their sparse and semi-sparse
counterparts for estimation of two-view geometry. This changes with our novel
dense method, which outperforms both dense and sparse methods on geometry
estimation. The novelty is threefold: First, we propose a kernel regression
global matcher. Secondly, we propose warp refinement through stacked feature
maps and depthwise convolution kernels. Thirdly, we propose learning dense
confidence through consistent depth and a balanced sampling approach for dense
confidence maps. Through extensive experiments we confirm that our proposed
dense method, \textbf{D}ense \textbf{K}ernelized Feature \textbf{M}atching,
sets a new state-of-the-art on multiple geometry estimation benchmarks. In
particular, we achieve an improvement on MegaDepth-1500 of +4.9 and +8.9
AUC$@5^{\circ}$ compared to the best previous sparse method and dense method
respectively. Our code is provided at https://github.com/Parskatt/dkm",https://github.com/Parskatt/dkm,29085
ff9d5096-3f50-4475-b1b3-fbc61bcc546a,Multiple Object Tracking from appearance by hierarchically clustering tracklets,0.435813,"Current approaches in Multiple Object Tracking (MOT) rely on the
spatio-temporal coherence between detections combined with object appearance to
match objects from consecutive frames. In this work, we explore MOT using
object appearances as the main source of association between objects in a
video, using spatial and temporal priors as weighting factors. We form initial
tracklets by leveraging on the idea that instances of an object that are close
in time should be similar in appearance, and build the final object tracks by
fusing the tracklets in a hierarchical fashion. We conduct extensive
experiments that show the effectiveness of our method over three different MOT
benchmarks, MOT17, MOT20, and DanceTrack, being competitive in MOT17 and MOT20
and establishing state-of-the-art results in DanceTrack.",https://github.com/NII-Satoh-Lab/MOT_FCG,-1
974bd629-3288-440f-8615-f636409e4c4f,Visual Concepts Tokenization,0.304596,"Obtaining the human-like perception ability of abstracting visual concepts
from concrete pixels has always been a fundamental and important target in
machine learning research fields such as disentangled representation learning
and scene decomposition. Towards this goal, we propose an unsupervised
transformer-based Visual Concepts Tokenization framework, dubbed VCT, to
perceive an image into a set of disentangled visual concept tokens, with each
concept token responding to one type of independent visual concept.
Particularly, to obtain these concept tokens, we only use cross-attention to
extract visual information from the image tokens layer by layer without
self-attention between concept tokens, preventing information leakage across
concept tokens. We further propose a Concept Disentangling Loss to facilitate
that different concept tokens represent independent visual concepts. The
cross-attention and disentangling loss play the role of induction and mutual
exclusion for the concept tokens, respectively. Extensive experiments on
several popular datasets verify the effectiveness of VCT on the tasks of
disentangled representation learning and scene decomposition. VCT achieves the
state of the art results by a large margin.",https://github.com/thomasmry/VCT,-1
c8bc9da7-d1e9-41dd-bf9f-670527a82205,Selecting and combining complementary feature representations and classifiers for hate speech detection,0.504499,"Hate speech is a major issue in social networks due to the high volume of
data generated daily. Recent works demonstrate the usefulness of machine
learning (ML) in dealing with the nuances required to distinguish between
hateful posts from just sarcasm or offensive language. Many ML solutions for
hate speech detection have been proposed by either changing how features are
extracted from the text or the classification algorithm employed. However, most
works consider only one type of feature extraction and classification
algorithm. This work argues that a combination of multiple feature extraction
techniques and different classification models is needed. We propose a
framework to analyze the relationship between multiple feature extraction and
classification techniques to understand how they complement each other. The
framework is used to select a subset of complementary techniques to compose a
robust multiple classifiers system (MCS) for hate speech detection. The
experimental study considering four hate speech classification datasets
demonstrates that the proposed framework is a promising methodology for
analyzing and designing high-performing MCS for this task. MCS system obtained
using the proposed framework significantly outperforms the combination of all
models and the homogeneous and heterogeneous selection heuristics,
demonstrating the importance of having a proper selection scheme. Source code,
figures, and dataset splits can be found in the GitHub repository:
https://github.com/Menelau/Hate-Speech-MCS.",https://github.com/Menelau/Hate-Speech-MCS,-1
58511f1d-120d-46bb-88e5-14f05ccaa7e0,End-to-end Document Recognition and Understanding with Dessurt,0.936588,"We introduce Dessurt, a relatively simple document understanding transformer
capable of being fine-tuned on a greater variety of document tasks than prior
methods. It receives a document image and task string as input and generates
arbitrary text autoregressively as output. Because Dessurt is an end-to-end
architecture that performs text recognition in addition to the document
understanding, it does not require an external recognition model as prior
methods do. Dessurt is a more flexible model than prior methods and is able to
handle a variety of document domains and tasks. We show that this model is
effective at 9 different dataset-task combinations.",https://github.com/herobd/dessurt2,-1
7041b816-5d2e-43fe-973c-6568bbd23abc,OPERA:Operation-Pivoted Discrete Reasoning over Text,0.201351,"Machine reading comprehension (MRC) that requires discrete reasoning
involving symbolic operations, e.g., addition, sorting, and counting, is a
challenging task. According to this nature, semantic parsing-based methods
predict interpretable but complex logical forms. However, logical form
generation is nontrivial and even a little perturbation in a logical form will
lead to wrong answers. To alleviate this issue, multi-predictor -based methods
are proposed to directly predict different types of answers and achieve
improvements. However, they ignore the utilization of symbolic operations and
encounter a lack of reasoning ability and interpretability. To inherit the
advantages of these two types of methods, we propose OPERA, an
operation-pivoted discrete reasoning framework, where lightweight symbolic
operations (compared with logical forms) as neural modules are utilized to
facilitate the reasoning ability and interpretability. Specifically, operations
are first selected and then softly executed to simulate the answer reasoning
procedure. Extensive experiments on both DROP and RACENum datasets show the
reasoning ability of OPERA. Moreover, further analysis verifies its
interpretability.",https://github.com/JD-AI-Research-NLP/OPERA,-1
2af96e8d-02a9-4bd7-a856-cfe4c08fc47b,Few-shot Learning with Noisy Labels,0.898638,"Few-shot learning (FSL) methods typically assume clean support sets with
accurately labeled samples when training on novel classes. This assumption can
often be unrealistic: support sets, no matter how small, can still include
mislabeled samples. Robustness to label noise is therefore essential for FSL
methods to be practical, but this problem surprisingly remains largely
unexplored. To address mislabeled samples in FSL settings, we make several
technical contributions. (1) We offer simple, yet effective, feature
aggregation methods, improving the prototypes used by ProtoNet, a popular FSL
technique. (2) We describe a novel Transformer model for Noisy Few-Shot
Learning (TraNFS). TraNFS leverages a transformer's attention mechanism to
weigh mislabeled versus correct samples. (3) Finally, we extensively test these
methods on noisy versions of MiniImageNet and TieredImageNet. Our results show
that TraNFS is on-par with leading FSL methods on clean support sets, yet
outperforms them, by far, in the presence of label noise.",None,16626
5b23eeff-5a27-402a-87c8-2125d926a5d4,UniGeo: Unifying Geometry Logical Reasoning via Reformulating Mathematical Expression,0.370562,"Geometry problem solving is a well-recognized testbed for evaluating the
high-level multi-modal reasoning capability of deep models. In most existing
works, two main geometry problems: calculation and proving, are usually treated
as two specific tasks, hindering a deep model to unify its reasoning capability
on multiple math tasks. However, in essence, these two tasks have similar
problem representations and overlapped math knowledge which can improve the
understanding and reasoning ability of a deep model on both two tasks.
Therefore, we construct a large-scale Unified Geometry problem benchmark,
UniGeo, which contains 4,998 calculation problems and 9,543 proving problems.
Each proving problem is annotated with a multi-step proof with reasons and
mathematical expressions. The proof can be easily reformulated as a proving
sequence that shares the same formats with the annotated program sequence for
calculation problems. Naturally, we also present a unified multi-task Geometric
Transformer framework, Geoformer, to tackle calculation and proving problems
simultaneously in the form of sequence generation, which finally shows the
reasoning ability can be improved on both two tasks by unifying formulation.
Furthermore, we propose a Mathematical Expression Pretraining (MEP) method that
aims to predict the mathematical expressions in the problem solution, thus
improving the Geoformer model. Experiments on the UniGeo demonstrate that our
proposed Geoformer obtains state-of-the-art performance by outperforming
task-specific model NGS with over 5.6% and 3.2% accuracies on calculation and
proving problems, respectively.",https://github.com/chen-judge/UniGeo,-1
fd87baf5-b7e0-42ed-8dde-f4ec5a465ebb,Meta-Ensemble Parameter Learning,0.248523,"Ensemble of machine learning models yields improved performance as well as
robustness. However, their memory requirements and inference costs can be
prohibitively high. Knowledge distillation is an approach that allows a single
model to efficiently capture the approximate performance of an ensemble while
showing poor scalability as demand for re-training when introducing new teacher
models. In this paper, we study if we can utilize the meta-learning strategy to
directly predict the parameters of a single model with comparable performance
of an ensemble. Hereto, we introduce WeightFormer, a Transformer-based model
that can predict student network weights layer by layer in a forward pass,
according to the teacher model parameters. The proprieties of WeightFormer are
investigated on the CIFAR-10, CIFAR-100, and ImageNet datasets for model
structures of VGGNet-11, ResNet-50, and ViT-B/32, where it demonstrates that
our method can achieve approximate classification performance of an ensemble
and outperforms both the single network and standard knowledge distillation.
More encouragingly, we show that WeightFormer results can further exceeds
average ensemble with minor fine-tuning. Importantly, our task along with the
model and results can potentially lead to a new, more efficient, and scalable
paradigm of ensemble networks parameter learning.",https://github.com/mlfoundations/model-soups,-1
0dd78bcb-1eae-48dd-a9a1-d87a94a944fc,On three types of $L$-fuzzy $β$-covering-based rough sets,0.372911,"In this paper, we mainly construct three types of $L$-fuzzy
$\beta$-covering-based rough set models and study the axiom sets, matrix
representations and interdependency of these three pairs of $L$-fuzzy
$\beta$-covering-based rough approximation operators. Firstly, we propose three
pairs of $L$-fuzzy $\beta$-covering-based rough approximation operators by
introducing the concepts such as $\beta$-degree of intersection and
$\beta$-subsethood degree, which are generalizations of degree of intersection
and subsethood degree, respectively. And then, the axiom set for each of these
$L$-fuzzy $\beta$-covering-based rough approximation operator is investigated.
Thirdly, we give the matrix representations of three types of $L$-fuzzy
$\beta$-covering-based rough approximation operators, which make it valid to
calculate the $L$-fuzzy $\beta$-covering-based lower and upper rough
approximation operators through operations on matrices. Finally, the
interdependency of the three pairs of rough approximation operators based on
$L$-fuzzy $\beta$-covering is studied by using the notion of reducible elements
and independent elements. In other words, we present the necessary and
sufficient conditions under which two $L$-fuzzy $\beta$-coverings can generate
the same lower and upper rough approximation operations.",None,7646
68d1d45f-9384-4713-8d77-3a54f2ebb9fa,SWEM: Towards Real-Time Video Object Segmentation with Sequential Weighted Expectation-Maximization,0.650821,"Matching-based methods, especially those based on space-time memory, are
significantly ahead of other solutions in semi-supervised video object
segmentation (VOS). However, continuously growing and redundant template
features lead to an inefficient inference. To alleviate this, we propose a
novel Sequential Weighted Expectation-Maximization (SWEM) network to greatly
reduce the redundancy of memory features. Different from the previous methods
which only detect feature redundancy between frames, SWEM merges both
intra-frame and inter-frame similar features by leveraging the sequential
weighted EM algorithm. Further, adaptive weights for frame features endow SWEM
with the flexibility to represent hard samples, improving the discrimination of
templates. Besides, the proposed method maintains a fixed number of template
features in memory, which ensures the stable inference complexity of the VOS
system. Extensive experiments on commonly used DAVIS and YouTube-VOS datasets
verify the high efficiency (36 FPS) and high performance (84.3\%
$\mathcal{J}\&\mathcal{F}$ on DAVIS 2017 validation dataset) of SWEM. Code is
available at: https://github.com/lmm077/SWEM.",https://github.com/lmm077/SWEM,-1
644b1032-b809-43d8-995f-a9c559f742b4,Are GAN-based Morphs Threatening Face Recognition?,0.716655,"Morphing attacks are a threat to biometric systems where the biometric
reference in an identity document can be altered. This form of attack presents
an important issue in applications relying on identity documents such as border
security or access control. Research in generation of face morphs and their
detection is developing rapidly, however very few datasets with morphing
attacks and open-source detection toolkits are publicly available. This paper
bridges this gap by providing two datasets and the corresponding code for four
types of morphing attacks: two that rely on facial landmarks based on OpenCV
and FaceMorpher, and two that use StyleGAN 2 to generate synthetic morphs. We
also conduct extensive experiments to assess the vulnerability of four
state-of-the-art face recognition systems, including FaceNet, VGG-Face,
ArcFace, and ISV. Surprisingly, the experiments demonstrate that, although
visually more appealing, morphs based on StyleGAN 2 do not pose a significant
threat to the state to face recognition systems, as these morphs were
outmatched by the simple morphs that are based facial landmarks.",None,-1
70e10440-5312-4e68-916c-3d1e840c9836,VideoCoCa: Video-Text Modeling with Zero-Shot Transfer from Contrastive Captioners,0.634628,"We explore an efficient approach to establish a foundational video-text
model. We present VideoCoCa that maximally reuses a pretrained image-text
contrastive captioner (CoCa) model and adapt it to video-text tasks with
minimal extra training. While previous works adapt image-text models with
various cross-frame fusion modules, we find that the generative attentional
pooling and contrastive attentional pooling layers in CoCa are instantly
adaptable to flattened frame embeddings, yielding state-of-the-art results on
zero-shot video classification and zero-shot text-to-video retrieval.
Furthermore, we explore lightweight finetuning on top of VideoCoCa, and achieve
strong results on video question-answering and video captioning.",None,-1
26357719-a5f1-4da0-88b9-02a83648951b,On The Robustness of Offensive Language Classifiers,0.354832,"Social media platforms are deploying machine learning based offensive
language classification systems to combat hateful, racist, and other forms of
offensive speech at scale. However, despite their real-world deployment, we do
not yet comprehensively understand the extent to which offensive language
classifiers are robust against adversarial attacks. Prior work in this space is
limited to studying robustness of offensive language classifiers against
primitive attacks such as misspellings and extraneous spaces. To address this
gap, we systematically analyze the robustness of state-of-the-art offensive
language classifiers against more crafty adversarial attacks that leverage
greedy- and attention-based word selection and context-aware embeddings for
word replacement. Our results on multiple datasets show that these crafty
adversarial attacks can degrade the accuracy of offensive language classifiers
by more than 50% while also being able to preserve the readability and meaning
of the modified text.",https://github.com/JonRusert/RobustnessOfOffensiveClassiﬁers,-1
a5be1d17-3a2e-4280-abc1-537e95cf1cc6,ATST: Audio Representation Learning with Teacher-Student Transformer,0.364117,"Self-supervised learning (SSL) learns knowledge from a large amount of
unlabeled data, and then transfers the knowledge to a specific problem with a
limited number of labeled data. SSL has achieved promising results in various
domains. This work addresses the problem of segment-level general audio SSL,
and proposes a new transformer-based teacher-student SSL model, named ATST. A
transformer encoder is developed on a recently emerged teacher-student baseline
scheme, which largely improves the modeling capability of pre-training. In
addition, a new strategy for positive pair creation is designed to fully
leverage the capability of transformer. Extensive experiments have been
conducted, and the proposed model achieves the new state-of-the-art results on
almost all of the downstream tasks.",https://github.com/Audio-WestlakeU/audiossl,-1
b55520f2-8ba8-466a-8dfe-82d176a25a72,DeiT III: Revenge of the ViT,0.981459,"A Vision Transformer (ViT) is a simple neural architecture amenable to serve
several computer vision tasks. It has limited built-in architectural priors, in
contrast to more recent architectures that incorporate priors either about the
input data or of specific tasks. Recent works show that ViTs benefit from
self-supervised pre-training, in particular BerT-like pre-training like BeiT.
In this paper, we revisit the supervised training of ViTs. Our procedure builds
upon and simplifies a recipe introduced for training ResNet-50. It includes a
new simple data-augmentation procedure with only 3 augmentations, closer to the
practice in self-supervised learning. Our evaluations on Image classification
(ImageNet-1k with and without pre-training on ImageNet-21k), transfer learning
and semantic segmentation show that our procedure outperforms by a large margin
previous fully supervised training recipes for ViT. It also reveals that the
performance of our ViT trained with supervision is comparable to that of more
recent architectures. Our results could serve as better baselines for recent
self-supervised approaches demonstrated on ViT.",None,-1
905b9c8d-787e-422c-a34a-c8178b4dd9be,Keys to Better Image Inpainting: Structure and Texture Go Hand in Hand,0.709273,"Deep image inpainting has made impressive progress with recent advances in
image generation and processing algorithms. We claim that the performance of
inpainting algorithms can be better judged by the generated structures and
textures. Structures refer to the generated object boundary or novel geometric
structures within the hole, while texture refers to high-frequency details,
especially man-made repeating patterns filled inside the structural regions. We
believe that better structures are usually obtained from a coarse-to-fine
GAN-based generator network while repeating patterns nowadays can be better
modeled using state-of-the-art high-frequency fast fourier convolutional
layers. In this paper, we propose a novel inpainting network combining the
advantages of the two designs. Therefore, our model achieves a remarkable
visual quality to match state-of-the-art performance in both structure
generation and repeating texture synthesis using a single network. Extensive
experiments demonstrate the effectiveness of the method, and our conclusions
further highlight the two critical factors of image inpainting quality,
structures, and textures, as the future design directions of inpainting
networks.",https://github.com/SHI-Labs/FcF-Inpainting/,-1
07c611be-7af9-477d-805e-065fa21c1af4,HyperNST: Hyper-Networks for Neural Style Transfer,0.401853,"We present HyperNST; a neural style transfer (NST) technique for the artistic
stylization of images, based on Hyper-networks and the StyleGAN2 architecture.
Our contribution is a novel method for inducing style transfer parameterized by
a metric space, pre-trained for style-based visual search (SBVS). We show for
the first time that such space may be used to drive NST, enabling the
application and interpolation of styles from an SBVS system. The technical
contribution is a hyper-network that predicts weight updates to a StyleGAN2
pre-trained over a diverse gamut of artistic content (portraits), tailoring the
style parameterization on a per-region basis using a semantic map of the facial
regions. We show HyperNST to exceed state of the art in content preservation
for our stylized content while retaining good style transfer performance.",None,33989
47d43878-fb81-4fd5-8f84-72e13a8e0aed,VQ-Flows: Vector Quantized Local Normalizing Flows,0.379527,"Normalizing flows provide an elegant approach to generative modeling that
allows for efficient sampling and exact density evaluation of unknown data
distributions. However, current techniques have significant limitations in
their expressivity when the data distribution is supported on a low-dimensional
manifold or has a non-trivial topology. We introduce a novel statistical
framework for learning a mixture of local normalizing flows as ""chart maps""
over the data manifold. Our framework augments the expressivity of recent
approaches while preserving the signature property of normalizing flows, that
they admit exact density evaluation. We learn a suitable atlas of charts for
the data manifold via a vector quantized auto-encoder (VQ-AE) and the
distributions over them using a conditional flow. We validate experimentally
that our probabilistic framework enables existing approaches to better model
data distributions over complex manifolds.",None,-1
980e5340-8446-45eb-8620-2e68fc7afbcb,AI-based Malware and Ransomware Detection Models,0.677428,"Cybercrime is one of the major digital threats of this century. In
particular, ransomware attacks have significantly increased, resulting in
global damage costs of tens of billion dollars. In this paper, we train and
test different Machine Learning and Deep Learning models for malware detection,
malware classification and ransomware detection. We introduce a novel and
flexible solution that combines two optimized models for malware and ransomware
detection. Our results demonstrate some improvements both in terms of detection
performances and flexibility. In particular, our combined models pave the way
for easier future enhancements using specialized and thus interchangeable
detection modules.",None,-1
193f6ec2-d553-4b2c-9576-14fb9b01df20,Seeking Diverse Reasoning Logic: Controlled Equation Expression Generation for Solving Math Word Problems,0.418547,"To solve Math Word Problems, human students leverage diverse reasoning logic
that reaches different possible equation solutions. However, the mainstream
sequence-to-sequence approach of automatic solvers aims to decode a fixed
solution equation supervised by human annotation. In this paper, we propose a
controlled equation generation solver by leveraging a set of control codes to
guide the model to consider certain reasoning logic and decode the
corresponding equations expressions transformed from the human reference. The
empirical results suggest that our method universally improves the performance
on single-unknown (Math23K) and multiple-unknown (DRAW1K, HMWP) benchmarks,
with substantial improvements up to 13.2% accuracy on the challenging
multiple-unknown datasets.",https://github.com/yiyunya/CTRL-MWP,7897
70971da0-53af-4c91-93f5-c5a9e760a03b,Multitask Pre-training of Modular Prompt for Chinese Few-Shot Learning,0.191265,"Prompt tuning is a parameter-efficient approach to adapting pre-trained
language models to downstream tasks. Although prompt tuning has been shown to
match the performance of full model tuning when training data is sufficient, it
tends to struggle in few-shot learning settings. In this paper, we present
Multi-task Pre-trained Modular Prompt (MP2) to boost prompt tuning for few-shot
learning. MP2 is a set of combinable prompts pre-trained on 38 Chinese tasks.
On downstream tasks, the pre-trained prompts are selectively activated and
combined, leading to strong compositional generalization to unseen tasks. To
bridge the gap between pre-training and fine-tuning, we formulate upstream and
downstream tasks into a unified machine reading comprehension task. Extensive
experiments under two learning paradigms, i.e., gradient descent and black-box
tuning, show that MP2 significantly outperforms prompt tuning, full model
tuning, and prior prompt pre-training methods in few-shot settings. In
addition, we demonstrate that MP2 can achieve surprisingly fast and strong
adaptation to downstream tasks by merely learning 8 parameters to combine the
pre-trained modular prompts.",https://github.com/Hzfinfdu/MPMP,-1
bfdd5493-0076-4bb6-a787-e4f081ba6a39,Characterizing the Efficiency vs. Accuracy Trade-off for Long-Context NLP Models,0.35213,"With many real-world applications of Natural Language Processing (NLP)
comprising of long texts, there has been a rise in NLP benchmarks that measure
the accuracy of models that can handle longer input sequences. However, these
benchmarks do not consider the trade-offs between accuracy, speed, and power
consumption as input sizes or model sizes are varied. In this work, we perform
a systematic study of this accuracy vs. efficiency trade-off on two widely used
long-sequence models - Longformer-Encoder-Decoder (LED) and Big Bird - during
fine-tuning and inference on four datasets from the SCROLLS benchmark. To study
how this trade-off differs across hyperparameter settings, we compare the
models across four sequence lengths (1024, 2048, 3072, 4096) and two model
sizes (base and large) under a fixed resource budget. We find that LED
consistently achieves better accuracy at lower energy costs than Big Bird. For
summarization, we find that increasing model size is more energy efficient than
increasing sequence length for higher accuracy. However, this comes at the cost
of a large drop in inference speed. For question answering, we find that
smaller models are both more efficient and more accurate due to the larger
training batch sizes possible under a fixed resource budget.",https://github.com/phyllisayk/nlp-efficiency-tradeoff,-1
d3db65af-c679-458c-a43f-7ae44b3e0e63,Understanding Masked Image Modeling via Learning Occlusion Invariant Feature,0.988595,"Recently, Masked Image Modeling (MIM) achieves great success in
self-supervised visual recognition. However, as a reconstruction-based
framework, it is still an open question to understand how MIM works, since MIM
appears very different from previous well-studied siamese approaches such as
contrastive learning. In this paper, we propose a new viewpoint: MIM implicitly
learns occlusion-invariant features, which is analogous to other siamese
methods while the latter learns other invariance. By relaxing MIM formulation
into an equivalent siamese form, MIM methods can be interpreted in a unified
framework with conventional methods, among which only a) data transformations,
i.e. what invariance to learn, and b) similarity measurements are different.
Furthermore, taking MAE (He et al.) as a representative example of MIM, we
empirically find the success of MIM models relates a little to the choice of
similarity functions, but the learned occlusion invariant feature introduced by
masked image -- it turns out to be a favored initialization for vision
transformers, even though the learned feature could be less semantic. We hope
our findings could inspire researchers to develop more powerful self-supervised
methods in computer vision community.",None,-1
57d36da5-7438-4db7-832a-a54eb4e0abb1,Robust Category-Level 6D Pose Estimation with Coarse-to-Fine Rendering of Neural Features,0.660481,"We consider the problem of category-level 6D pose estimation from a single
RGB image. Our approach represents an object category as a cuboid mesh and
learns a generative model of the neural feature activations at each mesh vertex
to perform pose estimation through differentiable rendering. A common problem
of rendering-based approaches is that they rely on bounding box proposals,
which do not convey information about the 3D rotation of the object and are not
reliable when objects are partially occluded. Instead, we introduce a
coarse-to-fine optimization strategy that utilizes the rendering process to
estimate a sparse set of 6D object proposals, which are subsequently refined
with gradient-based optimization. The key to enabling the convergence of our
approach is a neural feature representation that is trained to be scale- and
rotation-invariant using contrastive learning. Our experiments demonstrate an
enhanced category-level 6D pose estimation performance compared to prior work,
particularly under strong partial occlusion.",None,-1
ac790832-c724-4c01-942b-40cab6caf482,Few-shot Single-view 3D Reconstruction with Memory Prior Contrastive Network,0.594711,"3D reconstruction of novel categories based on few-shot learning is appealing
in real-world applications and attracts increasing research interests. Previous
approaches mainly focus on how to design shape prior models for different
categories. Their performance on unseen categories is not very competitive. In
this paper, we present a Memory Prior Contrastive Network (MPCN) that can store
shape prior knowledge in a few-shot learning based 3D reconstruction framework.
With the shape memory, a multi-head attention module is proposed to capture
different parts of a candidate shape prior and fuse these parts together to
guide 3D reconstruction of novel categories. Besides, we introduce a 3D-aware
contrastive learning method, which can not only complement the retrieval
accuracy of memory network, but also better organize image features for
downstream tasks. Compared with previous few-shot 3D reconstruction methods,
MPCN can handle the inter-class variability without category annotations.
Experimental results on a benchmark synthetic dataset and the Pascal3D+
real-world dataset show that our model outperforms the current state-of-the-art
methods significantly.",None,-1
181b3683-7a1e-4170-8bc2-de7d65933b63,Graph Enhanced Contrastive Learning for Radiology Findings Summarization,0.978534,"The impression section of a radiology report summarizes the most prominent
observation from the findings section and is the most important section for
radiologists to communicate to physicians. Summarizing findings is
time-consuming and can be prone to error for inexperienced radiologists, and
thus automatic impression generation has attracted substantial attention. With
the encoder-decoder framework, most previous studies explore incorporating
extra knowledge (e.g., static pre-defined clinical ontologies or extra
background information). Yet, they encode such knowledge by a separate encoder
to treat it as an extra input to their models, which is limited in leveraging
their relations with the original findings. To address the limitation, we
propose a unified framework for exploiting both extra knowledge and the
original findings in an integrated way so that the critical information (i.e.,
key words and their relations) can be extracted in an appropriate way to
facilitate impression generation. In detail, for each input findings, it is
encoded by a text encoder, and a graph is constructed through its entities and
dependency tree. Then, a graph encoder (e.g., graph neural networks (GNNs)) is
adopted to model relation information in the constructed graph. Finally, to
emphasize the key words in the findings, contrastive learning is introduced to
map positive samples (constructed by masking non-key words) closer and push
apart negative ones (constructed by masking key words). The experimental
results on OpenI and MIMIC-CXR confirm the effectiveness of our proposed
method.",https://github.com/jinpeng01/AIG_CL,-1
1652d8de-21f8-4af8-b4a1-d4a9f458f59f,Thalamus: a brain-inspired algorithm for biologically-plausible continual learning and disentangled representations,0.105476,"Animals thrive in a constantly changing environment and leverage the temporal
structure to learn well-factorized causal representations. In contrast,
traditional neural networks suffer from forgetting in changing environments and
many methods have been proposed to limit forgetting with different trade-offs.
Inspired by the brain thalamocortical circuit, we introduce a simple algorithm
that uses optimization at inference time to generate internal representations
of the current task dynamically. The algorithm alternates between updating the
model weights and a latent task embedding, allowing the agent to parse the
stream of temporal experience into discrete events and organize learning about
them. On a continual learning benchmark, it achieves competitive end average
accuracy by mitigating forgetting, but importantly, by requiring the model to
adapt through latent updates, it organizes knowledge into flexible structures
with a cognitive interface to control them. Tasks later in the sequence can be
solved through knowledge transfer as they become reachable within the
well-factorized latent space. The algorithm meets many of the desiderata of an
ideal continually learning agent in open-ended environments, and its simplicity
suggests fundamental computations in circuits with abundant feedback control
loops such as the thalamocortical circuits in the brain.",None,-1
f1b35206-1d43-4629-aad9-2dbc5d1c9c6d,ExAgt: Expert-guided Augmentation for Representation Learning of Traffic Scenarios,0.0849589,"Representation learning in recent years has been addressed with
self-supervised learning methods. The input data is augmented into two
distorted views and an encoder learns the representations that are invariant to
distortions -- cross-view prediction. Augmentation is one of the key components
in cross-view self-supervised learning frameworks to learn visual
representations. This paper presents ExAgt, a novel method to include expert
knowledge for augmenting traffic scenarios, to improve the learnt
representations without any human annotation. The expert-guided augmentations
are generated in an automated fashion based on the infrastructure, the
interactions between the EGO and the traffic participants and an ideal sensor
model. The ExAgt method is applied in two state-of-the-art cross-view
prediction methods and the representations learnt are tested in downstream
tasks like classification and clustering. Results show that the ExAgt method
improves representation learning compared to using only standard augmentations
and it provides a better representation space stability. The code is available
at https://github.com/lab176344/ExAgt.",https://github.com/lab176344/ExAgt,-1
100c4224-ea33-4fe9-956a-c8c6de65f05a,ClusterGNN: Cluster-based Coarse-to-Fine Graph Neural Network for Efficient Feature Matching,0.989159,"Graph Neural Networks (GNNs) with attention have been successfully applied
for learning visual feature matching. However, current methods learn with
complete graphs, resulting in a quadratic complexity in the number of features.
Motivated by a prior observation that self- and cross- attention matrices
converge to a sparse representation, we propose ClusterGNN, an attentional GNN
architecture which operates on clusters for learning the feature matching task.
Using a progressive clustering module we adaptively divide keypoints into
different subgraphs to reduce redundant connectivity, and employ a
coarse-to-fine paradigm for mitigating miss-classification within images. Our
approach yields a 59.7% reduction in runtime and 58.4% reduction in memory
consumption for dense detection, compared to current state-of-the-art GNN-based
matching, while achieving a competitive performance on various computer vision
tasks.",None,-1
241d4961-104d-4803-8c80-1123f40cadbb,M2I: From Factored Marginal Trajectory Prediction to Interactive Prediction,0.981273,"Predicting future motions of road participants is an important task for
driving autonomously in urban scenes. Existing models excel at predicting
marginal trajectories for single agents, yet it remains an open question to
jointly predict scene compliant trajectories over multiple agents. The
challenge is due to exponentially increasing prediction space as a function of
the number of agents. In this work, we exploit the underlying relations between
interacting agents and decouple the joint prediction problem into marginal
prediction problems. Our proposed approach M2I first classifies interacting
agents as pairs of influencers and reactors, and then leverages a marginal
prediction model and a conditional prediction model to predict trajectories for
the influencers and reactors, respectively. The predictions from interacting
agents are combined and selected according to their joint likelihoods.
Experiments show that our simple but effective approach achieves
state-of-the-art performance on the Waymo Open Motion Dataset interactive
prediction benchmark.",None,18787
46f68e10-22f5-47e2-8168-cb1f4039f4b8,LineCap: Line Charts for Data Visualization Captioning Models,0.924862,"Data visualization captions help readers understand the purpose of a
visualization and are crucial for individuals with visual impairments. The
prevalence of poor figure captions and the successful application of deep
learning approaches to image captioning motivate the use of similar techniques
for automated figure captioning. However, research in this field has been
stunted by the lack of suitable datasets. We introduce LineCap, a novel figure
captioning dataset of 3,528 figures, and we provide insights from curating this
dataset and using end-to-end deep learning models for automated figure
captioning.",https://github.com/anita76/LineCapDataset,-1
a3b32bea-ba6e-4a34-8994-91d3d6ae115e,Contrastive Classification and Representation Learning with Probabilistic Interpretation,0.141549,"Cross entropy loss has served as the main objective function for
classification-based tasks. Widely deployed for learning neural network
classifiers, it shows both effectiveness and a probabilistic interpretation.
Recently, after the success of self supervised contrastive representation
learning methods, supervised contrastive methods have been proposed to learn
representations and have shown superior and more robust performance, compared
to solely training with cross entropy loss. However, cross entropy loss is
still needed to train the final classification layer. In this work, we
investigate the possibility of learning both the representation and the
classifier using one objective function that combines the robustness of
contrastive learning and the probabilistic interpretation of cross entropy
loss. First, we revisit a previously proposed contrastive-based objective
function that approximates cross entropy loss and present a simple extension to
learn the classifier jointly. Second, we propose a new version of the
supervised contrastive training that learns jointly the parameters of the
classifier and the backbone of the network. We empirically show that our
proposed objective functions show a significant improvement over the standard
cross entropy loss with more training stability and robustness in various
challenging settings.",None,-1
7f894540-043e-4096-a946-dc943976120f,Dynamic Global Memory for Document-level Argument Extraction,0.97874,"Extracting informative arguments of events from news articles is a
challenging problem in information extraction, which requires a global
contextual understanding of each document. While recent work on document-level
extraction has gone beyond single-sentence and increased the cross-sentence
inference capability of end-to-end models, they are still restricted by certain
input sequence length constraints and usually ignore the global context between
events. To tackle this issue, we introduce a new global neural generation-based
framework for document-level event argument extraction by constructing a
document memory store to record the contextual event information and leveraging
it to implicitly and explicitly help with decoding of arguments for later
events. Empirical results show that our framework outperforms prior methods
substantially and it is more robust to adversarially annotated examples with
our constrained decoding design. (Our code and resources are available at
https://github.com/xinyadu/memory_docie for research purpose.)",https://github.com/xinyadu/memory_docie,-1
75e00f30-ae78-40d0-9080-163e52f6c27f,Near Perfect GAN Inversion,0.430688,"To edit a real photo using Generative Adversarial Networks (GANs), we need a
GAN inversion algorithm to identify the latent vector that perfectly reproduces
it. Unfortunately, whereas existing inversion algorithms can synthesize images
similar to real photos, they cannot generate the identical clones needed in
most applications. Here, we derive an algorithm that achieves near perfect
reconstructions of photos. Rather than relying on encoder- or
optimization-based methods to find an inverse mapping on a fixed generator
$G(\cdot)$, we derive an approach to locally adjust $G(\cdot)$ to more
optimally represent the photos we wish to synthesize. This is done by locally
tweaking the learned mapping $G(\cdot)$ s.t. $\| {\bf x} - G({\bf z})
\|<\epsilon$, with ${\bf x}$ the photo we wish to reproduce, ${\bf z}$ the
latent vector, $\|\cdot\|$ an appropriate metric, and $\epsilon > 0$ a small
scalar. We show that this approach can not only produce synthetic images that
are indistinguishable from the real photos we wish to replicate, but that these
images are readily editable. We demonstrate the effectiveness of the derived
algorithm on a variety of datasets including human faces, animals, and cars,
and discuss its importance for diversity and inclusion.",https://github.com/davisking/dlibofStyleGAN2,-1
c1df873f-b2a8-42f2-8587-88704f62aa08,The Third International Verification of Neural Networks Competition (VNN-COMP 2022): Summary and Results,0.857211,"This report summarizes the 3rd International Verification of Neural Networks
Competition (VNN-COMP 2022), held as a part of the 5th Workshop on Formal
Methods for ML-Enabled Autonomous Systems (FoMLAS), which was collocated with
the 34th International Conference on Computer-Aided Verification (CAV).
VNN-COMP is held annually to facilitate the fair and objective comparison of
state-of-the-art neural network verification tools, encourage the
standardization of tool interfaces, and bring together the neural network
verification community. To this end, standardized formats for networks (ONNX)
and specification (VNN-LIB) were defined, tools were evaluated on equal-cost
hardware (using an automatic evaluation pipeline based on AWS instances), and
tool parameters were chosen by the participants before the final test sets were
made public. In the 2022 iteration, 11 teams participated on a diverse set of
12 scored benchmarks. This report summarizes the rules, benchmarks,
participating tools, results, and lessons learned from this iteration of this
competition.",None,-1
421abf39-52c2-42ed-9bab-7ee4edb69a24,Hierarchies of Reward Machines,0.289378,"Reward machines (RMs) are a recent formalism for representing the reward
function of a reinforcement learning task through a finite-state machine whose
edges encode subgoals of the task using high-level events. The structure of RMs
enables the decomposition of a task into simpler and independently solvable
subtasks that help tackle long-horizon and/or sparse reward tasks. We propose a
formalism for further abstracting the subtask structure by endowing an RM with
the ability to call other RMs, thus composing a hierarchy of RMs (HRM). We
exploit HRMs by treating each call to an RM as an independently solvable
subtask using the options framework, and describe a curriculum-based method to
learn HRMs from traces observed by the agent. Our experiments reveal that
exploiting a handcrafted HRM leads to faster convergence than with a flat HRM,
and that learning an HRM is feasible in cases where its equivalent flat
representation is not.",https://github.com/ertsiger/hrm-learning,-1
4984df6e-134c-4bd9-8589-ada6482cb2ca,Benchmarking for Public Health Surveillance tasks on Social Media with a Domain-Specific Pretrained Language Model,0.899891,"A user-generated text on social media enables health workers to keep track of
information, identify possible outbreaks, forecast disease trends, monitor
emergency cases, and ascertain disease awareness and response to official
health correspondence. This exchange of health information on social media has
been regarded as an attempt to enhance public health surveillance (PHS).
Despite its potential, the technology is still in its early stages and is not
ready for widespread application. Advancements in pretrained language models
(PLMs) have facilitated the development of several domain-specific PLMs and a
variety of downstream applications. However, there are no PLMs for social media
tasks involving PHS. We present and release PHS-BERT, a transformer-based PLM,
to identify tasks related to public health surveillance on social media. We
compared and benchmarked the performance of PHS-BERT on 25 datasets from
different social medial platforms related to 7 different PHS tasks. Compared
with existing PLMs that are mainly evaluated on limited tasks, PHS-BERT
achieved state-of-the-art performance on all 25 tested datasets, showing that
our PLM is robust and generalizable in the common PHS tasks. By making PHS-BERT
available, we aim to facilitate the community to reduce the computational cost
and introduce new baselines for future works across various PHS-related tasks.",https://huggingface.co/publichealthsurveillance/PHS-BERT,-1
ae67d3b7-8941-4ea3-b68d-e4ecbcea72ca,Densely Constrained Depth Estimator for Monocular 3D Object Detection,0.687387,"Estimating accurate 3D locations of objects from monocular images is a
challenging problem because of lacking depth. Previous work shows that
utilizing the object's keypoint projection constraints to estimate multiple
depth candidates boosts the detection performance. However, the existing
methods can only utilize vertical edges as projection constraints for depth
estimation. So these methods only use a small number of projection constraints
and produce insufficient depth candidates, leading to inaccurate depth
estimation. In this paper, we propose a method that utilizes dense projection
constraints from edges of any direction. In this way, we employ much more
projection constraints and produce considerable depth candidates. Besides, we
present a graph matching weighting module to merge the depth candidates. The
proposed method DCD (Densely Constrained Detector) achieves state-of-the-art
performance on the KITTI and WOD benchmarks. Code is released at
https://github.com/BraveGroup/DCD.",https://github.com/BraveGroup/DCD,-1
319f4eaf-20ff-4519-b65f-df954757e76a,Addressing the Challenges of Cross-Lingual Hate Speech Detection,0.0877459,"The goal of hate speech detection is to filter negative online content aiming
at certain groups of people. Due to the easy accessibility of social media
platforms it is crucial to protect everyone which requires building hate speech
detection systems for a wide range of languages. However, the available labeled
hate speech datasets are limited making it problematic to build systems for
many languages. In this paper we focus on cross-lingual transfer learning to
support hate speech detection in low-resource languages. We leverage
cross-lingual word embeddings to train our neural network systems on the source
language and apply it to the target language, which lacks labeled examples, and
show that good performance can be achieved. We then incorporate unlabeled
target language data for further model improvements by bootstrapping labels
using an ensemble of different model architectures. Furthermore, we investigate
the issue of label imbalance of hate speech datasets, since the high ratio of
non-hate examples compared to hate examples often leads to low model
performance. We test simple data undersampling and oversampling techniques and
show their effectiveness.",None,38141
5f324795-99b0-4296-bea1-49dd0e6835f2,Unsupervised Semantic Segmentation with Self-supervised Object-centric Representations,0.726289,"In this paper, we show that recent advances in self-supervised feature
learning enable unsupervised object discovery and semantic segmentation with a
performance that matches the state of the field on supervised semantic
segmentation 10 years ago. We propose a methodology based on unsupervised
saliency masks and self-supervised feature clustering to kickstart object
discovery followed by training a semantic segmentation network on pseudo-labels
to bootstrap the system on images with multiple objects. We present results on
PASCAL VOC that go far beyond the current state of the art (50.0 mIoU), and we
report for the first time results on MS COCO for the whole set of 81 classes:
our method discovers 34 categories with more than $20\%$ IoU, while obtaining
an average IoU of 19.6 for all 81 categories.",https://github.com/zadaianchuk/comus,-1
799a28be-65e9-44e9-8f5c-df448aea949f,Understanding the Covariance Structure of Convolutional Filters,0.523239,"Neural network weights are typically initialized at random from univariate
distributions, controlling just the variance of individual weights even in
highly-structured operations like convolutions. Recent ViT-inspired
convolutional networks such as ConvMixer and ConvNeXt use large-kernel
depthwise convolutions whose learned filters have notable structure; this
presents an opportunity to study their empirical covariances. In this work, we
first observe that such learned filters have highly-structured covariance
matrices, and moreover, we find that covariances calculated from small networks
may be used to effectively initialize a variety of larger networks of different
depths, widths, patch sizes, and kernel sizes, indicating a degree of
model-independence to the covariance structure. Motivated by these findings, we
then propose a learning-free multivariate initialization scheme for
convolutional filters using a simple, closed-form construction of their
covariance. Models using our initialization outperform those using traditional
univariate initializations, and typically meet or exceed the performance of
those initialized from the covariances of learned filters; in some cases, this
improvement can be achieved without training the depthwise convolutional
filters at all.",None,-1
7f8f491e-d248-47d0-a657-b70abd0e94e4,Look at Adjacent Frames: Video Anomaly Detection without Offline Training,0.125617,"We propose a solution to detect anomalous events in videos without the need
to train a model offline. Specifically, our solution is based on a
randomly-initialized multilayer perceptron that is optimized online to
reconstruct video frames, pixel-by-pixel, from their frequency information.
Based on the information shifts between adjacent frames, an incremental learner
is used to update parameters of the multilayer perceptron after observing each
frame, thus allowing to detect anomalous events along the video stream.
Traditional solutions that require no offline training are limited to operating
on videos with only a few abnormal frames. Our solution breaks this limit and
achieves strong performance on benchmark datasets.",None,-1
65a94cf9-0280-4742-a96f-46f4f350064a,SALTED: A Framework for SAlient Long-Tail Translation Error Detection,0.702872,"Traditional machine translation (MT) metrics provide an average measure of
translation quality that is insensitive to the long tail of behavioral problems
in MT. Examples include translation of numbers, physical units, dropped content
and hallucinations. These errors, which occur rarely and unpredictably in
Neural Machine Translation (NMT), greatly undermine the reliability of
state-of-the-art MT systems. Consequently, it is important to have visibility
into these problems during model development. Towards this direction, we
introduce SALTED, a specifications-based framework for behavioral testing of MT
models that provides fine-grained views of salient long-tail errors, permitting
trustworthy visibility into previously invisible problems. At the core of our
approach is the development of high-precision detectors that flag errors (or
alternatively, verify output correctness) between a source sentence and a
system output. We demonstrate that such detectors could be used not just to
identify salient long-tail errors in MT systems, but also for higher-recall
filtering of the training data, fixing targeted errors with model fine-tuning
in NMT and generating novel data for metamorphic testing to elicit further bugs
in models.",https://github.com/pytorch/fairseq/tree/main/examples/wmt21,-1
4d4624d8-ea6e-443d-afa2-9daf45458bb1,DARER: Dual-task Temporal Relational Recurrent Reasoning Network for Joint Dialog Sentiment Classification and Act Recognition,0.827567,"The task of joint dialog sentiment classification (DSC) and act recognition
(DAR) aims to simultaneously predict the sentiment label and act label for each
utterance in a dialog. In this paper, we put forward a new framework which
models the explicit dependencies via integrating \textit{prediction-level
interactions} other than semantics-level interactions, more consistent with
human intuition. Besides, we propose a speaker-aware temporal graph (SATG) and
a dual-task relational temporal graph (DRTG) to introduce \textit{temporal
relations} into dialog understanding and dual-task reasoning. To implement our
framework, we propose a novel model dubbed DARER, which first generates the
context-, speaker- and temporal-sensitive utterance representations via
modeling SATG, then conducts recurrent dual-task relational reasoning on DRTG,
in which process the estimated label distributions act as key clues in
prediction-level interactions. Experiment results show that DARER outperforms
existing models by large margins while requiring much less computation resource
and costing less training time. Remarkably, on DSC task in Mastodon, DARER
gains a relative improvement of about 25% over previous best model in terms of
F1, with less than 50% parameters and about only 60% required GPU memory.",https://github.com/XingBowen714/DARER,-1
391c379d-03b6-4b4e-8ac9-7066853d21f1,Bilinear value networks,0.41405,"The dominant framework for off-policy multi-goal reinforcement learning
involves estimating goal conditioned Q-value function. When learning to achieve
multiple goals, data efficiency is intimately connected with the generalization
of the Q-function to new goals. The de-facto paradigm is to approximate Q(s, a,
g) using monolithic neural networks. To improve the generalization of the
Q-function, we propose a bilinear decomposition that represents the Q-value via
a low-rank approximation in the form of a dot product between two vector
fields. The first vector field, f(s, a), captures the environment's local
dynamics at the state s; whereas the second component, {\phi}(s, g), captures
the global relationship between the current state and the goal. We show that
our bilinear decomposition scheme substantially improves data efficiency, and
has superior transfer to out-of-distribution goals compared to prior methods.
Empirical evidence is provided on the simulated Fetch robot task-suite and
dexterous manipulation with a Shadow hand.",https://github.com/Improbable-AI/bvn,-1
7c0a6b6f-346b-4336-900a-f417bef3649c,Analogical Math Word Problems Solving with Enhanced Problem-Solution Association,0.250567,"Math word problem (MWP) solving is an important task in question answering
which requires human-like reasoning ability. Analogical reasoning has long been
used in mathematical education, as it enables students to apply common
relational structures of mathematical situations to solve new problems. In this
paper, we propose to build a novel MWP solver by leveraging analogical MWPs,
which advance the solver's generalization ability across different kinds of
MWPs. The key idea, named analogy identification, is to associate the
analogical MWP pairs in a latent space, i.e., encoding an MWP close to another
analogical MWP, while moving away from the non-analogical ones. Moreover, a
solution discriminator is integrated into the MWP solver to enhance the
association between the representations of MWPs and their true solutions. The
evaluation results verify that our proposed analogical learning strategy
promotes the performance of MWP-BERT on Math23k over the state-of-the-art model
Generate2Rank, with 5 times fewer parameters in the encoder. We also find that
our model has a stronger generalization ability in solving difficult MWPs due
to the analogical learning from easy MWPs.",https://github.com/ShichaoSun/math_seq2tree,-1
9d58227a-491f-4fb1-8a1d-0bb8bf566535,Training Robots without Robots: Deep Imitation Learning for Master-to-Robot Policy Transfer,0.750612,"Deep imitation learning is promising for robot manipulation because it only
requires demonstration samples. In this study, deep imitation learning is
applied to tasks that require force feedback. However, existing demonstration
methods have deficiencies; bilateral teleoperation requires a complex control
scheme and is expensive, and kinesthetic teaching suffers from visual
distractions from human intervention. This research proposes a new
master-to-robot (M2R) policy transfer system that does not require robots for
teaching force feedback-based manipulation tasks. The human directly
demonstrates a task using a controller. This controller resembles the kinematic
parameters of the robot arm and uses the same end-effector with force/torque
(F/T) sensors to measure the force feedback. Using this controller, the
operator can feel force feedback without a bilateral system. The proposed
method can overcome domain gaps between the master and robot using gaze-based
imitation learning and a simple calibration method. Furthermore, a Transformer
is applied to infer policy from F/T sensory input. The proposed system was
evaluated on a bottle-cap-opening task that requires force feedback.",None,-1
9f855844-d019-4f07-ba7d-637e8f072053,Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning,0.94417,"We present Bit Diffusion: a simple and generic approach for generating
discrete data with continuous state and continuous time diffusion models. The
main idea behind our approach is to first represent the discrete data as binary
bits, and then train a continuous diffusion model to model these bits as real
numbers which we call analog bits. To generate samples, the model first
generates the analog bits, which are then thresholded to obtain the bits that
represent the discrete variables. We further propose two simple techniques,
namely Self-Conditioning and Asymmetric Time Intervals, which lead to a
significant improvement in sample quality. Despite its simplicity, the proposed
approach can achieve strong performance in both discrete image generation and
image captioning tasks. For discrete image generation, we significantly improve
previous state-of-the-art on both CIFAR-10 (which has 3K discrete 8-bit tokens)
and ImageNet-64x64 (which has 12K discrete 8-bit tokens), outperforming the
best autoregressive model in both sample quality (measured by FID) and
efficiency. For image captioning on MS-COCO dataset, our approach achieves
competitive results compared to autoregressive models.",https://github.com/google-research/pix2seq,-1
88e3b38e-14d3-4ff4-bab8-5a5ac9b2e8b6,Kratt: Developing an Automatic Subject Indexing Tool for The National Library of Estonia,0.303119,"Manual subject indexing in libraries is a time-consuming and costly process
and the quality of the assigned subjects is affected by the cataloguer's
knowledge on the specific topics contained in the book. Trying to solve these
issues, we exploited the opportunities arising from artificial intelligence to
develop Kratt: a prototype of an automatic subject indexing tool. Kratt is able
to subject index a book independent of its extent and genre with a set of
keywords present in the Estonian Subject Thesaurus. It takes Kratt
approximately 1 minute to subject index a book, outperforming humans 10-15
times. Although the resulting keywords were not considered satisfactory by the
cataloguers, the ratings of a small sample of regular library users showed more
promise. We also argue that the results can be enhanced by including a bigger
corpus for training the model and applying more careful preprocessing
techniques.",None,-1
410b3285-a8db-458b-a687-d895129c058f,Mixed-effects transformers for hierarchical adaptation,0.0259254,"Language use differs dramatically from context to context. To some degree,
modern language models like GPT-3 are able to account for such variance by
conditioning on a string of previous input text, or prompt. Yet prompting is
ineffective when contexts are sparse, out-of-sample, or extra-textual; for
instance, accounting for when and where the text was produced or who produced
it. In this paper, we introduce the mixed-effects transformer (MET), a novel
approach for learning hierarchically-structured prefixes -- lightweight modules
prepended to the input -- to account for structured variation. Specifically, we
show how the popular class of mixed-effects models may be extended to
transformer-based architectures using a regularized prefix-tuning procedure
with dropout. We evaluate this approach on several domain-adaptation
benchmarks, finding that it efficiently adapts to novel contexts with minimal
data while still effectively generalizing to unseen contexts.",https://github.com/juliaiwhite/mixed-effects-transformers,-1
c6f39119-c4dc-4320-8ea5-9518a9218136,SoK: Differential Privacy on Graph-Structured Data,0.584724,"In this work, we study the applications of differential privacy (DP) in the
context of graph-structured data. We discuss the formulations of DP applicable
to the publication of graphs and their associated statistics as well as machine
learning on graph-based data, including graph neural networks (GNNs). The
formulation of DP in the context of graph-structured data is difficult, as
individual data points are interconnected (often non-linearly or sparsely).
This connectivity complicates the computation of individual privacy loss in
differentially private learning. The problem is exacerbated by an absence of a
single, well-established formulation of DP in graph settings. This issue
extends to the domain of GNNs, rendering private machine learning on
graph-structured data a challenging task. A lack of prior systematisation work
motivated us to study graph-based learning from a privacy perspective. In this
work, we systematise different formulations of DP on graphs, discuss challenges
and promising applications, including the GNN domain. We compare and separate
works into graph analysis tasks and graph learning tasks with GNNs. Finally, we
conclude our work with a discussion of open questions and potential directions
for further research in this area.",None,-1
4898d9f7-672d-4d6a-a5d9-39dd7714c7bf,Combining Predictions under Uncertainty: The Case of Random Decision Trees,0.0901886,"A common approach to aggregate classification estimates in an ensemble of
decision trees is to either use voting or to average the probabilities for each
class. The latter takes uncertainty into account, but not the reliability of
the uncertainty estimates (so to say, the ""uncertainty about the uncertainty"").
More generally, much remains unknown about how to best combine probabilistic
estimates from multiple sources. In this paper, we investigate a number of
alternative prediction methods. Our methods are inspired by the theories of
probability, belief functions and reliable classification, as well as a
principle that we call evidence accumulation. Our experiments on a variety of
data sets are based on random decision trees which guarantees a high diversity
in the predictions to be combined. Somewhat unexpectedly, we found that taking
the average over the probabilities is actually hard to beat. However, evidence
accumulation showed consistently better results on all but very small leafs.",https://github.com/olfub/RDT-Uncertainty,-1
c4c85114-e54d-4956-a8b8-4f3ddb50ba07,Learning to Prove Trigonometric Identities,0.18601,"Automatic theorem proving with deep learning methods has attracted attentions
recently. In this paper, we construct an automatic proof system for
trigonometric identities. We define the normalized form of trigonometric
identities, design a set of rules for the proof and put forward a method which
can generate theoretically infinite trigonometric identities. Our goal is not
only to complete the proof, but to complete the proof in as few steps as
possible. For this reason, we design a model to learn proof data generated by
random BFS (rBFS), and it is proved theoretically and experimentally that the
model can outperform rBFS after a simple imitation learning. After further
improvement through reinforcement learning, we get AutoTrig, which can give
proof steps for identities in almost as short steps as BFS (theoretically
shortest method), with a time cost of only one-thousandth. In addition,
AutoTrig also beats Sympy, Matlab and human in the synthetic dataset, and
performs well in many generalization tasks.",None,-1
6d34607f-8ed2-41b1-9df3-08ed4fe91d9d,Tailor: A Prompt-Based Approach to Attribute-Based Controlled Text Generation,0.35071,"Attribute-based Controlled Text Generation (CTG) refers to generating
sentences that satisfy desirable attributes (e.g., emotions and topics).
Existing works often utilize fine-tuning or resort to extra attribute
classifiers, yet suffer from storage and inference time increases. To address
these concerns, we explore attribute-based CTG in a prompt-based manner. In
short, the proposed Tailor represents each attribute as a pre-trained
continuous vector (i.e., single-attribute prompt) and guides the generation of
a fixed PLM switch to a pre-specified attribute. We experimentally find that
these prompts can be simply concatenated as a whole to multi-attribute CTG
without any re-training, yet raises problems of fluency decrease and position
sensitivity. To this end, Tailor provides a multi-attribute prompt mask and a
re-indexing position-ids sequence to bridge the gap between the training (one
prompt for each task) and testing stage (concatenating more than one prompt).
To further enhance such single-attribute prompt combinations, Tailor also
introduces a trainable prompt connector, which can be concatenated with any two
single-attribute prompts to multi-attribute text generation. Experiments on 11
attribute-specific generation tasks demonstrate strong performances of Tailor
on both single-attribute and multi-attribute CTG, with 0.08\% training
parameters of a GPT-2.",https://github.com/uber-research/PPLM,-1
92f56832-8f2e-4145-85c4-102703920ea8,METGEN: A Module-Based Entailment Tree Generation Framework for Answer Explanation,0.955353,"Knowing the reasoning chains from knowledge to the predicted answers can help
construct an explainable question answering (QA) system. Advances on QA
explanation propose to explain the answers with entailment trees composed of
multiple entailment steps. While current work proposes to generate entailment
trees with end-to-end generative models, the steps in the generated trees are
not constrained and could be unreliable. In this paper, we propose METGEN, a
Module-based Entailment Tree GENeration framework that has multiple modules and
a reasoning controller. Given a question and several supporting knowledge,
METGEN can iteratively generate the entailment tree by conducting single-step
entailment with separate modules and selecting the reasoning flow with the
controller. As each module is guided to perform a specific type of entailment
reasoning, the steps generated by METGEN are more reliable and valid.
Experiment results on the standard benchmark show that METGEN can outperform
previous state-of-the-art models with only 9% of the parameters.",https://github.com/huggingface/transformers,-1
5ac0dca9-d441-4e47-bb13-0f807b28f866,"One Model, Any CSP: Graph Neural Networks as Fast Global Search Heuristics for Constraint Satisfaction",0.309732,"We propose a universal Graph Neural Network architecture which can be trained
as an end-2-end search heuristic for any Constraint Satisfaction Problem (CSP).
Our architecture can be trained unsupervised with policy gradient descent to
generate problem specific heuristics for any CSP in a purely data driven
manner. The approach is based on a novel graph representation for CSPs that is
both generic and compact and enables us to process every possible CSP instance
with one GNN, regardless of constraint arity, relations or domain size. Unlike
previous RL-based methods, we operate on a global search action space and allow
our GNN to modify any number of variables in every step of the stochastic
search. This enables our method to properly leverage the inherent parallelism
of GNNs. We perform a thorough empirical evaluation where we learn heuristics
for well known and important CSPs from random data, including graph coloring,
MaxCut, 3-SAT and MAX-k-SAT. Our approach outperforms prior approaches for
neural combinatorial optimization by a substantial margin. It can compete with,
and even improve upon, conventional search heuristics on test instances that
are several orders of magnitude larger and structurally more complex than those
seen during training.",None,-1
63b04612-e5d2-4d81-9ecc-29dc12a91133,Anomaly Detection in Emails using Machine Learning and Header Information,0.397112,"Anomalies in emails such as phishing and spam present major security risks
such as the loss of privacy, money, and brand reputation to both individuals
and organizations. Previous studies on email anomaly detection relied on a
single type of anomaly and the analysis of the email body and subject content.
A drawback of this approach is that it takes into account the written language
of the email content. To overcome this deficit, this study conducted feature
extraction and selection on email header datasets and leveraged both multi and
one-class anomaly detection approaches. Experimental analysis results obtained
demonstrate that email header information only is enough to reliably detect
spam and phishing emails. Supervised learning algorithms such as Random Forest,
SVM, MLP, KNN, and their stacked ensembles were found to be very successful,
achieving high accuracy scores of 97% for phishing and 99% for spam emails.
One-class classification with One-Class SVM achieved accuracy scores of 87% and
89% with spam and phishing emails, respectively. Real-world email filtering
applications will benefit from the use of only the header information in terms
of resources utilization and efficiency.",https://github.com/kregg34/EmailHeaderAnomalyDetection,-1
0f5b6867-291d-49c6-be11-eaa26a3fa321,Semi-supervised detection of structural damage using Variational Autoencoder and a One-Class Support Vector Machine,0.393621,"In recent years, Artificial Neural Networks (ANNs) have been introduced in
Structural Health Monitoring (SHM) systems. A semi-supervised method with a
data-driven approach allows the ANN training on data acquired from an undamaged
structural condition to detect structural damages. In standard approaches,
after the training stage, a decision rule is manually defined to detect
anomalous data. However, this process could be made automatic using machine
learning methods, whom performances are maximised using hyperparameter
optimization techniques. The paper proposes a semi-supervised method with a
data-driven approach to detect structural anomalies. The methodology consists
of: (i) a Variational Autoencoder (VAE) to approximate undamaged data
distribution and (ii) a One-Class Support Vector Machine (OC-SVM) to
discriminate different health conditions using damage sensitive features
extracted from VAE's signal reconstruction. The method is applied to a scale
steel structure that was tested in nine damage's scenarios by IASC-ASCE
Structural Health Monitoring Task Group.",None,-1
d197e36a-4e40-465c-b96b-7828a28f77e3,Are Synonym Substitution Attacks Really Synonym Substitution Attacks?,0.357494,"In this paper, we explore the following question: Are synonym substitution
attacks really synonym substitution attacks (SSAs)? We approach this question
by examining how SSAs replace words in the original sentence and show that
there are still unresolved obstacles that make current SSAs generate invalid
adversarial samples. We reveal that four widely used word substitution methods
generate a large fraction of invalid substitution words that are ungrammatical
or do not preserve the original sentence's semantics. Next, we show that the
semantic and grammatical constraints used in SSAs for detecting invalid word
replacements are highly insufficient in detecting invalid adversarial samples.",https://textattack.readthedocs.io/en/latest/3recipes/models.html,-1
71ab2550-c68c-4a86-b8d9-4cd296bdd40d,Generating Multiple-Length Summaries via Reinforcement Learning for Unsupervised Sentence Summarization,0.633891,"Sentence summarization shortens given texts while maintaining core contents
of the texts. Unsupervised approaches have been studied to summarize texts
without human-written summaries. However, recent unsupervised models are
extractive, which remove words from texts and thus they are less flexible than
abstractive summarization. In this work, we devise an abstractive model based
on reinforcement learning without ground-truth summaries. We formulate the
unsupervised summarization based on the Markov decision process with rewards
representing the summary quality. To further enhance the summary quality, we
develop a multi-summary learning mechanism that generates multiple summaries
with varying lengths for a given text, while making the summaries mutually
enhance each other. Experimental results show that the proposed model
substantially outperforms both abstractive and extractive models, yet
frequently generating new words not contained in input texts.",https://github.com/dmhyun/MSRP,-1
a78f7ac8-7380-4f84-9966-42befe0e728d,NeuMan: Neural Human Radiance Field from a Single Video,0.995569,"Photorealistic rendering and reposing of humans is important for enabling
augmented reality experiences. We propose a novel framework to reconstruct the
human and the scene that can be rendered with novel human poses and views from
just a single in-the-wild video. Given a video captured by a moving camera, we
train two NeRF models: a human NeRF model and a scene NeRF model. To train
these models, we rely on existing methods to estimate the rough geometry of the
human and the scene. Those rough geometry estimates allow us to create a
warping field from the observation space to the canonical pose-independent
space, where we train the human model in. Our method is able to learn subject
specific details, including cloth wrinkles and accessories, from just a 10
seconds video clip, and to provide high quality renderings of the human under
novel poses, from novel views, together with the background.",https://github.com/apple/ml-neuman,-1
73f57456-239f-4336-9cd3-f6f63bdd1f17,Practical Adversarial Attacks on Spatiotemporal Traffic Forecasting Models,0.897133,"Machine learning based traffic forecasting models leverage sophisticated
spatiotemporal auto-correlations to provide accurate predictions of city-wide
traffic states. However, existing methods assume a reliable and unbiased
forecasting environment, which is not always available in the wild. In this
work, we investigate the vulnerability of spatiotemporal traffic forecasting
models and propose a practical adversarial spatiotemporal attack framework.
Specifically, instead of simultaneously attacking all geo-distributed data
sources, an iterative gradient-guided node saliency method is proposed to
identify the time-dependent set of victim nodes. Furthermore, we devise a
spatiotemporal gradient descent based scheme to generate real-valued
adversarial traffic states under a perturbation constraint. Meanwhile, we
theoretically demonstrate the worst performance bound of adversarial traffic
forecasting attacks. Extensive experiments on two real-world datasets show that
the proposed two-step framework achieves up to $67.8\%$ performance degradation
on various advanced spatiotemporal forecasting models. Remarkably, we also show
that adversarial training with our proposed attacks can significantly improve
the robustness of spatiotemporal traffic forecasting models. Our code is
available in \url{https://github.com/luckyfan-cs/ASTFA}.",https://github.com/kdd-hkust/Adv-ST,-1
c14b7db7-78f1-4b05-b351-5d5662bfaab4,Learned k-NN Distance Estimation,0.594149,"Big data mining is well known to be an important task for data science,
because it can provide useful observations and new knowledge hidden in given
large datasets. Proximity-based data analysis is particularly utilized in many
real-life applications. In such analysis, the distances to k nearest neighbors
are usually employed, thus its main bottleneck is derived from data retrieval.
Much efforts have been made to improve the efficiency of these analyses.
However, they still incur large costs, because they essentially need many data
accesses. To avoid this issue, we propose a machine-learning technique that
quickly and accurately estimates the k-NN distances (i.e., distances to the k
nearest neighbors) of a given query. We train a fully connected neural network
model and utilize pivots to achieve accurate estimation. Our model is designed
to have useful advantages: it infers distances to the k-NNs at a time, its
inference time is O(1) (no data accesses are incurred), but it keeps high
accuracy. Our experimental results and case studies on real datasets
demonstrate the efficiency and effectiveness of our solution.",https://github.com/arailly/pivnet,-1
a138c87b-473e-4d28-91ab-f2af45431f33,Streaming Adaptive Submodular Maximization,0.767535,"Many sequential decision making problems can be formulated as an adaptive
submodular maximization problem. However, most of existing studies in this
field focus on pool-based setting, where one can pick items in any order, and
there have been few studies for the stream-based setting where items arrive in
an arbitrary order and one must immediately decide whether to select an item or
not upon its arrival. In this paper, we introduce a new class of utility
functions, semi-policywise submodular functions. We develop a series of
effective algorithms to maximize a semi-policywise submodular function under
the stream-based setting.",None,-1
20bcebd5-5823-48c4-bcf5-317f50b8922a,ClarifyDelphi: Reinforced Clarification Questions with Defeasibility Rewards for Social and Moral Situations,0.268148,"Context is everything, even in commonsense moral reasoning. Changing contexts
can flip the moral judgment of an action; ""Lying to a friend"" is wrong in
general, but may be morally acceptable if it is intended to protect their life.
  We present ClarifyDelphi, an interactive system that learns to ask
clarification questions (e.g., why did you lie to your friend?) in order to
elicit additional salient contexts of a social or moral situation. We posit
that questions whose potential answers lead to diverging moral judgments are
the most informative. Thus, we propose a reinforcement learning framework with
a defeasibility reward that aims to maximize the divergence between moral
judgments of hypothetical answers to a question. Human evaluation demonstrates
that our system generates more relevant, informative and defeasible questions
compared to competitive baselines. Our work is ultimately inspired by studies
in cognitive science that have investigated the flexibility in moral cognition
(i.e., the diverse contexts in which moral rules can be bent), and we hope that
research in this direction can assist both cognitive and computational
investigations of moral judgments.",https://github.com/allenai/clarifydelphi,46374
b1a9542b-1513-40e2-9130-29b3301c18ed,Spatial Pruned Sparse Convolution for Efficient 3D Object Detection,0.92663,"3D scenes are dominated by a large number of background points, which is
redundant for the detection task that mainly needs to focus on foreground
objects. In this paper, we analyze major components of existing sparse 3D CNNs
and find that 3D CNNs ignore the redundancy of data and further amplify it in
the down-sampling process, which brings a huge amount of extra and unnecessary
computational overhead. Inspired by this, we propose a new convolution operator
named spatial pruned sparse convolution (SPS-Conv), which includes two
variants, spatial pruned submanifold sparse convolution (SPSS-Conv) and spatial
pruned regular sparse convolution (SPRS-Conv), both of which are based on the
idea of dynamically determining crucial areas for redundancy reduction. We
validate that the magnitude can serve as important cues to determine crucial
areas which get rid of the extra computations of learning-based methods. The
proposed modules can easily be incorporated into existing sparse 3D CNNs
without extra architectural modifications. Extensive experiments on the KITTI,
Waymo and nuScenes datasets demonstrate that our method can achieve more than
50% reduction in GFLOPs without compromising the performance.",None,-1
ef12cb19-3f48-4679-bbe5-acd55e04f6a3,What Do Compressed Multilingual Machine Translation Models Forget?,0.735116,"Recently, very large pre-trained models achieve state-of-the-art results in
various natural language processing (NLP) tasks, but their size makes it more
challenging to apply them in resource-constrained environments. Compression
techniques allow to drastically reduce the size of the models and therefore
their inference time with negligible impact on top-tier metrics. However, the
general performance averaged across multiple tasks and/or languages may hide a
drastic performance drop on under-represented features, which could result in
the amplification of biases encoded by the models. In this work, we assess the
impact of compression methods on Multilingual Neural Machine Translation models
(MNMT) for various language groups, gender, and semantic biases by extensive
analysis of compressed models on different machine translation benchmarks, i.e.
FLORES-101, MT-Gender, and DiBiMT. We show that the performance of
under-represented languages drops significantly, while the average BLEU metric
only slightly decreases. Interestingly, the removal of noisy memorization with
compression leads to a significant improvement for some medium-resource
languages. Finally, we demonstrate that compression amplifies intrinsic gender
and semantic biases, even in high-resource languages. Code:
https://github.com/alirezamshi/bias-compressedMT",https://github.com/alirezamshi/bias-compressedMT,-1
10fba8ea-ec06-4f5d-a718-618cb766ed75,Multimodal Image Fusion based on Hybrid CNN-Transformer and Non-local Cross-modal Attention,0.0450109,"The fusion of images taken by heterogeneous sensors helps to enrich the
information and improve the quality of imaging. In this article, we present a
hybrid model consisting of a convolutional encoder and a Transformer-based
decoder to fuse multimodal images. In the encoder, a non-local cross-modal
attention block is proposed to capture both local and global dependencies of
multiple source images. A branch fusion module is designed to adaptively fuse
the features of the two branches. We embed a Transformer module with linear
complexity in the decoder to enhance the reconstruction capability of the
proposed network. Qualitative and quantitative experiments demonstrate the
effectiveness of the proposed method by comparing it with existing
state-of-the-art fusion models. The source code of our work is available at
https://github.com/pandayuanyu/HCFusion.",https://github.com/pandayuanyu/HCFusion,4962
b88a6cdb-3cb3-4929-acb0-1a77dd5b37ea,Large Language Models Can Self-Improve,1.0,"Large Language Models (LLMs) have achieved excellent performances in various
tasks. However, fine-tuning an LLM requires extensive supervision. Human, on
the other hand, may improve their reasoning abilities by self-thinking without
external inputs. In this work, we demonstrate that an LLM is also capable of
self-improving with only unlabeled datasets. We use a pre-trained LLM to
generate ""high-confidence"" rationale-augmented answers for unlabeled questions
using Chain-of-Thought prompting and self-consistency, and fine-tune the LLM
using those self-generated solutions as target outputs. We show that our
approach improves the general reasoning ability of a 540B-parameter LLM
(74.4%->82.1% on GSM8K, 78.2%->83.0% on DROP, 90.0%->94.4% on OpenBookQA, and
63.4%->67.9% on ANLI-A3) and achieves state-of-the-art-level performance,
without any ground truth label. We conduct ablation studies and show that
fine-tuning on reasoning is critical for self-improvement.",https://github.com/google-research/google-research/tree/master/ul2,-1
2df16605-57c3-4974-b39b-30ca62f6bd35,CIRCLe: Color Invariant Representation Learning for Unbiased Classification of Skin Lesions,0.952044,"While deep learning based approaches have demonstrated expert-level
performance in dermatological diagnosis tasks, they have also been shown to
exhibit biases toward certain demographic attributes, particularly skin types
(e.g., light versus dark), a fairness concern that must be addressed. We
propose CIRCLe, a skin color invariant deep representation learning method for
improving fairness in skin lesion classification. CIRCLe is trained to classify
images by utilizing a regularization loss that encourages images with the same
diagnosis but different skin types to have similar latent representations.
Through extensive evaluation and ablation studies, we demonstrate CIRCLe's
superior performance over the state-of-the-art when evaluated on 16k+ images
spanning 6 Fitzpatrick skin types and 114 diseases, using classification
accuracy, equal opportunity difference (for light versus dark groups), and
normalized accuracy range, a new measure we propose to assess fairness on
multiple skin type groups.",https://github.com/arezou-pakzad/CIRCLe,13990
62e8472d-1de7-4290-b916-72b30ae1cc0d,Unifying Motion Deblurring and Frame Interpolation with Events,0.98419,"Slow shutter speed and long exposure time of frame-based cameras often cause
visual blur and loss of inter-frame information, degenerating the overall
quality of captured videos. To this end, we present a unified framework of
event-based motion deblurring and frame interpolation for blurry video
enhancement, where the extremely low latency of events is leveraged to
alleviate motion blur and facilitate intermediate frame prediction.
Specifically, the mapping relation between blurry frames and sharp latent
images is first predicted by a learnable double integral network, and a fusion
network is then proposed to refine the coarse results via utilizing the
information from consecutive blurry inputs and the concurrent events. By
exploring the mutual constraints among blurry frames, latent images, and event
streams, we further propose a self-supervised learning framework to enable
network training with real-world blurry videos and events. Extensive
experiments demonstrate that our method compares favorably against the
state-of-the-art approaches and achieves remarkable performance on both
synthetic and real-world datasets.",https://github.com/XiangZ-0/EVDI,-1
0e07b8bb-57e5-4deb-9072-6cf613dc2caa,Danish Airs and Grounds: A Dataset for Aerial-to-Street-Level Place Recognition and Localization,0.736403,"Place recognition and visual localization are particularly challenging in
wide baseline configurations. In this paper, we contribute with the
\emph{Danish Airs and Grounds} (DAG) dataset, a large collection of
street-level and aerial images targeting such cases. Its main challenge lies in
the extreme viewing-angle difference between query and reference images with
consequent changes in illumination and perspective. The dataset is larger and
more diverse than current publicly available data, including more than 50 km of
road in urban, suburban and rural areas. All images are associated with
accurate 6-DoF metadata that allows the benchmarking of visual localization
methods.
  We also propose a map-to-image re-localization pipeline, that first estimates
a dense 3D reconstruction from the aerial images and then matches query
street-level images to street-level renderings of the 3D model. The dataset can
be downloaded at: https://frederikwarburg.github.io/DAG",None,-1
7da45cc3-5885-4eb6-adf2-afd7fab74cfe,Negativity Spreads Faster: A Large-Scale Multilingual Twitter Analysis on the Role of Sentiment in Political Communication,0.444694,"Social media has become extremely influential when it comes to policy making
in modern societies, especially in the western world, where platforms such as
Twitter allow users to follow politicians, thus making citizens more involved
in political discussion. In the same vein, politicians use Twitter to express
their opinions, debate among others on current topics and promote their
political agendas aiming to influence voter behaviour. In this paper, we
attempt to analyse tweets of politicians from three European countries and
explore the virality of their tweets. Previous studies have shown that tweets
conveying negative sentiment are likely to be retweeted more frequently. By
utilising state-of-the-art pre-trained language models, we performed sentiment
analysis on hundreds of thousands of tweets collected from members of
parliament in Greece, Spain and the United Kingdom, including devolved
administrations. We achieved this by systematically exploring and analysing the
differences between influential and less popular tweets. Our analysis indicates
that politicians' negatively charged tweets spread more widely, especially in
more recent times, and highlights interesting differences between political
parties as well as between politicians and the general population.",https://github.com/cardiffnlp/politics-and-virality-twitter,-1
4e0feaf8-6b8e-4c67-b41a-bff53abf61c3,End-to-end Multilingual Coreference Resolution with Mention Head Prediction,0.650769,"This paper describes our approach to the CRAC 2022 Shared Task on
Multilingual Coreference Resolution. Our model is based on a state-of-the-art
end-to-end coreference resolution system. Apart from joined multilingual
training, we improved our results with mention head prediction. We also tried
to integrate dependency information into our model. Our system ended up in
$3^{rd}$ place. Moreover, we reached the best performance on two datasets out
of 13.",https://github.com/ufal/corefud-scorer,-1
209190ea-6205-481f-84c7-c796be4b46d8,Improving Robustness of Convolutional Neural Networks Using Element-Wise Activation Scaling,0.42834,"Recent works reveal that re-calibrating the intermediate activation of
adversarial examples can improve the adversarial robustness of a CNN model. The
state of the arts [Baiet al., 2021] and [Yanet al., 2021] explores this feature
at the channel level, i.e. the activation of a channel is uniformly scaled by a
factor. In this paper, we investigate the intermediate activation manipulation
at a more fine-grained level. Instead of uniformly scaling the activation, we
individually adjust each element within an activation and thus propose
Element-Wise Activation Scaling, dubbed EWAS, to improve CNNs' adversarial
robustness. Experimental results on ResNet-18 and WideResNet with CIFAR10 and
SVHN show that EWAS significantly improves the robustness accuracy. Especially
for ResNet18 on CIFAR10, EWAS increases the adversarial accuracy by 37.65% to
82.35% against C&W attack. EWAS is simple yet very effective in terms of
improving robustness. The codes are anonymously available at
https://anonymous.4open.science/r/EWAS-DD64.",https://anonymous.4open.science/r/EWAS-DD64,-1
46462065-90d2-4789-97c0-d8e326f50a37,Improved Beam Search for Hallucination Mitigation in Abstractive Summarization,0.388897,"Advancement in large pretrained language models has significantly improved
their performance for conditional language generation tasks including
summarization albeit with hallucinations. To reduce hallucinations,
conventional methods proposed improving beam search or using a fact checker as
a postprocessing step. In this paper, we investigate the use of the Natural
Language Inference (NLI) entailment metric to detect and prevent hallucinations
in summary generation. We propose an NLI-assisted beam re-ranking mechanism by
computing entailment probability scores between the input context and
summarization model-generated beams during saliency-enhanced greedy decoding.
Moreover, a diversity metric is introduced to compare its effectiveness against
vanilla beam search. Our proposed algorithm significantly outperforms vanilla
beam decoding on XSum and CNN/DM datasets.",None,-1
55b94f03-fdb0-4778-8f59-e63a7ba7bee4,TeleGraph: A Benchmark Dataset for Hierarchical Link Prediction,0.299722,"Link prediction is a key problem for network-structured data, attracting
considerable research efforts owing to its diverse applications. The current
link prediction methods focus on general networks and are overly dependent on
either the closed triangular structure of networks or node attributes. Their
performance on sparse or highly hierarchical networks has not been well
studied. On the other hand, the available tree-like benchmark datasets are
either simulated, with limited node information, or small in scale. To bridge
this gap, we present a new benchmark dataset TeleGraph, a highly sparse and
hierarchical telecommunication network associated with rich node attributes,
for assessing and fostering the link inference techniques. Our empirical
results suggest that most of the algorithms fail to produce a satisfactory
performance on a nearly tree-like dataset, which calls for special attention
when designing or deploying the link prediction algorithm in practice.",None,-1
1fb102f0-aa2a-4d18-86b2-e85f226d2cd9,Applied monocular reconstruction of parametric faces with domain engineering,0.283763,"Many modern online 3D applications and videogames rely on parametric models
of human faces for creating believable avatars. However, manual reproduction of
someone's facial likeness with a parametric model is difficult and
time-consuming. Machine Learning solution for that task is highly desirable but
is also challenging. The paper proposes a novel approach to the so-called
Face-to-Parameters problem (F2P for short), aiming to reconstruct a parametric
face from a single image. The proposed method utilizes synthetic data, domain
decomposition, and domain adaptation for addressing multifaceted challenges in
solving the F2P. The open-sourced codebase illustrates our key observations and
provides means for quantitative evaluation. The presented approach proves
practical in an industrial application; it improves accuracy and allows for
more efficient models training. The techniques have the potential to extend to
other types of parametric models.",None,567
08f4f576-36c5-44a3-96ee-ff51ea9a4f70,ST-MoE: Designing Stable and Transferable Sparse Expert Models,0.835356,"Scale has opened new frontiers in natural language processing -- but at a
high cost. In response, Mixture-of-Experts (MoE) and Switch Transformers have
been proposed as an energy efficient path to even larger and more capable
language models. But advancing the state-of-the-art across a broad set of
natural language tasks has been hindered by training instabilities and
uncertain quality during fine-tuning. Our work focuses on these issues and acts
as a design guide. We conclude by scaling a sparse model to 269B parameters,
with a computational cost comparable to a 32B dense encoder-decoder Transformer
(Stable and Transferable Mixture-of-Experts or ST-MoE-32B). For the first time,
a sparse model achieves state-of-the-art performance in transfer learning,
across a diverse set of tasks including reasoning (SuperGLUE, ARC Easy, ARC
Challenge), summarization (XSum, CNN-DM), closed book question answering
(WebQA, Natural Questions), and adversarially constructed tasks (Winogrande,
ANLI R3).",https://github.com/tensorflow/mesh/blob/master/mesh_tensorflow/transformer/moe.py,-1
41ce4987-3a4f-4fce-9416-16887b8e2427,Orders Are Unwanted: Dynamic Deep Graph Convolutional Network for Personality Detection,0.199619,"Predicting personality traits based on online posts has emerged as an
important task in many fields such as social network analysis. One of the
challenges of this task is assembling information from various posts into an
overall profile for each user. While many previous solutions simply concatenate
the posts into a long document and then encode the document by sequential or
hierarchical models, they introduce unwarranted orders for the posts, which may
mislead the models. In this paper, we propose a dynamic deep graph
convolutional network (D-DGCN) to overcome the above limitation. Specifically,
we design a learn-to-connect approach that adopts a dynamic multi-hop structure
instead of a deterministic structure, and combine it with a DGCN module to
automatically learn the connections between posts. The modules of post encoder,
learn-to-connect, and DGCN are jointly trained in an end-to-end manner.
Experimental results on the Kaggle and Pandora datasets show the superior
performance of D-DGCN to state-of-the-art baselines. Our code is available at
https://github.com/djz233/D-DGCN.",https://github.com/djz233/D-DGCN,-1
fca01e29-4788-46ff-b5ba-256b06611a27,Non-Linear Pairwise Language Mappings for Low-Resource Multilingual Acoustic Model Fusion,0.334307,"Multilingual speech recognition has drawn significant attention as an
effective way to compensate data scarcity for low-resource languages.
End-to-end (e2e) modelling is preferred over conventional hybrid systems,
mainly because of no lexicon requirement. However, hybrid DNN-HMMs still
outperform e2e models in limited data scenarios. Furthermore, the problem of
manual lexicon creation has been alleviated by publicly available trained
models of grapheme-to-phoneme (G2P) and text to IPA transliteration for a lot
of languages. In this paper, a novel approach of hybrid DNN-HMM acoustic models
fusion is proposed in a multilingual setup for the low-resource languages.
Posterior distributions from different monolingual acoustic models, against a
target language speech signal, are fused together. A separate regression neural
network is trained for each source-target language pair to transform posteriors
from source acoustic model to the target language. These networks require very
limited data as compared to the ASR training. Posterior fusion yields a
relative gain of 14.65% and 6.5% when compared with multilingual and
monolingual baselines respectively. Cross-lingual model fusion shows that the
comparable results can be achieved without using posteriors from the language
dependent ASR.",None,-1
ce10972f-09b5-433f-a1a2-0bf772bb407c,Pronunciation Modeling of Foreign Words for Mandarin ASR by Considering the Effect of Language Transfer,0.49142,"One of the challenges in automatic speech recognition is foreign words
recognition. It is observed that a speaker's pronunciation of a foreign word is
influenced by his native language knowledge, and such phenomenon is known as
the effect of language transfer. This paper focuses on examining the phonetic
effect of language transfer in automatic speech recognition. A set of lexical
rules is proposed to convert an English word into Mandarin phonetic
representation. In this way, a Mandarin lexicon can be augmented by including
English words. Hence, the Mandarin ASR system becomes capable to recognize
English words without retraining or re-estimation of the acoustic model
parameters. Using the lexicon that derived from the proposed rules, the ASR
performance of Mandarin English mixed speech is improved without harming the
accuracy of Mandarin only speech. The proposed lexical rules are generalized
and they can be directly applied to unseen English words.",None,-1
3855b7de-2d10-4790-bf26-aee9bca81c8c,Morphological Processing of Low-Resource Languages: Where We Are and What's Next,0.283779,"Automatic morphological processing can aid downstream natural language
processing applications, especially for low-resource languages, and assist
language documentation efforts for endangered languages. Having long been
multilingual, the field of computational morphology is increasingly moving
towards approaches suitable for languages with minimal or no annotated
resources. First, we survey recent developments in computational morphology
with a focus on low-resource languages. Second, we argue that the field is
ready to tackle the logical next challenge: understanding a language's
morphology from raw text alone. We perform an empirical study on a truly
unsupervised version of the paradigm completion task and show that, while
existing state-of-the-art models bridged by two newly proposed models we devise
perform reasonably, there is still much room for improvement. The stakes are
high: solving this task will increase the language coverage of morphological
resources by a number of magnitudes.",https://github.com/Adamits/tUMPC,3375
7732ff66-f07c-4a9e-ba52-5b986e39a1d6,Energy-Aware Edge Association for Cluster-based Personalized Federated Learning,0.457948,"Federated Learning (FL) over wireless network enables data-conscious services
by leveraging the ubiquitous intelligence at network edge for
privacy-preserving model training. As the proliferation of context-aware
services, the diversified personal preferences causes disagreeing conditional
distributions among user data, which leads to poor inference performance. In
this sense, clustered federated learning is proposed to group user devices with
similar preference and provide each cluster with a personalized model. This
calls for innovative design in edge association that involves user clustering
and also resource management optimization. We formulate an accuracy-cost
trade-off optimization problem by jointly considering model accuracy,
communication resource allocation and energy consumption. To comply with
parameter encryption techniques in FL, we propose an iterative solution
procedure which employs deep reinforcement learning based approach at cloud
server for edge association. The reward function consists of minimized energy
consumption at each base station and the averaged model accuracy of all users.
Under our proposed solution, multiple edge base station are fully exploited to
realize cost efficient personalized federated learning without any prior
knowledge on model parameters. Simulation results show that our proposed
strategy outperforms existing strategies in achieving accurate learning at low
energy cost.",None,-1
250d3dd7-2e16-459f-9a21-7e637a662ad6,Improving Speech Emotion Recognition Through Focus and Calibration Attention Mechanisms,0.646242,"Attention has become one of the most commonly used mechanisms in deep
learning approaches. The attention mechanism can help the system focus more on
the feature space's critical regions. For example, high amplitude regions can
play an important role for Speech Emotion Recognition (SER). In this paper, we
identify misalignments between the attention and the signal amplitude in the
existing multi-head self-attention. To improve the attention area, we propose
to use a Focus-Attention (FA) mechanism and a novel Calibration-Attention (CA)
mechanism in combination with the multi-head self-attention. Through the FA
mechanism, the network can detect the largest amplitude part in the segment. By
employing the CA mechanism, the network can modulate the information flow by
assigning different weights to each attention head and improve the utilization
of surrounding contexts. To evaluate the proposed method, experiments are
performed with the IEMOCAP and RAVDESS datasets. Experimental results show that
the proposed framework significantly outperforms the state-of-the-art
approaches on both datasets.",None,5129
a08524ba-0e58-442e-ba42-1c404f4e91b4,Scene Graph Modification as Incremental Structure Expanding,0.272233,"A scene graph is a semantic representation that expresses the objects,
attributes, and relationships between objects in a scene. Scene graphs play an
important role in many cross modality tasks, as they are able to capture the
interactions between images and texts. In this paper, we focus on scene graph
modification (SGM), where the system is required to learn how to update an
existing scene graph based on a natural language query. Unlike previous
approaches that rebuilt the entire scene graph, we frame SGM as a graph
expansion task by introducing the incremental structure expanding (ISE). ISE
constructs the target graph by incrementally expanding the source graph without
changing the unmodified structure. Based on ISE, we further propose a model
that iterates between nodes prediction and edges prediction, inferring more
accurate and harmonious expansion decisions progressively. In addition, we
construct a challenging dataset that contains more complicated queries and
larger scene graphs than existing datasets. Experiments on four benchmarks
demonstrate the effectiveness of our approach, which surpasses the previous
state-of-the-art model by large margins.",https://github.com/THU-BPM/SGM,-1
616b791f-28bb-4ac3-94cc-7db73b937379,Normal reconstruction from specularity in the endoscopic setting,0.326053,"We show that for a plane imaged by an endoscope the specular isophotes are
concentric circles on the scene plane, which appear as nested ellipses in the
image. We show that these ellipses can be detected and used to estimate the
plane's normal direction, forming a normal reconstruction method, which we
validate on simulated data. In practice, the anatomical surfaces visible in
endoscopic images are locally planar. We use our method to show that the
surface normal can thus be reconstructed for each of the numerous specularities
typically visible on moist tissues. We show results on laparoscopic and
colonoscopic images.",None,-1
42a26473-6c36-4b3b-acd1-c7db7d71ba58,Motion Policy Networks,0.754901,"Collision-free motion generation in unknown environments is a core building
block for robot manipulation. Generating such motions is challenging due to
multiple objectives; not only should the solutions be optimal, the motion
generator itself must be fast enough for real-time performance and reliable
enough for practical deployment. A wide variety of methods have been proposed
ranging from local controllers to global planners, often being combined to
offset their shortcomings. We present an end-to-end neural model called Motion
Policy Networks (M$\pi$Nets) to generate collision-free, smooth motion from
just a single depth camera observation. M$\pi$Nets are trained on over 3
million motion planning problems in over 500,000 environments. Our experiments
show that M$\pi$Nets are significantly faster than global planners while
exhibiting the reactivity needed to deal with dynamic scenes. They are 46%
better than prior neural planners and more robust than local control policies.
Despite being only trained in simulation, M$\pi$Nets transfer well to the real
robot with noisy partial point clouds. Code and data are publicly available at
https://mpinets.github.io.",https://mpinets.github.io,-1
637c37ff-13ec-4749-bb2b-616b3de94409,Deep Reinforcement Learning for Stabilization of Large-scale Probabilistic Boolean Networks,0.35901,"The ability to direct a Probabilistic Boolean Network (PBN) to a desired
state is important to applications such as targeted therapeutics in cancer
biology. Reinforcement Learning (RL) has been proposed as a framework that
solves a discrete-time optimal control problem cast as a Markov Decision
Process. We focus on an integrative framework powered by a model-free deep RL
method that can address different flavours of the control problem (e.g., with
or without control inputs; attractor state or a subset of the state space as
the target domain). The method is agnostic to the distribution of probabilities
for the next state, hence it does not use the probability transition matrix.
The time complexity is linear on the time steps, or interactions between the
agent (deep RL) and the environment (PBN), during training. Indeed, we explore
the scalability of the deep RL approach to (set) stabilization of large-scale
PBNs and demonstrate successful control on large networks, including a
metastatic melanoma PBN with 200 nodes.",https://github.com/UoS-PLCCN/pbn-rl/,-1
00f66d96-6cc4-4acb-8649-63f6a86fdd85,The Importance of Credo in Multiagent Learning,0.189882,"We propose a model for multi-objective optimization, a credo, for agents in a
system that are configured into multiple groups (i.e., teams). Our model of
credo regulates how agents optimize their behavior for the groups they belong
to. We evaluate credo in the context of challenging social dilemmas with
reinforcement learning agents. Our results indicate that the interests of
teammates, or the entire system, are not required to be fully aligned for
achieving globally beneficial outcomes. We identify two scenarios without full
common interest that achieve high equality and significantly higher mean
population rewards compared to when the interests of all agents are aligned.",https://github.com/eugenevinitsky/sequential_social_dilemma_games/,-1
9cbba103-2b4c-43f9-90ba-efdf2fae4b7f,DiVAE: Photorealistic Images Synthesis with Denoising Diffusion Decoder,0.269034,"Recently most successful image synthesis models are multi stage process to
combine the advantages of different methods, which always includes a VAE-like
model for faithfully reconstructing embedding to image and a prior model to
generate image embedding. At the same time, diffusion models have shown be
capacity to generate high-quality synthetic images. Our work proposes a VQ-VAE
architecture model with a diffusion decoder (DiVAE) to work as the
reconstructing component in image synthesis. We explore how to input image
embedding into diffusion model for excellent performance and find that simple
modification on diffusion's UNet can achieve it. Training on ImageNet, Our
model achieves state-of-the-art results and generates more photorealistic
images specifically. In addition, we apply the DiVAE with an Auto-regressive
generator on conditional synthesis tasks to perform more human-feeling and
detailed samples.",None,-1
bc57b919-cc0c-485e-a492-3eadd342ccf0,"Text and Patterns: For Effective Chain of Thought, It Takes Two to Tango",0.728393,"The past decade has witnessed dramatic gains in natural language processing
and an unprecedented scaling of large language models. These developments have
been accelerated by the advent of few-shot techniques such as chain of thought
(CoT) prompting. Specifically, CoT pushes the performance of large language
models in a few-shot setup by augmenting the prompts with intermediate steps.
Despite impressive results across various tasks, the reasons behind their
success have not been explored. This work uses counterfactual prompting to
develop a deeper understanding of CoT-based few-shot prompting mechanisms in
large language models. We first systematically identify and define the key
components of a prompt: symbols, patterns, and text. Then, we devise and
conduct an exhaustive set of experiments across four different tasks, by
querying the model with counterfactual prompts where only one of these
components is altered. Our experiments across three models (PaLM, GPT-3, and
CODEX) reveal several surprising findings and brings into question the
conventional wisdom around few-shot prompting. First, the presence of factual
patterns in a prompt is practically immaterial to the success of CoT. Second,
our results conclude that the primary role of intermediate steps may not be to
facilitate learning how to solve a task. The intermediate steps are rather a
beacon for the model to realize what symbols to replicate in the output to form
a factual answer. Further, text imbues patterns with commonsense knowledge and
meaning. Our empirical and qualitative analysis reveals that a symbiotic
relationship between text and patterns explains the success of few-shot
prompting: text helps extract commonsense from the question to help patterns,
and patterns enforce task understanding and direct text generation.",https://github.com/google-research/google-research/tree/master/l2da/learned2design,-1
72b526ca-b3cb-40ff-a25c-cb83796fe360,Proximal PanNet: A Model-Based Deep Network for Pansharpening,0.594003,"Recently, deep learning techniques have been extensively studied for
pansharpening, which aims to generate a high resolution multispectral (HRMS)
image by fusing a low resolution multispectral (LRMS) image with a high
resolution panchromatic (PAN) image. However, existing deep learning-based
pansharpening methods directly learn the mapping from LRMS and PAN to HRMS.
These network architectures always lack sufficient interpretability, which
limits further performance improvements. To alleviate this issue, we propose a
novel deep network for pansharpening by combining the model-based methodology
with the deep learning method. Firstly, we build an observation model for
pansharpening using the convolutional sparse coding (CSC) technique and design
a proximal gradient algorithm to solve this model. Secondly, we unfold the
iterative algorithm into a deep network, dubbed as Proximal PanNet, by learning
the proximal operators using convolutional neural networks. Finally, all the
learnable modules can be automatically learned in an end-to-end manner.
Experimental results on some benchmark datasets show that our network performs
better than other advanced methods both quantitatively and qualitatively.",None,-1
b24b27a8-13fc-4330-8eda-d45d4a8392e9,Searching for Structure in Unfalsifiable Claims,0.161338,"Social media platforms give rise to an abundance of posts and comments on
every topic imaginable. Many of these posts express opinions on various aspects
of society, but their unfalsifiable nature makes them ill-suited to
fact-checking pipelines. In this work, we aim to distill such posts into a
small set of narratives that capture the essential claims related to a given
topic. Understanding and visualizing these narratives can facilitate more
informed debates on social media. As a first step towards systematically
identifying the underlying narratives on social media, we introduce PAPYER, a
fine-grained dataset of online comments related to hygiene in public restrooms,
which contains a multitude of unfalsifiable claims. We present a
human-in-the-loop pipeline that uses a combination of machine and human kernels
to discover the prevailing narratives and show that this pipeline outperforms
recent large transformer models and state-of-the-art unsupervised topic models.",None,-1
31e1af43-cf9c-413c-8bb6-e586e6a5ea74,What do Models Learn From Training on More Than Text? Measuring Visual Commonsense Knowledge,0.0618474,"There are limitations in learning language from text alone. Therefore, recent
focus has been on developing multimodal models. However, few benchmarks exist
that can measure what language models learn about language from multimodal
training. We hypothesize that training on a visual modality should improve on
the visual commonsense knowledge in language models. Therefore, we introduce
two evaluation tasks for measuring visual commonsense knowledge in language
models and use them to evaluate different multimodal models and unimodal
baselines. Primarily, we find that the visual commonsense knowledge is not
significantly different between the multimodal models and unimodal baseline
models trained on visual text data.",https://github.com/lovhag/measure-visual-commonsense-knowledge,32
b8b38240-55b9-402f-842c-66247e200f17,Building an Efficiency Pipeline: Commutativity and Cumulativeness of Efficiency Operators for Transformers,0.165917,"There exists a wide variety of efficiency methods for natural language
processing (NLP) tasks, such as pruning, distillation, dynamic inference,
quantization, etc. We can consider an efficiency method as an operator applied
on a model. Naturally, we may construct a pipeline of multiple efficiency
methods, i.e., to apply multiple operators on the model sequentially. In this
paper, we study the plausibility of this idea, and more importantly, the
commutativity and cumulativeness of efficiency operators. We make two
interesting observations: (1) Efficiency operators are commutative -- the order
of efficiency methods within the pipeline has little impact on the final
results; (2) Efficiency operators are also cumulative -- the final results of
combining several efficiency methods can be estimated by combining the results
of individual methods. These observations deepen our understanding of
efficiency operators and provide useful guidelines for their real-world
applications.",None,-1
7a62e1a5-7712-43c9-8ff4-3126b437d4ab,Ontology-enhanced Prompt-tuning for Few-shot Learning,0.794797,"Few-shot Learning (FSL) is aimed to make predictions based on a limited
number of samples. Structured data such as knowledge graphs and ontology
libraries has been leveraged to benefit the few-shot setting in various tasks.
However, the priors adopted by the existing methods suffer from challenging
knowledge missing, knowledge noise, and knowledge heterogeneity, which hinder
the performance for few-shot learning. In this study, we explore knowledge
injection for FSL with pre-trained language models and propose
ontology-enhanced prompt-tuning (OntoPrompt). Specifically, we develop the
ontology transformation based on the external knowledge graph to address the
knowledge missing issue, which fulfills and converts structure knowledge to
text. We further introduce span-sensitive knowledge injection via a visible
matrix to select informative knowledge to handle the knowledge noise issue. To
bridge the gap between knowledge and text, we propose a collective training
algorithm to optimize representations jointly. We evaluate our proposed
OntoPrompt in three tasks, including relation extraction, event extraction, and
knowledge graph completion, with eight datasets. Experimental results
demonstrate that our approach can obtain better few-shot performance than
baselines.",None,-1
26d57db3-67d8-421e-9180-9fa2f75181ae,From Multi-agent to Multi-robot: A Scalable Training and Evaluation Platform for Multi-robot Reinforcement Learning,0.362493,"Multi-agent reinforcement learning (MARL) has been gaining extensive
attention from academia and industries in the past few decades. One of the
fundamental problems in MARL is how to evaluate different approaches
comprehensively. Most existing MARL methods are evaluated in either video games
or simplistic simulated scenarios. It remains unknown how these methods perform
in real-world scenarios, especially multi-robot systems. This paper introduces
a scalable emulation platform for multi-robot reinforcement learning (MRRL)
called SMART to meet this need. Precisely, SMART consists of two components: 1)
a simulation environment that provides a variety of complex interaction
scenarios for training and 2) a real-world multi-robot system for realistic
performance evaluation. Besides, SMART offers agent-environment APIs that are
plug-and-play for algorithm implementation. To illustrate the practicality of
our platform, we conduct a case study on the cooperative driving lane change
scenario. Building off the case study, we summarize several unique challenges
of MRRL, which are rarely considered previously. Finally, we open-source the
simulation environments, associated benchmark tasks, and state-of-the-art
baselines to encourage and empower MRRL research.",None,27290
ae6cef1b-e33c-441b-ad57-4de53f75ed28,Bringing NURC/SP to Digital Life: the Role of Open-source Automatic Speech Recognition Models,0.418248,"The NURC Project that started in 1969 to study the cultured linguistic urban
norm spoken in five Brazilian capitals, was responsible for compiling a large
corpus for each capital. The digitized NURC/SP comprises 375 inquiries in 334
hours of recordings taken in S\~ao Paulo capital. Although 47 inquiries have
transcripts, there was no alignment between the audio-transcription, and 328
inquiries were not transcribed. This article presents an evaluation and error
analysis of three automatic speech recognition models trained with spontaneous
speech in Portuguese and one model trained with prepared speech. The evaluation
allowed us to choose the best model, using WER and CER metrics, in a manually
aligned sample of NURC/SP, to automatically transcribe 284 hours.",https://github.com/nilc-nlp/nurc-sp,-1
eeb14ce7-06e0-4d9a-97a6-3a69c57a2852,Automatic Multi-Label Prompting: Simple and Interpretable Few-Shot Classification,0.247929,"Prompt-based learning (i.e., prompting) is an emerging paradigm for
exploiting knowledge learned by a pretrained language model. In this paper, we
propose Automatic Multi-Label Prompting (AMuLaP), a simple yet effective method
to automatically select label mappings for few-shot text classification with
prompting. Our method exploits one-to-many label mappings and a
statistics-based algorithm to select label mappings given a prompt template.
Our experiments demonstrate that AMuLaP achieves competitive performance on the
GLUE benchmark without human effort or external resources.",https://github.com/HanNight/AMuLaP,-1
ab4dee82-44c0-4d72-91b8-fea649d99587,Clinical Dialogue Transcription Error Correction using Seq2Seq Models,0.193411,"Good communication is critical to good healthcare. Clinical dialogue is a
conversation between health practitioners and their patients, with the explicit
goal of obtaining and sharing medical information. This information contributes
to medical decision-making regarding the patient and plays a crucial role in
their healthcare journey. The reliance on note taking and manual scribing
processes are extremely inefficient and leads to manual transcription errors
when digitizing notes. Automatic Speech Recognition (ASR) plays a significant
role in speech-to-text applications, and can be directly used as a text
generator in conversational applications. However, recording clinical dialogue
presents a number of general and domain-specific challenges. In this paper, we
present a seq2seq learning approach for ASR transcription error correction of
clinical dialogues. We introduce a new Gastrointestinal Clinical Dialogue (GCD)
Dataset which was gathered by healthcare professionals from a NHS Inflammatory
Bowel Disease clinic and use this in a comparative study with four commercial
ASR systems. Using self-supervision strategies, we fine-tune a seq2seq model on
a mask-filling task using a domain-specific PubMed dataset which we have shared
publicly for future research. The BART model fine-tuned for mask-filling was
able to correct transcription errors and achieve lower word error rates for
three out of four commercial ASR outputs.",None,-1
0cf1af7c-bb53-4afc-96d1-998520fa2735,Few-Shot Table-to-Text Generation with Prefix-Controlled Generator,0.102137,"Neural table-to-text generation approaches are data-hungry, limiting their
adaptation for low-resource real-world applications. Previous works mostly
resort to Pre-trained Language Models (PLMs) to generate fluent summaries of a
table. However, they often contain hallucinated contents due to the
uncontrolled nature of PLMs. Moreover, the topological differences between
tables and sequences are rarely studied. Last but not least, fine-tuning on
PLMs with a handful of instances may lead to over-fitting and catastrophic
forgetting. To alleviate these problems, we propose a prompt-based approach,
Prefix-Controlled Generator (i.e., PCG), for few-shot table-to-text generation.
We prepend a task-specific prefix for a PLM to make the table structure better
fit the pre-trained input. In addition, we generate an input-specific prefix to
control the factual contents and word order of the generated text. Both
automatic and human evaluations on different domains (humans, books and songs)
of the Wikibio dataset show substantial improvements over baseline approaches.",None,2888
9eff1a7c-5a5f-4967-ae4f-708672192f1c,Norm of Word Embedding Encodes Information Gain,0.250673,"Distributed representations of words encode lexical semantic information, but
what type of information is encoded and how? Focusing on the skip-gram with
negative-sampling method, we found that the squared norm of static word
embedding encodes the information gain conveyed by the word; the information
gain is defined by the Kullback-Leibler divergence of the co-occurrence
distribution of the word to the unigram distribution. Our findings are
explained by the theoretical framework of the exponential family of probability
distributions and confirmed through precise experiments that remove spurious
correlations arising from word frequency. This theory also extends to
contextualized word embeddings in language models or any neural networks with
the softmax output layer. We also demonstrate that both the KL divergence and
the squared norm of embedding provide a useful metric of the informativeness of
a word in tasks such as keyword extraction, proper-noun discrimination, and
hypernym discrimination.",None,-1
2dfffd70-6b8e-479f-972f-50df7e469088,Device-friendly Guava fruit and leaf disease detection using deep learning,0.314037,"This work presents a deep learning-based plant disease diagnostic system
using images of fruits and leaves. Five state-of-the-art convolutional neural
networks (CNN) have been employed for implementing the system. Hitherto model
accuracy has been the focus for such applications and model optimization has
not been accounted for the model to be applicable to end-user devices. Two
model quantization techniques such as float16 and dynamic range quantization
have been applied to the five state-of-the-art CNN architectures. The study
shows that the quantized GoogleNet model achieved the size of 0.143 MB with an
accuracy of 97%, which is the best candidate model considering the size
criterion. The EfficientNet model achieved the size of 4.2MB with an accuracy
of 99%, which is the best model considering the performance criterion. The
source codes are available at
https://github.com/CompostieAI/Guava-disease-detection.",https://github.com/CompostieAI/Guava-disease-detection,4298
5aeda20e-da53-4f55-8879-770299a1b788,"""I'm sorry to hear that"": Finding New Biases in Language Models with a Holistic Descriptor Dataset",0.855002,"As language models grow in popularity, it becomes increasingly important to
clearly measure all possible markers of demographic identity in order to avoid
perpetuating existing societal harms. Many datasets for measuring bias
currently exist, but they are restricted in their coverage of demographic axes
and are commonly used with preset bias tests that presuppose which types of
biases models can exhibit. In this work, we present a new, more inclusive bias
measurement dataset, HolisticBias, which includes nearly 600 descriptor terms
across 13 different demographic axes. HolisticBias was assembled in a
participatory process including experts and community members with lived
experience of these terms. These descriptors combine with a set of bias
measurement templates to produce over 450,000 unique sentence prompts, which we
use to explore, identify, and reduce novel forms of bias in several generative
models. We demonstrate that HolisticBias is effective at measuring previously
undetectable biases in token likelihoods from language models, as well as in an
offensiveness classifier. We will invite additions and amendments to the
dataset, which we hope will serve as a basis for more easy-to-use and
standardized methods for evaluating bias in NLP models.",https://github.com/facebookresearch/ResponsibleNLP/tree/main/holistic_bias,-1
be56591b-d054-4b71-bc94-26754ed25ab7,Empathic Conversations: A Multi-level Dataset of Contextualized Conversations,0.942892,"Empathy is a cognitive and emotional reaction to an observed situation of
others. Empathy has recently attracted interest because it has numerous
applications in psychology and AI, but it is unclear how different forms of
empathy (e.g., self-report vs counterpart other-report, concern vs. distress)
interact with other affective phenomena or demographics like gender and age. To
better understand this, we created the {\it Empathic Conversations} dataset of
annotated negative, empathy-eliciting dialogues in which pairs of participants
converse about news articles. People differ in their perception of the empathy
of others. These differences are associated with certain characteristics such
as personality and demographics. Hence, we collected detailed characterization
of the participants' traits, their self-reported empathetic response to news
articles, their conversational partner other-report, and turn-by-turn
third-party assessments of the level of self-disclosure, emotion, and empathy
expressed. This dataset is the first to present empathy in multiple forms along
with personal distress, emotion, personality characteristics, and person-level
demographic information. We present baseline models for predicting some of
these features from conversations.",https://github.com/wwbp/empathic_reactions,-1
11d6cd06-7acc-4b85-b270-75dfe138b646,Improving Low-Resource Cross-lingual Parsing with Expected Statistic Regularization,0.362526,"We present Expected Statistic Regularization (ESR), a novel regularization
technique that utilizes low-order multi-task structural statistics to shape
model distributions for semi-supervised learning on low-resource datasets. We
study ESR in the context of cross-lingual transfer for syntactic analysis (POS
tagging and labeled dependency parsing) and present several classes of
low-order statistic functions that bear on model behavior. Experimentally, we
evaluate the proposed statistics with ESR for unsupervised transfer on 5
diverse target languages and show that all statistics, when estimated
accurately, yield improvements to both POS and LAS, with the best statistic
improving POS by +7.0 and LAS by +8.5 on average. We also present
semi-supervised transfer and learning curve experiments that show ESR provides
significant gains over strong cross-lingual-transfer-plus-fine-tuning baselines
for modest amounts of label data. These results indicate that ESR is a
promising and complementary approach to model-transfer approaches for
cross-lingual parsing.",https://github.com/teffland/expected-statistic-regularization,-1
58e4acb7-ffc2-487f-8d67-120cc280502c,Neural apparent BRDF fields for multiview photometric stereo,0.44494,"We propose to tackle the multiview photometric stereo problem using an
extension of Neural Radiance Fields (NeRFs), conditioned on light source
direction. The geometric part of our neural representation predicts surface
normal direction, allowing us to reason about local surface reflectance. The
appearance part of our neural representation is decomposed into a neural
bidirectional reflectance function (BRDF), learnt as part of the fitting
process, and a shadow prediction network (conditioned on light source
direction) allowing us to model the apparent BRDF. This balance of learnt
components with inductive biases based on physical image formation models
allows us to extrapolate far from the light source and viewer directions
observed during training. We demonstrate our approach on a multiview
photometric stereo benchmark and show that competitive performance can be
obtained with the neural density representation of a NeRF.",None,-1
f104536c-87cf-4bb1-8057-6c26bbdc6364,Online Segmentation of LiDAR Sequences: Dataset and Algorithm,0.537489,"Roof-mounted spinning LiDAR sensors are widely used by autonomous vehicles.
However, most semantic datasets and algorithms used for LiDAR sequence
segmentation operate on $360^\circ$ frames, causing an acquisition latency
incompatible with real-time applications. To address this issue, we first
introduce HelixNet, a $10$ billion point dataset with fine-grained labels,
timestamps, and sensor rotation information necessary to accurately assess the
real-time readiness of segmentation algorithms. Second, we propose Helix4D, a
compact and efficient spatio-temporal transformer architecture specifically
designed for rotating LiDAR sequences. Helix4D operates on acquisition slices
corresponding to a fraction of a full sensor rotation, significantly reducing
the total latency. Helix4D reaches accuracy on par with the best segmentation
algorithms on HelixNet and SemanticKITTI with a reduction of over $5\times$ in
terms of latency and $50\times$ in model size. The code and data are available
at: https://romainloiseau.fr/helixnet",https://romainloiseau.fr/helixnet,-1
5bc79b31-312d-43d3-8af3-55b76d65b165,MusIAC: An extensible generative framework for Music Infilling Applications with multi-level Control,0.148334,"We present a novel music generation framework for music infilling, with a
user friendly interface. Infilling refers to the task of generating musical
sections given the surrounding multi-track music. The proposed
transformer-based framework is extensible for new control tokens as the added
music control tokens such as tonal tension per bar and track polyphony level in
this work. We explore the effects of including several musically meaningful
control tokens, and evaluate the results using objective metrics related to
pitch and rhythm. Our results demonstrate that adding additional control tokens
helps to generate music with stronger stylistic similarities to the original
music. It also provides the user with more control to change properties like
the music texture and tonal tension in each bar compared to previous research
which only provided control for track density. We present the model in a Google
Colab notebook to enable interactive generation.",https://github.com/ruiguo-bio/MusIAC,-1
976381f0-85c6-441c-9a7c-6f066b9f5aea,Passage-Mask: A Learnable Regularization Strategy for Retriever-Reader Models,0.213508,"Retriever-reader models achieve competitive performance across many different
NLP tasks such as open question answering and dialogue conversations. In this
work, we notice these models easily overfit the top-rank retrieval passages and
standard training fails to reason over the entire retrieval passages. We
introduce a learnable passage mask mechanism which desensitizes the impact from
the top-rank retrieval passages and prevents the model from overfitting.
Controlling the gradient variance with fewer mask candidates and selecting the
mask candidates with one-shot bi-level optimization, our learnable
regularization strategy enforces the answer generation to focus on the entire
retrieval passages. Experiments on different tasks across open question
answering, dialogue conversation, and fact verification show that our method
consistently outperforms its baselines. Extensive experiments and ablation
studies demonstrate that our method can be general, effective, and beneficial
for many NLP tasks.",https://github.com/facebookresearch/FiD,-1
2bc7e5d6-ca2d-452b-812b-8dfa35f33326,Multiscale Analysis for Improving Texture Classification,0.562578,"Information from an image occurs over multiple and distinct spatial scales.
Image pyramid multiresolution representations are a useful data structure for
image analysis and manipulation over a spectrum of spatial scales. This paper
employs the Gaussian-Laplacian pyramid to treat different spatial frequency
bands of a texture separately. First, we generate three images corresponding to
three levels of the Gaussian-Laplacian pyramid for an input image to capture
intrinsic details. Then we aggregate features extracted from gray and color
texture images using bio-inspired texture descriptors, information-theoretic
measures, gray-level co-occurrence matrix features, and Haralick statistical
features into a single feature vector. Such an aggregation aims at producing
features that characterize textures to their maximum extent, unlike employing
each descriptor separately, which may lose some relevant textural information
and reduce the classification performance. The experimental results on texture
and histopathologic image datasets have shown the advantages of the proposed
method compared to state-of-the-art approaches. Such findings emphasize the
importance of multiscale image analysis and corroborate that the descriptors
mentioned above are complementary.",None,-1
2bd86f18-4d0f-4db0-9486-d037e9d2373c,Omnigrok: Grokking Beyond Algorithmic Data,0.53064,"Grokking, the unusual phenomenon for algorithmic datasets where
generalization happens long after overfitting the training data, has remained
elusive. We aim to understand grokking by analyzing the loss landscapes of
neural networks, identifying the mismatch between training and test losses as
the cause for grokking. We refer to this as the ""LU mechanism"" because training
and test losses (against model weight norm) typically resemble ""L"" and ""U"",
respectively. This simple mechanism can nicely explain many aspects of
grokking: data size dependence, weight decay dependence, the emergence of
representations, etc. Guided by the intuitive picture, we are able to induce
grokking on tasks involving images, language and molecules. In the reverse
direction, we are able to eliminate grokking for algorithmic datasets. We
attribute the dramatic nature of grokking for algorithmic datasets to
representation learning.",https://github.com/KindXiaoming/Omnigrok,-1
0185766d-2894-49b9-831b-c7116bb89d62,Semiconductor Defect Pattern Classification by Self-Proliferation-and-Attention Neural Network,0.364209,"Semiconductor manufacturing is on the cusp of a revolution: the Internet of
Things (IoT). With IoT we can connect all the equipment and feed information
back to the factory so that quality issues can be detected. In this situation,
more and more edge devices are used in wafer inspection equipment. This edge
device must have the ability to quickly detect defects. Therefore, how to
develop a high-efficiency architecture for automatic defect classification to
be suitable for edge devices is the primary task. In this paper, we present a
novel architecture that can perform defect classification in a more efficient
way. The first function is self-proliferation, using a series of linear
transformations to generate more feature maps at a cheaper cost. The second
function is self-attention, capturing the long-range dependencies of feature
map by the channel-wise and spatial-wise attention mechanism. We named this
method as self-proliferation-and-attention neural network. This method has been
successfully applied to various defect pattern classification tasks. Compared
with other latest methods, SP&A-Net has higher accuracy and lower computation
cost in many defect inspection tasks.",https://github.com/Yfyangd/SPA,7483
5e9a6c65-76fd-44c7-b4d4-d7cf3d6b23df,Real Time Egocentric Segmentation for Video-self Avatar in Mixed Reality,0.6145,"In this work we present our real-time egocentric body segmentation algorithm.
Our algorithm achieves a frame rate of 66 fps for an input resolution of
640x480, thanks to our shallow network inspired in Thundernet's architecture.
Besides, we put a strong emphasis on the variability of the training data. More
concretely, we describe the creation process of our Egocentric Bodies
(EgoBodies) dataset, composed of almost 10,000 images from three datasets,
created both from synthetic methods and real capturing. We conduct experiments
to understand the contribution of the individual datasets; compare Thundernet
model trained with EgoBodies with simpler and more complex previous approaches
and discuss their corresponding performance in a real-life setup in terms of
segmentation quality and inference times. The described trained semantic
segmentation algorithm is already integrated in an end-to-end system for Mixed
Reality (MR), making it possible for users to see his/her own body while being
immersed in a MR scene.",None,-1
345873d9-9d45-46b3-a538-048f5a4a867b,Deep Speech Based End-to-End Automated Speech Recognition (ASR) for Indian-English Accents,0.345501,"Automated Speech Recognition (ASR) is an interdisciplinary application of
computer science and linguistics that enable us to derive the transcription
from the uttered speech waveform. It finds several applications in Military
like High-performance fighter aircraft, helicopters, air-traffic controller.
Other than military speech recognition is used in healthcare, persons with
disabilities and many more. ASR has been an active research area. Several
models and algorithms for speech to text (STT) have been proposed. One of the
most recent is Mozilla Deep Speech, it is based on the Deep Speech research
paper by Baidu. Deep Speech is a state-of-art speech recognition system is
developed using end-to-end deep learning, it is trained using well-optimized
Recurrent Neural Network (RNN) training system utilizing multiple Graphical
Processing Units (GPUs). This training is mostly done using American-English
accent datasets, which results in poor generalizability to other English
accents. India is a land of vast diversity. This can even be seen in the
speech, there are several English accents which vary from state to state. In
this work, we have used transfer learning approach using most recent Deep
Speech model i.e., deepspeech-0.9.3 to develop an end-to-end speech recognition
system for Indian-English accents. This work utilizes fine-tuning and data
argumentation to further optimize and improve the Deep Speech ASR system. Indic
TTS data of Indian-English accents is used for transfer learning and
fine-tuning the pre-trained Deep Speech model. A general comparison is made
among the untrained model, our trained model and other available speech
recognition services for Indian-English Accents.",None,15
3a4e42ce-0a03-4420-9288-45566cf95fa6,HIT at SemEval-2022 Task 2: Pre-trained Language Model for Idioms Detection,0.0379321,"The same multi-word expressions may have different meanings in different
sentences. They can be mainly divided into two categories, which are literal
meaning and idiomatic meaning. Non-contextual-based methods perform poorly on
this problem, and we need contextual embedding to understand the idiomatic
meaning of multi-word expressions correctly. We use a pre-trained language
model, which can provide a context-aware sentence embedding, to detect whether
multi-word expression in the sentence is idiomatic usage.",None,-1
a4f83f9f-cda6-418f-8fc5-e6580fb67b8a,Coreference Resolution through a seq2seq Transition-Based System,0.508337,"Most recent coreference resolution systems use search algorithms over
possible spans to identify mentions and resolve coreference. We instead present
a coreference resolution system that uses a text-to-text (seq2seq) paradigm to
predict mentions and links jointly. We implement the coreference system as a
transition system and use multilingual T5 as an underlying language model. We
obtain state-of-the-art accuracy on the CoNLL-2012 datasets with 83.3 F1-score
for English (a 2.3 higher F1-score than previous work (Dobrovolskii, 2021))
using only CoNLL data for training, 68.5 F1-score for Arabic (+4.1 higher than
previous work) and 74.3 F1-score for Chinese (+5.3). In addition we use the
SemEval-2010 data sets for experiments in the zero-shot setting, a few-shot
setting, and supervised setting using all available training data. We get
substantially higher zero-shot F1-scores for 3 out of 4 languages than previous
approaches and significantly exceed previous supervised state-of-the-art
results for all five tested languages.",https://github.com/google-research/coref_mt5,-1
a36f896c-4dbd-416f-b841-6818b3a3182f,Towards Responsible AI for Financial Transactions,0.230077,"The application of AI in finance is increasingly dependent on the principles
of responsible AI. These principles - explainability, fairness, privacy,
accountability, transparency and soundness form the basis for trust in future
AI systems. In this study, we address the first principle by providing an
explanation for a deep neural network that is trained on a mixture of
numerical, categorical and textual inputs for financial transaction
classification. The explanation is achieved through (1) a feature importance
analysis using Shapley additive explanations (SHAP) and (2) a hybrid approach
of text clustering and decision tree classifiers. We then test the robustness
of the model by exposing it to a targeted evasion attack, leveraging the
knowledge we gained about the model through the extracted explanation.",None,-1
72b64e52-9709-418f-aee6-91083af56845,Differentiable Data Augmentation for Contrastive Sentence Representation Learning,0.168884,"Fine-tuning a pre-trained language model via the contrastive learning
framework with a large amount of unlabeled sentences or labeled sentence pairs
is a common way to obtain high-quality sentence representations. Although the
contrastive learning framework has shown its superiority on sentence
representation learning over previous methods, the potential of such a
framework is under-explored so far due to the simple method it used to
construct positive pairs. Motivated by this, we propose a method that makes
hard positives from the original training examples. A pivotal ingredient of our
approach is the use of prefix that is attached to a pre-trained language model,
which allows for differentiable data augmentation during contrastive learning.
Our method can be summarized in two steps: supervised prefix-tuning followed by
joint contrastive fine-tuning with unlabeled or labeled examples. Our
experiments confirm the effectiveness of our data augmentation approach. The
proposed method yields significant improvements over existing methods under
both semi-supervised and supervised settings. Our experiments under a low
labeled data setting also show that our method is more label-efficient than the
state-of-the-art contrastive learning methods.",https://github.com/TianduoWang/DiffAug,-1
04d3b443-5570-42c0-88ed-b000f107b7f3,Label-Driven Denoising Framework for Multi-Label Few-Shot Aspect Category Detection,0.290915,"Multi-Label Few-Shot Aspect Category Detection (FS-ACD) is a new sub-task of
aspect-based sentiment analysis, which aims to detect aspect categories
accurately with limited training instances. Recently, dominant works use the
prototypical network to accomplish this task, and employ the attention
mechanism to extract keywords of aspect category from the sentences to produce
the prototype for each aspect. However, they still suffer from serious noise
problems: (1) due to lack of sufficient supervised data, the previous methods
easily catch noisy words irrelevant to the current aspect category, which
largely affects the quality of the generated prototype; (2) the
semantically-close aspect categories usually generate similar prototypes, which
are mutually noisy and confuse the classifier seriously. In this paper, we
resort to the label information of each aspect to tackle the above problems,
along with proposing a novel Label-Driven Denoising Framework (LDF). Extensive
experimental results show that our framework achieves better performance than
other state-of-the-art methods.",https://github.com/1429904852/LDF,4048
4fc99a62-49d7-4dee-bf8e-db326e685527,Beyond the Granularity: Multi-Perspective Dialogue Collaborative Selection for Dialogue State Tracking,0.304535,"In dialogue state tracking, dialogue history is a crucial material, and its
utilization varies between different models. However, no matter how the
dialogue history is used, each existing model uses its own consistent dialogue
history during the entire state tracking process, regardless of which slot is
updated. Apparently, it requires different dialogue history to update different
slots in different turns. Therefore, using consistent dialogue contents may
lead to insufficient or redundant information for different slots, which
affects the overall performance. To address this problem, we devise DiCoS-DST
to dynamically select the relevant dialogue contents corresponding to each slot
for state updating. Specifically, it first retrieves turn-level utterances of
dialogue history and evaluates their relevance to the slot from a combination
of three perspectives: (1) its explicit connection to the slot name; (2) its
relevance to the current turn dialogue; (3) Implicit Mention Oriented
Reasoning. Then these perspectives are combined to yield a decision, and only
the selected dialogue contents are fed into State Generator, which explicitly
minimizes the distracting information passed to the downstream state
prediction. Experimental results show that our approach achieves new
state-of-the-art performance on MultiWOZ 2.1 and MultiWOZ 2.2, and achieves
superior performance on multiple mainstream benchmark datasets (including
Sim-M, Sim-R, and DSTC2).",https://github.com/guojinyu88/DiCoS-master,-1
809d689d-d039-4082-a5a8-11df3116e6b5,An End-to-End Transformer Model for Crowd Localization,0.619025,"Crowd localization, predicting head positions, is a more practical and
high-level task than simply counting. Existing methods employ pseudo-bounding
boxes or pre-designed localization maps, relying on complex post-processing to
obtain the head positions. In this paper, we propose an elegant, end-to-end
Crowd Localization Transformer named CLTR that solves the task in the
regression-based paradigm. The proposed method views the crowd localization as
a direct set prediction problem, taking extracted features and trainable
embeddings as input of the transformer-decoder. To reduce the ambiguous points
and generate more reasonable matching results, we introduce a KMO-based
Hungarian matcher, which adopts the nearby context as the auxiliary matching
cost. Extensive experiments conducted on five datasets in various data settings
show the effectiveness of our method. In particular, the proposed method
achieves the best localization performance on the NWPU-Crowd, UCF-QNRF, and
ShanghaiTech Part A datasets.",https://dk-liang.github.io/CLTR/,-1
4966d118-6278-439a-b5cf-03f6da254ae1,Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind,0.934603,"When reading a story, humans can quickly understand new fictional characters
with a few observations, mainly by drawing analogies to fictional and real
people they already know. This reflects the few-shot and meta-learning essence
of humans' inference of characters' mental states, i.e., theory-of-mind (ToM),
which is largely ignored in existing research. We fill this gap with a novel
NLP dataset, ToM-in-AMC, the first assessment of machines' meta-learning of ToM
in a realistic narrative understanding scenario. Our dataset consists of ~1,000
parsed movie scripts, each corresponding to a few-shot character understanding
task that requires models to mimic humans' ability of fast digesting characters
with a few starting scenes in a new movie.
  We propose a novel ToM prompting approach designed to explicitly assess the
influence of multiple ToM dimensions. It surpasses existing baseline models,
underscoring the significance of modeling multiple ToM dimensions for our task.
Our extensive human study verifies that humans are capable of solving our
problem by inferring characters' mental states based on their previously seen
movies. In comparison, our systems based on either state-of-the-art large
language models (GPT-4) or meta-learning algorithms lags >20% behind,
highlighting a notable limitation in existing approaches' ToM capabilities.",None,-1
90f18f7b-ddd6-49c6-ab77-1b196cc0e213,CTI4AI: Threat Intelligence Generation and Sharing after Red Teaming AI Models,0.174673,"As the practicality of Artificial Intelligence (AI) and Machine Learning (ML)
based techniques grow, there is an ever increasing threat of adversarial
attacks. There is a need to red team this ecosystem to identify system
vulnerabilities, potential threats, characterize properties that will enhance
system robustness, and encourage the creation of effective defenses. A
secondary need is to share this AI security threat intelligence between
different stakeholders like, model developers, users, and AI/ML security
professionals. In this paper, we create and describe a prototype system CTI4AI,
to overcome the need to methodically identify and share AI/ML specific
vulnerabilities and threat intelligence.",None,-1
16f023e3-a6a2-4470-9eb1-6080b95ab37c,GIFS: Neural Implicit Function for General Shape Representation,0.844034,"Recent development of neural implicit function has shown tremendous success
on high-quality 3D shape reconstruction. However, most works divide the space
into inside and outside of the shape, which limits their representing power to
single-layer and watertight shapes. This limitation leads to tedious data
processing (converting non-watertight raw data to watertight) as well as the
incapability of representing general object shapes in the real world. In this
work, we propose a novel method to represent general shapes including
non-watertight shapes and shapes with multi-layer surfaces. We introduce
General Implicit Function for 3D Shape (GIFS), which models the relationships
between every two points instead of the relationships between points and
surfaces. Instead of dividing 3D space into predefined inside-outside regions,
GIFS encodes whether two points are separated by any surface. Experiments on
ShapeNet show that GIFS outperforms previous state-of-the-art methods in terms
of reconstruction quality, rendering efficiency, and visual fidelity. Project
page is available at https://jianglongye.com/gifs .",https://jianglongye.com/gifs,25908
d3777a43-c405-48ad-acaf-ff308358c5ed,AnimeRun: 2D Animation Visual Correspondence from Open Source 3D Movies,0.483183,"Existing correspondence datasets for two-dimensional (2D) cartoon suffer from
simple frame composition and monotonic movements, making them insufficient to
simulate real animations. In this work, we present a new 2D animation visual
correspondence dataset, AnimeRun, by converting open source three-dimensional
(3D) movies to full scenes in 2D style, including simultaneous moving
background and interactions of multiple subjects. Our analyses show that the
proposed dataset not only resembles real anime more in image composition, but
also possesses richer and more complex motion patterns compared to existing
datasets. With this dataset, we establish a comprehensive benchmark by
evaluating several existing optical flow and segment matching methods, and
analyze shortcomings of these methods on animation data. Data, code and other
supplementary materials are available at
https://lisiyao21.github.io/projects/AnimeRun.",https://github.com/lisiyao21/AnimeRun,-1
059a0bca-5d2c-4306-ab5b-9d588b2ac501,Synthesizing Personalized Non-speech Vocalization from Discrete Speech Representations,0.684499,"We formulated non-speech vocalization (NSV) modeling as a text-to-speech task
and verified its viability. Specifically, we evaluated the phonetic
expressivity of HUBERT speech units on NSVs and verified our model's ability to
control over speaker timbre even though the training data is speaker few-shot.
In addition, we substantiated that the heterogeneity in recording conditions is
the major obstacle for NSV modeling. Finally, we discussed five improvements
over our method for future research. Audio samples of synthesized NSVs are
available on our demo page: https://resemble-ai.github.io/reLaugh.",None,4373
7949e384-e5d6-4ae3-99e8-4fc6e1e06196,Imagination-Augmented Natural Language Understanding,0.86367,"Human brains integrate linguistic and perceptual information simultaneously
to understand natural language, and hold the critical ability to render
imaginations. Such abilities enable us to construct new abstract concepts or
concrete objects, and are essential in involving practical knowledge to solve
problems in low-resource scenarios. However, most existing methods for Natural
Language Understanding (NLU) are mainly focused on textual signals. They do not
simulate human visual imagination ability, which hinders models from inferring
and learning efficiently from limited data samples. Therefore, we introduce an
Imagination-Augmented Cross-modal Encoder (iACE) to solve natural language
understanding tasks from a novel learning perspective -- imagination-augmented
cross-modal understanding. iACE enables visual imagination with external
knowledge transferred from the powerful generative and pre-trained
vision-and-language models. Extensive experiments on GLUE and SWAG show that
iACE achieves consistent improvement over visually-supervised pre-trained
models. More importantly, results in extreme and normal few-shot settings
validate the effectiveness of iACE in low-resource natural language
understanding circumstances.",https://github.com/YujieLu10/IACE-NLU,-1
878aedf5-ca59-4dc6-87e4-7a26c4c7ac8e,Indian Commercial Truck License Plate Detection and Recognition for Weighbridge Automation,0.335434,"Detection and recognition of a licence plate is important when automating
weighbridge services. While many large databases are available for Latin and
Chinese alphanumeric license plates, data for Indian License Plates is
inadequate. In particular, databases of Indian commercial truck license plates
are inadequate, despite the fact that commercial vehicle license plate
recognition plays a profound role in terms of logistics management and
weighbridge automation. Moreover, models to recognise license plates are not
effectively able to generalise to such data due to its challenging nature, and
due to the abundant frequency of handwritten license plates, leading to the
usage of diverse font styles. Thus, a database and effective models to
recognise and detect such license plates are crucial. This paper provides a
database on commercial truck license plates, and using state-of-the-art models
in real-time object Detection: You Only Look Once Version 7, and SceneText
Recognition: Permuted Autoregressive Sequence Models, our method outperforms
the other cited references where the maximum accuracy obtained was less than
90%, while we have achieved 95.82% accuracy in our algorithm implementation on
the presented challenging license plate dataset. Index Terms- Automatic License
Plate Recognition, character recognition, license plate detection, vision
transformer.",None,-1
9d37b7e3-62a9-437b-bb4a-0766a78402cf,A Song of (Dis)agreement: Evaluating the Evaluation of Explainable Artificial Intelligence in Natural Language Processing,0.570345,"There has been significant debate in the NLP community about whether or not
attention weights can be used as an explanation - a mechanism for interpreting
how important each input token is for a particular prediction. The validity of
""attention as explanation"" has so far been evaluated by computing the rank
correlation between attention-based explanations and existing feature
attribution explanations using LSTM-based models. In our work, we (i) compare
the rank correlation between five more recent feature attribution methods and
two attention-based methods, on two types of NLP tasks, and (ii) extend this
analysis to also include transformer-based models. We find that attention-based
explanations do not correlate strongly with any recent feature attribution
methods, regardless of the model or task. Furthermore, we find that none of the
tested explanations correlate strongly with one another for the
transformer-based model, leading us to question the underlying assumption that
we should measure the validity of attention-based explanations based on how
well they correlate with existing feature attribution explanation methods.
After conducting experiments on five datasets using two different models, we
argue that the community should stop using rank correlation as an evaluation
metric for attention-based explanations. We suggest that researchers and
practitioners should instead test various explanation methods and employ a
human-in-the-loop process to determine if the explanations align with human
intuition for the particular use case at hand.",None,-1
17833094-4e43-4b5c-b96a-bd21d97f6ff6,Joint covariate-alignment and concept-alignment: a framework for domain generalization,0.182522,"In this paper, we propose a novel domain generalization (DG) framework based
on a new upper bound to the risk on the unseen domain. Particularly, our
framework proposes to jointly minimize both the covariate-shift as well as the
concept-shift between the seen domains for a better performance on the unseen
domain. While the proposed approach can be implemented via an arbitrary
combination of covariate-alignment and concept-alignment modules, in this work
we use well-established approaches for distributional alignment namely, Maximum
Mean Discrepancy (MMD) and covariance Alignment (CORAL), and use an Invariant
Risk Minimization (IRM)-based approach for concept alignment. Our numerical
results show that the proposed methods perform as well as or better than the
state-of-the-art for domain generalization on several data sets.",https://github.com/thuan2412/Joint-covariate-alignment-and-concept-alignment-for-domain-generalization,12938
b5e4c6ba-4bbe-4b08-8079-451ca2efe3f1,Evidential Temporal-aware Graph-based Social Event Detection via Dempster-Shafer Theory,0.458979,"The rising popularity of online social network services has attracted lots of
research on mining social media data, especially on mining social events.
Social event detection, due to its wide applications, has now become a trivial
task. State-of-the-art approaches exploiting Graph Neural Networks (GNNs)
usually follow a two-step strategy: 1) constructing text graphs based on
various views (\textit{co-user}, \textit{co-entities} and
\textit{co-hashtags}); and 2) learning a unified text representation by a
specific GNN model. Generally, the results heavily rely on the quality of the
constructed graphs and the specific message passing scheme. However, existing
methods have deficiencies in both aspects: 1) They fail to recognize the noisy
information induced by unreliable views. 2) Temporal information which works as
a vital indicator of events is neglected in most works. To this end, we propose
ETGNN, a novel Evidential Temporal-aware Graph Neural Network. Specifically, we
construct view-specific graphs whose nodes are the texts and edges are
determined by several types of shared elements respectively. To incorporate
temporal information into the message passing scheme, we introduce a novel
temporal-aware aggregator which assigns weights to neighbours according to an
adaptive time exponential decay formula. Considering the view-specific
uncertainty, the representations of all views are converted into mass functions
through evidential deep learning (EDL) neural networks, and further combined
via Dempster-Shafer theory (DST) to make the final detection. Experimental
results on three real-world datasets demonstrate the effectiveness of ETGNN in
accuracy, reliability and robustness in social event detection.",None,-1
75e36924-b686-4e38-a68a-5c1ef3256ea9,Can Requirements Engineering Support Explainable Artificial Intelligence? Towards a User-Centric Approach for Explainability Requirements,0.508468,"With the recent proliferation of artificial intelligence systems, there has
been a surge in the demand for explainability of these systems. Explanations
help to reduce system opacity, support transparency, and increase stakeholder
trust. In this position paper, we discuss synergies between requirements
engineering (RE) and Explainable AI (XAI). We highlight challenges in the field
of XAI, and propose a framework and research directions on how RE practices can
help to mitigate these challenges.",None,-1
3f09c125-8402-456d-be23-29ea2f7b0848,Mitigating spectral bias for the multiscale operator learning with hierarchical attention,0.270617,"Neural operators have emerged as a powerful tool for learning the mapping
between infinite-dimensional parameter and solution spaces of partial
differential equations (PDEs). In this work, we focus on multiscale PDEs that
have important applications such as reservoir modeling and turbulence
prediction. We demonstrate that for such PDEs, the spectral bias towards
low-frequency components presents a significant challenge for existing neural
operators. To address this challenge, we propose a hierarchical attention
neural operator (HANO) inspired by the hierarchical matrix approach. HANO
features a scale-adaptive interaction range and self-attentions over a
hierarchy of levels, enabling nested feature computation with controllable
linear cost and encoding/decoding of multiscale solution space. We also
incorporate an empirical $H^1$ loss function to enhance the learning of
high-frequency components. Our numerical experiments demonstrate that HANO
outperforms state-of-the-art (SOTA) methods for representative multiscale
problems.",https://github.com/zongyi-li/fourier_neural_operator/,-1
31c9d5c8-37af-48d9-9765-e7773257d97f,Emergent Bartering Behaviour in Multi-Agent Reinforcement Learning,0.801799,"Advances in artificial intelligence often stem from the development of new
environments that abstract real-world situations into a form where research can
be done conveniently. This paper contributes such an environment based on ideas
inspired by elementary Microeconomics. Agents learn to produce resources in a
spatially complex world, trade them with one another, and consume those that
they prefer. We show that the emergent production, consumption, and pricing
behaviors respond to environmental conditions in the directions predicted by
supply and demand shifts in Microeconomics. We also demonstrate settings where
the agents' emergent prices for goods vary over space, reflecting the local
abundance of goods. After the price disparities emerge, some agents then
discover a niche of transporting goods between regions with different
prevailing prices -- a profitable strategy because they can buy goods where
they are cheap and sell them where they are expensive. Finally, in a series of
ablation experiments, we investigate how choices in the environmental rewards,
bartering actions, agent architecture, and ability to consume tradable goods
can either aid or inhibit the emergence of this economic behavior. This work is
part of the environment development branch of a research program that aims to
build human-like artificial general intelligence through multi-agent
interactions in simulated societies. By exploring which environment features
are needed for the basic phenomena of elementary microeconomics to emerge
automatically from learning, we arrive at an environment that differs from
those studied in prior multi-agent reinforcement learning work along several
dimensions. For example, the model incorporates heterogeneous tastes and
physical abilities, and agents negotiate with one another as a grounded form of
communication.",https://github.com/deepmind/meltingpot,-1
6b57ee63-d156-4314-b93c-8fa7e23127b1,SPA-VAE: Similar-Parts-Assignment for Unsupervised 3D Point Cloud Generation,0.112796,"This paper addresses the problem of unsupervised parts-aware point cloud
generation with learned parts-based self-similarity. Our SPA-VAE infers a set
of latent canonical candidate shapes for any given object, along with a set of
rigid body transformations for each such candidate shape to one or more
locations within the assembled object. In this way, noisy samples on the
surface of, say, each leg of a table, are effectively combined to estimate a
single leg prototype. When parts-based self-similarity exists in the raw data,
sharing data among parts in this way confers numerous advantages: modeling
accuracy, appropriately self-similar generative outputs, precise in-filling of
occlusions, and model parsimony. SPA-VAE is trained end-to-end using a
variational Bayesian approach which uses the Gumbel-softmax trick for the
shared part assignments, along with various novel losses to provide appropriate
inductive biases. Quantitative and qualitative analyses on ShapeNet demonstrate
the advantage of SPA-VAE.",None,-1
8bc01110-5817-4ae3-98e4-e332cbaa930c,Multiple Domain Cyberspace Attack and Defense Game Based on Reward Randomization Reinforcement Learning,0.981684,"The existing network attack and defense method can be regarded as game, but
most of the game only involves network domain, not multiple domain cyberspace.
To address this challenge, this paper proposed a multiple domain cyberspace
attack and defense game model based on reinforcement learning. We define the
multiple domain cyberspace include physical domain, network domain and digital
domain. By establishing two agents, representing the attacker and the defender
respectively, defender will select the multiple domain actions in the multiple
domain cyberspace to obtain defender's optimal reward by reinforcement
learning. In order to improve the defense ability of defender, a game model
based on reward randomization reinforcement learning is proposed. When the
defender takes the multiple domain defense action, the reward is randomly given
and subject to linear distribution, so as to find the better defense policy and
improve defense success rate. The experimental results show that the game model
can effectively simulate the attack and defense state of multiple domain
cyberspace, and the proposed method has a higher defense success rate than DDPG
and DQN.",None,-1
0b794819-2689-40ee-a00c-4b17ec1e8e79,Learning Instance Representation Banks for Aerial Scene Classification,0.0929922,"Aerial scenes are more complicated in terms of object distribution and
spatial arrangement than natural scenes due to the bird view, and thus remain
challenging to learn discriminative scene representation. Recent solutions
design \textit{local semantic descriptors} so that region of interests (RoIs)
can be properly highlighted. However, each local descriptor has limited
description capability and the overall scene representation remains to be
refined. In this paper, we solve this problem by designing a novel
representation set named \textit{instance representation bank} (IRB), which
unifies multiple local descriptors under the multiple instance learning (MIL)
formulation. This unified framework is not trivial as all the local semantic
descriptors can be aligned to the same scene scheme, enhancing the scene
representation capability. Specifically, our IRB learning framework consists of
a backbone, an instance representation bank, a semantic fusion module and a
scene scheme alignment loss function. All the components are organized in an
end-to-end manner. Extensive experiments on three aerial scene benchmarks
demonstrate that our proposed method outperforms the state-of-the-art
approaches by a large margin.",None,-1
c5cc417f-6a84-45cc-b366-3e58bd6f2c32,Deep Generalized Unfolding Networks for Image Restoration,0.998185,"Deep neural networks (DNN) have achieved great success in image restoration.
However, most DNN methods are designed as a black box, lacking transparency and
interpretability. Although some methods are proposed to combine traditional
optimization algorithms with DNN, they usually demand pre-defined degradation
processes or handcrafted assumptions, making it difficult to deal with complex
and real-world applications. In this paper, we propose a Deep Generalized
Unfolding Network (DGUNet) for image restoration. Concretely, without loss of
interpretability, we integrate a gradient estimation strategy into the gradient
descent step of the Proximal Gradient Descent (PGD) algorithm, driving it to
deal with complex and real-world image degradation. In addition, we design
inter-stage information pathways across proximal mapping in different PGD
iterations to rectify the intrinsic information loss in most deep unfolding
networks (DUN) through a multi-scale and spatial-adaptive way. By integrating
the flexible gradient descent and informative proximal mapping, we unfold the
iterative PGD algorithm into a trainable DNN. Extensive experiments on various
image restoration tasks demonstrate the superiority of our method in terms of
state-of-the-art performance, interpretability, and generalizability. The
source code is available at
https://github.com/MC-E/Deep-Generalized-Unfolding-Networks-for-Image-Restoration.",https://github.com/MC-E/DGUNet,-1
73b4951c-69d3-446f-a97d-8eb88fd16a3e,Modeling Human Behavior Part I -- Learning and Belief Approaches,0.165002,"There is a clear desire to model and comprehend human behavior. Trends in
research covering this topic show a clear assumption that many view human
reasoning as the presupposed standard in artificial reasoning. As such, topics
such as game theory, theory of mind, machine learning, etc. all integrate
concepts which are assumed components of human reasoning. These serve as
techniques to attempt to both replicate and understand the behaviors of humans.
In addition, next generation autonomous and adaptive systems will largely
include AI agents and humans working together as teams. To make this possible,
autonomous agents will require the ability to embed practical models of human
behavior, which allow them not only to replicate human models as a technique to
""learn"", but to to understand the actions of users and anticipate their
behavior, so as to truly operate in symbiosis with them. The main objective of
this paper it to provide a succinct yet systematic review of the most important
approaches in two areas dealing with quantitative models of human behaviors.
Specifically, we focus on (i) techniques which learn a model or policy of
behavior through exploration and feedback, such as Reinforcement Learning, and
(ii) directly model mechanisms of human reasoning, such as beliefs and bias,
without going necessarily learning via trial-and-error.",None,-1
48f9ddc0-b947-42b6-a8a7-79ac688fe766,Alternate Intermediate Conditioning with Syllable-level and Character-level Targets for Japanese ASR,0.0926003,"End-to-end automatic speech recognition directly maps input speech to
characters. However, the mapping can be problematic when several different
pronunciations should be mapped into one character or when one pronunciation is
shared among many different characters. Japanese ASR suffers the most from such
many-to-one and one-to-many mapping problems due to Japanese kanji characters.
To alleviate the problems, we introduce explicit interaction between characters
and syllables using Self-conditioned connectionist temporal classification
(CTC), in which the upper layers are ``self-conditioned'' on the intermediate
predictions from the lower layers. The proposed method utilizes character-level
and syllable-level intermediate predictions as conditioning features to deal
with mutual dependency between characters and syllables. Experimental results
on Corpus of Spontaneous Japanese show that the proposed method outperformed
the conventional multi-task and Self-conditioned CTC methods.",https://github.com/mozillazg/python-pinyin,-1
292adf72-95f7-4920-8789-000fa10246e4,Consistent Representation Learning for Continual Relation Extraction,0.954679,"Continual relation extraction (CRE) aims to continuously train a model on
data with new relations while avoiding forgetting old ones. Some previous work
has proved that storing a few typical samples of old relations and replaying
them when learning new relations can effectively avoid forgetting. However,
these memory-based methods tend to overfit the memory samples and perform
poorly on imbalanced datasets. To solve these challenges, a consistent
representation learning method is proposed, which maintains the stability of
the relation embedding by adopting contrastive learning and knowledge
distillation when replaying memory. Specifically, supervised contrastive
learning based on a memory bank is first used to train each new task so that
the model can effectively learn the relation representation. Then, contrastive
replay is conducted of the samples in memory and makes the model retain the
knowledge of historical relations through memory knowledge distillation to
prevent the catastrophic forgetting of the old task. The proposed method can
better learn consistent representations to alleviate forgetting effectively.
Extensive experiments on FewRel and TACRED datasets show that our method
significantly outperforms state-of-the-art baselines and yield strong
robustness on the imbalanced dataset.",https://github.com/thuiar/CRL,-1
466fa5af-fd76-4534-80a3-eedb16da6d5f,Towards Better Generalization with Flexible Representation of Multi-Module Graph Neural Networks,0.149399,"Graph neural networks (GNNs) have become compelling models designed to
perform learning and inference on graph-structured data. However, little work
has been done to understand the fundamental limitations of GNNs for scaling to
larger graphs and generalizing to out-of-distribution (OOD) inputs. In this
paper, we use a random graph generator to systematically investigate how the
graph size and structural properties affect the predictive performance of GNNs.
We present specific evidence that the average node degree is a key feature in
determining whether GNNs can generalize to unseen graphs, and that the use of
multiple node update functions can improve the generalization performance of
GNNs when dealing with graphs of multimodal degree distributions. Accordingly,
we propose a multi-module GNN framework that allows the network to adapt
flexibly to new graphs by generalizing a single canonical nonlinear
transformation over aggregated inputs. Our results show that the multi-module
GNNs improve the OOD generalization on a variety of inference tasks in the
direction of diverse structural features.",None,-1
364484b6-8204-419b-97a5-18c515ba2da4,LocalBins: Improving Depth Estimation by Learning Local Distributions,0.95091,"We propose a novel architecture for depth estimation from a single image. The
architecture itself is based on the popular encoder-decoder architecture that
is frequently used as a starting point for all dense regression tasks. We build
on AdaBins which estimates a global distribution of depth values for the input
image and evolve the architecture in two ways. First, instead of predicting
global depth distributions, we predict depth distributions of local
neighborhoods at every pixel. Second, instead of predicting depth distributions
only towards the end of the decoder, we involve all layers of the decoder. We
call this new architecture LocalBins. Our results demonstrate a clear
improvement over the state-of-the-art in all metrics on the NYU-Depth V2
dataset. Code and pretrained models will be made publicly available.",https://github.com/shariqfarooq123/LocalBins,21729
e6f2cbdd-e4cc-4b43-a47b-c982d073ffc0,Experiments on Generalizability of BERTopic on Multi-Domain Short Text,0.206975,"Topic modeling is widely used for analytically evaluating large collections
of textual data. One of the most popular topic techniques is Latent Dirichlet
Allocation (LDA), which is flexible and adaptive, but not optimal for e.g.
short texts from various domains. We explore how the state-of-the-art BERTopic
algorithm performs on short multi-domain text and find that it generalizes
better than LDA in terms of topic coherence and diversity. We further analyze
the performance of the HDBSCAN clustering algorithm utilized by BERTopic and
find that it classifies a majority of the documents as outliers. This crucial,
yet overseen problem excludes too many documents from further analysis. When we
replace HDBSCAN with k-Means, we achieve similar performance, but without
outliers.",None,-1
1a765ca3-4eaf-4a3d-ac7e-faf3568a69c8,Generative Category-Level Shape and Pose Estimation with Semantic Primitives,0.638949,"Empowering autonomous agents with 3D understanding for daily objects is a
grand challenge in robotics applications. When exploring in an unknown
environment, existing methods for object pose estimation are still not
satisfactory due to the diversity of object shapes. In this paper, we propose a
novel framework for category-level object shape and pose estimation from a
single RGB-D image. To handle the intra-category variation, we adopt a semantic
primitive representation that encodes diverse shapes into a unified latent
space, which is the key to establish reliable correspondences between observed
point clouds and estimated shapes. Then, by using a SIM(3)-invariant shape
descriptor, we gracefully decouple the shape and pose of an object, thus
supporting latent shape optimization of target objects in arbitrary poses.
Extensive experiments show that the proposed method achieves SOTA pose
estimation performance and better generalization in the real-world dataset.
Code and video are available at https://zju3dv.github.io/gCasp.",https://zju3dv.github.io/gCasp,4589
9d44829e-72ad-45d7-ba1b-c399f4ba0fb9,Unsupervised Extractive Opinion Summarization Using Sparse Coding,0.884775,"Opinion summarization is the task of automatically generating summaries that
encapsulate information from multiple user reviews. We present Semantic
Autoencoder (SemAE) to perform extractive opinion summarization in an
unsupervised manner. SemAE uses dictionary learning to implicitly capture
semantic information from the review and learns a latent representation of each
sentence over semantic units. A semantic unit is supposed to capture an
abstract semantic concept. Our extractive summarization algorithm leverages the
representations to identify representative opinions among hundreds of reviews.
SemAE is also able to perform controllable summarization to generate
aspect-specific summaries. We report strong performance on SPACE and AMAZON
datasets, and perform experiments to investigate the functioning of our model.
Our code is publicly available at https://github.com/brcsomnath/SemAE.",https://github.com/brcsomnath/SemAE,-1
9203c9bb-eb49-4554-a47d-aae9a4726009,Salience Allocation as Guidance for Abstractive Summarization,0.703719,"Abstractive summarization models typically learn to capture the salient
information from scratch implicitly. Recent literature adds extractive
summaries as guidance for abstractive summarization models to provide hints of
salient content and achieves better performance. However, extractive summaries
as guidance could be over strict, leading to information loss or noisy signals.
Furthermore, it cannot easily adapt to documents with various abstractiveness.
As the number and allocation of salience content pieces vary, it is hard to
find a fixed threshold deciding which content should be included in the
guidance. In this paper, we propose a novel summarization approach with a
flexible and reliable salience guidance, namely SEASON (SaliencE Allocation as
Guidance for Abstractive SummarizatiON). SEASON utilizes the allocation of
salience expectation to guide abstractive summarization and adapts well to
articles in different abstractiveness. Automatic and human evaluations on two
benchmark datasets show that the proposed method is effective and reliable.
Empirical results on more than one million news articles demonstrate a natural
fifteen-fifty salience split for news article sentences, providing a useful
insight for composing news articles.",https://github.com/tencent-ailab/season,-1
2c3eba00-a9a6-49b9-a861-a1ea38fb246b,Keep Me Updated! Memory Management in Long-term Conversations,0.662878,"Remembering important information from the past and continuing to talk about
it in the present are crucial in long-term conversations. However, previous
literature does not deal with cases where the memorized information is
outdated, which may cause confusion in later conversations. To address this
issue, we present a novel task and a corresponding dataset of memory management
in long-term conversations, in which bots keep track of and bring up the latest
information about users while conversing through multiple sessions. In order to
support more precise and interpretable memory, we represent memory as
unstructured text descriptions of key information and propose a new mechanism
of memory management that selectively eliminates invalidated or redundant
information. Experimental results show that our approach outperforms the
baselines that leave the stored memory unchanged in terms of engagingness and
humanness, with larger performance gap especially in the later sessions.",https://github.com/naver-ai/carecall-memory,6394
6c0efc62-e9b1-4aef-b75b-042d9d37636e,Shared Coupling-bridge for Weakly Supervised Local Feature Learning,0.34289,"Sparse local feature extraction is usually believed to be of important
significance in typical vision tasks such as simultaneous localization and
mapping, image matching and 3D reconstruction. At present, it still has some
deficiencies needing further improvement, mainly including the discrimination
power of extracted local descriptors, the localization accuracy of detected
keypoints, and the efficiency of local feature learning. This paper focuses on
promoting the currently popular sparse local feature learning with camera pose
supervision. Therefore, it pertinently proposes a Shared Coupling-bridge scheme
with four light-weight yet effective improvements for weakly-supervised local
feature (SCFeat) learning. It mainly contains: i) the
\emph{Feature-Fusion-ResUNet Backbone} (F2R-Backbone) for local descriptors
learning, ii) a shared coupling-bridge normalization to improve the decoupling
training of description network and detection network, iii) an improved
detection network with peakiness measurement to detect keypoints and iv) the
fundamental matrix error as a reward factor to further optimize feature
detection training. Extensive experiments prove that our SCFeat improvement is
effective. It could often obtain a state-of-the-art performance on classic
image matching and visual localization. In terms of 3D reconstruction, it could
still achieve competitive results. For sharing and communication, our source
codes are available at https://github.com/sunjiayuanro/SCFeat.git.",https://github.com/sunjiayuanro/SCFeat.git,-1
aaf8b1fa-20f3-4db2-945a-c3bbd90de337,Introducing BEREL: BERT Embeddings for Rabbinic-Encoded Language,0.615917,"We present a new pre-trained language model (PLM) for Rabbinic Hebrew, termed
Berel (BERT Embeddings for Rabbinic-Encoded Language). Whilst other PLMs exist
for processing Hebrew texts (e.g., HeBERT, AlephBert), they are all trained on
modern Hebrew texts, which diverges substantially from Rabbinic Hebrew in terms
of its lexicographical, morphological, syntactic and orthographic norms. We
demonstrate the superiority of Berel on Rabbinic texts via a challenge set of
Hebrew homographs. We release the new model and homograph challenge set for
unrestricted use.",None,-1
94bb2f18-52d6-4657-a709-afd1bfd49023,Introspective Learning : A Two-Stage Approach for Inference in Neural Networks,0.183427,"In this paper, we advocate for two stages in a neural network's decision
making process. The first is the existing feed-forward inference framework
where patterns in given data are sensed and associated with previously learned
patterns. The second stage is a slower reflection stage where we ask the
network to reflect on its feed-forward decision by considering and evaluating
all available choices. Together, we term the two stages as introspective
learning. We use gradients of trained neural networks as a measurement of this
reflection. A simple three-layered Multi Layer Perceptron is used as the second
stage that predicts based on all extracted gradient features. We perceptually
visualize the post-hoc explanations from both stages to provide a visual
grounding to introspection. For the application of recognition, we show that an
introspective network is 4% more robust and 42% less prone to calibration
errors when generalizing to noisy data. We also illustrate the value of
introspective networks in downstream tasks that require generalizability and
calibration including active learning, out-of-distribution detection, and
uncertainty estimation. Finally, we ground the proposed machine introspection
to human introspection for the application of image quality assessment.",https://github.com/olivesgatech/Introspective-Learning,-1
01fc01e3-16e9-4d07-bf96-b087ed5e01cc,Human Interpretation of Saliency-based Explanation Over Text,0.796287,"While a lot of research in explainable AI focuses on producing effective
explanations, less work is devoted to the question of how people understand and
interpret the explanation. In this work, we focus on this question through a
study of saliency-based explanations over textual data. Feature-attribution
explanations of text models aim to communicate which parts of the input text
were more influential than others towards the model decision. Many current
explanation methods, such as gradient-based or Shapley value-based methods,
provide measures of importance which are well-understood mathematically. But
how does a person receiving the explanation (the explainee) comprehend it? And
does their understanding match what the explanation attempted to communicate?
We empirically investigate the effect of various factors of the input, the
feature-attribution explanation, and visualization procedure, on laypeople's
interpretation of the explanation. We query crowdworkers for their
interpretation on tasks in English and German, and fit a GAMM model to their
responses considering the factors of interest. We find that people often
mis-interpret the explanations: superficial and unrelated factors, such as word
length, influence the explainees' importance assignment despite the explanation
communicating importance directly. We then show that some of this distortion
can be attenuated: we propose a method to adjust saliencies based on model
estimates of over- and under-perception, and explore bar charts as an
alternative to heatmap saliency visualization. We find that both approaches can
attenuate the distorting effect of specific factors, leading to
better-calibrated understanding of the explanation.",None,-1
98b80260-9111-4574-abb8-d01a3d4d1446,Incorporating Causal Analysis into Diversified and Logical Response Generation,0.246968,"Although the Conditional Variational AutoEncoder (CVAE) model can generate
more diversified responses than the traditional Seq2Seq model, the responses
often have low relevance with the input words or are illogical with the
question. A causal analysis is carried out to study the reasons behind, and a
methodology of searching for the mediators and mitigating the confounding bias
in dialogues is provided. Specifically, we propose to predict the mediators to
preserve relevant information and auto-regressively incorporate the mediators
into generating process. Besides, a dynamic topic graph guided conditional
variational autoencoder (TGG-CVAE) model is utilized to complement the semantic
space and reduce the confounding bias in responses. Extensive experiments
demonstrate that the proposed model is able to generate both relevant and
informative responses, and outperforms the state-of-the-art in terms of
automatic metrics and human evaluations.",None,-1
385fb687-7c7e-426b-97b2-2f3e7c707e59,TALM: Tool Augmented Language Models,0.99359,"Transformer based language models (LMs) demonstrate increasing performance
with scale across a wide variety of tasks. Scale alone however cannot enable
models to solve tasks that require access to ephemeral, changing, or private
data that was unavailable at training time. Many useful tasks may also benefit
from LMs being able to access APIs that read or modify state. In this work, we
present Tool Augmented Language Models (TALM), combining a text-only approach
to augment language models with non-differentiable tools, and an iterative
""self-play"" technique to bootstrap performance starting from few tool
demonstrations. TALM exhibits strong performance on both a knowledge-heavy QA
task and a reasoning oriented math task with simple tools. At a given model
scale, TALM significantly outperforms non-augmented LMs. We further demonstrate
that TALM successfully performs out-of-distribution inferences on both QA and
math tasks, where non-augmented LMs fail. Our results suggest that Tool
Augmented Language Models are a promising direction to enrich LMs'
capabilities, with less dependence on scale.",None,-1
65b2ec8b-027a-4524-87a4-d813f2e0cdfb,Empathetic Dialogue Generation via Sensitive Emotion Recognition and Sensible Knowledge Selection,0.673167,"Empathy, which is widely used in psychological counselling, is a key trait of
everyday human conversations. Equipped with commonsense knowledge, current
approaches to empathetic response generation focus on capturing implicit
emotion within dialogue context, where the emotions are treated as a static
variable throughout the conversations. However, emotions change dynamically
between utterances, which makes previous works difficult to perceive the
emotion flow and predict the correct emotion of the target response, leading to
inappropriate response. Furthermore, simply importing commonsense knowledge
without harmonization may trigger the conflicts between knowledge and emotion,
which confuse the model to choose incorrect information to guide the generation
process. To address the above problems, we propose a Serial Encoding and
Emotion-Knowledge interaction (SEEK) method for empathetic dialogue generation.
We use a fine-grained encoding strategy which is more sensitive to the emotion
dynamics (emotion flow) in the conversations to predict the emotion-intent
characteristic of response. Besides, we design a novel framework to model the
interaction between knowledge and emotion to generate more sensible response.
Extensive experiments on EmpatheticDialogues demonstrate that SEEK outperforms
the strong baselines in both automatic and manual evaluations.",https://github.com/wlr737/EMNLP2022-SEEK,-1
5901bf2c-9b6f-4511-bec6-18bfca44e7f8,Policy-Based Bayesian Experimental Design for Non-Differentiable Implicit Models,0.151339,"For applications in healthcare, physics, energy, robotics, and many other
fields, designing maximally informative experiments is valuable, particularly
when experiments are expensive, time-consuming, or pose safety hazards. While
existing approaches can sequentially design experiments based on prior
observation history, many of these methods do not extend to implicit models,
where simulation is possible but computing the likelihood is intractable.
Furthermore, they often require either significant online computation during
deployment or a differentiable simulation system. We introduce Reinforcement
Learning for Deep Adaptive Design (RL-DAD), a method for simulation-based
optimal experimental design for non-differentiable implicit models. RL-DAD
extends prior work in policy-based Bayesian Optimal Experimental Design (BOED)
by reformulating it as a Markov Decision Process with a reward function based
on likelihood-free information lower bounds, which is used to learn a policy
via deep reinforcement learning. The learned design policy maps prior histories
to experiment designs offline and can be quickly deployed during online
execution. We evaluate RL-DAD and find that it performs competitively with
baselines on three benchmarks.",None,-1
5d471b4f-6a8b-4e99-bfdd-1f6738cad26c,NeRF-RPN: A general framework for object detection in NeRFs,0.81361,"This paper presents the first significant object detection framework,
NeRF-RPN, which directly operates on NeRF. Given a pre-trained NeRF model,
NeRF-RPN aims to detect all bounding boxes of objects in a scene. By exploiting
a novel voxel representation that incorporates multi-scale 3D neural volumetric
features, we demonstrate it is possible to regress the 3D bounding boxes of
objects in NeRF directly without rendering the NeRF at any viewpoint. NeRF-RPN
is a general framework and can be applied to detect objects without class
labels. We experimented NeRF-RPN with various backbone architectures, RPN head
designs and loss functions. All of them can be trained in an end-to-end manner
to estimate high quality 3D bounding boxes. To facilitate future research in
object detection for NeRF, we built a new benchmark dataset which consists of
both synthetic and real-world data with careful labeling and clean up. Code and
dataset are available at https://github.com/lyclyc52/NeRF_RPN.",https://github.com/lyclyc52/NeRF_RPN,-1
4d7465dd-82cb-4ee8-87f1-35628fce5478,UzbekStemmer: Development of a Rule-Based Stemming Algorithm for Uzbek Language,0.409933,"In this paper we present a rule-based stemming algorithm for the Uzbek
language. Uzbek is an agglutinative language, so many words are formed by
adding suffixes, and the number of suffixes is also large. For this reason, it
is difficult to find a stem of words. The methodology is proposed for doing the
stemming of the Uzbek words with an affix stripping approach whereas not
including any database of the normal word forms of the Uzbek language. Word
affixes are classified into fifteen classes and designed as finite state
machines (FSMs) for each class according to morphological rules. We created
fifteen FSMs and linked them together to create the Basic FSM. A lexicon of
affixes in XML format was created and a stemming application for Uzbek words
has been developed based on the FSMs.",https://www.higithub.com/MaksudSharipov/repo/UzbekStemmer,-1
64806613-ff8e-43f9-9e45-9babba0d758f,Improved Touchless Respiratory Rate Sensing,0.211093,"Recently, remote respiratory rate measurement techniques gained much
attention as they were developed to overcome the limitations of device-based
classical methods and manual counting. Many approaches for RR extraction from
the video stream of the visible light camera were proposed, including the pixel
intensity changes method. In this paper, we propose a new method for 1D profile
creation for pixel intensity changes-based method, which significantly
increases the algorithm's performance. Additional accuracy gain is obtained via
a new method of motion signals grouping presented in this work. We introduce
several changes to the standard pipeline, which enables real-time continuous RR
monitoring and allows applications in the human-computer interaction systems.
Evaluation results on two internal and one public datasets showed 0.7 BPM, 0.6
BPM, and 1.4 BPM MAE, respectively.",None,-1
873fb4f2-360b-4ca7-9081-352ee4838e66,Recurrent Memory Transformer,0.940889,"Transformer-based models show their effectiveness across multiple domains and
tasks. The self-attention allows to combine information from all sequence
elements into context-aware representations. However, global and local
information has to be stored mostly in the same element-wise representations.
Moreover, the length of an input sequence is limited by quadratic computational
complexity of self-attention.
  In this work, we propose and study a memory-augmented segment-level recurrent
Transformer (RMT). Memory allows to store and process local and global
information as well as to pass information between segments of the long
sequence with the help of recurrence.
  We implement a memory mechanism with no changes to Transformer model by
adding special memory tokens to the input or output sequence. Then the model is
trained to control both memory operations and sequence representations
processing.
  Results of experiments show that RMT performs on par with the Transformer-XL
on language modeling for smaller memory sizes and outperforms it for tasks that
require longer sequence processing. We show that adding memory tokens to Tr-XL
is able to improve its performance. This makes Recurrent Memory Transformer a
promising architecture for applications that require learning of long-term
dependencies and general purpose in memory processing, such as algorithmic
tasks and reasoning.",https://github.com/booydar/LM-RMT,-1
76514e0d-a875-438d-b4c1-00ded682c0a3,A method for ethical AI in Defence: A case study on developing trustworthy autonomous systems,0.879198,"What does it mean to be responsible and responsive when developing and
deploying trusted autonomous systems in Defence? In this short reflective
article, we describe a case study of building a trusted autonomous system -
Athena AI - within an industry-led, government-funded project with diverse
collaborators and stakeholders. Using this case study, we draw out lessons on
the value and impact of embedding responsible research and innovation-aligned,
ethics-by-design approaches and principles throughout the development of
technology at high translation readiness levels.",None,-1
be96c08c-899d-465f-895f-435394578046,A Second Wave of UD Hebrew Treebanking and Cross-Domain Parsing,0.882681,"Foundational Hebrew NLP tasks such as segmentation, tagging and parsing, have
relied to date on various versions of the Hebrew Treebank (HTB, Sima'an et al.
2001). However, the data in HTB, a single-source newswire corpus, is now over
30 years old, and does not cover many aspects of contemporary Hebrew on the
web. This paper presents a new, freely available UD treebank of Hebrew
stratified from a range of topics selected from Hebrew Wikipedia. In addition
to introducing the corpus and evaluating the quality of its annotations, we
deploy automatic validation tools based on grew (Guillaume, 2021), and conduct
the first cross domain parsing experiments in Hebrew. We obtain new
state-of-the-art (SOTA) results on UD NLP tasks, using a combination of the
latest language modelling and some incremental improvements to existing
transformer based approaches. We also release a new version of the UD HTB
matching annotation scheme updates from our new corpus.",https://github.com/amir-zeldes/HebPipe/,-1
27cf5b6c-c6a9-4258-90e1-f698c17572ca,Interpretable Distribution Shift Detection using Optimal Transport,0.0697738,"We propose a method to identify and characterize distribution shifts in
classification datasets based on optimal transport. It allows the user to
identify the extent to which each class is affected by the shift, and retrieves
corresponding pairs of samples to provide insights on its nature. We illustrate
its use on synthetic and natural shift examples. While the results we present
are preliminary, we hope that this inspires future work on interpretable
methods for analyzing distribution shifts.",None,14789
6b8318f3-4265-4f34-8950-2fa166c2449a,On Calibrating Semantic Segmentation Models: Analyses and An Algorithm,0.468647,"We study the problem of semantic segmentation calibration. Lots of solutions
have been proposed to approach model miscalibration of confidence in image
classification. However, to date, confidence calibration research on semantic
segmentation is still limited. We provide a systematic study on the calibration
of semantic segmentation models and propose a simple yet effective approach.
First, we find that model capacity, crop size, multi-scale testing, and
prediction correctness have impact on calibration. Among them, prediction
correctness, especially misprediction, is more important to miscalibration due
to over-confidence. Next, we propose a simple, unifying, and effective
approach, namely selective scaling, by separating correct/incorrect prediction
for scaling and more focusing on misprediction logit smoothing. Then, we study
popular existing calibration methods and compare them with selective scaling on
semantic segmentation calibration. We conduct extensive experiments with a
variety of benchmarks on both in-domain and domain-shift calibration and show
that selective scaling consistently outperforms other methods.",https://github.com/dwang181/selectivecal,-1
eb64e2e6-2b40-482b-8cdc-9585d6f5e0c8,Hierarchical Multi-Label Classification of Scientific Documents,0.673935,"Automatic topic classification has been studied extensively to assist
managing and indexing scientific documents in a digital collection. With the
large number of topics being available in recent years, it has become necessary
to arrange them in a hierarchy. Therefore, the automatic classification systems
need to be able to classify the documents hierarchically. In addition, each
paper is often assigned to more than one relevant topic. For example, a paper
can be assigned to several topics in a hierarchy tree. In this paper, we
introduce a new dataset for hierarchical multi-label text classification
(HMLTC) of scientific papers called SciHTC, which contains 186,160 papers and
1,233 categories from the ACM CCS tree. We establish strong baselines for HMLTC
and propose a multi-task learning approach for topic classification with
keyword labeling as an auxiliary task. Our best model achieves a Macro-F1 score
of 34.57% which shows that this dataset provides significant research
opportunities on hierarchical scientific topic classification. We make our
dataset and code available on Github.",https://github.com/msadat3/SciHTC,-1
24913e11-364e-4cc6-b402-ba5ec8ed5e22,"Decentralized, Communication- and Coordination-free Learning in Structured Matching Markets",0.395144,"We study the problem of online learning in competitive settings in the
context of two-sided matching markets. In particular, one side of the market,
the agents, must learn about their preferences over the other side, the firms,
through repeated interaction while competing with other agents for successful
matches. We propose a class of decentralized, communication- and
coordination-free algorithms that agents can use to reach to their stable match
in structured matching markets. In contrast to prior works, the proposed
algorithms make decisions based solely on an agent's own history of play and
requires no foreknowledge of the firms' preferences. Our algorithms are
constructed by splitting up the statistical problem of learning one's
preferences, from noisy observations, from the problem of competing for firms.
We show that under realistic structural assumptions on the underlying
preferences of the agents and firms, the proposed algorithms incur a regret
which grows at most logarithmically in the time horizon. Our results show that,
in the case of matching markets, competition need not drastically affect the
performance of decentralized, communication and coordination free online
learning algorithms.",None,910
d0728487-f21f-4293-af6c-5f3cf4e1c7b6,A Study of Gender Impact in Self-supervised Models for Speech-to-Text Systems,0.187105,"Self-supervised models for speech processing emerged recently as popular
foundation blocks in speech processing pipelines. These models are pre-trained
on unlabeled audio data and then used in speech processing downstream tasks
such as automatic speech recognition (ASR) or speech translation (ST). Since
these models are now used in research and industrial systems alike, it becomes
necessary to understand the impact caused by some features such as gender
distribution within pre-training data. Using French as our investigation
language, we train and compare gender-specific wav2vec 2.0 models against
models containing different degrees of gender balance in their pre-training
data. The comparison is performed by applying these models to two
speech-to-text downstream tasks: ASR and ST. Results show the type of
downstream integration matters. We observe lower overall performance using
gender-specific pre-training before fine-tuning an end-to-end ASR system.
However, when self-supervised models are used as feature extractors, the
overall ASR and ST results follow more complex patterns in which the balanced
pre-trained model does not necessarily lead to the best results. Lastly, our
crude 'fairness' metric, the relative performance difference measured between
female and male test sets, does not display a strong variation from balanced to
gender-specific pre-trained wav2vec 2.0 models.",None,-1
877e9d25-7aa4-48ca-b067-fa7eaafde023,Accelerating DETR Convergence via Semantic-Aligned Matching,0.993459,"The recently developed DEtection TRansformer (DETR) establishes a new object
detection paradigm by eliminating a series of hand-crafted components. However,
DETR suffers from extremely slow convergence, which increases the training cost
significantly. We observe that the slow convergence is largely attributed to
the complication in matching object queries with target features in different
feature embedding spaces. This paper presents SAM-DETR, a
Semantic-Aligned-Matching DETR that greatly accelerates DETR's convergence
without sacrificing its accuracy. SAM-DETR addresses the convergence issue from
two perspectives. First, it projects object queries into the same embedding
space as encoded image features, where the matching can be accomplished
efficiently with aligned semantics. Second, it explicitly searches salient
points with the most discriminative features for semantic-aligned matching,
which further speeds up the convergence and boosts detection accuracy as well.
Being like a plug and play, SAM-DETR complements existing convergence solutions
well yet only introduces slight computational overhead. Extensive experiments
show that the proposed SAM-DETR achieves superior convergence as well as
competitive detection accuracy. The implementation codes are available at
https://github.com/ZhangGongjie/SAM-DETR.",https://github.com/ZhangGongjie/SAM-DETR,-1
1ccdf084-09c3-4cbc-bea1-6e099ee0a759,Selective Annotation Makes Language Models Better Few-Shot Learners,0.946758,"Many recent approaches to natural language tasks are built on the remarkable
abilities of large language models. Large language models can perform
in-context learning, where they learn a new task from a few task
demonstrations, without any parameter updates. This work examines the
implications of in-context learning for the creation of datasets for new
natural language tasks. Departing from recent in-context learning methods, we
formulate an annotation-efficient, two-step framework: selective annotation
that chooses a pool of examples to annotate from unlabeled data in advance,
followed by prompt retrieval that retrieves task examples from the annotated
pool at test time. Based on this framework, we propose an unsupervised,
graph-based selective annotation method, voke-k, to select diverse,
representative examples to annotate. Extensive experiments on 10 datasets
(covering classification, commonsense reasoning, dialogue, and text/code
generation) demonstrate that our selective annotation method improves the task
performance by a large margin. On average, vote-k achieves a 12.9%/11.4%
relative gain under an annotation budget of 18/100, as compared to randomly
selecting examples to annotate. Compared to state-of-the-art supervised
finetuning approaches, it yields similar performance with 10-100x less
annotation cost across 10 tasks. We further analyze the effectiveness of our
framework in various scenarios: language models with varying sizes, alternative
selective annotation methods, and cases where there is a test data domain
shift. We hope that our studies will serve as a basis for data annotations as
large language models are increasingly applied to new tasks. Our code is
available at https://github.com/HKUNLP/icl-selective-annotation.",None,104111
82c15f3e-17f4-4b0d-b47c-b46c307e8fe6,ROAD-R: The Autonomous Driving Dataset with Logical Requirements,0.807808,"Neural networks have proven to be very powerful at computer vision tasks.
However, they often exhibit unexpected behaviours, violating known requirements
expressing background knowledge. This calls for models (i) able to learn from
the requirements, and (ii) guaranteed to be compliant with the requirements
themselves. Unfortunately, the development of such models is hampered by the
lack of datasets equipped with formally specified requirements. In this paper,
we introduce the ROad event Awareness Dataset with logical Requirements
(ROAD-R), the first publicly available dataset for autonomous driving with
requirements expressed as logical constraints. Given ROAD-R, we show that
current state-of-the-art models often violate its logical constraints, and that
it is possible to exploit them to create models that (i) have a better
performance, and (ii) are guaranteed to be compliant with the requirements
themselves.",https://github.com/gurkirt/road-dataset,-1
692726a6-7ab2-4437-bc8f-553f6fd5bac3,Distantly-Supervised Named Entity Recognition with Adaptive Teacher Learning and Fine-grained Student Ensemble,0.940915,"Distantly-Supervised Named Entity Recognition (DS-NER) effectively alleviates
the data scarcity problem in NER by automatically generating training samples.
Unfortunately, the distant supervision may induce noisy labels, thus
undermining the robustness of the learned models and restricting the practical
application. To relieve this problem, recent works adopt self-training
teacher-student frameworks to gradually refine the training labels and improve
the generalization ability of NER models. However, we argue that the
performance of the current self-training frameworks for DS-NER is severely
underestimated by their plain designs, including both inadequate student
learning and coarse-grained teacher updating. Therefore, in this paper, we make
the first attempt to alleviate these issues by proposing: (1) adaptive teacher
learning comprised of joint training of two teacher-student networks and
considering both consistent and inconsistent predictions between two teachers,
thus promoting comprehensive student learning. (2) fine-grained student
ensemble that updates each fragment of the teacher model with a temporal moving
average of the corresponding fragment of the student, which enhances consistent
predictions on each model fragment against noise. To verify the effectiveness
of our proposed method, we conduct experiments on four DS-NER datasets. The
experimental results demonstrate that our method significantly surpasses
previous SOTA methods.",https://github.com/zenhjunpro/ATSEN,-1
1a2ddaed-43a9-430c-b76a-9a628467c270,CLIPascene: Scene Sketching with Different Types and Levels of Abstraction,0.579664,"In this paper, we present a method for converting a given scene image into a
sketch using different types and multiple levels of abstraction. We distinguish
between two types of abstraction. The first considers the fidelity of the
sketch, varying its representation from a more precise portrayal of the input
to a looser depiction. The second is defined by the visual simplicity of the
sketch, moving from a detailed depiction to a sparse sketch. Using an explicit
disentanglement into two abstraction axes -- and multiple levels for each one
-- provides users additional control over selecting the desired sketch based on
their personal goals and preferences. To form a sketch at a given level of
fidelity and simplification, we train two MLP networks. The first network
learns the desired placement of strokes, while the second network learns to
gradually remove strokes from the sketch without harming its recognizability
and semantics. Our approach is able to generate sketches of complex scenes
including those with complex backgrounds (e.g., natural and urban settings) and
subjects (e.g., animals and people) while depicting gradual abstractions of the
input scene in terms of fidelity and simplicity.",None,-1
850c3493-3736-4939-97cf-1dab1fd1426e,What is Software Quality for AI Engineers? Towards a Thinning of the Fog,0.872147,"It is often overseen that AI-enabled systems are also software systems and
therefore rely on software quality assurance (SQA). Thus, the goal of this
study is to investigate the software quality assurance strategies adopted
during the development, integration, and maintenance of AI/ML components and
code. We conducted semi-structured interviews with representatives of ten
Austrian SMEs that develop AI-enabled systems. A qualitative analysis of the
interview data identified 12 issues in the development of AI/ML components.
Furthermore, we identified when quality issues arise in AI/ML components and
how they are detected. The results of this study should guide future work on
software quality assurance processes and techniques for AI/ML components.",None,-1
08bdcd22-44d5-4c9a-8f75-a5efdee22252,FORCE: A Framework of Rule-Based Conversational Recommender System,0.0559572,"The conversational recommender systems (CRSs) have received extensive
attention in recent years. However, most of the existing works focus on various
deep learning models, which are largely limited by the requirement of
large-scale human-annotated datasets. Such methods are not able to deal with
the cold-start scenarios in industrial products. To alleviate the problem, we
propose FORCE, a Framework Of Rule-based Conversational Recommender system that
helps developers to quickly build CRS bots by simple configuration. We conduct
experiments on two datasets in different languages and domains to verify its
effectiveness and usability.",None,122012
b597e61f-4e3f-4af2-a826-2745e5a3c1ab,REx: Data-Free Residual Quantization Error Expansion,0.107764,"Deep neural networks (DNNs) are ubiquitous in computer vision and natural
language processing, but suffer from high inference cost. This problem can be
addressed by quantization, which consists in converting floating point
operations into a lower bit-width format. With the growing concerns on privacy
rights, we focus our efforts on data-free methods. However, such techniques
suffer from their lack of adaptability to the target devices, as a hardware
typically only support specific bit widths. Thus, to adapt to a variety of
devices, a quantization method shall be flexible enough to find good accuracy
v.s. speed trade-offs for every bit width and target device. To achieve this,
we propose REx, a quantization method that leverages residual error expansion,
along with group sparsity and an ensemble approximation for better
parallelization. REx is backed off by strong theoretical guarantees and
achieves superior performance on every benchmarked application (from vision to
NLP tasks), architecture (ConvNets, transformers) and bit-width (from int8 to
ternary quantization).",None,-1
83692936-701f-413c-8491-ef4ed38e9af6,Competency Assessment for Autonomous Agents using Deep Generative Models,0.438298,"For autonomous agents to act as trustworthy partners to human users, they
must be able to reliably communicate their competency for the tasks they are
asked to perform. Towards this objective, we develop probabilistic world models
based on deep generative modelling that allow for the simulation of agent
trajectories and accurate calculation of tasking outcome probabilities. By
combining the strengths of conditional variational autoencoders with recurrent
neural networks, the deep generative world model can probabilistically forecast
trajectories over long horizons to task completion. We show how these
forecasted trajectories can be used to calculate outcome probability
distributions, which enable the precise assessment of agent competency for
specific tasks and initial settings.",None,-1
53700508-a61e-43a9-9e9a-13388410176b,"Re2G: Retrieve, Rerank, Generate",0.85879,"As demonstrated by GPT-3 and T5, transformers grow in capability as parameter
spaces become larger and larger. However, for tasks that require a large amount
of knowledge, non-parametric memory allows models to grow dramatically with a
sub-linear increase in computational cost and GPU memory requirements. Recent
models such as RAG and REALM have introduced retrieval into conditional
generation. These models incorporate neural initial retrieval from a corpus of
passages. We build on this line of research, proposing Re2G, which combines
both neural initial retrieval and reranking into a BART-based
sequence-to-sequence generation. Our reranking approach also permits merging
retrieval results from sources with incomparable scores, enabling an ensemble
of BM25 and neural initial retrieval. To train our system end-to-end, we
introduce a novel variation of knowledge distillation to train the initial
retrieval, reranker, and generation using only ground truth on the target
sequence output. We find large gains in four diverse tasks: zero-shot slot
filling, question answering, fact-checking, and dialog, with relative gains of
9% to 34% over the previous state-of-the-art on the KILT leaderboard. We make
our code available as open source at
https://github.com/IBM/kgi-slot-filling/tree/re2g.",https://github.com/IBM/kgi-slot-filling,-1
557e7161-205a-45cd-b3dc-b423c7323e36,Image Segmentation-based Unsupervised Multiple Objects Discovery,0.543427,"Unsupervised object discovery aims to localize objects in images, while
removing the dependence on annotations required by most deep learning-based
methods. To address this problem, we propose a fully unsupervised, bottom-up
approach, for multiple objects discovery. The proposed approach is a two-stage
framework. First, instances of object parts are segmented by using the
intra-image similarity between self-supervised local features. The second step
merges and filters the object parts to form complete object instances. The
latter is performed by two CNN models that capture semantic information on
objects from the entire dataset. We demonstrate that the pseudo-labels
generated by our method provide a better precision-recall trade-off than
existing single and multiple objects discovery methods. In particular, we
provide state-of-the-art results for both unsupervised class-agnostic object
detection and unsupervised image segmentation.",None,-1
06418f9f-4322-4111-87f8-d8ebc5e8c16d,Domain-General Crowd Counting in Unseen Scenarios,0.61098,"Domain shift across crowd data severely hinders crowd counting models to
generalize to unseen scenarios. Although domain adaptive crowd counting
approaches close this gap to a certain extent, they are still dependent on the
target domain data to adapt (e.g. finetune) their models to the specific
domain. In this paper, we aim to train a model based on a single source domain
which can generalize well on any unseen domain. This falls into the realm of
domain generalization that remains unexplored in crowd counting. We first
introduce a dynamic sub-domain division scheme which divides the source domain
into multiple sub-domains such that we can initiate a meta-learning framework
for domain generalization. The sub-domain division is dynamically refined
during the meta-learning. Next, in order to disentangle domain-invariant
information from domain-specific information in image features, we design the
domain-invariant and -specific crowd memory modules to re-encode image
features. Two types of losses, i.e. feature reconstruction and orthogonal
losses, are devised to enable this disentanglement. Extensive experiments on
several standard crowd counting benchmarks i.e. SHA, SHB, QNRF, and NWPU, show
the strong generalizability of our method.",https://github.com/ZPDu/Domain-general-Crowd-Counting-in-Unseen-Scenarios,2009
14fb4035-eecd-4b4a-a84c-97c4b5823d46,Third Time's the Charm? Image and Video Editing with StyleGAN3,0.894966,"StyleGAN is arguably one of the most intriguing and well-studied generative
models, demonstrating impressive performance in image generation, inversion,
and manipulation. In this work, we explore the recent StyleGAN3 architecture,
compare it to its predecessor, and investigate its unique advantages, as well
as drawbacks. In particular, we demonstrate that while StyleGAN3 can be trained
on unaligned data, one can still use aligned data for training, without
hindering the ability to generate unaligned imagery. Next, our analysis of the
disentanglement of the different latent spaces of StyleGAN3 indicates that the
commonly used W/W+ spaces are more entangled than their StyleGAN2 counterparts,
underscoring the benefits of using the StyleSpace for fine-grained editing.
Considering image inversion, we observe that existing encoder-based techniques
struggle when trained on unaligned data. We therefore propose an encoding
scheme trained solely on aligned data, yet can still invert unaligned images.
Finally, we introduce a novel video inversion and editing workflow that
leverages the capabilities of a fine-tuned StyleGAN3 generator to reduce
texture sticking and expand the field of view of the edited video.",https://yuval-alaluf.github.io/stylegan3-editing/,62088
8804dc3a-163a-439c-a574-dc671cb883c4,Diverse Plausible 360-Degree Image Outpainting for Efficient 3DCG Background Creation,0.76693,"We address the problem of generating a 360-degree image from a single image
with a narrow field of view by estimating its surroundings. Previous methods
suffered from overfitting to the training resolution and deterministic
generation. This paper proposes a completion method using a transformer for
scene modeling and novel methods to improve the properties of a 360-degree
image on the output image. Specifically, we use CompletionNets with a
transformer to perform diverse completions and AdjustmentNet to match color,
stitching, and resolution with an input image, enabling inference at any
resolution. To improve the properties of a 360-degree image on an output image,
we also propose WS-perceptual loss and circular inference. Thorough experiments
show that our method outperforms state-of-the-art (SOTA) methods both
qualitatively and quantitatively. For example, compared to SOTA methods, our
method completes images 16 times larger in resolution and achieves 1.7 times
lower Frechet inception distance (FID). Furthermore, we propose a pipeline that
uses the completion results for lighting and background of 3DCG scenes. Our
plausible background completion enables perceptually natural results in the
application of inserting virtual objects with specular surfaces.",None,-1
40fa99f3-e9c1-4dfc-8070-dbc93b6db989,Controllable Dialogue Simulation with In-Context Learning,0.868075,"Building dialogue systems requires a large corpus of annotated dialogues.
Such datasets are usually created via crowdsourcing, which is expensive and
time-consuming. In this paper, we propose \textsc{Dialogic}, a novel dialogue
simulation method based on large language model in-context learning to automate
dataset creation. Seeded with a few annotated dialogues, \textsc{Dialogic}
automatically selects in-context examples for demonstration and prompts GPT-3
to generate new dialogues and annotations in a controllable way. Our method can
rapidly expand a small set of dialogue data with minimum or zero \textit{human
involvement} and \textit{parameter update} and is thus much more cost-efficient
and time-saving than crowdsourcing. Experimental results on the MultiWOZ
dataset demonstrate that training a model on the simulated dialogues leads to
even better performance than using the same amount of human-generated dialogues
under the challenging low-resource settings, with as few as 85 dialogues as a
seed. When enough data is available, our method can still serve as an effective
data augmentation method. Human evaluation results also show that our simulated
dialogues have near-human fluency and annotation accuracy. The code and data
are available at \textbf{\url{https://github.com/Leezekun/dialogic}}.",https://github.com/Leezekun/dialogic,-1
ad35d77a-aa7f-4fc9-b0b7-7bfed59234d6,Prompt for Extraction? PAIE: Prompting Argument Interaction for Event Argument Extraction,0.999995,"In this paper, we propose an effective yet efficient model PAIE for both
sentence-level and document-level Event Argument Extraction (EAE), which also
generalizes well when there is a lack of training data. On the one hand, PAIE
utilizes prompt tuning for extractive objectives to take the best advantages of
Pre-trained Language Models (PLMs). It introduces two span selectors based on
the prompt to select start/end tokens among input texts for each role. On the
other hand, it captures argument interactions via multi-role prompts and
conducts joint optimization with optimal span assignments via a bipartite
matching loss. Also, with a flexible prompt design, PAIE can extract multiple
arguments with the same role instead of conventional heuristic threshold
tuning. We have conducted extensive experiments on three benchmarks, including
both sentence- and document-level EAE. The results present promising
improvements from PAIE (3.5\% and 2.3\% F1 gains in average on three
benchmarks, for PAIE-base and PAIE-large respectively). Further analysis
demonstrates the efficiency, generalization to few-shot settings, and
effectiveness of different extractive prompt tuning strategies. Our code is
available at https://github.com/mayubo2333/PAIE.",https://github.com/mayubo2333/PAIE,-1
b92015b2-8dd6-4461-b21e-067dee8f5832,ICANet: A Method of Short Video Emotion Recognition Driven by Multimodal Data,0.405596,"With the fast development of artificial intelligence and short videos,
emotion recognition in short videos has become one of the most important
research topics in human-computer interaction. At present, most emotion
recognition methods still stay in a single modality. However, in daily life,
human beings will usually disguise their real emotions, which leads to the
problem that the accuracy of single modal emotion recognition is relatively
terrible. Moreover, it is not easy to distinguish similar emotions. Therefore,
we propose a new approach denoted as ICANet to achieve multimodal short video
emotion recognition by employing three different modalities of audio, video and
optical flow, making up for the lack of a single modality and then improving
the accuracy of emotion recognition in short videos. ICANet has a better
accuracy of 80.77% on the IEMOCAP benchmark, exceeding the SOTA methods by
15.89%.",None,-1
451ad024-f80c-4120-af50-e26eccd18b3e,DIGAT: Modeling News Recommendation with Dual-Graph Interaction,0.199728,"News recommendation (NR) is essential for online news services. Existing NR
methods typically adopt a news-user representation learning framework, facing
two potential limitations. First, in news encoder, single candidate news
encoding suffers from an insufficient semantic information problem. Second,
existing graph-based NR methods are promising but lack effective news-user
feature interaction, rendering the graph-based recommendation suboptimal. To
overcome these limitations, we propose dual-interactive graph attention
networks (DIGAT) consisting of news- and user-graph channels. In the news-graph
channel, we enrich the semantics of single candidate news by incorporating the
semantically relevant news information with a semantic-augmented graph (SAG).
In the user-graph channel, multi-level user interests are represented with a
news-topic graph. Most notably, we design a dual-graph interaction process to
perform effective feature interaction between the news and user graphs, which
facilitates accurate news-user representation matching. Experiment results on
the benchmark dataset MIND show that DIGAT outperforms existing news
recommendation methods. Further ablation studies and analyses validate the
effectiveness of (1) semantic-augmented news graph modeling and (2) dual-graph
interaction.",https://github.com/Veason-silverbullet/DIGAT,-1
285f469e-e11b-4e66-875d-d93b34eceee9,Physical Attack on Monocular Depth Estimation with Optimal Adversarial Patches,0.971271,"Deep learning has substantially boosted the performance of Monocular Depth
Estimation (MDE), a critical component in fully vision-based autonomous driving
(AD) systems (e.g., Tesla and Toyota). In this work, we develop an attack
against learning-based MDE. In particular, we use an optimization-based method
to systematically generate stealthy physical-object-oriented adversarial
patches to attack depth estimation. We balance the stealth and effectiveness of
our attack with object-oriented adversarial design, sensitive region
localization, and natural style camouflage. Using real-world driving scenarios,
we evaluate our attack on concurrent MDE models and a representative downstream
task for AD (i.e., 3D object detection). Experimental results show that our
method can generate stealthy, effective, and robust adversarial patches for
different target objects and models and achieves more than 6 meters mean depth
estimation error and 93% attack success rate (ASR) in object detection with a
patch of 1/9 of the vehicle's rear area. Field tests on three different driving
routes with a real vehicle indicate that we cause over 6 meters mean depth
estimation error and reduce the object detection rate from 90.70% to 5.16% in
continuous video frames.",None,15242
aab49400-b93c-46e8-bbc0-873946e3d0a9,An Implicit Parametric Morphable Dental Model,0.93292,"3D Morphable models of the human body capture variations among subjects and
are useful in reconstruction and editing applications. Current dental models
use an explicit mesh scene representation and model only the teeth, ignoring
the gum. In this work, we present the first parametric 3D morphable dental
model for both teeth and gum. Our model uses an implicit scene representation
and is learned from rigidly aligned scans. It is based on a component-wise
representation for each tooth and the gum, together with a learnable latent
code for each of such components. It also learns a template shape thus enabling
several applications such as segmentation, interpolation, and tooth
replacement. Our reconstruction quality is on par with the most advanced global
implicit representations while enabling novel applications. Project page:
https://vcai.mpi-inf.mpg.de/projects/DMM/",None,-1
2afdaab5-2363-474c-ab89-10607a66dd89,GPoeT-2: A GPT-2 Based Poem Generator,0.0286278,"This project aims to produce the next volume of machine-generated poetry, a
complex art form that can be structured and unstructured, and carries depth in
the meaning between the lines. GPoeT-2 is based on fine-tuning a state of the
art natural language model (i.e. GPT-2) to generate limericks, typically
humorous structured poems consisting of five lines with a AABBA rhyming scheme.
With a two-stage generation system utilizing both forward and reverse language
modeling, GPoeT-2 is capable of freely generating limericks in diverse topics
while following the rhyming structure without any seed phrase or a posteriori
constraints.Based on the automated generation process, we explore a wide
variety of evaluation metrics to quantify ""good poetry,"" including syntactical
correctness, lexical diversity, and subject continuity. Finally, we present a
collection of 94 categorized limericks that rank highly on the explored ""good
poetry"" metrics to provoke human creativity.",None,-1
c7075f76-0387-4d7c-8274-0eb45ac9d736,Generating Executable Action Plans with Environmentally-Aware Language Models,0.905127,"Large Language Models (LLMs) trained using massive text datasets have
recently shown promise in generating action plans for robotic agents from high
level text queries. However, these models typically do not consider the robot's
environment, resulting in generated plans that may not actually be executable,
due to ambiguities in the planned actions or environmental constraints. In this
paper, we propose an approach to generate environmentally-aware action plans
that agents are better able to execute. Our approach involves integrating
environmental objects and object relations as additional inputs into LLM action
plan generation to provide the system with an awareness of its surroundings,
resulting in plans where each generated action is mapped to objects present in
the scene. We also design a novel scoring function that, along with generating
the action steps and associating them with objects, helps the system
disambiguate among object instances and take into account their states. We
evaluated our approach using the VirtualHome simulator and the ActivityPrograms
knowledge base and found that action plans generated from our system had a 310%
improvement in executability and a 147% improvement in correctness over prior
work. The complete code and a demo of our method is publicly available at
https://github.com/hri-ironlab/scene_aware_language_planner.",https://github.com/hri-ironlab/scene_aware_language_planner,-1
a5a0b082-becc-42e1-a5d6-588bb62f38ea,PrivHAR: Recognizing Human Actions From Privacy-preserving Lens,0.656398,"The accelerated use of digital cameras prompts an increasing concern about
privacy and security, particularly in applications such as action recognition.
In this paper, we propose an optimizing framework to provide robust visual
privacy protection along the human action recognition pipeline. Our framework
parameterizes the camera lens to successfully degrade the quality of the videos
to inhibit privacy attributes and protect against adversarial attacks while
maintaining relevant features for activity recognition. We validate our
approach with extensive simulations and hardware experiments.",None,-1
47831805-a861-4191-95a3-9f733d026a94,Multimodal and Explainable Internet Meme Classification,0.107133,"In the current context where online platforms have been effectively
weaponized in a variety of geo-political events and social issues, Internet
memes make fair content moderation at scale even more difficult. Existing work
on meme classification and tracking has focused on black-box methods that do
not explicitly consider the semantics of the memes or the context of their
creation. In this paper, we pursue a modular and explainable architecture for
Internet meme understanding. We design and implement multimodal classification
methods that perform example- and prototype-based reasoning over training
cases, while leveraging both textual and visual SOTA models to represent the
individual cases. We study the relevance of our modular and explainable models
in detecting harmful memes on two existing tasks: Hate Speech Detection and
Misogyny Classification. We compare the performance between example- and
prototype-based methods, and between text, vision, and multimodal models,
across different categories of harmfulness (e.g., stereotype and
objectification). We devise a user-friendly interface that facilitates the
comparative analysis of examples retrieved by all of our models for any given
meme, informing the community about the strengths and limitations of these
explainable methods.",https://github.com/usc-isi-i2/meme-understanding,-1
25acd395-b15e-45b1-9b3f-1739a6015d28,Learning Progressive Modality-shared Transformers for Effective Visible-Infrared Person Re-identification,0.956954,"Visible-Infrared Person Re-Identification (VI-ReID) is a challenging
retrieval task under complex modality changes. Existing methods usually focus
on extracting discriminative visual features while ignoring the reliability and
commonality of visual features between different modalities. In this paper, we
propose a novel deep learning framework named Progressive Modality-shared
Transformer (PMT) for effective VI-ReID. To reduce the negative effect of
modality gaps, we first take the gray-scale images as an auxiliary modality and
propose a progressive learning strategy. Then, we propose a Modality-Shared
Enhancement Loss (MSEL) to guide the model to explore more reliable identity
information from modality-shared features. Finally, to cope with the problem of
large intra-class differences and small inter-class differences, we propose a
Discriminative Center Loss (DCL) combined with the MSEL to further improve the
discrimination of reliable features. Extensive experiments on SYSU-MM01 and
RegDB datasets show that our proposed framework performs better than most
state-of-the-art methods. For model reproduction, we release the source code at
https://github.com/hulu88/PMT.",https://github.com/hulu88/PMT,370
743f9007-e57e-46c0-b383-db0fb565108c,Practical Phase Retrieval Using Double Deep Image Priors,0.414824,"Phase retrieval (PR) concerns the recovery of complex phases from complex
magnitudes. We identify the connection between the difficulty level and the
number and variety of symmetries in PR problems. We focus on the most difficult
far-field PR (FFPR), and propose a novel method using double deep image priors.
In realistic evaluation, our method outperforms all competing methods by large
margins. As a single-instance method, our method requires no training data and
minimal hyperparameter tuning, and hence enjoys good practicality.",None,-1
1f8d4153-213d-4bea-9f16-94651ec273b3,Cyberbullying detection across social media platforms via platform-aware adversarial encoding,0.808821,"Despite the increasing interest in cyberbullying detection, existing efforts
have largely been limited to experiments on a single platform and their
generalisability across different social media platforms have received less
attention. We propose XP-CB, a novel cross-platform framework based on
Transformers and adversarial learning. XP-CB can enhance a Transformer
leveraging unlabelled data from the source and target platforms to come up with
a common representation while preventing platform-specific training. To
validate our proposed framework, we experiment on cyberbullying datasets from
three different platforms through six cross-platform configurations, showing
its effectiveness with both BERT and RoBERTa as the underlying Transformer
models.",None,-1
3a92a602-168f-46b7-a14c-038cadd1e3ad,GRAM: Fast Fine-tuning of Pre-trained Language Models for Content-based Collaborative Filtering,0.552016,"Content-based collaborative filtering (CCF) predicts user-item interactions
based on both users' interaction history and items' content information.
Recently, pre-trained language models (PLM) have been used to extract
high-quality item encodings for CCF. However, it is resource-intensive to train
a PLM-based CCF model in an end-to-end (E2E) manner, since optimization
involves back-propagating through every content encoding within a given user
interaction sequence. To tackle this issue, we propose GRAM (GRadient
Accumulation for Multi-modality in CCF), which exploits the fact that a given
item often appears multiple times within a batch of interaction histories.
Specifically, Single-step GRAM aggregates each item encoding's gradients for
back-propagation, with theoretic equivalence to the standard E2E training. As
an extension of Single-step GRAM, we propose Multi-step GRAM, which increases
the gradient update latency, achieving a further speedup with drastically less
GPU memory. GRAM significantly improves training efficiency (up to 146x) on
five datasets from two task domains of Knowledge Tracing and News
Recommendation. Our code is available at https://github.com/yoonseok312/GRAM.",https://github.com/yoonseok312/GRAM,-1
1fa4bf14-cd38-4333-9053-a1b98c178ec0,Multi-task Learning for Cross-Lingual Sentiment Analysis,0.764061,"This paper presents a cross-lingual sentiment analysis of news articles using
zero-shot and few-shot learning. The study aims to classify the Croatian news
articles with positive, negative, and neutral sentiments using the Slovene
dataset. The system is based on a trilingual BERT-based model trained in three
languages: English, Slovene, Croatian. The paper analyses different setups
using datasets in two languages and proposes a simple multi-task model to
perform sentiment classification. The evaluation is performed using the
few-shot and zero-shot scenarios in single-task and multi-task experiments for
Croatian and Slovene.",https://github.com/cleopatra-itn/SentimentAnalyserSLHRNews,1490
f570ed84-05c9-4a5a-b670-597b6e1e90d3,LaKo: Knowledge-driven Visual Question Answering via Late Knowledge-to-Text Injection,0.580291,"Visual question answering (VQA) often requires an understanding of visual
concepts and language semantics, which relies on external knowledge. Most
existing methods exploit pre-trained language models or/and unstructured text,
but the knowledge in these resources are often incomplete and noisy. Some other
methods prefer to use knowledge graphs (KGs) which often have intensive
structured knowledge, but the research is still quite preliminary. In this
paper, we propose LaKo, a knowledge-driven VQA method via Late
Knowledge-to-text Injection. To effectively incorporate an external KG, we
transfer triples into textual format and propose a late injection mechanism for
knowledge fusion. Finally we address VQA as a text generation task with an
effective encoder-decoder paradigm, which achieves state-of-the-art results on
OKVQA dataset.",https://github.com/hackerchenzhuo/LaKo,-1
6ca9c61d-a806-4204-b771-b6792b6560cb,SC-wLS: Towards Interpretable Feed-forward Camera Re-localization,0.859523,"Visual re-localization aims to recover camera poses in a known environment,
which is vital for applications like robotics or augmented reality.
Feed-forward absolute camera pose regression methods directly output poses by a
network, but suffer from low accuracy. Meanwhile, scene coordinate based
methods are accurate, but need iterative RANSAC post-processing, which brings
challenges to efficient end-to-end training and inference. In order to have the
best of both worlds, we propose a feed-forward method termed SC-wLS that
exploits all scene coordinate estimates for weighted least squares pose
regression. This differentiable formulation exploits a weight network imposed
on 2D-3D correspondences, and requires pose supervision only. Qualitative
results demonstrate the interpretability of learned weights. Evaluations on
7Scenes and Cambridge datasets show significantly promoted performance when
compared with former feed-forward counterparts. Moreover, our SC-wLS method
enables a new capability: self-supervised test-time adaptation on the weight
network. Codes and models are publicly available.",https://github.com/XinWu98/SC-wLSAbstract.Visualre-localizationaimstorecovercameraposesinaknownenvironment,-1
3c58645f-54eb-4a0a-a842-d55b8bf4a9b5,SpeedFolding: Learning Efficient Bimanual Folding of Garments,0.952553,"Folding garments reliably and efficiently is a long standing challenge in
robotic manipulation due to the complex dynamics and high dimensional
configuration space of garments. An intuitive approach is to initially
manipulate the garment to a canonical smooth configuration before folding. In
this work, we develop SpeedFolding, a reliable and efficient bimanual system,
which given user-defined instructions as folding lines, manipulates an
initially crumpled garment to (1) a smoothed and (2) a folded configuration.
Our primary contribution is a novel neural network architecture that is able to
predict pairs of gripper poses to parameterize a diverse set of bimanual action
primitives. After learning from 4300 human-annotated and self-supervised
actions, the robot is able to fold garments from a random initial configuration
in under 120s on average with a success rate of 93%. Real-world experiments
show that the system is able to generalize to unseen garments of different
color, shape, and stiffness. While prior work achieved 3-6 Folds Per Hour
(FPH), SpeedFolding achieves 30-40 FPH.",None,-1
387644ff-93ef-47c0-87ca-c34ea832e1e5,User-Centric Gender Rewriting,0.563221,"In this paper, we define the task of gender rewriting in contexts involving
two users (I and/or You) - first and second grammatical persons with
independent grammatical gender preferences. We focus on Arabic, a
gender-marking morphologically rich language. We develop a multi-step system
that combines the positive aspects of both rule-based and neural rewriting
models. Our results successfully demonstrate the viability of this approach on
a recently created corpus for Arabic gender rewriting, achieving 88.42 M2 F0.5
on a blind test set. Our proposed system improves over previous work on the
first-person-only version of this task, by 3.05 absolute increase in M2 F0.5.
We demonstrate a use case of our gender rewriting system by using it to
post-edit the output of a commercial MT system to provide personalized outputs
based on the users' grammatical gender preferences. We make our code, data, and
models publicly available.",https://github.com/CAMeL-Lab/gender-rewriting/,16583
34bd4ce3-8438-4d28-981a-68365cfcee9b,D2A-BSP: Distilled Data Association Belief Space Planning with Performance Guarantees Under Budget Constraints,0.539801,"Unresolved data association in ambiguous and perceptually aliased
environments leads to multi-modal hypotheses on both the robot's and the
environment state. To avoid catastrophic results, when operating in such
ambiguous environments, it is crucial to reason about data association within
Belief Space Planning (BSP). However, explicitly considering all possible data
associations, the number of hypotheses grows exponentially with the planning
horizon and determining the optimal action sequence quickly becomes
intractable. Moreover, with hard budget constraints where some non-negligible
hypotheses must be pruned, achieving performance guarantees is crucial. In this
work we present a computationally efficient novel approach that utilizes only a
distilled subset of hypotheses to solve BSP problems while reasoning about data
association. Furthermore, to provide performance guarantees, we derive error
bounds with respect to the optimal solution. We then demonstrate our approach
in an extremely aliased environment, where we manage to significantly reduce
computation time without compromising on the quality of the solution.",None,2485
3df3fd2b-5bcb-4e99-b057-e30f427a4619,Balancing Discriminability and Transferability for Source-Free Domain Adaptation,0.977451,"Conventional domain adaptation (DA) techniques aim to improve domain
transferability by learning domain-invariant representations; while
concurrently preserving the task-discriminability knowledge gathered from the
labeled source data. However, the requirement of simultaneous access to labeled
source and unlabeled target renders them unsuitable for the challenging
source-free DA setting. The trivial solution of realizing an effective original
to generic domain mapping improves transferability but degrades task
discriminability. Upon analyzing the hurdles from both theoretical and
empirical standpoints, we derive novel insights to show that a mixup between
original and corresponding translated generic samples enhances the
discriminability-transferability trade-off while duly respecting the
privacy-oriented source-free setting. A simple but effective realization of the
proposed insights on top of the existing source-free DA approaches yields
state-of-the-art performance with faster convergence. Beyond single-source, we
also outperform multi-source prior-arts across both classification and semantic
segmentation benchmarks.",https://github.com/iver56/audiomentations,13740
b0baaf0e-1845-403e-979c-09580454cd9e,Modeling the Lighting in Scenes as Style for Auto White-Balance Correction,0.3732,"Style may refer to different concepts (e.g. painting style, hairstyle,
texture, color, filter, etc.) depending on how the feature space is formed. In
this work, we propose a novel idea of interpreting the lighting in the single-
and multi-illuminant scenes as the concept of style. To verify this idea, we
introduce an enhanced auto white-balance (AWB) method that models the lighting
in single- and mixed-illuminant scenes as the style factor. Our AWB method does
not require any illumination estimation step, yet contains a network learning
to generate the weighting maps of the images with different WB settings.
Proposed network utilizes the style information, extracted from the scene by a
multi-head style extraction module. AWB correction is completed after blending
these weighting maps and the scene. Experiments on single- and mixed-illuminant
datasets demonstrate that our proposed method achieves promising correction
results when compared to the recent works. This shows that the lighting in the
scenes with multiple illuminations can be modeled by the concept of style.
Source code and trained models are available on
https://github.com/birdortyedi/lighting-as-style-awb-correction.",https://github.com/birdortyedi/lighting-as-style-awb-correction,-1
04c10fb0-c6e8-4d30-97b0-a5526a205c27,Non-Autoregressive Machine Translation: It's Not as Fast as it Seems,0.83748,"Efficient machine translation models are commercially important as they can
increase inference speeds, and reduce costs and carbon emissions. Recently,
there has been much interest in non-autoregressive (NAR) models, which promise
faster translation. In parallel to the research on NAR models, there have been
successful attempts to create optimized autoregressive models as part of the
WMT shared task on efficient translation. In this paper, we point out flaws in
the evaluation methodology present in the literature on NAR models and we
provide a fair comparison between a state-of-the-art NAR model and the
autoregressive submissions to the shared task. We make the case for consistent
evaluation of NAR models, and also for the importance of comparing NAR models
with other widely used methods for improving efficiency. We run experiments
with a connectionist-temporal-classification-based (CTC) NAR model implemented
in C++ and compare it with AR models using wall clock times. Our results show
that, although NAR models are faster on GPUs, with small batch sizes, they are
almost always slower under more realistic usage conditions. We call for more
realistic and extensive evaluation of NAR models in future work.",https://github.com/jindrahelcl/marian-dev,23570
a1f11077-f013-43c0-9fd7-c3d3df061743,Reconstructed Student-Teacher and Discriminative Networks for Anomaly Detection,0.678675,"Anomaly detection is an important problem in computer vision; however, the
scarcity of anomalous samples makes this task difficult. Thus, recent anomaly
detection methods have used only normal images with no abnormal areas for
training. In this work, a powerful anomaly detection method is proposed based
on student-teacher feature pyramid matching (STPM), which consists of a student
and teacher network. Generative models are another approach to anomaly
detection. They reconstruct normal images from an input and compute the
difference between the predicted normal and the input. Unfortunately, STPM does
not have the ability to generate normal images. To improve the accuracy of
STPM, this work uses a student network, as in generative models, to reconstruct
normal features. This improves the accuracy; however, the anomaly maps for
normal images are not clean because STPM does not use anomaly images for
training, which decreases the accuracy of the image-level anomaly detection. To
further improve accuracy, a discriminative network trained with
pseudo-anomalies from anomaly maps is used in our method, which consists of two
pairs of student-teacher networks and a discriminative network. The method
displayed high accuracy on the MVTec anomaly detection dataset.",None,-1
a831284c-9f5a-4b86-928d-89733c18acd3,ButterflyFlow: Building Invertible Layers with Butterfly Matrices,0.213822,"Normalizing flows model complex probability distributions using maps obtained
by composing invertible layers. Special linear layers such as masked and 1x1
convolutions play a key role in existing architectures because they increase
expressive power while having tractable Jacobians and inverses. We propose a
new family of invertible linear layers based on butterfly layers, which are
known to theoretically capture complex linear structures including permutations
and periodicity, yet can be inverted efficiently. This representational power
is a key advantage of our approach, as such structures are common in many
real-world datasets. Based on our invertible butterfly layers, we construct a
new class of normalizing flow models called ButterflyFlow. Empirically, we
demonstrate that ButterflyFlows not only achieve strong density estimation
results on natural images such as MNIST, CIFAR-10, and ImageNet 32x32, but also
obtain significantly better log-likelihoods on structured datasets such as
galaxy images and MIMIC-III patient cohorts -- all while being more efficient
in terms of memory and computation than relevant baselines.",None,-1
6b20af64-8e18-428a-b830-31ffc75a5991,Jacobian Computation for Cumulative B-Splines on SE(3) and Application to Continuous-Time Object Tracking,0.307826,"In this paper we propose a method that estimates the $SE(3)$ continuous
trajectories (orientation and translation) of the dynamic rigid objects present
in a scene, from multiple RGB-D views. Specifically, we fit the object
trajectories to cumulative B-Splines curves, which allow us to interpolate, at
any intermediate time stamp, not only their poses but also their linear and
angular velocities and accelerations. Additionally, we derive in this work the
analytical $SE(3)$ Jacobians needed by the optimization, being applicable to
any other approach that uses this type of curves. To the best of our knowledge
this is the first work that proposes 6-DoF continuous-time object tracking,
which we endorse with significant computational cost reduction thanks to our
analytical derivations. We evaluate our proposal in synthetic data and in a
public benchmark, showing competitive results in localization and significant
improvements in velocity estimation in comparison to discrete-time approaches.",None,-1
a5ea9f8c-dba5-463b-bc43-63e8a5d91ef6,Learning Across Domains and Devices: Style-Driven Source-Free Domain Adaptation in Clustered Federated Learning,0.649403,"Federated Learning (FL) has recently emerged as a possible way to tackle the
domain shift in real-world Semantic Segmentation (SS) without compromising the
private nature of the collected data. However, most of the existing works on FL
unrealistically assume labeled data in the remote clients. Here we propose a
novel task (FFREEDA) in which the clients' data is unlabeled and the server
accesses a source labeled dataset for pre-training only. To solve FFREEDA, we
propose LADD, which leverages the knowledge of the pre-trained model by
employing self-supervision with ad-hoc regularization techniques for local
training and introducing a novel federated clustered aggregation scheme based
on the clients' style. Our experiments show that our algorithm is able to
efficiently tackle the new task outperforming existing approaches. The code is
available at https://github.com/Erosinho13/LADD.",https://github.com/Erosinho13/LADD,-1
022a6860-1935-4e98-a364-950b78015431,In-Vehicle Interface Adaptation to Environment-Induced Cognitive Workload,0.521885,"Many car accidents are caused by human distractions, including cognitive
distractions. In-vehicle human-machine interfaces (HMIs) have evolved
throughout the years, providing more and more functions. Interaction with the
HMIs can, however, also lead to further distractions and, as a consequence,
accidents. To tackle this problem, we propose using adaptive HMIs that change
according to the mental workload of the driver. In this work, we present the
current status as well as preliminary results of a user study using
naturalistic secondary tasks while driving (i.e., the primary task) that
attempt to understand the effects of one such interface.",None,67
2affec14-cf16-4861-af60-2e54e56b50cf,Self-Supervised Domain Calibration and Uncertainty Estimation for Place Recognition,0.253216,"Visual place recognition techniques based on deep learning, which have
imposed themselves as the state-of-the-art in recent years, do not generalize
well to environments visually different from the training set. Thus, to achieve
top performance, it is sometimes necessary to fine-tune the networks to the
target environment. To this end, we propose a self-supervised domain
calibration procedure based on robust pose graph optimization from Simultaneous
Localization and Mapping (SLAM) as the supervision signal without requiring GPS
or manual labeling. Moreover, we leverage the procedure to improve uncertainty
estimation for place recognition matches which is important in safety critical
applications. We show that our approach can improve the performance of a
state-of-the-art technique on a target environment dissimilar from its training
set and that we can obtain uncertainty estimates. We believe that this approach
will help practitioners to deploy robust place recognition solutions in
real-world applications. Our code is available publicly:
https://github.com/MISTLab/vpr-calibration-and-uncertainty",https://github.com/MISTLab/vpr-calibration-and-uncertainty,2903
be5c75d8-3d71-493d-b66c-e2081ff2734c,FRAME: Evaluating Rationale-Label Consistency Metrics for Free-Text Rationales,0.578565,"Following how humans communicate, free-text rationales aim to use natural
language to explain neural language model (LM) behavior. However, free-text
rationales' unconstrained nature makes them prone to hallucination, so it is
important to have metrics for free-text rationale quality. Existing free-text
rationale metrics measure how consistent the rationale is with the LM's
predicted label, but there is no protocol for assessing such metrics'
reliability. Thus, we propose FRAME, a framework for evaluating rationale-label
consistency (RLC) metrics for free-text rationales. FRAME is based on three
axioms: (1) good metrics should yield highest scores for reference rationales,
which maximize RLC by construction; (2) good metrics should be appropriately
sensitive to semantic perturbation of rationales; and (3) good metrics should
be robust to variation in the LM's task performance. Across three text
classification datasets, we show that existing RLC metrics cannot satisfy all
three FRAME axioms, since they are implemented via model pretraining which
muddles the metric's signal. Then, we introduce a non-pretraining RLC metric
that greatly outperforms baselines on (1) and (3), while performing
competitively on (2). Finally, we discuss the limitations of using RLC to
evaluate free-text rationales.",None,-1
4fec8d23-c2a8-4cf2-918e-43bb06f824e3,DALL-E 2 Fails to Reliably Capture Common Syntactic Processes,0.457871,"Machine intelligence is increasingly being linked to claims about sentience,
language processing, and an ability to comprehend and transform natural
language into a range of stimuli. We systematically analyze the ability of
DALL-E 2 to capture 8 grammatical phenomena pertaining to compositionality that
are widely discussed in linguistics and pervasive in human language: binding
principles and coreference, passives, word order, coordination, comparatives,
negation, ellipsis, and structural ambiguity. Whereas young children routinely
master these phenomena, learning systematic mappings between syntax and
semantics, DALL-E 2 is unable to reliably infer meanings that are consistent
with the syntax. These results challenge recent claims concerning the capacity
of such systems to understand of human language. We make available the full set
of test materials as a benchmark for future testing.",None,-1
8950a2f1-f40f-41cc-abf1-3bf0cccb3cc2,Near-Infrared Depth-Independent Image Dehazing using Haar Wavelets,0.0773233,"We propose a fusion algorithm for haze removal that combines color
information from an RGB image and edge information extracted from its
corresponding NIR image using Haar wavelets. The proposed algorithm is based on
the key observation that NIR edge features are more prominent in the hazy
regions of the image than the RGB edge features in those same regions. To
combine the color and edge information, we introduce a haze-weight map which
proportionately distributes the color and edge information during the fusion
process. Because NIR images are, intrinsically, nearly haze-free, our work
makes no assumptions like existing works that rely on a scattering model and
essentially designing a depth-independent method. This helps in minimizing
artifacts and gives a more realistic sense to the restored haze-free image.
Extensive experiments show that the proposed algorithm is both qualitatively
and quantitatively better on several key metrics when compared to existing
state-of-the-art methods.",None,-1
01e2b936-0a1c-40bf-baa3-5e842ab697a8,Design of Fuzzy Logic Controller for Washing Machine,0.33322,"Things are becoming more advanced as technology advances,and machines now
perform the majority of the manual work. The most often used home appliance is
the washing machine for cloths. In this paper, we used the Mamdani approach and
created an algorithm based on multi-input multi-output. The algorithm is
implemented in Python.The results of this simulation show that the washing
machine provides better execution at a low computation cost",None,-1
ba596697-dd0e-408d-83c6-8cb00aed4432,Unified Chinese License Plate Detection and Recognition with High Efficiency,0.997996,"Recently, deep learning-based methods have reached an excellent performance
on License Plate (LP) detection and recognition tasks. However, it is still
challenging to build a robust model for Chinese LPs since there are not enough
large and representative datasets. In this work, we propose a new dataset named
Chinese Road Plate Dataset (CRPD) that contains multi-objective Chinese LP
images as a supplement to the existing public benchmarks. The images are mainly
captured with electronic monitoring systems with detailed annotations. To our
knowledge, CRPD is the largest public multi-objective Chinese LP dataset with
annotations of vertices. With CRPD, a unified detection and recognition network
with high efficiency is presented as the baseline. The network is end-to-end
trainable with totally real-time inference efficiency (30 fps with 640p). The
experiments on several public benchmarks demonstrate that our method has
reached competitive performance. The code and dataset will be publicly
available at https://github.com/yxgong0/CRPD.",https://github.com/yxgong0/CRPD,-1
99a22f8c-542d-40a8-a96a-5e3b28ff7d1f,TemporalUV: Capturing Loose Clothing with Temporally Coherent UV Coordinates,0.24396,"We propose a novel approach to generate temporally coherent UV coordinates
for loose clothing. Our method is not constrained by human body outlines and
can capture loose garments and hair. We implemented a differentiable pipeline
to learn UV mapping between a sequence of RGB inputs and textures via UV
coordinates. Instead of treating the UV coordinates of each frame separately,
our data generation approach connects all UV coordinates via feature matching
for temporal stability. Subsequently, a generative model is trained to balance
the spatial quality and temporal stability. It is driven by supervised and
unsupervised losses in both UV and image spaces. Our experiments show that the
trained models output high-quality UV coordinates and generalize to new poses.
Once a sequence of UV coordinates has been inferred by our model, it can be
used to flexibly synthesize new looks and modified visual styles. Compared to
existing methods, our approach reduces the computational workload to animate
new outfits by several orders of magnitude.",None,-1
eecf876d-4445-43b1-9749-a361c2ebad83,"Fast, Accurate and Memory-Efficient Partial Permutation Synchronization",0.465452,"Previous partial permutation synchronization (PPS) algorithms, which are
commonly used for multi-object matching, often involve computation-intensive
and memory-demanding matrix operations. These operations become intractable for
large scale structure-from-motion datasets. For pure permutation
synchronization, the recent Cycle-Edge Message Passing (CEMP) framework
suggests a memory-efficient and fast solution. Here we overcome the restriction
of CEMP to compact groups and propose an improved algorithm, CEMP-Partial, for
estimating the corruption levels of the observed partial permutations. It
allows us to subsequently implement a nonconvex weighted projected power method
without the need of spectral initialization. The resulting new PPS algorithm,
MatchFAME (Fast, Accurate and Memory-Efficient Matching), only involves sparse
matrix operations, and thus enjoys lower time and space complexities in
comparison to previous PPS algorithms. We prove that under adversarial
corruption, though without additive noise and with certain assumptions,
CEMP-Partial is able to exactly classify corrupted and clean partial
permutations. We demonstrate the state-of-the-art accuracy, speed and memory
efficiency of our method on both synthetic and real datasets.",None,-1
01a56791-637c-4bf7-9899-b9cf4b98b819,Practical Exposure Correction: Great Truths Are Always Simple,0.672288,"Improving the visual quality of the given degraded observation by correcting
exposure level is a fundamental task in the computer vision community. Existing
works commonly lack adaptability towards unknown scenes because of the
data-driven patterns (deep networks) and limited regularization (traditional
optimization), and they usually need time-consuming inference. These two points
heavily limit their practicability. In this paper, we establish a Practical
Exposure Corrector (PEC) that assembles the characteristics of efficiency and
performance. To be concrete, we rethink the exposure correction to provide a
linear solution with exposure-sensitive compensation. Around generating the
compensation, we introduce an exposure adversarial function as the key engine
to fully extract valuable information from the observation. By applying the
defined function, we construct a segmented shrinkage iterative scheme to
generate the desired compensation. Its shrinkage nature supplies powerful
support for algorithmic stability and robustness. Extensive experimental
evaluations fully reveal the superiority of our proposed PEC. The code is
available at https://rsliu.tech/PEC.",https://rsliu.tech/PEC,11667
92ee5409-b16c-4a86-8908-3bf66df831f5,Conversational Analysis of Daily Dialog Data using Polite Emotional Dialogue Acts,0.221199,"Many socio-linguistic cues are used in conversational analysis, such as
emotion, sentiment, and dialogue acts. One of the fundamental cues is
politeness, which linguistically possesses properties such as social manners
useful in conversational analysis. This article presents findings of polite
emotional dialogue act associations, where we can correlate the relationships
between the socio-linguistic cues. We confirm our hypothesis that the
utterances with the emotion classes Anger and Disgust are more likely to be
impolite. At the same time, Happiness and Sadness are more likely to be polite.
A less expectable phenomenon occurs with dialogue acts Inform and Commissive
which contain more polite utterances than Question and Directive. Finally, we
conclude on the future work of these findings to extend the learning of social
behaviours using politeness.",https://github.com/bothe/politeEDAs,-1
73d3c6ac-131b-46a4-8dcb-63c9b9d01184,A Graph-Based Method for Soccer Action Spotting Using Unsupervised Player Classification,0.575975,"Action spotting in soccer videos is the task of identifying the specific time
when a certain key action of the game occurs. Lately, it has received a large
amount of attention and powerful methods have been introduced. Action spotting
involves understanding the dynamics of the game, the complexity of events, and
the variation of video sequences. Most approaches have focused on the latter,
given that their models exploit the global visual features of the sequences. In
this work, we focus on the former by (a) identifying and representing the
players, referees, and goalkeepers as nodes in a graph, and by (b) modeling
their temporal interactions as sequences of graphs. For the player
identification, or player classification task, we obtain an accuracy of 97.72%
in our annotated benchmark. For the action spotting task, our method obtains an
overall performance of 57.83% average-mAP by combining it with other
audiovisual modalities. This performance surpasses similar graph-based methods
and has competitive results with heavy computing methods. Code and data are
available at https://github.com/IPCV/soccer_action_spotting.",https://github.com/IPCV/soccer_action_spotting,-1
03b6e914-5ce2-42ff-8b5b-677c83f16bbc,Data Determines Distributional Robustness in Contrastive Language Image Pre-training (CLIP),0.983459,"Contrastively trained language-image models such as CLIP, ALIGN, and BASIC
have demonstrated unprecedented robustness to multiple challenging natural
distribution shifts. Since these language-image models differ from previous
training approaches in several ways, an important question is what causes the
large robustness gains. We answer this question via a systematic experimental
investigation. Concretely, we study five different possible causes for the
robustness gains: (i) the training set size, (ii) the training distribution,
(iii) language supervision at training time, (iv) language supervision at test
time, and (v) the contrastive loss function. Our experiments show that the more
diverse training distribution is the main cause for the robustness gains, with
the other factors contributing little to no robustness. Beyond our experimental
results, we also introduce ImageNet-Captions, a version of ImageNet with
original text annotations from Flickr, to enable further controlled experiments
of language-image training.",None,-1
71bc4b52-7db8-4fbe-af29-1a38c0ea6fba,Introducing Randomized High Order Fuzzy Cognitive Maps as Reservoir Computing Models: A Case Study in Solar Energy and Load Forecasting,0.432556,"Fuzzy Cognitive Maps (FCMs) have emerged as an interpretable signed weighted
digraph method consisting of nodes (concepts) and weights which represent the
dependencies among the concepts. Although FCMs have attained considerable
achievements in various time series prediction applications, designing an FCM
model with time-efficient training method is still an open challenge. Thus,
this paper introduces a novel univariate time series forecasting technique,
which is composed of a group of randomized high order FCM models labeled
R-HFCM. The novelty of the proposed R-HFCM model is relevant to merging the
concepts of FCM and Echo State Network (ESN) as an efficient and particular
family of Reservoir Computing (RC) models, where the least squares algorithm is
applied to train the model. From another perspective, the structure of R-HFCM
consists of the input layer, reservoir layer, and output layer in which only
the output layer is trainable while the weights of each sub-reservoir
components are selected randomly and keep constant during the training process.
As case studies, this model considers solar energy forecasting with public data
for Brazilian solar stations as well as Malaysia dataset, which includes hourly
electric load and temperature data of the power supply company of the city of
Johor in Malaysia. The experiment also includes the effect of the map size,
activation function, the presence of bias and the size of the reservoir on the
accuracy of R-HFCM method. The obtained results confirm the outperformance of
the proposed R-HFCM model in comparison to the other methods. This study
provides evidence that FCM can be a new way to implement a reservoir of
dynamics in time series modelling.",None,-1
087d4609-cf59-45f5-bc58-9f74f1d94f3c,Language Does More Than Describe: On The Lack Of Figurative Speech in Text-To-Image Models,0.0287667,"The impressive capacity shown by recent text-to-image diffusion models to
generate high-quality pictures from textual input prompts has leveraged the
debate about the very definition of art. Nonetheless, these models have been
trained using text data collected from content-based labelling protocols that
focus on describing the items and actions in an image but neglect any
subjective appraisal. Consequently, these automatic systems need rigorous
descriptions of the elements and the pictorial style of the image to be
generated, otherwise failing to deliver. As potential indicators of the actual
artistic capabilities of current generative models, we characterise the
sentimentality, objectiveness and degree of abstraction of publicly available
text data used to train current text-to-image diffusion models. Considering the
sharp difference observed between their language style and that typically
employed in artistic contexts, we suggest generative models should incorporate
additional sources of subjective information in their training in order to
overcome (or at least to alleviate) some of their current limitations, thus
effectively unleashing a truly artistic and creative generation.",None,-1
cb1f451c-4dbd-4d79-be16-51d81fe4c6bb,Multilingual BERT has an accent: Evaluating English influences on fluency in multilingual models,0.0748553,"While multilingual language models can improve NLP performance on
low-resource languages by leveraging higher-resource languages, they also
reduce average performance on all languages (the 'curse of multilinguality').
Here we show another problem with multilingual models: grammatical structures
in higher-resource languages bleed into lower-resource languages, a phenomenon
we call grammatical structure bias. We show this bias via a novel method for
comparing the fluency of multilingual models to the fluency of monolingual
Spanish and Greek models: testing their preference for two carefully-chosen
variable grammatical structures (optional pronoun-drop in Spanish and optional
Subject-Verb ordering in Greek). We find that multilingual BERT is biased
toward the English-like setting (explicit pronouns and Subject-Verb-Object
ordering) as compared to our monolingual control language model. With our case
studies, we hope to bring to light the fine-grained ways in which multilingual
models can be biased,and encourage more linguistically-aware fluency
evaluation.",None,-1
193590bc-21e9-403d-9b80-e1b649ea3a7f,Cerebral Palsy Prediction with Frequency Attention Informed Graph Convolutional Networks,0.637302,"Early diagnosis and intervention are clinically considered the paramount part
of treating cerebral palsy (CP), so it is essential to design an efficient and
interpretable automatic prediction system for CP. We highlight a significant
difference between CP infants' frequency of human movement and that of the
healthy group, which improves prediction performance. However, the existing
deep learning-based methods did not use the frequency information of infants'
movement for CP prediction. This paper proposes a frequency attention informed
graph convolutional network and validates it on two consumer-grade RGB video
datasets, namely MINI-RGBD and RVI-38 datasets. Our proposed frequency
attention module aids in improving both classification performance and system
interpretability. In addition, we design a frequency-binning method that
retains the critical frequency of the human joint position data while filtering
the noise. Our prediction performance achieves state-of-the-art research on
both datasets. Our work demonstrates the effectiveness of frequency information
in supporting the prediction of CP non-intrusively and provides a way for
supporting the early diagnosis of CP in the resource-limited regions where the
clinical resources are not abundant.",https://github.com/zhz95/FAIGCN,3498
2950a477-20a2-49e9-b1e2-33734cda888f,Adapted Multimodal BERT with Layer-wise Fusion for Sentiment Analysis,0.156356,"Multimodal learning pipelines have benefited from the success of pretrained
language models. However, this comes at the cost of increased model parameters.
In this work, we propose Adapted Multimodal BERT (AMB), a BERT-based
architecture for multimodal tasks that uses a combination of adapter modules
and intermediate fusion layers. The adapter adjusts the pretrained language
model for the task at hand, while the fusion layers perform task-specific,
layer-wise fusion of audio-visual information with textual BERT
representations. During the adaptation process the pre-trained language model
parameters remain frozen, allowing for fast, parameter-efficient training. In
our ablations we see that this approach leads to efficient models, that can
outperform their fine-tuned counterparts and are robust to input noise. Our
experiments on sentiment analysis with CMU-MOSEI show that AMB outperforms the
current state-of-the-art across metrics, with 3.4% relative reduction in the
resulting error and 2.1% relative improvement in 7-class classification
accuracy.",None,-1
ba15a27d-98df-40ba-a40d-5327d78e6d52,A Novel Sampling Scheme for Text- and Image-Conditional Image Synthesis in Quantized Latent Spaces,0.0300174,"Recent advancements in the domain of text-to-image synthesis have culminated
in a multitude of enhancements pertaining to quality, fidelity, and diversity.
Contemporary techniques enable the generation of highly intricate visuals which
rapidly approach near-photorealistic quality. Nevertheless, as progress is
achieved, the complexity of these methodologies increases, consequently
intensifying the comprehension barrier between individuals within the field and
those external to it.
  In an endeavor to mitigate this disparity, we propose a streamlined approach
for text-to-image generation, which encompasses both the training paradigm and
the sampling process. Despite its remarkable simplicity, our method yields
aesthetically pleasing images with few sampling iterations, allows for
intriguing ways for conditioning the model, and imparts advantages absent in
state-of-the-art techniques. To demonstrate the efficacy of this approach in
achieving outcomes comparable to existing works, we have trained a one-billion
parameter text-conditional model, which we refer to as ""Paella"". In the
interest of fostering future exploration in this field, we have made our source
code and models publicly accessible for the research community.",https://github.com/delicious-tasty/Paella,-1
a30acb43-eb85-4430-b762-b279e70553e6,Diverse Multiple Trajectory Prediction Using a Two-stage Prediction Network Trained with Lane Loss,0.630542,"Prior arts in the field of motion predictions for autonomous driving tend to
focus on finding a trajectory that is close to the ground truth trajectory.
Such problem formulations and approaches, however, frequently lead to loss of
diversity and biased trajectory predictions. Therefore, they are unsuitable for
real-world autonomous driving where diverse and road-dependent multimodal
trajectory predictions are critical for safety. To this end, this study
proposes a novel loss function, \textit{Lane Loss}, that ensures map-adaptive
diversity and accommodates geometric constraints. A two-stage trajectory
prediction architecture with a novel trajectory candidate proposal module,
\textit{Trajectory Prediction Attention (TPA)}, is trained with Lane Loss
encourages multiple trajectories to be diversely distributed, covering feasible
maneuvers in a map-aware manner. Furthermore, considering that the existing
trajectory performance metrics are focusing on evaluating the accuracy based on
the ground truth future trajectory, a quantitative evaluation metric is also
suggested to evaluate the diversity of predicted multiple trajectories. The
experiments performed on the Argoverse dataset show that the proposed method
significantly improves the diversity of the predicted trajectories without
sacrificing the prediction accuracy.",None,-1
b0c1c895-d59b-46a2-93bd-4538abd6f4ab,"A Distant Supervision Corpus for Extracting Biomedical Relationships Between Chemicals, Diseases and Genes",0.451174,"We introduce ChemDisGene, a new dataset for training and evaluating
multi-class multi-label document-level biomedical relation extraction models.
Our dataset contains 80k biomedical research abstracts labeled with mentions of
chemicals, diseases, and genes, portions of which human experts labeled with 18
types of biomedical relationships between these entities (intended for
evaluation), and the remainder of which (intended for training) has been
distantly labeled via the CTD database with approximately 78\% accuracy. In
comparison to similar preexisting datasets, ours is both substantially larger
and cleaner; it also includes annotations linking mentions to their entities.
We also provide three baseline deep neural network relation extraction models
trained and evaluated on our new dataset.",https://github.com/chanzuckerberg/ChemDisGene,-1
8323484f-0d22-49e9-91ae-4937bf7ff9b6,MicroBERT: Effective Training of Low-resource Monolingual BERTs through Parameter Reduction and Multitask Learning,0.714053,"Transformer language models (TLMs) are critical for most NLP tasks, but they
are difficult to create for low-resource languages because of how much
pretraining data they require. In this work, we investigate two techniques for
training monolingual TLMs in a low-resource setting: greatly reducing TLM size,
and complementing the masked language modeling objective with two
linguistically rich supervised tasks (part-of-speech tagging and dependency
parsing). Results from 7 diverse languages indicate that our model, MicroBERT,
is able to produce marked improvements in downstream task evaluations relative
to a typical monolingual TLM pretraining approach. Specifically, we find that
monolingual MicroBERT models achieve gains of up to 18% for parser LAS and 11%
for NER F1 compared to a multilingual baseline, mBERT, while having less than
1% of its parameter count. We conclude reducing TLM parameter count and using
labeled data for pretraining low-resource TLMs can yield large quality benefits
and in some cases produce models that outperform multilingual approaches.",https://github.com/lgessler/microbert,-1
e5e23871-16e5-4d41-95f3-54c0137d6376,DetIE: Multilingual Open Information Extraction Inspired by Object Detection,0.45841,"State of the art neural methods for open information extraction (OpenIE)
usually extract triplets (or tuples) iteratively in an autoregressive or
predicate-based manner in order not to produce duplicates. In this work, we
propose a different approach to the problem that can be equally or more
successful. Namely, we present a novel single-pass method for OpenIE inspired
by object detection algorithms from computer vision. We use an order-agnostic
loss based on bipartite matching that forces unique predictions and a
Transformer-based encoder-only architecture for sequence labeling. The proposed
approach is faster and shows superior or similar performance in comparison with
state of the art models on standard benchmarks in terms of both quality metrics
and inference time. Our model sets the new state of the art performance of
67.7% F1 on CaRB evaluated as OIE2016 while being 3.35x faster at inference
than previous state of the art. We also evaluate the multilingual version of
our model in the zero-shot setting for two languages and introduce a strategy
for generating synthetic multilingual data to fine-tune the model for each
specific language. In this setting, we show performance improvement 15% on
multilingual Re-OIE2016, reaching 75% F1 for both Portuguese and Spanish
languages. Code and models are available at
https://github.com/sberbank-ai/DetIE.",https://github.com/sberbank-ai/DetIE,-1
d01e3fdc-df92-47e9-aad3-8faeeaaecaa7,Real or Fake Text?: Investigating Human Ability to Detect Boundaries Between Human-Written and Machine-Generated Text,0.759209,"As text generated by large language models proliferates, it becomes vital to
understand how humans engage with such text, and whether or not they are able
to detect when the text they are reading did not originate with a human writer.
Prior work on human detection of generated text focuses on the case where an
entire passage is either human-written or machine-generated. In this paper, we
study a more realistic setting where text begins as human-written and
transitions to being generated by state-of-the-art neural language models. We
show that, while annotators often struggle at this task, there is substantial
variance in annotator skill and that given proper incentives, annotators can
improve at this task over time. Furthermore, we conduct a detailed comparison
study and analyze how a variety of variables (model size, decoding strategy,
fine-tuning, prompt genre, etc.) affect human detection performance. Finally,
we collect error annotations from our participants and use them to show that
certain textual genres influence models to make different types of errors and
that certain sentence-level features correlate highly with annotator selection.
We release the RoFT dataset: a collection of over 21,000 human annotations
paired with error classifications to encourage future work in human detection
and evaluation of generated text.",https://github.com/liamdugan/human-detection,-1
c6dd35e2-f7be-47f4-b41d-7e01a36b1f3d,Half Wavelet Attention on M-Net+ for Low-Light Image Enhancement,0.895265,"Low-Light Image Enhancement is a computer vision task which intensifies the
dark images to appropriate brightness. It can also be seen as an ill-posed
problem in image restoration domain. With the success of deep neural networks,
the convolutional neural networks surpass the traditional algorithm-based
methods and become the mainstream in the computer vision area. To advance the
performance of enhancement algorithms, we propose an image enhancement network
(HWMNet) based on an improved hierarchical model: M-Net+. Specifically, we use
a half wavelet attention block on M-Net+ to enrich the features from wavelet
domain. Furthermore, our HWMNet has competitive performance results on two
image enhancement datasets in terms of quantitative metrics and visual quality.
The source code and pretrained model are available at
https://github.com/FanChiMao/HWMNet.",https://github.com/FanChiMao/HWMNet,-1
016511d1-9f07-44ba-93f8-4660b5db5db9,How Well Do Vision Transformers (VTs) Transfer To The Non-Natural Image Domain? An Empirical Study Involving Art Classification,0.0260904,"Vision Transformers (VTs) are becoming a valuable alternative to
Convolutional Neural Networks (CNNs) when it comes to problems involving
high-dimensional and spatially organized inputs such as images. However, their
Transfer Learning (TL) properties are not yet well studied, and it is not fully
known whether these neural architectures can transfer across different domains
as well as CNNs. In this paper we study whether VTs that are pre-trained on the
popular ImageNet dataset learn representations that are transferable to the
non-natural image domain. To do so we consider three well-studied art
classification problems and use them as a surrogate for studying the TL
potential of four popular VTs. Their performance is extensively compared
against that of four common CNNs across several TL experiments. Our results
show that VTs exhibit strong generalization properties and that these networks
are more powerful feature extractors than CNNs.",https://github.com/IndoorAdventurer/ViTTransferLearningForArtClassification,-1
5d12e717-c269-4205-8758-1eb705a7827a,Surgical Fine-Tuning Improves Adaptation to Distribution Shifts,0.906729,"A common approach to transfer learning under distribution shift is to
fine-tune the last few layers of a pre-trained model, preserving learned
features while also adapting to the new task. This paper shows that in such
settings, selectively fine-tuning a subset of layers (which we term surgical
fine-tuning) matches or outperforms commonly used fine-tuning approaches.
Moreover, the type of distribution shift influences which subset is more
effective to tune: for example, for image corruptions, fine-tuning only the
first few layers works best. We validate our findings systematically across
seven real-world data tasks spanning three types of distribution shifts.
Theoretically, we prove that for two-layer neural networks in an idealized
setting, first-layer tuning can outperform fine-tuning all layers. Intuitively,
fine-tuning more parameters on a small target dataset can cause information
learned during pre-training to be forgotten, and the relevant information
depends on the type of shift.",None,-1
8e0f91b8-c2ac-4e72-a793-3713a49d83da,Domain-Agnostic Prior for Transfer Semantic Segmentation,0.4126,"Unsupervised domain adaptation (UDA) is an important topic in the computer
vision community. The key difficulty lies in defining a common property between
the source and target domains so that the source-domain features can align with
the target-domain semantics. In this paper, we present a simple and effective
mechanism that regularizes cross-domain representation learning with a
domain-agnostic prior (DAP) that constrains the features extracted from source
and target domains to align with a domain-agnostic space. In practice, this is
easily implemented as an extra loss term that requires a little extra costs. In
the standard evaluation protocol of transferring synthesized data to real data,
we validate the effectiveness of different types of DAP, especially that
borrowed from a text embedding model that shows favorable performance beyond
the state-of-the-art UDA approaches in terms of segmentation accuracy. Our
research reveals that UDA benefits much from better proxies, possibly from
other data modalities.",None,-1
42fbd4c1-4a02-4296-a713-7ef5a998a5ac,Data-Driven Online Interactive Bidding Strategy for Demand Response,0.155924,"Demand response (DR), as one of the important energy resources in the
future's grid, provides the services of peak shaving, enhancing the efficiency
of renewable energy utilization with a short response period, and low cost.
Various categories of DR are established, e.g. automated DR, incentive DR,
emergency DR, and demand bidding. However, with the practical issue of the
unawareness of residential and commercial consumers' utility models, the
researches about demand bidding aggregator involved in the electricity market
are just at the beginning stage. For this issue, the bidding price and bidding
quantity are two required decision variables while considering the
uncertainties due to the market and participants. In this paper, we determine
the bidding and purchasing strategy simultaneously employing the smart meter
data and functions. A two-agent deep deterministic policy gradient method is
developed to optimize the decisions through learning historical bidding
experiences. The online learning further utilizes the daily newest bidding
experience attained to ensure trend tracing and self-adaptation. Two
environment simulators are adopted for testifying the robustness of the model.
The results prove that when facing diverse situations the proposed model can
earn the optimal profit via off/online learning the bidding rules and robustly
making the proper bid.",None,-1
6ea0fa94-3e1e-4d8c-a0fd-424d6d29dc95,Automatic Language Identification for Celtic Texts,0.0827117,"Language identification is an important Natural Language Processing task. It
has been thoroughly researched in the literature. However, some issues are
still open. This work addresses the identification of the related low-resource
languages on the example of the Celtic language family.
  This work's main goals were: (1) to collect the dataset of three Celtic
languages; (2) to prepare a method to identify the languages from the Celtic
family, i.e. to train a successful classification model; (3) to evaluate the
influence of different feature extraction methods, and explore the
applicability of the unsupervised models as a feature extraction technique; (4)
to experiment with the unsupervised feature extraction on a reduced annotated
set.
  We collected a new dataset including Irish, Scottish, Welsh and English
records. We tested supervised models such as SVM and neural networks with
traditional statistical features alongside the output of clustering,
autoencoder, and topic modelling methods. The analysis showed that the
unsupervised features could serve as a valuable extension to the n-gram feature
vectors. It led to an improvement in performance for more entangled classes.
The best model achieved a 98\% F1 score and 97\% MCC. The dense neural network
consistently outperformed the SVM model.
  The low-resource languages are also challenging due to the scarcity of
available annotated training data. This work evaluated the performance of the
classifiers using the unsupervised feature extraction on the reduced labelled
dataset to handle this issue. The results uncovered that the unsupervised
feature vectors are more robust to the labelled set reduction. Therefore, they
proved to help achieve comparable classification performance with much less
labelled data.",None,-1
2ffcc61f-63e2-4446-98d1-31dac2ecc80e,"CVM-Cervix: A Hybrid Cervical Pap-Smear Image Classification Framework Using CNN, Visual Transformer and Multilayer Perceptron",0.768205,"Cervical cancer is the seventh most common cancer among all the cancers
worldwide and the fourth most common cancer among women. Cervical cytopathology
image classification is an important method to diagnose cervical cancer. Manual
screening of cytopathology images is time-consuming and error-prone. The
emergence of the automatic computer-aided diagnosis system solves this problem.
This paper proposes a framework called CVM-Cervix based on deep learning to
perform cervical cell classification tasks. It can analyze pap slides quickly
and accurately. CVM-Cervix first proposes a Convolutional Neural Network module
and a Visual Transformer module for local and global feature extraction
respectively, then a Multilayer Perceptron module is designed to fuse the local
and global features for the final classification. Experimental results show the
effectiveness and potential of the proposed CVM-Cervix in the field of cervical
Pap smear image classification. In addition, according to the practical needs
of clinical work, we perform a lightweight post-processing to compress the
model.",None,14255
340caa25-454f-443d-a6a2-7ea2d7d607a8,DialCrowd 2.0: A Quality-Focused Dialog System Crowdsourcing Toolkit,0.437403,"Dialog system developers need high-quality data to train, fine-tune and
assess their systems. They often use crowdsourcing for this since it provides
large quantities of data from many workers. However, the data may not be of
sufficiently good quality. This can be due to the way that the requester
presents a task and how they interact with the workers. This paper introduces
DialCrowd 2.0 to help requesters obtain higher quality data by, for example,
presenting tasks more clearly and facilitating effective communication with
workers. DialCrowd 2.0 guides developers in creating improved Human
Intelligence Tasks (HITs) and is directly applicable to the workflows used
currently by developers and researchers.",None,14484
8c589d35-cc50-425c-8134-1b31e21c14ad,Unbiased Multi-Modality Guidance for Image Inpainting,0.481432,"Image inpainting is an ill-posed problem to recover missing or damaged image
content based on incomplete images with masks. Previous works usually predict
the auxiliary structures (e.g., edges, segmentation and contours) to help fill
visually realistic patches in a multi-stage fashion. However, imprecise
auxiliary priors may yield biased inpainted results. Besides, it is
time-consuming for some methods to be implemented by multiple stages of complex
neural networks. To solve this issue, we develop an end-to-end multi-modality
guided transformer network, including one inpainting branch and two auxiliary
branches for semantic segmentation and edge textures. Within each transformer
block, the proposed multi-scale spatial-aware attention module can learn the
multi-modal structural features efficiently via auxiliary denormalization.
Different from previous methods relying on direct guidance from biased priors,
our method enriches semantically consistent context in an image based on
discriminative interplay information from multiple modalities. Comprehensive
experiments on several challenging image inpainting datasets show that our
method achieves state-of-the-art performance to deal with various
regular/irregular masks efficiently.",None,-1
03a4c408-4d0b-4c65-9a4a-d421d2b4df94,SmallCap: Lightweight Image Captioning Prompted with Retrieval Augmentation,0.669765,"Recent advances in image captioning have focused on scaling the data and
model size, substantially increasing the cost of pre-training and finetuning.
As an alternative to large models, we present SmallCap, which generates a
caption conditioned on an input image and related captions retrieved from a
datastore. Our model is lightweight and fast to train, as the only learned
parameters are in newly introduced cross-attention layers between a pre-trained
CLIP encoder and GPT-2 decoder. SmallCap can transfer to new domains without
additional finetuning and can exploit large-scale data in a training-free
fashion since the contents of the datastore can be readily replaced. Our
experiments show that SmallCap, trained only on COCO, has competitive
performance on this benchmark, and also transfers to other domains without
retraining, solely through retrieval from target-domain data. Further
improvement is achieved through the training-free exploitation of diverse
human-labeled and web data, which proves to be effective for a range of
domains, including the nocaps benchmark, designed to test generalization to
unseen visual concepts.",https://github.com/RitaRamo/smallcap,-1
07e0ce8c-c6e6-439b-b313-4eed5abbf495,Instance-Dependent Noisy Label Learning via Graphical Modelling,0.65292,"Noisy labels are unavoidable yet troublesome in the ecosystem of deep
learning because models can easily overfit them. There are many types of label
noise, such as symmetric, asymmetric and instance-dependent noise (IDN), with
IDN being the only type that depends on image information. Such dependence on
image information makes IDN a critical type of label noise to study, given that
labelling mistakes are caused in large part by insufficient or ambiguous
information about the visual classes present in images. Aiming to provide an
effective technique to address IDN, we present a new graphical modelling
approach called InstanceGM, that combines discriminative and generative models.
The main contributions of InstanceGM are: i) the use of the continuous
Bernoulli distribution to train the generative model, offering significant
training advantages, and ii) the exploration of a state-of-the-art noisy-label
discriminative classifier to generate clean labels from instance-dependent
noisy-label samples. InstanceGM is competitive with current noisy-label
learning approaches, particularly in IDN benchmarks using synthetic and
real-world datasets, where our method shows better accuracy than the
competitors in most experiments.",https://github.com/a5507203/IDLN,-1
0416eaa1-1e34-4b29-b70b-1ff207f7a2b1,Unsupervised Human Action Recognition with Skeletal Graph Laplacian and Self-Supervised Viewpoints Invariance,0.878565,"This paper presents a novel end-to-end method for the problem of
skeleton-based unsupervised human action recognition. We propose a new
architecture with a convolutional autoencoder that uses graph Laplacian
regularization to model the skeletal geometry across the temporal dynamics of
actions. Our approach is robust towards viewpoint variations by including a
self-supervised gradient reverse layer that ensures generalization across
camera views. The proposed method is validated on NTU-60 and NTU-120
large-scale datasets in which it outperforms all prior unsupervised
skeleton-based approaches on the cross-subject, cross-view, and cross-setup
protocols. Although unsupervised, our learnable representation allows our
method even to surpass a few supervised skeleton-based action recognition
methods. The code is available in:
www.github.com/IIT-PAVIS/UHAR_Skeletal_Laplacian",www.github.com/IIT-PAVIS/UHAR_Skeletal_Laplacian,5556
46517c33-f805-4d6b-8a30-4621fd159916,Restoring Vision in Hazy Weather with Hierarchical Contrastive Learning,0.67158,"Image restoration under hazy weather condition, which is called single image
dehazing, has been of significant interest for various computer vision
applications. In recent years, deep learning-based methods have achieved
success. However, existing image dehazing methods typically neglect the
hierarchy of features in the neural network and fail to exploit their
relationships fully. To this end, we propose an effective image dehazing method
named Hierarchical Contrastive Dehazing (HCD), which is based on feature fusion
and contrastive learning strategies. HCD consists of a hierarchical dehazing
network (HDN) and a novel hierarchical contrastive loss (HCL). Specifically,
the core design in the HDN is a hierarchical interaction module, which utilizes
multi-scale activation to revise the feature responses hierarchically. To
cooperate with the training of HDN, we propose HCL which performs contrastive
learning on hierarchically paired exemplars, facilitating haze removal.
Extensive experiments on public datasets, RESIDE, HazeRD, and DENSE-HAZE,
demonstrate that HCD quantitatively outperforms the state-of-the-art methods in
terms of PSNR, SSIM and achieves better visual quality.",None,-1
1e611b82-3626-4a9b-b5df-523995b5ded7,Choose Your QA Model Wisely: A Systematic Study of Generative and Extractive Readers for Question Answering,0.376032,"While both extractive and generative readers have been successfully applied
to the Question Answering (QA) task, little attention has been paid toward the
systematic comparison of them. Characterizing the strengths and weaknesses of
the two readers is crucial not only for making a more informed reader selection
in practice but also for developing a deeper understanding to foster further
research on improving readers in a principled manner. Motivated by this goal,
we make the first attempt to systematically study the comparison of extractive
and generative readers for question answering. To be aligned with the
state-of-the-art, we explore nine transformer-based large pre-trained language
models (PrLMs) as backbone architectures. Furthermore, we organize our findings
under two main categories: (1) keeping the architecture invariant, and (2)
varying the underlying PrLMs. Among several interesting findings, it is
important to highlight that (1) the generative readers perform better in long
context QA, (2) the extractive readers perform better in short context while
also showing better out-of-domain generalization, and (3) the encoder of
encoder-decoder PrLMs (e.g., T5) turns out to be a strong extractive reader and
outperforms the standard choice of encoder-only PrLMs (e.g., RoBERTa). We also
study the effect of multi-task learning on the two types of readers varying the
underlying PrLMs and perform qualitative and quantitative diagnosis to provide
further insights into future directions in modeling better readers.",None,14059
74e733b0-c1d1-41d8-aa61-32e6cc3b2a38,KGI: An Integrated Framework for Knowledge Intensive Language Tasks,0.24863,"In this paper, we present a system to showcase the capabilities of the latest
state-of-the-art retrieval augmented generation models trained on
knowledge-intensive language tasks, such as slot filling, open domain question
answering, dialogue, and fact-checking. Moreover, given a user query, we show
how the output from these different models can be combined to cross-examine the
outputs of each other. Particularly, we show how accuracy in dialogue can be
improved using the question answering model. We are also releasing all models
used in the demo as a contribution of this paper. A short video demonstrating
the system is available at https://ibm.box.com/v/emnlp2022-demo.",https://huggingface.co/ibm,-1
d4164fb9-a4a3-4419-8e4a-9df84e7a4c9f,Uncertainty-aware Personal Assistant for Making Personalized Privacy Decisions,0.683977,"Many software systems, such as online social networks enable users to share
information about themselves. While the action of sharing is simple, it
requires an elaborate thought process on privacy: what to share, with whom to
share, and for what purposes. Thinking about these for each piece of content to
be shared is tedious. Recent approaches to tackle this problem build personal
assistants that can help users by learning what is private over time and
recommending privacy labels such as private or public to individual content
that a user considers sharing. However, privacy is inherently ambiguous and
highly personal. Existing approaches to recommend privacy decisions do not
address these aspects of privacy sufficiently. Ideally, a personal assistant
should be able to adjust its recommendation based on a given user, considering
that user's privacy understanding. Moreover, the personal assistant should be
able to assess when its recommendation would be uncertain and let the user make
the decision on her own. Accordingly, this paper proposes a personal assistant
that uses evidential deep learning to classify content based on its privacy
label. An important characteristic of the personal assistant is that it can
model its uncertainty in its decisions explicitly, determine that it does not
know the answer, and delegate from making a recommendation when its uncertainty
is high. By factoring in the user's own understanding of privacy, such as risk
factors or own labels, the personal assistant can personalize its
recommendations per user. We evaluate our proposed personal assistant using a
well-known data set. Our results show that our personal assistant can
accurately identify uncertain cases, personalize them to its user's needs, and
thus helps users preserve their privacy well.",None,-1
573250c3-b569-4110-8a8b-0c6a50b3f150,Knowledge Is Flat: A Seq2Seq Generative Framework for Various Knowledge Graph Completion,0.834493,"Knowledge Graph Completion (KGC) has been recently extended to multiple
knowledge graph (KG) structures, initiating new research directions, e.g.
static KGC, temporal KGC and few-shot KGC. Previous works often design KGC
models closely coupled with specific graph structures, which inevitably results
in two drawbacks: 1) structure-specific KGC models are mutually incompatible;
2) existing KGC methods are not adaptable to emerging KGs. In this paper, we
propose KG-S2S, a Seq2Seq generative framework that could tackle different
verbalizable graph structures by unifying the representation of KG facts into
""flat"" text, regardless of their original form. To remedy the KG structure
information loss from the ""flat"" text, we further improve the input
representations of entities and relations, and the inference algorithm in
KG-S2S. Experiments on five benchmarks show that KG-S2S outperforms many
competitive baselines, setting new state-of-the-art performance. Finally, we
analyze KG-S2S's ability on the different relations and the Non-entity
Generations.",https://github.com/chenchens190009/KG-S2S,-1
b7663622-ee2d-4045-a04d-aa207f88d823,Unsupervised Domain Adaptation for COVID-19 Information Service with Contrastive Adversarial Domain Mixup,0.377368,"In the real-world application of COVID-19 misinformation detection, a
fundamental challenge is the lack of the labeled COVID data to enable
supervised end-to-end training of the models, especially at the early stage of
the pandemic. To address this challenge, we propose an unsupervised domain
adaptation framework using contrastive learning and adversarial domain mixup to
transfer the knowledge from an existing source data domain to the target
COVID-19 data domain. In particular, to bridge the gap between the source
domain and the target domain, our method reduces a radial basis function (RBF)
based discrepancy between these two domains. Moreover, we leverage the power of
domain adversarial examples to establish an intermediate domain mixup, where
the latent representations of the input text from both domains could be mixed
during the training process. Extensive experiments on multiple real-world
datasets suggest that our method can effectively adapt misinformation detection
systems to the unseen COVID-19 target domain with significant improvements
compared to the state-of-the-art baselines.",None,-1
310969e7-60d7-4778-a0d1-946e1e9f6619,Quantifying Robustness to Adversarial Word Substitutions,0.10347,"Deep-learning-based NLP models are found to be vulnerable to word
substitution perturbations. Before they are widely adopted, the fundamental
issues of robustness need to be addressed. Along this line, we propose a formal
framework to evaluate word-level robustness. First, to study safe regions for a
model, we introduce robustness radius which is the boundary where the model can
resist any perturbation. As calculating the maximum robustness radius is
computationally hard, we estimate its upper and lower bound. We repurpose
attack methods as ways of seeking upper bound and design a pseudo-dynamic
programming algorithm for a tighter upper bound. Then verification method is
utilized for a lower bound. Further, for evaluating the robustness of regions
outside a safe radius, we reexamine robustness from another view:
quantification. A robustness metric with a rigorous statistical guarantee is
introduced to measure the quantification of adversarial examples, which
indicates the model's susceptibility to perturbations outside the safe radius.
The metric helps us figure out why state-of-the-art models like BERT can be
easily fooled by a few word substitutions, but generalize well in the presence
of real-world noises.",None,8526
6e9e0a66-3877-4e98-b7cd-4b3cb3bd8efd,Weakly Supervised Data Augmentation Through Prompting for Dialogue Understanding,0.349816,"Dialogue understanding tasks often necessitate abundant annotated data to
achieve good performance and that presents challenges in low-resource settings.
To alleviate this barrier, we explore few-shot data augmentation for dialogue
understanding by prompting large pre-trained language models and present a
novel approach that iterates on augmentation quality by applying
weakly-supervised filters. We evaluate our methods on the emotion and act
classification tasks in DailyDialog and the intent classification task in
Facebook Multilingual Task-Oriented Dialogue. Models fine-tuned on our
augmented data mixed with few-shot ground truth data are able to approach or
surpass existing state-of-the-art performance on both datasets. For DailyDialog
specifically, using 10% of the ground truth data we outperform the current
state-of-the-art model which uses 100% of the data.",https://github.com/kingoflolz/mesh-transformer-jax,-1
e05e0031-eaba-4476-9bb4-1a17b6137abd,TuGeBiC: A Turkish German Bilingual Code-Switching Corpus,0.0260293,"In this paper we describe the process of collection, transcription, and
annotation of recordings of spontaneous speech samples from Turkish-German
bilinguals, and the compilation of a corpus called TuGeBiC. Participants in the
study were adult Turkish-German bilinguals living in Germany or Turkey at the
time of recording in the first half of the 1990s. The data were manually
tokenised and normalised, and all proper names (names of participants and
places mentioned in the conversations) were replaced with pseudonyms.
Token-level automatic language identification was performed, which made it
possible to establish the proportions of words from each language. The corpus
is roughly balanced between both languages. We also present quantitative
information about the number of code-switches, and give examples of different
types of code-switching found in the data. The resulting corpus has been made
freely available to the research community.",https://github.com/ozlemcek/TuGeBiC,-1
5d88efd0-9305-4d26-9f7f-c3629a63be6a,PAL: Persona-Augmented Emotional Support Conversation Generation,0.951647,"Due to the lack of human resources for mental health support, there is an
increasing demand for employing conversational agents for support. Recent work
has demonstrated the effectiveness of dialogue models in providing emotional
support. As previous studies have demonstrated that seekers' persona is an
important factor for effective support, we investigate whether there are
benefits to modeling such information in dialogue models for support. In this
paper, our empirical analysis verifies that persona has an important impact on
emotional support. Therefore, we propose a framework for dynamically inferring
and modeling seekers' persona. We first train a model for inferring the
seeker's persona from the conversation history. Accordingly, we propose PAL, a
model that leverages persona information and, in conjunction with our
strategy-based controllable generation method, provides personalized emotional
support. Automatic and manual evaluations demonstrate that PAL achieves
state-of-the-art results, outperforming the baselines on the studied benchmark.
Our code and data are publicly available at https://github.com/chengjl19/PAL.",https://github.com/chengjl19/PAL,-1
7088039f-676b-4fba-be8d-d8f87a7d4b46,"How ""Multi"" is Multi-Document Summarization?",0.69657,"The task of multi-document summarization (MDS) aims at models that, given
multiple documents as input, are able to generate a summary that combines
disperse information, originally spread across these documents. Accordingly, it
is expected that both reference summaries in MDS datasets, as well as system
summaries, would indeed be based on such dispersed information. In this paper,
we argue for quantifying and assessing this expectation. To that end, we
propose an automated measure for evaluating the degree to which a summary is
``disperse'', in the sense of the number of source documents needed to cover
its content. We apply our measure to empirically analyze several popular MDS
datasets, with respect to their reference summaries, as well as the output of
state-of-the-art systems. Our results show that certain MDS datasets barely
require combining information from multiple documents, where a single document
often covers the full summary content. Overall, we advocate using our metric
for assessing and improving the degree to which summarization datasets require
combining multi-document information, and similarly how summarization models
actually meet this challenge. Our code is available in
https://github.com/ariecattan/multi_mds.",https://github.com/ariecattan/multi_mds,-1
188d8162-ec2b-4a0c-88c3-8521b30d7dd4,The Role of Exploration for Task Transfer in Reinforcement Learning,0.156956,"The exploration--exploitation trade-off in reinforcement learning (RL) is a
well-known and much-studied problem that balances greedy action selection with
novel experience, and the study of exploration methods is usually only
considered in the context of learning the optimal policy for a single learning
task. However, in the context of online task transfer, where there is a change
to the task during online operation, we hypothesize that exploration strategies
that anticipate the need to adapt to future tasks can have a pronounced impact
on the efficiency of transfer. As such, we re-examine the
exploration--exploitation trade-off in the context of transfer learning. In
this work, we review reinforcement learning exploration methods, define a
taxonomy with which to organize them, analyze these methods' differences in the
context of task transfer, and suggest avenues for future investigation.",None,-1
293cfe94-f890-4671-a96e-abe551b43c3a,Consistency Regularization for Domain Adaptation,0.0477416,"Collection of real world annotations for training semantic segmentation
models is an expensive process. Unsupervised domain adaptation (UDA) tries to
solve this problem by studying how more accessible data such as synthetic data
can be used to train and adapt models to real world images without requiring
their annotations. Recent UDA methods applies self-learning by training on
pixel-wise classification loss using a student and teacher network. In this
paper, we propose the addition of a consistency regularization term to
semi-supervised UDA by modelling the inter-pixel relationship between elements
in networks' output. We demonstrate the effectiveness of the proposed
consistency regularization term by applying it to the state-of-the-art DAFormer
framework and improving mIoU19 performance on the GTA5 to Cityscapes benchmark
by 0.8 and mIou16 performance on the SYNTHIA to Cityscapes benchmark by 1.2.",https://github.com/kw01sg/CRDA,-1
05f108de-6f83-4f87-9e63-4607eab42a49,Improving Neural Machine Translation of Indigenous Languages with Multilingual Transfer Learning,0.271443,"Machine translation (MT) involving Indigenous languages, including those
possibly endangered, is challenging due to lack of sufficient parallel data. We
describe an approach exploiting bilingual and multilingual pretrained MT models
in a transfer learning setting to translate from Spanish to ten South American
Indigenous languages. Our models set new SOTA on five out of the ten language
pairs we consider, even doubling performance on one of these five pairs. Unlike
previous SOTA that perform data augmentation to enlarge the train sets, we
retain the low-resource setting to test the effectiveness of our models under
such a constraint. In spite of the rarity of linguistic information available
about the Indigenous languages, we offer a number of quantitative and
qualitative analyses (e.g., as to morphology, tokenization, and orthography) to
contextualize our results.",None,-1
c2193b38-9ff9-470f-8699-e8503c36761a,Learning Attention-based Representations from Multiple Patterns for Relation Prediction in Knowledge Graphs,0.0407972,"Knowledge bases, and their representations in the form of knowledge graphs
(KGs), are naturally incomplete. Since scientific and industrial applications
have extensively adopted them, there is a high demand for solutions that
complete their information. Several recent works tackle this challenge by
learning embeddings for entities and relations, then employing them to predict
new relations among the entities. Despite their aggrandizement, most of those
methods focus only on the local neighbors of a relation to learn the
embeddings. As a result, they may fail to capture the KGs' context information
by neglecting long-term dependencies and the propagation of entities'
semantics. In this manuscript, we propose {\AE}MP (Attention-based Embeddings
from Multiple Patterns), a novel model for learning contextualized
representations by: (i) acquiring entities' context information through an
attention-enhanced message-passing scheme, which captures the entities' local
semantics while focusing on different aspects of their neighborhood; and (ii)
capturing the semantic context, by leveraging the paths and their relationships
between entities. Our empirical findings draw insights into how attention
mechanisms can improve entities' context representation and how combining
entities and semantic path contexts improves the general representation of
entities and the relation predictions. Experimental results on several large
and small knowledge graph benchmarks show that {\AE}MP either outperforms or
competes with state-of-the-art relation prediction methods.",https://github.com/MeLLL-UFF/AEMP,-1
6a50b866-d4bf-4410-a5f6-1fc42c4561c9,MM-DFN: Multimodal Dynamic Fusion Network for Emotion Recognition in Conversations,0.99092,"Emotion Recognition in Conversations (ERC) has considerable prospects for
developing empathetic machines. For multimodal ERC, it is vital to understand
context and fuse modality information in conversations. Recent graph-based
fusion methods generally aggregate multimodal information by exploring unimodal
and cross-modal interactions in a graph. However, they accumulate redundant
information at each layer, limiting the context understanding between
modalities. In this paper, we propose a novel Multimodal Dynamic Fusion Network
(MM-DFN) to recognize emotions by fully understanding multimodal conversational
context. Specifically, we design a new graph-based dynamic fusion module to
fuse multimodal contextual features in a conversation. The module reduces
redundancy and enhances complementarity between modalities by capturing the
dynamics of contextual information in different semantic spaces. Extensive
experiments on two public benchmark datasets demonstrate the effectiveness and
superiority of MM-DFN.",https://github.com/zerohd4869/MM-DFN,-1
f015a043-8ff9-4425-9915-9648dcdfab7a,Wavelet Feature Maps Compression for Image-to-Image CNNs,0.0652204,"Convolutional Neural Networks (CNNs) are known for requiring extensive
computational resources, and quantization is among the best and most common
methods for compressing them. While aggressive quantization (i.e., less than
4-bits) performs well for classification, it may cause severe performance
degradation in image-to-image tasks such as semantic segmentation and depth
estimation. In this paper, we propose Wavelet Compressed Convolution (WCC) -- a
novel approach for high-resolution activation maps compression integrated with
point-wise convolutions, which are the main computational cost of modern
architectures. To this end, we use an efficient and hardware-friendly
Haar-wavelet transform, known for its effectiveness in image compression, and
define the convolution on the compressed activation map. We experiment with
various tasks that benefit from high-resolution input. By combining WCC with
light quantization, we achieve compression rates equivalent to 1-4bit
activation quantization with relatively small and much more graceful
degradation in performance. Our code is available at
https://github.com/BGUCompSci/WaveletCompressedConvolution.",https://github.com/BGUCompSci/WaveletCompressedConvolution,-1
a2d90ec4-dae0-4690-980c-80c2d597b454,Multi-modal Multi-label Facial Action Unit Detection with Transformer,0.904693,"Facial Action Coding System is an important approach of facial expression
analysis.This paper describes our submission to the third Affective Behavior
Analysis (ABAW) 2022 competition. We proposed a transfomer based model to
detect facial action unit (FAU) in video. To be specific, we firstly trained a
multi-modal model to extract both audio and visual feature. After that, we
proposed a action units correlation module to learn relationships between each
action unit labels and refine action unit detection result. Experimental
results on validation dataset shows that our method achieves better performance
than baseline model, which verifies that the effectiveness of proposed network.",None,-1
b30a9518-4aa8-49fd-86c2-e73e921ef016,SPot-the-Difference Self-Supervised Pre-training for Anomaly Detection and Segmentation,0.995159,"Visual anomaly detection is commonly used in industrial quality inspection.
In this paper, we present a new dataset as well as a new self-supervised
learning method for ImageNet pre-training to improve anomaly detection and
segmentation in 1-class and 2-class 5/10/high-shot training setups. We release
the Visual Anomaly (VisA) Dataset consisting of 10,821 high-resolution color
images (9,621 normal and 1,200 anomalous samples) covering 12 objects in 3
domains, making it the largest industrial anomaly detection dataset to date.
Both image and pixel-level labels are provided. We also propose a new
self-supervised framework - SPot-the-difference (SPD) - which can regularize
contrastive self-supervised pre-training, such as SimSiam, MoCo and SimCLR, to
be more suitable for anomaly detection tasks. Our experiments on VisA and
MVTec-AD dataset show that SPD consistently improves these contrastive
pre-training baselines and even the supervised pre-training. For example, SPD
improves Area Under the Precision-Recall curve (AU-PR) for anomaly segmentation
by 5.9% and 6.8% over SimSiam and supervised pre-training respectively in the
2-class high-shot regime. We open-source the project at
http://github.com/amazon-research/spot-diff .",http://github.com/amazon-research/spot-diff,-1
874e6997-09b7-495a-b813-17db1344cca6,Occlusion-Aware Cost Constructor for Light Field Depth Estimation,0.991032,"Matching cost construction is a key step in light field (LF) depth
estimation, but was rarely studied in the deep learning era. Recent deep
learning-based LF depth estimation methods construct matching cost by
sequentially shifting each sub-aperture image (SAI) with a series of predefined
offsets, which is complex and time-consuming. In this paper, we propose a
simple and fast cost constructor to construct matching cost for LF depth
estimation. Our cost constructor is composed by a series of convolutions with
specifically designed dilation rates. By applying our cost constructor to SAI
arrays, pixels under predefined disparities can be integrated and matching cost
can be constructed without using any shifting operation. More importantly, the
proposed cost constructor is occlusion-aware and can handle occlusions by
dynamically modulating pixels from different views. Based on the proposed cost
constructor, we develop a deep network for LF depth estimation. Our network
ranks first on the commonly used 4D LF benchmark in terms of the mean square
error (MSE), and achieves a faster running time than other state-of-the-art
methods.",https://github.com/YingqianWang/OACC-Net,-1
73bbc3fb-e156-46df-a126-9eda8a16e195,A Sneak Attack on Segmentation of Medical Images Using Deep Neural Network Classifiers,0.0274553,"Instead of using current deep-learning segmentation models (like the UNet and
variants), we approach the segmentation problem using trained Convolutional
Neural Network (CNN) classifiers, which automatically extract important
features from images for classification. Those extracted features can be
visualized and formed into heatmaps using Gradient-weighted Class Activation
Mapping (Grad-CAM). This study tested whether the heatmaps could be used to
segment the classified targets. We also proposed an evaluation method for the
heatmaps; that is, to re-train the CNN classifier using images filtered by
heatmaps and examine its performance. We used the mean-Dice coefficient to
evaluate segmentation results. Results from our experiments show that heatmaps
can locate and segment partial tumor areas. But use of only the heatmaps from
CNN classifiers may not be an optimal approach for segmentation. We have
verified that the predictions of CNN classifiers mainly depend on tumor areas,
and dark regions in Grad-CAM's heatmaps also contribute to classification.",None,-1
8bebd1b4-aa9d-485e-9958-1a62e6d4acbd,Physics-Constrained Backdoor Attacks on Power System Fault Localization,0.270787,"The advances in deep learning (DL) techniques have the potential to deliver
transformative technological breakthroughs to numerous complex tasks in modern
power systems that suffer from increasing uncertainty and nonlinearity.
However, the vulnerability of DL has yet to be thoroughly explored in power
system tasks under various physical constraints. This work, for the first time,
proposes a novel physics-constrained backdoor poisoning attack, which embeds
the undetectable attack signal into the learned model and only performs the
attack when it encounters the corresponding signal. The paper illustrates the
proposed attack on the real-time fault line localization application.
Furthermore, the simulation results on the 68-bus power system demonstrate that
DL-based fault line localization methods are not robust to our proposed attack,
indicating that backdoor poisoning attacks pose real threats to DL
implementations in power systems. The proposed attack pipeline can be easily
generalized to other power system tasks.",None,-1
1bbbb5f8-cb15-4c6b-bf81-295ab213b6fc,Utilizing unsupervised learning to improve sward content prediction and herbage mass estimation,0.0551094,"Sward species composition estimation is a tedious one. Herbage must be
collected in the field, manually separated into components, dried and weighed
to estimate species composition. Deep learning approaches using neural networks
have been used in previous work to propose faster and more cost efficient
alternatives to this process by estimating the biomass information from a
picture of an area of pasture alone. Deep learning approaches have, however,
struggled to generalize to distant geographical locations and necessitated
further data collection to retrain and perform optimally in different climates.
In this work, we enhance the deep learning solution by reducing the need for
ground-truthed (GT) images when training the neural network. We demonstrate how
unsupervised contrastive learning can be used in the sward composition
prediction problem and compare with the state-of-the-art on the publicly
available GrassClover dataset collected in Denmark as well as a more recent
dataset from Ireland where we tackle herbage mass and height estimation.",https://git.io/JMrY1,4356
f821bf1e-4b5a-490d-af8f-d6747770c708,Deep Sequence Models for Text Classification Tasks,0.00937728,"The exponential growth of data generated on the Internet in the current
information age is a driving force for the digital economy. Extraction of
information is the major value in an accumulated big data. Big data dependency
on statistical analysis and hand-engineered rules machine learning algorithms
are overwhelmed with vast complexities inherent in human languages. Natural
Language Processing (NLP) is equipping machines to understand these human
diverse and complicated languages. Text Classification is an NLP task which
automatically identifies patterns based on predefined or undefined labeled
sets. Common text classification application includes information retrieval,
modeling news topic, theme extraction, sentiment analysis, and spam detection.
In texts, some sequences of words depend on the previous or next word sequences
to make full meaning; this is a challenging dependency task that requires the
machine to be able to store some previous important information to impact
future meaning. Sequence models such as RNN, GRU, and LSTM is a breakthrough
for tasks with long-range dependencies. As such, we applied these models to
Binary and Multi-class classification. Results generated were excellent with
most of the models performing within the range of 80% and 94%. However, this
result is not exhaustive as we believe there is room for improvement if
machines are to compete with humans.",None,-1
fb4f304e-50af-45bd-9422-d1471543510d,TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models,0.964854,"Language Models (LMs) become outdated as the world changes; they often fail
to perform tasks requiring recent factual information which was absent or
different during training, a phenomenon called temporal misalignment. This is
especially a challenging problem because the research community still lacks a
coherent dataset for assessing the adaptability of LMs to frequently-updated
knowledge corpus such as Wikipedia. To this end, we introduce TemporalWiki, a
lifelong benchmark for ever-evolving LMs that utilizes the difference between
consecutive snapshots of English Wikipedia and English Wikidata for training
and evaluation, respectively. The benchmark hence allows researchers to
periodically track an LM's ability to retain previous knowledge and acquire
updated/new knowledge at each point in time. We also find that training an LM
on the diff data through continual learning methods achieves similar or better
perplexity than on the entire snapshot in our benchmark with 12 times less
computational cost, which verifies that factual knowledge in LMs can be safely
updated with minimal training data via continual learning. The dataset and the
code are available at https://github.com/joeljang/temporalwiki.",None,-1
8de18786-4648-4b44-baee-cb32adc06e90,Abstraction for Deep Reinforcement Learning,0.524873,"We characterise the problem of abstraction in the context of deep
reinforcement learning. Various well established approaches to analogical
reasoning and associative memory might be brought to bear on this issue, but
they present difficulties because of the need for end-to-end differentiability.
We review developments in AI and machine learning that could facilitate their
adoption.",None,-1
8b71fae1-9e96-49be-9a1b-575a24d12c6f,Improving Variational Autoencoders with Density Gap-based Regularization,0.164092,"Variational autoencoders (VAEs) are one of the powerful unsupervised learning
frameworks in NLP for latent representation learning and latent-directed
generation. The classic optimization goal of VAEs is to maximize the Evidence
Lower Bound (ELBo), which consists of a conditional likelihood for generation
and a negative Kullback-Leibler (KL) divergence for regularization. In
practice, optimizing ELBo often leads the posterior distribution of all samples
converge to the same degenerated local optimum, namely posterior collapse or KL
vanishing. There are effective ways proposed to prevent posterior collapse in
VAEs, but we observe that they in essence make trade-offs between posterior
collapse and hole problem, i.e., mismatch between the aggregated posterior
distribution and the prior distribution. To this end, we introduce new training
objectives to tackle both two problems through a novel regularization based on
the probabilistic density gap between the aggregated posterior distribution and
the prior distribution. Through experiments on language modeling, latent space
visualization and interpolation, we show that our proposed method can solve
both problems effectively and thus outperforms the existing methods in
latent-directed generation. To the best of our knowledge, we are the first to
jointly solve the hole problem and the posterior collapse.",https://github.com/zhangjf-nlp/DG-VAEs,-1
327692b9-5329-4563-b907-23d78ad80151,Learning Reduced Nonlinear State-Space Models: an Output-Error Based Canonical Approach,0.0524384,"The identification of a nonlinear dynamic model is an open topic in control
theory, especially from sparse input-output measurements. A fundamental
challenge of this problem is that very few to zero prior knowledge is available
on both the state and the nonlinear system model. To cope with this challenge,
we investigate the effectiveness of deep learning in the modeling of dynamic
systems with nonlinear behavior by advocating an approach which relies on three
main ingredients: (i) we show that under some structural conditions on the
to-be-identified model, the state can be expressed in function of a sequence of
the past inputs and outputs; (ii) this relation which we call the state map can
be modelled by resorting to the well-documented approximation power of deep
neural networks; (iii) taking then advantage of existing learning schemes, a
state-space model can be finally identified. After the formulation and analysis
of the approach, we show its ability to identify three different nonlinear
systems. The performances are evaluated in terms of open-loop prediction on
test data generated in simulation as well as a real world data-set of unmanned
aerial vehicle flight measurements.",None,8251
30270393-a615-4489-89eb-6e9fa2b89478,CarFi: Rider Localization Using Wi-Fi CSI,0.629042,"With the rise of hailing services, people are increasingly relying on shared
mobility (e.g., Uber, Lyft) drivers to pick up for transportation. However,
such drivers and riders have difficulties finding each other in urban areas as
GPS signals get blocked by skyscrapers, in crowded environments (e.g., in
stadiums, airports, and bars), at night, and in bad weather. It wastes their
time, creates a bad user experience, and causes more CO2 emissions due to idle
driving. In this work, we explore the potential of Wi-Fi to help drivers to
determine the street side of the riders. Our proposed system is called CarFi
that uses Wi-Fi CSI from two antennas placed inside a moving vehicle and a
data-driven technique to determine the street side of the rider. By collecting
real-world data in realistic and challenging settings by blocking the signal
with other people and other parked cars, we see that CarFi is 95.44% accurate
in rider-side determination in both line of sight (LoS) and non-line of sight
(nLoS) conditions, and can be run on an embedded GPU in real-time.",None,2064
05684b17-af4c-47a4-a41a-9e9da2e36bcc,AdaTranS: Adapting with Boundary-based Shrinking for End-to-End Speech Translation,0.470986,"To alleviate the data scarcity problem in End-to-end speech translation (ST),
pre-training on data for speech recognition and machine translation is
considered as an important technique. However, the modality gap between speech
and text prevents the ST model from efficiently inheriting knowledge from the
pre-trained models. In this work, we propose AdaTranS for end-to-end ST. It
adapts the speech features with a new shrinking mechanism to mitigate the
length mismatch between speech and text features by predicting word boundaries.
Experiments on the MUST-C dataset demonstrate that AdaTranS achieves better
performance than the other shrinking-based methods, with higher inference speed
and lower memory usage. Further experiments also show that AdaTranS can be
equipped with additional alignment losses to further improve performance.",https://github.com/google/sentencepiece,-1
c9c7e888-cb49-431c-9f19-7434e14802fa,Boundary Smoothing for Named Entity Recognition,0.903493,"Neural named entity recognition (NER) models may easily encounter the
over-confidence issue, which degrades the performance and calibration. Inspired
by label smoothing and driven by the ambiguity of boundary annotation in NER
engineering, we propose boundary smoothing as a regularization technique for
span-based neural NER models. It re-assigns entity probabilities from annotated
spans to the surrounding ones. Built on a simple but strong baseline, our model
achieves results better than or competitive with previous state-of-the-art
systems on eight well-known NER benchmarks. Further empirical analysis suggests
that boundary smoothing effectively mitigates over-confidence, improves model
calibration, and brings flatter neural minima and more smoothed loss
landscapes.",https://github.com/syuoni/eznlp,-1
933bb0c2-0b57-4e80-9133-e05d0392635d,Why Deep Surgical Models Fail?: Revisiting Surgical Action Triplet Recognition through the Lens of Robustness,0.418379,"Surgical action triplet recognition provides a better understanding of the
surgical scene. This task is of high relevance as it provides the surgeon with
context-aware support and safety. The current go-to strategy for improving
performance is the development of new network mechanisms. However, the
performance of current state-of-the-art techniques is substantially lower than
other surgical tasks. Why is this happening? This is the question that we
address in this work. We present the first study to understand the failure of
existing deep learning models through the lens of robustness and
explainability. Firstly, we study current existing models under weak and strong
$\delta-$perturbations via an adversarial optimisation scheme. We then analyse
the failure modes via feature based explanations. Our study reveals that the
key to improving performance and increasing reliability is in the core and
spurious attributes. Our work opens the door to more trustworthy and reliable
deep learning models in surgical data science.",None,-1
f8829d4c-3cdd-430d-b92c-9bcb8e2bfdd7,Ultrahyperbolic Knowledge Graph Embeddings,0.727421,"Recent knowledge graph (KG) embeddings have been advanced by hyperbolic
geometry due to its superior capability for representing hierarchies. The
topological structures of real-world KGs, however, are rather heterogeneous,
i.e., a KG is composed of multiple distinct hierarchies and non-hierarchical
graph structures. Therefore, a homogeneous (either Euclidean or hyperbolic)
geometry is not sufficient for fairly representing such heterogeneous
structures. To capture the topological heterogeneity of KGs, we present an
ultrahyperbolic KG embedding (UltraE) in an ultrahyperbolic (or
pseudo-Riemannian) manifold that seamlessly interleaves hyperbolic and
spherical manifolds. In particular, we model each relation as a
pseudo-orthogonal transformation that preserves the pseudo-Riemannian bilinear
form. The pseudo-orthogonal transformation is decomposed into various operators
(i.e., circular rotations, reflections and hyperbolic rotations), allowing for
simultaneously modeling heterogeneous structures as well as complex relational
patterns. Experimental results on three standard KGs show that UltraE
outperforms previous Euclidean- and hyperbolic-based approaches.",None,-1
3812a753-694e-43b5-b999-577d8d9f231c,Hierarchical Attention Network for Few-Shot Object Detection via Meta-Contrastive Learning,0.27857,"Few-shot object detection (FSOD) aims to classify and detect few images of
novel categories. Existing meta-learning methods insufficiently exploit
features between support and query images owing to structural limitations. We
propose a hierarchical attention network with sequentially large receptive
fields to fully exploit the query and support images. In addition,
meta-learning does not distinguish the categories well because it determines
whether the support and query images match. In other words, metric-based
learning for classification is ineffective because it does not work directly.
Thus, we propose a contrastive learning method called meta-contrastive
learning, which directly helps achieve the purpose of the meta-learning
strategy. Finally, we establish a new state-of-the-art network, by realizing
significant margins. Our method brings 2.3, 1.0, 1.3, 3.4 and 2.4% AP
improvements for 1-30 shots object detection on COCO dataset. Our code is
available at: https://github.com/infinity7428/hANMCL",https://github.com/infinity7428/hANMCL,12071
862b9d41-4b8c-4dbc-bb74-3eecbe864fab,CITRIS: Causal Identifiability from Temporal Intervened Sequences,0.804722,"Understanding the latent causal factors of a dynamical system from visual
observations is considered a crucial step towards agents reasoning in complex
environments. In this paper, we propose CITRIS, a variational autoencoder
framework that learns causal representations from temporal sequences of images
in which underlying causal factors have possibly been intervened upon. In
contrast to the recent literature, CITRIS exploits temporality and observing
intervention targets to identify scalar and multidimensional causal factors,
such as 3D rotation angles. Furthermore, by introducing a normalizing flow,
CITRIS can be easily extended to leverage and disentangle representations
obtained by already pretrained autoencoders. Extending previous results on
scalar causal factors, we prove identifiability in a more general setting, in
which only some components of a causal factor are affected by interventions. In
experiments on 3D rendered image sequences, CITRIS outperforms previous methods
on recovering the underlying causal variables. Moreover, using pretrained
autoencoders, CITRIS can even generalize to unseen instantiations of causal
factors, opening future research areas in sim-to-real generalization for causal
representation learning.",https://github.com/phlippe/CITRIS,-1
83265bf0-692b-4a09-b2fa-0355d1bd9fd5,Whose Language Counts as High Quality? Measuring Language Ideologies in Text Data Selection,0.820799,"Language models increasingly rely on massive web dumps for diverse text data.
However, these sources are rife with undesirable content. As such, resources
like Wikipedia, books, and newswire often serve as anchors for automatically
selecting web text most suitable for language modeling, a process typically
referred to as quality filtering. Using a new dataset of U.S. high school
newspaper articles -- written by students from across the country -- we
investigate whose language is preferred by the quality filter used for GPT-3.
We find that newspapers from larger schools, located in wealthier, educated,
and urban ZIP codes are more likely to be classified as high quality. We then
demonstrate that the filter's measurement of quality is unaligned with other
sensible metrics, such as factuality or literary acclaim. We argue that
privileging any corpus as high quality entails a language ideology, and more
care is needed to construct training corpora for language models, with better
transparency and justification for the inclusion or exclusion of various texts.",https://github.com/kernelmachine/quality-filter,-1
dbb7870c-f1f2-453a-91e2-32332b6196fc,Why Should Adversarial Perturbations be Imperceptible? Rethink the Research Paradigm in Adversarial NLP,0.576935,"Textual adversarial samples play important roles in multiple subfields of NLP
research, including security, evaluation, explainability, and data
augmentation. However, most work mixes all these roles, obscuring the problem
definitions and research goals of the security role that aims to reveal the
practical concerns of NLP models. In this paper, we rethink the research
paradigm of textual adversarial samples in security scenarios. We discuss the
deficiencies in previous work and propose our suggestions that the research on
the Security-oriented adversarial NLP (SoadNLP) should: (1) evaluate their
methods on security tasks to demonstrate the real-world concerns; (2) consider
real-world attackers' goals, instead of developing impractical methods. To this
end, we first collect, process, and release a security datasets collection
Advbench. Then, we reformalize the task and adjust the emphasis on different
goals in SoadNLP. Next, we propose a simple method based on heuristic rules
that can easily fulfill the actual adversarial goals to simulate real-world
attack methods. We conduct experiments on both the attack and the defense sides
on Advbench. Experimental results show that our method has higher practical
value, indicating that the research paradigm in SoadNLP may start from our new
benchmark. All the code and data of Advbench can be obtained at
\url{https://github.com/thunlp/Advbench}.",https://github.com/thunlp/Advbench,-1
215c845d-c872-4ac9-8e84-6602b6038ff0,Advancing Semi-Supervised Task Oriented Dialog Systems by JSA Learning of Discrete Latent Variable Models,0.168704,"Developing semi-supervised task-oriented dialog (TOD) systems by leveraging
unlabeled dialog data has attracted increasing interests. For semi-supervised
learning of latent state TOD models, variational learning is often used, but
suffers from the annoying high-variance of the gradients propagated through
discrete latent variables and the drawback of indirectly optimizing the target
log-likelihood. Recently, an alternative algorithm, called joint stochastic
approximation (JSA), has emerged for learning discrete latent variable models
with impressive performances. In this paper, we propose to apply JSA to
semi-supervised learning of the latent state TOD models, which is referred to
as JSA-TOD. To our knowledge, JSA-TOD represents the first work in developing
JSA based semi-supervised learning of discrete latent variable conditional
models for such long sequential generation problems like in TOD systems.
Extensive experiments show that JSA-TOD significantly outperforms its
variational learning counterpart. Remarkably, semi-supervised JSA-TOD using 20%
labels performs close to the full-supervised baseline on MultiWOZ2.1.",https://github.com/cycrab/JSA-TOD,-1
4e49f842-9a68-4077-8358-aa4fe4f230e5,MGTR: End-to-End Mutual Gaze Detection with Transformer,0.603583,"People's looking at each other or mutual gaze is ubiquitous in our daily
interactions, and detecting mutual gaze is of great significance for
understanding human social scenes. Current mutual gaze detection methods focus
on two-stage methods, whose inference speed is limited by the two-stage
pipeline and the performance in the second stage is affected by the first one.
In this paper, we propose a novel one-stage mutual gaze detection framework
called Mutual Gaze TRansformer or MGTR to perform mutual gaze detection in an
end-to-end manner. By designing mutual gaze instance triples, MGTR can detect
each human head bounding box and simultaneously infer mutual gaze relationship
based on global image information, which streamlines the whole process with
simplicity. Experimental results on two mutual gaze datasets show that our
method is able to accelerate mutual gaze detection process without losing
performance. Ablation study shows that different components of MGTR can capture
different levels of semantic information in images. Code is available at
https://github.com/Gmbition/MGTR",https://github.com/Gmbition/MGTR,-1
043a6fc9-02eb-4611-8519-afc9e92599a9,Phantom Sponges: Exploiting Non-Maximum Suppression to Attack Deep Object Detectors,0.594228,"Adversarial attacks against deep learning-based object detectors have been
studied extensively in the past few years. Most of the attacks proposed have
targeted the model's integrity (i.e., caused the model to make incorrect
predictions), while adversarial attacks targeting the model's availability, a
critical aspect in safety-critical domains such as autonomous driving, have not
yet been explored by the machine learning research community. In this paper, we
propose a novel attack that negatively affects the decision latency of an
end-to-end object detection pipeline. We craft a universal adversarial
perturbation (UAP) that targets a widely used technique integrated in many
object detector pipelines -- non-maximum suppression (NMS). Our experiments
demonstrate the proposed UAP's ability to increase the processing time of
individual frames by adding ""phantom"" objects that overload the NMS algorithm
while preserving the detection of the original objects which allows the attack
to go undetected for a longer period of time.",https://github.com/AvishagS422/PhantomSponges,-1
6e64a6bd-069a-43a7-97f1-77199b4060bd,Test-Time Adaptation for Visual Document Understanding,0.273317,"For visual document understanding (VDU), self-supervised pretraining has been
shown to successfully generate transferable representations, yet, effective
adaptation of such representations to distribution shifts at test-time remains
to be an unexplored area. We propose DocTTA, a novel test-time adaptation
method for documents, that does source-free domain adaptation using unlabeled
target document data. DocTTA leverages cross-modality self-supervised learning
via masked visual language modeling, as well as pseudo labeling to adapt models
learned on a \textit{source} domain to an unlabeled \textit{target} domain at
test time. We introduce new benchmarks using existing public datasets for
various VDU tasks, including entity recognition, key-value extraction, and
document visual question answering. DocTTA shows significant improvements on
these compared to the source model performance, up to 1.89\% in (F1 score),
3.43\% (F1 score), and 17.68\% (ANLS score), respectively. Our benchmark
datasets are available at \url{https://saynaebrahimi.github.io/DocTTA.html}.",None,-1
9dab8cea-c0e7-47df-aef9-c8304bc40c2e,MASNet:Improve Performance of Siamese Networks with Mutual-attention for Remote Sensing Change Detection Tasks,0.0306846,"Siamese networks are widely used for remote sensing change detection tasks. A
vanilla siamese network has two identical feature extraction branches which
share weights, these two branches work independently and the feature maps are
not fused until about to be sent to a decoder head. However we find that it is
critical to exchange information between two feature extraction branches at
early stage for change detection task. In this work we present Mutual-Attention
Siamese Network (MASNet), a general siamese network with mutual-attention
plug-in, so to exchange information between the two feature extraction
branches. We show that our modification improve the performance of siamese
networks on multi change detection datasets, and it works for both
convolutional neural network and visual transformer.",None,-1
3c3dbc64-abf5-487d-8e7a-815e18e0df40,Policy Regularization for Legible Behavior,0.056174,"In Reinforcement Learning interpretability generally means to provide insight
into the agent's mechanisms such that its decisions are understandable by an
expert upon inspection. This definition, with the resulting methods from the
literature, may however fall short for online settings where the fluency of
interactions prohibits deep inspections of the decision-making algorithm. To
support interpretability in online settings it is useful to borrow from the
Explainable Planning literature methods that focus on the legibility of the
agent, by making its intention easily discernable in an observer model. As we
propose in this paper, injecting legible behavior inside an agent's policy
doesn't require modify components of its learning algorithm. Rather, the
agent's optimal policy can be regularized for legibility by evaluating how the
policy may produce observations that would make an observer infer an incorrect
policy. In our formulation, the decision boundary introduced by legibility
impacts the states in which the agent's policy returns an action that has high
likelihood also in other policies. In these cases, a trade-off between such
action, and legible/sub-optimal action is made.",None,2588
8fc20250-9d58-4224-b273-e3caa0d7e528,MIDMs: Matching Interleaved Diffusion Models for Exemplar-based Image Translation,0.933722,"We present a novel method for exemplar-based image translation, called
matching interleaved diffusion models (MIDMs). Most existing methods for this
task were formulated as GAN-based matching-then-generation framework. However,
in this framework, matching errors induced by the difficulty of semantic
matching across cross-domain, e.g., sketch and photo, can be easily propagated
to the generation step, which in turn leads to degenerated results. Motivated
by the recent success of diffusion models overcoming the shortcomings of GANs,
we incorporate the diffusion models to overcome these limitations.
Specifically, we formulate a diffusion-based matching-and-generation framework
that interleaves cross-domain matching and diffusion steps in the latent space
by iteratively feeding the intermediate warp into the noising process and
denoising it to generate a translated image. In addition, to improve the
reliability of the diffusion process, we design a confidence-aware process
using cycle-consistency to consider only confident regions during translation.
Experimental results show that our MIDMs generate more plausible images than
state-of-the-art methods.",https://ku-cvlab.github.io/MIDMs/,-1
76d1c66f-da76-42a0-8417-9d6df4daa5ba,Batch-Ensemble Stochastic Neural Networks for Out-of-Distribution Detection,0.16562,"Out-of-distribution (OOD) detection has recently received much attention from
the machine learning community due to its importance in deploying machine
learning models in real-world applications. In this paper we propose an
uncertainty quantification approach by modelling the distribution of features.
We further incorporate an efficient ensemble mechanism, namely batch-ensemble,
to construct the batch-ensemble stochastic neural networks (BE-SNNs) and
overcome the feature collapse problem. We compare the performance of the
proposed BE-SNNs with the other state-of-the-art approaches and show that
BE-SNNs yield superior performance on several OOD benchmarks, such as the
Two-Moons dataset, the FashionMNIST vs MNIST dataset, FashionMNIST vs NotMNIST
dataset, and the CIFAR10 vs SVHN dataset.",None,-1
9d1f9d7a-715f-40eb-b86d-31600375f6b0,Team ÚFAL at CMCL 2022 Shared Task: Figuring out the correct recipe for predicting Eye-Tracking features using Pretrained Language Models,0.240295,"Eye-Tracking data is a very useful source of information to study cognition
and especially language comprehension in humans. In this paper, we describe our
systems for the CMCL 2022 shared task on predicting eye-tracking information.
We describe our experiments with pretrained models like BERT and XLM and the
different ways in which we used those representations to predict four
eye-tracking features. Along with analysing the effect of using two different
kinds of pretrained multilingual language models and different ways of pooling
the tokenlevel representations, we also explore how contextual information
affects the performance of the systems. Finally, we also explore if factors
like augmenting linguistic information affect the predictions. Our submissions
achieved an average MAE of 5.72 and ranked 5th in the shared task. The average
MAE showed further reduction to 5.25 in post task evaluation.",None,-1
34ecd008-ade9-45c4-801a-c0138543ebe8,Ham2Pose: Animating Sign Language Notation into Pose Sequences,0.89581,"Translating spoken languages into Sign languages is necessary for open
communication between the hearing and hearing-impaired communities. To achieve
this goal, we propose the first method for animating a text written in
HamNoSys, a lexical Sign language notation, into signed pose sequences. As
HamNoSys is universal by design, our proposed method offers a generic solution
invariant to the target Sign language. Our method gradually generates pose
predictions using transformer encoders that create meaningful representations
of the text and poses while considering their spatial and temporal information.
We use weak supervision for the training process and show that our method
succeeds in learning from partial and inaccurate data. Additionally, we offer a
new distance measurement that considers missing keypoints, to measure the
distance between pose sequences using DTW-MJE. We validate its correctness
using AUTSL, a large-scale Sign language dataset, show that it measures the
distance between pose sequences more accurately than existing measurements, and
use it to assess the quality of our generated pose sequences. Code for the data
pre-processing, the model, and the distance measurement is publicly released
for future research.",https://github.com/AmitMY/pose-format,3241
9b0c68e7-6a03-44ee-acd6-b86d4a0000f6,Unsupervised Neural Stylistic Text Generation using Transfer learning and Adapters,0.0715592,"Research has shown that personality is a key driver to improve engagement and
user experience in conversational systems. Conversational agents should also
maintain a consistent persona to have an engaging conversation with a user.
However, text generation datasets are often crowd sourced and thereby have an
averaging effect where the style of the generation model is an average style of
all the crowd workers that have contributed to the dataset. While one can
collect persona-specific datasets for each task, it would be an expensive and
time consuming annotation effort. In this work, we propose a novel transfer
learning framework which updates only $0.3\%$ of model parameters to learn
style specific attributes for response generation. For the purpose of this
study, we tackle the problem of stylistic story ending generation using the ROC
stories Corpus. We learn style specific attributes from the
PERSONALITY-CAPTIONS dataset. Through extensive experiments and evaluation
metrics we show that our novel training procedure can improve the style
generation by 200 over Encoder-Decoder baselines while maintaining on-par
content relevance metrics with",None,-1
a15aea73-7736-4f97-8908-1f3be6f3ff35,The GatedTabTransformer. An enhanced deep learning architecture for tabular modeling,0.421026,"There is an increasing interest in the application of deep learning
architectures to tabular data. One of the state-of-the-art solutions is
TabTransformer which incorporates an attention mechanism to better track
relationships between categorical features and then makes use of a standard MLP
to output its final logits. In this paper we propose multiple modifications to
the original TabTransformer performing better on binary classification tasks
for three separate datasets with more than 1% AUROC gains. Inspired by gated
MLP, linear projections are implemented in the MLP block and multiple
activation functions are tested. We also evaluate the importance of specific
hyper parameters during training.",https://github.com/radi-cho/GatedTabTransformer,-1
e99a281f-a762-4ec2-a3d5-b3c13d810ac6,Towards Automated Polyp Segmentation Using Weakly- and Semi-Supervised Learning and Deformable Transformers,0.091589,"Polyp segmentation is a crucial step towards computer-aided diagnosis of
colorectal cancer. However, most of the polyp segmentation methods require
pixel-wise annotated datasets. Annotated datasets are tedious and
time-consuming to produce, especially for physicians who must dedicate their
time to their patients. We tackle this issue by proposing a novel framework
that can be trained using only weakly annotated images along with exploiting
unlabeled images. To this end, we propose three ideas to address this problem,
more specifically our contributions are: 1) a novel sparse foreground loss that
suppresses false positives and improves weakly-supervised training, 2) a
batch-wise weighted consistency loss utilizing predicted segmentation maps from
identical networks trained using different initialization during
semi-supervised training, 3) a deformable transformer encoder neck for feature
enhancement by fusing information across levels and flexible spatial locations.
  Extensive experimental results demonstrate the merits of our ideas on five
challenging datasets outperforming some state-of-the-art fully supervised
models. Also, our framework can be utilized to fine-tune models trained on
natural image segmentation datasets drastically improving their performance for
polyp segmentation and impressively demonstrating superior performance to fully
supervised fine-tuning.",None,-1
4190866c-fb45-4978-9f32-65382c2d5527,AdaPrompt: Adaptive Model Training for Prompt-based NLP,0.598129,"Prompt-based learning, with its capability to tackle zero-shot and few-shot
NLP tasks, has gained much attention in community. The main idea is to bridge
the gap between NLP downstream tasks and language modeling (LM), by mapping
these tasks into natural language prompts, which are then filled by pre-trained
language models (PLMs). However, for prompt learning, there are still two
salient gaps between NLP tasks and pretraining. First, prompt information is
not necessarily sufficiently present during LM pretraining. Second,
task-specific data are not necessarily well represented during pretraining. We
address these two issues by proposing AdaPrompt, adaptively retrieving external
data for continual pretraining of PLMs by making use of both task and prompt
characteristics. In addition, we make use of knowledge in Natural Language
Inference models for deriving adaptive verbalizers. Experimental results on
five NLP benchmarks show that AdaPrompt can improve over standard PLMs in
few-shot settings. In addition, in zero-shot settings, our method outperforms
standard prompt-based methods by up to 26.35\% relative error reduction.",https://github.com/cylnlp/AdaPrompt,-1
2607cd80-2cb9-48d6-bb7e-ad62c952a297,Block-coordinate Frank-Wolfe algorithm and convergence analysis for semi-relaxed optimal transport problem,0.329122,"The optimal transport (OT) problem has been used widely for machine learning.
It is necessary for computation of an OT problem to solve linear programming
with tight mass-conservation constraints. These constraints prevent its
application to large-scale problems. To address this issue, loosening such
constraints enables us to propose the relaxed-OT method using a faster
algorithm. This approach has demonstrated its effectiveness for applications.
However, it remains slow. As a superior alternative, we propose a fast
block-coordinate Frank-Wolfe (BCFW) algorithm for a convex semi-relaxed OT.
Specifically, we prove their upper bounds of the worst convergence iterations,
and equivalence between the linearization duality gap and the Lagrangian
duality gap. Additionally, we develop two fast variants of the proposed BCFW.
Numerical experiments have demonstrated that our proposed algorithms are
effective for color transfer and surpass state-of-the-art algorithms. This
report presents a short version of arXiv:2103.05857.",https://github.com/hiroyuki-kasai/srot,-1
00060343-e78e-4a36-b288-ee739b50c9ce,Normalization Perturbation: A Simple Domain Generalization Method for Real-World Domain Shifts,0.432195,"Improving model's generalizability against domain shifts is crucial,
especially for safety-critical applications such as autonomous driving.
Real-world domain styles can vary substantially due to environment changes and
sensor noises, but deep models only know the training domain style. Such domain
style gap impedes model generalization on diverse real-world domains. Our
proposed Normalization Perturbation (NP) can effectively overcome this domain
style overfitting problem. We observe that this problem is mainly caused by the
biased distribution of low-level features learned in shallow CNN layers. Thus,
we propose to perturb the channel statistics of source domain features to
synthesize various latent styles, so that the trained deep model can perceive
diverse potential domains and generalizes well even without observations of
target domain data in training. We further explore the style-sensitive channels
for effective style synthesis. Normalization Perturbation only relies on a
single source domain and is surprisingly effective and extremely easy to
implement. Extensive experiments verify the effectiveness of our method for
generalizing models under real-world domain shifts.",None,-1
7ea20d2e-f92b-4728-9ba7-f7f5dec9d94a,Problems with Cosine as a Measure of Embedding Similarity for High Frequency Words,0.902884,"Cosine similarity of contextual embeddings is used in many NLP tasks (e.g.,
QA, IR, MT) and metrics (e.g., BERTScore). Here, we uncover systematic ways in
which word similarities estimated by cosine over BERT embeddings are
understated and trace this effect to training data frequency. We find that
relative to human judgements, cosine similarity underestimates the similarity
of frequent words with other instances of the same word or other words across
contexts, even after controlling for polysemy and other factors. We conjecture
that this underestimation of similarity for high frequency words is due to
differences in the representational geometry of high and low frequency words
and provide a formal argument for the two-dimensional case.",https://github.com/katezhou/cosine_and_frequency,-1
5626ad9f-7098-4a63-b094-9636c71388c1,Distilling Inter-Class Distance for Semantic Segmentation,0.671495,"Knowledge distillation is widely adopted in semantic segmentation to reduce
the computation cost.The previous knowledge distillation methods for semantic
segmentation focus on pixel-wise feature alignment and intra-class feature
variation distillation, neglecting to transfer the knowledge of the inter-class
distance in the feature space, which is important for semantic segmentation. To
address this issue, we propose an Inter-class Distance Distillation (IDD)
method to transfer the inter-class distance in the feature space from the
teacher network to the student network. Furthermore, semantic segmentation is a
position-dependent task,thus we exploit a position information distillation
module to help the student network encode more position information. Extensive
experiments on three popular datasets: Cityscapes, Pascal VOC and ADE20K show
that our method is helpful to improve the accuracy of semantic segmentation
models and achieves the state-of-the-art performance. E.g. it boosts the
benchmark model(""PSPNet+ResNet18"") by 7.50% in accuracy on the Cityscapes
dataset.",None,-1
4d441496-bd1b-4f50-a666-217c90ae5a36,Multi-hop Evidence Retrieval for Cross-document Relation Extraction,0.711505,"Relation Extraction (RE) has been extended to cross-document scenarios
because many relations are not simply described in a single document. This
inevitably brings the challenge of efficient open-space evidence retrieval to
support the inference of cross-document relations, along with the challenge of
multi-hop reasoning on top of entities and evidence scattered in an open set of
documents. To combat these challenges, we propose MR.COD (Multi-hop evidence
retrieval for Cross-document relation extraction), which is a multi-hop
evidence retrieval method based on evidence path mining and ranking. We explore
multiple variants of retrievers to show evidence retrieval is essential in
cross-document RE. We also propose a contextual dense retriever for this
setting. Experiments on CodRED show that evidence retrieval with MR.COD
effectively acquires crossdocument evidence and boosts end-to-end RE
performance in both closed and open settings.",https://github.com/luka-group/MrCoD,-1
682ee121-c5be-45fe-8479-803afe80f3ea,Improved Evaluation and Generation of Grid Layouts using Distance Preservation Quality and Linear Assignment Sorting,0.576825,"Images sorted by similarity enables more images to be viewed simultaneously,
and can be very useful for stock photo agencies or e-commerce applications.
Visually sorted grid layouts attempt to arrange images so that their proximity
on the grid corresponds as closely as possible to their similarity. Various
metrics exist for evaluating such arrangements, but there is low experimental
evidence on correlation between human perceived quality and metric value. We
propose Distance Preservation Quality (DPQ) as a new metric to evaluate the
quality of an arrangement. Extensive user testing revealed stronger correlation
of DPQ with user-perceived quality and performance in image retrieval tasks
compared to other metrics. In addition, we introduce Fast Linear Assignment
Sorting (FLAS) as a new algorithm for creating visually sorted grid layouts.
FLAS achieves very good sorting qualities while improving run time and
computational resources.",https://github.com/Visual-Computing/LAS_FLAS,-1
e8c040fa-7afb-41b2-84f3-24e0f4105331,SemFormer: Semantic Guided Activation Transformer for Weakly Supervised Semantic Segmentation,0.0927033,"Recent mainstream weakly supervised semantic segmentation (WSSS) approaches
are mainly based on Class Activation Map (CAM) generated by a CNN
(Convolutional Neural Network) based image classifier. In this paper, we
propose a novel transformer-based framework, named Semantic Guided Activation
Transformer (SemFormer), for WSSS. We design a transformer-based Class-Aware
AutoEncoder (CAAE) to extract the class embeddings for the input image and
learn class semantics for all classes of the dataset. The class embeddings and
learned class semantics are then used to guide the generation of activation
maps with four losses, i.e., class-foreground, class-background, activation
suppression, and activation complementation loss. Experimental results show
that our SemFormer achieves \textbf{74.3}\% mIoU and surpasses many recent
mainstream WSSS approaches by a large margin on PASCAL VOC 2012 dataset. Code
will be available at \url{https://github.com/JLChen-C/SemFormer}.",https://github.com/JLChen-C/SemFormer,-1
a5bdd23a-53d8-44c1-a8f6-3301ef0576e0,4D Unsupervised Object Discovery,0.665042,"Object discovery is a core task in computer vision. While fast progresses
have been made in supervised object detection, its unsupervised counterpart
remains largely unexplored. With the growth of data volume, the expensive cost
of annotations is the major limitation hindering further study. Therefore,
discovering objects without annotations has great significance. However, this
task seems impractical on still-image or point cloud alone due to the lack of
discriminative information. Previous studies underlook the crucial temporal
information and constraints naturally behind multi-modal inputs. In this paper,
we propose 4D unsupervised object discovery, jointly discovering objects from
4D data -- 3D point clouds and 2D RGB images with temporal information. We
present the first practical approach for this task by proposing a ClusterNet on
3D point clouds, which is jointly iteratively optimized with a 2D localization
network. Extensive experiments on the large-scale Waymo Open Dataset suggest
that the localization network and ClusterNet achieve competitive performance on
both class-agnostic 2D object detection and 3D instance segmentation, bridging
the gap between unsupervised methods and full supervised ones. Codes and models
will be made available at https://github.com/Robertwyq/LSMOL.",https://github.com/Robertwyq/LSMOL,-1
34a8aaf0-cc89-4ee2-946f-c13074cb19b3,On Almost-Sure Intention Deception Planning that Exploits Imperfect Observers,0.492248,"Intention deception involves computing a strategy which deceives the opponent
into a wrong belief about the agent's intention or objective. This paper
studies a class of probabilistic planning problems with intention deception and
investigates how a defender's limited sensing modality can be exploited by an
attacker to achieve its attack objective almost surely (with probability one)
while hiding its intention. In particular, we model the attack planning in a
stochastic system modeled as a Markov decision process (MDP). The attacker is
to reach some target states while avoiding unsafe states in the system and
knows that his behavior is monitored by a defender with partial observations.
Given partial state observations for the defender, we develop qualitative
intention deception planning algorithms that construct attack strategies to
play against an action-visible defender and an action-invisible defender,
respectively. The synthesized attack strategy not only ensures the attack
objective is satisfied almost surely but also deceives the defender into
believing that the observed behavior is generated by a normal/legitimate user
and thus failing to detect the presence of an attack. We show the proposed
algorithms are correct and complete and illustrate the deceptive planning
methods with examples.",None,-1
fd398e17-9901-4fce-a7b9-8060a87096ab,TriPINet: Tripartite Progressive Integration Network for Image Manipulation Localization,0.0691325,"Image manipulation localization aims at distinguishing forged regions from
the whole test image. Although many outstanding prior arts have been proposed
for this task, there are still two issues that need to be further studied: 1)
how to fuse diverse types of features with forgery clues; 2) how to
progressively integrate multistage features for better localization
performance. In this paper, we propose a tripartite progressive integration
network (TriPINet) for end-to-end image manipulation localization. First, we
extract both visual perception information, e.g., RGB input images, and visual
imperceptible features, e.g., frequency and noise traces for forensic feature
learning. Second, we develop a guided cross-modality dual-attention (gCMDA)
module to fuse different types of forged clues. Third, we design a set of
progressive integration squeeze-and-excitation (PI-SE) modules to improve
localization performance by appropriately incorporating multiscale features in
the decoder. Extensive experiments are conducted to compare our method with
state-of-the-art image forensics approaches. The proposed TriPINet obtains
competitive results on several benchmark datasets.",https://github.com/ntdat017/BusterNet,-1
5fd8a158-5623-41a1-aaa9-62648b9f5c5d,Missingness Bias in Model Debugging,0.522385,"Missingness, or the absence of features from an input, is a concept
fundamental to many model debugging tools. However, in computer vision, pixels
cannot simply be removed from an image. One thus tends to resort to heuristics
such as blacking out pixels, which may in turn introduce bias into the
debugging process. We study such biases and, in particular, show how
transformer-based architectures can enable a more natural implementation of
missingness, which side-steps these issues and improves the reliability of
model debugging in practice. Our code is available at
https://github.com/madrylab/missingness",https://github.com/madrylab/missingness,-1
4cc5a86b-1d38-4db1-ba2c-266dfdc58e2c,Exploring Continuous Integrate-and-Fire for Adaptive Simultaneous Speech Translation,0.633786,"Simultaneous speech translation (SimulST) is a challenging task aiming to
translate streaming speech before the complete input is observed. A SimulST
system generally includes two components: the pre-decision that aggregates the
speech information and the policy that decides to read or write. While recent
works had proposed various strategies to improve the pre-decision, they mainly
adopt the fixed wait-k policy, leaving the adaptive policies rarely explored.
This paper proposes to model the adaptive policy by adapting the Continuous
Integrate-and-Fire (CIF). Compared with monotonic multihead attention (MMA),
our method has the advantage of simpler computation, superior quality at low
latency, and better generalization to long utterances. We conduct experiments
on the MuST-C V2 dataset and show the effectiveness of our approach.",https://github.com/George0828Zhang/simulst,-1
4b82c0a7-ad7d-4b10-b3c2-1298df8d285e,Social Diversity Reduces the Complexity and Cost of Fostering Fairness,0.512968,"Institutions and investors are constantly faced with the challenge of
appropriately distributing endowments. No budget is limitless and optimising
overall spending without sacrificing positive outcomes has been approached and
resolved using several heuristics. To date, prior works have failed to consider
how to encourage fairness in a population where social diversity is ubiquitous,
and in which investors can only partially observe the population. Herein, by
incorporating social diversity in the Ultimatum game through heterogeneous
graphs, we investigate the effects of several interference mechanisms which
assume incomplete information and flexible standards of fairness. We quantify
the role of diversity and show how it reduces the need for information
gathering, allowing us to relax a strict, costly interference process.
Furthermore, we find that the influence of certain individuals, expressed by
different network centrality measures, can be exploited to further reduce
spending if minimal fairness requirements are lowered. Our results indicate
that diversity changes and opens up novel mechanisms available to institutions
wishing to promote fairness. Overall, our analysis provides novel insights to
guide institutional policies in socially diverse complex systems.",None,-1
d809306e-b87d-422b-80f5-18cd69500f25,Accelerating Machine Learning via the Weber-Fechner Law,0.528608,"The Weber-Fechner Law observes that human perception scales as the logarithm
of the stimulus. We argue that learning algorithms for human concepts could
benefit from the Weber-Fechner Law. Specifically, we impose Weber-Fechner on
simple neural networks, with or without convolution, via the logarithmic power
series of their sorted output. Our experiments show surprising performance and
accuracy on the MNIST data set within a few training iterations and limited
computational resources, suggesting that Weber-Fechner can accelerate machine
learning of human concepts.",None,-1
ad85bab8-391f-4fac-a799-50853a202553,GIAOTracker: A comprehensive framework for MCMOT with global information and optimizing strategies in VisDrone 2021,0.86646,"In recent years, algorithms for multiple object tracking tasks have benefited
from great progresses in deep models and video quality. However, in challenging
scenarios like drone videos, they still suffer from problems, such as small
objects, camera movements and view changes. In this paper, we propose a new
multiple object tracker, which employs Global Information And some Optimizing
strategies, named GIAOTracker. It consists of three stages, i.e., online
tracking, global link and post-processing. Given detections in every frame, the
first stage generates reliable tracklets using information of camera motion,
object motion and object appearance. Then they are associated into trajectories
by exploiting global clues and refined through four post-processing methods.
With the effectiveness of the three stages, GIAOTracker achieves
state-of-the-art performance on the VisDrone MOT dataset and wins the 3rd place
in the VisDrone2021 MOT Challenge.",https://github.com/ultralytics/yolov5,-1
f8e207f2-9965-424d-9792-35789e5f73ab,BITE: Textual Backdoor Attacks with Iterative Trigger Injection,0.831134,"Backdoor attacks have become an emerging threat to NLP systems. By providing
poisoned training data, the adversary can embed a ""backdoor"" into the victim
model, which allows input instances satisfying certain textual patterns (e.g.,
containing a keyword) to be predicted as a target label of the adversary's
choice. In this paper, we demonstrate that it is possible to design a backdoor
attack that is both stealthy (i.e., hard to notice) and effective (i.e., has a
high attack success rate). We propose BITE, a backdoor attack that poisons the
training data to establish strong correlations between the target label and a
set of ""trigger words"". These trigger words are iteratively identified and
injected into the target-label instances through natural word-level
perturbations. The poisoned training data instruct the victim model to predict
the target label on inputs containing trigger words, forming the backdoor.
Experiments on four text classification datasets show that our proposed attack
is significantly more effective than baseline methods while maintaining decent
stealthiness, raising alarm on the usage of untrusted training data. We further
propose a defense method named DeBITE based on potential trigger word removal,
which outperforms existing methods in defending against BITE and generalizes
well to handling other backdoor attacks.",https://github.com/INK-USC/BITE,-1
211b27bb-a6f4-4866-aac3-5535894b6251,WR-ONE2SET: Towards Well-Calibrated Keyphrase Generation,0.0943829,"Keyphrase generation aims to automatically generate short phrases summarizing
an input document. The recently emerged ONE2SET paradigm (Ye et al., 2021)
generates keyphrases as a set and has achieved competitive performance.
Nevertheless, we observe serious calibration errors outputted by ONE2SET,
especially in the over-estimation of $\varnothing$ token (means ""no
corresponding keyphrase""). In this paper, we deeply analyze this limitation and
identify two main reasons behind: 1) the parallel generation has to introduce
excessive $\varnothing$ as padding tokens into training instances; and 2) the
training mechanism assigning target to each slot is unstable and further
aggravates the $\varnothing$ token over-estimation. To make the model
well-calibrated, we propose WR-ONE2SET which extends ONE2SET with an adaptive
instance-level cost Weighting strategy and a target Re-assignment mechanism.
The former dynamically penalizes the over-estimated slots for different
instances thus smoothing the uneven training distribution. The latter refines
the original inappropriate assignment and reduces the supervisory signals of
over-estimated slots. Experimental results on commonly-used datasets
demonstrate the effectiveness and generality of our proposed paradigm.",https://github.com/nltk/nltk/blob/develop/nltk/stem/porter.py,13445
224bf1ac-8197-461c-9981-793d9573f086,Learning to Express in Knowledge-Grounded Conversation,0.340851,"Grounding dialogue generation by extra knowledge has shown great potentials
towards building a system capable of replying with knowledgeable and engaging
responses. Existing studies focus on how to synthesize a response with proper
knowledge, yet neglect that the same knowledge could be expressed differently
by speakers even under the same context. In this work, we mainly consider two
aspects of knowledge expression, namely the structure of the response and style
of the content in each part. We therefore introduce two sequential latent
variables to represent the structure and the content style respectively. We
propose a segmentation-based generation model and optimize the model by a
variational approach to discover the underlying pattern of knowledge expression
in a response. Evaluation results on two benchmarks indicate that our model can
learn the structure style defined by a few examples and generate responses in
desired content style.",https://github.com/nlpxucan/ZRKGC,-1
345da955-b6fb-4af2-8d63-de6b3ad10005,Bingham Policy Parameterization for 3D Rotations in Reinforcement Learning,0.108674,"We propose a new policy parameterization for representing 3D rotations during
reinforcement learning. Today in the continuous control reinforcement learning
literature, many stochastic policy parameterizations are Gaussian. We argue
that universally applying a Gaussian policy parameterization is not always
desirable for all environments. One such case in particular where this is true
are tasks that involve predicting a 3D rotation output, either in isolation, or
coupled with translation as part of a full 6D pose output. Our proposed Bingham
Policy Parameterization (BPP) models the Bingham distribution and allows for
better rotation (quaternion) prediction over a Gaussian policy parameterization
in a range of reinforcement learning tasks. We evaluate BPP on the rotation
Wahba problem task, as well as a set of vision-based next-best pose robot
manipulation tasks from RLBench. We hope that this paper encourages more
research into developing other policy parameterization that are more suited for
particular environments, rather than always assuming Gaussian.",https://github.com/DLR-RM/stable-baselines3,-1
5e71df5d-1b60-428c-a1a9-f7301af3923c,A Safety Assurable Human-Inspired Perception Architecture,0.0627888,"Although artificial intelligence-based perception (AIP) using deep neural
networks (DNN) has achieved near human level performance, its well-known
limitations are obstacles to the safety assurance needed in autonomous
applications. These include vulnerability to adversarial inputs, inability to
handle novel inputs and non-interpretability. While research in addressing
these limitations is active, in this paper, we argue that a fundamentally
different approach is needed to address them. Inspired by dual process models
of human cognition, where Type 1 thinking is fast and non-conscious while Type
2 thinking is slow and based on conscious reasoning, we propose a dual process
architecture for safe AIP. We review research on how humans address the
simplest non-trivial perception problem, image classification, and sketch a
corresponding AIP architecture for this task. We argue that this architecture
can provide a systematic way of addressing the limitations of AIP using DNNs
and an approach to assurance of human-level performance and beyond. We conclude
by discussing what components of the architecture may already be addressed by
existing work and what remains future work.",None,-1
5a382577-9eed-47b0-a997-58a76e059ef6,COIN: Co-Cluster Infomax for Bipartite Graphs,0.832239,"Bipartite graphs are powerful data structures to model interactions between
two types of nodes, which have been used in a variety of applications, such as
recommender systems, information retrieval, and drug discovery. A fundamental
challenge for bipartite graphs is how to learn informative node embeddings.
Despite the success of recent self-supervised learning methods on bipartite
graphs, their objectives are discriminating instance-wise positive and negative
node pairs, which could contain cluster-level errors. In this paper, we
introduce a novel co-cluster infomax (COIN) framework, which captures the
cluster-level information by maximizing the mutual information of co-clusters.
Different from previous infomax methods which estimate mutual information by
neural networks, COIN could easily calculate mutual information. Besides, COIN
is an end-to-end coclustering method which can be trained jointly with other
objective functions and optimized via back-propagation. Furthermore, we also
provide theoretical analysis for COIN. We theoretically prove that COIN is able
to effectively increase the mutual information of node embeddings and COIN is
upper-bounded by the prior distributions of nodes. We extensively evaluate the
proposed COIN framework on various benchmark datasets and tasks to demonstrate
the effectiveness of COIN.",https://github.com/clhchtcjj/BiNE/tree/master/data/wiki,-1
3e460cea-a957-43d3-a93c-f576d0fed5e3,Smart Multi-tenant Federated Learning,0.242747,"Federated learning (FL) is an emerging distributed machine learning method
that empowers in-situ model training on decentralized edge devices. However,
multiple simultaneous training activities could overload resource-constrained
devices. In this work, we propose a smart multi-tenant FL system, MuFL, to
effectively coordinate and execute simultaneous training activities. We first
formalize the problem of multi-tenant FL, define multi-tenant FL scenarios, and
introduce a vanilla multi-tenant FL system that trains activities sequentially
to form baselines. Then, we propose two approaches to optimize multi-tenant FL:
1) activity consolidation merges training activities into one activity with a
multi-task architecture; 2) after training it for rounds, activity splitting
divides it into groups by employing affinities among activities such that
activities within a group have better synergy. Extensive experiments
demonstrate that MuFL outperforms other methods while consuming 40% less
energy. We hope this work will inspire the community to further study and
optimize multi-tenant FL.",https://github.com/tstandley/taskgrouping,20521
91823b49-408f-40ab-951a-9169bd5482f0,Effective and Efficient Training for Sequential Recommendation using Recency Sampling,0.675775,"Many modern sequential recommender systems use deep neural networks, which
can effectively estimate the relevance of items but require a lot of time to
train. Slow training increases expenses, hinders product development timescales
and prevents the model from being regularly updated to adapt to changing user
preferences. Training such sequential models involves appropriately sampling
past user interactions to create a realistic training objective. The existing
training objectives have limitations. For instance, next item prediction never
uses the beginning of the sequence as a learning target, thereby potentially
discarding valuable data. On the other hand, the item masking used by BERT4Rec
is only weakly related to the goal of the sequential recommendation; therefore,
it requires much more time to obtain an effective model. Hence, we propose a
novel Recency-based Sampling of Sequences training objective that addresses
both limitations. We apply our method to various recent and state-of-the-art
model architectures - such as GRU4Rec, Caser, and SASRec. We show that the
models enhanced with our method can achieve performances exceeding or very
close to stateof-the-art BERT4Rec, but with much less training time.",None,-1
a5e39904-b69d-407e-8ef5-9a33f47ff4bc,Efficient Training of Language Models to Fill in the Middle,0.719577,"We show that autoregressive language models can learn to infill text after we
apply a straightforward transformation to the dataset, which simply moves a
span of text from the middle of a document to its end. While this data
augmentation has garnered much interest in recent years, we provide extensive
evidence that training models with a large fraction of data transformed in this
way does not harm the original left-to-right generative capability, as measured
by perplexity and sampling evaluations across a wide range of scales. Given the
usefulness, simplicity, and efficiency of training models to fill-in-the-middle
(FIM), we suggest that future autoregressive language models be trained with
FIM by default. To this end, we run a series of ablations on key
hyperparameters, such as the data transformation frequency, the structure of
the transformation, and the method of selecting the infill span. We use these
ablations to prescribe strong default settings and best practices to train FIM
models. We have released our best infilling model trained with best practices
in our API, and release our infilling benchmarks to aid future research.",None,-1
2ee889a7-bbf5-4160-ad2e-c98895d88797,CS-Insights: A System for Analyzing Computer Science Research,0.0638774,"This paper presents CS-Insights, an interactive web application to analyze
computer science publications from DBLP through multiple perspectives. The
dedicated interfaces allow its users to identify trends in research activity,
productivity, accessibility, author's productivity, venues' statistics, topics
of interest, and the impact of computer science research on other fields.
CS-Insightsis publicly available, and its modular architecture can be easily
adapted to domains other than computer science.",https://github.com/jpwahle/cs-insights,8244
29c6b6a1-155b-4c8b-983a-7d93197bfb03,BoxGraph: Semantic Place Recognition and Pose Estimation from 3D LiDAR,0.780225,"This paper is about extremely robust and lightweight localisation using LiDAR
point clouds based on instance segmentation and graph matching. We model 3D
point clouds as fully-connected graphs of semantically identified components
where each vertex corresponds to an object instance and encodes its shape.
Optimal vertex association across graphs allows for full 6-Degree-of-Freedom
(DoF) pose estimation and place recognition by measuring similarity. This
representation is very concise, condensing the size of maps by a factor of 25
against the state-of-the-art, requiring only 3kB to represent a 1.4MB laser
scan. We verify the efficacy of our system on the SemanticKITTI dataset, where
we achieve a new state-of-the-art in place recognition, with an average of
88.4% recall at 100% precision where the next closest competitor follows with
64.9%. We also show accurate metric pose estimation performance - estimating
6-DoF pose with median errors of 10 cm and 0.33 deg.",None,-1
a0ef30a3-661c-4633-a0e2-f66a5c7c51ff,Model-based Multi-agent Reinforcement Learning: Recent Progress and Prospects,0.519939,"Significant advances have recently been achieved in Multi-Agent Reinforcement
Learning (MARL) which tackles sequential decision-making problems involving
multiple participants. However, MARL requires a tremendous number of samples
for effective training. On the other hand, model-based methods have been shown
to achieve provable advantages of sample efficiency. However, the attempts of
model-based methods to MARL have just started very recently. This paper
presents a review of the existing research on model-based MARL, including
theoretical analyses, algorithms, and applications, and analyzes the advantages
and potential of model-based MARL. Specifically, we provide a detailed taxonomy
of the algorithms and point out the pros and cons for each algorithm according
to the challenges inherent to multi-agent scenarios. We also outline promising
directions for future development of this field.",None,-1
30f34c4e-7fec-4d70-a300-0585c9b1abdb,CHQ-Summ: A Dataset for Consumer Healthcare Question Summarization,0.792252,"The quest for seeking health information has swamped the web with consumers'
health-related questions. Generally, consumers use overly descriptive and
peripheral information to express their medical condition or other healthcare
needs, contributing to the challenges of natural language understanding. One
way to address this challenge is to summarize the questions and distill the key
information of the original question. To address this issue, we introduce a new
dataset, CHQ-Summ that contains 1507 domain-expert annotated consumer health
questions and corresponding summaries. The dataset is derived from the
community question-answering forum and therefore provides a valuable resource
for understanding consumer health-related posts on social media. We benchmark
the dataset on multiple state-of-the-art summarization models to show the
effectiveness of the dataset.",https://github.com/shwetanlp/Yahoo-CHQ-Summ,14142
3c18f293-faa8-4c53-b238-3cc4084a36fc,PathologyBERT -- Pre-trained Vs. A New Transformer Language Model for Pathology Domain,0.690825,"Pathology text mining is a challenging task given the reporting variability
and constant new findings in cancer sub-type definitions. However, successful
text mining of a large pathology database can play a critical role to advance
'big data' cancer research like similarity-based treatment selection, case
identification, prognostication, surveillance, clinical trial screening, risk
stratification, and many others. While there is a growing interest in
developing language models for more specific clinical domains, no
pathology-specific language space exist to support the rapid data-mining
development in pathology space. In literature, a few approaches fine-tuned
general transformer models on specialized corpora while maintaining the
original tokenizer, but in fields requiring specialized terminology, these
models often fail to perform adequately. We propose PathologyBERT - a
pre-trained masked language model which was trained on 347,173 histopathology
specimen reports and publicly released in the Huggingface repository. Our
comprehensive experiments demonstrate that pre-training of transformer model on
pathology corpora yields performance improvements on Natural Language
Understanding (NLU) and Breast Cancer Diagnose Classification when compared to
nonspecific language models.",None,-1
fb3eb02f-e7d2-4f6b-b93b-d8f4e2b314da,Point Cloud Semantic Segmentation using Multi Scale Sparse Convolution Neural Network,0.236197,"In recent years, with the development of computing resources and LiDAR, point
cloud semantic segmentation has attracted many researchers. For the sparsity of
point clouds, although there is already a way to deal with sparse convolution,
multi-scale features are not considered. In this letter, we propose a feature
extraction module based on multi-scale sparse convolution and a feature
selection module based on channel attention and build a point cloud
segmentation network framework based on this. By introducing multi-scale sparse
convolution, the network could capture richer feature information based on
convolution kernels with different sizes, improving the segmentation result of
point cloud segmentation. Experimental results on Stanford large-scale 3-D
Indoor Spaces(S3DIS) dataset and outdoor dataset(SemanticKITTI), demonstrate
effectiveness and superiority of the proposed mothod.",None,-1
6ce8fa29-e8b9-4e23-97fc-d5a54b694bc7,Impact of Tokenization on Language Models: An Analysis for Turkish,0.561189,"Tokenization is an important text preprocessing step to prepare input tokens
for deep language models. WordPiece and BPE are de facto methods employed by
important models, such as BERT and GPT. However, the impact of tokenization can
be different for morphologically rich languages, such as Turkic languages,
where many words can be generated by adding prefixes and suffixes. We compare
five tokenizers at different granularity levels, i.e. their outputs vary from
smallest pieces of characters to the surface form of words, including a
Morphological-level tokenizer. We train these tokenizers and pretrain
medium-sized language models using RoBERTa pretraining procedure on the Turkish
split of the OSCAR corpus. We then fine-tune our models on six downstream
tasks. Our experiments, supported by statistical tests, reveal that
Morphological-level tokenizer has challenging performance with de facto
tokenizers. Furthermore, we find that increasing the vocabulary size improves
the performance of Morphological and Word-level tokenizers more than that of de
facto tokenizers. The ratio of the number of vocabulary parameters to the total
number of model parameters can be empirically chosen as 20% for de facto
tokenizers and 40% for other tokenizers to obtain a reasonable trade-off
between model size and performance.",None,-1
01baf525-564c-45d3-85d5-a928a7fabf05,RePFormer: Refinement Pyramid Transformer for Robust Facial Landmark Detection,0.845796,"This paper presents a Refinement Pyramid Transformer (RePFormer) for robust
facial landmark detection. Most facial landmark detectors focus on learning
representative image features. However, these CNN-based feature representations
are not robust enough to handle complex real-world scenarios due to ignoring
the internal structure of landmarks, as well as the relations between landmarks
and context. In this work, we formulate the facial landmark detection task as
refining landmark queries along pyramid memories. Specifically, a pyramid
transformer head (PTH) is introduced to build both homologous relations among
landmarks and heterologous relations between landmarks and cross-scale
contexts. Besides, a dynamic landmark refinement (DLR) module is designed to
decompose the landmark regression into an end-to-end refinement procedure,
where the dynamically aggregated queries are transformed to residual
coordinates predictions. Extensive experimental results on four facial landmark
detection benchmarks and their various subsets demonstrate the superior
performance and high robustness of our framework.",None,51979
7f1b0364-3e71-4f63-8af0-8175d28df00a,QAGAN: Adversarial Approach To Learning Domain Invariant Language Features,0.212678,"Training models that are robust to data domain shift has gained an increasing
interest both in academia and industry. Question-Answering language models,
being one of the typical problem in Natural Language Processing (NLP) research,
has received much success with the advent of large transformer models. However,
existing approaches mostly work under the assumption that data is drawn from
same distribution during training and testing which is unrealistic and
non-scalable in the wild.
  In this paper, we explore adversarial training approach towards learning
domain-invariant features so that language models can generalize well to
out-of-domain datasets. We also inspect various other ways to boost our model
performance including data augmentation by paraphrasing sentences, conditioning
end of answer span prediction on the start word, and carefully designed
annealing function. Our initial results show that in combination with these
methods, we are able to achieve $15.2\%$ improvement in EM score and $5.6\%$
boost in F1 score on out-of-domain validation dataset over the baseline. We
also dissect our model outputs and visualize the model hidden-states by
projecting them onto a lower-dimensional space, and discover that our specific
adversarial training approach indeed encourages the model to learn domain
invariant embedding and bring them closer in the multi-dimensional space.",https://github.com/towardsautonomy/QAGAN,-1
020d0364-6fa6-4811-aa5c-81c65273996e,A Deep-Discrete Learning Framework for Spherical Surface Registration,0.778236,"Cortical surface registration is a fundamental tool for neuroimaging analysis
that has been shown to improve the alignment of functional regions relative to
volumetric approaches. Classically, image registration is performed by
optimizing a complex objective similarity function, leading to long run times.
This contributes to a convention for aligning all data to a global average
reference frame that poorly reflects the underlying cortical heterogeneity. In
this paper, we propose a novel unsupervised learning-based framework that
converts registration to a multi-label classification problem, where each point
in a low-resolution control grid deforms to one of fixed, finite number of
endpoints. This is learned using a spherical geometric deep learning
architecture, in an end-to-end unsupervised way, with regularization imposed
using a deep Conditional Random Field (CRF). Experiments show that our proposed
framework performs competitively, in terms of similarity and areal distortion,
relative to the most popular classical surface registration algorithms and
generates smoother deformations than other learning-based surface registration
methods, even in subjects with atypical cortical morphology.",https://github.com/ThomasYeoLab/CBIG,10746
151faea4-77ac-45cf-a264-7d5413b209bb,Shape-Guided Diffusion with Inside-Outside Attention,0.765696,"We introduce precise object silhouette as a new form of user control in
text-to-image diffusion models, which we dub Shape-Guided Diffusion. Our
training-free method uses an Inside-Outside Attention mechanism during the
inversion and generation process to apply a shape constraint to the cross- and
self-attention maps. Our mechanism designates which spatial region is the
object (inside) vs. background (outside) then associates edits to the correct
region. We demonstrate the efficacy of our method on the shape-guided editing
task, where the model must replace an object according to a text prompt and
object mask. We curate a new ShapePrompts benchmark derived from MS-COCO and
achieve SOTA results in shape faithfulness without a degradation in text
alignment or image realism according to both automatic metrics and annotator
ratings. Our data and code will be made available at
https://shape-guided-diffusion.github.io.",https://shape-guided-diffusion.github.io,-1
cdb8195d-8ebd-424a-baa4-aef0f34f4c48,DPMS: An ADD-Based Symbolic Approach for Generalized MaxSAT Solving,0.0837034,"Boolean MaxSAT, as well as generalized formulations such as Min-MaxSAT and
Max-hybrid-SAT, are fundamental optimization problems in Boolean reasoning.
Existing methods for MaxSAT have been successful in solving benchmarks in CNF
format. They lack, however, the ability to handle 1) (non-CNF) hybrid
constraints, such as XORs and 2) generalized MaxSAT problems natively. To
address this issue, we propose a novel dynamic-programming approach for solving
generalized MaxSAT problems with hybrid constraints -- called
\emph{Dynamic-Programming-MaxSAT} or DPMS for short -- based on Algebraic
Decision Diagrams (ADDs). With the power of ADDs and the (graded)
project-join-tree builder, our versatile framework admits many generalizations
of CNF-MaxSAT, such as MaxSAT, Min-MaxSAT, and MinSAT with hybrid constraints.
Moreover, DPMS scales provably well on instances with low width. Empirical
results indicate that DPMS is able to solve certain problems quickly, where
other algorithms based on various techniques all fail. Hence, DPMS is a
promising framework and opens a new line of research that invites more
investigation in the future.",None,-1
e1806389-d28d-4fe2-a67f-fdd9da8bfb24,Combining Lipschitz and RBF Surrogate Models for High-dimensional Computationally Expensive Problems,0.747803,"Standard evolutionary optimization algorithms assume that the evaluation of
the objective and constraint functions is straightforward and computationally
cheap. However, in many real-world optimization problems, these evaluations
involve computationally expensive numerical simulations or physical
experiments. Surrogate-assisted evolutionary algorithms (SAEAs) have recently
gained increased attention for their performance in solving these types of
problems. The main idea of SAEAs is the integration of an evolutionary
algorithm with a selected surrogate model that approximates the computationally
expensive function. In this paper, we propose a surrogate model based on a
Lipschitz underestimation and use it to develop a differential evolution-based
algorithm. The algorithm, called Lipschitz Surrogate-assisted Differential
Evolution (LSADE), utilizes the Lipschitz-based surrogate model, along with a
standard radial basis function surrogate model and a local search procedure.
The experimental results on seven benchmark functions of dimensions 30, 50,
100, and 200 show that the proposed LSADE algorithm is competitive compared
with the state-of-the-art algorithms under a limited computational budget,
being especially effective for the very complicated benchmark functions in high
dimensions.",https://github.com/JakubKudela89/LSADE,-1
3662c7cf-a397-4a77-b48f-c0b06f58d6a2,Continuous Prompt Tuning Based Textual Entailment Model for E-commerce Entity Typing,0.722407,"The explosion of e-commerce has caused the need for processing and analysis
of product titles, like entity typing in product titles. However, the rapid
activity in e-commerce has led to the rapid emergence of new entities, which is
difficult to be solved by general entity typing. Besides, product titles in
e-commerce have very different language styles from text data in general
domain. In order to handle new entities in product titles and address the
special language styles problem of product titles in e-commerce domain, we
propose our textual entailment model with continuous prompt tuning based
hypotheses and fusion embeddings for e-commerce entity typing. First, we
reformulate the entity typing task into a textual entailment problem to handle
new entities that are not present during training. Second, we design a model to
automatically generate textual entailment hypotheses using a continuous prompt
tuning method, which can generate better textual entailment hypotheses without
manual design. Third, we utilize the fusion embeddings of BERT embedding and
CharacterBERT embedding with a two-layer MLP classifier to solve the problem
that the language styles of product titles in e-commerce are different from
that of general domain. To analyze the effect of each contribution, we compare
the performance of entity typing and textual entailment model, and conduct
ablation studies on continuous prompt tuning and fusion embeddings. We also
evaluate the impact of different prompt template initialization for the
continuous prompt tuning. We show our proposed model improves the average F1
score by around 2% compared to the baseline BERT entity typing model.",None,197861
d21e9fa2-9893-4637-a6b6-43dd8e4f1aea,Probing Semantic Grounding in Language Models of Code with Representational Similarity Analysis,0.0514724,"Representational Similarity Analysis is a method from cognitive neuroscience,
which helps in comparing representations from two different sources of data. In
this paper, we propose using Representational Similarity Analysis to probe the
semantic grounding in language models of code. We probe representations from
the CodeBERT model for semantic grounding by using the data from the IBM
CodeNet dataset. Through our experiments, we show that current pre-training
methods do not induce semantic grounding in language models of code, and
instead focus on optimizing form-based patterns. We also show that even a
little amount of fine-tuning on semantically relevant tasks increases the
semantic grounding in CodeBERT significantly. Our ablations with the input
modality to the CodeBERT model show that using bimodal inputs (code and natural
language) over unimodal inputs (only code) gives better semantic grounding and
sample efficiency during semantic fine-tuning. Finally, our experiments with
semantic perturbations in code reveal that CodeBERT is able to robustly
distinguish between semantically correct and incorrect code.",None,-1
7954be40-1d7e-4bbb-91b7-17e0c8b83003,Improving Generalizability in Implicitly Abusive Language Detection with Concept Activation Vectors,0.656093,"Robustness of machine learning models on ever-changing real-world data is
critical, especially for applications affecting human well-being such as
content moderation. New kinds of abusive language continually emerge in online
discussions in response to current events (e.g., COVID-19), and the deployed
abuse detection systems should be updated regularly to remain accurate. In this
paper, we show that general abusive language classifiers tend to be fairly
reliable in detecting out-of-domain explicitly abusive utterances but fail to
detect new types of more subtle, implicit abuse. Next, we propose an
interpretability technique, based on the Testing Concept Activation Vector
(TCAV) method from computer vision, to quantify the sensitivity of a trained
model to the human-defined concepts of explicit and implicit abusive language,
and use that to explain the generalizability of the model on new data, in this
case, COVID-related anti-Asian hate speech. Extending this technique, we
introduce a novel metric, Degree of Explicitness, for a single instance and
show that the new metric is beneficial in suggesting out-of-domain unlabeled
examples to effectively enrich the training data with informative, implicitly
abusive texts.",https://github.com/IsarNejad/TCAV-for-Text-Classifiers,-1
4e932f1e-946f-4a3f-a38d-d8d5fd294e24,Entity-driven Fact-aware Abstractive Summarization of Biomedical Literature,0.408179,"As part of the large number of scientific articles being published every
year, the publication rate of biomedical literature has been increasing.
Consequently, there has been considerable effort to harness and summarize the
massive amount of biomedical research articles. While transformer-based
encoder-decoder models in a vanilla source document-to-summary setting have
been extensively studied for abstractive summarization in different domains,
their major limitations continue to be entity hallucination (a phenomenon where
generated summaries constitute entities not related to or present in source
article(s)) and factual inconsistency. This problem is exacerbated in a
biomedical setting where named entities and their semantics (which can be
captured through a knowledge base) constitute the essence of an article. The
use of named entities and facts mined from background knowledge bases
pertaining to the named entities to guide abstractive summarization has not
been studied in biomedical article summarization literature. In this paper, we
propose an entity-driven fact-aware framework for training end-to-end
transformer-based encoder-decoder models for abstractive summarization of
biomedical articles. We call the proposed approach, whose building block is a
transformer-based model, EFAS, Entity-driven Fact-aware Abstractive
Summarization. We conduct experiments using five state-of-the-art
transformer-based models (two of which are specifically designed for long
document summarization) and demonstrate that injecting knowledge into the
training/inference phase of these models enables the models to achieve
significantly better performance than the standard source document-to-summary
setting in terms of entity-level factual accuracy, N-gram novelty, and semantic
equivalence while performing comparably on ROUGE metrics. The proposed approach
is evaluated on ICD-11-Summ-1000, and PubMed-50k.",https://github.com/AmanuelF/biomed,-1
c4d232e5-48d2-4f67-98d7-3d8b3dbc770b,Iterative Patch Selection for High-Resolution Image Recognition,0.666843,"High-resolution images are prevalent in various applications, such as
autonomous driving and computer-aided diagnosis. However, training neural
networks on such images is computationally challenging and easily leads to
out-of-memory errors even on modern GPUs. We propose a simple method, Iterative
Patch Selection (IPS), which decouples the memory usage from the input size and
thus enables the processing of arbitrarily large images under tight hardware
constraints. IPS achieves this by selecting only the most salient patches,
which are then aggregated into a global representation for image recognition.
For both patch selection and aggregation, a cross-attention based transformer
is introduced, which exhibits a close connection to Multiple Instance Learning.
Our method demonstrates strong performance and has wide applicability across
different domains, training regimes and image sizes while using minimal
accelerator memory. For example, we are able to finetune our model on
whole-slide images consisting of up to 250k patches (>16 gigapixels) with only
5 GB of GPU VRAM at a batch size of 16.",https://github.com/benbergner/ips,-1
4947bae1-5dc5-4c44-900f-4b28dbe6413c,A Span-level Bidirectional Network for Aspect Sentiment Triplet Extraction,0.92044,"Aspect Sentiment Triplet Extraction (ASTE) is a new fine-grained sentiment
analysis task that aims to extract triplets of aspect terms, sentiments, and
opinion terms from review sentences. Recently, span-level models achieve
gratifying results on ASTE task by taking advantage of the predictions of all
possible spans. Since all possible spans significantly increases the number of
potential aspect and opinion candidates, it is crucial and challenging to
efficiently extract the triplet elements among them. In this paper, we present
a span-level bidirectional network which utilizes all possible spans as input
and extracts triplets from spans bidirectionally. Specifically, we devise both
the aspect decoder and opinion decoder to decode the span representations and
extract triples from aspect-to-opinion and opinion-to-aspect directions. With
these two decoders complementing with each other, the whole network can extract
triplets from spans more comprehensively. Moreover, considering that mutual
exclusion cannot be guaranteed between the spans, we design a similar span
separation loss to facilitate the downstream task of distinguishing the correct
span by expanding the KL divergence of similar spans during the training
process; in the inference process, we adopt an inference strategy to remove
conflicting triplets from the results base on their confidence scores.
Experimental results show that our framework not only significantly outperforms
state-of-the-art methods, but achieves better performance in predicting
triplets with multi-token entities and extracting triplets in sentences contain
multi-triplets.",https://github.com/chen1310054465/SBN,-1
ca2cd4dc-1b2d-459c-bfbf-021abfc2ad91,Leveraging QA Datasets to Improve Generative Data Augmentation,0.368318,"The ability of generative language models (GLMs) to generate text has
improved considerably in the last few years, enabling their use for generative
data augmentation. In this work, we propose CONDA, an approach to further
improve GLMs' ability to generate synthetic data by reformulating data
generation as context generation for a given question-answer (QA) pair and
leveraging QA datasets for training context generators. Then, we cast
downstream tasks into the same question answering format and adapt the
fine-tuned context generators to the target task domain. Finally, we use the
fine-tuned GLM to generate relevant contexts, which are in turn used as
synthetic training data for their corresponding tasks. We perform extensive
experiments on multiple classification datasets and demonstrate substantial
improvements in performance for both few- and zero-shot settings. Our analysis
reveals that QA datasets that require high-level reasoning abilities (e.g.,
abstractive and common-sense QA datasets) tend to give the best boost in
performance in both few-shot and zero-shot settings.",https://github.com/dheeraj7596/CONDA,-1
a4f4ae41-16e2-4fac-aad8-fee4d98cd2b1,Multi-class Token Transformer for Weakly Supervised Semantic Segmentation,0.998657,"This paper proposes a new transformer-based framework to learn class-specific
object localization maps as pseudo labels for weakly supervised semantic
segmentation (WSSS). Inspired by the fact that the attended regions of the
one-class token in the standard vision transformer can be leveraged to form a
class-agnostic localization map, we investigate if the transformer model can
also effectively capture class-specific attention for more discriminative
object localization by learning multiple class tokens within the transformer.
To this end, we propose a Multi-class Token Transformer, termed as MCTformer,
which uses multiple class tokens to learn interactions between the class tokens
and the patch tokens. The proposed MCTformer can successfully produce
class-discriminative object localization maps from class-to-patch attentions
corresponding to different class tokens. We also propose to use a patch-level
pairwise affinity, which is extracted from the patch-to-patch transformer
attention, to further refine the localization maps. Moreover, the proposed
framework is shown to fully complement the Class Activation Mapping (CAM)
method, leading to remarkably superior WSSS results on the PASCAL VOC and MS
COCO datasets. These results underline the importance of the class token for
WSSS.",https://github.com/xulianuwa/MCTformer,-1
529692b5-da99-4fb8-b25a-94782d034dfa,An Application of Pseudo-Log-Likelihoods to Natural Language Scoring,0.145375,"Language models built using semi-supervised machine learning on large corpora
of natural language have very quickly enveloped the fields of natural language
generation and understanding. In this paper we apply a zero-shot approach
independently developed by a number of researchers now gaining recognition as a
significant alternative to fine-tuning for evaluation on common sense tasks. A
language model with relatively few parameters and training steps compared to a
more recent language model (T5) can outperform it on a recent large data set
(TimeDial), while displaying robustness in its performance across a similar
class of language tasks. Surprisingly, this result is achieved by using a
hyperparameter-free zero-shot method with the smaller model, compared to
fine-tuning to the larger model. We argue that robustness of the smaller model
ought to be understood in terms of compositionality, in a sense that we draw
from recent literature on a class of similar models. We identify a practical
cost for our method and model: high GPU-time for natural language evaluation.
The zero-shot measurement technique that produces remarkable stability, both
for ALBERT and other BERT variants, is an application of pseudo-log-likelihoods
to masked language models for the relative measurement of probability for
substitution alternatives in forced choice language tasks such as the Winograd
Schema Challenge, Winogrande, and others. One contribution of this paper is to
bring together a number of similar, but independent strands of research. We
produce some absolute state-of-the-art results for common sense reasoning in
binary choice tasks, performing better than any published result in the
literature, including fine-tuned efforts. We show a remarkable consistency of
the model's performance under adversarial settings, which we argue is best
explained by the model's compositionality of representations.",https://anonymous.4open.science/r/NotSoFineTuning-4620/,-1
609339f1-8ce8-4cb8-b834-b2d19e459c9a,Audio-Adaptive Activity Recognition Across Video Domains,0.611457,"This paper strives for activity recognition under domain shift, for example
caused by change of scenery or camera viewpoint. The leading approaches reduce
the shift in activity appearance by adversarial training and self-supervised
learning. Different from these vision-focused works we leverage activity sounds
for domain adaptation as they have less variance across domains and can
reliably indicate which activities are not happening. We propose an
audio-adaptive encoder and associated learning methods that discriminatively
adjust the visual feature representation as well as addressing shifts in the
semantic distribution. To further eliminate domain-specific features and
include domain-invariant activity sounds for recognition, an audio-infused
recognizer is proposed, which effectively models the cross-modal interaction
across domains. We also introduce the new task of actor shift, with a
corresponding audio-visual dataset, to challenge our method with situations
where the activity appearance changes dramatically. Experiments on this
dataset, EPIC-Kitchens and CharadesEgo show the effectiveness of our approach.",https://github.com/open-mmlab/mmaction2,-1
4d594e56-d21f-4fa0-aea1-88ff8dc406d8,Improving the Generalizability of Depression Detection by Leveraging Clinical Questionnaires,0.409463,"Automated methods have been widely used to identify and analyze mental health
conditions (e.g., depression) from various sources of information, including
social media. Yet, deployment of such models in real-world healthcare
applications faces challenges including poor out-of-domain generalization and
lack of trust in black box models. In this work, we propose approaches for
depression detection that are constrained to different degrees by the presence
of symptoms described in PHQ9, a questionnaire used by clinicians in the
depression screening process. In dataset-transfer experiments on three social
media datasets, we find that grounding the model in PHQ9's symptoms
substantially improves its ability to generalize to out-of-distribution data
compared to a standard BERT-based approach. Furthermore, this approach can
still perform competitively on in-domain data. These results and our
qualitative analyses suggest that grounding model predictions in
clinically-relevant symptoms can improve generalizability while producing a
model that is easier to inspect.",https://github.com/thongnt99/,-1
457c54c6-91e7-4200-94d1-37c94e325ddc,GRS: Combining Generation and Revision in Unsupervised Sentence Simplification,0.581492,"We propose GRS: an unsupervised approach to sentence simplification that
combines text generation and text revision. We start with an iterative
framework in which an input sentence is revised using explicit edit operations,
and add paraphrasing as a new edit operation. This allows us to combine the
advantages of generative and revision-based approaches: paraphrasing captures
complex edit operations, and the use of explicit edit operations in an
iterative manner provides controllability and interpretability. We demonstrate
these advantages of GRS compared to existing methods on the Newsela and ASSET
datasets.",https://github.com/imohammad12/GRS,-1
48bb48f3-de82-4c8b-88c8-57d76ba8a8d2,VidConv: A modernized 2D ConvNet for Efficient Video Recognition,0.107343,"Since being introduced in 2020, Vision Transformers (ViT) has been steadily
breaking the record for many vision tasks and are often described as
``all-you-need"" to replace ConvNet. Despite that, ViTs are generally
computational, memory-consuming, and unfriendly for embedded devices. In
addition, recent research shows that standard ConvNet if redesigned and trained
appropriately can compete favorably with ViT in terms of accuracy and
scalability. In this paper, we adopt the modernized structure of ConvNet to
design a new backbone for action recognition. Particularly, our main target is
to serve for industrial product deployment, such as FPGA boards in which only
standard operations are supported. Therefore, our network simply consists of 2D
convolutions, without using any 3D convolution, long-range attention plugin, or
Transformer blocks. While being trained with much fewer epochs (5x-10x), our
backbone surpasses the methods using (2+1)D and 3D convolution, and achieve
comparable results with ViT on two benchmark datasets.",https://github.com/open-mmlab/mmaction2,-1
d6013329-8af6-4e05-ae93-999a31976863,Real-world Video Anomaly Detection by Extracting Salient Features in Videos,0.14117,"We propose a lightweight and accurate method for detecting anomalies in
videos. Existing methods used multiple-instance learning (MIL) to determine the
normal/abnormal status of each segment of the video. Recent successful
researches argue that it is important to learn the temporal relationships among
segments to achieve high accuracy, instead of focusing on only a single
segment. Therefore we analyzed the existing methods that have been successful
in recent years, and found that while it is indeed important to learn all
segments together, the temporal orders among them are irrelevant to achieving
high accuracy. Based on this finding, we do not use the MIL framework, but
instead propose a lightweight model with a self-attention mechanism to
automatically extract features that are important for determining
normal/abnormal from all input segments. As a result, our neural network model
has 1.3\% of the number of parameters of the existing method. We evaluated the
frame-level detection accuracy of our method on three benchmark datasets
(UCF-Crime, ShanghaiTech, and XD-Violence) and demonstrate that our method can
achieve the comparable or better accuracy than state-of-the-art methods.",None,-1
c037fa5f-7b9d-4be2-ab4a-12e687152609,Evaluating Explainability for Graph Neural Networks,0.887414,"As post hoc explanations are increasingly used to understand the behavior of
graph neural networks (GNNs), it becomes crucial to evaluate the quality and
reliability of GNN explanations. However, assessing the quality of GNN
explanations is challenging as existing graph datasets have no or unreliable
ground-truth explanations for a given task. Here, we introduce a synthetic
graph data generator, ShapeGGen, which can generate a variety of benchmark
datasets (e.g., varying graph sizes, degree distributions, homophilic vs.
heterophilic graphs) accompanied by ground-truth explanations. Further, the
flexibility to generate diverse synthetic datasets and corresponding
ground-truth explanations allows us to mimic the data generated by various
real-world applications. We include ShapeGGen and several real-world graph
datasets into an open-source graph explainability library, GraphXAI. In
addition to synthetic and real-world graph datasets with ground-truth
explanations, GraphXAI provides data loaders, data processing functions,
visualizers, GNN model implementations, and evaluation metrics to benchmark the
performance of GNN explainability methods.",https://github.com/mims-harvard/GraphXAI,-1
24e91ce4-7034-4a65-8b49-588c20035512,Energy-Based Residual Latent Transport for Unsupervised Point Cloud Completion,0.178686,"Unsupervised point cloud completion aims to infer the whole geometry of a
partial object observation without requiring partial-complete correspondence.
Differing from existing deterministic approaches, we advocate generative
modeling based unsupervised point cloud completion to explore the missing
correspondence. Specifically, we propose a novel framework that performs
completion by transforming a partial shape encoding into a complete one using a
latent transport module, and it is designed as a latent-space energy-based
model (EBM) in an encoder-decoder architecture, aiming to learn a probability
distribution conditioned on the partial shape encoding. To train the latent
code transport module and the encoder-decoder network jointly, we introduce a
residual sampling strategy, where the residual captures the domain gap between
partial and complete shape latent spaces. As a generative model-based
framework, our method can produce uncertainty maps consistent with human
perception, leading to explainable unsupervised point cloud completion. We
experimentally show that the proposed method produces high-fidelity completion
results, outperforming state-of-the-art models by a significant margin.",None,-1
08d404d9-442c-40c1-9a35-6daffd45053d,Robust Preference Learning for Storytelling via Contrastive Reinforcement Learning,0.963419,"Controlled automated story generation seeks to generate natural language
stories satisfying constraints from natural language critiques or preferences.
Existing methods to control for story preference utilize prompt engineering
which is labor intensive and often inconsistent. They may also use
logit-manipulation methods which require annotated datasets to exist for the
desired attributes. To address these issues, we first train a contrastive
bi-encoder model to align stories with corresponding human critiques, named
CARP, building a general purpose preference model. This is subsequently used as
a reward function to fine-tune a generative language model via reinforcement
learning. However, simply fine-tuning a generative language model with a
contrastive reward model does not always reliably result in a story generation
system capable of generating stories that meet user preferences. To increase
story generation robustness we further fine-tune the contrastive reward model
using a prompt-learning technique. A human participant study is then conducted
comparing generations from our full system, ablations, and two baselines. We
show that the full fine-tuning pipeline results in a story generator preferred
over a LLM 20x as large as well as logit-based methods. This motivates the use
of contrastive learning for general purpose human preference modeling.",https://github.com/lvwerra/trl/,19820
a32a30d2-d2cf-4237-8106-ad6af1ff04c0,Learning from Bootstrapping and Stepwise Reinforcement Reward: A Semi-Supervised Framework for Text Style Transfer,0.029388,"Text style transfer is an important task in controllable language generation.
Supervised approaches have pushed performance improvement on style-oriented
rewriting such as formality conversion. However, challenges remain due to the
scarcity of large-scale parallel data in many domains. While unsupervised
approaches do not rely on annotated sentence pairs for each style, they are
often plagued with instability issues such as mode collapse or quality
degradation. To take advantage of both supervised and unsupervised paradigms
and tackle the challenges, in this work, we propose a semi-supervised framework
for text style transfer. First, the learning process is bootstrapped with
supervision guided by automatically constructed pseudo-parallel pairs using
lexical and semantic-based methods. Then the model learns from unlabeled data
via reinforcement rewards. Specifically, we propose to improve the
sequence-to-sequence policy gradient via stepwise reward optimization,
providing fine-grained learning signals and stabilizing the reinforced learning
process. Experimental results show that the proposed approach achieves
state-of-the-art performance on multiple datasets, and produces effective
generation with as minimal as 10\% of training data.",https://github.com/huggingface/transformers,-1
f3c1c6ef-5ade-4870-8928-3b6f535dfb47,Semantic-shape Adaptive Feature Modulation for Semantic Image Synthesis,0.238035,"Recent years have witnessed substantial progress in semantic image synthesis,
it is still challenging in synthesizing photo-realistic images with rich
details. Most previous methods focus on exploiting the given semantic map,
which just captures an object-level layout for an image. Obviously, a
fine-grained part-level semantic layout will benefit object details generation,
and it can be roughly inferred from an object's shape. In order to exploit the
part-level layouts, we propose a Shape-aware Position Descriptor (SPD) to
describe each pixel's positional feature, where object shape is explicitly
encoded into the SPD feature. Furthermore, a Semantic-shape Adaptive Feature
Modulation (SAFM) block is proposed to combine the given semantic map and our
positional features to produce adaptively modulated features. Extensive
experiments demonstrate that the proposed SPD and SAFM significantly improve
the generation of objects with rich details. Moreover, our method performs
favorably against the SOTA methods in terms of quantitative and qualitative
evaluation. The source code and model are available at
https://github.com/cszy98/SAFM.",None,-1
396f78ab-3bcc-4fe0-be8c-74ab6e101ed3,"The Better Your Syntax, the Better Your Semantics? Probing Pretrained Language Models for the English Comparative Correlative",0.940257,"Construction Grammar (CxG) is a paradigm from cognitive linguistics
emphasising the connection between syntax and semantics. Rather than rules that
operate on lexical items, it posits constructions as the central building
blocks of language, i.e., linguistic units of different granularity that
combine syntax and semantics. As a first step towards assessing the
compatibility of CxG with the syntactic and semantic knowledge demonstrated by
state-of-the-art pretrained language models (PLMs), we present an investigation
of their capability to classify and understand one of the most commonly studied
constructions, the English comparative correlative (CC). We conduct experiments
examining the classification accuracy of a syntactic probe on the one hand and
the models' behaviour in a semantic application task on the other, with BERT,
RoBERTa, and DeBERTa as the example PLMs. Our results show that all three
investigated PLMs are able to recognise the structure of the CC but fail to use
its meaning. While human-like performance of PLMs on many NLP tasks has been
alleged, this indicates that PLMs still suffer from substantial shortcomings in
central domains of linguistic knowledge.",https://github.com/LeonieWeissweiler/ComparativeCorrelative,76971
8e9e562d-ca9c-4810-9766-fe9e64c16ac0,Efficient Algorithms for Planning with Participation Constraints,0.501251,"We consider the problem of planning with participation constraints introduced
in [Zhang et al., 2022]. In this problem, a principal chooses actions in a
Markov decision process, resulting in separate utilities for the principal and
the agent. However, the agent can and will choose to end the process whenever
his expected onward utility becomes negative. The principal seeks to compute
and commit to a policy that maximizes her expected utility, under the
constraint that the agent should always want to continue participating. We
provide the first polynomial-time exact algorithm for this problem for
finite-horizon settings, where previously only an additive
$\varepsilon$-approximation algorithm was known. Our approach can also be
extended to the (discounted) infinite-horizon case, for which we give an
algorithm that runs in time polynomial in the size of the input and
$\log(1/\varepsilon)$, and returns a policy that is optimal up to an additive
error of $\varepsilon$.",None,-1
62df594f-253e-4895-acf6-52295eda6ada,On Mitigating Hard Clusters for Face Clustering,0.355252,"Face clustering is a promising way to scale up face recognition systems using
large-scale unlabeled face images. It remains challenging to identify small or
sparse face image clusters that we call hard clusters, which is caused by the
heterogeneity, \ie, high variations in size and sparsity, of the clusters.
Consequently, the conventional way of using a uniform threshold (to identify
clusters) often leads to a terrible misclassification for the samples that
should belong to hard clusters. We tackle this problem by leveraging the
neighborhood information of samples and inferring the cluster memberships (of
samples) in a probabilistic way. We introduce two novel modules,
Neighborhood-Diffusion-based Density (NDDe) and Transition-Probability-based
Distance (TPDi), based on which we can simply apply the standard Density Peak
Clustering algorithm with a uniform threshold. Our experiments on multiple
benchmarks show that each module contributes to the final performance of our
method, and by incorporating them into other advanced face clustering methods,
these two modules can boost the performance of these methods to a new
state-of-the-art. Code is available at:
https://github.com/echoanran/On-Mitigating-Hard-Clusters.",https://github.com/echoanran/On-Mitigating-Hard-Clusters,-1
5780960a-ca79-47dc-9029-299d4194267d,RAILD: Towards Leveraging Relation Features for Inductive Link Prediction In Knowledge Graphs,0.689223,"Due to the open world assumption, Knowledge Graphs (KGs) are never complete.
In order to address this issue, various Link Prediction (LP) methods are
proposed so far. Some of these methods are inductive LP models which are
capable of learning representations for entities not seen during training.
However, to the best of our knowledge, none of the existing inductive LP models
focus on learning representations for unseen relations. In this work, a novel
Relation Aware Inductive Link preDiction (RAILD) is proposed for KG completion
which learns representations for both unseen entities and unseen relations. In
addition to leveraging textual literals associated with both entities and
relations by employing language models, RAILD also introduces a novel
graph-based approach to generate features for relations. Experiments are
conducted with different existing and newly created challenging benchmark
datasets and the results indicate that RAILD leads to performance improvement
over the state-of-the-art models. Moreover, since there are no existing
inductive LP models which learn representations for unseen relations, we have
created our own baselines and the results obtained with RAILD also outperform
these baselines.",https://github.com/GenetAsefa/RAILD,-1
574a22bf-52d9-49f1-950e-3c90a88e958e,Diagnostics for Deep Neural Networks with Automated Copy/Paste Attacks,0.57359,"This paper considers the problem of helping humans exercise scalable
oversight over deep neural networks (DNNs). Adversarial examples can be useful
by helping to reveal weaknesses in DNNs, but they can be difficult to interpret
or draw actionable conclusions from. Some previous works have proposed using
human-interpretable adversarial attacks including copy/paste attacks in which
one natural image pasted into another causes an unexpected misclassification.
We build on these with two contributions. First, we introduce Search for
Natural Adversarial Features Using Embeddings (SNAFUE) which offers a fully
automated method for finding copy/paste attacks. Second, we use SNAFUE to red
team an ImageNet classifier. We reproduce copy/paste attacks from previous
works and find hundreds of other easily-describable vulnerabilities, all
without a human in the loop. Code is available at
https://github.com/thestephencasper/snafue",https://github.com/thestephencasper/snafue,-1
96c45ed5-86d2-46ad-a179-928f07d2a7a5,Building an Icelandic Entity Linking Corpus,0.146291,"In this paper, we present the first Entity Linking corpus for Icelandic. We
describe our approach of using a multilingual entity linking model (mGENRE) in
combination with Wikipedia API Search (WAPIS) to label our data and compare it
to an approach using WAPIS only. We find that our combined method reaches 53.9%
coverage on our corpus, compared to 30.9% using only WAPIS. We analyze our
results and explain the value of using a multilingual system when working with
Icelandic. Additionally, we analyze the data that remain unlabeled, identify
patterns and discuss why they may be more difficult to annotate.",None,-1
1c0567b3-051b-4cb8-9135-c65cc38b5808,On the Effectiveness of Parameter-Efficient Fine-Tuning,0.898387,"Fine-tuning pre-trained models has been ubiquitously proven to be effective
in a wide range of NLP tasks. However, fine-tuning the whole model is parameter
inefficient as it always yields an entirely new model for each task. Currently,
many research works propose to only fine-tune a small portion of the parameters
while keeping most of the parameters shared across different tasks. These
methods achieve surprisingly good performance and are shown to be more stable
than their corresponding fully fine-tuned counterparts. However, such kind of
methods is still not well understood. Some natural questions arise: How does
the parameter sparsity lead to promising performance? Why is the model more
stable than the fully fine-tuned models? How to choose the tunable parameters?
In this paper, we first categorize the existing methods into random approaches,
rule-based approaches, and projection-based approaches based on how they choose
which parameters to tune. Then, we show that all of the methods are actually
sparse fine-tuned models and conduct a novel theoretical analysis of them. We
indicate that the sparsity is actually imposing a regularization on the
original model by controlling the upper bound of the stability. Such stability
leads to better generalization capability which has been empirically observed
in a lot of recent research works. Despite the effectiveness of sparsity
grounded by our theory, it still remains an open problem of how to choose the
tunable parameters. To better choose the tunable parameters, we propose a novel
Second-order Approximation Method (SAM) which approximates the original problem
with an analytically solvable optimization function. The tunable parameters are
determined by directly optimizing the approximation function. The experimental
results show that our proposed SAM model outperforms many strong baseline
models and it also verifies our theoretical analysis.",https://github.com/fuzihaofzh/AnalyzeParameterEfficientFinetune,-1
fa3e13ef-799b-4a88-a9fa-91b49ac70ae3,Interpretable Hidden Markov Model-Based Deep Reinforcement Learning Hierarchical Framework for Predictive Maintenance of Turbofan Engines,0.676536,"An open research question in deep reinforcement learning is how to focus the
policy learning of key decisions within a sparse domain. This paper emphasizes
combining the advantages of inputoutput hidden Markov models and reinforcement
learning towards interpretable maintenance decisions. We propose a novel
hierarchical-modeling methodology that, at a high level, detects and interprets
the root cause of a failure as well as the health degradation of the turbofan
engine, while, at a low level, it provides the optimal replacement policy. It
outperforms the baseline performance of deep reinforcement learning methods
applied directly to the raw data or when using a hidden Markov model without
such a specialized hierarchy. It also provides comparable performance to prior
work, however, with the additional benefit of interpretability.",None,-1
889de63b-fbe4-46f8-9298-2862db935173,SNeS: Learning Probably Symmetric Neural Surfaces from Incomplete Data,0.340137,"We present a method for the accurate 3D reconstruction of partly-symmetric
objects. We build on the strengths of recent advances in neural reconstruction
and rendering such as Neural Radiance Fields (NeRF). A major shortcoming of
such approaches is that they fail to reconstruct any part of the object which
is not clearly visible in the training image, which is often the case for
in-the-wild images and videos. When evidence is lacking, structural priors such
as symmetry can be used to complete the missing information. However,
exploiting such priors in neural rendering is highly non-trivial: while
geometry and non-reflective materials may be symmetric, shadows and reflections
from the ambient scene are not symmetric in general. To address this, we apply
a soft symmetry constraint to the 3D geometry and material properties, having
factored appearance into lighting, albedo colour and reflectivity. We evaluate
our method on the recently introduced CO3D dataset, focusing on the car
category due to the challenge of reconstructing highly-reflective materials. We
show that it can reconstruct unobserved regions with high fidelity and render
high-quality novel view images.",None,-1
d09bc21d-4bd2-400c-8de8-0d64b1aa9384,Apport des ontologies pour le calcul de la similarité sémantique au sein d'un système de recommandation,0.635075,"Measurement of the semantic relatedness or likeness between terms, words, or
text data plays an important role in different applications dealing with
textual data such as knowledge acquisition, recommender system, and natural
language processing. Over the past few years, many ontologies have been
developed and used as a form of structured representation of knowledge bases
for information systems. The calculation of semantic similarity from ontology
has developed and depending on the context is complemented by other similarity
calculation methods. In this paper, we propose and carry on an approach for the
calculation of ontology-based semantic similarity using in the context of a
recommender system.",None,-1
d3c55138-6b34-4017-a5c1-2bd7a0f61050,Towards Accurate Open-Set Recognition via Background-Class Regularization,0.450777,"In open-set recognition (OSR), classifiers should be able to reject
unknown-class samples while maintaining high closed-set classification
accuracy. To effectively solve the OSR problem, previous studies attempted to
limit latent feature space and reject data located outside the limited space
via offline analyses, e.g., distance-based feature analyses, or complicated
network architectures. To conduct OSR via a simple inference process (without
offline analyses) in standard classifier architectures, we use distance-based
classifiers instead of conventional Softmax classifiers. Afterwards, we design
a background-class regularization strategy, which uses background-class data as
surrogates of unknown-class ones during training phase. Specifically, we
formulate a novel regularization loss suitable for distance-based classifiers,
which reserves sufficiently large class-wise latent feature spaces for known
classes and forces background-class samples to be located far away from the
limited spaces. Through our extensive experiments, we show that the proposed
method provides robust OSR results, while maintaining high closed-set
classification accuracy.",https://github.com/Anjin-Liu/Openset_Learning_AOSR,-1
224498e4-2097-452a-8b2b-ac34e25215a2,Semi-Supervised Knowledge-Grounded Pre-training for Task-Oriented Dialog Systems,0.885175,"Recent advances in neural approaches greatly improve task-oriented dialogue
(TOD) systems which assist users to accomplish their goals. However, such
systems rely on costly manually labeled dialogs which are not available in
practical scenarios. In this paper, we present our models for Track 2 of the
SereTOD 2022 challenge, which is the first challenge of building
semi-supervised and reinforced TOD systems on a large-scale real-world Chinese
TOD dataset MobileCS. We build a knowledge-grounded dialog model to formulate
dialog history and local KB as input and predict the system response. And we
perform semi-supervised pre-training both on the labeled and unlabeled data.
Our system achieves the first place both in the automatic evaluation and human
interaction, especially with higher BLEU (+7.64) and Success (+13.6\%) than the
second place.",https://github.com/Zeng-WH/S2KG,-1
213328de-6f93-4994-aae1-f5f2179e4e4f,Perturbation Augmentation for Fairer NLP,0.892518,"Unwanted and often harmful social biases are becoming ever more salient in
NLP research, affecting both models and datasets. In this work, we ask whether
training on demographically perturbed data leads to fairer language models. We
collect a large dataset of human annotated text perturbations and train a
neural perturbation model, which we show outperforms heuristic alternatives. We
find that (i) language models (LMs) pre-trained on demographically perturbed
corpora are typically more fair, and (ii) LMs finetuned on perturbed GLUE
datasets exhibit less demographic bias on downstream tasks, and (iii) fairness
improvements do not come at the expense of performance on downstream tasks.
Lastly, we discuss outstanding questions about how best to evaluate the
(un)fairness of large language models. We hope that this exploration of neural
demographic perturbation will help drive more improvement towards fairer NLP.",https://github.com/facebookresearch/ParlAI,-1
60ba9fd8-dfbc-46a0-8d53-37479a613a70,Neural Knowledge Bank for Pretrained Transformers,0.483295,"The ability of pretrained Transformers to remember factual knowledge is
essential but still limited for existing models. Inspired by existing work that
regards Feed-Forward Networks (FFNs) in Transformers as key-value memories, we
design a Neural Knowledge Bank (NKB) and a knowledge injection strategy to
introduce extra factual knowledge for pretrained Transformers. The NKB is in
the form of additional knowledgeable memory slots to the FFN and the
memory-like architecture makes it highly interpretable and flexible. When
injecting extra knowledge with the Salient Span Masking (SSM) pretraining
objective, we fix the original pretrained model and train only the NKB. This
training strategy makes sure the general language modeling ability of the
original pretrained model is not influenced. By mounting the NKB onto the T5
model, we verify its strong ability to store extra factual knowledge based on
three closed-book question answering datasets. Also, we prove that mounting the
NKB will not degrade the general language modeling ability of T5 through two
representative tasks, summarization and machine translation. Further, we
thoroughly analyze the interpretability of the NKB and reveal the meaning of
its keys and values in a human-readable way. Finally, we show the flexibility
of the NKB by directly modifying its value vectors to update the factual
knowledge stored in it.",https://github.com/huggingface/transformers,-1
fbe81432-7eee-459b-8933-4872b40476e2,Exemplar-free Online Continual Learning,0.752234,"Targeted for real world scenarios, online continual learning aims to learn
new tasks from sequentially available data under the condition that each data
is observed only once by the learner. Though recent works have made remarkable
achievements by storing part of learned task data as exemplars for knowledge
replay, the performance is greatly relied on the size of stored exemplars while
the storage consumption is a significant constraint in continual learning. In
addition, storing exemplars may not always be feasible for certain applications
due to privacy concerns. In this work, we propose a novel exemplar-free method
by leveraging nearest-class-mean (NCM) classifier where the class mean is
estimated during training phase on all data seen so far through online mean
update criteria. We focus on image classification task and conduct extensive
experiments on benchmark datasets including CIFAR-100 and Food-1k. The results
demonstrate that our method without using any exemplar outperforms
state-of-the-art exemplar-based approaches with large margins under standard
protocol (20 exemplars per class) and is able to achieve competitive
performance even with larger exemplar size (100 exemplars per class).",None,-1
47c2dc4d-eb82-4b06-93d1-9c7bce5fc3df,Efficient Hybrid Network: Inducting Scattering Features,0.0546577,"Recent work showed that hybrid networks, which combine predefined and learnt
filters within a single architecture, are more amenable to theoretical analysis
and less prone to overfitting in data-limited scenarios. However, their
performance has yet to prove competitive against the conventional counterparts
when sufficient amounts of training data are available. In an attempt to
address this core limitation of current hybrid networks, we introduce an
Efficient Hybrid Network (E-HybridNet). We show that it is the first scattering
based approach that consistently outperforms its conventional counterparts on a
diverse range of datasets. It is achieved with a novel inductive architecture
that embeds scattering features into the network flow using Hybrid Fusion
Blocks. We also demonstrate that the proposed design inherits the key property
of prior hybrid networks -- an effective generalisation in data-limited
scenarios. Our approach successfully combines the best of the two worlds:
flexibility and power of learnt features and stability and predictability of
scattering representations.",https://github.com/dminskiy/EHybridNet-icpr2022,-1
67d21991-c4b5-46ac-a714-308442be0ec2,Meta-Learning Sparse Compression Networks,0.604255,"Recent work in Deep Learning has re-imagined the representation of data as
functions mapping from a coordinate space to an underlying continuous signal.
When such functions are approximated by neural networks this introduces a
compelling alternative to the more common multi-dimensional array
representation. Recent work on such Implicit Neural Representations (INRs) has
shown that - following careful architecture search - INRs can outperform
established compression methods such as JPEG (e.g. Dupont et al., 2021). In
this paper, we propose crucial steps towards making such ideas scalable:
Firstly, we employ state-of-the-art network sparsification techniques to
drastically improve compression. Secondly, introduce the first method allowing
for sparsification to be employed in the inner-loop of commonly used
Meta-Learning algorithms, drastically improving both compression and the
computational cost of learning INRs. The generality of this formalism allows us
to present results on diverse data modalities such as images, manifolds, signed
distance functions, 3D shapes and scenes, several of which establish new
state-of-the-art results.",None,-1
687098ed-3bbf-4691-a68e-290b65451e20,RelTR: Relation Transformer for Scene Graph Generation,0.958783,"Different objects in the same scene are more or less related to each other,
but only a limited number of these relationships are noteworthy. Inspired by
DETR, which excels in object detection, we view scene graph generation as a set
prediction problem and propose an end-to-end scene graph generation model RelTR
which has an encoder-decoder architecture. The encoder reasons about the visual
feature context while the decoder infers a fixed-size set of triplets
subject-predicate-object using different types of attention mechanisms with
coupled subject and object queries. We design a set prediction loss performing
the matching between the ground truth and predicted triplets for the end-to-end
training. In contrast to most existing scene graph generation methods, RelTR is
a one-stage method that predicts a set of relationships directly only using
visual appearance without combining entities and labeling all possible
predicates. Extensive experiments on the Visual Genome and Open Images V6
datasets demonstrate the superior performance and fast inference of our model.",https://github.com/yrcong/RelTR,-1
055781b6-a489-4a94-9581-e811e475915f,Learnable Graph Convolutional Network and Feature Fusion for Multi-view Learning,0.983776,"In practical applications, multi-view data depicting objectives from assorted
perspectives can facilitate the accuracy increase of learning algorithms.
However, given multi-view data, there is limited work for learning
discriminative node relationships and graph information simultaneously via
graph convolutional network that has drawn the attention from considerable
researchers in recent years. Most of existing methods only consider the
weighted sum of adjacency matrices, yet a joint neural network of both feature
and graph fusion is still under-explored. To cope with these issues, this paper
proposes a joint deep learning framework called Learnable Graph Convolutional
Network and Feature Fusion (LGCN-FF), consisting of two stages: feature fusion
network and learnable graph convolutional network. The former aims to learn an
underlying feature representation from heterogeneous views, while the latter
explores a more discriminative graph fusion via learnable weights and a
parametric activation function dubbed Differentiable Shrinkage Activation (DSA)
function. The proposed LGCN-FF is validated to be superior to various
state-of-the-art methods in multi-view semi-supervised classification.",None,-1
a14f5581-2abc-4985-ad13-587e75768e4e,Writer Recognition Using Off-line Handwritten Single Block Characters,0.104666,"Block characters are often used when filling paper forms for a variety of
purposes. We investigate if there is biometric information contained within
individual digits of handwritten text. In particular, we use personal identity
numbers consisting of the six digits of the date of birth, DoB. We evaluate two
recognition approaches, one based on handcrafted features that compute contour
directional measurements, and another based on deep features from a ResNet50
model. We use a self-captured database of 317 individuals and 4920 written DoBs
in total. Results show the presence of identity-related information in a piece
of handwritten information as small as six digits with the DoB. We also analyze
the impact of the amount of enrolment samples, varying its number between one
and ten. Results with such small amount of data are promising. With ten
enrolment samples, the Top-1 accuracy with deep features is around 94%, and
reaches nearly 100% by Top-10. The verification accuracy is more modest, with
EER>20%with any given feature and enrolment set size, showing that there is
still room for improvement.",None,-1
8b863fa1-c62b-40ba-9c48-f664823c79b9,Wireless Ad Hoc Federated Learning: A Fully Distributed Cooperative Machine Learning,0.334296,"Privacy-sensitive data is stored in autonomous vehicles, smart devices, or
sensor nodes that can move around with making opportunistic contact with each
other. Federation among such nodes was mainly discussed in the context of
federated learning with a centralized mechanism in many works. However, because
of multi-vendor issues, those nodes do not want to rely on a specific server
operated by a third party for this purpose. In this paper, we propose a
wireless ad hoc federated learning (WAFL) -- a fully distributed cooperative
machine learning organized by the nodes physically nearby. WAFL can develop
generalized models from Non-IID datasets stored in distributed nodes locally by
exchanging and aggregating them with each other over opportunistic node-to-node
contacts. In our benchmark-based evaluation with various opportunistic
networks, WAFL has achieved higher accuracy of 94.8-96.3% than the
self-training case of 84.7%. All our evaluation results show that WAFL can
train and converge the model parameters from highly-partitioned Non-IID
datasets over opportunistic networks without any centralized mechanisms.",None,-1
65f33aa7-5cfb-48a6-baf5-7afbb7eeea11,Molecular Substructure-Aware Network for Drug-Drug Interaction Prediction,0.609175,"Concomitant administration of drugs can cause drug-drug interactions (DDIs).
Some drug combinations are beneficial, but other ones may cause negative
effects which are previously unrecorded. Previous works on DDI prediction
usually rely on hand-engineered domain knowledge, which is laborious to obtain.
In this work, we propose a novel model, Molecular Substructure-Aware Network
(MSAN), to effectively predict potential DDIs from molecular structures of drug
pairs. We adopt a Transformer-like substructure extraction module to acquire a
fixed number of representative vectors that are associated with various
substructure patterns of the drug molecule. Then, interaction strength between
the two drugs' substructures will be captured by a similarity-based interaction
module. We also perform a substructure dropping augmentation before graph
encoding to alleviate overfitting. Experimental results from a real-world
dataset reveal that our proposed model achieves the state-of-the-art
performance. We also show that the predictions of our model are highly
interpretable through a case study.",https://github.com/Hienyriux/MSAN,-1
05b2b505-605b-44a6-9fad-c3ad19482a7b,Parallel Instance Query Network for Named Entity Recognition,0.533566,"Named entity recognition (NER) is a fundamental task in natural language
processing. Recent works treat named entity recognition as a reading
comprehension task, constructing type-specific queries manually to extract
entities. This paradigm suffers from three issues. First, type-specific queries
can only extract one type of entities per inference, which is inefficient.
Second, the extraction for different types of entities is isolated, ignoring
the dependencies between them. Third, query construction relies on external
knowledge and is difficult to apply to realistic scenarios with hundreds of
entity types. To deal with them, we propose Parallel Instance Query Network
(PIQN), which sets up global and learnable instance queries to extract entities
from a sentence in a parallel manner. Each instance query predicts one entity,
and by feeding all instance queries simultaneously, we can query all entities
in parallel. Instead of being constructed from external knowledge, instance
queries can learn their different query semantics during training. For training
the model, we treat label assignment as a one-to-many Linear Assignment Problem
(LAP) and dynamically assign gold entities to instance queries with minimal
assignment cost. Experiments on both nested and flat NER datasets demonstrate
that our proposed method outperforms previous state-of-the-art models.",https://github.com/tricktreat/piqn,-1
8fb12a65-0f82-412a-9e19-8f1e60dcd825,BlenderBot 3: a deployed conversational agent that continually learns to responsibly engage,1.0,"We present BlenderBot 3, a 175B parameter dialogue model capable of
open-domain conversation with access to the internet and a long-term memory,
and having been trained on a large number of user defined tasks. We release
both the model weights and code, and have also deployed the model on a public
web page to interact with organic users. This technical report describes how
the model was built (architecture, model and training scheme), and details of
its deployment, including safety mechanisms. Human evaluations show its
superiority to existing open-domain dialogue agents, including its predecessors
(Roller et al., 2021; Komeili et al., 2022). Finally, we detail our plan for
continual learning using the data collected from deployment, which will also be
publicly released. The goal of this research program is thus to enable the
community to study ever-improving responsible agents that learn through
interaction.",https://www.parl.ai/projects/bb3,-1
661dbd9c-7ae4-431c-a58c-375dea35180c,Tele-Knowledge Pre-training for Fault Analysis,0.543068,"In this work, we share our experience on tele-knowledge pre-training for
fault analysis, a crucial task in telecommunication applications that requires
a wide range of knowledge normally found in both machine log data and product
documents. To organize this knowledge from experts uniformly, we propose to
create a Tele-KG (tele-knowledge graph). Using this valuable data, we further
propose a tele-domain language pre-training model TeleBERT and its
knowledge-enhanced version, a tele-knowledge re-training model KTeleBERT. which
includes effective prompt hints, adaptive numerical data encoding, and two
knowledge injection paradigms. Concretely, our proposal includes two stages:
first, pre-training TeleBERT on 20 million tele-related corpora, and then
re-training it on 1 million causal and machine-related corpora to obtain
KTeleBERT. Our evaluation on multiple tasks related to fault analysis in
tele-applications, including root-cause analysis, event association prediction,
and fault chain tracing, shows that pre-training a language model with
tele-domain data is beneficial for downstream tasks. Moreover, the KTeleBERT
re-training further improves the performance of task models, highlighting the
effectiveness of incorporating diverse tele-knowledge into the model.",None,-1
e2675e79-54a9-411d-819c-27a5835addd4,Generalization Differences between End-to-End and Neuro-Symbolic Vision-Language Reasoning Systems,0.0162693,"For vision-and-language reasoning tasks, both fully connectionist, end-to-end
methods and hybrid, neuro-symbolic methods have achieved high in-distribution
performance. In which out-of-distribution settings does each paradigm excel? We
investigate this question on both single-image and multi-image visual
question-answering through four types of generalization tests: a novel
segment-combine test for multi-image queries, contrast set, compositional
generalization, and cross-benchmark transfer. Vision-and-language end-to-end
trained systems exhibit sizeable performance drops across all these tests.
Neuro-symbolic methods suffer even more on cross-benchmark transfer from GQA to
VQA, but they show smaller accuracy drops on the other generalization tests and
their performance quickly improves by few-shot training. Overall, our results
demonstrate the complementary benefits of these two paradigms, and emphasize
the importance of using a diverse suite of generalization tests to fully
characterize model robustness to distribution shift.",https://github.com/Bill1235813/gendiff_vlsys,-1
aa30b509-5392-40ea-a360-fa93a7777ba6,Semantic-Preserving Adversarial Code Comprehension,0.0783221,"Based on the tremendous success of pre-trained language models (PrLMs) for
source code comprehension tasks, current literature studies either ways to
further improve the performance (generalization) of PrLMs, or their robustness
against adversarial attacks. However, they have to compromise on the trade-off
between the two aspects and none of them consider improving both sides in an
effective and practical way. To fill this gap, we propose Semantic-Preserving
Adversarial Code Embeddings (SPACE) to find the worst-case semantic-preserving
attacks while forcing the model to predict the correct labels under these worst
cases. Experiments and analysis demonstrate that SPACE can stay robust against
state-of-the-art attacks while boosting the performance of PrLMs for code.",https://github.com/EricLee8/SPACE,-1
e39381b1-ab57-421e-acc2-5ec255ef2d80,IT5: Large-scale Text-to-text Pretraining for Italian Language Understanding and Generation,0.47226,"The T5 model and its unified text-to-text paradigm contributed in advancing
the state-of-the-art for many natural language processing tasks. While some
multilingual variants of the T5 model have recently been introduced, their
performances were found to provide suboptimal performances for languages other
than English if compared to monolingual variants. We are motivated by these
findings to introduce IT5, the first family of encoder-decoder transformer
models pretrained specifically on Italian. We perform a thorough cleaning of a
web-crawled Italian corpus including more than 40 billion words and use it to
pretrain three IT5 models of different sizes. The performance of IT5 models and
their multilingual counterparts is then evaluated on a broad range of natural
language understanding and generation benchmarks for Italian. We find the
monolingual IT5 models to provide the best scale-to-performance ratio across
tested models, consistently outperforming their multilingual counterparts and
setting a new state-of-the-art for most Italian conditional language generation
tasks.",https://github.com/gsarti/it5,-1
a4fa9dfd-e590-47d2-8f8e-8da4ee5281e1,CommunityLM: Probing Partisan Worldviews from Language Models,0.321067,"As political attitudes have diverged ideologically in the United States,
political speech has diverged lingusitically. The ever-widening polarization
between the US political parties is accelerated by an erosion of mutual
understanding between them. We aim to make these communities more
comprehensible to each other with a framework that probes community-specific
responses to the same survey questions using community language models
CommunityLM. In our framework we identify committed partisan members for each
community on Twitter and fine-tune LMs on the tweets authored by them. We then
assess the worldviews of the two groups using prompt-based probing of their
corresponding LMs, with prompts that elicit opinions about public figures and
groups surveyed by the American National Election Studies (ANES) 2020
Exploratory Testing Survey. We compare the responses generated by the LMs to
the ANES survey results, and find a level of alignment that greatly exceeds
several baseline methods. Our work aims to show that we can use community LMs
to query the worldview of any group of people given a sufficiently large sample
of their social media discussions or media diet.",https://github.com/hjian42/CommunityLM,-1
6b7d334c-c9a9-4c6e-9682-4171a7756cf6,HyPe: Better Pre-trained Language Model Fine-tuning with Hidden Representation Perturbation,0.835253,"Language models with the Transformers structure have shown great performance
in natural language processing. However, there still poses problems when
fine-tuning pre-trained language models on downstream tasks, such as
over-fitting or representation collapse. In this work, we propose HyPe, a
simple yet effective fine-tuning technique to alleviate such problems by
perturbing hidden representations of Transformers layers. Unlike previous works
that only add noise to inputs or parameters, we argue that the hidden
representations of Transformers layers convey more diverse and meaningful
language information. Therefore, making the Transformers layers more robust to
hidden representation perturbations can further benefit the fine-tuning of PLMs
en bloc. We conduct extensive experiments and analyses on GLUE and other
natural language inference datasets. Results demonstrate that HyPe outperforms
vanilla fine-tuning and enhances generalization of hidden representations from
different layers. In addition, HyPe acquires negligible computational
overheads, and is better than and compatible with previous state-of-the-art
fine-tuning techniques.",https://github.com/Yuanhy1997/HyPe,-1
8e3f86f2-6abe-4a90-9fc1-fb6304f74b38,Imitating Past Successes can be Very Suboptimal,0.287571,"Prior work has proposed a simple strategy for reinforcement learning (RL):
label experience with the outcomes achieved in that experience, and then
imitate the relabeled experience. These outcome-conditioned imitation learning
methods are appealing because of their simplicity, strong performance, and
close ties with supervised learning. However, it remains unclear how these
methods relate to the standard RL objective, reward maximization. In this
paper, we formally relate outcome-conditioned imitation learning to reward
maximization, drawing a precise relationship between the learned policy and
Q-values and explaining the close connections between these methods and prior
EM-based policy search methods. This analysis shows that existing
outcome-conditioned imitation learning methods do not necessarily improve the
policy, but a simple modification results in a method that does guarantee
policy improvement, under some assumptions.",https://github.com/ben-eysenbach/normalized-ocbc/blob/main/experiments.ipynb,-1
38646deb-0418-4581-b461-54aef8592560,Smoothing Entailment Graphs with Language Models,0.728046,"The diversity and Zipfian frequency distribution of natural language
predicates in corpora leads to sparsity in Entailment Graphs (EGs) built by
Open Relation Extraction (ORE). EGs are computationally efficient and
explainable models of natural language inference, but as symbolic models, they
fail if a novel premise or hypothesis vertex is missing at test-time. We
present theory and methodology for overcoming such sparsity in symbolic models.
First, we introduce a theory of optimal smoothing of EGs by constructing
transitive chains. We then demonstrate an efficient, open-domain, and
unsupervised smoothing method using an off-the-shelf Language Model to find
approximations of missing premise predicates. This improves recall by 25.1 and
16.3 percentage points on two difficult directional entailment datasets, while
raising average precision and maintaining model explainability. Further, in a
QA task we show that EG smoothing is most useful for answering questions with
lesser supporting text, where missing premise predicates are more costly.
Finally, controlled experiments with WordNet confirm our theory and show that
hypothesis smoothing is difficult, but possible in principle.",https://github.com/nighttime/EntGraph,26355
7fb2628b-1b79-40a9-b533-ffa34efd80e2,DialogConv: A Lightweight Fully Convolutional Network for Multi-view Response Selection,0.335796,"Current end-to-end retrieval-based dialogue systems are mainly based on
Recurrent Neural Networks or Transformers with attention mechanisms. Although
promising results have been achieved, these models often suffer from slow
inference or huge number of parameters. In this paper, we propose a novel
lightweight fully convolutional architecture, called DialogConv, for response
selection. DialogConv is exclusively built on top of convolution to extract
matching features of context and response. Dialogues are modeled in 3D views,
where DialogConv performs convolution operations on embedding view, word view
and utterance view to capture richer semantic information from multiple
contextual views. On the four benchmark datasets, compared with
state-of-the-art baselines, DialogConv is on average about 8.5x smaller in
size, and 79.39x and 10.64x faster on CPU and GPU devices, respectively. At the
same time, DialogConv achieves the competitive effectiveness of response
selection.",https://github.com/misonsky/DialogConv,-1
178e5a3f-2405-4b97-ac1d-61bad5d1e68b,Multi-label topic classification for COVID-19 literature with Bioformer,0.297017,"We describe Bioformer team's participation in the multi-label topic
classification task for COVID-19 literature (track 5 of BioCreative VII). Topic
classification is performed using different BERT models (BioBERT, PubMedBERT,
and Bioformer). We formulate the topic classification task as a sentence pair
classification problem, where the title is the first sentence, and the abstract
is the second sentence. Our results show that Bioformer outperforms BioBERT and
PubMedBERT in this task. Compared to the baseline results, our best model
increased micro, macro, and instance-based F1 score by 8.8%, 15.5%, 7.4%,
respectively. Bioformer achieved the highest micro F1 and macro F1 scores in
this challenge. In post-challenge experiments, we found that pretraining of
Bioformer on COVID-19 articles further improves the performance.",None,-1
400daee5-d54e-4e11-bd40-bddd617a6789,Shadow-Background-Noise 3D Spatial Decomposition Using Sparse Low-Rank Gaussian Properties for Video-SAR Moving Target Shadow Enhancement,0.95926,"Moving target shadows among video synthetic aperture radar (Video-SAR) images
are always interfered by low scattering backgrounds and cluttered noises,
causing poor detec-tion-tracking accuracy. Thus, a shadow-background-noise 3D
spatial decomposition (SBN-3D-SD) model is proposed to enhance shadows for
higher detection-tracking accuracy. It leverages the sparse property of
shadows, the low-rank property of back-grounds, and the Gaussian property of
noises to perform 3D spatial three-decomposition. It separates shadows from
back-grounds and noises by the alternating direction method of multi-pliers
(ADMM). Results on the Sandia National Laboratories (SNL) data verify its
effectiveness. It boosts the shadow saliency from the qualitative and
quantitative evaluation. It boosts the shadow detection accuracy of Faster
R-CNN, RetinaNet and YOLOv3. It also boosts the shadow tracking accuracy of
TransTrack, FairMOT and ByteTrack.",None,-1
57238be8-bb4c-4f02-9b0d-a4b66abba651,Multi-model Ensemble Learning Method for Human Expression Recognition,0.208826,"Analysis of human affect plays a vital role in human-computer interaction
(HCI) systems. Due to the difficulty in capturing large amounts of real-life
data, most of the current methods have mainly focused on controlled
environments, which limit their application scenarios. To tackle this problem,
we propose our solution based on the ensemble learning method. Specifically, we
formulate the problem as a classification task, and then train several
expression classification models with different types of backbones--ResNet,
EfficientNet and InceptionNet. After that, the outputs of several models are
fused via model ensemble method to predict the final results. Moreover, we
introduce the multi-fold ensemble method to train and ensemble several models
with the same architecture but different data distributions to enhance the
performance of our solution. We conduct many experiments on the AffWild2
dataset of the ABAW2022 Challenge, and the results demonstrate the
effectiveness of our solution.",None,-1
1c843553-a694-426c-aca1-486c04b3536f,Arabic Word-level Readability Visualization for Assisted Text Simplification,0.457826,"This demo paper presents a Google Docs add-on for automatic Arabic word-level
readability visualization. The add-on includes a lemmatization component that
is connected to a five-level readability lexicon and Arabic WordNet-based
substitution suggestions. The add-on can be used for assessing the reading
difficulty of a text and identifying difficult words as part of the task of
manual text simplification. We make our add-on and its code publicly available.",None,16583
f3441009-afdb-4f7f-b350-e2d9fbd01e53,Multiple Object Tracking Challenge Technical Report for Team MT_IoT,0.262924,"This is a brief technical report of our proposed method for Multiple-Object
Tracking (MOT) Challenge in Complex Environments. In this paper, we treat the
MOT task as a two-stage task including human detection and trajectory matching.
Specifically, we designed an improved human detector and associated most of
detection to guarantee the integrity of the motion trajectory. We also propose
a location-wise matching matrix to obtain more accurate trace matching. Without
any model merging, our method achieves 66.672 HOTA and 93.971 MOTA on the
DanceTrack challenge dataset.",None,-1
9e00e7b0-b1c6-427a-bda1-e3f256014fb9,Efficient Semantic Segmentation on Edge Devices,0.137407,"Semantic segmentation works on the computer vision algorithm for assigning
each pixel of an image into a class. The task of semantic segmentation should
be performed with both accuracy and efficiency. Most of the existing deep FCNs
yield to heavy computations and these networks are very power hungry,
unsuitable for real-time applications on portable devices. This project
analyzes current semantic segmentation models to explore the feasibility of
applying these models for emergency response during catastrophic events. We
compare the performance of real-time semantic segmentation models with
non-real-time counterparts constrained by aerial images under oppositional
settings. Furthermore, we train several models on the Flood-Net dataset,
containing UAV images captured after Hurricane Harvey, and benchmark their
execution on special classes such as flooded buildings vs. non-flooded
buildings or flooded roads vs. non-flooded roads. In this project, we developed
a real-time UNet based model and deployed that network on Jetson AGX Xavier
module.",None,-1
9d05c8db-4b2a-41a1-a75a-5499efbd9379,Investigation of Ensemble features of Self-Supervised Pretrained Models for Automatic Speech Recognition,0.486811,"Self-supervised learning (SSL) based models have been shown to generate
powerful representations that can be used to improve the performance of
downstream speech tasks. Several state-of-the-art SSL models are available, and
each of these models optimizes a different loss which gives rise to the
possibility of their features being complementary. This paper proposes using an
ensemble of such SSL representations and models, which exploits the
complementary nature of the features extracted by the various pretrained
models. We hypothesize that this results in a richer feature representation and
shows results for the ASR downstream task. To this end, we use three SSL models
that have shown excellent results on ASR tasks, namely HuBERT, Wav2vec2.0, and
WaveLM. We explore the ensemble of models fine-tuned for the ASR task and the
ensemble of features using the embeddings obtained from the pre-trained models
for a downstream ASR task. We get improved performance over individual models
and pre-trained features using Librispeech(100h) and WSJ dataset for the
downstream tasks.",None,-1
645a2a60-8fb7-486d-a629-a6c39906ffac,Imitation Is Not Enough: Robustifying Imitation with Reinforcement Learning for Challenging Driving Scenarios,0.948692,"Imitation learning (IL) is a simple and powerful way to use high-quality
human driving data, which can be collected at scale, to produce human-like
behavior. However, policies based on imitation learning alone often fail to
sufficiently account for safety and reliability concerns. In this paper, we
show how imitation learning combined with reinforcement learning using simple
rewards can substantially improve the safety and reliability of driving
policies over those learned from imitation alone. In particular, we train a
policy on over 100k miles of urban driving data, and measure its effectiveness
in test scenarios grouped by different levels of collision likelihood. Our
analysis shows that while imitation can perform well in low-difficulty
scenarios that are well-covered by the demonstration data, our proposed
approach significantly improves robustness on the most challenging scenarios
(over 38% reduction in failures). To our knowledge, this is the first
application of a combined imitation and reinforcement learning approach in
autonomous driving that utilizes large amounts of real-world human driving
data.",None,-1
f5773c30-f0e7-4543-87f3-8506af84eec8,A Novel Underwater Image Enhancement and Improved Underwater Biological Detection Pipeline,0.323108,"For aquaculture resource evaluation and ecological environment monitoring,
automatic detection and identification of marine organisms is critical.
However, due to the low quality of underwater images and the characteristics of
underwater biological, a lack of abundant features may impede traditional
hand-designed feature extraction approaches or CNN-based object detection
algorithms, particularly in complex underwater environment. Therefore, the goal
of this paper is to perform object detection in the underwater environment.
This paper proposed a novel method for capturing feature information, which
adds the convolutional block attention module (CBAM) to the YOLOv5 backbone.
The interference of underwater creature characteristics on object
characteristics is decreased, and the output of the backbone network to object
information is enhanced. In addition, the self-adaptive global histogram
stretching algorithm (SAGHS) is designed to eliminate the degradation problems
such as low contrast and color loss caused by underwater environmental
information to better restore image quality. Extensive experiments and
comprehensive evaluation on the URPC2021 benchmark dataset demonstrate the
effectiveness and adaptivity of our methods. Beyond that, this paper conducts
an exhaustive analysis of the role of training data on performance.",None,-1
99c4916c-ad71-44a5-a9c3-6e6e37c46629,Neural Enhanced Belief Propagation for Data Association in Multiobject Tracking,0.571702,"Situation-aware technologies enabled by multiobject tracking (MOT) methods
will create new services and applications in fields such as autonomous
navigation and applied ocean sciences. Belief propagation (BP) is a
state-of-the-art method for Bayesian MOT but fully relies on a statistical
model and preprocessed sensor measurements. In this paper, we establish a
hybrid method for model-based and data-driven MOT. The proposed neural enhanced
belief propagation (NEBP) approach complements BP by information learned from
raw sensor data with the goal to improve data association and to reject false
alarm measurements. We evaluate the performance of our NEBP approach for MOT on
the nuScenes autonomous driving dataset and demonstrate that it can outperform
state-of-the-art reference methods.",None,-1
e449b281-dbf7-40f3-89d9-01d56cb9e567,RecipeSnap -- a lightweight image-to-recipe model,0.0310899,"In this paper we want to address the problem of automation for recognition of
photographed cooking dishes and generating the corresponding food recipes.
Current image-to-recipe models are computation expensive and require powerful
GPUs for model training and implementation. High computational cost prevents
those existing models from being deployed on portable devices, like smart
phones. To solve this issue we introduce a lightweight image-to-recipe
prediction model, RecipeSnap, that reduces memory cost and computational cost
by more than 90% while still achieving 2.0 MedR, which is in line with the
state-of-the-art model. A pre-trained recipe encoder was used to compute recipe
embeddings. Recipes from Recipe1M dataset and corresponding recipe embeddings
are collected as a recipe library, which are used for image encoder training
and image query later. We use MobileNet-V2 as image encoder backbone, which
makes our model suitable to portable devices. This model can be further
developed into an application for smart phones with a few effort. A comparison
of the performance between this lightweight model to other heavy models are
presented in this paper. Code, data and models are publicly accessible on
github.",https://github.com/jianfa/RecipeSnap-a-lightweight-image-to-recipe-model.git,-1
1c46fa75-7ed7-4134-9a07-2f9b0381af88,Toxicity Detection for Indic Multilingual Social Media Content,0.0808696,"Toxic content is one of the most critical issues for social media platforms
today. India alone had 518 million social media users in 2020. In order to
provide a good experience to content creators and their audience, it is crucial
to flag toxic comments and the users who post that. But the big challenge is
identifying toxicity in low resource Indic languages because of the presence of
multiple representations of the same text. Moreover, the posts/comments on
social media do not adhere to a particular format, grammar or sentence
structure; this makes the task of abuse detection even more challenging for
multilingual social media platforms. This paper describes the system proposed
by team 'Moj Masti' using the data provided by ShareChat/Moj in \emph{IIIT-D
Multilingual Abusive Comment Identification} challenge. We focus on how we can
leverage multilingual transformer based pre-trained and fine-tuned models to
approach code-mixed/code-switched classification tasks. Our best performing
system was an ensemble of XLM-RoBERTa and MuRIL which achieved a Mean F-1 score
of 0.9 on the test data/leaderboard. We also observed an increase in the
performance by adding transliterated data. Furthermore, using weak metadata,
ensembling and some post-processing techniques boosted the performance of our
system, thereby placing us 1st on the leaderboard.",https://github.com/isi-nlp/uroman,4373
4bc3aa4a-c7b6-43ce-ac2a-7a147a32d07a,CLUES: A Benchmark for Learning Classifiers using Natural Language Explanations,0.128986,"Supervised learning has traditionally focused on inductive learning by
observing labeled examples of a task. In contrast, humans have the ability to
learn new concepts from language. Here, we explore training zero-shot
classifiers for structured data purely from language. For this, we introduce
CLUES, a benchmark for Classifier Learning Using natural language ExplanationS,
consisting of a range of classification tasks over structured data along with
natural language supervision in the form of explanations. CLUES consists of 36
real-world and 144 synthetic classification tasks. It contains crowdsourced
explanations describing real-world tasks from multiple teachers and
programmatically generated explanations for the synthetic tasks. To model the
influence of explanations in classifying an example, we develop ExEnt, an
entailment-based model that learns classifiers using explanations. ExEnt
generalizes up to 18% better (relative) on novel tasks than a baseline that
does not use explanations. We delineate key challenges for automated learning
from explanations, addressing which can lead to progress on CLUES in the
future. Code and datasets are available at: https://clues-benchmark.github.io.",https://clues-benchmark.github.io,-1
74f9b1e2-a0d2-416f-b4fd-42cede3ab303,Extending Temporal Data Augmentation for Video Action Recognition,0.264164,"Pixel space augmentation has grown in popularity in many Deep Learning areas,
due to its effectiveness, simplicity, and low computational cost. Data
augmentation for videos, however, still remains an under-explored research
topic, as most works have been treating inputs as stacks of static images
rather than temporally linked series of data. Recently, it has been shown that
involving the time dimension when designing augmentations can be superior to
its spatial-only variants for video action recognition. In this paper, we
propose several novel enhancements to these techniques to strengthen the
relationship between the spatial and temporal domains and achieve a deeper
level of perturbations. The video action recognition results of our techniques
outperform their respective variants in Top-1 and Top-5 settings on the UCF-101
and the HMDB-51 datasets.",None,-1
23eff797-9495-4dea-aef0-74bcdbfc1a2c,PolQA: Polish Question Answering Dataset,0.172887,"Recently proposed systems for open-domain question answering (OpenQA) require
large amounts of training data to achieve state-of-the-art performance.
However, data annotation is known to be time-consuming and therefore expensive
to acquire. As a result, the appropriate datasets are available only for a
handful of languages (mainly English and Chinese). In this work, we introduce
and publicly release PolQA, the first Polish dataset for OpenQA. It consists of
7,000 questions, 87,525 manually labeled evidence passages, and a corpus of
over 7,097,322 candidate passages. Each question is classified according to its
formulation, type, as well as entity type of the answer. This resource allows
us to evaluate the impact of different annotation choices on the performance of
the QA system and propose an efficient annotation strategy that increases the
passage retrieval accuracy@10 by 10.55 p.p. while reducing the annotation cost
by 82%.",None,-1
7318d6cb-1209-4292-bf04-af963c2b9ee1,Annotating Norwegian Language Varieties on Twitter for Part-of-Speech,0.739761,"Norwegian Twitter data poses an interesting challenge for Natural Language
Processing (NLP) tasks. These texts are difficult for models trained on
standardized text in one of the two Norwegian written forms (Bokm{\aa}l and
Nynorsk), as they contain both the typical variation of social media text, as
well as a large amount of dialectal variety. In this paper we present a novel
Norwegian Twitter dataset annotated with POS-tags. We show that models trained
on Universal Dependency (UD) data perform worse when evaluated against this
dataset, and that models trained on Bokm{\aa}l generally perform better than
those trained on Nynorsk. We also see that performance on dialectal tweets is
comparable to the written standards for some models. Finally we perform a
detailed analysis of the errors that models commonly make on this data.",https://github.com/noklesta/,-1
2a0a738b-5c97-4b1f-ba25-74dd6aa3169e,Hand Avatar: Free-Pose Hand Animation and Rendering from Monocular Video,0.707822,"We present HandAvatar, a novel representation for hand animation and
rendering, which can generate smoothly compositional geometry and
self-occlusion-aware texture. Specifically, we first develop a MANO-HD model as
a high-resolution mesh topology to fit personalized hand shapes. Sequentially,
we decompose hand geometry into per-bone rigid parts, and then re-compose
paired geometry encodings to derive an across-part consistent occupancy field.
As for texture modeling, we propose a self-occlusion-aware shading field
(SelF). In SelF, drivable anchors are paved on the MANO-HD surface to record
albedo information under a wide variety of hand poses. Moreover, directed soft
occupancy is designed to describe the ray-to-surface relation, which is
leveraged to generate an illumination field for the disentanglement of
pose-independent albedo and pose-dependent illumination. Trained from monocular
video data, our HandAvatar can perform free-pose hand animation and rendering
while at the same time achieving superior appearance fidelity. We also
demonstrate that HandAvatar provides a route for hand appearance editing.
Project website: https://seanchenxy.github.io/HandAvatarWeb.",None,2845
c349f159-1e53-49c7-a8d4-3bfc5909e1a4,Label-enhanced Prototypical Network with Contrastive Learning for Multi-label Few-shot Aspect Category Detection,0.826386,"Multi-label aspect category detection allows a given review sentence to
contain multiple aspect categories, which is shown to be more practical in
sentiment analysis and attracting increasing attention. As annotating large
amounts of data is time-consuming and labor-intensive, data scarcity occurs
frequently in real-world scenarios, which motivates multi-label few-shot aspect
category detection. However, research on this problem is still in infancy and
few methods are available. In this paper, we propose a novel label-enhanced
prototypical network (LPN) for multi-label few-shot aspect category detection.
The highlights of LPN can be summarized as follows. First, it leverages label
description as auxiliary knowledge to learn more discriminative prototypes,
which can retain aspect-relevant information while eliminating the harmful
effect caused by irrelevant aspects. Second, it integrates with contrastive
learning, which encourages that the sentences with the same aspect label are
pulled together in embedding space while simultaneously pushing apart the
sentences with different aspect labels. In addition, it introduces an adaptive
multi-label inference module to predict the aspect count in the sentence, which
is simple yet effective. Extensive experimental results on three datasets
demonstrate that our proposed model LPN can consistently achieve
state-of-the-art performance.",None,-1
27345a4f-463e-4ac7-92c8-54ada880a9b4,MPANet: Multi-Patch Attention For Infrared Small Target object Detection,0.625713,"Infrared small target detection (ISTD) has attracted widespread attention and
been applied in various fields. Due to the small size of infrared targets and
the noise interference from complex backgrounds, the performance of ISTD using
convolutional neural networks (CNNs) is restricted. Moreover, the constriant
that long-distance dependent features can not be encoded by the vanilla CNNs
also impairs the robustness of capturing targets' shapes and locations in
complex scenarios. To this end, a multi-patch attention network (MPANet) based
on the axial-attention encoder and the multi-scale patch branch (MSPB)
structure is proposed. Specially, an axial-attention-improved encoder
architecture is designed to highlight the effective features of small targets
and suppress background noises. Furthermore, the developed MSPB structure fuses
the coarse-grained and fine-grained features from different semantic scales.
Extensive experiments on the SIRST dataset show the superiority performance and
effectiveness of the proposed MPANet compared to the state-of-the-art methods.",None,15602
4439d9a6-2958-47ef-8fc6-e1a1f9ae801f,Intelligent Exploration of Solution Spaces Exemplified by Industrial Reconfiguration Management,0.0523328,"Many decision-making approaches rely on the exploration of solution spaces
with regards to specified criteria. However, in complex environments,
brute-force exploration strategies are usually not feasible. As an alternative,
we propose the combination of an exploration task's vertical sub-division into
layers representing different sequentially interdependent sub-problems of the
paramount problem and a horizontal sub-division into self-sustained solution
sub-spaces. In this paper, we present a universal methodology for the
intelligent exploration of solution spaces and derive a use-case specific
example from the field of reconfiguration management in industry 4.0.",None,-1
5549a5ee-832f-49be-922d-985e0c3c507d,A Memory Transformer Network for Incremental Learning,0.679776,"We study class-incremental learning, a training setup in which new classes of
data are observed over time for the model to learn from. Despite the
straightforward problem formulation, the naive application of classification
models to class-incremental learning results in the ""catastrophic forgetting""
of previously seen classes. One of the most successful existing methods has
been the use of a memory of exemplars, which overcomes the issue of
catastrophic forgetting by saving a subset of past data into a memory bank and
utilizing it to prevent forgetting when training future tasks. In our paper, we
propose to enhance the utilization of this memory bank: we not only use it as a
source of additional training data like existing works but also integrate it in
the prediction process explicitly.Our method, the Memory Transformer Network
(MTN), learns how to combine and aggregate the information from the nearest
neighbors in the memory with a transformer to make more accurate predictions.
We conduct extensive experiments and ablations to evaluate our approach. We
show that MTN achieves state-of-the-art performance on the challenging
ImageNet-1k and Google-Landmarks-1k incremental learning benchmarks.",None,-1
9a74cccf-1e5d-4f6c-97a2-7b7438c333e9,Mask and Reason: Pre-Training Knowledge Graph Transformers for Complex Logical Queries,0.805202,"Knowledge graph (KG) embeddings have been a mainstream approach for reasoning
over incomplete KGs. However, limited by their inherently shallow and static
architectures, they can hardly deal with the rising focus on complex logical
queries, which comprise logical operators, imputed edges, multiple source
entities, and unknown intermediate entities. In this work, we present the
Knowledge Graph Transformer (kgTransformer) with masked pre-training and
fine-tuning strategies. We design a KG triple transformation method to enable
Transformer to handle KGs, which is further strengthened by the
Mixture-of-Experts (MoE) sparse activation. We then formulate the complex
logical queries as masked prediction and introduce a two-stage masked
pre-training strategy to improve transferability and generalizability.
Extensive experiments on two benchmarks demonstrate that kgTransformer can
consistently outperform both KG embedding-based baselines and advanced encoders
on nine in-domain and out-of-domain reasoning tasks. Additionally,
kgTransformer can reason with explainability via providing the full reasoning
paths to interpret given answers.",https://github.com/THUDM/kgTransformer,-1
da1a553d-a0bc-452a-bab0-2aeca2d111e5,Cross-TOP: Zero-Shot Cross-Schema Task-Oriented Parsing,0.121533,"Deep learning methods have enabled task-oriented semantic parsing of
increasingly complex utterances. However, a single model is still typically
trained and deployed for each task separately, requiring labeled training data
for each, which makes it challenging to support new tasks, even within a single
business vertical (e.g., food-ordering or travel booking). In this paper we
describe Cross-TOP (Cross-Schema Task-Oriented Parsing), a zero-shot method for
complex semantic parsing in a given vertical. By leveraging the fact that user
requests from the same vertical share lexical and semantic similarities, a
single cross-schema parser is trained to service an arbitrary number of tasks,
seen or unseen, within a vertical. We show that Cross-TOP can achieve high
accuracy on a previously unseen task without requiring any additional training
data, thereby providing a scalable way to bootstrap semantic parsers for new
tasks. As part of this work we release the FoodOrdering dataset, a
task-oriented parsing dataset in the food-ordering vertical, with utterances
and annotations derived from five schemas, each from a different restaurant
menu.",https://github.com/amazon-research/food-ordering-semantic-parsing-dataset,-1
961c2344-e38e-4f2e-a534-d382d172c0b5,Query-based Industrial Analytics over Knowledge Graphs with Ontology Reshaping,0.706386,"Industrial analytics that includes among others equipment diagnosis and
anomaly detection heavily relies on integration of heterogeneous production
data. Knowledge Graphs (KGs) as the data format and ontologies as the unified
data schemata are a prominent solution that offers high quality data
integration and a convenient and standardised way to exchange data and to layer
analytical applications over it. However, poor design of ontologies of high
degree of mismatch between them and industrial data naturally lead to KGs of
low quality that impede the adoption and scalability of industrial analytics.
Indeed, such KGs substantially increase the training time of writing queries
for users, consume high volume of storage for redundant information, and are
hard to maintain and update. To address this problem we propose an ontology
reshaping approach to transform ontologies into KG schemata that better reflect
the underlying data and thus help to construct better KGs. In this poster we
present a preliminary discussion of our on-going research, evaluate our
approach with a rich set of SPARQL queries on real-world industry data at Bosch
and discuss our findings.",None,-1
172b9813-f8b6-46d4-be28-8be9373548dc,Real-time Detection of 2D Tool Landmarks with Synthetic Training Data,0.329588,"In this paper a deep learning architecture is presented that can, in real
time, detect the 2D locations of certain landmarks of physical tools, such as a
hammer or screwdriver. To avoid the labor of manual labeling, the network is
trained on synthetically generated data. Training computer vision models on
computer generated images, while still achieving good accuracy on real images,
is a challenge due to the difference in domain. The proposed method uses an
advanced rendering method in combination with transfer learning and an
intermediate supervision architecture to address this problem. It is shown that
the model presented in this paper, named Intermediate Heatmap Model (IHM),
generalizes to real images when trained on synthetic data. To avoid the need
for an exact textured 3D model of the tool in question, it is shown that the
model will generalize to an unseen tool when trained on a set of different 3D
models of the same type of tool. IHM is compared to two existing approaches to
keypoint detection and it is shown that it outperforms those at detecting tool
landmarks, trained on synthetic data.",https://github.com/yuanyuanli85/Stacked Hourglass Network Keras,-1
9ee27393-3dd0-47c9-8d40-ecfaf922da80,Should We Rely on Entity Mentions for Relation Extraction? Debiasing Relation Extraction with Counterfactual Analysis,0.793283,"Recent literature focuses on utilizing the entity information in the
sentence-level relation extraction (RE), but this risks leaking superficial and
spurious clues of relations. As a result, RE still suffers from unintended
entity bias, i.e., the spurious correlation between entity mentions (names) and
relations. Entity bias can mislead the RE models to extract the relations that
do not exist in the text. To combat this issue, some previous work masks the
entity mentions to prevent the RE models from overfitting entity mentions.
However, this strategy degrades the RE performance because it loses the
semantic information of entities. In this paper, we propose the CORE
(Counterfactual Analysis based Relation Extraction) debiasing method that
guides the RE models to focus on the main effects of textual context without
losing the entity information. We first construct a causal graph for RE, which
models the dependencies between variables in RE models. Then, we propose to
conduct counterfactual analysis on our causal graph to distill and mitigate the
entity bias, that captures the causal effects of specific entity mentions in
each instance. Note that our CORE method is model-agnostic to debias existing
RE systems during inference without changing their training processes.
Extensive experimental results demonstrate that our CORE yields significant
gains on both effectiveness and generalization for RE. The source code is
provided at: https://github.com/vanoracai/CoRE.",https://github.com/vanoracai/CoRE,-1
8be5bb87-6ba8-4794-a4b7-05085fb1b4bb,CaSS: A Channel-aware Self-supervised Representation Learning Framework for Multivariate Time Series Classification,0.246933,"Self-supervised representation learning of Multivariate Time Series (MTS) is
a challenging task and attracts increasing research interests in recent years.
Many previous works focus on the pretext task of self-supervised learning and
usually neglect the complex problem of MTS encoding, leading to unpromising
results. In this paper, we tackle this challenge from two aspects: encoder and
pretext task, and propose a unified channel-aware self-supervised learning
framework CaSS. Specifically, we first design a new Transformer-based encoder
Channel-aware Transformer (CaT) to capture the complex relationships between
different time channels of MTS. Second, we combine two novel pretext tasks Next
Trend Prediction (NTP) and Contextual Similarity (CS) for the self-supervised
representation learning with our proposed encoder. Extensive experiments are
conducted on several commonly used benchmark datasets. The experimental results
show that our framework achieves new state-of-the-art comparing with previous
self-supervised MTS representation learning methods (up to +7.70\% improvement
on LSST dataset) and can be well applied to the downstream MTS classification.",None,-1
e3e51a7a-268f-47c4-968d-a185ee573b04,CUNI-KIT System for Simultaneous Speech Translation Task at IWSLT 2022,0.970615,"In this paper, we describe our submission to the Simultaneous Speech
Translation at IWSLT 2022. We explore strategies to utilize an offline model in
a simultaneous setting without the need to modify the original model. In our
experiments, we show that our onlinization algorithm is almost on par with the
offline setting while being $3\times$ faster than offline in terms of latency
on the test set. We also show that the onlinized offline model outperforms the
best IWSLT2021 simultaneous system in medium and high latency regimes and is
almost on par in the low latency regime. We make our system publicly available.",https://hub.docker.com/repository/docker/polape7/cuni-kit-simultaneous,-1
b6f6f700-777f-441e-9f0e-0db092a212a6,Watermark Vaccine: Adversarial Attacks to Prevent Watermark Removal,0.857967,"As a common security tool, visible watermarking has been widely applied to
protect copyrights of digital images. However, recent works have shown that
visible watermarks can be removed by DNNs without damaging their host images.
Such watermark-removal techniques pose a great threat to the ownership of
images. Inspired by the vulnerability of DNNs on adversarial perturbations, we
propose a novel defence mechanism by adversarial machine learning for good.
From the perspective of the adversary, blind watermark-removal networks can be
posed as our target models; then we actually optimize an imperceptible
adversarial perturbation on the host images to proactively attack against
watermark-removal networks, dubbed Watermark Vaccine. Specifically, two types
of vaccines are proposed. Disrupting Watermark Vaccine (DWV) induces to ruin
the host image along with watermark after passing through watermark-removal
networks. In contrast, Inerasable Watermark Vaccine (IWV) works in another
fashion of trying to keep the watermark not removed and still noticeable.
Extensive experiments demonstrate the effectiveness of our DWV/IWV in
preventing watermark removal, especially on various watermark removal networks.",https://github.com/thinwayliu/Watermark-Vaccine,-1
a7185e4d-9e48-4752-acd9-b19a75905e21,UniGDD: A Unified Generative Framework for Goal-Oriented Document-Grounded Dialogue,0.809392,"The goal-oriented document-grounded dialogue aims at responding to the user
query based on the dialogue context and supporting document. Existing studies
tackle this problem by decomposing it into two sub-tasks: knowledge
identification and response generation. However, such pipeline methods would
unavoidably suffer from the error propagation issue. This paper proposes to
unify these two sub-tasks via sequentially generating the grounding knowledge
and the response. We further develop a prompt-connected multi-task learning
strategy to model the characteristics and connections of different tasks and
introduce linear temperature scheduling to reduce the negative effect of
irrelevant document information. Experimental results demonstrate the
effectiveness of our framework.",https://github.com/doc2dial/sharedtask-dialdoc2021,-1
56338680-8997-4aee-ad56-746720bda879,Modeling Information Change in Science Communication with Semantically Matched Paraphrases,0.797138,"Whether the media faithfully communicate scientific information has long been
a core issue to the science community. Automatically identifying paraphrased
scientific findings could enable large-scale tracking and analysis of
information changes in the science communication process, but this requires
systems to understand the similarity between scientific information across
multiple domains. To this end, we present the SCIENTIFIC PARAPHRASE AND
INFORMATION CHANGE DATASET (SPICED), the first paraphrase dataset of scientific
findings annotated for degree of information change. SPICED contains 6,000
scientific finding pairs extracted from news stories, social media discussions,
and full texts of original papers. We demonstrate that SPICED poses a
challenging task and that models trained on SPICED improve downstream
performance on evidence retrieval for fact checking of real-world scientific
claims. Finally, we show that models trained on SPICED can reveal large-scale
trends in the degrees to which people and organizations faithfully communicate
new scientific findings. Data, code, and pre-trained models are available at
http://www.copenlu.com/publication/2022_emnlp_wright/.",http://www.copenlu.com/publication/2022_emnlp_wright/,-1
24eb2ffa-2aa0-4f87-bf65-df43f772f37d,Fine- and Coarse-Granularity Hybrid Self-Attention for Efficient BERT,0.0724676,"Transformer-based pre-trained models, such as BERT, have shown extraordinary
success in achieving state-of-the-art results in many natural language
processing applications. However, deploying these models can be prohibitively
costly, as the standard self-attention mechanism of the Transformer suffers
from quadratic computational cost in the input sequence length. To confront
this, we propose FCA, a fine- and coarse-granularity hybrid self-attention that
reduces the computation cost through progressively shortening the computational
sequence length in self-attention. Specifically, FCA conducts an
attention-based scoring strategy to determine the informativeness of tokens at
each layer. Then, the informative tokens serve as the fine-granularity
computing units in self-attention and the uninformative tokens are replaced
with one or several clusters as the coarse-granularity computing units in
self-attention. Experiments on GLUE and RACE datasets show that BERT with FCA
achieves 2x reduction in FLOPs over original BERT with <1% loss in accuracy. We
show that FCA offers a significantly better trade-off between accuracy and
FLOPs compared to prior methods.",https://github.com/pierre-zhao/FCA-BERT,-1
80ebb927-64cb-4b63-85ae-c99c93b40e1f,Meta Self-Refinement for Robust Learning with Weak Supervision,0.316988,"Training deep neural networks (DNNs) under weak supervision has attracted
increasing research attention as it can significantly reduce the annotation
cost. However, labels from weak supervision can be noisy, and the high capacity
of DNNs enables them to easily overfit the label noise, resulting in poor
generalization. Recent methods leverage self-training to build noise-resistant
models, in which a teacher trained under weak supervision is used to provide
highly confident labels for teaching the students. Nevertheless, the teacher
derived from such frameworks may have fitted a substantial amount of noise and
therefore produce incorrect pseudo-labels with high confidence, leading to
severe error propagation. In this work, we propose Meta Self-Refinement (MSR),
a noise-resistant learning framework, to effectively combat label noise from
weak supervision. Instead of relying on a fixed teacher trained with noisy
labels, we encourage the teacher to refine its pseudo-labels. At each training
step, MSR performs a meta gradient descent on the current mini-batch to
maximize the student performance on a clean validation set. Extensive
experimentation on eight NLP benchmarks demonstrates that MSR is robust against
label noise in all settings and outperforms state-of-the-art methods by up to
11.4% in accuracy and 9.26% in F1 score.",https://github.com/uds-lsv/msr,-1
ea810c60-6898-4863-88cb-40ea3e5bcc91,SAViR-T: Spatially Attentive Visual Reasoning with Transformers,0.123538,"We present a novel computational model, ""SAViR-T"", for the family of visual
reasoning problems embodied in the Raven's Progressive Matrices (RPM). Our
model considers explicit spatial semantics of visual elements within each image
in the puzzle, encoded as spatio-visual tokens, and learns the intra-image as
well as the inter-image token dependencies, highly relevant for the visual
reasoning task. Token-wise relationship, modeled through a transformer-based
SAViR-T architecture, extract group (row or column) driven representations by
leveraging the group-rule coherence and use this as the inductive bias to
extract the underlying rule representations in the top two row (or column) per
token in the RPM. We use this relation representations to locate the correct
choice image that completes the last row or column for the RPM. Extensive
experiments across both synthetic RPM benchmarks, including RAVEN, I-RAVEN,
RAVEN-FAIR, and PGM, and the natural image-based ""V-PROM"" demonstrate that
SAViR-T sets a new state-of-the-art for visual reasoning, exceeding prior
models' performance by a considerable margin.",None,-1
e5dba8d3-7253-4f81-a1ce-ae63fc4b7c97,MISm: A Medical Image Segmentation Metric for Evaluation of weak labeled Data,0.0868917,"Performance measures are an important tool for assessing and comparing
different medical image segmentation algorithms. Unfortunately, the current
measures have their weaknesses when it comes to assessing certain edge cases.
These limitations arouse when images with a very small region of interest or
without a region of interest at all are assessed. As a solution for these
limitations, we propose a new medical image segmentation metric: MISm. To
evaluate MISm, the popular metrics in the medical image segmentation and MISm
were compared using images of magnet resonance tomography from several
scenarios. In order to allow application in the community and reproducibility
of experimental results, we included MISm in the publicly available evaluation
framework MISeval:
https://github.com/frankkramer-lab/miseval/tree/master/miseval",https://github.com/frankkramer-lab/miseval,-1
84821d2d-0399-4cd5-884e-9c22a820b734,Weakly Supervised Video Anomaly Detection Based on Cross-Batch Clustering Guidance,0.36206,"Weakly supervised video anomaly detection (WSVAD) is a challenging task since
only video-level labels are available for training. In previous studies, the
discriminative power of the learned features is not strong enough, and the data
imbalance resulting from the mini-batch training strategy is ignored. To
address these two issues, we propose a novel WSVAD method based on cross-batch
clustering guidance. To enhance the discriminative power of features, we
propose a batch clustering based loss to encourage a clustering branch to
generate distinct normal and abnormal clusters based on a batch of data.
Meanwhile, we design a cross-batch learning strategy by introducing clustering
results from previous mini-batches to reduce the impact of data imbalance. In
addition, we propose to generate more accurate segment-level anomaly scores
based on batch clustering guidance further improving the performance of WSVAD.
Extensive experiments on two public datasets demonstrate the effectiveness of
our approach.",None,-1
2787078c-d618-45c6-9cb6-f92b311709db,Combining Humor and Sarcasm for Improving Political Parody Detection,0.469148,"Parody is a figurative device used for mimicking entities for comedic or
critical purposes. Parody is intentionally humorous and often involves sarcasm.
This paper explores jointly modelling these figurative tropes with the goal of
improving performance of political parody detection in tweets. To this end, we
present a multi-encoder model that combines three parallel encoders to enrich
parody-specific representations with humor and sarcasm information. Experiments
on a publicly available data set of political parody tweets demonstrate that
our approach outperforms previous state-of-the-art methods.",https://github.com/iamoscar1/Multi_Encoder_Model_for_Political_Parody_Prediction,-1
786c4fef-4ca7-470a-a650-5125acea57ea,Construction and Evaluation of a Self-Attention Model for Semantic Understanding of Sentence-Final Particles,0.0440456,"Sentence-final particles serve an essential role in spoken Japanese because
they express the speaker's mental attitudes toward a proposition and/or an
interlocutor. They are acquired at early ages and occur very frequently in
everyday conversation. However, there has been little proposal for a
computational model of acquiring sentence-final particles. This paper proposes
Subjective BERT, a self-attention model that takes various subjective senses in
addition to language and images as input and learns the relationship between
words and subjective senses. An evaluation experiment revealed that the model
understands the usage of ""yo"", which expresses the speaker's intention to
communicate new information, and that of ""ne"", which denotes the speaker's
desire to confirm that some information is shared.",None,-1
3d5dc918-b4e1-48bb-af7a-6c3bc84e09f7,N-Best Hypotheses Reranking for Text-To-SQL Systems,0.861995,"Text-to-SQL task maps natural language utterances to structured queries that
can be issued to a database. State-of-the-art (SOTA) systems rely on finetuning
large, pre-trained language models in conjunction with constrained decoding
applying a SQL parser. On the well established Spider dataset, we begin with
Oracle studies: specifically, choosing an Oracle hypothesis from a SOTA model's
10-best list, yields a $7.7\%$ absolute improvement in both exact match (EM)
and execution (EX) accuracy, showing significant potential improvements with
reranking. Identifying coherence and correctness as reranking approaches, we
design a model generating a query plan and propose a heuristic schema linking
algorithm. Combining both approaches, with T5-Large, we obtain a consistent
$1\% $ improvement in EM accuracy, and a $~2.5\%$ improvement in EX,
establishing a new SOTA for this task. Our comprehensive error studies on DEV
data show the underlying difficulty in making progress on this task.",https://github.com/microsoft/DeepSpeed,-1
4c1e58a5-ecc8-4ab0-b323-7cf41a20c230,Not always about you: Prioritizing community needs when developing endangered language technology,0.757213,"Languages are classified as low-resource when they lack the quantity of data
necessary for training statistical and machine learning tools and models.
Causes of resource scarcity vary but can include poor access to technology for
developing these resources, a relatively small population of speakers, or a
lack of urgency for collecting such resources in bilingual populations where
the second language is high-resource. As a result, the languages described as
low-resource in the literature are as different as Finnish on the one hand,
with millions of speakers using it in every imaginable domain, and Seneca, with
only a small-handful of fluent speakers using the language primarily in a
restricted domain. While issues stemming from the lack of resources necessary
to train models unite this disparate group of languages, many other issues cut
across the divide between widely-spoken low resource languages and endangered
languages. In this position paper, we discuss the unique technological,
cultural, practical, and ethical challenges that researchers and indigenous
speech community members face when working together to develop language
technology to support endangered language documentation and revitalization. We
report the perspectives of language teachers, Master Speakers and elders from
indigenous communities, as well as the point of view of academics. We describe
an ongoing fruitful collaboration and make recommendations for future
partnerships between academic researchers and language community stakeholders.",None,-1
ceb1e6f9-3120-46c1-9b22-6fb53c5804de,Using Ontologies for the Formalization and Recognition of Criticality for Automated Driving,0.792145,"Knowledge representation and reasoning has a long history of examining how
knowledge can be formalized, interpreted, and semantically analyzed by
machines. In the area of automated vehicles, recent advances suggest the
ability to formalize and leverage relevant knowledge as a key enabler in
handling the inherently open and complex context of the traffic world. This
paper demonstrates ontologies to be a powerful tool for a) modeling and
formalization of and b) reasoning about factors associated with criticality in
the environment of automated vehicles. For this, we leverage the well-known
6-Layer Model to create a formal representation of the environmental context.
Within this representation, an ontology models domain knowledge as logical
axioms, enabling deduction on the presence of critical factors within traffic
scenes and scenarios. For executing automated analyses, a joint description
logic and rule reasoner is used in combination with an a-priori predicate
augmentation. We elaborate on the modular approach, present a publicly
available implementation, and evaluate the method by means of a large-scale
drone data set of urban traffic scenarios.",None,-1
32f310f2-06a8-41a6-8c4c-bbf5c83bd4f3,Cross-Spectral Neural Radiance Fields,0.689794,"We propose X-NeRF, a novel method to learn a Cross-Spectral scene
representation given images captured from cameras with different light spectrum
sensitivity, based on the Neural Radiance Fields formulation. X-NeRF optimizes
camera poses across spectra during training and exploits Normalized
Cross-Device Coordinates (NXDC) to render images of different modalities from
arbitrary viewpoints, which are aligned and at the same resolution. Experiments
on 16 forward-facing scenes, featuring color, multi-spectral and infrared
images, confirm the effectiveness of X-NeRF at modeling Cross-Spectral scene
representations.",None,12441
0c3b756c-26ca-469a-a409-e28ae238b0cd,Estimating Confidence of Predictions of Individual Classifiers and Their Ensembles for the Genre Classification Task,0.0392013,"Genre identification is a subclass of non-topical text classification. The
main difference between this task and topical classification is that genres,
unlike topics, usually do not correspond to simple keywords, and thus they need
to be defined in terms of their functions in communication. Neural models based
on pre-trained transformers, such as BERT or XLM-RoBERTa, demonstrate SOTA
results in many NLP tasks, including non-topical classification. However, in
many cases, their downstream application to very large corpora, such as those
extracted from social media, can lead to unreliable results because of dataset
shifts, when some raw texts do not match the profile of the training set. To
mitigate this problem, we experiment with individual models as well as with
their ensembles. To evaluate the robustness of all models we use a prediction
confidence metric, which estimates the reliability of a prediction in the
absence of a gold standard label. We can evaluate robustness via the confidence
gap between the correctly classified texts and the misclassified ones on a
labeled test corpus, higher gaps make it easier to improve our confidence that
our classifier made the right decision. Our results show that for all of the
classifiers tested in this study, there is a confidence gap, but for the
ensembles, the gap is bigger, meaning that ensembles are more robust than their
individual models.",https://github.com/MikeLepekhin/GenreClassifierEnsembles,-1
f1c4dcbe-021e-4167-9a0e-846ef9619cd5,Text-Only Training for Image Captioning using Noise-Injected CLIP,0.59811,"We consider the task of image-captioning using only the CLIP model and
additional text data at training time, and no additional captioned images. Our
approach relies on the fact that CLIP is trained to make visual and textual
embeddings similar. Therefore, we only need to learn how to translate CLIP
textual embeddings back into text, and we can learn how to do this by learning
a decoder for the frozen CLIP text encoder using only text. We argue that this
intuition is ""almost correct"" because of a gap between the embedding spaces,
and propose to rectify this via noise injection during training. We demonstrate
the effectiveness of our approach by showing SOTA zero-shot image captioning
across four benchmarks, including style transfer. Code, data, and models are
available on GitHub.",https://github.com/DavidHuji/CapDec,-1
630f2ea8-65f0-4a7a-aad2-a27cac294a80,Parameter-Efficient Abstractive Question Answering over Tables or Text,0.329895,"A long-term ambition of information seeking QA systems is to reason over
multi-modal contexts and generate natural answers to user queries. Today,
memory intensive pre-trained language models are adapted to downstream tasks
such as QA by fine-tuning the model on QA data in a specific modality like
unstructured text or structured tables. To avoid training such memory-hungry
models while utilizing a uniform architecture for each modality,
parameter-efficient adapters add and train small task-specific bottle-neck
layers between transformer layers. In this work, we study parameter-efficient
abstractive QA in encoder-decoder models over structured tabular data and
unstructured textual data using only 1.5% additional parameters for each
modality. We also ablate over adapter layers in both encoder and decoder
modules to study the efficiency-performance trade-off and demonstrate that
reducing additional trainable parameters down to 0.7%-1.0% leads to comparable
results. Our models out-perform current state-of-the-art models on tabular QA
datasets such as Tablesum and FeTaQA, and achieve comparable performance on a
textual QA dataset such as NarrativeQA using significantly less trainable
parameters than fine-tuning.",https://github.com/kolk/Pea-QA,-1
8ba3cf92-280f-4650-b0b4-72c02261fc58,On Label Granularity and Object Localization,0.395277,"Weakly supervised object localization (WSOL) aims to learn representations
that encode object location using only image-level category labels. However,
many objects can be labeled at different levels of granularity. Is it an
animal, a bird, or a great horned owl? Which image-level labels should we use?
In this paper we study the role of label granularity in WSOL. To facilitate
this investigation we introduce iNatLoc500, a new large-scale fine-grained
benchmark dataset for WSOL. Surprisingly, we find that choosing the right
training label granularity provides a much larger performance boost than
choosing the best WSOL algorithm. We also show that changing the label
granularity can significantly improve data efficiency.",https://github.com/tensorflow/models/blob/65407126c5adc216d606d360429fe12ed3c3f187/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config,-1
67e16ee7-2a91-4e72-a293-b5c76c666559,Medical Dialogue Response Generation with Pivotal Information Recalling,0.447659,"Medical dialogue generation is an important yet challenging task. Most
previous works rely on the attention mechanism and large-scale pretrained
language models. However, these methods often fail to acquire pivotal
information from the long dialogue history to yield an accurate and informative
response, due to the fact that the medical entities usually scatters throughout
multiple utterances along with the complex relationships between them. To
mitigate this problem, we propose a medical response generation model with
Pivotal Information Recalling (MedPIR), which is built on two components, i.e.,
knowledge-aware dialogue graph encoder and recall-enhanced generator. The
knowledge-aware dialogue graph encoder constructs a dialogue graph by
exploiting the knowledge relationships between entities in the utterances, and
encodes it with a graph attention network. Then, the recall-enhanced generator
strengthens the usage of these pivotal information by generating a summary of
the dialogue before producing the actual response. Experimental results on two
large-scale medical dialogue datasets show that MedPIR outperforms the strong
baselines in BLEU scores and medical entities F1 measure.",https://github.com/lwgkzl/MedDG,-1
b6c276ac-f669-4b34-82be-eb577508773b,Beyond the Return: Off-policy Function Estimation under User-specified Error-measuring Distributions,0.749518,"Off-policy evaluation often refers to two related tasks: estimating the
expected return of a policy and estimating its value function (or other
functions of interest, such as density ratios). While recent works on
marginalized importance sampling (MIS) show that the former can enjoy provable
guarantees under realizable function approximation, the latter is only known to
be feasible under much stronger assumptions such as prohibitively expressive
discriminators. In this work, we provide guarantees for off-policy function
estimation under only realizability, by imposing proper regularization on the
MIS objectives. Compared to commonly used regularization in MIS, our
regularizer is much more flexible and can account for an arbitrary
user-specified distribution, under which the learned function will be close to
the groundtruth. We provide exact characterization of the optimal dual solution
that needs to be realized by the discriminator class, which determines the
data-coverage assumption in the case of value-function learning. As another
surprising observation, the regularizer can be altered to relax the
data-coverage requirement, and completely eliminate it in the ideal case with
strong side information.",None,-1
98540505-41d9-4122-b976-6e2c623aa238,Is Surprisal in Issue Trackers Actionable?,0.157774,"Background. From information theory, surprisal is a measurement of how
unexpected an event is. Statistical language models provide a probabilistic
approximation of natural languages, and because surprisal is constructed with
the probability of an event occuring, it is therefore possible to determine the
surprisal associated with English sentences. The issues and pull requests of
software repository issue trackers give insight into the development process
and likely contain the surprising events of this process.
  Objective. Prior works have identified that unusual events in software
repositories are of interest to developers, and use simple code metrics-based
methods for detecting them. In this study we will propose a new method for
unusual event detection in software repositories using surprisal. With the
ability to find surprising issues and pull requests, we intend to further
analyse them to determine if they actually hold importance in a repository, or
if they pose a significant challenge to address. If it is possible to find bad
surprises early, or before they cause additional troubles, it is plausible that
effort, cost and time will be saved as a result.
  Method. After extracting the issues and pull requests from 5000 of the most
popular software repositories on GitHub, we will train a language model to
represent these issues. We will measure their perceived importance in the
repository, measure their resolution difficulty using several analogues,
measure the surprisal of each, and finally generate inferential statistics to
describe any correlations.",None,-1
6fe57c31-14e2-4009-8b4b-a59b65436bc3,Are Face Detection Models Biased?,0.181839,"The presence of bias in deep models leads to unfair outcomes for certain
demographic subgroups. Research in bias focuses primarily on facial recognition
and attribute prediction with scarce emphasis on face detection. Existing
studies consider face detection as binary classification into 'face' and
'non-face' classes. In this work, we investigate possible bias in the domain of
face detection through facial region localization which is currently
unexplored. Since facial region localization is an essential task for all face
recognition pipelines, it is imperative to analyze the presence of such bias in
popular deep models. Most existing face detection datasets lack suitable
annotation for such analysis. Therefore, we web-curate the Fair Face
Localization with Attributes (F2LA) dataset and manually annotate more than 10
attributes per face, including facial localization information. Utilizing the
extensive annotations from F2LA, an experimental setup is designed to study the
performance of four pre-trained face detectors. We observe (i) a high disparity
in detection accuracies across gender and skin-tone, and (ii) interplay of
confounding factors beyond demography. The F2LA data and associated annotations
can be accessed at http://iab-rubric.org/index.php/F2LA.",None,-1
f768b7e2-cb5f-4f0d-96b6-b91c100a66fe,Deep Structural Causal Shape Models,0.308789,"Causal reasoning provides a language to ask important interventional and
counterfactual questions beyond purely statistical association. In medical
imaging, for example, we may want to study the causal effect of genetic,
environmental, or lifestyle factors on the normal and pathological variation of
anatomical phenotypes. However, while anatomical shape models of 3D surface
meshes, extracted from automated image segmentation, can be reliably
constructed, there is a lack of computational tooling to enable causal
reasoning about morphological variations. To tackle this problem, we propose
deep structural causal shape models (CSMs), which utilise high-quality mesh
generation techniques, from geometric deep learning, within the expressive
framework of deep structural causal models. CSMs enable subject-specific
prognoses through counterfactual mesh generation (""How would this patient's
brain structure change if they were ten years older?""), which is in contrast to
most current works on purely population-level statistical shape modelling. We
demonstrate the capabilities of CSMs at all levels of Pearl's causal hierarchy
through a number of qualitative and quantitative experiments leveraging a large
dataset of 3D brain structures.",None,-1
29de8a5b-b176-41af-8e42-c1a46ed9e96f,Word-Level Fine-Grained Story Visualization,0.681272,"Story visualization aims to generate a sequence of images to narrate each
sentence in a multi-sentence story with a global consistency across dynamic
scenes and characters. Current works still struggle with output images' quality
and consistency, and rely on additional semantic information or auxiliary
captioning networks. To address these challenges, we first introduce a new
sentence representation, which incorporates word information from all story
sentences to mitigate the inconsistency problem. Then, we propose a new
discriminator with fusion features and further extend the spatial attention to
improve image quality and story consistency. Extensive experiments on different
datasets and human evaluation demonstrate the superior performance of our
approach, compared to state-of-the-art methods, neither using segmentation
masks nor auxiliary captioning networks.",https://github.com/mrlibw/Word-Level-Story-Visualization,-1
fbc07ad2-050e-4b45-a236-3684151258ae,Non-Contrastive Learning Meets Language-Image Pre-Training,0.288636,"Contrastive language-image pre-training (CLIP) serves as a de-facto standard
to align images and texts. Nonetheless, the loose correlation between images
and texts of web-crawled data renders the contrastive objective data
inefficient and craving for a large training batch size. In this work, we
explore the validity of non-contrastive language-image pre-training (nCLIP),
and study whether nice properties exhibited in visual self-supervised models
can emerge. We empirically observe that the non-contrastive objective nourishes
representation learning while sufficiently underperforming under zero-shot
recognition. Based on the above study, we further introduce xCLIP, a
multi-tasking framework combining CLIP and nCLIP, and show that nCLIP aids CLIP
in enhancing feature semantics. The synergy between two objectives lets xCLIP
enjoy the best of both worlds: superior performance in both zero-shot transfer
and representation learning. Systematic evaluation is conducted spanning a wide
variety of downstream tasks including zero-shot classification, out-of-domain
classification, retrieval, visual representation learning, and textual
representation learning, showcasing a consistent performance gain and
validating the effectiveness of xCLIP.",None,-1
bf7c4496-303b-48be-a5f9-9c94e7ce54c1,Latent Image Animator: Learning to Animate Images via Latent Space Navigation,0.95365,"Due to the remarkable progress of deep generative models, animating images
has become increasingly efficient, whereas associated results have become
increasingly realistic. Current animation-approaches commonly exploit structure
representation extracted from driving videos. Such structure representation is
instrumental in transferring motion from driving videos to still images.
However, such approaches fail in case the source image and driving video
encompass large appearance variation. Moreover, the extraction of structure
information requires additional modules that endow the animation-model with
increased complexity. Deviating from such models, we here introduce the Latent
Image Animator (LIA), a self-supervised autoencoder that evades need for
structure representation. LIA is streamlined to animate images by linear
navigation in the latent space. Specifically, motion in generated video is
constructed by linear displacement of codes in the latent space. Towards this,
we learn a set of orthogonal motion directions simultaneously, and use their
linear combination, in order to represent any displacement in the latent space.
Extensive quantitative and qualitative analysis suggests that our model
systematically and significantly outperforms state-of-art methods on VoxCeleb,
Taichi and TED-talk datasets w.r.t. generated quality.",https://wyhsirius.github.io/LIA-project/,-1
6cb09006-fea7-4399-b48b-5d690617467a,"""What makes a question inquisitive?"" A Study on Type-Controlled Inquisitive Question Generation",0.46581,"We propose a type-controlled framework for inquisitive question generation.
We annotate an inquisitive question dataset with question types, train question
type classifiers, and finetune models for type-controlled question generation.
Empirical results demonstrate that we can generate a variety of questions that
adhere to specific types while drawing from the source texts. We also
investigate strategies for selecting a single question from a generated set,
considering both an informative vs.~inquisitive question classifier and a
pairwise ranker trained from a small set of expert annotations. Question
selection using the pairwise ranker yields strong results in automatic and
manual evaluation. Our human evaluation assesses multiple aspects of the
generated questions, finding that the ranker chooses questions with the best
syntax (4.59), semantics (4.37), and inquisitiveness (3.92) on a scale of 1-5,
even rivaling the performance of human-written questions.",https://github.com/EducationalTestingService/inquisitive-questions,-1
e538b5d1-44b4-49c1-9e02-721ba6ee4a8c,Testing predictive automated driving systems: lessons learned and future recommendations,0.638137,"Conventional vehicles are certified through classical approaches, where
different physical certification tests are set up on test tracks to assess
required safety levels. These approaches are well suited for vehicles with
limited complexity and limited interactions with other entities as last-second
resources. However, these approaches do not allow to evaluate safety with real
behaviors for critical and edge cases, nor to evaluate the ability to
anticipate them in the mid or long term. This is particularly relevant for
automated and autonomous driving functions that make use of advanced predictive
systems to anticipate future actions and motions to be considered in the path
planning layer. In this paper, we present and analyze the results of physical
tests on proving grounds of several predictive systems in automated driving
functions developed within the framework of the BRAVE project. Based on our
experience in testing predictive automated driving functions, we identify the
main limitations of current physical testing approaches when dealing with
predictive systems, analyze the main challenges ahead, and provide a set of
practical actions and recommendations to consider in future physical testing
procedures for automated and autonomous driving functions.",None,-1
3c307ff7-e00e-4dd4-b51c-d234ae566be8,Bi-PointFlowNet: Bidirectional Learning for Point Cloud Based Scene Flow Estimation,0.960023,"Scene flow estimation, which extracts point-wise motion between scenes, is
becoming a crucial task in many computer vision tasks. However, all of the
existing estimation methods utilize only the unidirectional features,
restricting the accuracy and generality. This paper presents a novel scene flow
estimation architecture using bidirectional flow embedding layers. The proposed
bidirectional layer learns features along both forward and backward directions,
enhancing the estimation performance. In addition, hierarchical feature
extraction and warping improve the performance and reduce computational
overhead. Experimental results show that the proposed architecture achieved a
new state-of-the-art record by outperforming other approaches with large margin
in both FlyingThings3D and KITTI benchmarks. Codes are available at
https://github.com/cwc1260/BiFlow.",https://github.com/cwc1260/BiFlow,1348
16b70efc-3d52-4eb2-b5c4-1327c5f4490c,Multiple Instance Neuroimage Transformer,0.757316,"For the first time, we propose using a multiple instance learning based
convolution-free transformer model, called Multiple Instance Neuroimage
Transformer (MINiT), for the classification of T1weighted (T1w) MRIs. We first
present several variants of transformer models adopted for neuroimages. These
models extract non-overlapping 3D blocks from the input volume and perform
multi-headed self-attention on a sequence of their linear projections. MINiT,
on the other hand, treats each of the non-overlapping 3D blocks of the input
MRI as its own instance, splitting it further into non-overlapping 3D patches,
on which multi-headed self-attention is computed. As a proof-of-concept, we
evaluate the efficacy of our model by training it to identify sex from T1w-MRIs
of two public datasets: Adolescent Brain Cognitive Development (ABCD) and the
National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA).
The learned attention maps highlight voxels contributing to identifying sex
differences in brain morphometry. The code is available at
https://github.com/singlaayush/MINIT.",None,14913
8be6398c-edee-4258-a3e6-f4748a6c8233,Building an Endangered Language Resource in the Classroom: Universal Dependencies for Kakataibo,0.354351,"In this paper, we launch a new Universal Dependencies treebank for an
endangered language from Amazonia: Kakataibo, a Panoan language spoken in Peru.
We first discuss the collaborative methodology implemented, which proved
effective to create a treebank in the context of a Computational Linguistic
course for undergraduates. Then, we describe the general details of the
treebank and the language-specific considerations implemented for the proposed
annotation. We finally conduct some experiments on part-of-speech tagging and
syntactic dependency parsing. We focus on monolingual and transfer learning
settings, where we study the impact of a Shipibo-Konibo treebank, another
Panoan language resource.",https://github.com/yzhangcs/parser,-1
5d357cac-9e79-4c35-a425-cc4308fab3b4,Deep Apprenticeship Learning for Playing Games,0.0216841,"In the last decade, deep learning has achieved great success in machine
learning tasks where the input data is represented with different levels of
abstractions. Driven by the recent research in reinforcement learning using
deep neural networks, we explore the feasibility of designing a learning model
based on expert behaviour for complex, multidimensional tasks where reward
function is not available. We propose a novel method for apprenticeship
learning based on the previous research on supervised learning techniques in
reinforcement learning. Our method is applied to video frames from Atari games
in order to teach an artificial agent to play those games. Even though the
reported results are not comparable with the state-of-the-art results in
reinforcement learning, we demonstrate that such an approach has the potential
to achieve strong performance in the future and is worthwhile for further
research.",None,-1
11af33cb-251e-49aa-8db2-48d57bb6557f,Fault-Aware Design and Training to Enhance DNNs Reliability with Zero-Overhead,0.655846,"Deep Neural Networks (DNNs) enable a wide series of technological
advancements, ranging from clinical imaging, to predictive industrial
maintenance and autonomous driving. However, recent findings indicate that
transient hardware faults may corrupt the models prediction dramatically. For
instance, the radiation-induced misprediction probability can be so high to
impede a safe deployment of DNNs models at scale, urging the need for efficient
and effective hardening solutions. In this work, we propose to tackle the
reliability issue both at training and model design time. First, we show that
vanilla models are highly affected by transient faults, that can induce a
performances drop up to 37%. Hence, we provide three zero-overhead solutions,
based on DNN re-design and re-train, that can improve DNNs reliability to
transient faults up to one order of magnitude. We complement our work with
extensive ablation studies to quantify the gain in performances of each
hardening component.",None,-1
cd2e7069-91b4-45ba-9c48-9f1adcbd945a,CONCRETE: Improving Cross-lingual Fact-checking with Cross-lingual Retrieval,0.91663,"Fact-checking has gained increasing attention due to the widespread of
falsified information. Most fact-checking approaches focus on claims made in
English only due to the data scarcity issue in other languages. The lack of
fact-checking datasets in low-resource languages calls for an effective
cross-lingual transfer technique for fact-checking. Additionally, trustworthy
information in different languages can be complementary and helpful in
verifying facts. To this end, we present the first fact-checking framework
augmented with cross-lingual retrieval that aggregates evidence retrieved from
multiple languages through a cross-lingual retriever. Given the absence of
cross-lingual information retrieval datasets with claim-like queries, we train
the retriever with our proposed Cross-lingual Inverse Cloze Task (X-ICT), a
self-supervised algorithm that creates training instances by translating the
title of a passage. The goal for X-ICT is to learn cross-lingual retrieval in
which the model learns to identify the passage corresponding to a given
translated title. On the X-Fact dataset, our approach achieves 2.23% absolute
F1 improvement in the zero-shot cross-lingual setup over prior systems. The
source code and data are publicly available at
https://github.com/khuangaf/CONCRETE.",https://github.com/khuangaf/CONCRETE,-1
90fb7522-bde1-48fe-af89-8d345604ad40,Graph Neural Networks: a bibliometrics overview,0.31101,"Recently, graph neural networks have become a hot topic in machine learning
community. This paper presents a Scopus based bibliometric overview of the GNNs
research since 2004, when GNN papers were first published. The study aims to
evaluate GNN research trend, both quantitatively and qualitatively. We provide
the trend of research, distribution of subjects, active and influential authors
and institutions, sources of publications, most cited documents, and hot
topics. Our investigations reveal that the most frequent subject categories in
this field are computer science, engineering, telecommunications, linguistics,
operations research and management science, information science and library
science, business and economics, automation and control systems, robotics, and
social sciences. In addition, the most active source of GNN publications is
Lecture Notes in Computer Science. The most prolific or impactful institutions
are found in the United States, China, and Canada. We also provide must read
papers and future directions. Finally, the application of graph convolutional
networks and attention mechanism are now among hot topics of GNN research.",None,-1
3c24eff8-4b91-47a7-ac69-e6489f3f68b4,Multielement polynomial chaos Kriging-based metamodelling for Bayesian inference of non-smooth systems,0.695532,"This paper presents a surrogate modelling technique based on domain
partitioning for Bayesian parameter inference of highly nonlinear engineering
models. In order to alleviate the computational burden typically involved in
Bayesian inference applications, a multielement Polynomial Chaos Expansion
based Kriging metamodel is proposed. The developed surrogate model combines in
a piecewise function an array of local Polynomial Chaos based Kriging
metamodels constructed on a finite set of non-overlapping subdomains of the
stochastic input space. Therewith, the presence of non-smoothness in the
response of the forward model (e.g.~ nonlinearities and sparseness) can be
reproduced by the proposed metamodel with minimum computational costs owing to
its local adaptation capabilities. The model parameter inference is conducted
through a Markov chain Monte Carlo approach comprising adaptive exploration and
delayed rejection. The efficiency and accuracy of the proposed approach are
validated through two case studies, including an analytical benchmark and a
numerical case study. The latter relates the partial differential equation
governing the hydrogen diffusion phenomenon of metallic materials in Thermal
Desorption Spectroscopy tests.",None,-1
7edcc794-affb-46f4-b050-74399c4623f6,FinBERT-MRC: financial named entity recognition using BERT under the machine reading comprehension paradigm,0.872557,"Financial named entity recognition (FinNER) from literature is a challenging
task in the field of financial text information extraction, which aims to
extract a large amount of financial knowledge from unstructured texts. It is
widely accepted to use sequence tagging frameworks to implement FinNER tasks.
However, such sequence tagging models cannot fully take advantage of the
semantic information in the texts. Instead, we formulate the FinNER task as a
machine reading comprehension (MRC) problem and propose a new model termed
FinBERT-MRC. This formulation introduces significant prior information by
utilizing well-designed queries, and extracts start index and end index of
target entities without decoding modules such as conditional random fields
(CRF). We conduct experiments on a publicly available Chinese financial dataset
ChFinAnn and a real-word bussiness dataset AdminPunish. FinBERT-MRC model
achieves average F1 scores of 92.78% and 96.80% on the two datasets,
respectively, with average F1 gains +3.94% and +0.89% over some sequence
tagging models including BiLSTM-CRF, BERT-Tagger, and BERT-CRF. The source code
is available at https://github.com/zyz0000/FinBERT-MRC.",https://github.com/zyz0000/FinBERT-MRC,-1
aaf0df49-fcf7-44da-b6dc-ce7f09f60d2c,"SeasoNet: A Seasonal Scene Classification, segmentation and Retrieval dataset for satellite Imagery over Germany",0.417159,"This work presents SeasoNet, a new large-scale multi-label land cover and
land use scene understanding dataset. It includes $1\,759\,830$ images from
Sentinel-2 tiles, with 12 spectral bands and patch sizes of up to $ 120 \
\mathrm{px} \times 120 \ \mathrm{px}$. Each image is annotated with large scale
pixel level labels from the German land cover model LBM-DE2018 with land cover
classes based on the CORINE Land Cover database (CLC) 2018 and a five times
smaller minimum mapping unit (MMU) than the original CLC maps. We provide pixel
synchronous examples from all four seasons, plus an additional snowy set. These
properties make SeasoNet the currently most versatile and biggest remote
sensing scene understanding dataset with possible applications ranging from
scene classification over land cover mapping to content-based cross season
image retrieval and self-supervised feature learning. We provide baseline
results by evaluating state-of-the-art deep networks on the new dataset in
scene classification and semantic segmentation scenarios.",None,-1
e81d14ed-0a6b-4c12-ac84-80fb1d417bfd,GMF: General Multimodal Fusion Framework for Correspondence Outlier Rejection,0.817084,"Rejecting correspondence outliers enables to boost the correspondence
quality, which is a critical step in achieving high point cloud registration
accuracy. The current state-of-the-art correspondence outlier rejection methods
only utilize the structure features of the correspondences. However, texture
information is critical to reject the correspondence outliers in our human
vision system. In this paper, we propose General Multimodal Fusion (GMF) to
learn to reject the correspondence outliers by leveraging both the structure
and texture information. Specifically, two cross-attention-based fusion layers
are proposed to fuse the texture information from paired images and structure
information from point correspondences. Moreover, we propose a convolutional
position encoding layer to enhance the difference between Tokens and enable the
encoding feature pay attention to neighbor information. Our position encoding
layer will make the cross-attention operation integrate both local and global
information. Experiments on multiple datasets(3DMatch, 3DLoMatch, KITTI) and
recent state-of-the-art models (3DRegNet, DGR, PointDSC) prove that our GMF
achieves wide generalization ability and consistently improves the point cloud
registration accuracy. Furthermore, several ablation studies demonstrate the
robustness of the proposed GMF on different loss functions, lighting conditions
and noises.The code is available at https://github.com/XiaoshuiHuang/GMF.",https://github.com/XiaoshuiHuang/GMF,-1
2107581f-8b1b-4b85-9cd0-c379173c3e18,e-CARE: a New Dataset for Exploring Explainable Causal Reasoning,0.55242,"Understanding causality has vital importance for various Natural Language
Processing (NLP) applications. Beyond the labeled instances, conceptual
explanations of the causality can provide deep understanding of the causal
facts to facilitate the causal reasoning process. However, such explanation
information still remains absent in existing causal reasoning resources. In
this paper, we fill this gap by presenting a human-annotated explainable CAusal
REasoning dataset (e-CARE), which contains over 21K causal reasoning questions,
together with natural language formed explanations of the causal questions.
Experimental results show that generating valid explanations for causal facts
still remains especially challenging for the state-of-the-art models, and the
explanation information can be helpful for promoting the accuracy and stability
of causal reasoning models.",https://github.com/Waste-Wood/e-CARE/,21012
42a67388-d8f7-4fbf-b41f-40a37ffee297,RASAT: Integrating Relational Structures into Pretrained Seq2Seq Model for Text-to-SQL,0.998734,"Relational structures such as schema linking and schema encoding have been
validated as a key component to qualitatively translating natural language into
SQL queries. However, introducing these structural relations comes with prices:
they often result in a specialized model structure, which largely prohibits
using large pretrained models in text-to-SQL. To address this problem, we
propose RASAT: a Transformer seq2seq architecture augmented with relation-aware
self-attention that could leverage a variety of relational structures while
inheriting the pretrained parameters from the T5 model effectively. Our model
can incorporate almost all types of existing relations in the literature, and
in addition, we propose introducing co-reference relations for the multi-turn
scenario. Experimental results on three widely used text-to-SQL datasets,
covering both single-turn and multi-turn scenarios, have shown that RASAT could
achieve state-of-the-art results across all three benchmarks (75.5% EX on
Spider, 52.6% IEX on SParC, and 37.4% IEX on CoSQL).",https://github.com/LUMIA-group/rasat,-1
51cfd124-a8ec-4cda-89f5-1aa8b8554cbf,Autonomous Mobile Clinics: Empowering Affordable Anywhere Anytime Healthcare Access,0.412965,"We are facing a global healthcare crisis today as the healthcare cost is ever
climbing, but with the aging population, government fiscal revenue is ever
dropping. To create a more efficient and effective healthcare system, three
technical challenges immediately present themselves: healthcare access,
healthcare equity, and healthcare efficiency. An autonomous mobile clinic
solves the healthcare access problem by bringing healthcare services to the
patient by the order of the patient's fingertips. Nevertheless, to enable a
universal autonomous mobile clinic network, a three-stage technical roadmap
needs to be achieved: In stage one, we focus on solving the inequity challenge
in the existing healthcare system by combining autonomous mobility and
telemedicine. In stage two, we develop an AI doctor for primary care, which we
foster from infancy to adulthood with clean healthcare data. With the AI
doctor, we can solve the inefficiency problem. In stage three, after we have
proven that the autonomous mobile clinic network can truly solve the target
clinical use cases, we shall open up the platform for all medical verticals,
thus enabling universal healthcare through this whole new system.",None,-1
a0d3f16c-d6df-4ec4-8822-31a1fdbbd663,Compressing Sentence Representation for Semantic Retrieval via Homomorphic Projective Distillation,0.0693017,"How to learn highly compact yet effective sentence representation?
Pre-trained language models have been effective in many NLP tasks. However,
these models are often huge and produce large sentence embeddings. Moreover,
there is a big performance gap between large and small models. In this paper,
we propose Homomorphic Projective Distillation (HPD) to learn compressed
sentence embeddings. Our method augments a small Transformer encoder model with
learnable projection layers to produce compact representations while mimicking
a large pre-trained language model to retain the sentence representation
quality. We evaluate our method with different model sizes on both semantic
textual similarity (STS) and semantic retrieval (SR) tasks. Experiments show
that our method achieves 2.7-4.5 points performance gain on STS tasks compared
with previous best representations of the same size. In SR tasks, our method
improves retrieval speed (8.2$\times$) and memory usage (8.0$\times$) compared
with state-of-the-art large models.",https://github.com/XuandongZhao/HPD,-1
f1b8c8a9-5e21-413c-b0a3-46ddafb48121,"Towards Trustworthy AutoGrading of Short, Multi-lingual, Multi-type Answers",0.997875,"Autograding short textual answers has become much more feasible due to the
rise of NLP and the increased availability of question-answer pairs brought
about by a shift to online education. Autograding performance is still inferior
to human grading. The statistical and black-box nature of state-of-the-art
machine learning models makes them untrustworthy, raising ethical concerns and
limiting their practical utility. Furthermore, the evaluation of autograding is
typically confined to small, monolingual datasets for a specific question type.
This study uses a large dataset consisting of about 10 million question-answer
pairs from multiple languages covering diverse fields such as math and
language, and strong variation in question and answer syntax. We demonstrate
the effectiveness of fine-tuning transformer models for autograding for such
complex datasets. Our best hyperparameter-tuned model yields an accuracy of
about 86.5\%, comparable to the state-of-the-art models that are less general
and more tuned to a specific type of question, subject, and language. More
importantly, we address trust and ethical concerns. By involving humans in the
autograding process, we show how to improve the accuracy of automatically
graded answers, achieving accuracy equivalent to that of teaching assistants.
We also show how teachers can effectively control the type of errors made by
the system and how they can validate efficiently that the autograder's
performance on individual exams is close to the expected performance.",None,-1
5f3c319c-f24a-4d17-a042-b9c9ab83a14b,Zero-Shot Voice Conditioning for Denoising Diffusion TTS Models,0.87582,"We present a novel way of conditioning a pretrained denoising diffusion
speech model to produce speech in the voice of a novel person unseen during
training. The method requires a short (~3 seconds) sample from the target
person, and generation is steered at inference time, without any training
steps. At the heart of the method lies a sampling process that combines the
estimation of the denoising model with a low-pass version of the new speaker's
sample. The objective and subjective evaluations show that our sampling method
can generate a voice similar to that of the target speaker in terms of
frequency, with an accuracy comparable to state-of-the-art methods, and without
training.",None,-1
754d8cdf-6c30-45af-85cc-594a5d5d55fb,Back to the Future: On Potential Histories in NLP,0.113327,"Machine learning and NLP require the construction of datasets to train and
fine-tune models. In this context, previous work has demonstrated the
sensitivity of these data sets. For instance, potential societal biases in this
data are likely to be encoded and to be amplified in the models we deploy. In
this work, we draw from developments in the field of history and take a novel
perspective on these problems: considering datasets and models through the lens
of historical fiction surfaces their political nature, and affords
re-configuring how we view the past, such that marginalized discourses are
surfaced. Building on such insights, we argue that contemporary methods for
machine learning are prejudiced towards dominant and hegemonic histories.
Employing the example of neopronouns, we show that by surfacing marginalized
histories within contemporary conditions, we can create models that better
represent the lived realities of traditionally marginalized and excluded
communities.",None,-1
4ccd492a-579b-495c-b6f2-8441cae1830f,PhoCaL: A Multi-Modal Dataset for Category-Level Object Pose Estimation with Photometrically Challenging Objects,0.84623,"Object pose estimation is crucial for robotic applications and augmented
reality. Beyond instance level 6D object pose estimation methods, estimating
category-level pose and shape has become a promising trend. As such, a new
research field needs to be supported by well-designed datasets. To provide a
benchmark with high-quality ground truth annotations to the community, we
introduce a multimodal dataset for category-level object pose estimation with
photometrically challenging objects termed PhoCaL. PhoCaL comprises 60 high
quality 3D models of household objects over 8 categories including highly
reflective, transparent and symmetric objects. We developed a novel
robot-supported multi-modal (RGB, depth, polarisation) data acquisition and
annotation process. It ensures sub-millimeter accuracy of the pose for opaque
textured, shiny and transparent objects, no motion blur and perfect camera
synchronisation. To set a benchmark for our dataset, state-of-the-art RGB-D and
monocular RGB methods are evaluated on the challenging scenes of PhoCaL.",None,-1
a82efd8e-c210-44f8-9335-908829c51b4c,Federated Learning: Balancing the Thin Line Between Data Intelligence and Privacy,0.0987622,"Federated learning holds great promise in learning from fragmented sensitive
data and has revolutionized how machine learning models are trained. This
article provides a systematic overview and detailed taxonomy of federated
learning. We investigate the existing security challenges in federated learning
and provide a comprehensive overview of established defense techniques for data
poisoning, inference attacks, and model poisoning attacks. The work also
presents an overview of current training challenges for federated learning,
focusing on handling non-i.i.d. data, high dimensionality issues, and
heterogeneous architecture, and discusses several solutions for the associated
challenges. Finally, we discuss the remaining challenges in managing federated
learning training and suggest focused research directions to address the open
questions. Potential candidate areas for federated learning, including IoT
ecosystem, healthcare applications, are discussed with a particular focus on
banking and financial domains.",None,-1
07e13998-be46-4e6d-84ed-59b8622bffe5,DetMatch: Two Teachers are Better Than One for Joint 2D and 3D Semi-Supervised Object Detection,0.499327,"While numerous 3D detection works leverage the complementary relationship
between RGB images and point clouds, developments in the broader framework of
semi-supervised object recognition remain uninfluenced by multi-modal fusion.
Current methods develop independent pipelines for 2D and 3D semi-supervised
learning despite the availability of paired image and point cloud frames.
Observing that the distinct characteristics of each sensor cause them to be
biased towards detecting different objects, we propose DetMatch, a flexible
framework for joint semi-supervised learning on 2D and 3D modalities. By
identifying objects detected in both sensors, our pipeline generates a cleaner,
more robust set of pseudo-labels that both demonstrates stronger performance
and stymies single-modality error propagation. Further, we leverage the richer
semantics of RGB images to rectify incorrect 3D class predictions and improve
localization of 3D boxes. Evaluating on the challenging KITTI and Waymo
datasets, we improve upon strong semi-supervised learning methods and observe
higher quality pseudo-labels. Code will be released at
https://github.com/Divadi/DetMatch",None,-1
9234a7da-ce14-4c2f-bd05-5a1d842f8d35,Learning Invariant Representation and Risk Minimized for Unsupervised Accent Domain Adaptation,0.0931086,"Unsupervised representation learning for speech audios attained impressive
performances for speech recognition tasks, particularly when annotated speech
is limited. However, the unsupervised paradigm needs to be carefully designed
and little is known about what properties these representations acquire. There
is no guarantee that the model learns meaningful representations for valuable
information for recognition. Moreover, the adaptation ability of the learned
representations to other domains still needs to be estimated. In this work, we
explore learning domain-invariant representations via a direct mapping of
speech representations to their corresponding high-level linguistic
informations. Results prove that the learned latents not only capture the
articulatory feature of each phoneme but also enhance the adaptation ability,
outperforming the baseline largely on accented benchmarks.",None,-1
059b5ea9-f60e-46f8-8847-2a10925a85a4,BBA-net: A bi-branch attention network for crowd counting,0.21453,"In the field of crowd counting, the current mainstream CNN-based regression
methods simply extract the density information of pedestrians without finding
the position of each person. This makes the output of the network often found
to contain incorrect responses, which may erroneously estimate the total number
and not conducive to the interpretation of the algorithm. To this end, we
propose a Bi-Branch Attention Network (BBA-NET) for crowd counting, which has
three innovation points. i) A two-branch architecture is used to estimate the
density information and location information separately. ii) Attention
mechanism is used to facilitate feature extraction, which can reduce false
responses. iii) A new density map generation method combining geometric
adaptation and Voronoi split is introduced. Our method can integrate the
pedestrian's head and body information to enhance the feature expression
ability of the density map. Extensive experiments performed on two public
datasets show that our method achieves a lower crowd counting error compared to
other state-of-the-art methods.",None,5878
ef002ab3-db60-4218-9d9c-c35a4b5de99e,Uncertainty estimation for Cross-dataset performance in Trajectory prediction,0.633854,"While a lot of work has been carried on developing trajectory prediction
methods, and various datasets have been proposed for benchmarking this task,
little study has been done so far on the generalizability and the
transferability of these methods across dataset. In this paper, we observe the
performance of two of the latest state-of-the-art trajectory prediction methods
across four different datasets (Argoverse, NuScenes, Interaction, Shifts). This
analysis allows to gain some insights on the generalizability proprieties of
most recent trajectory prediction models and to analyze which dataset is more
representative of real driving scenes and therefore enables better
transferability. Furthermore we present a novel method to estimate prediction
uncertainty and show how it could be used to achieve better performance across
datasets.",None,-1
22fa9f4d-d4ba-4a90-b5ab-a5c554577bcf,Revisiting Generative Commonsense Reasoning: A Pre-Ordering Approach,0.0711312,"Pre-trained models (PTMs) have lead to great improvements in natural language
generation (NLG). However, it is still unclear how much commonsense knowledge
they possess. With the goal of evaluating commonsense knowledge of NLG models,
recent work has proposed the problem of generative commonsense reasoning, e.g.,
to compose a logical sentence given a set of unordered concepts. Existing
approaches to this problem hypothesize that PTMs lack sufficient parametric
knowledge for this task, which can be overcome by introducing external
knowledge or task-specific pre-training objectives. Different from this trend,
we argue that PTM's inherent ability for generative commonsense reasoning is
underestimated due to the order-agnostic property of its input. In particular,
we hypothesize that the order of the input concepts can affect the PTM's
ability to utilize its commonsense knowledge. To this end, we propose a
pre-ordering approach to elaborately manipulate the order of the given concepts
before generation. Experiments show that our approach can outperform the more
sophisticated models that have access to a lot of external data and resources.",https://github.com/zhaochaocs/Planned-PTM,1956
093dccfa-083e-4a9b-b155-d43e2ad339b5,Hierarchical Phrase-based Sequence-to-Sequence Learning,0.675982,"We describe a neural transducer that maintains the flexibility of standard
sequence-to-sequence (seq2seq) models while incorporating hierarchical phrases
as a source of inductive bias during training and as explicit constraints
during inference. Our approach trains two models: a discriminative parser based
on a bracketing transduction grammar whose derivation tree hierarchically
aligns source and target phrases, and a neural seq2seq model that learns to
translate the aligned phrases one-by-one. We use the same seq2seq model to
translate at all phrase scales, which results in two inference modes: one mode
in which the parser is discarded and only the seq2seq component is used at the
sequence-level, and another in which the parser is combined with the seq2seq
model. Decoding in the latter mode is done with the cube-pruned CKY algorithm,
which is more involved but can make use of new translation rules during
inference. We formalize our model as a source-conditioned synchronous grammar
and develop an efficient variational inference algorithm for training. When
applied on top of both randomly initialized and pretrained seq2seq models, we
find that both inference modes performs well compared to baselines on small
scale machine translation benchmarks.",https://github.com/berlino/btg-seq2seq,29122
1d2779c1-6768-478e-8c0b-4b6d0448cc99,Breaking the Spurious Causality of Conditional Generation via Fairness Intervention with Corrective Sampling,0.27894,"To capture the relationship between samples and labels, conditional
generative models often inherit spurious correlations from the training
dataset. This can result in label-conditional distributions that are imbalanced
with respect to another latent attribute. To mitigate this issue, which we call
spurious causality of conditional generation, we propose a general two-step
strategy. (a) Fairness Intervention (FI): emphasize the minority samples that
are hard to generate due to the spurious correlation in the training dataset.
(b) Corrective Sampling (CS): explicitly filter the generated samples and
ensure that they follow the desired latent attribute distribution. We have
designed the fairness intervention to work for various degrees of supervision
on the spurious attribute, including unsupervised, weakly-supervised, and
semi-supervised scenarios. Our experimental results demonstrate that FICS can
effectively resolve spurious causality of conditional generation across various
datasets.",https://github.com/POSTECH-CVLab/PyTorch-StudioGAN,11542
49edd048-7af2-4b82-a80d-c40230de6c52,DeciWatch: A Simple Baseline for 10x Efficient 2D and 3D Pose Estimation,0.802446,"This paper proposes a simple baseline framework for video-based 2D/3D human
pose estimation that can achieve 10 times efficiency improvement over existing
works without any performance degradation, named DeciWatch. Unlike current
solutions that estimate each frame in a video, DeciWatch introduces a simple
yet effective sample-denoise-recover framework that only watches sparsely
sampled frames, taking advantage of the continuity of human motions and the
lightweight pose representation. Specifically, DeciWatch uniformly samples less
than 10% video frames for detailed estimation, denoises the estimated 2D/3D
poses with an efficient Transformer architecture, and then accurately recovers
the rest of the frames using another Transformer-based network. Comprehensive
experimental results on three video-based human pose estimation and body mesh
recovery tasks with four datasets validate the efficiency and effectiveness of
DeciWatch. Code is available at https://github.com/cure-lab/DeciWatch.",https://github.com/cure-lab/DeciWatch,-1
192dcb18-1f2f-43bd-b6f8-01ec214e0ebe,Retrieval Based Time Series Forecasting,0.245293,"Time series data appears in a variety of applications such as smart
transportation and environmental monitoring. One of the fundamental problems
for time series analysis is time series forecasting. Despite the success of
recent deep time series forecasting methods, they require sufficient
observation of historical values to make accurate forecasting. In other words,
the ratio of the output length (or forecasting horizon) to the sum of the input
and output lengths should be low enough (e.g., 0.3). As the ratio increases
(e.g., to 0.8), the uncertainty for the forecasting accuracy increases
significantly. In this paper, we show both theoretically and empirically that
the uncertainty could be effectively reduced by retrieving relevant time series
as references. In the theoretical analysis, we first quantify the uncertainty
and show its connections to the Mean Squared Error (MSE). Then we prove that
models with references are easier to learn than models without references since
the retrieved references could reduce the uncertainty. To empirically
demonstrate the effectiveness of the retrieval based time series forecasting
models, we introduce a simple yet effective two-stage method, called ReTime
consisting of a relational retrieval and a content synthesis. We also show that
ReTime can be easily adapted to the spatial-temporal time series and time
series imputation settings. Finally, we evaluate ReTime on real-world datasets
to demonstrate its effectiveness.",None,80967
2100eff6-1065-4750-b0fd-bd621381162f,Adversarial Masking for Self-Supervised Learning,0.717541,"We propose ADIOS, a masked image model (MIM) framework for self-supervised
learning, which simultaneously learns a masking function and an image encoder
using an adversarial objective. The image encoder is trained to minimise the
distance between representations of the original and that of a masked image.
The masking function, conversely, aims at maximising this distance. ADIOS
consistently improves on state-of-the-art self-supervised learning (SSL)
methods on a variety of tasks and datasets -- including classification on
ImageNet100 and STL10, transfer learning on CIFAR10/100, Flowers102 and
iNaturalist, as well as robustness evaluated on the backgrounds challenge (Xiao
et al., 2021) -- while generating semantically meaningful masks. Unlike modern
MIM models such as MAE, BEiT and iBOT, ADIOS does not rely on the image-patch
tokenisation construction of Vision Transformers, and can be implemented with
convolutional backbones. We further demonstrate that the masks learned by ADIOS
are more effective in improving representation learning of SSL methods than
masking schemes used in popular MIM models. Code is available at
https://github.com/YugeTen/adios.",None,-1
bef1366a-3bc9-4e06-974b-3df7335aea3e,Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe,0.45696,"Privacy concerns have attracted increasing attention in data-driven products
due to the tendency of machine learning models to memorize sensitive training
data. Generating synthetic versions of such data with a formal privacy
guarantee, such as differential privacy (DP), provides a promising path to
mitigating these privacy concerns, but previous approaches in this direction
have typically failed to produce synthetic data of high quality. In this work,
we show that a simple and practical recipe in the text domain is effective:
simply fine-tuning a pretrained generative language model with DP enables the
model to generate useful synthetic text with strong privacy protection. Through
extensive empirical analyses on both benchmark and private customer data, we
demonstrate that our method produces synthetic text that is competitive in
terms of utility with its non-private counterpart, meanwhile providing strong
protection against potential privacy leakages.",https://github.com/microsoft/dp-transformers,-1
2275320a-9ad3-473d-9ea7-7c9377fabc08,Monte Carlo Tree Search Algorithms for Risk-Aware and Multi-Objective Reinforcement Learning,0.533053,"In many risk-aware and multi-objective reinforcement learning settings, the
utility of the user is derived from a single execution of a policy. In these
settings, making decisions based on the average future returns is not suitable.
For example, in a medical setting a patient may only have one opportunity to
treat their illness. Making decisions using just the expected future returns --
known in reinforcement learning as the value -- cannot account for the
potential range of adverse or positive outcomes a decision may have. Therefore,
we should use the distribution over expected future returns differently to
represent the critical information that the agent requires at decision time by
taking both the future and accrued returns into consideration. In this paper,
we propose two novel Monte Carlo tree search algorithms. Firstly, we present a
Monte Carlo tree search algorithm that can compute policies for nonlinear
utility functions (NLU-MCTS) by optimising the utility of the different
possible returns attainable from individual policy executions, resulting in
good policies for both risk-aware and multi-objective settings. Secondly, we
propose a distributional Monte Carlo tree search algorithm (DMCTS) which
extends NLU-MCTS. DMCTS computes an approximate posterior distribution over the
utility of the returns, and utilises Thompson sampling during planning to
compute policies in risk-aware and multi-objective settings. Both algorithms
outperform the state-of-the-art in multi-objective reinforcement learning for
the expected utility of the returns.",None,-1
4bd3a7b6-abff-44d6-856c-eb982ebf95a5,"Artificial Intelligence for Cybersecurity: Threats, Attacks and Mitigation",0.835668,"With the advent of the digital era, every day-to-day task is automated due to
technological advances. However, technology has yet to provide people with
enough tools and safeguards. As the internet connects more-and-more devices
around the globe, the question of securing the connected devices grows at an
even spiral rate. Data thefts, identity thefts, fraudulent transactions,
password compromises, and system breaches are becoming regular everyday news.
The surging menace of cyber-attacks got a jolt from the recent advancements in
Artificial Intelligence. AI is being applied in almost every field of different
sciences and engineering. The intervention of AI not only automates a
particular task but also improves efficiency by many folds. So it is evident
that such a scrumptious spread would be very appetizing to cybercriminals. Thus
the conventional cyber threats and attacks are now ``intelligent"" threats. This
article discusses cybersecurity and cyber threats along with both conventional
and intelligent ways of defense against cyber-attacks. Furthermore finally, end
the discussion with the potential prospects of the future of AI in
cybersecurity.",None,-1
0d1164af-4052-4c30-ba31-01bdabb053b7,Learning to Detect Mobile Objects from LiDAR Scans Without Labels,0.40574,"Current 3D object detectors for autonomous driving are almost entirely
trained on human-annotated data. Although of high quality, the generation of
such data is laborious and costly, restricting them to a few specific locations
and object types. This paper proposes an alternative approach entirely based on
unlabeled data, which can be collected cheaply and in abundance almost
everywhere on earth. Our approach leverages several simple common sense
heuristics to create an initial set of approximate seed labels. For example,
relevant traffic participants are generally not persistent across multiple
traversals of the same route, do not fly, and are never under ground. We
demonstrate that these seed labels are highly effective to bootstrap a
surprisingly accurate detector through repeated self-training without a single
human annotated label.",https://github.com/YurongYou/MODEST,46951
aaad281b-e05e-4790-9f51-fc8607596d90,QuantArt: Quantizing Image Style Transfer Towards High Visual Fidelity,0.512302,"The mechanism of existing style transfer algorithms is by minimizing a hybrid
loss function to push the generated image toward high similarities in both
content and style. However, this type of approach cannot guarantee visual
fidelity, i.e., the generated artworks should be indistinguishable from real
ones. In this paper, we devise a new style transfer framework called QuantArt
for high visual-fidelity stylization. QuantArt pushes the latent representation
of the generated artwork toward the centroids of the real artwork distribution
with vector quantization. By fusing the quantized and continuous latent
representations, QuantArt allows flexible control over the generated artworks
in terms of content preservation, style similarity, and visual fidelity.
Experiments on various style transfer settings show that our QuantArt framework
achieves significantly higher visual fidelity compared with the existing style
transfer methods.",https://github.com/siyuhuang/QuantArt,-1
f7bca222-f685-4efb-b843-e136e5308aa4,Multi-Agent Terraforming: Efficient Multi-Agent Path Finding via Environment Manipulation,0.0863705,"Multi-agent pathfinding (MAPF) is concerned with planning collision-free
paths for a team of agents from their start to goal locations in an environment
cluttered with obstacles. Typical approaches for MAPF consider the locations of
obstacles as being fixed, which limits their effectiveness in automated
warehouses, where obstacles (representing pods or shelves) can be moved out of
the way by agents (representing robots) to relieve bottlenecks and introduce
shorter routes. In this work we initiate the study of MAPF with movable
obstacles. In particular, we introduce a new extension of MAPF, which we call
Terraforming MAPF (tMAPF), where some agents are responsible for moving
obstacles to clear the way for other agents. Solving tMAPF is extremely
challenging as it requires reasoning not only about collisions between agents,
but also where and when obstacles should be moved. We present extensions of two
state-of-the-art algorithms, CBS and PBS, in order to tackle tMAPF, and
demonstrate that they can consistently outperform the best solution possible
under a static-obstacle setting.",None,-1
57ff2b0c-e8db-42bb-a6d2-2aeb7db8f94c,Open Vocabulary Semantic Segmentation with Patch Aligned Contrastive Learning,0.858513,"We introduce Patch Aligned Contrastive Learning (PACL), a modified
compatibility function for CLIP's contrastive loss, intending to train an
alignment between the patch tokens of the vision encoder and the CLS token of
the text encoder. With such an alignment, a model can identify regions of an
image corresponding to a given text input, and therefore transfer seamlessly to
the task of open vocabulary semantic segmentation without requiring any
segmentation annotations during training. Using pre-trained CLIP encoders with
PACL, we are able to set the state-of-the-art on the task of open vocabulary
zero-shot segmentation on 4 different segmentation benchmarks: Pascal VOC,
Pascal Context, COCO Stuff and ADE20K. Furthermore, we show that PACL is also
applicable to image-level predictions and when used with a CLIP backbone,
provides a general improvement in zero-shot classification accuracy compared to
CLIP, across a suite of 12 image classification datasets.",None,-1
7303ec02-ee4b-492e-8445-0c78e7ee622b,Ada3Diff: Defending against 3D Adversarial Point Clouds via Adaptive Diffusion,0.375688,"Deep 3D point cloud models are sensitive to adversarial attacks, which poses
threats to safety-critical applications such as autonomous driving. Robust
training and defend-by-denoising are typical strategies for defending
adversarial perturbations. However, they either induce massive computational
overhead or rely heavily upon specified priors, limiting generalized robustness
against attacks of all kinds. To remedy it, this paper introduces a novel
distortion-aware defense framework that can rebuild the pristine data
distribution with a tailored intensity estimator and a diffusion model. To
perform distortion-aware forward diffusion, we design a distortion estimation
algorithm that is obtained by summing the distance of each point to the
best-fitting plane of its local neighboring points, which is based on the
observation of the local spatial properties of the adversarial point cloud. By
iterative diffusion and reverse denoising, the perturbed point cloud under
various distortions can be restored back to a clean distribution. This approach
enables effective defense against adaptive attacks with varying noise budgets,
enhancing the robustness of existing 3D deep recognition models.",None,-1
159503bd-8648-4487-87e4-2ea2f05356bb,Mixture of Input-Output Hidden Markov Models for Heterogeneous Disease Progression Modeling,0.561354,"A particular challenge for disease progression modeling is the heterogeneity
of a disease and its manifestations in the patients. Existing approaches often
assume the presence of a single disease progression characteristics which is
unlikely for neurodegenerative disorders such as Parkinson's disease. In this
paper, we propose a hierarchical time-series model that can discover multiple
disease progression dynamics. The proposed model is an extension of an
input-output hidden Markov model that takes into account the clinical
assessments of patients' health status and prescribed medications. We
illustrate the benefits of our model using a synthetically generated dataset
and a real-world longitudinal dataset for Parkinson's disease.",https://github.com/tahaceritli/mIOHMM,17554
00fb004d-d6b8-4aa6-8cd2-8a7bf88c6549,Training Language Models with Language Feedback,0.746939,"Pretrained language models often do not perform tasks in ways that are in
line with our preferences, e.g., generating offensive text or factually
incorrect summaries. Recent work approaches the above issue by learning from a
simple form of human evaluation: comparisons between pairs of model-generated
task outputs. Comparison feedback conveys limited information about human
preferences per human evaluation. Here, we propose to learn from natural
language feedback, which conveys more information per human evaluation. We
learn from language feedback on model outputs using a three-step learning
algorithm. First, we condition the language model on the initial output and
feedback to generate many refinements. Second, we choose the refinement with
the highest similarity to the feedback. Third, we finetune a language model to
maximize the likelihood of the chosen refinement given the input. In synthetic
experiments, we first evaluate whether language models accurately incorporate
feedback to produce refinements, finding that only large language models (175B
parameters) do so. Using only 100 samples of human-written feedback, our
learning algorithm finetunes a GPT-3 model to roughly human-level summarization
ability.",None,150035
b7635038-bd15-4dad-8e90-a6785909b2dc,On the generalization capabilities of FSL methods through domain adaptation: a case study in endoscopic kidney stone image classification,0.129434,"Deep learning has shown great promise in diverse areas of computer vision,
such as image classification, object detection and semantic segmentation, among
many others. However, as it has been repeatedly demonstrated, deep learning
methods trained on a dataset do not generalize well to datasets from other
domains or even to similar datasets, due to data distribution shifts. In this
work, we propose the use of a meta-learning based few-shot learning approach to
alleviate these problems. In order to demonstrate its efficacy, we use two
datasets of kidney stones samples acquired with different endoscopes and
different acquisition conditions. The results show how such methods are indeed
capable of handling domain-shifts by attaining an accuracy of 74.38% and 88.52%
in the 5-way 5-shot and 5-way 20-shot settings respectively. Instead, in the
same dataset, traditional Deep Learning (DL) methods attain only an accuracy of
45%.",None,-1
72ffd20c-82d7-4366-81b9-eefb2b8fa68c,ImPosing: Implicit Pose Encoding for Efficient Visual Localization,0.339391,"We propose a novel learning-based formulation for visual localization of
vehicles that can operate in real-time in city-scale environments. Visual
localization algorithms determine the position and orientation from which an
image has been captured, using a set of geo-referenced images or a 3D scene
representation. Our new localization paradigm, named Implicit Pose Encoding
(ImPosing), embeds images and camera poses into a common latent representation
with 2 separate neural networks, such that we can compute a similarity score
for each image-pose pair. By evaluating candidates through the latent space in
a hierarchical manner, the camera position and orientation are not directly
regressed but incrementally refined. Very large environments force competitors
to store gigabytes of map data, whereas our method is very compact
independently of the reference database size. In this paper, we describe how to
effectively optimize our learned modules, how to combine them to achieve
real-time localization, and demonstrate results on diverse large scale
scenarios that significantly outperform prior work in accuracy and
computational efficiency.",https://github.com/Nanne/pytorch-NetVlad,-1
176dccc4-3274-48f9-b648-a464d85f30e9,A comparison of several AI techniques for authorship attribution on Romanian texts,0.355266,"Determining the author of a text is a difficult task. Here we compare
multiple AI techniques for classifying literary texts written by multiple
authors by taking into account a limited number of speech parts (prepositions,
adverbs, and conjunctions). We also introduce a new dataset composed of texts
written in the Romanian language on which we have run the algorithms. The
compared methods are Artificial Neural Networks, Support Vector Machines, Multi
Expression Programming, Decision Trees with C5.0, and k-Nearest Neighbour.
Numerical experiments show, first of all, that the problem is difficult, but
some algorithms are able to generate decent errors on the test set.",https://github.com/sanda-avram/ROST-source-code,2427
3a115f40-130d-4b7a-84b5-fb3f6b83f168,Neural-Symbolic Entangled Framework for Complex Query Answering,0.835968,"Answering complex queries over knowledge graphs (KG) is an important yet
challenging task because of the KG incompleteness issue and cascading errors
during reasoning. Recent query embedding (QE) approaches to embed the entities
and relations in a KG and the first-order logic (FOL) queries into a low
dimensional space, answering queries by dense similarity search. However,
previous works mainly concentrate on the target answers, ignoring intermediate
entities' usefulness, which is essential for relieving the cascading error
problem in logical query answering. In addition, these methods are usually
designed with their own geometric or distributional embeddings to handle
logical operators like union, intersection, and negation, with the sacrifice of
the accuracy of the basic operator - projection, and they could not absorb
other embedding methods to their models. In this work, we propose a Neural and
Symbolic Entangled framework (ENeSy) for complex query answering, which enables
the neural and symbolic reasoning to enhance each other to alleviate the
cascading error and KG incompleteness. The projection operator in ENeSy could
be any embedding method with the capability of link prediction, and the other
FOL operators are handled without parameters. With both neural and symbolic
reasoning results contained, ENeSy answers queries in ensembles. ENeSy achieves
the SOTA performance on several benchmarks, especially in the setting of the
training model only with the link prediction task.",None,-1
9c1533dc-c3e2-4711-92f9-ecb8eb993f38,Data Augmentation for Dementia Detection in Spoken Language,0.234353,"Dementia is a growing problem as our society ages, and detection methods are
often invasive and expensive. Recent deep-learning techniques can offer a
faster diagnosis and have shown promising results. However, they require large
amounts of labelled data which is not easily available for the task of dementia
detection. One effective solution to sparse data problems is data augmentation,
though the exact methods need to be selected carefully. To date, there has been
no empirical study of data augmentation on Alzheimer's disease (AD) datasets
for NLP and speech processing. In this work, we investigate data augmentation
techniques for the task of AD detection and perform an empirical evaluation of
the different approaches on two kinds of models for both the text and audio
domains. We use a transformer-based model for both domains, and SVM and Random
Forest models for the text and audio domains, respectively. We generate
additional samples using traditional as well as deep learning based methods and
show that data augmentation improves performance for both the text- and
audio-based models and that such results are comparable to state-of-the-art
results on the popular ADReSS set, with carefully crafted architectures and
features.",https://github.com/hl-anna/DA4AD,-1
7743ba21-06af-43c5-857a-cba25ca8d12c,Semantic Decomposition Improves Learning of Large Language Models on EHR Data,0.0332914,"Electronic health records (EHR) are widely believed to hold a profusion of
actionable insights, encrypted in an irregular, semi-structured format, amidst
a loud noise background. To simplify learning patterns of health and disease,
medical codes in EHR can be decomposed into semantic units connected by
hierarchical graphs. Building on earlier synergy between Bidirectional Encoder
Representations from Transformers (BERT) and Graph Attention Networks (GAT), we
present H-BERT, which ingests complete graph tree expansions of hierarchical
medical codes as opposed to only ingesting the leaves and pushes patient-level
labels down to each visit. This methodology significantly improves prediction
of patient membership in over 500 medical diagnosis classes as measured by
aggregated AUC and APS, and creates distinct representations of patients in
closely related but clinically distinct phenotypes.",None,-1
4fbdd34c-5bc5-43be-8b34-6ad47842760c,Conditional Bilingual Mutual Information Based Adaptive Training for Neural Machine Translation,0.189779,"Token-level adaptive training approaches can alleviate the token imbalance
problem and thus improve neural machine translation, through re-weighting the
losses of different target tokens based on specific statistical metrics (e.g.,
token frequency or mutual information). Given that standard translation models
make predictions on the condition of previous target contexts, we argue that
the above statistical metrics ignore target context information and may assign
inappropriate weights to target tokens. While one possible solution is to
directly take target contexts into these statistical metrics, the
target-context-aware statistical computing is extremely expensive, and the
corresponding storage overhead is unrealistic. To solve the above issues, we
propose a target-context-aware metric, named conditional bilingual mutual
information (CBMI), which makes it feasible to supplement target context
information for statistical metrics. Particularly, our CBMI can be formalized
as the log quotient of the translation model probability and language model
probability by decomposing the conditional joint distribution. Thus CBMI can be
efficiently calculated during model training without any pre-specific
statistical calculations and large storage overhead. Furthermore, we propose an
effective adaptive training approach based on both the token- and
sentence-level CBMI. Experimental results on WMT14 English-German and WMT19
Chinese-English tasks show our approach can significantly outperform the
Transformer baseline and other related methods.",https://github.com/songmzhang/CBMI,-1
751d61ef-01e2-4bf7-b9af-098ef57836b1,MICO: A Multi-alternative Contrastive Learning Framework for Commonsense Knowledge Representation,0.484537,"Commonsense reasoning tasks such as commonsense knowledge graph completion
and commonsense question answering require powerful representation learning. In
this paper, we propose to learn commonsense knowledge representation by MICO, a
Multi-alternative contrastve learning framework on COmmonsense knowledge graphs
(MICO). MICO generates the commonsense knowledge representation by contextual
interaction between entity nodes and relations with multi-alternative
contrastive learning. In MICO, the head and tail entities in an $(h,r,t)$
knowledge triple are converted to two relation-aware sequence pairs (a premise
and an alternative) in the form of natural language. Semantic representations
generated by MICO can benefit the following two tasks by simply comparing the
distance score between the representations: 1) zero-shot commonsense question
answering task; 2) inductive commonsense knowledge graph completion task.
Extensive experiments show the effectiveness of our method.",https://github.com/HKUST-KnowComp/MICO,-1
86db4964-cdb3-4734-8c5e-72e64d0a638e,Local Sliced-Wasserstein Feature Sets for Illumination-invariant Face Recognition,0.707265,"We present a new method for face recognition from digital images acquired
under varying illumination conditions. The method is based on mathematical
modeling of local gradient distributions using the Radon Cumulative
Distribution Transform (R-CDT). We demonstrate that lighting variations cause
certain types of deformations of local image gradient distributions which, when
expressed in R-CDT domain, can be modeled as a subspace. Face recognition is
then performed using a nearest subspace in R-CDT domain of local gradient
distributions. Experiment results demonstrate the proposed method outperforms
other alternatives in several face recognition tasks with challenging
illumination conditions. Python code implementing the proposed method is
available, which is integrated as a part of the software package PyTransKit.",https://github.com/rohdelab/drcdt face,-1
4dc6069d-b75f-4bd4-b14a-53cb45073003,Efficient Knowledge Distillation from Model Checkpoints,0.716099,"Knowledge distillation is an effective approach to learn compact models
(students) with the supervision of large and strong models (teachers). As
empirically there exists a strong correlation between the performance of
teacher and student models, it is commonly believed that a high performing
teacher is preferred. Consequently, practitioners tend to use a well trained
network or an ensemble of them as the teacher. In this paper, we make an
intriguing observation that an intermediate model, i.e., a checkpoint in the
middle of the training procedure, often serves as a better teacher compared to
the fully converged model, although the former has much lower accuracy. More
surprisingly, a weak snapshot ensemble of several intermediate models from a
same training trajectory can outperform a strong ensemble of independently
trained and fully converged models, when they are used as teachers. We show
that this phenomenon can be partially explained by the information bottleneck
principle: the feature representations of intermediate models can have higher
mutual information regarding the input, and thus contain more ""dark knowledge""
for effective distillation. We further propose an optimal intermediate teacher
selection algorithm based on maximizing the total task-related mutual
information. Experiments verify its effectiveness and applicability.",https://github.com/LeapLabTHU/CheckpointKD,-1
1b00acd4-8fba-4a3b-b8a5-358807110f33,C-Pack of IPAs: A C90 Program Benchmark of Introductory Programming Assignments,0.594346,"Due to the vast number of students enrolled in Massive Open Online Courses
(MOOCs), there has been an increasing number of automated program repair
techniques focused on introductory programming assignments (IPAs). Such
techniques take advantage of previous correct student implementations in order
to provide automated, comprehensive, and personalized feedback to students.
  This paper presents C-Pack-IPAs, a publicly available benchmark of students'
programs submitted for 25 different IPAs. C-Pack-IPAs contains semantically
correct, semantically incorrect, and syntactically incorrect programs plus a
test suite for each IPA. Hence, C-Pack-IPAs can be used to help evaluate the
development of novel semantic, as well as syntactic, automated program repair
frameworks, focused on providing feedback to novice programmers.",https://github.com/pmorvalho/C-Pack-IPAs,2685
e1e8a859-41a0-4b86-9a28-a42b5e540edf,Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting,0.987607,"In document classification for, e.g., legal and biomedical text, we often
deal with hundreds of classes, including very infrequent ones, as well as
temporal concept drift caused by the influence of real world events, e.g.,
policy changes, conflicts, or pandemics. Class imbalance and drift can
sometimes be mitigated by resampling the training data to simulate (or
compensate for) a known target distribution, but what if the target
distribution is determined by unknown future events? Instead of simply
resampling uniformly to hedge our bets, we focus on the underlying optimization
algorithms used to train such document classifiers and evaluate several
group-robust optimization algorithms, initially proposed to mitigate
group-level disparities. Reframing group-robust algorithms as adaptation
algorithms under concept drift, we find that Invariant Risk Minimization and
Spectral Decoupling outperform sampling-based approaches to class imbalance and
concept drift, and lead to much better performance on minority classes. The
effect is more pronounced the larger the label set.",https://github.com/coastalcph/lw-robust,-1
266effc5-c2bf-4c23-b381-edb9e14f672b,DDG-DA: Data Distribution Generation for Predictable Concept Drift Adaptation,0.952576,"In many real-world scenarios, we often deal with streaming data that is
sequentially collected over time. Due to the non-stationary nature of the
environment, the streaming data distribution may change in unpredictable ways,
which is known as concept drift. To handle concept drift, previous methods
first detect when/where the concept drift happens and then adapt models to fit
the distribution of the latest data. However, there are still many cases that
some underlying factors of environment evolution are predictable, making it
possible to model the future concept drift trend of the streaming data, while
such cases are not fully explored in previous work.
  In this paper, we propose a novel method DDG-DA, that can effectively
forecast the evolution of data distribution and improve the performance of
models. Specifically, we first train a predictor to estimate the future data
distribution, then leverage it to generate training samples, and finally train
models on the generated data. We conduct experiments on three real-world tasks
(forecasting on stock price trend, electricity load and solar irradiance) and
obtain significant improvement on multiple widely-used models.",https://github.com/Microsoft/qlib/tree/main/examples/benchmarks%20dynamic/DDG-DA,8108
250246ac-4b69-4606-b297-5f4f3f4f9815,Can Visual Dialogue Models Do Scorekeeping? Exploring How Dialogue Representations Incrementally Encode Shared Knowledge,0.864665,"Cognitively plausible visual dialogue models should keep a mental scoreboard
of shared established facts in the dialogue context. We propose a theory-based
evaluation method for investigating to what degree models pretrained on the
VisDial dataset incrementally build representations that appropriately do
scorekeeping. Our conclusion is that the ability to make the distinction
between shared and privately known statements along the dialogue is moderately
present in the analysed models, but not always incrementally consistent, which
may partially be due to the limited need for grounding interactions in the
original task.",https://github.com/vmurahari3/visdial-diversity,-1
392b431c-02b6-4dc7-9125-2b6b48fba61a,LogiGAN: Learning Logical Reasoning via Adversarial Pre-training,0.315414,"We present LogiGAN, an unsupervised adversarial pre-training framework for
improving logical reasoning abilities of language models. Upon automatic
identifying logical reasoning phenomena in massive text corpus via detection
heuristics, we train language models to predict the masked-out logical
statements. Inspired by the facilitation effect of reflective thinking in human
learning, we analogically simulate the learning-thinking process with an
adversarial Generator-Verifier architecture to assist logic learning. LogiGAN
implements a novel sequential GAN approach that (a) circumvents the
non-differentiable challenge of the sequential GAN by leveraging the Generator
as a sentence-level generative likelihood scorer with a learning objective of
reaching scoring consensus with the Verifier; (b) is computationally feasible
for large-scale pre-training with arbitrary target length. Both base and large
size language models pre-trained with LogiGAN demonstrate obvious performance
improvement on 12 datasets requiring general reasoning abilities, revealing the
fundamental role of logic in broad reasoning, as well as the effectiveness of
LogiGAN. Ablation studies on LogiGAN components reveal the relative
orthogonality between linguistic and logic abilities and suggest that
reflective thinking's facilitation effect might also generalize to machine
learning.",None,-1
f30edcfd-f18a-493a-9f1e-6b036bd2fe42,CrowdMLP: Weakly-Supervised Crowd Counting via Multi-Granularity MLP,0.735075,"Existing state-of-the-art crowd counting algorithms rely excessively on
location-level annotations, which are burdensome to acquire. When only
count-level (weak) supervisory signals are available, it is arduous and
error-prone to regress total counts due to the lack of explicit spatial
constraints. To address this issue, a novel and efficient counter (referred to
as CrowdMLP) is presented, which probes into modelling global dependencies of
embeddings and regressing total counts by devising a multi-granularity MLP
regressor. In specific, a locally-focused pre-trained frontend is cascaded to
extract crude feature maps with intrinsic spatial cues, which prevent the model
from collapsing into trivial outcomes. The crude embeddings, along with raw
crowd scenes, are tokenized at different granularity levels. The
multi-granularity MLP then proceeds to mix tokens at the dimensions of
cardinality, channel, and spatial for mining global information. An effective
proxy task, namely Split-Counting, is also proposed to evade the barrier of
limited samples and the shortage of spatial hints in a self-supervised manner.
Extensive experiments demonstrate that CrowdMLP significantly outperforms
existing weakly-supervised counting algorithms and performs on par with
state-of-the-art location-level supervised approaches.",None,-1
2d09c71a-b475-490e-b3be-8d702345790c,MVP: Robust Multi-View Practice for Driving Action Localization,0.235166,"Distracted driving causes thousands of deaths per year, and how to apply
deep-learning methods to prevent these tragedies has become a crucial problem.
In Track3 of the 6th AI City Challenge, researchers provide a high-quality
video dataset with densely action annotations. Due to the small data scale and
unclear action boundary, the dataset presents a unique challenge to precisely
localize all the different actions and classify their categories. In this
paper, we make good use of the multi-view synchronization among videos, and
conduct robust Multi-View Practice (MVP) for driving action localization. To
avoid overfitting, we fine-tune SlowFast with Kinetics-700 pre-training as the
feature extractor. Then the features of different views are passed to
ActionFormer to generate candidate action proposals. For precisely localizing
all the actions, we design elaborate post-processing, including model voting,
threshold filtering and duplication removal. The results show that our MVP is
robust for driving action localization, which achieves 28.49% F1-score in the
Track3 test set.",None,1527
6c4774e1-14c1-49a1-a7da-1393a4c218b5,Discrete-Constrained Regression for Local Counting Models,0.484458,"Local counts, or the number of objects in a local area, is a continuous value
by nature. Yet recent state-of-the-art methods show that formulating counting
as a classification task performs better than regression. Through a series of
experiments on carefully controlled synthetic data, we show that this
counter-intuitive result is caused by imprecise ground truth local counts.
Factors such as biased dot annotations and incorrectly matched Gaussian kernels
used to generate ground truth counts introduce deviations from the true local
counts. Standard continuous regression is highly sensitive to these errors,
explaining the performance gap between classification and regression. To
mitigate the sensitivity, we loosen the regression formulation from a
continuous scale to a discrete ordering and propose a novel
discrete-constrained (DC) regression. Applied to crowd counting, DC-regression
is more accurate than both classification and standard regression on three
public benchmarks. A similar advantage also holds for the age estimation task,
verifying the overall effectiveness of DC-regression.",None,-1
4dfc3cf2-3188-468a-bf95-787c2121f803,PriorLane: A Prior Knowledge Enhanced Lane Detection Approach Based on Transformer,0.253747,"Lane detection is one of the fundamental modules in self-driving. In this
paper we employ a transformer-only method for lane detection, thus it could
benefit from the blooming development of fully vision transformer and achieve
the state-of-the-art (SOTA) performance on both CULane and TuSimple benchmarks,
by fine-tuning the weight fully pre-trained on large datasets. More
importantly, this paper proposes a novel and general framework called
PriorLane, which is used to enhance the segmentation performance of the fully
vision transformer by introducing the low-cost local prior knowledge.
Specifically, PriorLane utilizes an encoder-only transformer to fuse the
feature extracted by a pre-trained segmentation model with prior knowledge
embeddings. Note that a Knowledge Embedding Alignment (KEA) module is adapted
to enhance the fusion performance by aligning the knowledge embedding.
Extensive experiments on our Zjlab dataset show that PriorLane outperforms SOTA
lane detection methods by a 2.82% mIoU when prior knowledge is employed, and
the code will be released at: https://github.com/vincentqqb/PriorLane.",https://github.com/vincentqqb/PriorLane,-1
7b1b54d9-bb79-4176-a7d2-49713c5e1d1f,Biometric identification by means of hand geometry and a neural net classifier,0.108669,"This Paper describes a hand geometry biometric identification system. We have
acquired a database of 22 people using a conventional document scanner. The
experimental section consists of a study about the discrimination capability of
different extracted features, and the identification rate using different
classifiers based on neural networks.",None,-1
a16831fc-8e81-470c-8ab3-9c7e789b5313,Understanding the Energy Consumption of HPC Scale Artificial Intelligence,0.11778,"This paper contributes towards better understanding the energy consumption
trade-offs of HPC scale Artificial Intelligence (AI), and more specifically
Deep Learning (DL) algorithms. For this task we developed benchmark-tracker, a
benchmark tool to evaluate the speed and energy consumption of DL algorithms in
HPC environments. We exploited hardware counters and Python libraries to
collect energy information through software, which enabled us to instrument a
known AI benchmark tool, and to evaluate the energy consumption of numerous DL
algorithms and models. Through an experimental campaign, we show a case example
of the potential of benchmark-tracker to measure the computing speed and the
energy consumption for training and inference DL algorithms, and also the
potential of Benchmark-Tracker to help better understanding the energy behavior
of DL algorithms in HPC platforms. This work is a step forward to better
understand the energy consumption of Deep Learning in HPC, and it also
contributes with a new tool to help HPC DL developers to better balance the HPC
infrastructure in terms of speed and energy consumption.",https://github.com/phamthi1812/Benchmark-Tracker,-1
10535b95-ec1c-465e-8ff4-0a61ecc88f34,AdaTest:Reinforcement Learning and Adaptive Sampling for On-chip Hardware Trojan Detection,0.69306,"This paper proposes AdaTest, a novel adaptive test pattern generation
framework for efficient and reliable Hardware Trojan (HT) detection. HT is a
backdoor attack that tampers with the design of victim integrated circuits
(ICs). AdaTest improves the existing HT detection techniques in terms of
scalability and accuracy of detecting smaller Trojans in the presence of noise
and variations. To achieve high trigger coverage, AdaTest leverages
Reinforcement Learning (RL) to produce a diverse set of test inputs.
Particularly, we progressively generate test vectors with high reward values in
an iterative manner. In each iteration, the test set is evaluated and
adaptively expanded as needed. Furthermore, AdaTest integrates adaptive
sampling to prioritize test samples that provide more information for HT
detection, thus reducing the number of samples while improving the sample
quality for faster exploration. We develop AdaTest with a Software/Hardware
co-design principle and provide an optimized on-chip architecture solution.
AdaTest's architecture minimizes the hardware overhead in two ways:(i)
Deploying circuit emulation on programmable hardware to accelerate reward
evaluation of the test input; (ii) Pipelining each computation stage in AdaTest
by automatically constructing auxiliary circuit for test input generation,
reward evaluation, and adaptive sampling. We evaluate AdaTest's performance on
various HT benchmarks and compare it with two prior works that use logic
testing for HT detection. Experimental results show that AdaTest engenders up
to two orders of test generation speedup and two orders of test set size
reduction compared to the prior works while achieving the same level or higher
Trojan detection rate.",None,31252
7a8759ee-06e4-425c-ac46-aafb719d6d4d,Error Compensation Framework for Flow-Guided Video Inpainting,0.453738,"The key to video inpainting is to use correlation information from as many
reference frames as possible. Existing flow-based propagation methods split the
video synthesis process into multiple steps: flow completion -> pixel
propagation -> synthesis. However, there is a significant drawback that the
errors in each step continue to accumulate and amplify in the next step. To
this end, we propose an Error Compensation Framework for Flow-guided Video
Inpainting (ECFVI), which takes advantage of the flow-based method and offsets
its weaknesses. We address the weakness with the newly designed flow completion
module and the error compensation network that exploits the error guidance map.
Our approach greatly improves the temporal consistency and the visual quality
of the completed videos. Experimental results show the superior performance of
our proposed method with the speed up of x6, compared to the state-of-the-art
methods. In addition, we present a new benchmark dataset for evaluation by
supplementing the weaknesses of existing test datasets.",None,-1
1b1d4eeb-2215-4ce9-8fdb-b7583fada4bb,Tourist Guidance Robot Based on HyperCLOVA,0.335462,"This paper describes our system submitted to Dialogue Robot Competition 2022.
Our proposed system is a combined model of rule-based and generation-based
dialog systems. The system utilizes HyperCLOVA, a Japanese foundation model,
not only to generate responses but also summarization, search information, etc.
We also used our original speech recognition system, which was fine-tuned for
this dialog task. As a result, our system ranked second in the preliminary
round and moved on to the finals.",None,-1
b1ca9554-bcd2-4412-accd-8aec506b169f,Focus on the Target's Vocabulary: Masked Label Smoothing for Machine Translation,0.282393,"Label smoothing and vocabulary sharing are two widely used techniques in
neural machine translation models. However, we argue that simply applying both
techniques can be conflicting and even leads to sub-optimal performance. When
allocating smoothed probability, original label smoothing treats the
source-side words that would never appear in the target language equally to the
real target-side words, which could bias the translation model. To address this
issue, we propose Masked Label Smoothing (MLS), a new mechanism that masks the
soft label probability of source-side words to zero. Simple yet effective, MLS
manages to better integrate label smoothing with vocabulary sharing. Our
extensive experiments show that MLS consistently yields improvement over
original label smoothing on different datasets, including bilingual and
multilingual translation from both translation quality and model's calibration.
Our code is released at https://github.com/PKUnlp-icler/MLS",https://github.com/shuo-git/InfECE,-1
67736c89-c7b4-4dca-8cbb-89a18a548c26,HINT: Hierarchical Neuron Concept Explainer,0.885059,"To interpret deep networks, one main approach is to associate neurons with
human-understandable concepts. However, existing methods often ignore the
inherent relationships of different concepts (e.g., dog and cat both belong to
animals), and thus lose the chance to explain neurons responsible for
higher-level concepts (e.g., animal). In this paper, we study hierarchical
concepts inspired by the hierarchical cognition process of human beings. To
this end, we propose HIerarchical Neuron concepT explainer (HINT) to
effectively build bidirectional associations between neurons and hierarchical
concepts in a low-cost and scalable manner. HINT enables us to systematically
and quantitatively study whether and how the implicit hierarchical
relationships of concepts are embedded into neurons, such as identifying
collaborative neurons responsible to one concept and multimodal neurons for
different concepts, at different semantic levels from concrete concepts (e.g.,
dog) to more abstract ones (e.g., animal). Finally, we verify the faithfulness
of the associations using Weakly Supervised Object Localization, and
demonstrate its applicability in various tasks such as discovering saliency
regions and explaining adversarial attacks. Code is available on
https://github.com/AntonotnaWang/HINT.",https://github.com/AntonotnaWang/HINT,-1
2463c5ad-c3f9-4829-9d80-5f98a4994030,Measuring Harmful Representations in Scandinavian Language Models,0.327672,"Scandinavian countries are perceived as role-models when it comes to gender
equality. With the advent of pre-trained language models and their widespread
usage, we investigate to what extent gender-based harmful and toxic content
exist in selected Scandinavian language models. We examine nine models,
covering Danish, Swedish, and Norwegian, by manually creating template-based
sentences and probing the models for completion. We evaluate the completions
using two methods for measuring harmful and toxic completions and provide a
thorough analysis of the results. We show that Scandinavian pre-trained
language models contain harmful and gender-based stereotypes with similar
values across all languages. This finding goes against the general expectations
related to gender equality in Scandinavian countries and shows the possible
problematic outcomes of using such models in real-world settings.",None,2551
ee9d81ee-c89d-4a3c-8d00-a7341f1076b3,Improving Temporal Generalization of Pre-trained Language Models with Lexical Semantic Change,0.317675,"Recent research has revealed that neural language models at scale suffer from
poor temporal generalization capability, i.e., the language model pre-trained
on static data from past years performs worse over time on emerging data.
Existing methods mainly perform continual training to mitigate such a
misalignment. While effective to some extent but is far from being addressed on
both the language modeling and downstream tasks. In this paper, we empirically
observe that temporal generalization is closely affiliated with lexical
semantic change, which is one of the essential phenomena of natural languages.
Based on this observation, we propose a simple yet effective lexical-level
masking strategy to post-train a converged language model. Experiments on two
pre-trained language models, two different classification tasks, and four
benchmark datasets demonstrate the effectiveness of our proposed method over
existing temporal adaptation methods, i.e., continual training with new data.
Our code is available at \url{https://github.com/zhaochen0110/LMLM}.",https://github.com/zhaochen0110/LMLM,-1
267362c8-250e-4c64-ae74-7592b8bb2034,Register Variation Remains Stable Across 60 Languages,0.225407,"This paper measures the stability of cross-linguistic register variation. A
register is a variety of a language that is associated with extra-linguistic
context. The relationship between a register and its context is functional: the
linguistic features that make up a register are motivated by the needs and
constraints of the communicative situation. This view hypothesizes that
register should be universal, so that we expect a stable relationship between
the extra-linguistic context that defines a register and the sets of linguistic
features which the register contains. In this paper, the universality and
robustness of register variation is tested by comparing variation within vs.
between register-specific corpora in 60 languages using corpora produced in
comparable communicative situations: tweets and Wikipedia articles. Our
findings confirm the prediction that register variation is, in fact, universal.",None,-1
eccad1e9-23ad-4f20-aaa6-4942edf942f1,TIE: Topological Information Enhanced Structural Reading Comprehension on Web Pages,0.719008,"Recently, the structural reading comprehension (SRC) task on web pages has
attracted increasing research interests. Although previous SRC work has
leveraged extra information such as HTML tags or XPaths, the informative
topology of web pages is not effectively exploited. In this work, we propose a
Topological Information Enhanced model (TIE), which transforms the token-level
task into a tag-level task by introducing a two-stage process (i.e. node
locating and answer refining). Based on that, TIE integrates Graph Attention
Network (GAT) and Pre-trained Language Model (PLM) to leverage the topological
information of both logical structures and spatial structures. Experimental
results demonstrate that our model outperforms strong baselines and achieves
state-of-the-art performances on the web-based SRC benchmark WebSRC at the time
of writing. The code of TIE will be publicly available at
https://github.com/X-LANCE/TIE.",https://github.com/X-LANCE/TIE,-1
9900e8e8-6a6f-494a-bd9b-c04c2cabcbf4,Probabilities of the third type: Statistical Relational Learning and Reasoning with Relative Frequencies,0.042327,"Dependencies on the relative frequency of a state in the domain are common
when modelling probabilistic dependencies on relational data. For instance, the
likelihood of a school closure during an epidemic might depend on the
proportion of infected pupils exceeding a threshold. Often, rather than
depending on discrete thresholds, dependencies are continuous: for instance,
the likelihood of any one mosquito bite transmitting an illness depends on the
proportion of carrier mosquitoes. Current approaches usually only consider
probabilities over possible worlds rather than over domain elements themselves.
An exception are the recently introduced Lifted Bayesian Networks for
Conditional Probability Logic, which express discrete dependencies on
probabilistic data. We introduce functional lifted Bayesian networks, a
formalism that explicitly incorporates continuous dependencies on relative
frequencies into statistical relational artificial intelligence. and compare
and contrast them with ifted Bayesian Networks for Conditional Probability
Logic. Incorporating relative frequencies is not only beneficial to modelling;
it also provides a more rigorous approach to learning problems where training
and test or application domains have different sizes. To this end, we provide a
representation of the asymptotic probability distributions induced by
functional lifted Bayesian networks on domains of increasing sizes. Since that
representation has well-understood scaling behaviour across domain sizes, it
can be used to estimate parameters for a large domain consistently from
randomly sampled subpopulations. Furthermore, we show that in parametric
families of FLBN, convergence is uniform in the parameters, which ensures a
meaningful dependence of the asymptotic probabilities on the parameters of the
model.",None,-1
34ecfb86-a82b-4d84-81d4-125aab93f62a,Direct Speech Translation for Automatic Subtitling,0.444886,"Automatic subtitling is the task of automatically translating the speech of
audiovisual content into short pieces of timed text, i.e. subtitles and their
corresponding timestamps. The generated subtitles need to conform to space and
time requirements, while being synchronised with the speech and segmented in a
way that facilitates comprehension. Given its considerable complexity, the task
has so far been addressed through a pipeline of components that separately deal
with transcribing, translating, and segmenting text into subtitles, as well as
predicting timestamps. In this paper, we propose the first direct ST model for
automatic subtitling that generates subtitles in the target language along with
their timestamps with a single model. Our experiments on 7 language pairs show
that our approach outperforms a cascade system in the same data condition, also
being competitive with production tools on both in-domain and newly-released
out-domain benchmarks covering new scenarios.",https://github.com/hlt-mt/FBK-fairseq/,-1
64c2c606-a36e-4873-ae9e-fb7851e65e49,VLCDoC: Vision-Language Contrastive Pre-Training Model for Cross-Modal Document Classification,0.398475,"Multimodal learning from document data has achieved great success lately as
it allows to pre-train semantically meaningful features as a prior into a
learnable downstream task. In this paper, we approach the document
classification problem by learning cross-modal representations through language
and vision cues, considering intra- and inter-modality relationships. Instead
of merging features from different modalities into a joint representation
space, the proposed method exploits high-level interactions and learns relevant
semantic information from effective attention flows within and across
modalities. The proposed learning objective is devised between intra- and
inter-modality alignment tasks, where the similarity distribution per task is
computed by contracting positive sample pairs while simultaneously contrasting
negative ones in the joint representation space}. Extensive experiments on
public document classification datasets demonstrate the effectiveness and the
generality of our model on low-scale and large-scale datasets.",https://github.com/tesseract-ocr/tesseract,-1
5081d9fa-3fc5-4fcb-8975-01ef3025a20a,Non-Isometric Shape Matching via Functional Maps on Landmark-Adapted Bases,0.397394,"We propose a principled approach for non-isometric landmark-preserving
non-rigid shape matching. Our method is based on the functional maps framework,
but rather than promoting isometries we focus instead on near-conformal maps
that preserve landmarks exactly. We achieve this, first, by introducing a novel
landmark-adapted basis using an intrinsic Dirichlet-Steklov eigenproblem.
Second, we establish the functional decomposition of conformal maps expressed
in this basis. Finally, we formulate a conformally-invariant energy that
promotes high-quality landmark-preserving maps, and show how it can be solved
via a variant of the recently proposed ZoomOut method that we extend to our
setting. Our method is descriptor-free, efficient and robust to significant
mesh variability. We evaluate our approach on a range of benchmark datasets and
demonstrate state-of-the-art performance on non-isometric benchmarks and near
state-of-the-art performance on isometric ones.",https://github.com/mpanine/DirichletSteklovLandmarkMatching,-1
88b5145e-3338-4b74-bb01-41ae456c8b03,Instance-Aware Image Completion,0.102863,"Image completion is a task that aims to fill in the missing region of a
masked image with plausible contents. However, existing image completion
methods tend to fill in the missing region with the surrounding texture instead
of hallucinating a visual instance that is suitable in accordance with the
context of the scene. In this work, we propose a novel image completion model,
dubbed ImComplete, that hallucinates the missing instance that harmonizes well
with - and thus preserves - the original context. ImComplete first adopts a
transformer architecture that considers the visible instances and the location
of the missing region. Then, ImComplete completes the semantic segmentation
masks within the missing region, providing pixel-level semantic and structural
guidance. Finally, the image synthesis blocks generate photo-realistic content.
We perform a comprehensive evaluation of the results in terms of visual quality
(LPIPS and FID) and contextual preservation scores (CLIPscore and object
detection accuracy) with COCO-panoptic and Visual Genome datasets. Experimental
results show the superiority of ImComplete on various natural images.",None,-1
600bc485-df53-480c-831a-a9532ae74c13,Conditional Generation with a Question-Answering Blueprint,0.977926,"The ability to convey relevant and faithful information is critical for many
tasks in conditional generation and yet remains elusive for neural seq-to-seq
models whose outputs often reveal hallucinations and fail to correctly cover
important details. In this work, we advocate planning as a useful intermediate
representation for rendering conditional generation less opaque and more
grounded. Our work proposes a new conceptualization of text plans as a sequence
of question-answer (QA) pairs. We enhance existing datasets (e.g., for
summarization) with a QA blueprint operating as a proxy for both content
selection (i.e.,~what to say) and planning (i.e.,~in what order). We obtain
blueprints automatically by exploiting state-of-the-art question generation
technology and convert input-output pairs into input-blueprint-output tuples.
We develop Transformer-based models, each varying in how they incorporate the
blueprint in the generated output (e.g., as a global plan or iteratively).
Evaluation across metrics and datasets demonstrates that blueprint models are
more factual than alternatives which do not resort to planning and allow
tighter control of the generation output.",None,-1
a1e0d6da-139a-47d7-964d-e55865d63541,FAMIE: A Fast Active Learning Framework for Multilingual Information Extraction,0.215563,"This paper presents FAMIE, a comprehensive and efficient active learning (AL)
toolkit for multilingual information extraction. FAMIE is designed to address a
fundamental problem in existing AL frameworks where annotators need to wait for
a long time between annotation batches due to the time-consuming nature of
model training and data selection at each AL iteration. This hinders the
engagement, productivity, and efficiency of annotators. Based on the idea of
using a small proxy network for fast data selection, we introduce a novel
knowledge distillation mechanism to synchronize the proxy network with the main
large model (i.e., BERT-based) to ensure the appropriateness of the selected
annotation examples for the main model. Our AL framework can support multiple
languages. The experiments demonstrate the advantages of FAMIE in terms of
competitive performance and time efficiency for sequence labeling with AL. We
publicly release our code (\url{https://github.com/nlp-uoregon/famie}) and demo
website (\url{http://nlp.uoregon.edu:9000/}). A demo video for FAMIE is
provided at: \url{https://youtu.be/I2i8n_jAyrY}.",https://github.com/nlp-uoregon/famie,-1
3798ff4b-6c9b-483f-8bc9-d7fd7645a381,Simple Techniques Work Surprisingly Well for Neural Network Test Prioritization and Active Learning (Replicability Study),0.728461,"Test Input Prioritizers (TIP) for Deep Neural Networks (DNN) are an important
technique to handle the typically very large test datasets efficiently, saving
computation and labeling costs. This is particularly true for large-scale,
deployed systems, where inputs observed in production are recorded to serve as
potential test or training data for the next versions of the system. Feng et.
al. propose DeepGini, a very fast and simple TIP, and show that it outperforms
more elaborate techniques such as neuron- and surprise coverage. In a
large-scale study (4 case studies, 8 test datasets, 32'200 trained models) we
verify their findings. However, we also find that other comparable or even
simpler baselines from the field of uncertainty quantification, such as the
predicted softmax likelihood or the entropy of the predicted softmax
likelihoods perform equally well as DeepGini.",https://github.com/testingautomated-usi/simple-tip,-1
32a5fa80-a61c-4f0e-b060-bdad75bc0b26,On the Influence of Explainable AI on Automation Bias,0.570767,"Artificial intelligence (AI) is gaining momentum, and its importance for the
future of work in many areas, such as medicine and banking, is continuously
rising. However, insights on the effective collaboration of humans and AI are
still rare. Typically, AI supports humans in decision-making by addressing
human limitations. However, it may also evoke human bias, especially in the
form of automation bias as an over-reliance on AI advice. We aim to shed light
on the potential to influence automation bias by explainable AI (XAI). In this
pre-test, we derive a research model and describe our study design.
Subsequentially, we conduct an online experiment with regard to hotel review
classifications and discuss first results. We expect our research to contribute
to the design and development of safe hybrid intelligence systems.",None,-1
6742bd4a-72d4-4865-a6e6-95fc4b97039f,DocEnTr: An End-to-End Document Image Enhancement Transformer,0.795889,"Document images can be affected by many degradation scenarios, which cause
recognition and processing difficulties. In this age of digitization, it is
important to denoise them for proper usage. To address this challenge, we
present a new encoder-decoder architecture based on vision transformers to
enhance both machine-printed and handwritten document images, in an end-to-end
fashion. The encoder operates directly on the pixel patches with their
positional information without the use of any convolutional layers, while the
decoder reconstructs a clean image from the encoded patches. Conducted
experiments show a superiority of the proposed model compared to the state-of
the-art methods on several DIBCO benchmarks. Code and models will be publicly
available at: \url{https://github.com/dali92002/DocEnTR}.",https://github.com/dali92002/DocEnTR,-1
a36fd127-21e5-4bd6-ab5a-ee586bcaab51,LogicSolver: Towards Interpretable Math Word Problem Solving with Logical Prompt-enhanced Learning,0.817618,"Recently, deep learning models have made great progress in MWP solving on
answer accuracy. However, they are uninterpretable since they mainly rely on
shallow heuristics to achieve high performance without understanding and
reasoning the grounded math logic. To address this issue and make a step
towards interpretable MWP solving, we first construct a high-quality MWP
dataset named InterMWP which consists of 11,495 MWPs and annotates
interpretable logical formulas based on algebraic knowledge as the grounded
linguistic logic of each solution equation. Different from existing MWP
datasets, our InterMWP benchmark asks for a solver to not only output the
solution expressions but also predict the corresponding logical formulas. We
further propose a novel approach with logical prompt and interpretation
generation, called LogicSolver. For each MWP, our LogicSolver first retrieves
some highly-correlated algebraic knowledge and then passes them to the backbone
model as prompts to improve the semantic representations of MWPs. With these
improved semantic representations, our LogicSolver generates corresponding
solution expressions and interpretable knowledge formulas in accord with the
generated solution expressions, simultaneously. Experimental results show that
our LogicSolver has stronger logical formula-based interpretability than
baselines while achieving higher answer accuracy with the help of logical
prompts, simultaneously. The source code and dataset is available at
https://github.com/yangzhch6/InterMWP.",https://github.com/yangzhch6/InterMWP,-1
43a4882c-2830-484e-aa2d-ffb46151eae4,Optimizing Multiple Simultaneous Objectives for Voting and Facility Location,0.230901,"We study the classic facility location setting, where we are given $n$
clients and $m$ possible facility locations in some arbitrary metric space, and
want to choose a location to build a facility. The exact same setting also
arises in spatial social choice, where voters are the clients and the goal is
to choose a candidate or outcome, with the distance from a voter to an outcome
representing the cost of this outcome for the voter (e.g., based on their
ideological differences). Unlike most previous work, we do not focus on a
single objective to optimize (e.g., the total distance from clients to the
facility, or the maximum distance, etc.), but instead attempt to optimize
several different objectives simultaneously. More specifically, we consider the
$l$-centrum family of objectives, which includes the total distance, max
distance, and many others. We present tight bounds on how well any pair of such
objectives (e.g., max and sum) can be simultaneously approximated compared to
their optimum outcomes. In particular, we show that for any such pair of
objectives, it is always possible to choose an outcome which simultaneously
approximates both objectives within a factor of $1+\sqrt{2}$, and give a
precise characterization of how this factor improves as the two objectives
being optimized become more similar. For $q>2$ different centrum objectives, we
show that it is always possible to approximate all $q$ of these objectives
within a small constant, and that this constant approaches 3 as $q\rightarrow
\infty$. Our results show that when optimizing only a few simultaneous
objectives, it is always possible to form an outcome which is a significantly
better than 3 approximation for all of these objectives.",None,-1
98d6c247-3d9a-480e-b4e5-02c2c6edbe0e,Hyperdecoders: Instance-specific decoders for multi-task NLP,0.465664,"We investigate input-conditioned hypernetworks for multi-tasking in NLP,
generating parameter-efficient adaptations for a decoder using a hypernetwork
conditioned on the output of an encoder. This approach produces a unique
decoder adaptation for every input instance, allowing the network a larger
degree of flexibility than prior work that only produces one decoder adaptation
per task. We apply our method to sequence classification tasks, extractive QA,
and summarisation and find that it surpasses previous parameter efficient
fine-tuning methods and often outperforms fully finetuning the underlying
model. An analysis of the embeddings used by our hypernetwork shows that they
are sensitive to output label and type, suggesting that our approach better
maps from encoder representations to output labels. Our code is publicly
available at https://github.com/allenai/hyperdecoders.",https://github.com/allenai/hyperdecoders,-1
9ad6cbd0-93ee-404a-af0e-be882be642d9,Deep reinforced active learning for multi-class image classification,0.200336,"High accuracy medical image classification can be limited by the costs of
acquiring more data as well as the time and expertise needed to label existing
images. In this paper, we apply active learning to medical image
classification, a method which aims to maximise model performance on a minimal
subset from a larger pool of data. We present a new active learning framework,
based on deep reinforcement learning, to learn an active learning query
strategy to label images based on predictions from a convolutional neural
network. Our framework modifies the deep-Q network formulation, allowing us to
pick data based additionally on geometric arguments in the latent space of the
classifier, allowing for high accuracy multi-class classification in a
batch-based active learning setting, enabling the agent to label datapoints
that are both diverse and about which it is most uncertain. We apply our
framework to two medical imaging datasets and compare with standard query
strategies as well as the most recent reinforcement learning based active
learning approach for image classification.",https://github.com/cosmic-cortex/modAL,-1
01f148b5-9367-4c80-a95f-08d4b693433e,The Neural Race Reduction: Dynamics of Abstraction in Gated Networks,0.761019,"Our theoretical understanding of deep learning has not kept pace with its
empirical success. While network architecture is known to be critical, we do
not yet understand its effect on learned representations and network behavior,
or how this architecture should reflect task structure.In this work, we begin
to address this gap by introducing the Gated Deep Linear Network framework that
schematizes how pathways of information flow impact learning dynamics within an
architecture. Crucially, because of the gating, these networks can compute
nonlinear functions of their input. We derive an exact reduction and, for
certain cases, exact solutions to the dynamics of learning. Our analysis
demonstrates that the learning dynamics in structured networks can be
conceptualized as a neural race with an implicit bias towards shared
representations, which then govern the model's ability to systematically
generalize, multi-task, and transfer. We validate our key insights on
naturalistic datasets and with relaxed assumptions. Taken together, our work
gives rise to general hypotheses relating neural architecture to learning and
provides a mathematical approach towards understanding the design of more
complex architectures and the role of modularity and compositionality in
solving real-world problems. The code and results are available at
https://www.saxelab.org/gated-dln .",None,1844
fe49dd74-8637-4e31-ae1c-e2a3bc8a0b95,Real-time Health Monitoring of Heat Exchangers using Hypernetworks and PINNs,0.243552,"We demonstrate a Physics-informed Neural Network (PINN) based model for
real-time health monitoring of a heat exchanger, that plays a critical role in
improving energy efficiency of thermal power plants. A hypernetwork based
approach is used to enable the domain-decomposed PINN learn the thermal
behavior of the heat exchanger in response to dynamic boundary conditions,
eliminating the need to re-train. As a result, we achieve orders of magnitude
reduction in inference time in comparison to existing PINNs, while maintaining
the accuracy on par with the physics-based simulations. This makes the approach
very attractive for predictive maintenance of the heat exchanger in digital
twin environments.",None,-1
331f1edc-cf8a-4b69-8b33-5318d5d1d7ca,Why Does Surprisal From Larger Transformer-Based Language Models Provide a Poorer Fit to Human Reading Times?,0.905425,"This work presents a detailed linguistic analysis into why larger
Transformer-based pre-trained language models with more parameters and lower
perplexity nonetheless yield surprisal estimates that are less predictive of
human reading times. First, regression analyses show a strictly monotonic,
positive log-linear relationship between perplexity and fit to reading times
for the more recently released five GPT-Neo variants and eight OPT variants on
two separate datasets, replicating earlier results limited to just GPT-2 (Oh et
al., 2022). Subsequently, analysis of residual errors reveals a systematic
deviation of the larger variants, such as underpredicting reading times of
named entities and making compensatory overpredictions for reading times of
function words such as modals and conjunctions. These results suggest that the
propensity of larger Transformer-based models to 'memorize' sequences during
training makes their surprisal estimates diverge from humanlike expectations,
which warrants caution in using pre-trained language models to study human
language processing.",https://github.com/byungdoh/llm_surprisal,176
84f56ab1-63d9-48f3-81e9-24b14b1d2d26,ERNIE-GeoL: A Geography-and-Language Pre-trained Model and its Applications in Baidu Maps,0.363496,"Pre-trained models (PTMs) have become a fundamental backbone for downstream
tasks in natural language processing and computer vision. Despite initial gains
that were obtained by applying generic PTMs to geo-related tasks at Baidu Maps,
a clear performance plateau over time was observed. One of the main reasons for
this plateau is the lack of readily available geographic knowledge in generic
PTMs. To address this problem, in this paper, we present ERNIE-GeoL, which is a
geography-and-language pre-trained model designed and developed for improving
the geo-related tasks at Baidu Maps. ERNIE-GeoL is elaborately designed to
learn a universal representation of geography-language by pre-training on
large-scale data generated from a heterogeneous graph that contains abundant
geographic knowledge. Extensive quantitative and qualitative experiments
conducted on large-scale real-world datasets demonstrate the superiority and
effectiveness of ERNIE-GeoL. ERNIE-GeoL has already been deployed in production
at Baidu Maps since April 2021, which significantly benefits the performance of
various downstream tasks. This demonstrates that ERNIE-GeoL can serve as a
fundamental backbone for a wide range of geo-related tasks.",None,-1
1ebc493b-eb6c-443e-8120-d664899bc65c,Let it RAIN for Social Good,0.129541,"Artificial Intelligence (AI) as a highly transformative technology take on a
special role as both an enabler and a threat to UN Sustainable Development
Goals (SDGs). AI Ethics and emerging high-level policy efforts stand at the
pivot point between these outcomes but is barred from effect due the
abstraction gap between high-level values and responsible action. In this paper
the Responsible Norms (RAIN) framework is presented, bridging this gap thereby
enabling effective high-level control of AI impact. With effective and
operationalized AI Ethics, AI technologies can be directed towards global
sustainable development.",None,-1
a1176844-d1c9-43e0-a75a-5852ec820fff,Multimodal hierarchical Variational AutoEncoders with Factor Analysis latent space,0.0904703,"Real-world databases are complex and usually require dealing with
heterogeneous and mixed data types making the exploitation of shared
information between views a critical issue. For this purpose, recent studies
based on deep generative models merge all views into a nonlinear complex latent
space, which can share information among views. However, this solution limits
the model's interpretability, flexibility, and modularity. We propose a novel
method to overcome these limitations by combining multiple Variational
AutoEncoders (VAE) with a Factor Analysis latent space (FA-VAE). We use VAEs to
learn a private representation of each heterogeneous view in a continuous
latent space. Then, we share the information between views by a low-dimensional
latent space using a linear projection matrix. This way, we create a flexible
and modular hierarchical dependency between private and shared information in
which new views can be incorporated afterwards. Beyond that, we can condition
pre-trained models, cross-generate data from different domains, and perform
transfer learning between generative models.",https://github.com/aguerrerolopez/FA-VAE,-1
0d9e1551-71ea-49ec-88b4-c544d9783839,WinoDict: Probing language models for in-context word acquisition,0.71724,"We introduce a new in-context learning paradigm to measure Large Language
Models' (LLMs) ability to learn novel words during inference. In particular, we
rewrite Winograd-style co-reference resolution problems by replacing the key
concept word with a synthetic but plausible word that the model must understand
to complete the task. Solving this task requires the model to make use of the
dictionary definition of the new word given in the prompt. This benchmark
addresses word acquisition, one important aspect of the diachronic degradation
known to afflict LLMs. As LLMs are frozen in time at the moment they are
trained, they are normally unable to reflect the way language changes over
time. We show that the accuracy of LLMs compared to the original Winograd tasks
decreases radically in our benchmark, thus identifying a limitation of current
models and providing a benchmark to measure future improvements in LLMs ability
to do in-context learning.",https://github.com/google-research/language/tree/master/language/wino_dict,2175
61df4f62-58b1-47b7-92a8-5ae048d1c15f,PromptBoosting: Black-Box Text Classification with Ten Forward Passes,0.715876,"We describe PromptBoosting, a query-efficient procedure for building a text
classifier from a neural language model (LM) without access to the LM's
parameters, gradients, or hidden representations. This form of ""black-box""
classifier training has become increasingly important as the cost of training
and inference in large-scale LMs grows. But existing black-box LM classifier
learning approaches are themselves computationally inefficient, typically
specializing LMs to the target task by searching in a large space of (discrete
or continuous) prompts using zeroth-order optimization methods. Instead of
directly optimizing in prompt space, PromptBoosting obtains a small pool of
prompts via a gradient-free approach and then constructs a large pool of weak
learners by pairing these prompts with different elements of the LM's output
distribution. These weak learners are then ensembled using the AdaBoost
algorithm. The entire learning process requires only a small number of forward
passes and no backward pass. Experiments show that PromptBoosting achieves
state-of-the-art performance in multiple black-box few-shot classification
tasks, and matches or outperforms full fine-tuning in both few-shot and
standard learning paradigms, while training 10x faster than existing black-box
methods.",https://github.com/UCSB-NLP-Chang/PromptBoosting,-1
43913f92-ab77-4aba-a3d1-4528675a1bd1,GANzzle: Reframing jigsaw puzzle solving as a retrieval task using a generative mental image,0.0840902,"Puzzle solving is a combinatorial challenge due to the difficulty of matching
adjacent pieces. Instead, we infer a mental image from all pieces, which a
given piece can then be matched against avoiding the combinatorial explosion.
Exploiting advancements in Generative Adversarial methods, we learn how to
reconstruct the image given a set of unordered pieces, allowing the model to
learn a joint embedding space to match an encoding of each piece to the cropped
layer of the generator. Therefore we frame the problem as a R@1 retrieval task,
and then solve the linear assignment using differentiable Hungarian attention,
making the process end-to-end. In doing so our model is puzzle size agnostic,
in contrast to prior deep learning methods which are single size. We evaluate
on two new large-scale datasets, where our model is on par with deep learning
methods, while generalizing to multiple puzzle sizes.",https://github.com/IIT-PAVIS/,-1
44f05010-07e7-4241-a203-5a12fb851dbd,Measuring Geographic Performance Disparities of Offensive Language Classifiers,0.516392,"Text classifiers are applied at scale in the form of one-size-fits-all
solutions. Nevertheless, many studies show that classifiers are biased
regarding different languages and dialects. When measuring and discovering
these biases, some gaps present themselves and should be addressed. First,
``Does language, dialect, and topical content vary across geographical
regions?'' and secondly ``If there are differences across the regions, do they
impact model performance?''. We introduce a novel dataset called GeoOLID with
more than 14 thousand examples across 15 geographically and demographically
diverse cities to address these questions. We perform a comprehensive analysis
of geographical-related content and their impact on performance disparities of
offensive language detection models. Overall, we find that current models do
not generalize across locations. Likewise, we show that while offensive
language models produce false positives on African American English, model
performance is not correlated with each city's minority population proportions.
Warning: This paper contains offensive language.",None,-1
918d8d31-dbae-4a02-b1a6-dc346a0555d3,Learning Optimal Phase-Shifts of Holographic Metasurface Transceivers,0.204331,"Holographic metasurface transceivers (HMT) is an emerging technology for
enhancing the coverage and rate of wireless communication systems. However,
acquiring accurate channel state information in HMT-assisted wireless
communication systems is critical for achieving these goals. In this paper, we
propose an algorithm for learning the optimal phase-shifts at a HMT for the
far-field channel model. Our proposed algorithm exploits the structure of the
channel gains in the far-field regions and learns the optimal phase-shifts in
presence of noise in the received signals. We prove that the probability that
the optimal phase-shifts estimated by our proposed algorithm deviate from the
true values decays exponentially in the number of pilot signals. Extensive
numerical simulations validate the theoretical guarantees and also demonstrate
significant gains as compared to the state-of-the-art policies.",None,-1
899e99d3-b0bc-4547-958f-00a25cd0b4f4,UIT-ViCoV19QA: A Dataset for COVID-19 Community-based Question Answering on Vietnamese Language,0.642567,"For the last two years, from 2020 to 2021, COVID-19 has broken disease
prevention measures in many countries, including Vietnam, and negatively
impacted various aspects of human life and the social community. Besides, the
misleading information in the community and fake news about the pandemic are
also serious situations. Therefore, we present the first Vietnamese
community-based question answering dataset for developing question answering
systems for COVID-19 called UIT-ViCoV19QA. The dataset comprises 4,500
question-answer pairs collected from trusted medical sources, with at least one
answer and at most four unique paraphrased answers per question. Along with the
dataset, we set up various deep learning models as baseline to assess the
quality of our dataset and initiate the benchmark results for further research
through commonly used metrics such as BLEU, METEOR, and ROUGE-L. We also
illustrate the positive effects of having multiple paraphrased answers
experimented on these models, especially on Transformer - a dominant
architecture in the field of study.",None,-1
87c60df3-a4ab-40f7-a8f3-7fb998f764e7,Human-to-Robot Imitation in the Wild,0.877126,"We approach the problem of learning by watching humans in the wild. While
traditional approaches in Imitation and Reinforcement Learning are promising
for learning in the real world, they are either sample inefficient or are
constrained to lab settings. Meanwhile, there has been a lot of success in
processing passive, unstructured human data. We propose tackling this problem
via an efficient one-shot robot learning algorithm, centered around learning
from a third-person perspective. We call our method WHIRL: In-the-Wild Human
Imitating Robot Learning. WHIRL extracts a prior over the intent of the human
demonstrator, using it to initialize our agent's policy. We introduce an
efficient real-world policy learning scheme that improves using interactions.
Our key contributions are a simple sampling-based policy optimization approach,
a novel objective function for aligning human and robot videos as well as an
exploration method to boost sample efficiency. We show one-shot generalization
and success in real-world settings, including 20 different manipulation tasks
in the wild. Videos and talk at https://human2robot.github.io",https://github.com/hello-robot,-1
70bd9090-b36f-4072-832d-18b34edae25f,A Privacy-Preserving Unsupervised Domain Adaptation Framework for Clinical Text Analysis,0.16314,"Unsupervised domain adaptation (UDA) generally aligns the unlabeled target
domain data to the distribution of the source domain to mitigate the
distribution shift problem. The standard UDA requires sharing the source data
with the target, having potential data privacy leaking risks. To protect the
source data's privacy, we first propose to share the source feature
distribution instead of the source data. However, sharing only the source
feature distribution may still suffer from the membership inference attack who
can infer an individual's membership by the black-box access to the source
model. To resolve this privacy issue, we further study the under-explored
problem of privacy-preserving domain adaptation and propose a method with a
novel differential privacy training strategy to protect the source data
privacy. We model the source feature distribution by Gaussian Mixture Models
(GMMs) under the differential privacy setting and send it to the target client
for adaptation. The target client resamples differentially private source
features from GMMs and adapts on target data with several state-of-art UDA
backbones. With our proposed method, the source data provider could avoid
leaking source data privacy during domain adaptation as well as reserve the
utility. To evaluate our proposed method's utility and privacy loss, we apply
our model on a medical report disease label classification task using two noisy
challenging clinical text datasets. The results show that our proposed method
can preserve source data's privacy with a minor performance influence on the
text classification task.",None,-1
8a1a53da-9c6f-40ff-90a3-84bc16f7d458,Heterogeneous-Agent Mirror Learning: A Continuum of Solutions to Cooperative MARL,0.674645,"The necessity for cooperation among intelligent machines has popularised
cooperative multi-agent reinforcement learning (MARL) in the artificial
intelligence (AI) research community. However, many research endeavors have
been focused on developing practical MARL algorithms whose effectiveness has
been studied only empirically, thereby lacking theoretical guarantees. As
recent studies have revealed, MARL methods often achieve performance that is
unstable in terms of reward monotonicity or suboptimal at convergence. To
resolve these issues, in this paper, we introduce a novel framework named
Heterogeneous-Agent Mirror Learning (HAML) that provides a general template for
MARL algorithmic designs. We prove that algorithms derived from the HAML
template satisfy the desired properties of the monotonic improvement of the
joint reward and the convergence to Nash equilibrium. We verify the
practicality of HAML by proving that the current state-of-the-art cooperative
MARL algorithms, HATRPO and HAPPO, are in fact HAML instances. Next, as a
natural outcome of our theory, we propose HAML extensions of two well-known RL
algorithms, HAA2C (for A2C) and HADDPG (for DDPG), and demonstrate their
effectiveness against strong baselines on StarCraftII and Multi-Agent MuJoCo
tasks.",https://github.com/anonymouswater/HAML,-1
050e6863-9f74-4d90-baff-f6ecb87408b6,IFQA: Interpretable Face Quality Assessment,0.302938,"Existing face restoration models have relied on general assessment metrics
that do not consider the characteristics of facial regions. Recent works have
therefore assessed their methods using human studies, which is not scalable and
involves significant effort. This paper proposes a novel face-centric metric
based on an adversarial framework where a generator simulates face restoration
and a discriminator assesses image quality. Specifically, our per-pixel
discriminator enables interpretable evaluation that cannot be provided by
traditional metrics. Moreover, our metric emphasizes facial primary regions
considering that even minor changes to the eyes, nose, and mouth significantly
affect human cognition. Our face-oriented metric consistently surpasses
existing general or facial image quality assessment metrics by impressive
margins. We demonstrate the generalizability of the proposed strategy in
various architectural designs and challenging scenarios. Interestingly, we find
that our IFQA can lead to performance improvement as an objective function.",https://github.com/VCLLab/IFQA,-1
1037bc3e-e3d4-4dfd-a0af-e4fdbb691c3d,A Computational Inflection for Scientific Discovery,0.708901,"We stand at the foot of a significant inflection in the trajectory of
scientific discovery. As society continues on its fast-paced digital
transformation, so does humankind's collective scientific knowledge and
discourse. We now read and write papers in digitized form, and a great deal of
the formal and informal processes of science are captured digitally --
including papers, preprints and books, code and datasets, conference
presentations, and interactions in social networks and collaboration and
communication platforms. The transition has led to the creation and growth of a
tremendous amount of information -- much of which is available for public
access -- opening exciting opportunities for computational models and systems
that analyze and harness it. In parallel, exponential growth in data processing
power has fueled remarkable advances in artificial intelligence, including
large neural language models capable of learning powerful representations from
unstructured text. Dramatic changes in scientific communication -- such as the
advent of the first scientific journal in the 17th century -- have historically
catalyzed revolutions in scientific thought. The confluence of societal and
computational trends suggests that computer science is poised to ignite a
revolution in the scientific process itself.",None,101093
93d9f5f9-c886-4362-9b4b-8f9e1c68db96,Adapting Pretrained Text-to-Text Models for Long Text Sequences,0.758419,"We present an empirical study of adapting an existing pretrained text-to-text
model for long-sequence inputs. Through a comprehensive study along three axes
of the pretraining pipeline -- model architecture, optimization objective, and
pretraining corpus, we propose an effective recipe to build long-context models
from existing short-context models. Specifically, we replace the full attention
in transformers with pooling-augmented blockwise attention, and pretrain the
model with a masked-span prediction task with spans of varying length. In terms
of the pretraining corpus, we find that using randomly concatenated
short-documents from a large open-domain corpus results in better performance
than using existing long document corpora which are typically limited in their
domain coverage. With these findings, we build a long-context model that
achieves competitive performance on long-text QA tasks and establishes the new
state of the art on five long-text summarization datasets, often outperforming
previous methods with larger model sizes. Our code has been released at
https://github.com/facebookresearch/bart_ls.",https://github.com/facebookresearch/bart_ls,-1
421997e4-c97f-46ac-96f8-394d12ca739f,ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts,0.571662,"This work introduces a new multi-task, parameter-efficient language model
(LM) tuning method that learns to transfer knowledge across different tasks via
a mixture of soft prompts-small prefix embedding vectors pre-trained for
different tasks. Our method, called ATTEMPT (ATTEntional Mixtures of Prompt
Tuning), obtains source prompts as encodings of large-scale source tasks into a
small number of parameters and trains an attention module to interpolate the
source prompts and a newly initialized target prompt for every instance in the
target task. During training, only the target task prompt and the attention
weights, which are shared between tasks in multi-task training, are updated,
while the original LM and source prompts are intact. ATTEMPT is highly
parameter-efficient (e.g., updates 2,300 times fewer parameters than full
fine-tuning) while achieving high task performance using knowledge from
high-resource tasks. Moreover, it is modular using pre-trained soft prompts,
and can flexibly add or remove source prompts for effective knowledge transfer.
Our experimental results across 21 diverse NLP datasets show that ATTEMPT
significantly outperforms prompt tuning and outperforms or matches fully
fine-tuned or other parameter-efficient tuning approaches that use over ten
times more parameters. Finally, ATTEMPT outperforms previous work in few-shot
learning settings.",https://github.com/AkariAsai/ATTEMPT,-1
123eb80a-add9-4b56-8d06-25c8c17c03bf,Graph Neural Network Policies and Imitation Learning for Multi-Domain Task-Oriented Dialogues,0.0553779,"Task-oriented dialogue systems are designed to achieve specific goals while
conversing with humans. In practice, they may have to handle simultaneously
several domains and tasks. The dialogue manager must therefore be able to take
into account domain changes and plan over different domains/tasks in order to
deal with multidomain dialogues. However, learning with reinforcement in such
context becomes difficult because the state-action dimension is larger while
the reward signal remains scarce. Our experimental results suggest that
structured policies based on graph neural networks combined with different
degrees of imitation learning can effectively handle multi-domain dialogues.
The reported experiments underline the benefit of structured policies over
standard policies.",None,3446
d27a005d-1a26-49bf-ab06-e37798e492bd,PSP-HDRI$+$: A Synthetic Dataset Generator for Pre-Training of Human-Centric Computer Vision Models,0.733332,"We introduce a new synthetic data generator PSP-HDRI$+$ that proves to be a
superior pre-training alternative to ImageNet and other large-scale synthetic
data counterparts. We demonstrate that pre-training with our synthetic data
will yield a more general model that performs better than alternatives even
when tested on out-of-distribution (OOD) sets. Furthermore, using ablation
studies guided by person keypoint estimation metrics with an off-the-shelf
model architecture, we show how to manipulate our synthetic data generator to
further improve model performance.",https://github.com/Unity-Technologies/PeopleSansPeople,-1
5312f080-d74a-462b-aee4-4d7fbfece6e4,SpeechMatrix: A Large-Scale Mined Corpus of Multilingual Speech-to-Speech Translations,0.894775,"We present SpeechMatrix, a large-scale multilingual corpus of
speech-to-speech translations mined from real speech of European Parliament
recordings. It contains speech alignments in 136 language pairs with a total of
418 thousand hours of speech. To evaluate the quality of this parallel speech,
we train bilingual speech-to-speech translation models on mined data only and
establish extensive baseline results on EuroParl-ST, VoxPopuli and FLEURS test
sets. Enabled by the multilinguality of SpeechMatrix, we also explore
multilingual speech-to-speech translation, a topic which was addressed by few
other works. We also demonstrate that model pre-training and sparse scaling
using Mixture-of-Experts bring large gains to translation performance. The
mined data and models are freely available.",https://github.com/facebookresearch/fairseq/tree/ust/examples/speech_matrix,-1
659ad065-c213-43d8-bb0a-95ec27e59440,Blockchain-based Monitoring for Poison Attack Detection in Decentralized Federated Learning,0.440975,"Federated Learning (FL) is a machine learning technique that addresses the
privacy challenges in terms of access rights of local datasets by enabling the
training of a model across nodes holding their data samples locally. To achieve
decentralized federated learning, blockchain-based FL was proposed as a
distributed FL architecture. In decentralized FL, the chief is eliminated from
the learning process as workers collaborate between each other to train the
global model. Decentralized FL applications need to account for the additional
delay incurred by blockchain-based FL deployments. Particularly in this
setting, to detect targeted/untargeted poisoning attacks, we investigate the
end-to-end learning completion latency of a realistic decentralized FL process
protected against poisoning attacks. We propose a technique which consists in
decoupling the monitoring phase from the detection phase in defenses against
poisoning attacks in a decentralized federated learning deployment that aim at
monitoring the behavior of the workers. We demonstrate that our proposed
blockchain-based monitoring improved network scalability, robustness and time
efficiency. The parallelization of operations results in minimized latency over
the end-to-end communication, computation, and consensus delays incurred during
the FL and blockchain operations.",https://github.com/LiTrans/BSMD/tree/master/,-1
acae0db4-bd4d-4f55-bae0-2359db8d1721,Sparse Probabilistic Circuits via Pruning and Growing,0.836845,"Probabilistic circuits (PCs) are a tractable representation of probability
distributions allowing for exact and efficient computation of likelihoods and
marginals. There has been significant recent progress on improving the scale
and expressiveness of PCs. However, PC training performance plateaus as model
size increases. We discover that most capacity in existing large PC structures
is wasted: fully-connected parameter layers are only sparsely used. We propose
two operations: pruning and growing, that exploit the sparsity of PC
structures. Specifically, the pruning operation removes unimportant
sub-networks of the PC for model compression and comes with theoretical
guarantees. The growing operation increases model capacity by increasing the
size of the latent space. By alternatingly applying pruning and growing, we
increase the capacity that is meaningfully used, allowing us to significantly
scale up PC learning. Empirically, our learner achieves state-of-the-art
likelihoods on MNIST-family image datasets and on Penn Tree Bank language data
compared to other PC learners and less tractable deep generative models such as
flow-based models and variational autoencoders (VAEs).",https://github.com/UCLA-StarAI/SparsePC,-1
1759771a-821d-407a-83ef-d2ae8a0432ca,MorisienMT: A Dataset for Mauritian Creole Machine Translation,0.811124,"In this paper, we describe MorisienMT, a dataset for benchmarking machine
translation quality of Mauritian Creole. Mauritian Creole (Morisien) is the
lingua franca of the Republic of Mauritius and is a French-based creole
language. MorisienMT consists of a parallel corpus between English and
Morisien, French and Morisien and a monolingual corpus for Morisien. We first
give an overview of Morisien and then describe the steps taken to create the
corpora and, from it, the training and evaluation splits. Thereafter, we
establish a variety of baseline models using the created parallel corpora as
well as large French--English corpora for transfer learning. We release our
datasets publicly for research purposes and hope that this spurs research for
Morisien machine translation.",https://huggingface.co/datasets/prajdabre/MorisienMT,1758
ce79288a-b658-4627-a4ed-589c096f7b73,WiCV 2021: The Eighth Women In Computer Vision Workshop,0.864665,"In this paper, we present the details of Women in Computer Vision Workshop -
WiCV 2021, organized alongside the virtual CVPR 2021. It provides a voice to a
minority (female) group in the computer vision community and focuses on
increasing the visibility of these researchers, both in academia and industry.
WiCV believes that such an event can play an important role in lowering the
gender imbalance in the field of computer vision. WiCV is organized each year
where it provides a)~opportunity for collaboration between researchers from
minority groups, b)~mentorship to female junior researchers, c)~financial
support to presenters to overcome monetary burden and d)~large and diverse
choice of role models, who can serve as examples to younger researchers at the
beginning of their careers. In this paper, we present a report on the workshop
program, trends over the past years, a summary of statistics regarding
presenters, attendees, and sponsorship for the WiCV 2021 workshop.",None,-1
1ab433ad-05c4-43bd-99e9-754c24d42ca8,Human Response to an AI-Based Decision Support System: A User Study on the Effects of Accuracy and Bias,0.125201,"Artificial Intelligence (AI) is increasingly used to build Decision Support
Systems (DSS) across many domains. This paper describes a series of experiments
designed to observe human response to different characteristics of a DSS such
as accuracy and bias, particularly the extent to which participants rely on the
DSS, and the performance they achieve. In our experiments, participants play a
simple online game inspired by so-called ""wildcat"" (i.e., exploratory) drilling
for oil. The landscape has two layers: a visible layer describing the costs
(terrain), and a hidden layer describing the reward (oil yield). Participants
in the control group play the game without receiving any assistance, while in
treatment groups they are assisted by a DSS suggesting places to drill. For
certain treatments, the DSS does not consider costs, but only rewards, which
introduces a bias that is observable by users. Between subjects, we vary the
accuracy and bias of the DSS, and observe the participants' total score, time
to completion, the extent to which they follow or ignore suggestions. We also
measure the acceptability of the DSS in an exit survey. Our results show that
participants tend to score better with the DSS, that the score increase is due
to users following the DSS advice, and related to the difficulty of the game
and the accuracy of the DSS. We observe that this setting elicits mostly
rational behavior from participants, who place a moderate amount of trust in
the DSS and show neither algorithmic aversion (under-reliance) nor automation
bias (over-reliance).However, their stated willingness to accept the DSS in the
exit survey seems less sensitive to the accuracy of the DSS than their
behavior, suggesting that users are only partially aware of the (lack of)
accuracy of the DSS.",None,27850
cd9c345e-1c81-467e-9961-4a010ec831a3,An LSTM model for Twitter Sentiment Analysis,0.649342,"Sentiment analysis on social media such as Twitter provides organizations and
individuals an effective way to monitor public emotions towards them and their
competitors. As a result, sentiment analysis has become an important and
challenging task. In this work, we have collected seven publicly available and
manually annotated twitter sentiment datasets. We create a new training and
testing dataset from the collected datasets. We develop an LSTM model to
classify sentiment of a tweet and evaluate the model with the new dataset.",None,-1
e7cc1d9f-523e-47bd-a4f6-83b92fe3de25,LPAttack: A Feasible Annotation Scheme for Capturing Logic Pattern of Attacks in Arguments,0.115664,"In argumentative discourse, persuasion is often achieved by refuting or
attacking others arguments. Attacking is not always straightforward and often
comprise complex rhetorical moves such that arguers might agree with a logic of
an argument while attacking another logic. Moreover, arguer might neither deny
nor agree with any logics of an argument, instead ignore them and attack the
main stance of the argument by providing new logics and presupposing that the
new logics have more value or importance than the logics present in the
attacked argument. However, no existing studies in the computational
argumentation capture such complex rhetorical moves in attacks or the
presuppositions or value judgements in them. In order to address this gap, we
introduce LPAttack, a novel annotation scheme that captures the common modes
and complex rhetorical moves in attacks along with the implicit presuppositions
and value judgements in them. Our annotation study shows moderate
inter-annotator agreement, indicating that human annotation for the proposed
scheme is feasible. We publicly release our annotated corpus and the annotation
guidelines.",None,-1
bacc71c0-59a8-42a3-b127-c0139c41c53b,Knowledge Removal in Sampling-based Bayesian Inference,0.903963,"The right to be forgotten has been legislated in many countries, but its
enforcement in the AI industry would cause unbearable costs. When single data
deletion requests come, companies may need to delete the whole models learned
with massive resources. Existing works propose methods to remove knowledge
learned from data for explicitly parameterized models, which however are not
appliable to the sampling-based Bayesian inference, i.e., Markov chain Monte
Carlo (MCMC), as MCMC can only infer implicit distributions. In this paper, we
propose the first machine unlearning algorithm for MCMC. We first convert the
MCMC unlearning problem into an explicit optimization problem. Based on this
problem conversion, an {\it MCMC influence function} is designed to provably
characterize the learned knowledge from data, which then delivers the MCMC
unlearning algorithm. Theoretical analysis shows that MCMC unlearning would not
compromise the generalizability of the MCMC models. Experiments on Gaussian
mixture models and Bayesian neural networks confirm the effectiveness of the
proposed algorithm. The code is available at
\url{https://github.com/fshp971/mcmc-unlearning}.",https://github.com/fshp971/mcmc-unlearning,-1
01a51a65-db0f-4ebb-b1b7-bd3d21cdb847,Video Anomaly Detection by Solving Decoupled Spatio-Temporal Jigsaw Puzzles,0.916779,"Video Anomaly Detection (VAD) is an important topic in computer vision.
Motivated by the recent advances in self-supervised learning, this paper
addresses VAD by solving an intuitive yet challenging pretext task, i.e.,
spatio-temporal jigsaw puzzles, which is cast as a multi-label fine-grained
classification problem. Our method exhibits several advantages over existing
works: 1) the spatio-temporal jigsaw puzzles are decoupled in terms of spatial
and temporal dimensions, responsible for capturing highly discriminative
appearance and motion features, respectively; 2) full permutations are used to
provide abundant jigsaw puzzles covering various difficulty levels, allowing
the network to distinguish subtle spatio-temporal differences between normal
and abnormal events; and 3) the pretext task is tackled in an end-to-end manner
without relying on any pre-trained models. Our method outperforms
state-of-the-art counterparts on three public benchmarks. Especially on
ShanghaiTech Campus, the result is superior to reconstruction and
prediction-based methods by a large margin.",https://github.com/wizyoung/YOLOv3,29064
cc272ca0-c47a-4e6f-a926-91d72dc78fb1,LingYi: Medical Conversational Question Answering System based on Multi-modal Knowledge Graphs,0.741724,"The medical conversational system can relieve the burden of doctors and
improve the efficiency of healthcare, especially during the pandemic. This
paper presents a medical conversational question answering (CQA) system based
on the multi-modal knowledge graph, namely ""LingYi"", which is designed as a
pipeline framework to maintain high flexibility. Our system utilizes automated
medical procedures including medical triage, consultation, image-text drug
recommendation and record. To conduct knowledge-grounded dialogues with
patients, we first construct a Chinese Medical Multi-Modal Knowledge Graph
(CM3KG) and collect a large-scale Chinese Medical CQA (CMCQA) dataset. Compared
with the other existing medical question-answering systems, our system adopts
several state-of-the-art technologies including medical entity disambiguation
and medical dialogue generation, which is more friendly to provide medical
services to patients. In addition, we have open-sourced our codes which contain
back-end models and front-end web pages at https://github.com/WENGSYX/LingYi.
The datasets including CM3KG at https://github.com/WENGSYX/CM3KG and CMCQA at
https://github.com/WENGSYX/CMCQA are also released to further promote future
research.",https://github.com/WENGSYX/LingYi,-1
481a1059-bc3b-4ccd-b041-b54ac1c301e0,"Q-Ensemble for Offline RL: Don't Scale the Ensemble, Scale the Batch Size",0.525486,"Training large neural networks is known to be time-consuming, with the
learning duration taking days or even weeks. To address this problem,
large-batch optimization was introduced. This approach demonstrated that
scaling mini-batch sizes with appropriate learning rate adjustments can speed
up the training process by orders of magnitude. While long training time was
not typically a major issue for model-free deep offline RL algorithms, recently
introduced Q-ensemble methods achieving state-of-the-art performance made this
issue more relevant, notably extending the training duration. In this work, we
demonstrate how this class of methods can benefit from large-batch
optimization, which is commonly overlooked by the deep offline RL community. We
show that scaling the mini-batch size and naively adjusting the learning rate
allows for (1) a reduced size of the Q-ensemble, (2) stronger penalization of
out-of-distribution actions, and (3) improved convergence time, effectively
shortening training duration by 3-4x times on average.",https://github.com/tinkoff-ai/lb-sac,-1
41e69fac-fba3-4486-aa54-50e39be6acec,DICE: Data-Efficient Clinical Event Extraction with Generative Models,0.784135,"Event extraction for the clinical domain is an under-explored research area.
The lack of training data along with the high volume of domain-specific
terminologies with vague entity boundaries makes the task especially
challenging. In this paper, we introduce DICE, a robust and data-efficient
generative model for clinical event extraction. DICE frames event extraction as
a conditional generation problem and introduces a contrastive learning
objective to accurately decide the boundaries of biomedical mentions. DICE also
trains an auxiliary mention identification task jointly with event extraction
tasks to better identify entity mention boundaries, and further introduces
special markers to incorporate identified entity mentions as trigger and
argument candidates for their respective tasks. To benchmark clinical event
extraction, we compose MACCROBAT-EE, the first clinical event extraction
dataset with argument annotation, based on an existing clinical information
extraction dataset MACCROBAT. Our experiments demonstrate state-of-the-art
performances of DICE for clinical and news domain event extraction, especially
under low data settings.",None,-1
4895a9af-c065-472e-971c-0b74404158c4,A Baseline for Detecting Out-of-Distribution Examples in Image Captioning,0.12448,"Image captioning research achieved breakthroughs in recent years by
developing neural models that can generate diverse and high-quality
descriptions for images drawn from the same distribution as training images.
However, when facing out-of-distribution (OOD) images, such as corrupted
images, or images containing unknown objects, the models fail in generating
relevant captions.
  In this paper, we consider the problem of OOD detection in image captioning.
We formulate the problem and suggest an evaluation setup for assessing the
model's performance on the task. Then, we analyze and show the effectiveness of
the caption's likelihood score at detecting and rejecting OOD images, which
implies that the relatedness between the input image and the generated caption
is encapsulated within the score.",None,-1
9abcd799-9e86-4ac0-891a-0ba57d60c57d,On Interactive Explanations as Non-Monotonic Reasoning,0.114408,"Recent work shows issues of consistency with explanations, with methods
generating local explanations that seem reasonable instance-wise, but that are
inconsistent across instances. This suggests not only that instance-wise
explanations can be unreliable, but mainly that, when interacting with a system
via multiple inputs, a user may actually lose confidence in the system. To
better analyse this issue, in this work we treat explanations as objects that
can be subject to reasoning and present a formal model of the interactive
scenario between user and system, via sequences of inputs, outputs, and
explanations. We argue that explanations can be thought of as committing to
some model behaviour (even if only prima facie), suggesting a form of
entailment, which, we argue, should be thought of as non-monotonic. This
allows: 1) to solve some considered inconsistencies in explanation, such as via
a specificity relation; 2) to consider properties from the non-monotonic
reasoning literature and discuss their desirability, gaining more insight on
the interactive explanation scenario.",None,-1
97ce9043-e3c7-472b-a66a-476306cdda15,Synthetic Disinformation Attacks on Automated Fact Verification Systems,0.908585,"Automated fact-checking is a needed technology to curtail the spread of
online misinformation. One current framework for such solutions proposes to
verify claims by retrieving supporting or refuting evidence from related
textual sources. However, the realistic use cases for fact-checkers will
require verifying claims against evidence sources that could be affected by the
same misinformation. Furthermore, the development of modern NLP tools that can
produce coherent, fabricated content would allow malicious actors to
systematically generate adversarial disinformation for fact-checkers.
  In this work, we explore the sensitivity of automated fact-checkers to
synthetic adversarial evidence in two simulated settings: AdversarialAddition,
where we fabricate documents and add them to the evidence repository available
to the fact-checking system, and AdversarialModification, where existing
evidence source documents in the repository are automatically altered. Our
study across multiple models on three benchmarks demonstrates that these
systems suffer significant performance drops against these attacks. Finally, we
discuss the growing threat of modern NLG systems as generators of
disinformation in the context of the challenges they pose to automated
fact-checkers.",https://github.com/Yibing-Du/adversarial-factcheck,-1
27b78b16-bdf6-45f9-917c-953d56e1bdb6,Concise Logarithmic Loss Function for Robust Training of Anomaly Detection Model,0.0410551,"Recently, deep learning-based algorithms are widely adopted due to the
advantage of being able to establish anomaly detection models without or with
minimal domain knowledge of the task. Instead, to train the artificial neural
network more stable, it should be better to define the appropriate neural
network structure or the loss function. For the training anomaly detection
model, the mean squared error (MSE) function is adopted widely. On the other
hand, the novel loss function, logarithmic mean squared error (LMSE), is
proposed in this paper to train the neural network more stable. This study
covers a variety of comparisons from mathematical comparisons, visualization in
the differential domain for backpropagation, loss convergence in the training
process, and anomaly detection performance. In an overall view, LMSE is
superior to the existing MSE function in terms of strongness of loss
convergence, anomaly detection performance. The LMSE function is expected to be
applicable for training not only the anomaly detection model but also the
general generative neural network.",None,-1
5eaf0076-a50e-453d-86f9-407b0cdca12d,Zero-shot Cross-Linguistic Learning of Event Semantics,0.0820605,"Typologically diverse languages offer systems of lexical and grammatical
aspect that allow speakers to focus on facets of event structure in ways that
comport with the specific communicative setting and discourse constraints they
face. In this paper, we look specifically at captions of images across Arabic,
Chinese, Farsi, German, Russian, and Turkish and describe a computational model
for predicting lexical aspects. Despite the heterogeneity of these languages,
and the salient invocation of distinctive linguistic resources across their
caption corpora, speakers of these languages show surprising similarities in
the ways they frame image content. We leverage this observation for zero-shot
cross-lingual learning and show that lexical aspects can be predicted for a
given language despite not having observed any annotated data for this language
at all.",None,-1
43547cae-131d-4b33-beba-f5ea758e9312,"Control Globally, Understand Locally: A Global-to-Local Hierarchical Graph Network for Emotional Support Conversation",0.99951,"Emotional support conversation aims at reducing the emotional distress of the
help-seeker, which is a new and challenging task. It requires the system to
explore the cause of help-seeker's emotional distress and understand their
psychological intention to provide supportive responses. However, existing
methods mainly focus on the sequential contextual information, ignoring the
hierarchical relationships with the global cause and local psychological
intention behind conversations, thus leads to a weak ability of emotional
support. In this paper, we propose a Global-to-Local Hierarchical Graph Network
to capture the multi-source information (global cause, local intentions and
dialog history) and model hierarchical relationships between them, which
consists of a multi-source encoder, a hierarchical graph reasoner, and a
global-guide decoder. Furthermore, a novel training objective is designed to
monitor semantic information of the global cause. Experimental results on the
emotional support conversation dataset, ESConv, confirm that the proposed GLHG
has achieved the state-of-the-art performance on the automatic and human
evaluations. The code will be released in here
\footnote{\small{~https://github.com/pengwei-iie/GLHG}}.",https://github.com/pengwei-iie/GLHG,-1
1bc83f1e-99d1-44c8-8f9c-6d63afed7f1b,Booster-SHOT: Boosting Stacked Homography Transformations for Multiview Pedestrian Detection with Attention,0.205477,"Improving multi-view aggregation is integral for multi-view pedestrian
detection, which aims to obtain a bird's-eye-view pedestrian occupancy map from
images captured through a set of calibrated cameras. Inspired by the success of
attention modules for deep neural networks, we first propose a Homography
Attention Module (HAM) which is shown to boost the performance of existing
end-to-end multiview detection approaches by utilizing a novel channel gate and
spatial gate. Additionally, we propose Booster-SHOT, an end-to-end
convolutional approach to multiview pedestrian detection incorporating our
proposed HAM as well as elements from previous approaches such as view-coherent
augmentation or stacked homography transformations. Booster-SHOT achieves 92.9%
and 94.2% for MODA on Wildtrack and MultiviewX respectively, outperforming the
state-of-the-art by 1.4% on Wildtrack and 0.5% on MultiviewX, achieving
state-of-the-art performance overall for standard evaluation metrics used in
multi-view pedestrian detection.",None,188
2f1f7c36-4b09-4a9c-841c-5b40e11989b8,Multi-channel Attentive Graph Convolutional Network With Sentiment Fusion For Multimodal Sentiment Analysis,0.402761,"Nowadays, with the explosive growth of multimodal reviews on social media
platforms, multimodal sentiment analysis has recently gained popularity because
of its high relevance to these social media posts. Although most previous
studies design various fusion frameworks for learning an interactive
representation of multiple modalities, they fail to incorporate sentimental
knowledge into inter-modality learning. This paper proposes a Multi-channel
Attentive Graph Convolutional Network (MAGCN), consisting of two main
components: cross-modality interactive learning and sentimental feature fusion.
For cross-modality interactive learning, we exploit the self-attention
mechanism combined with densely connected graph convolutional networks to learn
inter-modality dynamics. For sentimental feature fusion, we utilize multi-head
self-attention to merge sentimental knowledge into inter-modality feature
representations. Extensive experiments are conducted on three widely-used
datasets. The experimental results demonstrate that the proposed model achieves
competitive performance on accuracy and F1 scores compared to several
state-of-the-art approaches.",None,3594
41a9d05a-7dda-4cae-b595-c6dd0e1a32ee,Scalable Planning and Learning Framework Development for Swarm-to-Swarm Engagement Problems,0.864665,"Development of guidance, navigation and control frameworks/algorithms for
swarms attracted significant attention in recent years. That being said,
algorithms for planning swarm allocations/trajectories for engaging with enemy
swarms is largely an understudied problem. Although small-scale scenarios can
be addressed with tools from differential game theory, existing approaches fail
to scale for large-scale multi-agent pursuit evasion (PE) scenarios. In this
work, we propose a reinforcement learning (RL) based framework to decompose to
large-scale swarm engagement problems into a number of independent multi-agent
pursuit-evasion games. We simulate a variety of multi-agent PE scenarios, where
finite time capture is guaranteed under certain conditions. The calculated PE
statistics are provided as a reward signal to the high level allocation layer,
which uses an RL algorithm to allocate controlled swarm units to eliminate
enemy swarm units with maximum efficiency. We verify our approach in
large-scale swarm-to-swarm engagement simulations.",None,-1
5b60e3f7-9583-4679-b4b4-63062d7eaaea,Using EBGAN for Anomaly Intrusion Detection,0.122177,"As an active network security protection scheme, intrusion detection system
(IDS) undertakes the important responsibility of detecting network attacks in
the form of malicious network traffic. Intrusion detection technology is an
important part of IDS. At present, many scholars have carried out extensive
research on intrusion detection technology. However, developing an efficient
intrusion detection method for massive network traffic data is still difficult.
Since Generative Adversarial Networks (GANs) have powerful modeling
capabilities for complex high-dimensional data, they provide new ideas for
addressing this problem. In this paper, we put forward an EBGAN-based intrusion
detection method, IDS-EBGAN, that classifies network records as normal traffic
or malicious traffic. The generator in IDS-EBGAN is responsible for converting
the original malicious network traffic in the training set into adversarial
malicious examples. This is because we want to use adversarial learning to
improve the ability of discriminator to detect malicious traffic. At the same
time, the discriminator adopts Autoencoder model. During testing, IDS-EBGAN
uses reconstruction error of discriminator to classify traffic records.",None,-1
8666778c-e195-4fc8-9fca-7bf75649a730,RBC: Rectifying the Biased Context in Continual Semantic Segmentation,0.323235,"Recent years have witnessed a great development of Convolutional Neural
Networks in semantic segmentation, where all classes of training images are
simultaneously available. In practice, new images are usually made available in
a consecutive manner, leading to a problem called Continual Semantic
Segmentation (CSS). Typically, CSS faces the forgetting problem since previous
training images are unavailable, and the semantic shift problem of the
background class. Considering the semantic segmentation as a context-dependent
pixel-level classification task, we explore CSS from a new perspective of
context analysis in this paper. We observe that the context of old-class pixels
in the new images is much more biased on new classes than that in the old
images, which can sharply aggravate the old-class forgetting and new-class
overfitting. To tackle the obstacle, we propose a biased-context-rectified CSS
framework with a context-rectified image-duplet learning scheme and a
biased-context-insensitive consistency loss. Furthermore, we propose an
adaptive re-weighting class-balanced learning strategy for the biased class
distribution. Our approach outperforms state-of-the-art methods by a large
margin in existing CSS scenarios.",https://github.com/arthurdouillard/CVPR2021,-1
a3ed85b6-0130-49f4-8b23-5396f007ff63,Transductive CLIP with Class-Conditional Contrastive Learning,0.161872,"Inspired by the remarkable zero-shot generalization capacity of
vision-language pre-trained model, we seek to leverage the supervision from
CLIP model to alleviate the burden of data labeling. However, such supervision
inevitably contains the label noise, which significantly degrades the
discriminative power of the classification model. In this work, we propose
Transductive CLIP, a novel framework for learning a classification network with
noisy labels from scratch. Firstly, a class-conditional contrastive learning
mechanism is proposed to mitigate the reliance on pseudo labels and boost the
tolerance to noisy labels. Secondly, ensemble labels is adopted as a pseudo
label updating strategy to stabilize the training of deep neural networks with
noisy labels. This framework can reduce the impact of noisy labels from CLIP
model effectively by combining both techniques. Experiments on multiple
benchmark datasets demonstrate the substantial improvements over other
state-of-the-art methods.",None,-1
1f73aa40-5bca-4890-9c62-6611c79b3996,Aligned Weight Regularizers for Pruning Pretrained Neural Networks,0.143807,"While various avenues of research have been explored for iterative pruning,
little is known what effect pruning has on zero-shot test performance and its
potential implications on the choice of pruning criteria. This pruning setup is
particularly important for cross-lingual models that implicitly learn alignment
between language representations during pretraining, which if distorted via
pruning, not only leads to poorer performance on language data used for
retraining but also on zero-shot languages that are evaluated.
  In this work, we show that there is a clear performance discrepancy in
magnitude-based pruning when comparing standard supervised learning to the
zero-shot setting. From this finding, we propose two weight regularizers that
aim to maximize the alignment between units of pruned and unpruned networks to
mitigate alignment distortion in pruned cross-lingual models and perform well
for both non zero-shot and zero-shot settings.
  We provide experimental results on cross-lingual tasks for the zero-shot
setting using XLM-RoBERTa$_{\mathrm{Base}}$, where we also find that pruning
has varying degrees of representational degradation depending on the language
corresponding to the zero-shot test set. This is also the first study that
focuses on cross-lingual language model compression.",None,-1
a9ac386b-687a-4098-af67-f9617ddf2d29,Covariance Matrix Adaptation MAP-Annealing,0.43636,"Single-objective optimization algorithms search for the single
highest-quality solution with respect to an objective. Quality diversity (QD)
optimization algorithms, such as Covariance Matrix Adaptation MAP-Elites
(CMA-ME), search for a collection of solutions that are both high-quality with
respect to an objective and diverse with respect to specified measure
functions. However, CMA-ME suffers from three major limitations highlighted by
the QD community: prematurely abandoning the objective in favor of exploration,
struggling to explore flat objectives, and having poor performance for
low-resolution archives. We propose a new quality diversity algorithm,
Covariance Matrix Adaptation MAP-Annealing (CMA-MAE), that addresses all three
limitations. We provide theoretical justifications for the new algorithm with
respect to each limitation. Our theory informs our experiments, which support
the theory and show that CMA-MAE achieves state-of-the-art performance and
robustness.",https://github.com/icaros-usc/pyribs,-1
7ade40ba-b2dd-4ef3-9c74-3ba009bf950e,Clear Memory-Augmented Auto-Encoder for Surface Defect Detection,0.219126,"In surface defect detection, due to the extreme imbalance in the number of
positive and negative samples, positive-samples-based anomaly detection methods
have received more and more attention. Specifically, reconstruction-based
methods are the most popular. However, existing methods are either difficult to
repair abnormal foregrounds or reconstruct clear backgrounds. Therefore, we
propose a clear memory-augmented auto-encoder (CMA-AE). At first, we propose a
novel clear memory-augmented module (CMAM), which combines the encoding and
memoryencoding in a way of forgetting and inputting, thereby repairing abnormal
foregrounds and preserving clear backgrounds. Secondly, a general artificial
anomaly generation algorithm (GAAGA) is proposed to simulate anomalies that are
as realistic and feature-rich as possible. At last, we propose a novel multi
scale feature residual detection method (MSFR) for defect segmentation, which
makes the defect location more accurate. Extensive comparison experiments
demonstrate that CMA-AE achieves state-of-the-art detection accuracy and shows
great potential in industrial applications.",None,-1
1a403a82-477d-4c01-85cf-8ac569789edf,An Adaptive Repeated-Intersection-Reduction Local Search for the Maximum Independent Set Problem,0.0966327,"The maximum independent set (MIS) problem, a classical NP-hard problem with
extensive applications in various areas, aims to find the largest set of
vertices with no edge among them. Due to its computational intractability, it
is difficult to solve the MIS problem effectively, especially on large graphs.
Employing heuristic approaches to obtain a good solution within an acceptable
amount of time has attracted much attention in literature. In this paper, we
propose an efficient local search framework for MIS called ARIR, which
encompasses two main parts: a lightweight adaptive mechanism and a novel
inexact efficient reduction rule to simplify instances. Based on ARIR, three
algorithms -- ARIR-I, ARIR-II, and ARIR-III -- are developed by adopting three
distinct reduction strategies. We conduct experiments on five benchmarks,
encompassing 92 instances. Compared with six state-of-the-art algorithms, our
ARIR-based algorithms offer the best accuracy on the majority of instances,
while obtaining competitive results on the remaining instances.",None,9354
d09d2e2c-4d43-468d-851d-1de465540b72,Prompt Distribution Learning,0.943454,"We present prompt distribution learning for effectively adapting a
pre-trained vision-language model to address downstream recognition tasks. Our
method not only learns low-bias prompts from a few samples but also captures
the distribution of diverse prompts to handle the varying visual
representations. In this way, we provide high-quality task-related content for
facilitating recognition. This prompt distribution learning is realized by an
efficient approach that learns the output embeddings of prompts instead of the
input embeddings. Thus, we can employ a Gaussian distribution to model them
effectively and derive a surrogate loss for efficient training. Extensive
experiments on 12 datasets demonstrate that our method consistently and
significantly outperforms existing methods. For example, with 1 sample per
category, it relatively improves the average result by 9.1% compared to
human-crafted prompts.",None,-1
ec243ca2-86e5-4ec3-81cd-aa8d728515e0,Accelerating Shapley Explanation via Contributive Cooperator Selection,0.619467,"Even though Shapley value provides an effective explanation for a DNN model
prediction, the computation relies on the enumeration of all possible input
feature coalitions, which leads to the exponentially growing complexity. To
address this problem, we propose a novel method SHEAR to significantly
accelerate the Shapley explanation for DNN models, where only a few coalitions
of input features are involved in the computation. The selection of the feature
coalitions follows our proposed Shapley chain rule to minimize the absolute
error from the ground-truth Shapley values, such that the computation can be
both efficient and accurate. To demonstrate the effectiveness, we
comprehensively evaluate SHEAR across multiple metrics including the absolute
error from the ground-truth Shapley value, the faithfulness of the
explanations, and running speed. The experimental results indicate SHEAR
consistently outperforms state-of-the-art baseline methods across different
evaluation metrics, which demonstrates its potentials in real-world
applications where the computational resource is limited.",https://github.com/guanchuwang/SHEAR,-1
85e887c9-3dc9-4a38-b9ac-b6fd1d063f15,Tensor-based Sequential Learning via Hankel Matrix Representation for Next Item Recommendations,0.147834,"Self-attentive transformer models have recently been shown to solve the next
item recommendation task very efficiently. The learned attention weights
capture sequential dynamics in user behavior and generalize well. Motivated by
the special structure of learned parameter space, we question if it is possible
to mimic it with an alternative and more lightweight approach. We develop a new
tensor factorization-based model that ingrains the structural knowledge about
sequential data within the learning process. We demonstrate how certain
properties of a self-attention network can be reproduced with our approach
based on special Hankel matrix representation. The resulting model has a
shallow linear architecture and compares competitively to its neural
counterpart.",https://github.com/recspert/SATF,-1
f8f2245a-df15-4820-8a01-e947e8a03651,Collateral facilitation in humans and language models,0.265666,"Are the predictions of humans and language models affected by similar things?
Research suggests that while comprehending language, humans make predictions
about upcoming words, with more predictable words being processed more easily.
However, evidence also shows that humans display a similar processing advantage
for highly anomalous words when these words are semantically related to the
preceding context or to the most probable continuation. Using stimuli from 3
psycholinguistic experiments, we find that this is also almost always also the
case for 8 contemporary transformer language models (BERT, ALBERT, RoBERTa,
XLM-R, GPT-2, GPT-Neo, GPT-J, and XGLM). We then discuss the implications of
this phenomenon for our understanding of both human language comprehension and
the predictions made by language models.",https://github.com/jmichaelov/collateral-facilitation,-1
8cfe56ae-30f4-44e1-8bdc-c8b593f74b99,Motron: Multimodal Probabilistic Human Motion Forecasting,0.693447,"Autonomous systems and humans are increasingly sharing the same space. Robots
work side by side or even hand in hand with humans to balance each other's
limitations. Such cooperative interactions are ever more sophisticated. Thus,
the ability to reason not just about a human's center of gravity position, but
also its granular motion is an important prerequisite for human-robot
interaction. Though, many algorithms ignore the multimodal nature of humans or
neglect uncertainty in their motion forecasts. We present Motron, a multimodal,
probabilistic, graph-structured model, that captures human's multimodality
using probabilistic methods while being able to output deterministic
maximum-likelihood motions and corresponding confidence values for each mode.
Our model aims to be tightly integrated with the robotic
planning-control-interaction loop; outputting physically feasible human motions
and being computationally efficient. We demonstrate the performance of our
model on several challenging real-world motion forecasting datasets,
outperforming a wide array of generative/variational methods while providing
state-of-the-art single-output motions if required. Both using significantly
less computational power than state-of-the art algorithms.",https://github.com/TUM-AAS/motron-cvpr22,-1
e4eacb7b-d272-47c4-b9db-67ed3f5ec883,EBOCA: Evidences for BiOmedical Concepts Association Ontology,0.476631,"There is a large number of online documents data sources available nowadays.
The lack of structure and the differences between formats are the main
difficulties to automatically extract information from them, which also has a
negative impact on its use and reuse. In the biomedical domain, the DISNET
platform emerged to provide researchers with a resource to obtain information
in the scope of human disease networks by means of large-scale heterogeneous
sources. Specifically in this domain, it is critical to offer not only the
information extracted from different sources, but also the evidence that
supports it. This paper proposes EBOCA, an ontology that describes (i)
biomedical domain concepts and associations between them, and (ii) evidences
supporting these associations; with the objective of providing an schema to
improve the publication and description of evidences and biomedical
associations in this domain. The ontology has been successfully evaluated to
ensure there are no errors, modelling pitfalls and that it meets the previously
defined functional requirements. Test data coming from a subset of DISNET and
automatic association extractions from texts has been transformed according to
the proposed ontology to create a Knowledge Graph that can be used in real
scenarios, and which has also been used for the evaluation of the presented
ontology.",None,-1
a0000a0f-a26d-4a0c-9a58-85c25075864a,Adaptive Model Predictive Control by Learning Classifiers,0.0541781,"Stochastic model predictive control has been a successful and robust control
framework for many robotics tasks where the system dynamics model is slightly
inaccurate or in the presence of environment disturbances. Despite the
successes, it is still unclear how to best adjust control parameters to the
current task in the presence of model parameter uncertainty and heteroscedastic
noise. In this paper, we propose an adaptive MPC variant that automatically
estimates control and model parameters by leveraging ideas from Bayesian
optimisation (BO) and the classical expected improvement acquisition function.
We leverage recent results showing that BO can be reformulated via density
ratio estimation, which can be efficiently approximated by simply learning a
classifier. This is then integrated into a model predictive path integral
control framework yielding robust controllers for a variety of challenging
robotics tasks. We demonstrate the approach on classical control problems under
model uncertainty and robotics manipulation tasks.",None,-1
5484159d-65cf-4c92-bfba-73bc719cb179,Earnings-22: A Practical Benchmark for Accents in the Wild,0.453664,"Modern automatic speech recognition (ASR) systems have achieved superhuman
Word Error Rate (WER) on many common corpora despite lacking adequate
performance on speech in the wild. Beyond that, there is a lack of real-world,
accented corpora to properly benchmark academic and commercial models. To
ensure this type of speech is represented in ASR benchmarking, we present
Earnings-22, a 125 file, 119 hour corpus of English-language earnings calls
gathered from global companies. We run a comparison across 4 commercial models
showing the variation in performance when taking country of origin into
consideration. Looking at hypothesis transcriptions, we explore errors common
to all ASR systems tested. By examining Individual Word Error Rate (IWER), we
find that key speech features impact model performance more for certain accents
than others. Earnings-22 provides a free-to-use benchmark of real-world,
accented audio to bridge academic and industrial research.",https://github.com/revdotcom/speech-datasets/tree/master/earnings22,-1
f8c3359e-7e3c-42ee-9d70-108c343eef58,Optimizing Data Collection for Machine Learning,0.864665,"Modern deep learning systems require huge data sets to achieve impressive
performance, but there is little guidance on how much or what kind of data to
collect. Over-collecting data incurs unnecessary present costs, while
under-collecting may incur future costs and delay workflows. We propose a new
paradigm for modeling the data collection workflow as a formal optimal data
collection problem that allows designers to specify performance targets,
collection costs, a time horizon, and penalties for failing to meet the
targets. Additionally, this formulation generalizes to tasks requiring multiple
data sources, such as labeled and unlabeled data used in semi-supervised
learning. To solve our problem, we develop Learn-Optimize-Collect (LOC), which
minimizes expected future collection costs. Finally, we numerically compare our
framework to the conventional baseline of estimating data requirements by
extrapolating from neural scaling laws. We significantly reduce the risks of
failing to meet desired performance targets on several classification,
segmentation, and detection tasks, while maintaining low total collection
costs.",None,-1
e346ed93-81b0-4ac8-b847-889c89e10db4,Cardinality-Regularized Hawkes-Granger Model,0.89356,"We propose a new sparse Granger-causal learning framework for temporal event
data. We focus on a specific class of point processes called the Hawkes
process. We begin by pointing out that most of the existing sparse causal
learning algorithms for the Hawkes process suffer from a singularity in maximum
likelihood estimation. As a result, their sparse solutions can appear only as
numerical artifacts. In this paper, we propose a mathematically well-defined
sparse causal learning framework based on a cardinality-regularized Hawkes
process, which remedies the pathological issues of existing approaches. We
leverage the proposed algorithm for the task of instance-wise causal event
analysis, where sparsity plays a critical role. We validate the proposed
framework with two real use-cases, one from the power grid and the other from
the cloud data center management domain.",https://github.com/iancovert/Neural-GC,-1
2abcce3f-09d1-4ef3-bf54-9c4cfeb758be,Toward More Meaningful Resources for Lower-resourced Languages,0.432334,"In this position paper, we describe our perspective on how meaningful
resources for lower-resourced languages should be developed in connection with
the speakers of those languages. We first examine two massively multilingual
resources in detail. We explore the contents of the names stored in Wikidata
for a few lower-resourced languages and find that many of them are not in fact
in the languages they claim to be and require non-trivial effort to correct. We
discuss quality issues present in WikiAnn and evaluate whether it is a useful
supplement to hand annotated data. We then discuss the importance of creating
annotation for lower-resourced languages in a thoughtful and ethical way that
includes the languages' speakers as part of the development process. We
conclude with recommended guidelines for resource development.",https://github.com/masakhane-io/masakhane-ner,867
26b4889b-49f3-4da5-a1da-ee74d9c9bc11,Learning to Reverse DNNs from AI Programs Automatically,0.702398,"With the privatization deployment of DNNs on edge devices, the security of
on-device DNNs has raised significant concern. To quantify the model leakage
risk of on-device DNNs automatically, we propose NNReverse, the first
learning-based method which can reverse DNNs from AI programs without domain
knowledge. NNReverse trains a representation model to represent the semantics
of binary code for DNN layers. By searching the most similar function in our
database, NNReverse infers the layer type of a given function's binary code. To
represent assembly instructions semantics precisely, NNReverse proposes a more
fine-grained embedding model to represent the textual and structural-semantic
of assembly functions.",None,-1
91b93f41-74b6-47a3-a42d-7a407cd3d157,Robustness to corruption in pre-trained Bayesian neural networks,0.196091,"We develop ShiftMatch, a new training-data-dependent likelihood for
robustness to corruption in Bayesian neural networks (BNNs). ShiftMatch is
inspired by the training-data-dependent ""EmpCov"" priors from Izmailov et al.
(2021a), and efficiently matches test-time spatial correlations to those at
training time. Critically, ShiftMatch is designed to leave the neural network's
training time likelihood unchanged, allowing it to use publicly available
samples from pre-trained BNNs. Using pre-trained HMC samples, ShiftMatch gives
strong performance improvements on CIFAR-10-C, outperforms EmpCov priors
(though ShiftMatch uses extra information from a minibatch of corrupted test
points), and is perhaps the first Bayesian method capable of convincingly
outperforming plain deep ensembles.",https://github.com/xidulu/ShiftMatch,-1
4ec19b66-8c12-4ec9-aa85-6c7f9cdc420e,Funnel-based Reward Shaping for Signal Temporal Logic Tasks in Reinforcement Learning,0.214496,"Signal Temporal Logic (STL) is a powerful framework for describing the
complex temporal and logical behaviour of the dynamical system. Numerous
studies have attempted to employ reinforcement learning to learn a controller
that enforces STL specifications; however, they have been unable to effectively
tackle the challenges of ensuring robust satisfaction in continuous state space
and maintaining tractability. In this paper, leveraging the concept of funnel
functions, we propose a tractable reinforcement learning algorithm to learn a
time-dependent policy for robust satisfaction of STL specification in
continuous state space. We demonstrate the utility of our approach on several
STL tasks using different environments.",None,-1
150d49b6-13b6-4e90-ae08-2cef3b38dcd4,Residual Swin Transformer Channel Attention Network for Image Demosaicing,0.448439,"Image demosaicing is problem of interpolating full- resolution color images
from raw sensor (color filter array) data. During last decade, deep neural
networks have been widely used in image restoration, and in particular, in
demosaicing, attaining significant performance improvement. In recent years,
vision transformers have been designed and successfully used in various
computer vision applications. One of the recent methods of image restoration
based on a Swin Transformer (ST), SwinIR, demonstrates state-of-the-art
performance with a smaller number of parameters than neural network-based
methods. Inspired by the success of SwinIR, we propose in this paper a novel
Swin Transformer-based network for image demosaicing, called RSTCANet. To
extract image features, RSTCANet stacks several residual Swin Transformer
Channel Attention blocks (RSTCAB), introducing the channel attention for each
two successive ST blocks. Extensive experiments demonstrate that RSTCANet out-
performs state-of-the-art image demosaicing methods, and has a smaller number
of parameters.",None,-1
651956c7-cc4b-4ffc-85a5-ea264dfa4f6f,Watching the News: Towards VideoQA Models that can Read,0.517116,"Video Question Answering methods focus on commonsense reasoning and visual
cognition of objects or persons and their interactions over time. Current
VideoQA approaches ignore the textual information present in the video.
Instead, we argue that textual information is complementary to the action and
provides essential contextualisation cues to the reasoning process. To this
end, we propose a novel VideoQA task that requires reading and understanding
the text in the video. To explore this direction, we focus on news videos and
require QA systems to comprehend and answer questions about the topics
presented by combining visual and textual cues in the video. We introduce the
``NewsVideoQA'' dataset that comprises more than $8,600$ QA pairs on $3,000+$
news videos obtained from diverse news channels from around the world. We
demonstrate the limitations of current Scene Text VQA and VideoQA methods and
propose ways to incorporate scene text information into VideoQA methods.",https://github.com/facebookresearch/mmf,-1
b149d9f7-e1d1-4749-953d-eae72dc1c72d,Synthetic Distracted Driving (SynDD2) dataset for analyzing distracted behaviors and various gaze zones of a driver,0.773011,"This article presents a synthetic distracted driving (SynDD2 - a continuum of
SynDD1) dataset for machine learning models to detect and analyze drivers'
various distracted behavior and different gaze zones. We collected the data in
a stationary vehicle using three in-vehicle cameras positioned at locations: on
the dashboard, near the rearview mirror, and on the top right-side window
corner. The dataset contains two activity types: distracted activities and gaze
zones for each participant, and each activity type has two sets: without
appearance blocks and with appearance blocks such as wearing a hat or
sunglasses. The order and duration of each activity for each participant are
random. In addition, the dataset contains manual annotations for each activity,
having its start and end time annotated. Researchers could use this dataset to
evaluate the performance of machine learning algorithms to classify various
distracting activities and gaze zones of drivers.",None,-1
21712c66-3a91-4fb7-ade1-63bcfafd54c3,Effidit: Your AI Writing Assistant,0.410136,"In this technical report, we introduce Effidit (Efficient and Intelligent
Editing), a digital writing assistant that facilitates users to write
higher-quality text more efficiently by using artificial intelligence (AI)
technologies. Previous writing assistants typically provide the function of
error checking (to detect and correct spelling and grammatical errors) and
limited text-rewriting functionality. With the emergence of large-scale neural
language models, some systems support automatically completing a sentence or a
paragraph. In Effidit, we significantly expand the capacities of a writing
assistant by providing functions in five categories: text completion, error
checking, text polishing, keywords to sentences (K2S), and cloud input methods
(cloud IME). In the text completion category, Effidit supports generation-based
sentence completion, retrieval-based sentence completion, and phrase
completion. In contrast, many other writing assistants so far only provide one
or two of the three functions. For text polishing, we have three functions:
(context-aware) phrase polishing, sentence paraphrasing, and sentence
expansion, whereas many other writing assistants often support one or two
functions in this category. The main contents of this report include major
modules of Effidit, methods for implementing these modules, and evaluation
results of some key methods.",https://github.com/facebookresearch/unlikelihood_training,-1
9fff456f-6ef7-4fe4-b504-a48a40d0b381,Reducing the Vision and Language Bias for Temporal Sentence Grounding,0.869615,"Temporal sentence grounding (TSG) is an important yet challenging task in
multimedia information retrieval. Although previous TSG methods have achieved
decent performance, they tend to capture the selection biases of frequently
appeared video-query pairs in the dataset rather than present robust multimodal
reasoning abilities, especially for the rarely appeared pairs. In this paper,
we study the above issue of selection biases and accordingly propose a
Debiasing-TSG (D-TSG) model to filter and remove the negative biases in both
vision and language modalities for enhancing the model generalization ability.
Specifically, we propose to alleviate the issue from two perspectives: 1)
Feature distillation. We built a multi-modal debiasing branch to firstly
capture the vision and language biases, and then apply a bias identification
module to explicitly recognize the true negative biases and remove them from
the benign multi-modal representations. 2) Contrastive sample generation. We
construct two types of negative samples to enforce the model to accurately
learn the aligned multi-modal semantics and make complete semantic reasoning.
We apply the proposed model to both commonly and rarely appeared TSG cases, and
demonstrate its effectiveness by achieving the state-of-the-art performance on
three benchmark datasets (ActivityNet Caption, TACoS, and Charades-STA).",None,-1
76df7637-2162-4d12-bf51-2f80ad2ba3af,Target-Driven Structured Transformer Planner for Vision-Language Navigation,0.525488,"Vision-language navigation is the task of directing an embodied agent to
navigate in 3D scenes with natural language instructions. For the agent,
inferring the long-term navigation target from visual-linguistic clues is
crucial for reliable path planning, which, however, has rarely been studied
before in literature. In this article, we propose a Target-Driven Structured
Transformer Planner (TD-STP) for long-horizon goal-guided and room layout-aware
navigation. Specifically, we devise an Imaginary Scene Tokenization mechanism
for explicit estimation of the long-term target (even located in unexplored
environments). In addition, we design a Structured Transformer Planner which
elegantly incorporates the explored room layout into a neural attention
architecture for structured and global planning. Experimental results
demonstrate that our TD-STP substantially improves previous best methods'
success rate by 2% and 5% on the test set of R2R and REVERIE benchmarks,
respectively. Our code is available at https://github.com/YushengZhao/TD-STP .",https://github.com/YushengZhao/TD-STP,-1
6591f763-8ff8-4e41-83c1-f8fda5c6a407,An Effective Iterated Two-stage Heuristic Algorithm for the Multiple Traveling Salesmen Problem,0.515148,"The multiple Traveling Salesmen Problem (mTSP) is a general extension of the
famous NP-hard Traveling Salesmen Problem (TSP), that there are m (m > 1)
salesmen to visit the cities. In this paper, we address the mTSP with both the
minsum objective and minmax objective, which aims at minimizing the total
length of the $m$ tours and the length of the longest tour among all the m
tours, respectively. We propose an iterated two-stage heuristic algorithm
called ITSHA for the mTSP. Each iteration of ITSHA consists of an
initialization stage and an improvement stage. The initialization stage aims to
generate high-quality and diverse initial solutions. The improvement stage
mainly applies the variable neighborhood search (VNS) approach based on our
proposed effective local search neighborhoods to optimize the initial solution.
Moreover, some local optima escaping approaches are employed to enhance the
search ability of the algorithm. Extensive experimental results on a wide range
of public benchmark instances show that ITSHA significantly outperforms the
state-of-the-art heuristic algorithms in solving the mTSP on both the
objectives.",None,-1
d14518ad-9445-4b20-b504-bb15924e446e,Bayesian Optimization under Stochastic Delayed Feedback,0.685853,"Bayesian optimization (BO) is a widely-used sequential method for
zeroth-order optimization of complex and expensive-to-compute black-box
functions. The existing BO methods assume that the function evaluation
(feedback) is available to the learner immediately or after a fixed delay. Such
assumptions may not be practical in many real-life problems like online
recommendations, clinical trials, and hyperparameter tuning where feedback is
available after a random delay. To benefit from the experimental
parallelization in these problems, the learner needs to start new function
evaluations without waiting for delayed feedback. In this paper, we consider
the BO under stochastic delayed feedback problem. We propose algorithms with
sub-linear regret guarantees that efficiently address the dilemma of selecting
new function queries while waiting for randomly delayed feedback. Building on
our results, we also make novel contributions to batch BO and contextual
Gaussian process bandits. Experiments on synthetic and real-life datasets
verify the performance of our algorithms.",https://github.com/daizhongxiang/BO-SDF,-1
303454c6-9d04-4c7f-a8d0-0b0f83d6f9a8,Turbo Training with Token Dropout,0.199249,"The objective of this paper is an efficient training method for video tasks.
We make three contributions: (1) We propose Turbo training, a simple and
versatile training paradigm for Transformers on multiple video tasks. (2) We
illustrate the advantages of Turbo training on action classification,
video-language representation learning, and long-video activity classification,
showing that Turbo training can largely maintain competitive performance while
achieving almost 4X speed-up and significantly less memory consumption. (3)
Turbo training enables long-schedule video-language training and end-to-end
long-video training, delivering competitive or superior performance than
previous works, which were infeasible to train under limited resources.",https://www.robots.ox.ac.uk/~vgg/research/turbo/,-1
8cf53e97-7fe9-4d9c-95da-9f058fad8fad,Probabilistic Representations for Video Contrastive Learning,0.716789,"This paper presents Probabilistic Video Contrastive Learning, a
self-supervised representation learning method that bridges contrastive
learning with probabilistic representation. We hypothesize that the clips
composing the video have different distributions in short-term duration, but
can represent the complicated and sophisticated video distribution through
combination in a common embedding space. Thus, the proposed method represents
video clips as normal distributions and combines them into a Mixture of
Gaussians to model the whole video distribution. By sampling embeddings from
the whole video distribution, we can circumvent the careful sampling strategy
or transformations to generate augmented views of the clips, unlike previous
deterministic methods that have mainly focused on such sample generation
strategies for contrastive learning. We further propose a stochastic
contrastive loss to learn proper video distributions and handle the inherent
uncertainty from the nature of the raw video. Experimental results verify that
our probabilistic embedding stands as a state-of-the-art video representation
learning for action recognition and video retrieval on the most popular
benchmarks, including UCF101 and HMDB51.",None,-1
1ab90e46-6eed-4c5c-85f1-30c8f1c38891,Extreme Compression for Pre-trained Transformers Made Simple and Efficient,0.69133,"Extreme compression, particularly ultra-low bit precision (binary/ternary)
quantization, has been proposed to fit large NLP models on resource-constraint
devices. However, to preserve the accuracy for such aggressive compression
schemes, cutting-edge methods usually introduce complicated compression
pipelines, e.g., multi-stage expensive knowledge distillation with extensive
hyperparameter tuning. Also, they oftentimes focus less on smaller transformer
models that have already been heavily compressed via knowledge distillation and
lack a systematic study to show the effectiveness of their methods. In this
paper, we perform a very comprehensive systematic study to measure the impact
of many key hyperparameters and training strategies from previous works. As a
result, we find out that previous baselines for ultra-low bit precision
quantization are significantly under-trained. Based on our study, we propose a
simple yet effective compression pipeline for extreme compression, named XTC.
XTC demonstrates that (1) we can skip the pre-training knowledge distillation
to obtain a 5-layer BERT while achieving better performance than previous
state-of-the-art methods, e.g., the 6-layer TinyBERT; (2) extreme quantization
plus layer reduction is able to reduce the model size by 50x, resulting in new
state-of-the-art results on GLUE tasks.",https://github.com/microsoft/DeepSpeed,7580
52c7a82b-c293-485e-9baf-9e252d194c52,Chasing Streams with Existential Rules,0.0473641,"We study reasoning with existential rules to perform query answering over
streams of data. On static databases, this problem has been widely studied, but
its extension to rapidly changing data has not yet been considered. To bridge
this gap, we extend LARS, a well-known framework for rule-based stream
reasoning, to support existential rules. For that, we show how to translate
LARS with existentials into a semantics-preserving set of existential rules. As
query answering with such rules is undecidable in general, we describe how to
leverage the temporal nature of streams and present suitable notions of
acyclicity that ensure decidability.",https://github.com/karmaresearch/elars,-1
9b6e1656-918d-4b43-9a4a-5736765169da,Finding Dataset Shortcuts with Grammar Induction,0.43653,"Many NLP datasets have been found to contain shortcuts: simple decision rules
that achieve surprisingly high accuracy. However, it is difficult to discover
shortcuts automatically. Prior work on automatic shortcut detection has focused
on enumerating features like unigrams or bigrams, which can find only low-level
shortcuts, or relied on post-hoc model interpretability methods like saliency
maps, which reveal qualitative patterns without a clear statistical
interpretation. In this work, we propose to use probabilistic grammars to
characterize and discover shortcuts in NLP datasets. Specifically, we use a
context-free grammar to model patterns in sentence classification datasets and
use a synchronous context-free grammar to model datasets involving sentence
pairs. The resulting grammars reveal interesting shortcut features in a number
of datasets, including both simple and high-level features, and automatically
identify groups of test examples on which conventional classifiers fail.
Finally, we show that the features we discover can be used to generate
diagnostic contrast examples and incorporated into standard robust optimization
methods to improve worst-group accuracy.",https://github.com/princeton-nlp/ShortcutGrammar,-1
65f5fb87-9c57-4464-bc0d-6c3dc3cb81c7,PEANUT: Predicting and Navigating to Unseen Targets,0.504914,"Efficient ObjectGoal navigation (ObjectNav) in novel environments requires an
understanding of the spatial and semantic regularities in environment layouts.
In this work, we present a straightforward method for learning these
regularities by predicting the locations of unobserved objects from incomplete
semantic maps. Our method differs from previous prediction-based navigation
methods, such as frontier potential prediction or egocentric map completion, by
directly predicting unseen targets while leveraging the global context from all
previously explored areas. Our prediction model is lightweight and can be
trained in a supervised manner using a relatively small amount of passively
collected data. Once trained, the model can be incorporated into a modular
pipeline for ObjectNav without the need for any reinforcement learning. We
validate the effectiveness of our method on the HM3D and MP3D ObjectNav
datasets. We find that it achieves the state-of-the-art on both datasets,
despite not using any additional data for training.",https://github.com/open-mmlab/mmsegmentation,-1
adfc6fd8-2410-4417-a074-98247afde9e3,TransBoost: Improving the Best ImageNet Performance using Deep Transduction,0.0220703,"This paper deals with deep transductive learning, and proposes TransBoost as
a procedure for fine-tuning any deep neural model to improve its performance on
any (unlabeled) test set provided at training time. TransBoost is inspired by a
large margin principle and is efficient and simple to use. Our method
significantly improves the ImageNet classification performance on a wide range
of architectures, such as ResNets, MobileNetV3-L, EfficientNetB0, ViT-S, and
ConvNext-T, leading to state-of-the-art transductive performance. Additionally
we show that TransBoost is effective on a wide variety of image classification
datasets. The implementation of TransBoost is provided at:
https://github.com/omerb01/TransBoost .",https://github.com/omerb01/TransBoost,-1
d5ad5d32-2ae8-454c-aedc-cb642cacb10e,Power of Explanations: Towards automatic debiasing in hate speech detection,0.20941,"Hate speech detection is a common downstream application of natural language
processing (NLP) in the real world. In spite of the increasing accuracy,
current data-driven approaches could easily learn biases from the imbalanced
data distributions originating from humans. The deployment of biased models
could further enhance the existing social biases. But unlike handling tabular
data, defining and mitigating biases in text classifiers, which deal with
unstructured data, are more challenging. A popular solution for improving
machine learning fairness in NLP is to conduct the debiasing process with a
list of potentially discriminated words given by human annotators. In addition
to suffering from the risks of overlooking the biased terms, exhaustively
identifying bias with human annotators are unsustainable since discrimination
is variable among different datasets and may evolve over time. To this end, we
propose an automatic misuse detector (MiD) relying on an explanation method for
detecting potential bias. And built upon that, an end-to-end debiasing
framework with the proposed staged correction is designed for text classifiers
without any external resources required.",https://github.com/caiy0220/PoE,-1
e5c12bc4-0a59-47c7-8c82-12558138cde2,Towards Improved Room Impulse Response Estimation for Speech Recognition,0.983455,"We propose a novel approach for blind room impulse response (RIR) estimation
systems in the context of a downstream application scenario, far-field
automatic speech recognition (ASR). We first draw the connection between
improved RIR estimation and improved ASR performance, as a means of evaluating
neural RIR estimators. We then propose a generative adversarial network (GAN)
based architecture that encodes RIR features from reverberant speech and
constructs an RIR from the encoded features, and uses a novel energy decay
relief loss to optimize for capturing energy-based properties of the input
reverberant speech. We show that our model outperforms the state-of-the-art
baselines on acoustic benchmarks (by 17\% on the energy decay relief and 22\%
on an early-reflection energy metric), as well as in an ASR evaluation task (by
6.9\% in word error rate).",https://github.com/RoyJames/kaldi-reverb/,-1
b50e3a46-79f3-45f5-9bf7-cbeb687a5e92,Monte Carlo Tree Search based Variable Selection for High Dimensional Bayesian Optimization,0.806896,"Bayesian optimization (BO) is a class of popular methods for expensive
black-box optimization, and has been widely applied to many scenarios. However,
BO suffers from the curse of dimensionality, and scaling it to high-dimensional
problems is still a challenge. In this paper, we propose a variable selection
method MCTS-VS based on Monte Carlo tree search (MCTS), to iteratively select
and optimize a subset of variables. That is, MCTS-VS constructs a
low-dimensional subspace via MCTS and optimizes in the subspace with any BO
algorithm. We give a theoretical analysis of the general variable selection
method to reveal how it can work. Experiments on high-dimensional synthetic
functions and real-world problems (i.e., NAS-bench problems and MuJoCo
locomotion tasks) show that MCTS-VS equipped with a proper BO optimizer can
achieve state-of-the-art performance.",https://github.com/lamda-bbo/MCTS-VS,-1
7a8a5899-9d81-4686-8007-7819cc21d34b,OpenEarthMap: A Benchmark Dataset for Global High-Resolution Land Cover Mapping,0.986037,"We introduce OpenEarthMap, a benchmark dataset, for global high-resolution
land cover mapping. OpenEarthMap consists of 2.2 million segments of 5000
aerial and satellite images covering 97 regions from 44 countries across 6
continents, with manually annotated 8-class land cover labels at a 0.25--0.5m
ground sampling distance. Semantic segmentation models trained on the
OpenEarthMap generalize worldwide and can be used as off-the-shelf models in a
variety of applications. We evaluate the performance of state-of-the-art
methods for unsupervised domain adaptation and present challenging problem
settings suitable for further technical development. We also investigate
lightweight models using automated neural architecture search for limited
computational resources and fast mapping. The dataset is available at
https://open-earth-map.org.",None,-1
5622bd10-fe98-485d-a72e-f98ded330e2e,Speech Segmentation Optimization using Segmented Bilingual Speech Corpus for End-to-end Speech Translation,0.365894,"Speech segmentation, which splits long speech into short segments, is
essential for speech translation (ST). Popular VAD tools like WebRTC VAD have
generally relied on pause-based segmentation. Unfortunately, pauses in speech
do not necessarily match sentence boundaries, and sentences can be connected by
a very short pause that is difficult to detect by VAD. In this study, we
propose a speech segmentation method using a binary classification model
trained using a segmented bilingual speech corpus. We also propose a hybrid
method that combines VAD and the above speech segmentation method. Experimental
results revealed that the proposed method is more suitable for cascade and
end-to-end ST systems than conventional segmentation methods. The hybrid
approach further improved the translation performance.",https://github.com/wiseman/py-webrtcvad,-1
cceac6cc-8a49-4ea9-aa19-8b448655490b,Identifying Weaknesses in Machine Translation Metrics Through Minimum Bayes Risk Decoding: A Case Study for COMET,0.801211,"Neural metrics have achieved impressive correlation with human judgements in
the evaluation of machine translation systems, but before we can safely
optimise towards such metrics, we should be aware of (and ideally eliminate)
biases toward bad translations that receive high scores. Our experiments show
that sample-based Minimum Bayes Risk decoding can be used to explore and
quantify such weaknesses. When applying this strategy to COMET for en-de and
de-en, we find that COMET models are not sensitive enough to discrepancies in
numbers and named entities. We further show that these biases are hard to fully
remove by simply training on additional synthetic data and release our code and
data for facilitating further experiments.",https://github.com/Unbabel/COMET,-1
4a6be4fa-463a-499d-87b7-19a1a4854d59,Deepfake Video Detection with Spatiotemporal Dropout Transformer,0.716289,"While the abuse of deepfake technology has caused serious concerns recently,
how to detect deepfake videos is still a challenge due to the high
photo-realistic synthesis of each frame. Existing image-level approaches often
focus on single frame and ignore the spatiotemporal cues hidden in deepfake
videos, resulting in poor generalization and robustness. The key of a
video-level detector is to fully exploit the spatiotemporal inconsistency
distributed in local facial regions across different frames in deepfake videos.
Inspired by that, this paper proposes a simple yet effective patch-level
approach to facilitate deepfake video detection via spatiotemporal dropout
transformer. The approach reorganizes each input video into bag of patches that
is then fed into a vision transformer to achieve robust representation.
Specifically, a spatiotemporal dropout operation is proposed to fully explore
patch-level spatiotemporal cues and serve as effective data augmentation to
further enhance model's robustness and generalization ability. The operation is
flexible and can be easily plugged into existing vision transformers. Extensive
experiments demonstrate the effectiveness of our approach against 25
state-of-the-arts with impressive robustness, generalizability, and
representation ability.",https://github.com/MarekKowalski/FaceSwap/,-1
7c0d77c8-d1ae-4704-9b8c-d7d9e5b7dafd,Directed Acyclic Transformer for Non-Autoregressive Machine Translation,0.982786,"Non-autoregressive Transformers (NATs) significantly reduce the decoding
latency by generating all tokens in parallel. However, such independent
predictions prevent NATs from capturing the dependencies between the tokens for
generating multiple possible translations. In this paper, we propose Directed
Acyclic Transfomer (DA-Transformer), which represents the hidden states in a
Directed Acyclic Graph (DAG), where each path of the DAG corresponds to a
specific translation. The whole DAG simultaneously captures multiple
translations and facilitates fast predictions in a non-autoregressive fashion.
Experiments on the raw training data of WMT benchmark show that DA-Transformer
substantially outperforms previous NATs by about 3 BLEU on average, which is
the first NAT model that achieves competitive results with autoregressive
Transformers without relying on knowledge distillation.",None,-1
30ec786b-b0da-4dd0-9750-9987bf1b480e,State Space Closure: Revisiting Endless Online Level Generation via Reinforcement Learning,0.286084,"In this paper, we revisit endless online level generation with the recently
proposed experience-driven procedural content generation via reinforcement
learning (EDRL) framework. Inspired by an observation that EDRL tends to
generate recurrent patterns, we formulate a notion of state space closure which
makes any stochastic state appeared possibly in an infinite-horizon online
generation process can be found within a finite-horizon. Through theoretical
analysis, we find that even though state space closure arises a concern about
diversity, it generalises EDRL trained with a finite-horizon to the
infinite-horizon scenario without deterioration of content quality. Moreover,
we verify the quality and the diversity of contents generated by EDRL via
empirical studies, on the widely used Super Mario Bros. benchmark. Experimental
results reveal that the diversity of levels generated by EDRL is limited due to
the state space closure, whereas their quality does not deteriorate in a
horizon which is longer than the one specified in the training. Concluding our
outcomes and analysis, future work on endless online level generation via
reinforcement learning should address the issue of diversity while assuring the
occurrence of state space closure and quality.",https://github.com/SUSTechGameAI/MFEDRL,1829
63acf935-f064-4611-909f-fbc18a310e7e,Neural Topic Modeling of Psychotherapy Sessions,0.488786,"In this work, we compare different neural topic modeling methods in learning
the topical propensities of different psychiatric conditions from the
psychotherapy session transcripts parsed from speech recordings. We also
incorporate temporal modeling to put this additional interpretability to action
by parsing out topic similarities as a time series in a turn-level resolution.
We believe this topic modeling framework can offer interpretable insights for
the therapist to optimally decide his or her strategy and improve psychotherapy
effectiveness.",https://github.com/zll17/Neural Topic Models,-1
daff3120-20bd-4d08-a79a-8843e0456054,Stain Isolation-based Guidance for Improved Stain Translation,0.568289,"Unsupervised and unpaired domain translation using generative adversarial
neural networks, and more precisely CycleGAN, is state of the art for the stain
translation of histopathology images. It often, however, suffers from the
presence of cycle-consistent but non structure-preserving errors. We propose an
alternative approach to the set of methods which, relying on segmentation
consistency, enable the preservation of pathology structures. Focusing on
immunohistochemistry (IHC) and multiplexed immunofluorescence (mIF), we
introduce a simple yet effective guidance scheme as a loss function that
leverages the consistency of stain translation with stain isolation.
Qualitative and quantitative experiments show the ability of the proposed
approach to improve translation between the two domains.",None,-1
5f082014-c33b-44cd-b959-049d2d191b3e,Fast Point Cloud Generation with Straight Flows,0.708762,"Diffusion models have emerged as a powerful tool for point cloud generation.
A key component that drives the impressive performance for generating
high-quality samples from noise is iteratively denoise for thousands of steps.
While beneficial, the complexity of learning steps has limited its applications
to many 3D real-world. To address this limitation, we propose Point Straight
Flow (PSF), a model that exhibits impressive performance using one step. Our
idea is based on the reformulation of the standard diffusion model, which
optimizes the curvy learning trajectory into a straight path. Further, we
develop a distillation strategy to shorten the straight path into one step
without a performance loss, enabling applications to 3D real-world with latency
constraints. We perform evaluations on multiple 3D tasks and find that our PSF
performs comparably to the standard diffusion model, outperforming other
efficient 3D point cloud generation methods. On real-world applications such as
point cloud completion and training-free text-guided generation in a
low-latency setup, PSF performs favorably.",None,-1
abd138d0-6a7d-487f-a6e1-c645be613e22,Self-supervised Learning for Unintentional Action Prediction,0.142217,"Distinguishing if an action is performed as intended or if an intended action
fails is an important skill that not only humans have, but that is also
important for intelligent systems that operate in human environments.
Recognizing if an action is unintentional or anticipating if an action will
fail, however, is not straightforward due to lack of annotated data. While
videos of unintentional or failed actions can be found in the Internet in
abundance, high annotation costs are a major bottleneck for learning networks
for these tasks. In this work, we thus study the problem of self-supervised
representation learning for unintentional action prediction. While previous
works learn the representation based on a local temporal neighborhood, we show
that the global context of a video is needed to learn a good representation for
the three downstream tasks: unintentional action classification, localization
and anticipation. In the supplementary material, we show that the learned
representation can be used for detecting anomalies in videos as well.",None,-1
3ac91ebe-1e4a-4e52-bf31-7c2d3cc058a9,A-NeSI: A Scalable Approximate Method for Probabilistic Neurosymbolic Inference,0.489696,"We study the problem of combining neural networks with symbolic reasoning.
Recently introduced frameworks for Probabilistic Neurosymbolic Learning (PNL),
such as DeepProbLog, perform exponential-time exact inference, limiting the
scalability of PNL solutions. We introduce Approximate Neurosymbolic Inference
(A-NeSI): a new framework for PNL that uses neural networks for scalable
approximate inference. A-NeSI 1) performs approximate inference in polynomial
time without changing the semantics of probabilistic logics; 2) is trained
using data generated by the background knowledge; 3) can generate symbolic
explanations of predictions; and 4) can guarantee the satisfaction of logical
constraints at test time, which is vital in safety-critical applications. Our
experiments show that A-NeSI is the first end-to-end method to solve three
neurosymbolic tasks with exponential combinatorial scaling. Finally, our
experiments show that A-NeSI achieves explainability and safety without a
penalty in performance.",https://github.com/HEmile/a-nesi,40025
82533b04-cc6d-493f-9bb7-bff283076c39,Improving Iterative Text Revision by Learning Where to Edit from Other Revision Tasks,0.712479,"Iterative text revision improves text quality by fixing grammatical errors,
rephrasing for better readability or contextual appropriateness, or
reorganizing sentence structures throughout a document. Most recent research
has focused on understanding and classifying different types of edits in the
iterative revision process from human-written text instead of building accurate
and robust systems for iterative text revision. In this work, we aim to build
an end-to-end text revision system that can iteratively generate helpful edits
by explicitly detecting editable spans (where-to-edit) with their corresponding
edit intents and then instructing a revision model to revise the detected edit
spans. Leveraging datasets from other related text editing NLP tasks, combined
with the specification of editable spans, leads our system to more accurately
model the process of iterative text refinement, as evidenced by empirical
results and human evaluations. Our system significantly outperforms previous
baselines on our text revision tasks and other standard text revision tasks,
including grammatical error correction, text simplification, sentence fusion,
and style transfer. Through extensive qualitative and quantitative analysis, we
make vital connections between edit intentions and writing quality, and better
computational modeling of iterative text revisions.",https://github.com/vipulraheja/iterater,-1
151ea524-5fc3-445a-a554-5d76bf2ea776,DecBERT: Enhancing the Language Understanding of BERT with Causal Attention Masks,0.0451114,"Since 2017, the Transformer-based models play critical roles in various
downstream Natural Language Processing tasks. However, a common limitation of
the attention mechanism utilized in Transformer Encoder is that it cannot
automatically capture the information of word order, so explicit position
embeddings are generally required to be fed into the target model. In contrast,
Transformer Decoder with the causal attention masks is naturally sensitive to
the word order. In this work, we focus on improving the position encoding
ability of BERT with the causal attention masks. Furthermore, we propose a new
pre-trained language model DecBERT and evaluate it on the GLUE benchmark.
Experimental results show that (1) the causal attention mask is effective for
BERT on the language understanding tasks; (2) our DecBERT model without
position embeddings achieve comparable performance on the GLUE benchmark; and
(3) our modification accelerates the pre-training process and DecBERT w/ PE
achieves better overall performance than the baseline systems when pre-training
with the same amount of computational resources.",None,-1
e70f1af2-958d-464e-aa68-491b8df9bec6,Emotion detection of social data: APIs comparative study,0.368082,"The development of emotion detection technology has emerged as a highly
valuable possibility in the corporate sector due to the nearly limitless uses
of this new discipline, particularly with the unceasing propagation of social
data. In recent years, the electronic marketplace has witnessed the
establishment of a large number of start-up businesses with an almost sole
focus on building new commercial and open-source tools and APIs for emotion
detection and recognition. Yet, these tools and APIs must be continuously
reviewed and evaluated, and their performances should be reported and
discussed. There is a lack of research to empirically compare current emotion
detection technologies in terms of the results obtained from each model using
the same textual dataset. Also, there is a lack of comparative studies that
apply benchmark comparison to social data. This study compares eight
technologies; IBM Watson NLU, ParallelDots, Symanto-Ekman, Crystalfeel, Text to
Emotion, Senpy, Textprobe, and NLP Cloud. The comparison was undertaken using
two different datasets. The emotions from the chosen datasets were then derived
using the incorporated APIs. The performance of these APIs was assessed using
the aggregated scores that they delivered as well as the theoretically proven
evaluation metrics such as the micro-average of accuracy, classification error,
precision, recall, and f1-score. Lastly, the assessment of these APIs
incorporating the evaluation measures is reported and discussed.",None,-1
3f23ceae-c576-42dc-ae82-74ecc04722d4,Online Auction-Based Incentive Mechanism Design for Horizontal Federated Learning with Budget Constraint,0.255587,"Federated learning makes it possible for all parties with data isolation to
train the model collaboratively and efficiently while satisfying privacy
protection. To obtain a high-quality model, an incentive mechanism is necessary
to motivate more high-quality workers with data and computing power. The
existing incentive mechanisms are applied in offline scenarios, where the task
publisher collects all bids and selects workers before the task. However, it is
practical that different workers arrive online in different orders before or
during the task. Therefore, we propose a reverse auction-based online incentive
mechanism for horizontal federated learning with budget constraint. Workers
submit bids when they arrive online. The task publisher with a limited budget
leverages the information of the arrived workers to decide on whether to select
the new worker. Theoretical analysis proves that our mechanism satisfies budget
feasibility, computational efficiency, individual rationality, consumer
sovereignty, time truthfulness, and cost truthfulness with a sufficient budget.
The experimental results show that our online mechanism is efficient and can
obtain high-quality models.",None,49
a341ad76-41f3-4a50-a4ea-cf46305f2777,Practical Deepfake Detection: Vulnerabilities in Global Contexts,0.0357506,"Recent advances in deep learning have enabled realistic digital alterations
to videos, known as deepfakes. This technology raises important societal
concerns regarding disinformation and authenticity, galvanizing the development
of numerous deepfake detection algorithms. At the same time, there are
significant differences between training data and in-the-wild video data, which
may undermine their practical efficacy. We simulate data corruption techniques
and examine the performance of a state-of-the-art deepfake detection algorithm
on corrupted variants of the FaceForensics++ dataset.
  While deepfake detection models are robust against video corruptions that
align with training-time augmentations, we find that they remain vulnerable to
video corruptions that simulate decreases in video quality. Indeed, in the
controversial case of the video of Gabonese President Bongo's new year address,
the algorithm, which confidently authenticates the original video, judges
highly corrupted variants of the video to be fake. Our work opens up both
technical and ethical avenues of exploration into practical deepfake detection
in global contexts.",https://github.com/deepfakes/faceswap,-1
416d6687-a08a-4556-b592-f2908a031c0f,TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving,0.999975,"How should we integrate representations from complementary sensors for
autonomous driving? Geometry-based fusion has shown promise for perception
(e.g. object detection, motion forecasting). However, in the context of
end-to-end driving, we find that imitation learning based on existing sensor
fusion methods underperforms in complex driving scenarios with a high density
of dynamic agents. Therefore, we propose TransFuser, a mechanism to integrate
image and LiDAR representations using self-attention. Our approach uses
transformer modules at multiple resolutions to fuse perspective view and bird's
eye view feature maps. We experimentally validate its efficacy on a challenging
new benchmark with long routes and dense traffic, as well as the official
leaderboard of the CARLA urban driving simulator. At the time of submission,
TransFuser outperforms all prior work on the CARLA leaderboard in terms of
driving score by a large margin. Compared to geometry-based fusion, TransFuser
reduces the average collisions per kilometer by 48%.",https://github.com/autonomousvision/transfuser,-1
7b651287-a98f-4047-aee9-88f3700ab6d1,Monitoring Diversity of AI Conferences: Lessons Learnt and Future Challenges in the DivinAI Project,0.0550487,"DivinAI is an open and collaborative initiative promoted by the European
Commission's Joint Research Centre to measure and monitor diversity indicators
related to AI conferences, with special focus on gender balance, geographical
representation, and presence of academia vs companies. This paper summarizes
the main achievements and lessons learnt during the first year of life of the
DivinAI project, and proposes a set of recommendations for its further
development and maintenance by the AI community.",None,-1
c6b71491-7ab6-4149-81d0-145941a82bec,Are AlphaZero-like Agents Robust to Adversarial Perturbations?,0.519085,"The success of AlphaZero (AZ) has demonstrated that neural-network-based Go
AIs can surpass human performance by a large margin. Given that the state space
of Go is extremely large and a human player can play the game from any legal
state, we ask whether adversarial states exist for Go AIs that may lead them to
play surprisingly wrong actions. In this paper, we first extend the concept of
adversarial examples to the game of Go: we generate perturbed states that are
``semantically'' equivalent to the original state by adding meaningless moves
to the game, and an adversarial state is a perturbed state leading to an
undoubtedly inferior action that is obvious even for Go beginners. However,
searching the adversarial state is challenging due to the large, discrete, and
non-differentiable search space. To tackle this challenge, we develop the first
adversarial attack on Go AIs that can efficiently search for adversarial states
by strategically reducing the search space. This method can also be extended to
other board games such as NoGo. Experimentally, we show that the actions taken
by both Policy-Value neural network (PV-NN) and Monte Carlo tree search (MCTS)
can be misled by adding one or two meaningless stones; for example, on 58\% of
the AlphaGo Zero self-play games, our method can make the widely used KataGo
agent with 50 simulations of MCTS plays a losing action by adding two
meaningless stones. We additionally evaluated the adversarial examples found by
our algorithm with amateur human Go players and 90\% of examples indeed lead
the Go agent to play an obviously inferior action. Our code is available at
\url{https://PaperCode.cc/GoAttack}.",https://PaperCode.cc/GoAttack,-1
956db933-53d6-4afd-8d81-8106b360c28f,DEMETR: Diagnosing Evaluation Metrics for Translation,0.856547,"While machine translation evaluation metrics based on string overlap (e.g.,
BLEU) have their limitations, their computations are transparent: the BLEU
score assigned to a particular candidate translation can be traced back to the
presence or absence of certain words. The operations of newer learned metrics
(e.g., BLEURT, COMET), which leverage pretrained language models to achieve
higher correlations with human quality judgments than BLEU, are opaque in
comparison. In this paper, we shed light on the behavior of these learned
metrics by creating DEMETR, a diagnostic dataset with 31K English examples
(translated from 10 source languages) for evaluating the sensitivity of MT
evaluation metrics to 35 different linguistic perturbations spanning semantic,
syntactic, and morphological error categories. All perturbations were carefully
designed to form minimal pairs with the actual translation (i.e., differ in
only one aspect). We find that learned metrics perform substantially better
than string-based metrics on DEMETR. Additionally, learned metrics differ in
their sensitivity to various phenomena (e.g., BERTScore is sensitive to
untranslated words but relatively insensitive to gender manipulation, while
COMET is much more sensitive to word repetition than to aspectual changes). We
publicly release DEMETR to spur more informed future development of machine
translation evaluation metrics",https://github.com/marzenakrp/demetr,-1
082d3fac-442c-4868-9fc3-0ae7ed4212bf,RuArg-2022: Argument Mining Evaluation,0.425209,"Argumentation analysis is a field of computational linguistics that studies
methods for extracting arguments from texts and the relationships between them,
as well as building argumentation structure of texts. This paper is a report of
the organizers on the first competition of argumentation analysis systems
dealing with Russian language texts within the framework of the Dialogue
conference. During the competition, the participants were offered two tasks:
stance detection and argument classification. A corpus containing 9,550
sentences (comments on social media posts) on three topics related to the
COVID-19 pandemic (vaccination, quarantine, and wearing masks) was prepared,
annotated, and used for training and testing. The system that won the first
place in both tasks used the NLI (Natural Language Inference) variant of the
BERT architecture, automatic translation into English to apply a specialized
BERT model, retrained on Twitter posts discussing COVID-19, as well as
additional masking of target entities. This system showed the following
results: for the stance detection task an F1-score of 0.6968, for the argument
classification task an F1-score of 0.7404. We hope that the prepared dataset
and baselines will help to foster further research on argument mining for the
Russian language.",https://github.com/dialogue-evaluation/RuArg,-1
538fd6c0-fb55-4845-97bd-0152a126e264,MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal Open-domain Conversation,0.657132,"Responding with multi-modal content has been recognized as an essential
capability for an intelligent conversational agent. In this paper, we introduce
the MMDialog dataset to better facilitate multi-modal conversation. MMDialog is
composed of a curated set of 1.08 million real-world dialogues with 1.53
million unique images across 4,184 topics. MMDialog has two main and unique
advantages. First, it is the largest multi-modal conversation dataset by the
number of dialogues by 88x. Second, it contains massive topics to generalize
the open-domain. To build engaging dialogue system with this dataset, we
propose and normalize two response producing tasks based on retrieval and
generative scenarios. In addition, we build two baselines for above tasks with
state-of-the-art techniques and report their experimental performance. We also
propose a novel evaluation metric MM-Relevance to measure the multi-modal
responses. Our dataset and scripts are available in
https://github.com/victorsungo/MMDialog.",https://github.com/victorsungo/MMDialog,-1
44f298fa-d7d9-4d23-86f9-c49f791b5552,Unifying and Boosting Gradient-Based Training-Free Neural Architecture Search,0.759727,"Neural architecture search (NAS) has gained immense popularity owing to its
ability to automate neural architecture design. A number of training-free
metrics are recently proposed to realize NAS without training, hence making NAS
more scalable. Despite their competitive empirical performances, a unified
theoretical understanding of these training-free metrics is lacking. As a
consequence, (a) the relationships among these metrics are unclear, (b) there
is no theoretical interpretation for their empirical performances, and (c)
there may exist untapped potential in existing training-free NAS, which
probably can be unveiled through a unified theoretical understanding. To this
end, this paper presents a unified theoretical analysis of gradient-based
training-free NAS, which allows us to (a) theoretically study their
relationships, (b) theoretically guarantee their generalization performances,
and (c) exploit our unified theoretical understanding to develop a novel
framework named hybrid NAS (HNAS) which consistently boosts training-free NAS
in a principled way. Remarkably, HNAS can enjoy the advantages of both
training-free (i.e., the superior search efficiency) and training-based (i.e.,
the remarkable search effectiveness) NAS, which we have demonstrated through
extensive experiments.",https://github.com/fmfn/BayesianOptimization,-1
944dade1-4577-4e64-8f22-fafe5065ae8c,Robust Speech Recognition via Large-Scale Weak Supervision,1.0,"We study the capabilities of speech processing systems trained simply to
predict large amounts of transcripts of audio on the internet. When scaled to
680,000 hours of multilingual and multitask supervision, the resulting models
generalize well to standard benchmarks and are often competitive with prior
fully supervised results but in a zero-shot transfer setting without the need
for any fine-tuning. When compared to humans, the models approach their
accuracy and robustness. We are releasing models and inference code to serve as
a foundation for further work on robust speech processing.",https://github.com/openai/whisper,-1
198e2ce5-4741-4574-9cfc-f86884396dde,JamPatoisNLI: A Jamaican Patois Natural Language Inference Dataset,0.568936,"JamPatoisNLI provides the first dataset for natural language inference in a
creole language, Jamaican Patois. Many of the most-spoken low-resource
languages are creoles. These languages commonly have a lexicon derived from a
major world language and a distinctive grammar reflecting the languages of the
original speakers and the process of language birth by creolization. This gives
them a distinctive place in exploring the effectiveness of transfer from large
monolingual or multilingual pretrained models. While our work, along with
previous work, shows that transfer from these models to low-resource languages
that are unrelated to languages in their training set is not very effective, we
would expect stronger results from transfer to creoles. Indeed, our experiments
show considerably better results from few-shot learning of JamPatoisNLI than
for such unrelated languages, and help us begin to understand how the unique
relationship between creoles and their high-resource base languages affect
cross-lingual transfer. JamPatoisNLI, which consists of naturally-occurring
premises and expert-written hypotheses, is a step towards steering research
into a traditionally underserved language and a useful benchmark for
understanding cross-lingual NLP.",None,-1
142696c4-843f-4a46-a4e4-733b480892cc,Patch-Craft Self-Supervised Training for Correlated Image Denoising,0.234659,"Supervised neural networks are known to achieve excellent results in various
image restoration tasks. However, such training requires datasets composed of
pairs of corrupted images and their corresponding ground truth targets.
Unfortunately, such data is not available in many applications. For the task of
image denoising in which the noise statistics is unknown, several
self-supervised training methods have been proposed for overcoming this
difficulty. Some of these require knowledge of the noise model, while others
assume that the contaminating noise is uncorrelated, both assumptions are too
limiting for many practical needs. This work proposes a novel self-supervised
training technique suitable for the removal of unknown correlated noise. The
proposed approach neither requires knowledge of the noise model nor access to
ground truth targets. The input to our algorithm consists of easily captured
bursts of noisy shots. Our algorithm constructs artificial patch-craft images
from these bursts by patch matching and stitching, and the obtained crafted
images are used as targets for the training. Our method does not require
registration of the images within the burst. We evaluate the proposed framework
through extensive experiments with synthetic and real image noise.",https://github.com/grishavak/pcst,-1
25ca2233-8c0a-4596-bfba-952d140b93e5,MACC: Cross-Layer Multi-Agent Congestion Control with Deep Reinforcement Learning,0.101175,"Congestion Control (CC), as the core networking task to efficiently utilize
network capacity, received great attention and widely used in various Internet
communication applications such as 5G, Internet-of-Things, UAN, and more.
Various CC algorithms have been proposed both on network and transport layers
such as Active Queue Management (AQM) algorithm and Transmission Control
Protocol (TCP) congestion control mechanism. But it is hard to model dynamic
AQM/TCP system and cooperate two algorithms to obtain excellent performance
under different communication scenarios. In this paper, we explore the
performance of multi-agent reinforcement learning-based cross-layer congestion
control algorithms and present cooperation performance of two agents, known as
MACC (Multi-agent Congestion Control). We implement MACC in NS3. The simulation
results show that our scheme outperforms other congestion control combination
in terms of throughput and delay, etc. Not only does it proves that networking
protocols based on multi-agent deep reinforcement learning is efficient for
communication managing, but also verifies that networking area can be used as
new playground for machine learning algorithms.",None,12818
6c0a1eb5-4a8a-4f5f-a670-c9ce564cfbb6,Revisiting Self-Supervised Contrastive Learning for Facial Expression Recognition,0.645136,"The success of most advanced facial expression recognition works relies
heavily on large-scale annotated datasets. However, it poses great challenges
in acquiring clean and consistent annotations for facial expression datasets.
On the other hand, self-supervised contrastive learning has gained great
popularity due to its simple yet effective instance discrimination training
strategy, which can potentially circumvent the annotation issue. Nevertheless,
there remain inherent disadvantages of instance-level discrimination, which are
even more challenging when faced with complicated facial representations. In
this paper, we revisit the use of self-supervised contrastive learning and
explore three core strategies to enforce expression-specific representations
and to minimize the interference from other facial attributes, such as identity
and face styling. Experimental results show that our proposed method
outperforms the current state-of-the-art self-supervised learning methods, in
terms of both categorical and dimensional facial expression recognition tasks.",None,-1
9d4b79d0-b7c3-49cd-a93f-c031ebb48531,A novel cluster internal evaluation index based on hyper-balls,0.106913,"It is crucial to evaluate the quality and determine the optimal number of
clusters in cluster analysis. In this paper, the multi-granularity
characterization of the data set is carried out to obtain the hyper-balls. The
cluster internal evaluation index based on hyper-balls(HCVI) is defined.
Moreover, a general method for determining the optimal number of clusters based
on HCVI is proposed. The proposed methods can evaluate the clustering results
produced by the several classic methods and determine the optimal cluster
number for data sets containing noises and clusters with arbitrary shapes. The
experimental results on synthetic and real data sets indicate that the new
index outperforms existing ones.",None,-1
bb95d676-a78c-43a1-b6cb-2d635aee43f0,Walk this Way! Entity Walks and Property Walks for RDF2vec,0.650062,"RDF2vec is a knowledge graph embedding mechanism which first extracts
sequences from knowledge graphs by performing random walks, then feeds those
into the word embedding algorithm word2vec for computing vector representations
for entities. In this poster, we introduce two new flavors of walk extraction
coined e-walks and p-walks, which put an emphasis on the structure or the
neighborhood of an entity respectively, and thereby allow for creating
embeddings which focus on similarity or relatedness. By combining the walk
strategies with order-aware and classic RDF2vec, as well as CBOW and skip-gram
word2vec embeddings, we conduct a preliminary evaluation with a total of 12
RDF2vec variants.",None,-1
05ea18d9-624f-45d7-8f6e-7eb46da0e00f,Event-based YOLO Object Detection: Proof of Concept for Forward Perception System,0.297148,"Neuromorphic vision or event vision is an advanced vision technology, where
in contrast to the visible camera that outputs pixels, the event vision
generates neuromorphic events every time there is a brightness change which
exceeds a specific threshold in the field of view (FOV). This study focuses on
leveraging neuromorphic event data for roadside object detection. This is a
proof of concept towards building artificial intelligence (AI) based pipelines
which can be used for forward perception systems for advanced vehicular
applications. The focus is on building efficient state-of-the-art object
detection networks with better inference results for fast-moving forward
perception using an event camera. In this article, the event-simulated A2D2
dataset is manually annotated and trained on two different YOLOv5 networks
(small and large variants). To further assess its robustness, single model
testing and ensemble model testing are carried out.",https://github.com/ultralytics/yolov5,-1
38594c2e-11d0-4564-8258-3638fb6d1041,Large Language Models are Zero-Shot Reasoners,1.0,"Pretrained large language models (LLMs) are widely used in many sub-fields of
natural language processing (NLP) and generally known as excellent few-shot
learners with task-specific exemplars. Notably, chain of thought (CoT)
prompting, a recent technique for eliciting complex multi-step reasoning
through step-by-step answer examples, achieved the state-of-the-art
performances in arithmetics and symbolic reasoning, difficult system-2 tasks
that do not follow the standard scaling laws for LLMs. While these successes
are often attributed to LLMs' ability for few-shot learning, we show that LLMs
are decent zero-shot reasoners by simply adding ""Let's think step by step""
before each answer. Experimental results demonstrate that our Zero-shot-CoT,
using the same single prompt template, significantly outperforms zero-shot LLM
performances on diverse benchmark reasoning tasks including arithmetics
(MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin
Flip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled
Objects), without any hand-crafted few-shot examples, e.g. increasing the
accuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with
large InstructGPT model (text-davinci-002), as well as similar magnitudes of
improvements with another off-the-shelf large model, 540B parameter PaLM. The
versatility of this single prompt across very diverse reasoning tasks hints at
untapped and understudied fundamental zero-shot capabilities of LLMs,
suggesting high-level, multi-task broad cognitive capabilities may be extracted
by simple prompting. We hope our work not only serves as the minimal strongest
zero-shot baseline for the challenging reasoning benchmarks, but also
highlights the importance of carefully exploring and analyzing the enormous
zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or
few-shot exemplars.",None,-1
3ee6115d-bef3-427e-8be8-59cb28351e84,Integration of Text and Graph-based Features for Detecting Mental Health Disorders from Voice,0.167945,"With the availability of voice-enabled devices such as smart phones, mental
health disorders could be detected and treated earlier, particularly
post-pandemic. The current methods involve extracting features directly from
audio signals. In this paper, two methods are used to enrich voice analysis for
depression detection: graph transformation of voice signals, and natural
language processing of the transcript based on representational learning, fused
together to produce final class labels. The results of experiments with the
DAIC-WOZ dataset suggest that integration of text-based voice classification
and learning from low level and graph-based voice signal features can improve
the detection of mental disorders like depression.",None,-1
1b0c5cc8-2532-48ed-9932-626406c98771,NeRF-In: Free-Form NeRF Inpainting with RGB-D Priors,0.567973,"Though Neural Radiance Field (NeRF) demonstrates compelling novel view
synthesis results, it is still unintuitive to edit a pre-trained NeRF because
the neural network's parameters and the scene geometry/appearance are often not
explicitly associated. In this paper, we introduce the first framework that
enables users to remove unwanted objects or retouch undesired regions in a 3D
scene represented by a pre-trained NeRF without any category-specific data and
training. The user first draws a free-form mask to specify a region containing
unwanted objects over a rendered view from the pre-trained NeRF. Our framework
first transfers the user-provided mask to other rendered views and estimates
guiding color and depth images within these transferred masked regions. Next,
we formulate an optimization problem that jointly inpaints the image content in
all masked regions across multiple views by updating the NeRF model's
parameters. We demonstrate our framework on diverse scenes and show it obtained
visual plausible and structurally consistent results across multiple views
using shorter time and less user manual efforts.",None,-1
044e7d37-353b-47d8-a7e4-9d906cc25d53,WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named Entity Recognition,0.230056,"Named Entity Recognition task is one of the core tasks of information
extraction. Word ambiguity and word abbreviation are important reasons for the
low recognition rate of named entities. In this paper, we propose a novel named
entity recognition model WCL-BBCD (Word Contrastive Learning with
BERT-BiLSTM-CRF-DBpedia), which incorporates the idea of contrastive learning.
The model first trains the sentence pairs in the text, calculate similarity
between sentence pairs, and fine-tunes BERT used for the named entity
recognition task according to the similarity, so as to alleviate word
ambiguity. Then, the fine-tuned BERT is combined with BiLSTM-CRF to perform the
named entity recognition task. Finally, the recognition results are corrected
in combination with prior knowledge such as knowledge graphs, so as to
alleviate the low-recognition-rate problem caused by word abbreviations. The
results of experimentals conducted on the CoNLL-2003 English dataset and
OntoNotes V5 English dataset show that our model outperforms other similar
models on.",None,5311
1177bb07-0707-46a0-ac1b-7c56a50ab79f,Qtrade AI at SemEval-2022 Task 11: An Unified Framework for Multilingual NER Task,0.562066,"This paper describes our system, which placed third in the Multilingual Track
(subtask 11), fourth in the Code-Mixed Track (subtask 12), and seventh in the
Chinese Track (subtask 9) in the SemEval 2022 Task 11: MultiCoNER Multilingual
Complex Named Entity Recognition. Our system's key contributions are as
follows: 1) For multilingual NER tasks, we offer an unified framework with
which one can easily execute single-language or multilingual NER tasks, 2) for
low-resource code-mixed NER task, one can easily enhance his or her dataset
through implementing several simple data augmentation methods and 3) for
Chinese tasks, we propose a model that can capture Chinese lexical semantic,
lexical border, and lexical graph structural information. Finally, our system
achieves macro-f1 scores of 77.66, 84.35, and 74.00 on subtasks 11, 12, and 9,
respectively, during the testing phase.",None,42
8e975648-7c5c-4478-b2a9-53b18933f6a1,From Indoor To Outdoor: Unsupervised Domain Adaptive Gait Recognition,0.540927,"Gait recognition is an important AI task, which has been progressed rapidly
with the development of deep learning. However, existing learning based gait
recognition methods mainly focus on the single domain, especially the
constrained laboratory environment. In this paper, we study a new problem of
unsupervised domain adaptive gait recognition (UDA-GR), that learns a gait
identifier with supervised labels from the indoor scenes (source domain), and
is applied to the outdoor wild scenes (target domain). For this purpose, we
develop an uncertainty estimation and regularization based UDA-GR method.
Specifically, we investigate the characteristic of gaits in the indoor and
outdoor scenes, for estimating the gait sample uncertainty, which is used in
the unsupervised fine-tuning on the target domain to alleviate the noises of
the pseudo labels. We also establish a new benchmark for the proposed problem,
experimental results on which show the effectiveness of the proposed method. We
will release the benchmark and source code in this work to the public.",None,-1
02896e49-bf8f-4c29-8ac0-d33ce82455d7,Towards Robust k-Nearest-Neighbor Machine Translation,0.713316,"k-Nearest-Neighbor Machine Translation (kNN-MT) becomes an important research
direction of NMT in recent years. Its main idea is to retrieve useful key-value
pairs from an additional datastore to modify translations without updating the
NMT model. However, the underlying retrieved noisy pairs will dramatically
deteriorate the model performance. In this paper, we conduct a preliminary
study and find that this problem results from not fully exploiting the
prediction of the NMT model. To alleviate the impact of noise, we propose a
confidence-enhanced kNN-MT model with robust training. Concretely, we introduce
the NMT confidence to refine the modeling of two important components of
kNN-MT: kNN distribution and the interpolation weight. Meanwhile we inject two
types of perturbations into the retrieved pairs for robust training.
Experimental results on four benchmark datasets demonstrate that our model not
only achieves significant improvements over current kNN-MT models, but also
exhibits better robustness. Our code is available at
https://github.com/DeepLearnXMU/Robust-knn-mt.",https://github.com/DeepLearnXMU/Robust-knn-mt,4230
ca8af5e7-c866-41c6-85d2-a58a0d1385ae,"""Think Before You Speak"": Improving Multi-Action Dialog Policy by Planning Single-Action Dialogs",0.635567,"Multi-action dialog policy (MADP), which generates multiple atomic dialog
actions per turn, has been widely applied in task-oriented dialog systems to
provide expressive and efficient system responses. Existing MADP models usually
imitate action combinations from the labeled multi-action dialog samples. Due
to data limitations, they generalize poorly toward unseen dialog flows. While
interactive learning and reinforcement learning algorithms can be applied to
incorporate external data sources of real users and user simulators, they take
significant manual effort to build and suffer from instability. To address
these issues, we propose Planning Enhanced Dialog Policy (PEDP), a novel
multi-task learning framework that learns single-action dialog dynamics to
enhance multi-action prediction. Our PEDP method employs model-based planning
for conceiving what to express before deciding the current response through
simulating single-action dialogs. Experimental results on the MultiWOZ dataset
demonstrate that our fully supervised learning-based method achieves a solid
task success rate of 90.6%, improving 3% compared to the state-of-the-art
methods.",https://github.com/ShuoZhangXJTU/PEDP,-1
6a290d61-ee38-4b4f-9290-a0f302512669,Distilling the Knowledge of BERT for CTC-based ASR,0.357767,"Connectionist temporal classification (CTC) -based models are attractive
because of their fast inference in automatic speech recognition (ASR). Language
model (LM) integration approaches such as shallow fusion and rescoring can
improve the recognition accuracy of CTC-based ASR by taking advantage of the
knowledge in text corpora. However, they significantly slow down the inference
of CTC. In this study, we propose to distill the knowledge of BERT for
CTC-based ASR, extending our previous study for attention-based ASR. CTC-based
ASR learns the knowledge of BERT during training and does not use BERT during
testing, which maintains the fast inference of CTC. Different from
attention-based models, CTC-based models make frame-level predictions, so they
need to be aligned with token-level predictions of BERT for distillation. We
propose to obtain alignments by calculating the most plausible CTC paths.
Experimental evaluations on the Corpus of Spontaneous Japanese (CSJ) and
TED-LIUM2 show that our method improves the performance of CTC-based ASR
without the cost of inference speed.",None,-1
fb4d40a0-7875-47de-9d67-d1e0cb0925d6,Layout Aware Inpainting for Automated Furniture Removal in Indoor Scenes,0.593599,"We address the problem of detecting and erasing furniture from a wide angle
photograph of a room. Inpainting large regions of an indoor scene often results
in geometric inconsistencies of background elements within the inpaint mask. To
address this problem, we utilize perceptual information (e.g. instance
segmentation, and room layout) to produce a geometrically consistent empty
version of a room. We share important details to make this system viable, such
as per-plane inpainting, automatic rectification, and texture refinement. We
provide detailed ablation along with qualitative examples, justifying our
design choices. We show an application of our system by removing real furniture
from a room and redecorating it with virtual furniture.",None,-1
fce9bf18-62ac-478f-98a3-aaa1cf19e6ee,Spontaneous Emerging Preference in Two-tower Language Model,0.209694,"The ever-growing size of the foundation language model has brought
significant performance gains in various types of downstream tasks. With the
existence of side-effects brought about by the large size of the foundation
language model such as deployment cost, availability issues, and environmental
cost, there is some interest in exploring other possible directions, such as a
divide-and-conquer scheme. In this paper, we are asking a basic question: are
language processes naturally dividable? We study this problem with a simple
two-tower language model setting, where two language models with identical
configurations are trained side-by-side cooperatively. With this setting, we
discover the spontaneous emerging preference phenomenon, where some of the
tokens are consistently better predicted by one tower while others by another
tower. This phenomenon is qualitatively stable, regardless of model
configuration and type, suggesting this as an intrinsic property of natural
language. This study suggests that interesting properties of natural language
are still waiting to be discovered, which may aid the future development of
natural language processing techniques.",None,-1
848828e0-60e2-4525-add5-c4af75893609,Panoptic-PHNet: Towards Real-Time and High-Precision LiDAR Panoptic Segmentation via Clustering Pseudo Heatmap,0.897188,"As a rising task, panoptic segmentation is faced with challenges in both
semantic segmentation and instance segmentation. However, in terms of speed and
accuracy, existing LiDAR methods in the field are still limited. In this paper,
we propose a fast and high-performance LiDAR-based framework, referred to as
Panoptic-PHNet, with three attractive aspects: 1) We introduce a clustering
pseudo heatmap as a new paradigm, which, followed by a center grouping module,
yields instance centers for efficient clustering without object-level learning
tasks. 2) A knn-transformer module is proposed to model the interaction among
foreground points for accurate offset regression. 3) For backbone design, we
fuse the fine-grained voxel features and the 2D Bird's Eye View (BEV) features
with different receptive fields to utilize both detailed and global
information. Extensive experiments on both SemanticKITTI dataset and nuScenes
dataset show that our Panoptic-PHNet surpasses state-of-the-art methods by
remarkable margins with a real-time speed. We achieve the 1st place on the
public leaderboard of SemanticKITTI and leading performance on the recently
released leaderboard of nuScenes.",None,-1
5beb1367-72c5-4001-9ce2-3ff0e28997b3,Application of DatasetGAN in medical imaging: preliminary studies,0.103798,"Generative adversarial networks (GANs) have been widely investigated for many
potential applications in medical imaging. DatasetGAN is a recently proposed
framework based on modern GANs that can synthesize high-quality segmented
images while requiring only a small set of annotated training images. The
synthesized annotated images could be potentially employed for many medical
imaging applications, where images with segmentation information are required.
However, to the best of our knowledge, there are no published studies focusing
on its applications to medical imaging. In this work, preliminary studies were
conducted to investigate the utility of DatasetGAN in medical imaging. Three
improvements were proposed to the original DatasetGAN framework, considering
the unique characteristics of medical images. The synthesized segmented images
by DatasetGAN were visually evaluated. The trained DatasetGAN was further
analyzed by evaluating the performance of a pre-defined image segmentation
technique, which was trained by the use of the synthesized datasets. The
effectiveness, concerns, and potential usage of DatasetGAN were discussed.",https://github.com/NVlabs/stylegan2-ada-pytorch,-1
aba73d1d-5047-4e28-b60b-f12095cd6b89,RV4JaCa -- Runtime Verification for Multi-Agent Systems,0.423207,"This paper presents a Runtime Verification (RV) approach for Multi-Agent
Systems (MAS) using the JaCaMo framework. Our objective is to bring a layer of
security to the MAS. This layer is capable of controlling events during the
execution of the system without needing a specific implementation in the
behaviour of each agent to recognise the events. MAS have been used in the
context of hybrid intelligence. This use requires communication between
software agents and human beings. In some cases, communication takes place via
natural language dialogues. However, this kind of communication brings us to a
concern related to controlling the flow of dialogue so that agents can prevent
any change in the topic of discussion that could impair their reasoning. We
demonstrate the implementation of a monitor that aims to control this dialogue
flow in a MAS that communicates with the user through natural language to aid
decision-making in hospital bed allocation.",https://github.com/DeboraEngelmann/RV4JaCa,-1
4297a8f8-5e25-4754-b0d2-eee1ceea4620,MentSum: A Resource for Exploring Summarization of Mental Health Online Posts,0.49556,"Mental health remains a significant challenge of public health worldwide.
With increasing popularity of online platforms, many use the platforms to share
their mental health conditions, express their feelings, and seek help from the
community and counselors. Some of these platforms, such as Reachout, are
dedicated forums where the users register to seek help. Others such as Reddit
provide subreddits where the users publicly but anonymously post their mental
health distress. Although posts are of varying length, it is beneficial to
provide a short, but informative summary for fast processing by the counselors.
To facilitate research in summarization of mental health online posts, we
introduce Mental Health Summarization dataset, MentSum, containing over 24k
carefully selected user posts from Reddit, along with their short user-written
summary (called TLDR) in English from 43 mental health subreddits. This
domain-specific dataset could be of interest not only for generating short
summaries on Reddit, but also for generating summaries of posts on the
dedicated mental health forums such as Reachout. We further evaluate both
extractive and abstractive state-of-the-art summarization baselines in terms of
Rouge scores, and finally conduct an in-depth human evaluation study of both
user-written and system-generated summaries, highlighting challenges in this
research.",https://github.com/miso-belica/sumy,-1
7e7b4d4d-8a51-4620-b765-3257b4fad63f,USLN: A statistically guided lightweight network for underwater image enhancement via dual-statistic white balance and multi-color space stretch,0.501694,"Underwater images are inevitably affected by color distortion and reduced
contrast. Traditional statistic-based methods such as white balance and
histogram stretching attempted to adjust the imbalance of color channels and
narrow distribution of intensities a priori thus with limited performance.
Recently, deep-learning-based methods have achieved encouraging results.
However, the involved complicate architecture and high computational costs may
hinder their deployment in practical constrained platforms. Inspired by above
works, we propose a statistically guided lightweight underwater image
enhancement network (USLN). Concretely, we first develop a dual-statistic white
balance module which can learn to use both average and maximum of images to
compensate the color distortion for each specific pixel. Then this is followed
by a multi-color space stretch module to adjust the histogram distribution in
RGB, HSI, and Lab color spaces adaptively. Extensive experiments show that,
with the guidance of statistics, USLN significantly reduces the required
network capacity (over98%) and achieves state-of-the-art performance. The code
and relevant resources are available at https://github.com/deepxzy/USLN.",https://github.com/deepxzy/USLN,-1
41a65608-a965-4c3a-8b92-077b4a55e462,Penalizing Gradient Norm for Efficiently Improving Generalization in Deep Learning,0.999563,"How to train deep neural networks (DNNs) to generalize well is a central
concern in deep learning, especially for severely overparameterized networks
nowadays. In this paper, we propose an effective method to improve the model
generalization by additionally penalizing the gradient norm of loss function
during optimization. We demonstrate that confining the gradient norm of loss
function could help lead the optimizers towards finding flat minima. We
leverage the first-order approximation to efficiently implement the
corresponding gradient to fit well in the gradient descent framework. In our
experiments, we confirm that when using our methods, generalization performance
of various models could be improved on different datasets. Also, we show that
the recent sharpness-aware minimization method (Foret et al., 2021) is a
special, but not the best, case of our method, where the best case of our
method could give new state-of-art performance on these tasks. Code is
available at {https://github.com/zhaoyang-0204/gnp}.",https://github.com/zhaoyang-0204/gnp,-1
11a61a75-39fb-48f1-9e25-df616cd77c99,Hierarchical Decision Transformer,0.593557,"Sequence models in reinforcement learning require task knowledge to estimate
the task policy. This paper presents a hierarchical algorithm for learning a
sequence model from demonstrations. The high-level mechanism guides the
low-level controller through the task by selecting sub-goals for the latter to
reach. This sequence replaces the returns-to-go of previous methods, improving
its performance overall, especially in tasks with longer episodes and scarcer
rewards. We validate our method in multiple tasks of OpenAIGym, D4RL and
RoboMimic benchmarks. Our method outperforms the baselines in eight out of ten
tasks of varied horizons and reward frequencies without prior task knowledge,
showing the advantages of the hierarchical model approach for learning from
demonstrations using a sequence model.",None,3
57ecf52d-0981-4026-996e-1a2d1646b1f5,Confident Adaptive Language Modeling,0.816495,"Recent advances in Transformer-based large language models (LLMs) have led to
significant performance improvements across many tasks. These gains come with a
drastic increase in the models' size, potentially leading to slow and costly
use at inference time. In practice, however, the series of generations made by
LLMs is composed of varying levels of difficulty. While certain predictions
truly benefit from the models' full capacity, other continuations are more
trivial and can be solved with reduced compute. In this work, we introduce
Confident Adaptive Language Modeling (CALM), a framework for dynamically
allocating different amounts of compute per input and generation timestep.
Early exit decoding involves several challenges that we address here, such as:
(1) what confidence measure to use; (2) connecting sequence-level constraints
to local per-token exit decisions; and (3) attending back to missing hidden
representations due to early exits in previous tokens. Through theoretical
analysis and empirical experiments on three diverse text generation tasks, we
demonstrate the efficacy of our framework in reducing compute -- potential
speedup of up to $\times 3$ -- while provably maintaining high performance.",None,-1
cda7e3d9-2b2e-48ae-a202-e67144dfc57c,Tsetlin Machine for Solving Contextual Bandit Problems,0.340966,"This paper introduces an interpretable contextual bandit algorithm using
Tsetlin Machines, which solves complex pattern recognition tasks using
propositional logic. The proposed bandit learning algorithm relies on
straightforward bit manipulation, thus simplifying computation and
interpretation. We then present a mechanism for performing Thompson sampling
with Tsetlin Machine, given its non-parametric nature. Our empirical analysis
shows that Tsetlin Machine as a base contextual bandit learner outperforms
other popular base learners on eight out of nine datasets. We further analyze
the interpretability of our learner, investigating how arms are selected based
on propositional expressions that model the context.",https://github.com/xxx,-1
df372e27-e66e-4c4f-bfbe-434cd2dff790,Summarization as Indirect Supervision for Relation Extraction,0.996651,"Relation extraction (RE) models have been challenged by their reliance on
training data with expensive annotations. Considering that summarization tasks
aim at acquiring concise expressions of synoptical information from the longer
context, these tasks naturally align with the objective of RE, i.e., extracting
a kind of synoptical information that describes the relation of entity
mentions. We present SuRE, which converts RE into a summarization formulation.
SuRE leads to more precise and resource-efficient RE based on indirect
supervision from summarization tasks. To achieve this goal, we develop sentence
and relation conversion techniques that essentially bridge the formulation of
summarization and RE tasks. We also incorporate constraint decoding techniques
with Trie scoring to further enhance summarization-based RE with robust
inference. Experiments on three RE datasets demonstrate the effectiveness of
SuRE in both full-dataset and low-resource settings, showing that summarization
is a promising source of indirect supervision to improve RE models.",https://github.com/luka-group/SuRE,-1
77ce9502-4cd2-42c0-be8f-ab7898584846,Jury Learning: Integrating Dissenting Voices into Machine Learning Models,0.80373,"Whose labels should a machine learning (ML) algorithm learn to emulate? For
ML tasks ranging from online comment toxicity to misinformation detection to
medical diagnosis, different groups in society may have irreconcilable
disagreements about ground truth labels. Supervised ML today resolves these
label disagreements implicitly using majority vote, which overrides minority
groups' labels. We introduce jury learning, a supervised ML approach that
resolves these disagreements explicitly through the metaphor of a jury:
defining which people or groups, in what proportion, determine the classifier's
prediction. For example, a jury learning model for online toxicity might
centrally feature women and Black jurors, who are commonly targets of online
harassment. To enable jury learning, we contribute a deep learning architecture
that models every annotator in a dataset, samples from annotators' models to
populate the jury, then runs inference to classify. Our architecture enables
juries that dynamically adapt their composition, explore counterfactuals, and
visualize dissent.",None,-1
cb27a751-3100-4538-b06a-24c25866a60e,"On the sensitivity of pose estimation neural networks: rotation parameterizations, Lipschitz constants, and provable bounds",0.0543873,"In this paper, we approach the task of determining sensitivity bounds for
pose estimation neural networks. This task is particularly challenging as it
requires characterizing the sensitivity of 3D rotations. We develop a
sensitivity measure that describes the maximum rotational change in a network's
output with respect to a Euclidean change in its input. We show that this
measure is a type of Lipschitz constant, and that it is bounded by the product
of a network's Euclidean Lipschitz constant and an intrinsic property of a
rotation parameterization which we call the ""distance ratio constant"". We
derive the distance ratio constant for several rotation parameterizations, and
then discuss why the structure of most of these parameterizations makes it
difficult to construct a pose estimation network with provable sensitivity
bounds. However, we show that sensitivity bounds can be computed for networks
which parameterize rotation using unconstrained exponential coordinates. We
then construct and train such a network and compute sensitivity bounds for it.",https://github.com/uwaa-ndcl/pose_network_sensitivity,-1
78743bbe-3b0d-42bc-a807-c6151c153eb1,Interstellar Object Accessibility and Mission Design,0.434551,"Interstellar objects (ISOs) are fascinating and under-explored celestial
objects, providing physical laboratories to understand the formation of our
solar system and probe the composition and properties of material formed in
exoplanetary systems. This paper will discuss the accessibility of and mission
design to ISOs with varying characteristics, including a discussion of state
covariance estimation over the course of a cruise, handoffs from traditional
navigation approaches to novel autonomous navigation for fast flyby regimes,
and overall recommendations about preparing for the future in situ exploration
of these targets. The lessons learned also apply to the fast flyby of other
small bodies including long-period comets and potentially hazardous asteroids,
which also require a tactical response with similar characteristics",None,-1
b0b5b6b1-3a7d-41de-86ca-288f0651535a,A general-purpose material property data extraction pipeline from large polymer corpora using Natural Language Processing,0.842864,"The ever-increasing number of materials science articles makes it hard to
infer chemistry-structure-property relations from published literature. We used
natural language processing (NLP) methods to automatically extract material
property data from the abstracts of polymer literature. As a component of our
pipeline, we trained MaterialsBERT, a language model, using 2.4 million
materials science abstracts, which outperforms other baseline models in three
out of five named entity recognition datasets when used as the encoder for
text. Using this pipeline, we obtained ~300,000 material property records from
~130,000 abstracts in 60 hours. The extracted data was analyzed for a diverse
range of applications such as fuel cells, supercapacitors, and polymer solar
cells to recover non-trivial insights. The data extracted through our pipeline
is made available through a web platform at https://polymerscholar.org which
can be used to locate material property data recorded in abstracts
conveniently. This work demonstrates the feasibility of an automatic pipeline
that starts from published literature and ends with a complete set of extracted
material property information.",None,-1
9aac4521-c091-45c9-82f1-2624d225fb97,What's Behind the Mask: Understanding Masked Graph Modeling for Graph Autoencoders,0.347177,"The last years have witnessed the emergence of a promising self-supervised
learning strategy, referred to as masked autoencoding. However, there is a lack
of theoretical understanding of how masking matters on graph autoencoders
(GAEs). In this work, we present masked graph autoencoder (MaskGAE), a
self-supervised learning framework for graph-structured data. Different from
standard GAEs, MaskGAE adopts masked graph modeling (MGM) as a principled
pretext task - masking a portion of edges and attempting to reconstruct the
missing part with partially visible, unmasked graph structure. To understand
whether MGM can help GAEs learn better representations, we provide both
theoretical and empirical evidence to comprehensively justify the benefits of
this pretext task. Theoretically, we establish close connections between GAEs
and contrastive learning, showing that MGM significantly improves the
self-supervised learning scheme of GAEs. Empirically, we conduct extensive
experiments on a variety of graph benchmarks, demonstrating the superiority of
MaskGAE over several state-of-the-arts on both link prediction and node
classification tasks.",https://github.com/EdisonLeeeee/MaskGAE,-1
1ee40cec-def7-4e9c-b2f0-07e6d132f1d0,Investigating Reasons for Disagreement in Natural Language Inference,0.526118,"We investigate how disagreement in natural language inference (NLI)
annotation arises. We developed a taxonomy of disagreement sources with 10
categories spanning 3 high-level classes. We found that some disagreements are
due to uncertainty in the sentence meaning, others to annotator biases and task
artifacts, leading to different interpretations of the label distribution. We
explore two modeling approaches for detecting items with potential
disagreement: a 4-way classification with a ""Complicated"" label in addition to
the three standard NLI labels, and a multilabel classification approach. We
found that the multilabel classification is more expressive and gives better
recall of the possible interpretations in the data.",https://github.com/njjiang/NLI_disagreement_taxonomy,-1
f5d2d50a-142b-4b4b-81d3-fa63f937d2a7,BEVFormer v2: Adapting Modern Image Backbones to Bird's-Eye-View Recognition via Perspective Supervision,0.999951,"We present a novel bird's-eye-view (BEV) detector with perspective
supervision, which converges faster and better suits modern image backbones.
Existing state-of-the-art BEV detectors are often tied to certain depth
pre-trained backbones like VoVNet, hindering the synergy between booming image
backbones and BEV detectors. To address this limitation, we prioritize easing
the optimization of BEV detectors by introducing perspective space supervision.
To this end, we propose a two-stage BEV detector, where proposals from the
perspective head are fed into the bird's-eye-view head for final predictions.
To evaluate the effectiveness of our model, we conduct extensive ablation
studies focusing on the form of supervision and the generality of the proposed
detector. The proposed method is verified with a wide spectrum of traditional
and modern image backbones and achieves new SoTA results on the large-scale
nuScenes dataset. The code shall be released soon.",None,-1
2029f0a8-ffd8-4c76-984d-ac2117633857,Lempel-Ziv Networks,0.369687,"Sequence processing has long been a central area of machine learning
research. Recurrent neural nets have been successful in processing sequences
for a number of tasks; however, they are known to be both ineffective and
computationally expensive when applied to very long sequences.
Compression-based methods have demonstrated more robustness when processing
such sequences -- in particular, an approach pairing the Lempel-Ziv Jaccard
Distance (LZJD) with the k-Nearest Neighbor algorithm has shown promise on long
sequence problems (up to $T=200,000,000$ steps) involving malware
classification. Unfortunately, use of LZJD is limited to discrete domains. To
extend the benefits of LZJD to a continuous domain, we investigate the
effectiveness of a deep-learning analog of the algorithm, the Lempel-Ziv
Network. While we achieve successful proof of concept, we are unable to improve
meaningfully on the performance of a standard LSTM across a variety of datasets
and sequence processing tasks. In addition to presenting this negative result,
our work highlights the problem of sub-par baseline tuning in newer research
areas.",None,10329
31b1fd97-1a33-4930-8f61-87c7bf7dedfa,Information Extraction from Scanned Invoice Images using Text Analysis and Layout Features,0.414656,"While storing invoice content as metadata to avoid paper document processing
may be the future trend, almost all of daily issued invoices are still printed
on paper or generated in digital formats such as PDFs. In this paper, we
introduce the OCRMiner system for information extraction from scanned document
images which is based on text analysis techniques in combination with layout
features to extract indexing metadata of (semi-)structured documents. The
system is designed to process the document in a similar way a human reader
uses, i.e. to employ different layout and text attributes in a coordinated
decision. The system consists of a set of interconnected modules that start
with (possibly erroneous) character-based output from a standard OCR system and
allow to apply different techniques and to expand the extracted knowledge at
each step. Using an open source OCR, the system is able to recover the invoice
data in 90% for English and in 88% for the Czech set.",https://github.com/naiveHobo/InvoiceNet,-1
7df69ba2-06a2-48d0-9ed1-ccf70e184032,STL-Based Synthesis of Feedback Controllers Using Reinforcement Learning,0.120154,"Deep Reinforcement Learning (DRL) has the potential to be used for
synthesizing feedback controllers (agents) for various complex systems with
unknown dynamics. These systems are expected to satisfy diverse safety and
liveness properties best captured using temporal logic. In RL, the reward
function plays a crucial role in specifying the desired behaviour of these
agents. However, the problem of designing the reward function for an RL agent
to satisfy complex temporal logic specifications has received limited attention
in the literature. To address this, we provide a systematic way of generating
rewards in real-time by using the quantitative semantics of Signal Temporal
Logic (STL), a widely used temporal logic to specify the behaviour of
cyber-physical systems. We propose a new quantitative semantics for STL having
several desirable properties, making it suitable for reward generation. We
evaluate our STL-based reinforcement learning mechanism on several complex
continuous control benchmarks and compare our STL semantics with those
available in the literature in terms of their efficacy in synthesizing the
controller agent. Experimental results establish our new semantics to be the
most suitable for synthesizing feedback controllers for complex continuous
dynamical systems through reinforcement learning.",https://github.com/iitkcpslab/rlstl,-1
1ed5d2f0-86a6-4837-bb53-8deee77ca5da,PoissonMat: Remodeling Matrix Factorization using Poisson Distribution and Solving the Cold Start Problem without Input Data,0.789991,"Matrix Factorization is one of the most successful recommender system
techniques over the past decade. However, the classic probabilistic theory
framework for matrix factorization is modeled using normal distributions. To
find better probabilistic models, algorithms such as RankMat, ZeroMat and
DotMat have been invented in recent years. In this paper, we model the user
rating behavior in recommender system as a Poisson process, and design an
algorithm that relies on no input data to solve the recommendation problem and
the cold start issue at the same time. We prove the superiority of our
algorithm in comparison with matrix factorization, random placement, Zipf
placement, ZeroMat, DotMat, etc.",None,-1
0eee77ee-1937-45f5-a1ed-a23be37569c4,MiniViT: Compressing Vision Transformers with Weight Multiplexing,0.777443,"Vision Transformer (ViT) models have recently drawn much attention in
computer vision due to their high model capability. However, ViT models suffer
from huge number of parameters, restricting their applicability on devices with
limited memory. To alleviate this problem, we propose MiniViT, a new
compression framework, which achieves parameter reduction in vision
transformers while retaining the same performance. The central idea of MiniViT
is to multiplex the weights of consecutive transformer blocks. More
specifically, we make the weights shared across layers, while imposing a
transformation on the weights to increase diversity. Weight distillation over
self-attention is also applied to transfer knowledge from large-scale ViT
models to weight-multiplexed compact models. Comprehensive experiments
demonstrate the efficacy of MiniViT, showing that it can reduce the size of the
pre-trained Swin-B transformer by 48\%, while achieving an increase of 1.0\% in
Top-1 accuracy on ImageNet. Moreover, using a single-layer of parameters,
MiniViT is able to compress DeiT-B by 9.7 times from 86M to 9M parameters,
without seriously compromising the performance. Finally, we verify the
transferability of MiniViT by reporting its performance on downstream
benchmarks. Code and models are available at here.",None,18607
04da2f46-2906-4971-8ee4-1273c1fafc80,Visual Programming: Compositional visual reasoning without training,1.0,"We present VISPROG, a neuro-symbolic approach to solving complex and
compositional visual tasks given natural language instructions. VISPROG avoids
the need for any task-specific training. Instead, it uses the in-context
learning ability of large language models to generate python-like modular
programs, which are then executed to get both the solution and a comprehensive
and interpretable rationale. Each line of the generated program may invoke one
of several off-the-shelf computer vision models, image processing routines, or
python functions to produce intermediate outputs that may be consumed by
subsequent parts of the program. We demonstrate the flexibility of VISPROG on 4
diverse tasks - compositional visual question answering, zero-shot reasoning on
image pairs, factual knowledge object tagging, and language-guided image
editing. We believe neuro-symbolic approaches like VISPROG are an exciting
avenue to easily and effectively expand the scope of AI systems to serve the
long tail of complex tasks that people may wish to perform.",None,10523
49e04a7d-170a-42d2-b846-369f12d04ef8,EEML: Ensemble Embedded Meta-learning,0.0595482,"To accelerate learning process with few samples, meta-learning resorts to
prior knowledge from previous tasks. However, the inconsistent task
distribution and heterogeneity is hard to be handled through a global sharing
model initialization. In this paper, based on gradient-based meta-learning, we
propose an ensemble embedded meta-learning algorithm (EEML) that explicitly
utilizes multi-model-ensemble to organize prior knowledge into diverse specific
experts. We rely on a task embedding cluster mechanism to deliver diverse tasks
to matching experts in training process and instruct how experts collaborate in
test phase. As a result, the multi experts can focus on their own area of
expertise and cooperate in upcoming task to solve the task heterogeneity. The
experimental results show that the proposed method outperforms recent
state-of-the-arts easily in few-shot learning problem, which validates the
importance of differentiation and cooperation.",None,-1
2c6b167f-a2a4-4046-a8c4-b425e275d242,Iterative Scene Graph Generation,0.513511,"The task of scene graph generation entails identifying object entities and
their corresponding interaction predicates in a given image (or video). Due to
the combinatorially large solution space, existing approaches to scene graph
generation assume certain factorization of the joint distribution to make the
estimation feasible (e.g., assuming that objects are conditionally independent
of predicate predictions). However, this fixed factorization is not ideal under
all scenarios (e.g., for images where an object entailed in interaction is
small and not discernible on its own). In this work, we propose a novel
framework for scene graph generation that addresses this limitation, as well as
introduces dynamic conditioning on the image, using message passing in a Markov
Random Field. This is implemented as an iterative refinement procedure wherein
each modification is conditioned on the graph generated in the previous
iteration. This conditioning across refinement steps allows joint reasoning
over entities and relations. This framework is realized via a novel and
end-to-end trainable transformer-based architecture. In addition, the proposed
framework can improve existing approach performance. Through extensive
experiments on Visual Genome and Action Genome benchmark datasets we show
improved performance on the scene graph generation.",https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch,14517
7bdb9a0e-397b-4dc7-a6ec-005d56635413,Concordance based Survival Cobra with regression type weak learners,0.351477,"In this paper, we predict conditional survival functions through a combined
regression strategy. We take weak learners as different random survival trees.
We propose to maximize concordance in the right-censored set up to find the
optimal parameters. We explore two approaches, a usual survival cobra and a
novel weighted predictor based on the concordance index. Our proposed
formulations use two different norms, say, Max-norm and Frobenius norm, to find
a proximity set of predictions from query points in the test dataset. We
illustrate our algorithms through three different real-life dataset
implementations.",None,-1
0535a10a-2845-4de8-94bd-4c6e224daa8a,Ad Hoc Teamwork in the Presence of Adversaries,0.259182,"Advances in ad hoc teamwork have the potential to create agents that
collaborate robustly in real-world applications. Agents deployed in the real
world, however, are vulnerable to adversaries with the intent to subvert them.
There has been little research in ad hoc teamwork that assumes the presence of
adversaries. We explain the importance of extending ad hoc teamwork to include
the presence of adversaries and clarify why this problem is difficult. We then
propose some directions for new research opportunities in ad hoc teamwork that
leads to more robust multi-agent cyber-physical infrastructure systems.",None,1082
a6ab9225-e9e4-4dbf-9bc7-2095e692c2ce,A semantic web approach to uplift decentralized household energy data,0.403571,"In a decentralized household energy system comprised of various devices such
as home appliances, electric vehicles, and solar panels, end-users are able to
dig deeper into the system's details and further achieve energy sustainability
if they are presented with data on the electric energy consumption and
production at the granularity of the device. However, many databases in this
field are siloed from other domains, including solely information pertaining to
energy. This may result in the loss of information (e.g. weather) on each
device's energy use. Meanwhile, a large number of these datasets have been
extensively used in computational modeling techniques such as machine learning
models. While such computational approaches achieve great accuracy and
performance by concentrating only on a local view of datasets, model
reliability cannot be guaranteed since such models are very vulnerable to data
input fluctuations when information omission is taken into account. This
article tackles the data isolation issue in the field of smart energy systems
by examining Semantic Web methods on top of a household energy system. We offer
an ontology-based approach for managing decentralized data at the device-level
resolution in a system. As a consequence, the scope of the data associated with
each device may easily be expanded in an interoperable manner throughout the
Web, and additional information, such as weather, can be obtained from the Web,
provided that the data is organized according to W3C standards.",https://github.com/futaoo/semantic-energy,-1
8542e4f8-044e-45da-855a-02a9e544f965,A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models,0.612578,"We have recently witnessed a number of impressive results on hard
mathematical reasoning problems with language models. At the same time, the
robustness of these models has also been called into question; recent works
have shown that models can rely on shallow patterns in the problem description
when generating a solution. Building on the idea of behavioral testing, we
propose a novel framework, which pins down the causal effect of various factors
in the input, e.g., the surface form of the problem text, the operands, and
math operators on the output solution. By grounding the behavioral analysis in
a causal graph describing an intuitive reasoning process, we study the behavior
of language models in terms of robustness and sensitivity to direct
interventions in the input space. We apply our framework on a test bed of math
word problems. Our analysis shows that robustness does not appear to
continuously improve as a function of size, but the GPT-3 Davinci models (175B)
achieve a dramatic improvement in both robustness and sensitivity compared to
all other GPT variants.",https://github.com/alestolfo/causal-math,-1
ee2567a0-77a0-4445-92d1-b84ebe523b3d,Learning with Style: Continual Semantic Segmentation Across Tasks and Domains,0.167203,"Deep learning models dealing with image understanding in real-world settings
must be able to adapt to a wide variety of tasks across different domains.
Domain adaptation and class incremental learning deal with domain and task
variability separately, whereas their unified solution is still an open
problem. We tackle both facets of the problem together, taking into account the
semantic shift within both input and label spaces. We start by formally
introducing continual learning under task and domain shift. Then, we address
the proposed setup by using style transfer techniques to extend knowledge
across domains when learning incremental tasks and a robust distillation
framework to effectively recollect task knowledge under incremental domain
shift. The devised framework (LwS, Learning with Style) is able to generalize
incrementally acquired task knowledge across all the domains encountered,
proving to be robust against catastrophic forgetting. Extensive experimental
evaluation on multiple autonomous driving datasets shows how the proposed
method outperforms existing approaches, which prove to be ill-equipped to deal
with continual semantic segmentation under both task and domain shift.",None,-1
58a1341e-9371-46bb-b319-6f0fa9e098f4,MnTTS2: An Open-Source Multi-Speaker Mongolian Text-to-Speech Synthesis Dataset,0.632121,"Text-to-Speech (TTS) synthesis for low-resource languages is an attractive
research issue in academia and industry nowadays. Mongolian is the official
language of the Inner Mongolia Autonomous Region and a representative
low-resource language spoken by over 10 million people worldwide. However,
there is a relative lack of open-source datasets for Mongolian TTS. Therefore,
we make public an open-source multi-speaker Mongolian TTS dataset, named
MnTTS2, for the benefit of related researchers. In this work, we prepare the
transcription from various topics and invite three professional Mongolian
announcers to form a three-speaker TTS dataset, in which each announcer records
10 hours of speeches in Mongolian, resulting 30 hours in total. Furthermore, we
build the baseline system based on the state-of-the-art FastSpeech2 model and
HiFi-GAN vocoder. The experimental results suggest that the constructed MnTTS2
dataset is sufficient to build robust multi-speaker TTS models for real-world
applications. The MnTTS2 dataset, training recipe, and pretrained models are
released at: \url{https://github.com/ssmlkl/MnTTS2}",https://github.com/ssmlkl/MnTTS2,-1
81127511-20c6-43a9-aded-31dadb527e48,Self-Configuring nnU-Nets Detect Clouds in Satellite Images,0.219173,"Cloud detection is a pivotal satellite image pre-processing step that can be
performed both on the ground and on board a satellite to tag useful images. In
the latter case, it can help to reduce the amount of data to downlink by
pruning the cloudy areas, or to make a satellite more autonomous through
data-driven acquisition re-scheduling of the cloudy areas. We approach this
important task with nnU-Nets, a self-reconfigurable framework able to perform
meta-learning of a segmentation network over various datasets. Our experiments,
performed over Sentinel-2 and Landsat-8 multispectral images revealed that
nnU-Nets deliver state-of-the-art cloud segmentation performance without any
manual design. Our approach was ranked within the top 7% best solutions (across
847 participating teams) in the On Cloud N: Cloud Cover Detection Challenge,
where we reached the Jaccard index of 0.882 over more than 10k unseen
Sentinel-2 image patches (the winners obtained 0.897, whereas the baseline
U-Net with the ResNet-34 backbone used as an encoder: 0.817, and the classic
Sentinel-2 image thresholding: 0.652).",https://gitlab.com/jnalepa/nnUNets_for_clouds,-1
9e3793a9-cbc9-4636-b0e0-6f65b73ac2a8,Learning a General Clause-to-Clause Relationships for Enhancing Emotion-Cause Pair Extraction,0.761617,"Emotion-cause pair extraction (ECPE) is an emerging task aiming to extract
potential pairs of emotions and corresponding causes from documents. Previous
approaches have focused on modeling the pair-to-pair relationship and achieved
promising results. However, the clause-to-clause relationship, which
fundamentally symbolizes the underlying structure of a document, has still been
in its research infancy. In this paper, we define a novel clause-to-clause
relationship. To learn it applicably, we propose a general clause-level
encoding model named EA-GAT comprising E-GAT and Activation Sort. E-GAT is
designed to aggregate information from different types of clauses; Activation
Sort leverages the individual emotion/cause prediction and the sort-based
mapping to propel the clause to a more favorable representation. Since EA-GAT
is a clause-level encoding model, it can be broadly integrated with any
previous approach. Experimental results show that our approach has a
significant advantage over all current approaches on the Chinese and English
benchmark corpus, with an average of $2.1\%$ and $1.03\%$.",None,-1
9d9f7d99-7ac4-42f1-81fa-8e07913bd8b0,"""My nose is running.""""Are you also coughing?"": Building A Medical Diagnosis Agent with Interpretable Inquiry Logics",0.358487,"With the rise of telemedicine, the task of developing Dialogue Systems for
Medical Diagnosis (DSMD) has received much attention in recent years. Different
from early researches that needed to rely on extra human resources and
expertise to help construct the system, recent researches focused on how to
build DSMD in a purely data-driven manner. However, the previous data-driven
DSMD methods largely overlooked the system interpretability, which is critical
for a medical application, and they also suffered from the data sparsity issue
at the same time. In this paper, we explore how to bring interpretability to
data-driven DSMD. Specifically, we propose a more interpretable decision
process to implement the dialogue manager of DSMD by reasonably mimicking real
doctors' inquiry logics, and we devise a model with highly transparent
components to conduct the inference. Moreover, we collect a new DSMD dataset,
which has a much larger scale, more diverse patterns and is of higher quality
than the existing ones. The experiments show that our method obtains 7.7%,
10.0%, 3.0% absolute improvement in diagnosis accuracy respectively on three
datasets, demonstrating the effectiveness of its rational decision process and
model design. Our codes and the GMD-12 dataset are available at
https://github.com/lwgkzl/BR-Agent.",https://github.com/lwgkzl/BR-Agent,-1
ab2e3ad1-ee97-4871-aa01-563a38a3722b,Federated learning for violence incident prediction in a simulated cross-institutional psychiatric setting,0.903522,"Inpatient violence is a common and severe problem within psychiatry. Knowing
who might become violent can influence staffing levels and mitigate severity.
Predictive machine learning models can assess each patient's likelihood of
becoming violent based on clinical notes. Yet, while machine learning models
benefit from having more data, data availability is limited as hospitals
typically do not share their data for privacy preservation. Federated Learning
(FL) can overcome the problem of data limitation by training models in a
decentralised manner, without disclosing data between collaborators. However,
although several FL approaches exist, none of these train Natural Language
Processing models on clinical notes. In this work, we investigate the
application of Federated Learning to clinical Natural Language Processing,
applied to the task of Violence Risk Assessment by simulating a
cross-institutional psychiatric setting. We train and compare four models: two
local models, a federated model and a data-centralised model. Our results
indicate that the federated model outperforms the local models and has similar
performance as the data-centralised model. These findings suggest that
Federated Learning can be used successfully in a cross-institutional setting
and is a step towards new applications of Federated Learning based on clinical
notes",None,-1
5a9c748d-ed35-4a79-9658-5dda5387c173,Commonsense and Named Entity Aware Knowledge Grounded Dialogue Generation,0.133075,"Grounding dialogue on external knowledge and interpreting linguistic patterns
in dialogue history context, such as ellipsis, anaphora, and co-references is
critical for dialogue comprehension and generation. In this paper, we present a
novel open-domain dialogue generation model which effectively utilizes the
large-scale commonsense and named entity based knowledge in addition to the
unstructured topic-specific knowledge associated with each utterance. We
enhance the commonsense knowledge with named entity-aware structures using
co-references. Our proposed model utilizes a multi-hop attention layer to
preserve the most accurate and critical parts of the dialogue history and the
associated knowledge. In addition, we employ a Commonsense and Named Entity
Enhanced Attention Module, which starts with the extracted triples from various
sources and gradually finds the relevant supporting set of triples using
multi-hop attention with the query vector obtained from the interactive
dialogue-knowledge module. Empirical results on two benchmark dataset
demonstrate that our model significantly outperforms the state-of-the-art
methods in terms of both automatic evaluation metrics and human judgment. Our
code is publicly available at
\href{https://github.com/deekshaVarshney/CNTF}{https://github.com/deekshaVarshney/CNTF};
\href{https://www.iitp.ac.in/~ai-nlp-ml/resources/codes/CNTF.zip}{https://www.iitp.ac.in/-ai-nlp-ml/resources/
codes/CNTF.zip}.",https://github.com/deekshaVarshney/CNTF,-1
7519908b-9ebf-4e93-aafe-056a9fe79925,KERPLE: Kernelized Relative Positional Embedding for Length Extrapolation,0.467197,"Relative positional embeddings (RPE) have received considerable attention
since RPEs effectively model the relative distance among tokens and enable
length extrapolation. We propose KERPLE, a framework that generalizes relative
position embedding for extrapolation by kernelizing positional differences. We
achieve this goal using conditionally positive definite (CPD) kernels, a class
of functions known for generalizing distance metrics. To maintain the inner
product interpretation of self-attention, we show that a CPD kernel can be
transformed into a PD kernel by adding a constant offset. This offset is
implicitly absorbed in the Softmax normalization during self-attention. The
diversity of CPD kernels allows us to derive various RPEs that enable length
extrapolation in a principled way. Experiments demonstrate that the logarithmic
variant achieves excellent extrapolation performance on three large language
modeling datasets. Our implementation and pretrained checkpoints are released
at https://github.com/chijames/KERPLE.git.",https://github.com/chijames/KERPLE.git,-1
164232e5-6614-4935-87d4-593cd5e8fbc7,The DLCC Node Classification Benchmark for Analyzing Knowledge Graph Embeddings,0.501291,"Knowledge graph embedding is a representation learning technique that
projects entities and relations in a knowledge graph to continuous vector
spaces. Embeddings have gained a lot of uptake and have been heavily used in
link prediction and other downstream prediction tasks. Most approaches are
evaluated on a single task or a single group of tasks to determine their
overall performance. The evaluation is then assessed in terms of how well the
embedding approach performs on the task at hand. Still, it is hardly evaluated
(and often not even deeply understood) what information the embedding
approaches are actually learning to represent.
  To fill this gap, we present the DLCC (Description Logic Class Constructors)
benchmark, a resource to analyze embedding approaches in terms of which kinds
of classes they can represent. Two gold standards are presented, one based on
the real-world knowledge graph DBpedia and one synthetic gold standard. In
addition, an evaluation framework is provided that implements an experiment
protocol so that researchers can directly use the gold standard. To demonstrate
the use of DLCC, we compare multiple embedding approaches using the gold
standards. We find that many DL constructors on DBpedia are actually learned by
recognizing different correlated patterns than those defined in the gold
standard and that specific DL constructors, such as cardinality constraints,
are particularly hard to be learned for most embedding approaches.",None,-1
7a36e1b2-ab57-45e8-a1f6-844782404a53,ImageArg: A Multi-modal Tweet Dataset for Image Persuasiveness Mining,0.844932,"The growing interest in developing corpora of persuasive texts has promoted
applications in automated systems, e.g., debating and essay scoring systems;
however, there is little prior work mining image persuasiveness from an
argumentative perspective. To expand persuasiveness mining into a multi-modal
realm, we present a multi-modal dataset, ImageArg, consisting of annotations of
image persuasiveness in tweets. The annotations are based on a persuasion
taxonomy we developed to explore image functionalities and the means of
persuasion. We benchmark image persuasiveness tasks on ImageArg using
widely-used multi-modal learning methods. The experimental results show that
our dataset offers a useful resource for this rich and challenging topic, and
there is ample room for modeling improvement.",https://github.com/MeiqiGuo/ArgMining2022-ImageArg,-1
f3d208ff-3e88-440a-aaa8-68905abf3bf6,StyleBabel: Artistic Style Tagging and Captioning,0.249782,"We present StyleBabel, a unique open access dataset of natural language
captions and free-form tags describing the artistic style of over 135K digital
artworks, collected via a novel participatory method from experts studying at
specialist art and design schools. StyleBabel was collected via an iterative
method, inspired by `Grounded Theory': a qualitative approach that enables
annotation while co-evolving a shared language for fine-grained artistic style
attribute description. We demonstrate several downstream tasks for StyleBabel,
adapting the recent ALADIN architecture for fine-grained style similarity, to
train cross-modal embeddings for: 1) free-form tag generation; 2) natural
language description of artistic style; 3) fine-grained text search of style.
To do so, we extend ALADIN with recent advances in Visual Transformer (ViT) and
cross-modal representation learning, achieving a state of the art accuracy in
fine-grained style retrieval.",None,-1
a7243b5d-e31e-40b4-bb85-ff30db019190,CPED: A Large-Scale Chinese Personalized and Emotional Dialogue Dataset for Conversational AI,0.5966,"Human language expression is based on the subjective construal of the
situation instead of the objective truth conditions, which means that speakers'
personalities and emotions after cognitive processing have an important
influence on conversation. However, most existing datasets for conversational
AI ignore human personalities and emotions, or only consider part of them. It's
difficult for dialogue systems to understand speakers' personalities and
emotions although large-scale pre-training language models have been widely
used. In order to consider both personalities and emotions in the process of
conversation generation, we propose CPED, a large-scale Chinese personalized
and emotional dialogue dataset, which consists of multi-source knowledge
related to empathy and personal characteristic. These knowledge covers gender,
Big Five personality traits, 13 emotions, 19 dialogue acts and 10 scenes. CPED
contains more than 12K dialogues of 392 speakers from 40 TV shows. We release
the textual dataset with audio features and video features according to the
copyright claims, privacy issues, terms of service of video platforms. We
provide detailed description of the CPED construction process and introduce
three tasks for conversational AI, including personality recognition, emotion
recognition in conversations as well as personalized and emotional conversation
generation. Finally, we provide baseline systems for these tasks and consider
the function of speakers' personalities and emotions on conversation. Our
motivation is to propose a dataset to be widely adopted by the NLP community as
a new open benchmark for conversational AI research. The full dataset is
available at https://github.com/scutcyr/CPED.",None,-1
57859df6-455c-4b9c-a049-68e9fc3fe8cf,VRKitchen2.0-IndoorKit: A Tutorial for Augmented Indoor Scene Building in Omniverse,0.206621,"With the recent progress of simulations by 3D modeling software and game
engines, many researchers have focused on Embodied AI tasks in the virtual
environment. However, the research community lacks a platform that can easily
serve both indoor scene synthesis and model benchmarking with various
algorithms. Meanwhile, computer graphics-related tasks need a toolkit for
implementing advanced synthesizing techniques. To facilitate the study of
indoor scene building methods and their potential robotics applications, we
introduce INDOORKIT: a built-in toolkit for NVIDIA OMNIVERSE that provides
flexible pipelines for indoor scene building, scene randomizing, and animation
controls. Besides, combining Python coding in the animation software INDOORKIT
assists researchers in creating real-time training and controlling avatars and
robotics. The source code for this toolkit is available at
https://github.com/realvcla/VRKitchen2.0-Tutorial, and the tutorial along with
the toolkit is available at https://vrkitchen20-tutorial.readthedocs.io/en/",https://github.com/realvcla/VRKitchen2.0-Tutorial,-1
dc0cfe32-d380-4407-b164-fab4f3873504,IMU2CLIP: Multimodal Contrastive Learning for IMU Motion Sensors from Egocentric Videos and Text,0.413927,"We present IMU2CLIP, a novel pre-training approach to align Inertial
Measurement Unit (IMU) motion sensor recordings with video and text, by
projecting them into the joint representation space of Contrastive
Language-Image Pre-training (CLIP). The proposed approach allows IMU2CLIP to
translate human motions (as measured by IMU sensors) into their corresponding
textual descriptions and videos -- while preserving the transitivity across
these modalities.
  We explore several new IMU-based applications that IMU2CLIP enables, such as
motion-based media retrieval and natural language reasoning tasks with motion
data. In addition, we show that IMU2CLIP can significantly improve the
downstream performance when fine-tuned for each application (e.g. activity
recognition), demonstrating the universal usage of IMU2CLIP as a new
pre-trained resource. Our code will be made publicly available.",None,-1
2d2b45cd-bc65-41b6-862e-8598036ccf7e,Harnessing Artificial Intelligence to Infer Novel Spatial Biomarkers for the Diagnosis of Eosinophilic Esophagitis,0.271492,"Eosinophilic esophagitis (EoE) is a chronic allergic inflammatory condition
of the esophagus associated with elevated esophageal eosinophils. Second only
to gastroesophageal reflux disease, EoE is one of the leading causes of chronic
refractory dysphagia in adults and children. EoE diagnosis requires enumerating
the density of esophageal eosinophils in esophageal biopsies, a somewhat
subjective task that is time-consuming, thus reducing the ability to process
the complex tissue structure. Previous artificial intelligence (AI) approaches
that aimed to improve histology-based diagnosis focused on recapitulating
identification and quantification of the area of maximal eosinophil density.
However, this metric does not account for the distribution of eosinophils or
other histological features, over the whole slide image. Here, we developed an
artificial intelligence platform that infers local and spatial biomarkers based
on semantic segmentation of intact eosinophils and basal zone distributions.
Besides the maximal density of eosinophils (referred to as Peak Eosinophil
Count [PEC]) and a maximal basal zone fraction, we identify two additional
metrics that reflect the distribution of eosinophils and basal zone fractions.
This approach enables a decision support system that predicts EoE activity and
classifies the histological severity of EoE patients. We utilized a cohort that
includes 1066 biopsy slides from 400 subjects to validate the system's
performance and achieved a histological severity classification accuracy of
86.70%, sensitivity of 84.50%, and specificity of 90.09%. Our approach
highlights the importance of systematically analyzing the distribution of
biopsy features over the entire slide and paves the way towards a personalized
decision support system that will assist not only in counting cells but can
also potentially improve diagnosis and provide treatment prediction.",None,73438
77381d0a-fb5c-4a61-9522-1182a59a196c,FAPM: Fast Adaptive Patch Memory for Real-time Industrial Anomaly Detection,0.923662,"Feature embedding-based methods have shown exceptional performance in
detecting industrial anomalies by comparing features of target images with
normal images. However, some methods do not meet the speed requirements of
real-time inference, which is crucial for real-world applications. To address
this issue, we propose a new method called Fast Adaptive Patch Memory (FAPM)
for real-time industrial anomaly detection. FAPM utilizes patch-wise and
layer-wise memory banks that store the embedding features of images at the
patch and layer level, respectively, which eliminates unnecessary repetitive
computations. We also propose patch-wise adaptive coreset sampling for faster
and more accurate detection. FAPM performs well in both accuracy and speed
compared to other state-of-the-art methods",None,-1
4792756c-d2d0-4ef9-a8d6-5db46f4af4db,SeedFormer: Patch Seeds based Point Cloud Completion with Upsample Transformer,0.894548,"Point cloud completion has become increasingly popular among generation tasks
of 3D point clouds, as it is a challenging yet indispensable problem to recover
the complete shape of a 3D object from its partial observation. In this paper,
we propose a novel SeedFormer to improve the ability of detail preservation and
recovery in point cloud completion. Unlike previous methods based on a global
feature vector, we introduce a new shape representation, namely Patch Seeds,
which not only captures general structures from partial inputs but also
preserves regional information of local patterns. Then, by integrating seed
features into the generation process, we can recover faithful details for
complete point clouds in a coarse-to-fine manner. Moreover, we devise an
Upsample Transformer by extending the transformer structure into basic
operations of point generators, which effectively incorporates spatial and
semantic relationships between neighboring points. Qualitative and quantitative
evaluations demonstrate that our method outperforms state-of-the-art completion
networks on several benchmark datasets. Our code is available at
https://github.com/hrzhou2/seedformer.",https://github.com/hrzhou2/seedformer,-1
31f5c7a0-26c1-493e-b055-d6f8a7cdcd2a,SciNLI: A Corpus for Natural Language Inference on Scientific Text,0.745651,"Existing Natural Language Inference (NLI) datasets, while being instrumental
in the advancement of Natural Language Understanding (NLU) research, are not
related to scientific text. In this paper, we introduce SciNLI, a large dataset
for NLI that captures the formality in scientific text and contains 107,412
sentence pairs extracted from scholarly papers on NLP and computational
linguistics. Given that the text used in scientific literature differs vastly
from the text used in everyday language both in terms of vocabulary and
sentence structure, our dataset is well suited to serve as a benchmark for the
evaluation of scientific NLU models. Our experiments show that SciNLI is harder
to classify than the existing NLI datasets. Our best performing model with
XLNet achieves a Macro F1 score of only 78.18% and an accuracy of 78.23%
showing that there is substantial room for improvement.",https://github.com/msadat3/SciNLI,6491
71ff8374-0019-4aed-8bb3-89b88e0bf372,4D-MultispectralNet: Multispectral Stereoscopic Disparity Estimation using Human Masks,0.202127,"Multispectral stereoscopy is an emerging field. A lot of work has been done
in classical stereoscopy, but multispectral stereoscopy is not studied as
frequently. This type of stereoscopy can be used in autonomous vehicles to
complete the information given by RGB cameras. It helps to identify objects in
the surroundings when the conditions are more difficult, such as in night
scenes. This paper focuses on the RGB-LWIR spectrum. RGB-LWIR stereoscopy has
the same challenges as classical stereoscopy, that is occlusions, textureless
surfaces and repetitive patterns, plus specific ones related to the different
modalities. Finding matches between two spectrums adds another layer of
complexity. Color, texture and shapes are more likely to vary from a spectrum
to another. To address this additional challenge, this paper focuses on
estimating the disparity of people present in a scene. Given the fact that
people's shape is captured in both RGB and LWIR, we propose a novel method that
uses segmentation masks of the human in both spectrum and than concatenate them
to the original images before the first layer of a Siamese Network. This method
helps to improve the accuracy, particularly within the one pixel error range.",https://github.com/philippeDG/4D-MultispectralNet,-1
bd0e479d-923e-4e65-80dc-c781faf1e8e5,Data Feedback Loops: Model-driven Amplification of Dataset Biases,0.649881,"Datasets scraped from the internet have been critical to the successes of
large-scale machine learning. Yet, this very success puts the utility of future
internet-derived datasets at potential risk, as model outputs begin to replace
human annotations as a source of supervision.
  In this work, we first formalize a system where interactions with one model
are recorded as history and scraped as training data in the future. We then
analyze its stability over time by tracking changes to a test-time bias
statistic (e.g. gender bias of model predictions). We find that the degree of
bias amplification is closely linked to whether the model's outputs behave like
samples from the training distribution, a behavior which we characterize and
define as consistent calibration. Experiments in three conditional prediction
scenarios - image classification, visual role-labeling, and language generation
- demonstrate that models that exhibit a sampling-like behavior are more
calibrated and thus more stable. Based on this insight, we propose an
intervention to help calibrate and stabilize unstable feedback systems.
  Code is available at https://github.com/rtaori/data_feedback.",https://github.com/rtaori/data_feedback,-1
959b0f53-dc81-4b0d-a6a1-104a1d2aac4b,Cross-view and Cross-domain Underwater Localization based on Optical Aerial and Acoustic Underwater Images,0.528609,"Cross-view image matches have been widely explored on terrestrial image
localization using aerial images from drones or satellites. This study expands
the cross-view image match idea and proposes a cross-domain and cross-view
localization framework. The method identifies the correlation between color
aerial images and underwater acoustic images to improve the localization of
underwater vehicles that travel in partially structured environments such as
harbors and marinas. The approach is validated on a real dataset acquired by an
underwater vehicle in a marina. The results show an improvement in the
localization when compared to the dead reckoning of the vehicle.",https://github.com/matheusbg8/aracati2017,-1
0b39f0f0-5bdc-43f1-b47d-cdce09395d80,Is GPT-3 all you need for Visual Question Answering in Cultural Heritage?,0.327602,"The use of Deep Learning and Computer Vision in the Cultural Heritage domain
is becoming highly relevant in the last few years with lots of applications
about audio smart guides, interactive museums and augmented reality. All these
technologies require lots of data to work effectively and be useful for the
user. In the context of artworks, such data is annotated by experts in an
expensive and time consuming process. In particular, for each artwork, an image
of the artwork and a description sheet have to be collected in order to perform
common tasks like Visual Question Answering. In this paper we propose a method
for Visual Question Answering that allows to generate at runtime a description
sheet that can be used for answering both visual and contextual questions about
the artwork, avoiding completely the image and the annotation process. For this
purpose, we investigate on the use of GPT-3 for generating descriptions for
artworks analyzing the quality of generated descriptions through captioning
metrics. Finally we evaluate the performance for Visual Question Answering and
captioning tasks.",None,656
9c32738a-ccd1-4bb1-a9cc-337c4338b54b,The four-fifths rule is not disparate impact: a woeful tale of epistemic trespassing in algorithmic fairness,0.732937,"Computer scientists are trained to create abstractions that simplify and
generalize. However, a premature abstraction that omits crucial contextual
details creates the risk of epistemic trespassing, by falsely asserting its
relevance into other contexts. We study how the field of responsible AI has
created an imperfect synecdoche by abstracting the four-fifths rule (a.k.a. the
4/5 rule or 80% rule), a single part of disparate impact discrimination law,
into the disparate impact metric. This metric incorrectly introduces a new
deontic nuance and new potentials for ethical harms that were absent in the
original 4/5 rule. We also survey how the field has amplified the potential for
harm in codifying the 4/5 rule into popular AI fairness software toolkits. The
harmful erasure of legal nuances is a wake-up call for computer scientists to
self-critically re-evaluate the abstractions they create and use, particularly
in the interdisciplinary field of AI ethics.",None,-1
9907b102-64a7-4125-9c45-723cb7cf6a78,Graph Coloring with Physics-Inspired Graph Neural Networks,0.358783,"We show how graph neural networks can be used to solve the canonical graph
coloring problem. We frame graph coloring as a multi-class node classification
problem and utilize an unsupervised training strategy based on the statistical
physics Potts model. Generalizations to other multi-class problems such as
community detection, data clustering, and the minimum clique cover problem are
straightforward. We provide numerical benchmark results and illustrate our
approach with an end-to-end application for a real-world scheduling use case
within a comprehensive encode-process-decode framework. Our optimization
approach performs on par or outperforms existing solvers, with the ability to
scale to problems with millions of variables.",https://github.com/amazon-research/gcp-with-gnns-example,-1
cf654840-8e8c-40d9-81c4-43d4d145cb4e,Less is More: Learning to Refine Dialogue History for Personalized Dialogue Generation,0.896592,"Personalized dialogue systems explore the problem of generating responses
that are consistent with the user's personality, which has raised much
attention in recent years. Existing personalized dialogue systems have tried to
extract user profiles from dialogue history to guide personalized response
generation. Since the dialogue history is usually long and noisy, most existing
methods truncate the dialogue history to model the user's personality. Such
methods can generate some personalized responses, but a large part of dialogue
history is wasted, leading to sub-optimal performance of personalized response
generation. In this work, we propose to refine the user dialogue history on a
large scale, based on which we can handle more dialogue history and obtain more
abundant and accurate persona information. Specifically, we design an MSP model
which consists of three personal information refiners and a personalized
response generator. With these multi-level refiners, we can sparsely extract
the most valuable information (tokens) from the dialogue history and leverage
other similar users' data to enhance personalization. Experimental results on
two real-world datasets demonstrate the superiority of our model in generating
more informative and personalized responses.",https://github.com/bangbangbang12315/MSP/tree/release,-1
aec9975b-adda-407c-9537-7f8f1376cc30,Looking at the Overlooked: An Analysis on the Word-Overlap Bias in Natural Language Inference,0.454463,"It has been shown that NLI models are usually biased with respect to the
word-overlap between premise and hypothesis; they take this feature as a
primary cue for predicting the entailment label. In this paper, we focus on an
overlooked aspect of the overlap bias in NLI models: the reverse word-overlap
bias. Our experimental results demonstrate that current NLI models are highly
biased towards the non-entailment label on instances with low overlap, and the
existing debiasing methods, which are reportedly successful on existing
challenge datasets, are generally ineffective in addressing this category of
bias. We investigate the reasons for the emergence of the overlap bias and the
role of minority examples in its mitigation. For the former, we find that the
word-overlap bias does not stem from pre-training, and for the latter, we
observe that in contrast to the accepted assumption, eliminating minority
examples does not affect the generalizability of debiasing methods with respect
to the overlap bias.",https://github.com/sara-rajaee/reverse_bias,-1
3cfb316c-e08f-417b-b283-15100b4bca0c,Heart rate estimation in intense exercise videos,0.606504,"Estimating heart rate from video allows non-contact health monitoring with
applications in patient care, human interaction, and sports. Existing work can
robustly measure heart rate under some degree of motion by face tracking.
However, this is not always possible in unconstrained settings, as the face
might be occluded or even outside the camera. Here, we present IntensePhysio: a
challenging video heart rate estimation dataset with realistic face occlusions,
severe subject motion, and ample heart rate variation. To ensure heart rate
variation in a realistic setting we record each subject for around 1-2 hours.
The subject is exercising (at a moderate to high intensity) on a cycling
ergometer with an attached video camera and is given no instructions regarding
positioning or movement. We have 11 subjects, and approximately 20 total hours
of video. We show that the existing remote photo-plethysmography methods have
difficulty in estimating heart rate in this setting. In addition, we present
IBIS-CNN, a new baseline using spatio-temporal superpixels, which improves on
existing models by eliminating the need for a visible face/face tracking. We
will make the code and data publically available soon.",https://github.com/ynapolean/IBIS-CNN,-1
e43bc829-0b81-487c-8728-4ac12d94f61a,DEER: Descriptive Knowledge Graph for Explaining Entity Relationships,0.628506,"We propose DEER (Descriptive Knowledge Graph for Explaining Entity
Relationships) - an open and informative form of modeling entity relationships.
In DEER, relationships between entities are represented by free-text relation
descriptions. For instance, the relationship between entities of machine
learning and algorithm can be represented as ``Machine learning explores the
study and construction of algorithms that can learn from and make predictions
on data.'' To construct DEER, we propose a self-supervised learning method to
extract relation descriptions with the analysis of dependency patterns and
generate relation descriptions with a transformer-based relation description
synthesizing model, where no human labeling is required. Experiments
demonstrate that our system can extract and generate high-quality relation
descriptions for explaining entity relationships. The results suggest that we
can build an open and informative knowledge graph without human annotation.",https://github.com/jeffhj/DEER,-1
55f06078-072d-4a3d-876b-97820f13b04f,SHREC 2022 Track on Online Detection of Heterogeneous Gestures,0.282976,"This paper presents the outcomes of a contest organized to evaluate methods
for the online recognition of heterogeneous gestures from sequences of 3D hand
poses. The task is the detection of gestures belonging to a dictionary of 16
classes characterized by different pose and motion features. The dataset
features continuous sequences of hand tracking data where the gestures are
interleaved with non-significant motions. The data have been captured using the
Hololens 2 finger tracking system in a realistic use-case of mixed reality
interaction. The evaluation is based not only on the detection performances but
also on the latency and the false positives, making it possible to understand
the feasibility of practical interaction tools based on the algorithms
proposed. The outcomes of the contest's evaluation demonstrate the necessity of
further research to reduce recognition errors, while the computational cost of
the algorithms proposed is sufficiently low.",None,-1
261da98e-e62b-4e1f-b74a-57b44e57d99d,Learning Perception-Aware Agile Flight in Cluttered Environments,0.77599,"Recently, neural control policies have outperformed existing model-based
planning-and-control methods for autonomously navigating quadrotors through
cluttered environments in minimum time. However, they are not perception aware,
a crucial requirement in vision-based navigation due to the camera's limited
field of view and the underactuated nature of a quadrotor. We propose a
learning-based system that achieves perception-aware, agile flight in cluttered
environments. Our method combines imitation learning with reinforcement
learning (RL) by leveraging a privileged learning-by-cheating framework. Using
RL, we first train a perception-aware teacher policy with full-state
information to fly in minimum time through cluttered environments. Then, we use
imitation learning to distill its knowledge into a vision-based student policy
that only perceives the environment via a camera. Our approach tightly couples
perception and control, showing a significant advantage in computation speed
(10 times faster) and success rate. We demonstrate the closed-loop control
performance using hardware-in-the-loop simulation.",None,-1
ef4076ae-3d88-433a-a47a-985e58cbdd60,RMGN: A Regional Mask Guided Network for Parser-free Virtual Try-on,0.693199,"Virtual try-on(VTON) aims at fitting target clothes to reference person
images, which is widely adopted in e-commerce.Existing VTON approaches can be
narrowly categorized into Parser-Based(PB) and Parser-Free(PF) by whether
relying on the parser information to mask the persons' clothes and synthesize
try-on images. Although abandoning parser information has improved the
applicability of PF methods, the ability of detail synthesizing has also been
sacrificed. As a result, the distraction from original cloth may persistin
synthesized images, especially in complicated postures and high resolution
applications. To address the aforementioned issue, we propose a novel PF method
named Regional Mask Guided Network(RMGN). More specifically, a regional mask is
proposed to explicitly fuse the features of target clothes and reference
persons so that the persisted distraction can be eliminated. A posture
awareness loss and a multi-level feature extractor are further proposed to
handle the complicated postures and synthesize high resolution images.
Extensive experiments demonstrate that our proposed RMGN outperforms both
state-of-the-art PB and PF methods.Ablation studies further verify the
effectiveness ofmodules in RMGN.",https://github.com/jokerlc/RMGN-VITON,-1
75f4325a-9815-4640-b35c-69b92172cb7b,Clues Before Answers: Generation-Enhanced Multiple-Choice QA,0.982885,"A trending paradigm for multiple-choice question answering (MCQA) is using a
text-to-text framework. By unifying data in different tasks into a single
text-to-text format, it trains a generative encoder-decoder model which is both
powerful and universal. However, a side effect of twisting a generation target
to fit the classification nature of MCQA is the under-utilization of the
decoder and the knowledge that can be decoded. To exploit the generation
capability and underlying knowledge of a pre-trained encoder-decoder model, in
this paper, we propose a generation-enhanced MCQA model named GenMC. It
generates a clue from the question and then leverages the clue to enhance a
reader for MCQA. It outperforms text-to-text models on multiple MCQA datasets.",https://github.com/nju-websoft/GenMC,-1
0591de13-8c13-463b-910e-f3b5babcf656,On the Effect of Anticipation on Reading Times,0.726785,"Over the past two decades, numerous studies have demonstrated how less
predictable (i.e., higher surprisal) words take more time to read. In general,
these studies have implicitly assumed the reading process is purely responsive:
Readers observe a new word and allocate time to process it as required. We
argue that prior results are also compatible with a reading process that is at
least partially anticipatory: Readers could make predictions about a future
word and allocate time to process it based on their expectation. In this work,
we operationalize this anticipation as a word's contextual entropy. We assess
the effect of anticipation on reading by comparing how well surprisal and
contextual entropy predict reading times on four naturalistic reading datasets:
two self-paced and two eye-tracking. Experimentally, across datasets and
analyses, we find substantial evidence for effects of contextual entropy over
surprisal on a word's reading time (RT): in fact, entropy is sometimes better
than surprisal in predicting a word's RT. Spillover effects, however, are
generally not captured by entropy, but only by surprisal. Further, we
hypothesize four cognitive mechanisms through which contextual entropy could
impact RTs -- three of which we are able to design experiments to analyze.
Overall, our results support a view of reading that is not just responsive, but
also anticipatory.",https://github.com/rycolab/anticipation-on-reading-times,-1
0ac14974-0044-4e9a-b5db-7de47c9a3e5e,SDS-200: A Swiss German Speech to Standard German Text Corpus,0.928154,"We present SDS-200, a corpus of Swiss German dialectal speech with Standard
German text translations, annotated with dialect, age, and gender information
of the speakers. The dataset allows for training speech translation, dialect
recognition, and speech synthesis systems, among others. The data was collected
using a web recording tool that is open to the public. Each participant was
given a text in Standard German and asked to translate it to their Swiss German
dialect before recording it. To increase the corpus quality, recordings were
validated by other participants. The data consists of 200 hours of speech by
around 4000 different speakers and covers a large part of the Swiss-German
dialect landscape. We release SDS-200 alongside a baseline speech translation
model, which achieves a word error rate (WER) of 30.3 and a BLEU score of 53.1
on the SDS-200 test set. Furthermore, we use SDS-200 to fine-tune a pre-trained
XLS-R model, achieving 21.6 WER and 64.0 BLEU.",https://github.com/stt4sg/,-1
c585244e-26b7-4e7b-a1f7-9e0942604b1e,Contrastive Language-Image Pre-Training with Knowledge Graphs,0.584548,"Recent years have witnessed the fast development of large-scale pre-training
frameworks that can extract multi-modal representations in a unified form and
achieve promising performances when transferred to downstream tasks.
Nevertheless, existing approaches mainly focus on pre-training with simple
image-text pairs, while neglecting the semantic connections between concepts
from different modalities. In this paper, we propose a knowledge-based
pre-training framework, dubbed Knowledge-CLIP, which injects semantic
information into the widely used CLIP model. Through introducing
knowledge-based objectives in the pre-training process and utilizing different
types of knowledge graphs as training data, our model can semantically align
the representations in vision and language with higher quality, and enhance the
reasoning ability across scenarios and modalities. Extensive experiments on
various vision-language downstream tasks demonstrate the effectiveness of
Knowledge-CLIP compared with the original CLIP and competitive baselines.",None,-1
b31d7c4a-5535-42c5-8547-e408cec2a64e,Differentially Private Counterfactuals via Functional Mechanism,0.264414,"Counterfactual, serving as one emerging type of model explanation, has
attracted tons of attentions recently from both industry and academia.
Different from the conventional feature-based explanations (e.g.,
attributions), counterfactuals are a series of hypothetical samples which can
flip model decisions with minimal perturbations on queries. Given valid
counterfactuals, humans are capable of reasoning under ``what-if''
circumstances, so as to better understand the model decision boundaries.
However, releasing counterfactuals could be detrimental, since it may
unintentionally leak sensitive information to adversaries, which brings about
higher risks on both model security and data privacy. To bridge the gap, in
this paper, we propose a novel framework to generate differentially private
counterfactual (DPC) without touching the deployed model or explanation set,
where noises are injected for protection while maintaining the explanation
roles of counterfactual. In particular, we train an autoencoder with the
functional mechanism to construct noisy class prototypes, and then derive the
DPC from the latent prototypes based on the post-processing immunity of
differential privacy. Further evaluations demonstrate the effectiveness of the
proposed framework, showing that DPC can successfully relieve the risks on both
extraction and inference attacks.",None,-1
01ec561b-637e-4bf1-858d-0c2bafdc3aa6,BlazePose GHUM Holistic: Real-time 3D Human Landmarks and Pose Estimation,0.711012,"We present BlazePose GHUM Holistic, a lightweight neural network pipeline for
3D human body landmarks and pose estimation, specifically tailored to real-time
on-device inference. BlazePose GHUM Holistic enables motion capture from a
single RGB image including avatar control, fitness tracking and AR/VR effects.
Our main contributions include i) a novel method for 3D ground truth data
acquisition, ii) updated 3D body tracking with additional hand landmarks and
iii) full body pose estimation from a monocular image.",https://mediapipe.dev,19004
29bcea78-0a74-4dce-9c8d-043f3845bade,Applying Automatic Text Summarization for Fake News Detection,0.562473,"The distribution of fake news is not a new but a rapidly growing problem. The
shift to news consumption via social media has been one of the drivers for the
spread of misleading and deliberately wrong information, as in addition to it
of easy use there is rarely any veracity monitoring. Due to the harmful effects
of such fake news on society, the detection of these has become increasingly
important. We present an approach to the problem that combines the power of
transformer-based language models while simultaneously addressing one of their
inherent problems. Our framework, CMTR-BERT, combines multiple text
representations, with the goal of circumventing sequential limits and related
loss of information the underlying transformer architecture typically suffers
from. Additionally, it enables the incorporation of contextual information.
Extensive experiments on two very different, publicly available datasets
demonstrates that our approach is able to set new state-of-the-art performance
benchmarks. Apart from the benefit of using automatic text summarization
techniques we also find that the incorporation of contextual information
contributes to performance gains.",https://github.com/phHartl/lrec_2022,-1
d5ef96fc-b4e5-41e5-b895-53be21d7e4c1,Policy Optimization with Advantage Regularization for Long-Term Fairness in Decision Systems,0.368922,"Long-term fairness is an important factor of consideration in designing and
deploying learning-based decision systems in high-stake decision-making
contexts. Recent work has proposed the use of Markov Decision Processes (MDPs)
to formulate decision-making with long-term fairness requirements in
dynamically changing environments, and demonstrated major challenges in
directly deploying heuristic and rule-based policies that worked well in static
environments. We show that policy optimization methods from deep reinforcement
learning can be used to find strictly better decision policies that can often
achieve both higher overall utility and less violation of the fairness
requirements, compared to previously-known strategies. In particular, we
propose new methods for imposing fairness requirements in policy optimization
by regularizing the advantage evaluation of different actions. Our proposed
methods make it easy to impose fairness constraints without reward engineering
or sacrificing training efficiency. We perform detailed analyses in three
established case studies, including attention allocation in incident
monitoring, bank loan approval, and vaccine distribution in population
networks.",None,-1
74f151d1-3227-45e8-bdb3-3f82296f7ef7,Quality Diversity Evolutionary Learning of Decision Trees,0.210901,"Addressing the need for explainable Machine Learning has emerged as one of
the most important research directions in modern Artificial Intelligence (AI).
While the current dominant paradigm in the field is based on black-box models,
typically in the form of (deep) neural networks, these models lack direct
interpretability for human users, i.e., their outcomes (and, even more so,
their inner working) are opaque and hard to understand. This is hindering the
adoption of AI in safety-critical applications, where high interests are at
stake. In these applications, explainable by design models, such as decision
trees, may be more suitable, as they provide interpretability. Recent works
have proposed the hybridization of decision trees and Reinforcement Learning,
to combine the advantages of the two approaches. So far, however, these works
have focused on the optimization of those hybrid models. Here, we apply
MAP-Elites for diversifying hybrid models over a feature space that captures
both the model complexity and its behavioral variability. We apply our method
on two well-known control problems from the OpenAI Gym library, on which we
discuss the ""illumination"" patterns projected by MAP-Elites, comparing its
results against existing similar approaches.",None,-1
77f29bfe-d064-49c9-9e30-427e16dc1a28,Cold-Start Data Selection for Few-shot Language Model Fine-tuning: A Prompt-Based Uncertainty Propagation Approach,0.437965,"Large Language Models have demonstrated remarkable few-shot performance, but
the performance can be sensitive to the selection of few-shot instances. We
propose PATRON, a new method that uses prompt-based uncertainty estimation for
data selection for pre-trained language model fine-tuning under cold-start
scenarios, i.e., no initial labeled data are available. In PATRON, we design
(1) a prompt-based uncertainty propagation approach to estimate the importance
of data points and (2) a partition-then-rewrite (PTR) strategy to promote
sample diversity when querying for annotations. Experiments on six text
classification datasets show that PATRON outperforms the strongest cold-start
data selection baselines by up to 6.9%. Besides, with 128 labels only, PATRON
achieves 91.0% and 92.1% of the fully supervised performance based on vanilla
fine-tuning and prompt-based learning respectively. Our implementation of
PATRON is available at \url{https://github.com/yueyu1030/Patron}.",https://github.com/yueyu1030/Patron,-1
6843514b-73f2-4dd1-81ab-820ec934a605,AlphaDesign: A graph protein design method and benchmark on AlphaFoldDB,0.91636,"While DeepMind has tentatively solved protein folding, its inverse problem --
protein design which predicts protein sequences from their 3D structures --
still faces significant challenges. Particularly, the lack of large-scale
standardized benchmark and poor accuray hinder the research progress. In order
to standardize comparisons and draw more research interest, we use AlphaFold
DB, one of the world's largest protein structure databases, to establish a new
graph-based benchmark -- AlphaDesign. Based on AlphaDesign, we propose a new
method called ADesign to improve accuracy by introducing protein angles as new
features, using a simplified graph transformer encoder (SGT), and proposing a
confidence-aware protein decoder (CPD). Meanwhile, SGT and CPD also improve
model efficiency by simplifying the training and testing procedures.
Experiments show that ADesign significantly outperforms previous graph models,
e.g., the average accuracy is improved by 8\%, and the inference speed is 40+
times faster than before.",None,-1
647ddd4f-bc5e-403e-a916-e8cb2a72a15e,Asynchronous Actor-Critic for Multi-Agent Reinforcement Learning,0.692917,"Synchronizing decisions across multiple agents in realistic settings is
problematic since it requires agents to wait for other agents to terminate and
communicate about termination reliably. Ideally, agents should learn and
execute asynchronously instead. Such asynchronous methods also allow temporally
extended actions that can take different amounts of time based on the situation
and action executed. Unfortunately, current policy gradient methods are not
applicable in asynchronous settings, as they assume that agents synchronously
reason about action selection at every time step. To allow asynchronous
learning and decision-making, we formulate a set of asynchronous multi-agent
actor-critic methods that allow agents to directly optimize asynchronous
policies in three standard training paradigms: decentralized learning,
centralized learning, and centralized training for decentralized execution.
Empirical results (in simulation and hardware) in a variety of realistic
domains demonstrate the superiority of our approaches in large multi-agent
problems and validate the effectiveness of our algorithms for learning
high-quality and asynchronous solutions.",https://github.com/mgualti/PointCloudsPython,-1
7da17f29-1636-461d-aa35-92a0afce16fd,Federated Learning with Heterogeneous Architectures using Graph HyperNetworks,0.632121,"Standard Federated Learning (FL) techniques are limited to clients with
identical network architectures. This restricts potential use-cases like
cross-platform training or inter-organizational collaboration when both data
privacy and architectural proprietary are required. We propose a new FL
framework that accommodates heterogeneous client architecture by adopting a
graph hypernetwork for parameter sharing. A property of the graph hyper network
is that it can adapt to various computational graphs, thereby allowing
meaningful parameter sharing across models. Unlike existing solutions, our
framework does not limit the clients to share the same architecture type, makes
no use of external data and does not require clients to disclose their model
architecture. Compared with distillation-based and non-graph hypernetwork
baselines, our method performs notably better on standard benchmarks. We
additionally show encouraging generalization performance to unseen
architectures.",None,-1
527dc796-091f-4981-85c0-24b7001d3a26,BEV-Locator: An End-to-end Visual Semantic Localization Network Using Multi-View Images,0.264469,"Accurate localization ability is fundamental in autonomous driving.
Traditional visual localization frameworks approach the semantic map-matching
problem with geometric models, which rely on complex parameter tuning and thus
hinder large-scale deployment. In this paper, we propose BEV-Locator: an
end-to-end visual semantic localization neural network using multi-view camera
images. Specifically, a visual BEV (Birds-Eye-View) encoder extracts and
flattens the multi-view images into BEV space. While the semantic map features
are structurally embedded as map queries sequence. Then a cross-model
transformer associates the BEV features and semantic map queries. The
localization information of ego-car is recursively queried out by
cross-attention modules. Finally, the ego pose can be inferred by decoding the
transformer outputs. We evaluate the proposed method in large-scale nuScenes
and Qcraft datasets. The experimental results show that the BEV-locator is
capable to estimate the vehicle poses under versatile scenarios, which
effectively associates the cross-model information from multi-view images and
global semantic maps. The experiments report satisfactory accuracy with mean
absolute errors of 0.052m, 0.135m and 0.251$^\circ$ in lateral, longitudinal
translation and heading angle degree.",None,-1
fd6cc292-9c7d-42c9-bbd7-8f1233fc4b8d,CI-AVSR: A Cantonese Audio-Visual Speech Dataset for In-car Command Recognition,0.638463,"With the rise of deep learning and intelligent vehicle, the smart assistant
has become an essential in-car component to facilitate driving and provide
extra functionalities. In-car smart assistants should be able to process
general as well as car-related commands and perform corresponding actions,
which eases driving and improves safety. However, there is a data scarcity
issue for low resource languages, hindering the development of research and
applications. In this paper, we introduce a new dataset, Cantonese In-car
Audio-Visual Speech Recognition (CI-AVSR), for in-car command recognition in
the Cantonese language with both video and audio data. It consists of 4,984
samples (8.3 hours) of 200 in-car commands recorded by 30 native Cantonese
speakers. Furthermore, we augment our dataset using common in-car background
noises to simulate real environments, producing a dataset 10 times larger than
the collected one. We provide detailed statistics of both the clean and the
augmented versions of our dataset. Moreover, we implement two multimodal
baselines to demonstrate the validity of CI-AVSR. Experiment results show that
leveraging the visual signal improves the overall performance of the model.
Although our best model can achieve a considerable quality on the clean test
set, the speech recognition quality on the noisy data is still inferior and
remains as an extremely challenging task for real in-car speech recognition
systems. The dataset and code will be released at
https://github.com/HLTCHKUST/CI-AVSR.",https://github.com/HLTCHKUST/CI-AVSR,-1
ac6e2222-e7f1-4985-9ce1-16665fcb1360,Predicting and Explaining Mobile UI Tappability with Vision Modeling and Saliency Analysis,0.962557,"We use a deep learning based approach to predict whether a selected element
in a mobile UI screenshot will be perceived by users as tappable, based on
pixels only instead of view hierarchies required by previous work. To help
designers better understand model predictions and to provide more actionable
design feedback than predictions alone, we additionally use ML interpretability
techniques to help explain the output of our model. We use XRAI to highlight
areas in the input screenshot that most strongly influence the tappability
prediction for the selected region, and use k-Nearest Neighbors to present the
most similar mobile UIs from the dataset with opposing influences on
tappability perception.",None,-1
b36e0158-e98c-4b8d-96fc-a346dad45aa9,Lipschitz-constrained Unsupervised Skill Discovery,0.902285,"We study the problem of unsupervised skill discovery, whose goal is to learn
a set of diverse and useful skills with no external reward. There have been a
number of skill discovery methods based on maximizing the mutual information
(MI) between skills and states. However, we point out that their MI objectives
usually prefer static skills to dynamic ones, which may hinder the application
for downstream tasks. To address this issue, we propose Lipschitz-constrained
Skill Discovery (LSD), which encourages the agent to discover more diverse,
dynamic, and far-reaching skills. Another benefit of LSD is that its learned
representation function can be utilized for solving goal-following downstream
tasks even in a zero-shot manner - i.e., without further training or complex
planning. Through experiments on various MuJoCo robotic locomotion and
manipulation environments, we demonstrate that LSD outperforms previous
approaches in terms of skill diversity, state space coverage, and performance
on seven downstream tasks including the challenging task of following multiple
goals on Humanoid. Our code and videos are available at
https://shpark.me/projects/lsd/.",https://vision.snu.ac.kr/projects/lsd/,-1
8bdfab2f-4c7e-40d2-9d9b-29abbc93fd32,Black-box Prompt Learning for Pre-trained Language Models,0.447845,"The increasing scale of general-purpose Pre-trained Language Models (PLMs)
necessitates the study of more efficient adaptation across different downstream
tasks. In this paper, we establish a Black-box Discrete Prompt Learning (BDPL)
to resonate with pragmatic interactions between the cloud infrastructure and
edge devices. Particularly, instead of fine-tuning the model in the cloud, we
adapt PLMs by prompt learning, which efficiently optimizes only a few
parameters of the discrete prompts. Moreover, we consider the scenario that we
do not have access to the parameters and gradients of the pre-trained models,
except for its outputs given inputs. This black-box setting secures the cloud
infrastructure from potential attack and misuse to cause a single-point
failure, which is preferable to the white-box counterpart by current
infrastructures. Under this black-box constraint, we apply a variance-reduced
policy gradient algorithm to estimate the gradients of parameters in the
categorical distribution of each discrete prompt. In light of our method, the
user devices can efficiently tune their tasks by querying the PLMs bounded by a
range of API calls. Our experiments on RoBERTa and GPT-3 demonstrate that the
proposed algorithm achieves significant improvement on eight benchmarks in a
cloud-device collaboration manner. Finally, we conduct in-depth case studies to
comprehensively analyze our method in terms of various data sizes, prompt
lengths, training budgets, optimization objectives, prompt transferability, and
explanations of the learned prompts. Our code will be available at
https://github.com/shizhediao/Black-Box-Prompt-Learning.",None,-1
14f1c326-12fa-460f-a695-8ab582f068d0,DFA: Dynamic Feature Aggregation for Efficient Video Object Detection,0.622218,"Video object detection is a fundamental yet challenging task in computer
vision. One practical solution is to take advantage of temporal information
from the video and apply feature aggregation to enhance the object features in
each frame. Though effective, those existing methods always suffer from low
inference speeds because they use a fixed number of frames for feature
aggregation regardless of the input frame. Therefore, this paper aims to
improve the inference speed of the current feature aggregation-based video
object detectors while maintaining their performance. To achieve this goal, we
propose a vanilla dynamic aggregation module that adaptively selects the frames
for feature enhancement. Then, we extend the vanilla dynamic aggregation module
to a more effective and reconfigurable deformable version. Finally, we
introduce inplace distillation loss to improve the representations of objects
aggregated with fewer frames. Extensive experimental results validate the
effectiveness and efficiency of our proposed methods: On the ImageNet VID
benchmark, integrated with our proposed methods, FGFA and SELSA can improve the
inference speed by 31% and 76% respectively while getting comparable
performance on accuracy.",https://github.com/open-mmlab/mmtracking,-1
ae8cab73-8746-491c-ab78-3b9124180caa,A Note on the Regularity of Images Generated by Convolutional Neural Networks,0.176022,"The regularity of images generated by convolutional neural networks, such as
the U-net, generative networks, or the deep image prior, is analyzed. In a
resolution-independent, infinite dimensional setting, it is shown that such
images, represented as functions, are always continuous and, in some
circumstances, even continuously differentiable, contradicting the widely
accepted modeling of sharp edges in images via jump discontinuities. While such
statements require an infinite dimensional setting, the connection to
(discretized) neural networks used in practice is made by considering the limit
as the resolution approaches infinity. As practical consequence, the results of
this paper in particular provide analytical evidence that basic L2
regularization of network weights might lead to over-smoothed outputs.",https://github.com/aangelopoulos/im2im-uq,-1
df4667a0-4767-489f-918f-3512bddd08c5,"Continual Learning, Fast and Slow",0.568865,"According to the Complementary Learning Systems (CLS)
theory~\cite{mcclelland1995there} in neuroscience, humans do effective
\emph{continual learning} through two complementary systems: a fast learning
system centered on the hippocampus for rapid learning of the specifics,
individual experiences; and a slow learning system located in the neocortex for
the gradual acquisition of structured knowledge about the environment.
Motivated by this theory, we propose \emph{DualNets} (for Dual Networks), a
general continual learning framework comprising a fast learning system for
supervised learning of pattern-separated representation from specific tasks and
a slow learning system for representation learning of task-agnostic general
representation via Self-Supervised Learning (SSL). DualNets can seamlessly
incorporate both representation types into a holistic framework to facilitate
better continual learning in deep neural networks. Via extensive experiments,
we demonstrate the promising results of DualNets on a wide range of continual
learning protocols, ranging from the standard offline, task-aware setting to
the challenging online, task-free scenario. Notably, on the
CTrL~\cite{veniat2020efficient} benchmark that has unrelated tasks with vastly
different visual images, DualNets can achieve competitive performance with
existing state-of-the-art dynamic architecture
strategies~\cite{ostapenko2021continual}. Furthermore, we conduct comprehensive
ablation studies to validate DualNets efficacy, robustness, and scalability.
Code will be made available at \url{https://github.com/phquang/DualNet}.",https://github.com/phquang/DualNet,-1
5b530edb-e3c5-4a99-ba4a-cbc5ebe64de8,Improving Multi-Document Summarization through Referenced Flexible Extraction with Credit-Awareness,0.867076,"A notable challenge in Multi-Document Summarization (MDS) is the
extremely-long length of the input. In this paper, we present an
extract-then-abstract Transformer framework to overcome the problem.
Specifically, we leverage pre-trained language models to construct a
hierarchical extractor for salient sentence selection across documents and an
abstractor for rewriting the selected contents as summaries. However, learning
such a framework is challenging since the optimal contents for the abstractor
are generally unknown. Previous works typically create pseudo extraction oracle
to enable the supervised learning for both the extractor and the abstractor.
Nevertheless, we argue that the performance of such methods could be restricted
due to the insufficient information for prediction and inconsistent objectives
between training and testing. To this end, we propose a loss weighting
mechanism that makes the model aware of the unequal importance for the
sentences not in the pseudo extraction oracle, and leverage the fine-tuned
abstractor to generate summary references as auxiliary signals for learning the
extractor. Moreover, we propose a reinforcement learning method that can
efficiently apply to the extractor for harmonizing the optimization between
training and testing. Experiment results show that our framework substantially
outperforms strong baselines with comparable model sizes and achieves the best
results on the Multi-News, Multi-XScience, and WikiCatSum corpora.",None,-1
7de7502e-eb10-49f4-82dc-8d359190a5fb,Interactive Style Transfer: All is Your Palette,0.0945781,"Neural style transfer (NST) can create impressive artworks by transferring
reference style to content image. Current image-to-image NST methods are short
of fine-grained controls, which are often demanded by artistic editing. To
mitigate this limitation, we propose a drawing-like interactive style transfer
(IST) method, by which users can interactively create a harmonious-style image.
Our IST method can serve as a brush, dip style from anywhere, and then paint to
any region of the target content image. To determine the action scope, we
formulate a fluid simulation algorithm, which takes styles as pigments around
the position of brush interaction, and diffusion in style or content images
according to the similarity maps. Our IST method expands the creative dimension
of NST. By dipping and painting, even employing one style image can produce
thousands of eye-catching works. The demo video is available in supplementary
files or in http://mmcheng.net/ist.",None,-1
f540e077-c824-4f70-8646-b4a397ef2c91,End-to-end model for named entity recognition from speech without paired training data,0.753686,"Recent works showed that end-to-end neural approaches tend to become very
popular for spoken language understanding (SLU). Through the term end-to-end,
one considers the use of a single model optimized to extract semantic
information directly from the speech signal. A major issue for such models is
the lack of paired audio and textual data with semantic annotation. In this
paper, we propose an approach to build an end-to-end neural model to extract
semantic information in a scenario in which zero paired audio data is
available. Our approach is based on the use of an external model trained to
generate a sequence of vectorial representations from text. These
representations mimic the hidden representations that could be generated inside
an end-to-end automatic speech recognition (ASR) model by processing a speech
signal. An SLU neural module is then trained using these representations as
input and the annotated text as output. Last, the SLU module replaces the top
layers of the ASR model to achieve the construction of the end-to-end model.
Our experiments on named entity recognition, carried out on the QUAERO corpus,
show that this approach is very promising, getting better results than a
comparable cascade approach or than the use of synthetic voices.",https://github.com/mdhaffar/Named-Entity-Recognition,-1
e906d36c-70b5-409a-bbc0-bc3f3a25cf6b,Detection of Tool based Edited Images from Error Level Analysis and Convolutional Neural Network,0.222681,"Image Forgery is a problem of image forensics and its detection can be
leveraged using Deep Learning. In this paper we present an approach for
identification of authentic and tampered images done using image editing tools
with Error Level Analysis and Convolutional Neural Network. The process is
performed on CASIA ITDE v2 dataset and trained for 50 and 100 epochs
respectively. The respective accuracies of the training and validation sets are
represented using graphs.",None,-1
d77c22bf-357a-4b42-98d8-8eaabd122dd7,Accelerating Code Search with Deep Hashing and Code Classification,0.47169,"Code search is to search reusable code snippets from source code corpus based
on natural languages queries. Deep learning-based methods of code search have
shown promising results. However, previous methods focus on retrieval accuracy
but lacked attention to the efficiency of the retrieval process. We propose a
novel method CoSHC to accelerate code search with deep hashing and code
classification, aiming to perform an efficient code search without sacrificing
too much accuracy. To evaluate the effectiveness of CoSHC, we apply our method
to five code search models. Extensive experimental results indicate that
compared with previous code search baselines, CoSHC can save more than 90% of
retrieval time meanwhile preserving at least 99% of retrieval accuracy.",None,-1
150ac79e-4f77-447c-b440-b5e9718f499b,Revisiting End-to-End Speech-to-Text Translation From Scratch,0.97047,"End-to-end (E2E) speech-to-text translation (ST) often depends on pretraining
its encoder and/or decoder using source transcripts via speech recognition or
text translation tasks, without which translation performance drops
substantially. However, transcripts are not always available, and how
significant such pretraining is for E2E ST has rarely been studied in the
literature. In this paper, we revisit this question and explore the extent to
which the quality of E2E ST trained on speech-translation pairs alone can be
improved. We reexamine several techniques proven beneficial to ST previously,
and offer a set of best practices that biases a Transformer-based E2E ST system
toward training from scratch. Besides, we propose parameterized distance
penalty to facilitate the modeling of locality in the self-attention model for
speech. On four benchmarks covering 23 languages, our experiments show that,
without using any transcripts or pretraining, the proposed system reaches and
even outperforms previous studies adopting pretraining, although the gap
remains in (extremely) low-resource settings. Finally, we discuss neural
acoustic feature modeling, where a neural model is designed to extract acoustic
features from raw speech signals directly, with the goal to simplify inductive
biases and add freedom to the model in describing speech. For the first time,
we demonstrate its feasibility and show encouraging results on ST tasks.",None,21498
29fa583b-e65e-4435-8793-9d5623bb29d4,Pessimistic Off-Policy Optimization for Learning to Rank,0.165876,"Off-policy learning is a framework for optimizing policies without deploying
them, using data collected by another policy. In recommender systems, this is
especially challenging due to the imbalance in logged data: some items are
recommended and thus logged more frequently than others. This is further
perpetuated when recommending a list of items, as the action space is
combinatorial. To address this challenge, we study pessimistic off-policy
optimization for learning to rank. The key idea is to compute lower confidence
bounds on parameters of click models and then return the list with the highest
pessimistic estimate of its value. This approach is computationally efficient
and we analyze it. We study its Bayesian and frequentist variants, and overcome
the limitation of unknown prior by incorporating empirical Bayes. To show the
empirical effectiveness of our approach, we compare it to off-policy optimizers
that use inverse propensity scores or neglect uncertainty. Our approach
outperforms all baselines, is robust, and is also general.",None,5108
5b5d6798-0d92-4ded-bdd3-9c2492f10096,SalesBot: Transitioning from Chit-Chat to Task-Oriented Dialogues,0.783454,"Dialogue systems are usually categorized into two types, open-domain and
task-oriented. The first one focuses on chatting with users and making them
engage in the conversations, where selecting a proper topic to fit the dialogue
context is essential for a successful dialogue. The other one focuses on a
specific task instead of casual talks, e.g., finding a movie on Friday night,
or playing a song. These two directions have been studied separately due to
their different purposes. However, how smoothly transitioning from social
chatting to task-oriented dialogues is important for triggering business
opportunities, and there is no public data focusing on such scenarios. Hence,
this paper focuses on investigating the conversations starting from open-domain
social chatting and then gradually transitioning to task-oriented purposes, and
releases a large-scale dataset with detailed annotations for encouraging this
research direction. To achieve this goal, this paper proposes a framework to
automatically generate many dialogues without human involvement, in which any
powerful open-domain dialogue generation model can be easily leveraged. The
human evaluation shows that our generated dialogue data has a natural flow at a
reasonable quality, showing that our released data has a great potential of
guiding future research directions and commercial activities. Furthermore, the
released models allow researchers to automatically generate unlimited dialogues
in the target scenarios, which can greatly benefit semi-supervised and
unsupervised approaches.",https://github.com/MiuLab/SalesBot,-1
6c620f23-2b10-428c-aa52-a278671e4109,A Transfer Learning and Optimized CNN Based Intrusion Detection System for Internet of Vehicles,0.868415,"Modern vehicles, including autonomous vehicles and connected vehicles, are
increasingly connected to the external world, which enables various
functionalities and services. However, the improving connectivity also
increases the attack surfaces of the Internet of Vehicles (IoV), causing its
vulnerabilities to cyber-threats. Due to the lack of authentication and
encryption procedures in vehicular networks, Intrusion Detection Systems (IDSs)
are essential approaches to protect modern vehicle systems from network
attacks. In this paper, a transfer learning and ensemble learning-based IDS is
proposed for IoV systems using convolutional neural networks (CNNs) and
hyper-parameter optimization techniques. In the experiments, the proposed IDS
has demonstrated over 99.25% detection rates and F1-scores on two well-known
public benchmark IoV security datasets: the Car-Hacking dataset and the
CICIDS2017 dataset. This shows the effectiveness of the proposed IDS for
cyber-attack detection in both intra-vehicle and external vehicular networks.",https://github.com/Western-OC2-Lab/Intrusion-,-1
39dbe16c-390a-4c96-b012-9261eadda4c9,Algorithmic progress in computer vision,0.595847,"We investigate algorithmic progress in image classification on ImageNet,
perhaps the most well-known test bed for computer vision. We estimate a model,
informed by work on neural scaling laws, and infer a decomposition of progress
into the scaling of compute, data, and algorithms. Using Shapley values to
attribute performance improvements, we find that algorithmic improvements have
been roughly as important as the scaling of compute for progress computer
vision. Our estimates indicate that algorithmic innovations mostly take the
form of compute-augmenting algorithmic advances (which enable researchers to
get better performance from less compute), not data-augmenting algorithmic
advances. We find that compute-augmenting algorithmic advances are made at a
pace more than twice as fast as the rate usually associated with Moore's law.
In particular, we estimate that compute-augmenting innovations halve compute
requirements every nine months (95\% confidence interval: 4 to 25 months).",None,-1
d26f83ac-ab6f-413c-b978-694d0cf00a18,Sar Ship Detection based on Swin Transformer and Feature Enhancement Feature Pyramid Network,0.784527,"With the booming of Convolutional Neural Networks (CNNs), CNNs such as VGG-16
and ResNet-50 widely serve as backbone in SAR ship detection. However, CNN
based backbone is hard to model long-range dependencies, and causes the lack of
enough high-quality semantic information in feature maps of shallow layers,
which leads to poor detection performance in complicated background and
small-sized ships cases. To address these problems, we propose a SAR ship
detection method based on Swin Transformer and Feature Enhancement Feature
Pyramid Network (FEFPN). Swin Transformer serves as backbone to model
long-range dependencies and generates hierarchical features maps. FEFPN is
proposed to further improve the quality of feature maps by gradually enhancing
the semantic information of feature maps at all levels, especially feature maps
in shallow layers. Experiments conducted on SAR ship detection dataset (SSDD)
reveal the advantage of our proposed methods.",None,-1
a8521e28-8b15-4901-afba-f6bd7904dd03,CLRNet: Cross Layer Refinement Network for Lane Detection,0.980127,"Lane is critical in the vision navigation system of the intelligent vehicle.
Naturally, lane is a traffic sign with high-level semantics, whereas it owns
the specific local pattern which needs detailed low-level features to localize
accurately. Using different feature levels is of great importance for accurate
lane detection, but it is still under-explored. In this work, we present Cross
Layer Refinement Network (CLRNet) aiming at fully utilizing both high-level and
low-level features in lane detection. In particular, it first detects lanes
with high-level semantic features then performs refinement based on low-level
features. In this way, we can exploit more contextual information to detect
lanes while leveraging local detailed lane features to improve localization
accuracy. We present ROIGather to gather global context, which further enhances
the feature representation of lanes. In addition to our novel network design,
we introduce Line IoU loss which regresses the lane line as a whole unit to
improve the localization accuracy. Experiments demonstrate that the proposed
method greatly outperforms the state-of-the-art lane detection approaches.",None,-1
0c6dfb0c-8de0-411b-9827-da11ff916ef3,LiDAR-MIMO: Efficient Uncertainty Estimation for LiDAR-based 3D Object Detection,0.161925,"The estimation of uncertainty in robotic vision, such as 3D object detection,
is an essential component in developing safe autonomous systems aware of their
own performance. However, the deployment of current uncertainty estimation
methods in 3D object detection remains challenging due to timing and
computational constraints. To tackle this issue, we propose LiDAR-MIMO, an
adaptation of the multi-input multi-output (MIMO) uncertainty estimation method
to the LiDAR-based 3D object detection task. Our method modifies the original
MIMO by performing multi-input at the feature level to ensure the detection,
uncertainty estimation, and runtime performance benefits are retained despite
the limited capacity of the underlying detector and the large computational
costs of point cloud processing. We compare LiDAR-MIMO with MC dropout and
ensembles as baselines and show comparable uncertainty estimation results with
only a small number of output heads. Further, LiDAR-MIMO can be configured to
be twice as fast as MC dropout and ensembles, while achieving higher mAP than
MC dropout and approaching that of ensembles.",https://github.com/open-mmlab/OpenPCDet,12580
75388502-de18-4d96-ad47-686a85ef2a41,Research on Dual Channel News Headline Classification Based on ERNIE Pre-training Model,0.492335,"The classification of news headlines is an important direction in the field
of NLP, and its data has the characteristics of compactness, uniqueness and
various forms. Aiming at the problem that the traditional neural network model
cannot adequately capture the underlying feature information of the data and
cannot jointly extract key global features and deep local features, a
dual-channel network model DC-EBAD based on the ERNIE pre-training model is
proposed. Use ERNIE to extract the lexical, semantic and contextual feature
information at the bottom of the text, generate dynamic word vector
representations fused with context, and then use the BiLSTM-AT network channel
to secondary extract the global features of the data and use the attention
mechanism to give key parts higher The weight of the DPCNN channel is used to
overcome the long-distance text dependence problem and obtain deep local
features. The local and global feature vectors are spliced, and finally passed
to the fully connected layer, and the final classification result is output
through Softmax. The experimental results show that the proposed model improves
the accuracy, precision and F1-score of news headline classification compared
with the traditional neural network model and the single-channel model under
the same conditions. It can be seen that it can perform well in the
multi-classification application of news headline text under large data volume.",None,-1
82136e18-5c10-4209-ba92-a0829ff85cd4,CrackSeg9k: A Collection and Benchmark for Crack Segmentation Datasets and Frameworks,0.316485,"The detection of cracks is a crucial task in monitoring structural health and
ensuring structural safety. The manual process of crack detection is
time-consuming and subjective to the inspectors. Several researchers have tried
tackling this problem using traditional Image Processing or learning-based
techniques. However, their scope of work is limited to detecting cracks on a
single type of surface (walls, pavements, glass, etc.). The metrics used to
evaluate these methods are also varied across the literature, making it
challenging to compare techniques. This paper addresses these problems by
combining previously available datasets and unifying the annotations by
tackling the inherent problems within each dataset, such as noise and
distortions. We also present a pipeline that combines Image Processing and Deep
Learning models. Finally, we benchmark the results of proposed models on these
metrics on our new dataset and compare them with state-of-the-art models in the
literature.",None,-1
a0d8f5d1-11a3-4542-9df4-c09097b0b5e7,Partial Wasserstein Adversarial Network for Non-rigid Point Set Registration,0.235025,"Given two point sets, the problem of registration is to recover a
transformation that matches one set to the other. This task is challenging due
to the presence of the large number of outliers, the unknown non-rigid
deformations and the large sizes of point sets. To obtain strong robustness
against outliers, we formulate the registration problem as a partial
distribution matching (PDM) problem, where the goal is to partially match the
distributions represented by point sets in a metric space. To handle large
point sets, we propose a scalable PDM algorithm by utilizing the efficient
partial Wasserstein-1 (PW) discrepancy. Specifically, we derive the
Kantorovich-Rubinstein duality for the PW discrepancy, and show its gradient
can be explicitly computed. Based on these results, we propose a partial
Wasserstein adversarial network (PWAN), which is able to approximate the PW
discrepancy by a neural network, and minimize it by gradient descent. In
addition, it also incorporates an efficient coherence regularizer for non-rigid
transformations to avoid unrealistic deformations. We evaluate PWAN on
practical point set registration tasks, and show that the proposed PWAN is
robust, scalable and performs more favorably than the state-of-the-art methods.",None,-1
0ecec887-f046-427e-bd26-63ff775758c0,Physically Inspired Constraint for Unsupervised Regularized Ultrasound Elastography,0.513725,"Displacement estimation is a critical step of virtually all Ultrasound
Elastography (USE) techniques. Two main features make this task unique compared
to the general optical flow problem: the high-frequency nature of ultrasound
radio-frequency (RF) data and the governing laws of physics on the displacement
field. Recently, the architecture of the optical flow networks has been
modified to be able to use RF data. Also, semi-supervised and unsupervised
techniques have been employed for USE by considering prior knowledge of
displacement continuity in the form of the first- and second-derivative
regularizers. Despite these attempts, no work has considered the tissue
compression pattern, and displacements in axial and lateral directions have
been assumed to be independent. However, tissue motion pattern is governed by
laws of physics in USE, rendering the axial and the lateral displacements
highly correlated. In this paper, we propose Physically Inspired ConsTraint for
Unsupervised Regularized Elastography (PICTURE), where we impose constraints on
the Poisson's ratio to improve lateral displacement estimates. Experiments on
phantom and in vivo data show that PICTURE substantially improves the quality
of the lateral displacement estimation.",None,-1
a2e54acc-afb9-46cb-9910-4123f04f19f9,Personalized Federated Learning for Multi-task Fault Diagnosis of Rotating Machinery,0.42607,"Intelligent fault diagnosis is essential to safe operation of machinery.
However, due to scarce fault samples and data heterogeneity in field machinery,
deep learning based diagnosis methods are prone to over-fitting with poor
generalization ability. To solve the problem, this paper proposes a
personalized federated learning framework, enabling multi-task fault diagnosis
method across multiple factories in a privacypreserving manner. Firstly,
rotating machines from different factories with similar vibration feature data
are categorized into machine groups using a federated clustering method. Then,
a multi-task deep learning model based on convolutional neural network is
constructed to diagnose the multiple faults of machinery with heterogeneous
information fusion. Finally, a personalized federated learning framework is
proposed to solve data heterogeneity across different machines using adaptive
hierarchical aggregation strategy. The case study on collected data from real
machines verifies the effectiveness of the proposed framework. The result shows
that the diagnosis accuracy could be improved significantly using the proposed
personalized federated learning, especially for those machines with scarce
fault samples.",None,-1
74648a8a-0102-4bc7-9232-afed4f3a1e35,Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer,0.876453,"Videos are created to express emotion, exchange information, and share
experiences. Video synthesis has intrigued researchers for a long time. Despite
the rapid progress driven by advances in visual synthesis, most existing
studies focus on improving the frames' quality and the transitions between
them, while little progress has been made in generating longer videos. In this
paper, we present a method that builds on 3D-VQGAN and transformers to generate
videos with thousands of frames. Our evaluation shows that our model trained on
16-frame video clips from standard benchmarks such as UCF-101, Sky Time-lapse,
and Taichi-HD datasets can generate diverse, coherent, and high-quality long
videos. We also showcase conditional extensions of our approach for generating
meaningful long videos by incorporating temporal information with text and
audio. Videos and code can be found at
https://songweige.github.io/projects/tats/index.html.",https://songweige.github.io/projects/tats,-1
65d2d232-c9e0-477a-8faf-056b29545506,Formal Contracts Mitigate Social Dilemmas in Multi-Agent RL,0.474923,"Multi-agent Reinforcement Learning (MARL) is a powerful tool for training
autonomous agents acting independently in a common environment. However, it can
lead to sub-optimal behavior when individual incentives and group incentives
diverge. Humans are remarkably capable at solving these social dilemmas. It is
an open problem in MARL to replicate such cooperative behaviors in selfish
agents. In this work, we draw upon the idea of formal contracting from
economics to overcome diverging incentives between agents in MARL. We propose
an augmentation to a Markov game where agents voluntarily agree to binding
transfers of reward, under pre-specified conditions. Our contributions are
theoretical and empirical. First, we show that this augmentation makes all
subgame-perfect equilibria of all Fully Observable Markov Games exhibit
socially optimal behavior, given a sufficiently rich space of contracts. Next,
we show that for general contract spaces, and even under partial observability,
richer contract spaces lead to higher welfare. Hence, contract space design
solves an exploration-exploitation tradeoff, sidestepping incentive issues. We
complement our theoretical analysis with experiments. Issues of exploration in
the contracting augmentation are mitigated using a training methodology
inspired by multi-objective reinforcement learning: Multi-Objective Contract
Augmentation Learning (MOCA). We test our methodology in static, single-move
games, as well as dynamic domains that simulate traffic, pollution management
and common pool resource management.",https://github.com/Algorithmic-Alignment-Lab/contracts,-1
9a517990-d66b-40d5-8981-af53922461aa,CoShNet: A Hybrid Complex Valued Neural Network using Shearlets,0.113597,"In a hybrid neural network, the expensive convolutional layers are replaced
by a non-trainable fixed transform with a great reduction in parameters. In
previous works, good results were obtained by replacing the convolutions with
wavelets. However, wavelet based hybrid network inherited wavelet's lack of
vanishing moments along curves and its axis-bias. We propose to use Shearlets
with its robust support for important image features like edges, ridges and
blobs. The resulting network is called Complex Shearlets Network (CoShNet). It
was tested on Fashion-MNIST against ResNet-50 and Resnet-18, obtaining 92.2%
versus 90.7% and 91.8% respectively. The proposed network has 49.9k parameters
versus ResNet-18 with 11.18m and use 52 times fewer FLOPs. Finally, we trained
in under 20 epochs versus 200 epochs required by ResNet and do not need any
hyperparameter tuning nor regularization.
  Code: https://github.com/Ujjawal-K-Panchal/coshnet",https://github.com/Ujjawal-K-Panchal/coshnet,-1
a5a27e88-4619-4a8f-a44e-cdd009174b8d,Tell Your Story: Task-Oriented Dialogs for Interactive Content Creation,0.168002,"People capture photos and videos to relive and share memories of personal
significance. Recently, media montages (stories) have become a popular mode of
sharing these memories due to their intuitive and powerful storytelling
capabilities. However, creating such montages usually involves a lot of manual
searches, clicks, and selections that are time-consuming and cumbersome,
adversely affecting user experiences.
  To alleviate this, we propose task-oriented dialogs for montage creation as a
novel interactive tool to seamlessly search, compile, and edit montages from a
media collection. To the best of our knowledge, our work is the first to
leverage multi-turn conversations for such a challenging application, extending
the previous literature studying simple media retrieval tasks. We collect a new
dataset C3 (Conversational Content Creation), comprising 10k dialogs
conditioned on media montages simulated from a large media collection.
  We take a simulate-and-paraphrase approach to collect these dialogs to be
both cost and time efficient, while drawing from natural language distribution.
Our analysis and benchmarking of state-of-the-art language models showcase the
multimodal challenges present in the dataset. Lastly, we present a real-world
mobile demo application that shows the feasibility of the proposed work in
real-world applications. Our code and data will be made publicly available.",None,-1
308b2dda-18a8-4730-b8bf-a709241da18e,Using Sentence Embeddings and Semantic Similarity for Seeking Consensus when Assessing Trustworthy AI,0.263061,"Assessing the trustworthiness of artificial intelligence systems requires
knowledge from many different disciplines. These disciplines do not necessarily
share concepts between them and might use words with different meanings, or
even use the same words differently. Additionally, experts from different
disciplines might not be aware of specialized terms readily used in other
disciplines. Therefore, a core challenge of the assessment process is to
identify when experts from different disciplines talk about the same problem
but use different terminologies. In other words, the problem is to group
problem descriptions (a.k.a. issues) with the same semantic meaning but
described using slightly different terminologies.
  In this work, we show how we employed recent advances in natural language
processing, namely sentence embeddings and semantic textual similarity, to
support this identification process and to bridge communication gaps in
interdisciplinary teams of experts assessing the trustworthiness of an
artificial intelligence system used in healthcare.",None,-1
4175ddc7-0014-4486-9c32-2e19666487ba,Human Evaluation and Correlation with Automatic Metrics in Consultation Note Generation,0.99605,"In recent years, machine learning models have rapidly become better at
generating clinical consultation notes; yet, there is little work on how to
properly evaluate the generated consultation notes to understand the impact
they may have on both the clinician using them and the patient's clinical
safety. To address this we present an extensive human evaluation study of
consultation notes where 5 clinicians (i) listen to 57 mock consultations, (ii)
write their own notes, (iii) post-edit a number of automatically generated
notes, and (iv) extract all the errors, both quantitative and qualitative. We
then carry out a correlation study with 18 automatic quality metrics and the
human judgements. We find that a simple, character-based Levenshtein distance
metric performs on par if not better than common model-based metrics like
BertScore. All our findings and annotations are open-sourced.",https://github.com/babylonhealth/primock57,-1
383573ed-cbb2-4ec2-814b-e4ef4d362482,FSGANv2: Improved Subject Agnostic Face Swapping and Reenactment,0.529659,"We present Face Swapping GAN (FSGAN) for face swapping and reenactment.
Unlike previous work, we offer a subject agnostic swapping scheme that can be
applied to pairs of faces without requiring training on those faces. We derive
a novel iterative deep learning--based approach for face reenactment which
adjusts significant pose and expression variations that can be applied to a
single image or a video sequence. For video sequences, we introduce a
continuous interpolation of the face views based on reenactment, Delaunay
Triangulation, and barycentric coordinates. Occluded face regions are handled
by a face completion network. Finally, we use a face blending network for
seamless blending of the two faces while preserving the target skin color and
lighting conditions. This network uses a novel Poisson blending loss combining
Poisson optimization with a perceptual loss. We compare our approach to
existing state-of-the-art systems and show our results to be both qualitatively
and quantitatively superior. This work describes extensions of the FSGAN
method, proposed in an earlier conference version of our work, as well as
additional experiments and results.",None,4658
8ad4ae5b-cee4-4588-bd8c-a3dc478bd4ac,ET5: A Novel End-to-end Framework for Conversational Machine Reading Comprehension,0.497345,"Conversational machine reading comprehension (CMRC) aims to assist computers
to understand an natural language text and thereafter engage in a multi-turn
conversation to answer questions related to the text. Existing methods
typically require three steps: (1) decision making based on entailment
reasoning; (2) span extraction if required by the above decision; (3) question
rephrasing based on the extracted span. However, for nearly all these methods,
the span extraction and question rephrasing steps cannot fully exploit the
fine-grained entailment reasoning information in decision making step because
of their relative independence, which will further enlarge the information gap
between decision making and question phrasing. Thus, to tackle this problem, we
propose a novel end-to-end framework for conversational machine reading
comprehension based on shared parameter mechanism, called entailment reasoning
T5 (ET5). Despite the lightweight of our proposed framework, experimental
results show that the proposed ET5 achieves new state-of-the-art results on the
ShARC leaderboard with the BLEU-4 score of 55.2. Our model and code are
publicly available at https://github.com/Yottaxx/ET5.",https://github.com/Yottaxx/ET5,-1
9d235447-5757-4323-b5df-3ab213258cfc,UAV-aided Wireless Node Localization Using Hybrid Radio Channel Models,0.328558,"This paper considers the problem of ground user localization based on
received signal strength (RSS) measurements obtained by an unmanned aerial
vehicle (UAV). We treat UAV-user link channel model parameters and antenna
radiation pattern of the UAV as unknowns that need to be estimated. A hybrid
channel model is proposed that consists of a traditional path loss model
combined with a neural network approximating the UAV antenna gain function.
With this model and a set of offline RSS measurements, the unknown parameters
are estimated. We then employ the particle swarm optimization (PSO) technique
which utilizes the learned hybrid channel model along with a 3D map of the
environment to accurately localize the ground users. The performance of the
developed algorithm is evaluated through simulations and also real-world
experiments.",None,-1
06f4f94c-63f5-4010-81ed-f665ec546c00,Towards Improving Faithfulness in Abstractive Summarization,0.666072,"Despite the success achieved in neural abstractive summarization based on
pre-trained language models, one unresolved issue is that the generated
summaries are not always faithful to the input document. There are two possible
causes of the unfaithfulness problem: (1) the summarization model fails to
understand or capture the gist of the input text, and (2) the model over-relies
on the language model to generate fluent but inadequate words. In this work, we
propose a Faithfulness Enhanced Summarization model (FES), which is designed
for addressing these two problems and improving faithfulness in abstractive
summarization. For the first problem, we propose to use question-answering (QA)
to examine whether the encoder fully grasps the input document and can answer
the questions on the key information in the input. The QA attention on the
proper input words can also be used to stipulate how the decoder should attend
to the source. For the second problem, we introduce a max-margin loss defined
on the difference between the language and the summarization model, aiming to
prevent the overconfidence of the language model. Extensive experiments on two
benchmark summarization datasets, CNN/DM and XSum, demonstrate that our model
significantly outperforms strong baselines. The evaluation of factual
consistency also shows that our model generates more faithful summaries than
baselines.",https://github.com/iriscxy/FES,-1
36b0d1b1-bdac-469e-849e-ac416483fd21,Egocentric Prediction of Action Target in 3D,0.54661,"We are interested in anticipating as early as possible the target location of
a person's object manipulation action in a 3D workspace from egocentric vision.
It is important in fields like human-robot collaboration, but has not yet
received enough attention from vision and learning communities. To stimulate
more research on this challenging egocentric vision task, we propose a large
multimodality dataset of more than 1 million frames of RGB-D and IMU streams,
and provide evaluation metrics based on our high-quality 2D and 3D labels from
semi-automatic annotation. Meanwhile, we design baseline methods using
recurrent neural networks and conduct various ablation studies to validate
their effectiveness. Our results demonstrate that this new task is worthy of
further study by researchers in robotics, vision, and learning communities.",None,30070
7c133b5d-3109-4ba2-b5bc-186b6db087c3,Controllable Text Generation via Probability Density Estimation in the Latent Space,0.147638,"Previous work on controllable text generation has explored the idea of
control from the latent space, such as optimizing a representation with
attribute-related classifiers or sampling a representation from relevant
discrete samples. However, they are not effective enough in modeling both the
latent space and the control, leaving controlled text with low quality and
diversity. In this work, we propose a novel control framework using probability
density estimation in the latent space. Our method utilizes an invertible
transformation function, the Normalizing Flow, that maps the complex
distributions in the latent space to simple Gaussian distributions in the prior
space. Thus, we can perform sophisticated and flexible control in the prior
space and feed the control effects back into the latent space owing to the
one-one-mapping property of invertible transformations. Experiments on
single-attribute controls and multi-attribute control reveal that our method
outperforms several strong baselines on attribute relevance and text quality
and achieves the SOTA. Further analysis of control strength adjustment
demonstrates the flexibility of our control strategy.",https://github.com/HappyGu0524/MultiControl,-1
3162a222-9808-41f4-a1b9-bf55af343470,Linear Convergence of Natural Policy Gradient Methods with Log-Linear Policies,0.812857,"We consider infinite-horizon discounted Markov decision processes and study
the convergence rates of the natural policy gradient (NPG) and the Q-NPG
methods with the log-linear policy class. Using the compatible function
approximation framework, both methods with log-linear policies can be written
as inexact versions of the policy mirror descent (PMD) method. We show that
both methods attain linear convergence rates and
$\tilde{\mathcal{O}}(1/\epsilon^2)$ sample complexities using a simple,
non-adaptive geometrically increasing step size, without resorting to entropy
or other strongly convex regularization. Lastly, as a byproduct, we obtain
sublinear convergence rates for both methods with arbitrary constant step size.",None,-1
965abf95-a8ec-4831-8c1f-a9a3497f3374,Learning to Walk by Steering: Perceptive Quadrupedal Locomotion in Dynamic Environments,0.692367,"We tackle the problem of perceptive locomotion in dynamic environments. In
this problem, a quadrupedal robot must exhibit robust and agile walking
behaviors in response to environmental clutter and moving obstacles. We present
a hierarchical learning framework, named PRELUDE, which decomposes the problem
of perceptive locomotion into high-level decision-making to predict navigation
commands and low-level gait generation to realize the target commands. In this
framework, we train the high-level navigation controller with imitation
learning on human demonstrations collected on a steerable cart and the
low-level gait controller with reinforcement learning (RL). Therefore, our
method can acquire complex navigation behaviors from human supervision and
discover versatile gaits from trial and error. We demonstrate the effectiveness
of our approach in simulation and with hardware experiments. Videos and code
can be found at the project page: https://ut-austin-rpl.github.io/PRELUDE.",https://ut-austin-rpl.github.io/PRELUDE,-1
0fc481be-443e-4ae5-8e46-4505f73674dc,Towards Realistic Underwater Dataset Generation and Color Restoration,0.149369,"Recovery of true color from underwater images is an ill-posed problem. This
is because the wide-band attenuation coefficients for the RGB color channels
depend on object range, reflectance, etc. which are difficult to model. Also,
there is backscattering due to suspended particles in water. Thus, most
existing deep-learning based color restoration methods, which are trained on
synthetic underwater datasets, do not perform well on real underwater data.
This can be attributed to the fact that synthetic data cannot accurately
represent real conditions. To address this issue, we use an image to image
translation network to bridge the gap between the synthetic and real domains by
translating images from synthetic underwater domain to real underwater domain.
Using this multimodal domain adaptation technique, we create a dataset that can
capture a diverse array of underwater conditions. We then train a simple but
effective CNN based network on our domain adapted dataset to perform color
restoration. Code and pre-trained models can be accessed at
https://github.com/nehamjain10/TRUDGCR",https://github.com/nehamjain10/TRUDGCRCCSCONCEPTS,1848
bc37fe7e-5e42-4276-a94a-33b6047e857b,Are Current Task-oriented Dialogue Systems Able to Satisfy Impolite Users?,0.383945,"Task-oriented dialogue (TOD) systems have assisted users on many tasks,
including ticket booking and service inquiries. While existing TOD systems have
shown promising performance in serving customer needs, these systems mostly
assume that users would interact with the dialogue agent politely. This
assumption is unrealistic as impatient or frustrated customers may also
interact with TOD systems impolitely. This paper aims to address this research
gap by investigating impolite users' effects on TOD systems. Specifically, we
constructed an impolite dialogue corpus and conducted extensive experiments to
evaluate the state-of-the-art TOD systems on our impolite dialogue corpus. Our
experimental results show that existing TOD systems are unable to handle
impolite user utterances. We also present a data augmentation method to improve
TOD performance in impolite dialogues. Nevertheless, handling impolite
dialogues remains a very challenging research task. We hope by releasing the
impolite dialogue corpus and establishing the benchmark evaluations, more
researchers are encouraged to investigate this new challenging research task.",None,-1
b024d150-25e0-402c-9efc-919c0ade24ba,GSCLIP : A Framework for Explaining Distribution Shifts in Natural Language,0.385402,"Helping end users comprehend the abstract distribution shifts can greatly
facilitate AI deployment. Motivated by this, we propose a novel task, dataset
explanation. Given two image data sets, dataset explanation aims to
automatically point out their dataset-level distribution shifts with natural
language. Current techniques for monitoring distribution shifts provide
inadequate information to understand datasets with the goal of improving data
quality. Therefore, we introduce GSCLIP, a training-free framework to solve the
dataset explanation task. In GSCLIP, we propose the selector as the first
quantitative evaluation method to identify explanations that are proper to
summarize dataset shifts. Furthermore, we leverage this selector to demonstrate
the superiority of a generator based on language model generation. Systematic
evaluation on natural data shift verifies that GSCLIP, a combined system of a
hybrid generator group and an efficient selector is not only easy-to-use but
also powerful for dataset explanation at scale.",https://github.com/Weixin-Liang/MetaShift,-1
2334ecf9-078a-4b1d-8424-2ab241af1075,Semiconductor Defect Detection by Hybrid Classical-Quantum Deep Learning,0.934265,"With the rapid development of artificial intelligence and autonomous driving
technology, the demand for semiconductors is projected to rise substantially.
However, the massive expansion of semiconductor manufacturing and the
development of new technology will bring many defect wafers. If these defect
wafers have not been correctly inspected, the ineffective semiconductor
processing on these defect wafers will cause additional impact to our
environment, such as excessive carbon dioxide emission and energy consumption.
In this paper, we utilize the information processing advantages of quantum
computing to promote the defect learning defect review (DLDR). We propose a
classical-quantum hybrid algorithm for deep learning on near-term quantum
processors. By tuning parameters implemented on it, quantum circuit driven by
our framework learns a given DLDR task, include of wafer defect map
classification, defect pattern classification, and hotspot detection. In
addition, we explore parametrized quantum circuits with different
expressibility and entangling capacities. These results can be used to build a
future roadmap to develop circuit-based quantum deep learning for semiconductor
defect detection.",None,10320
8dfa0ae4-cb79-4c0c-8bd9-3a4f032fa611,GCDT: A Chinese RST Treebank for Multigenre and Multilingual Discourse Parsing,0.46885,"A lack of large-scale human-annotated data has hampered the hierarchical
discourse parsing of Chinese. In this paper, we present GCDT, the largest
hierarchical discourse treebank for Mandarin Chinese in the framework of
Rhetorical Structure Theory (RST). GCDT covers over 60K tokens across five
genres of freely available text, using the same relation inventory as
contemporary RST treebanks for English. We also report on this dataset's
parsing experiments, including state-of-the-art (SOTA) scores for Chinese RST
parsing and RST parsing on the English GUM dataset, using cross-lingual
training in Chinese and English with multilingual embeddings.",https://github.com/logan-siyao-peng/GCDT,-1
ac680eea-bd94-48e0-8397-5614810ecd7d,A Continuum of Generation Tasks for Investigating Length Bias and Degenerate Repetition,0.0715362,"Language models suffer from various degenerate behaviors. These differ
between tasks: machine translation (MT) exhibits length bias, while tasks like
story generation exhibit excessive repetition. Recent work has attributed the
difference to task constrainedness, but evidence for this claim has always
involved many confounding variables. To study this question directly, we
introduce a new experimental framework that allows us to smoothly vary task
constrainedness, from MT at one end to fully open-ended generation at the
other, while keeping all other aspects fixed. We find that: (1) repetition
decreases smoothly with constrainedness, explaining the difference in
repetition across tasks; (2) length bias surprisingly also decreases with
constrainedness, suggesting some other cause for the difference in length bias;
(3) across the board, these problems affect the mode, not the whole
distribution; (4) the differences cannot be attributed to a change in the
entropy of the distribution, since another method of changing the entropy,
label smoothing, does not produce the same effect.",https://github.com/darcey/transformers_without_tears/tree/mt-interpolation-paper,-1
4ba4bf3c-fca3-41ea-a99d-6dde1ca4b2cd,"Perceive, Interact, Predict: Learning Dynamic and Static Clues for End-to-End Motion Prediction",0.828319,"Motion prediction is highly relevant to the perception of dynamic objects and
static map elements in the scenarios of autonomous driving. In this work, we
propose PIP, the first end-to-end Transformer-based framework which jointly and
interactively performs online mapping, object detection and motion prediction.
PIP leverages map queries, agent queries and mode queries to encode the
instance-wise information of map elements, agents and motion intentions,
respectively. Based on the unified query representation, a differentiable
multi-task interaction scheme is proposed to exploit the correlation between
perception and prediction. Even without human-annotated HD map or agent's
historical tracking trajectory as guidance information, PIP realizes end-to-end
multi-agent motion prediction and achieves better performance than
tracking-based and HD-map-based methods. PIP provides comprehensive high-level
information of the driving scene (vectorized static map and dynamic objects
with motion information), and contributes to the downstream planning and
control. Code and models will be released for facilitating further research.",None,-1
076a86d6-ab8b-4e2a-a1c7-ccd282b8da4e,InducT-GCN: Inductive Graph Convolutional Networks for Text Classification,0.73218,"Text classification aims to assign labels to textual units by making use of
global information. Recent studies have applied graph neural network (GNN) to
capture the global word co-occurrence in a corpus. Existing approaches require
that all the nodes (training and test) in a graph are present during training,
which are transductive and do not naturally generalise to unseen nodes. To make
those models inductive, they use extra resources, like pretrained word
embedding. However, high-quality resource is not always available and hard to
train. Under the extreme settings with no extra resource and limited amount of
training set, can we still learn an inductive graph-based text classification
model? In this paper, we introduce a novel inductive graph-based text
classification framework, InducT-GCN (InducTive Graph Convolutional Networks
for Text classification). Compared to transductive models that require test
documents in training, we construct a graph based on the statistics of training
documents only and represent document vectors with a weighted sum of word
vectors. We then conduct one-directional GCN propagation during testing. Across
five text classification benchmarks, our InducT-GCN outperformed
state-of-the-art methods that are either transductive in nature or pre-trained
additional resources. We also conducted scalability testing by gradually
increasing the data size and revealed that our InducT-GCN can reduce the time
and space complexity. The code is available on:
https://github.com/usydnlp/InductTGCN.",https://github.com/usydnlp/InductTGCN,3559
010c6706-ae0f-46c5-8632-1a55c4d81ddc,Atypical lexical abbreviations identification in Russian medical texts,0.294335,"Abbreviation is a method of word formation that aims to construct the
shortened term from the first letters of the initial phrase. Implicit
abbreviations frequently cause the comprehension difficulties for unprepared
readers. In this paper, we propose an efficient ML-based algorithm which allows
to identify the abbreviations in Russian texts. The method achieves ROC AUC
score 0.926 and F1 score 0.706 which are confirmed as competitive in comparison
with the baselines. Along with the pipeline, we also establish first to our
knowledge Russian dataset that is relevant for the desired task.",https://github.com/aberdichevskaya/abbreviation-identification,-1
2fb31164-38c1-4dda-9548-37fbfc77a855,Fast Object Placement Assessment,0.815331,"Object placement assessment (OPA) aims to predict the rationality score of a
composite image in terms of the placement (e.g., scale, location) of inserted
foreground object. However, given a pair of scaled foreground and background,
to enumerate all the reasonable locations, existing OPA model needs to place
the foreground at each location on the background and pass the obtained
composite image through the model one at a time, which is very time-consuming.
In this work, we investigate a new task named as fast OPA. Specifically,
provided with a scaled foreground and a background, we only pass them through
the model once and predict the rationality scores for all locations. To
accomplish this task, we propose a pioneering fast OPA model with several
innovations (i.e., foreground dynamic filter, background prior transfer, and
composite feature mimicking) to bridge the performance gap between slow OPA
model and fast OPA model. Extensive experiments on OPA dataset show that our
proposed fast OPA model performs on par with slow OPA model but runs
significantly faster.",None,-1
577b284c-1b3a-49f2-8ab6-6495146eb4d6,Self-supervised Contrastive Learning for Audio-Visual Action Recognition,0.181817,"The underlying correlation between audio and visual modalities can be
utilized to learn supervised information for unlabeled videos. In this paper,
we propose an end-to-end self-supervised framework named Audio-Visual
Contrastive Learning (AVCL), to learn discriminative audio-visual
representations for action recognition. Specifically, we design an attention
based multi-modal fusion module (AMFM) to fuse audio and visual modalities. To
align heterogeneous audio-visual modalities, we construct a novel
co-correlation guided representation alignment module (CGRA). To learn
supervised information from unlabeled videos, we propose a novel
self-supervised contrastive learning module (SelfCL). Furthermore, we build a
new audio-visual action recognition dataset named Kinetics-Sounds100.
Experimental results on Kinetics-Sounds32 and Kinetics-Sounds100 datasets
demonstrate the superiority of our AVCL over the state-of-the-art methods on
large-scale action recognition benchmark.",None,-1
3364c45f-47fe-4d94-8619-70e14d3116cc,Data Augmentation using Transformers and Similarity Measures for Improving Arabic Text Classification,0.124493,"The performance of learning models heavily relies on the availability and
adequacy of training data. To address the dataset adequacy issue, researchers
have extensively explored data augmentation (DA) as a promising approach. DA
generates new data instances through transformations applied to the available
data, thereby increasing dataset size and variability. This approach has
enhanced model performance and accuracy, particularly in addressing class
imbalance problems in classification tasks. However, few studies have explored
DA for the Arabic language, relying on traditional approaches such as
paraphrasing or noising-based techniques. In this paper, we propose a new
Arabic DA method that employs the recent powerful modeling technique, namely
the AraGPT-2, for the augmentation process. The generated sentences are
evaluated in terms of context, semantics, diversity, and novelty using the
Euclidean, cosine, Jaccard, and BLEU distances. Finally, the AraBERT
transformer is used on sentiment classification tasks to evaluate the
classification performance of the augmented Arabic dataset. The experiments
were conducted on four sentiment Arabic datasets: AraSarcasm, ASTD, ATT, and
MOVIE. The selected datasets vary in size, label number, and unbalanced
classes. The results show that the proposed methodology enhanced the Arabic
sentiment text classification on all datasets with an increase in F1 score by
4% in AraSarcasm, 6% in ASTD, 9% in ATT, and 13% in MOVIE.",https://github.com/Dania-Refai/Arabic-Data-Augmentation,-1
98fc9595-fc06-4841-9a25-bff6daf2cfca,An approach to robust ICP initialization,0.161833,"In this note, we propose an approach to initialize the Iterative Closest
Point (ICP) algorithm to match unlabelled point clouds related by rigid
transformations. The method is based on matching the ellipsoids defined by the
points' covariance matrices and then testing the various principal half-axes
matchings that differ by elements of a finite reflection group. We derive
bounds on the robustness of our approach to noise and numerical experiments
confirm our theoretical findings.",None,-1
45e8930b-e5da-48db-b840-414f5ba14fb8,"Graph Neural Networks Meet Wireless Communications: Motivation, Applications, and Future Directions",0.855809,"As an efficient graph analytical tool, graph neural networks (GNNs) have
special properties that are particularly fit for the characteristics and
requirements of wireless communications, exhibiting good potential for the
advancement of next-generation wireless communications. This article aims to
provide a comprehensive overview of the interplay between GNNs and wireless
communications, including GNNs for wireless communications (GNN4Com) and
wireless communications for GNNs (Com4GNN). In particular, we discuss GNN4Com
based on how graphical models are constructed and introduce Com4GNN with
corresponding incentives. We also highlight potential research directions to
promote future research endeavors for GNNs in wireless communications.",None,-1
058ecc12-f391-4e31-b9c5-be5d66b12dbf,First do not fall: learning to exploit a wall with a damaged humanoid robot,0.20677,"Humanoid robots could replace humans in hazardous situations but most of such
situations are equally dangerous for them, which means that they have a high
chance of being damaged and falling. We hypothesize that humanoid robots would
be mostly used in buildings, which makes them likely to be close to a wall. To
avoid a fall, they can therefore lean on the closest wall, as a human would do,
provided that they find in a few milliseconds where to put the hand(s). This
article introduces a method, called D-Reflex, that learns a neural network that
chooses this contact position given the wall orientation, the wall distance,
and the posture of the robot. This contact position is then used by a
whole-body controller to reach a stable posture. We show that D-Reflex allows a
simulated TALOS robot (1.75m, 100kg, 30 degrees of freedom) to avoid more than
75% of the avoidable falls and can work on the real robot.",https://github.com/resibots/robot-dart,9262
0fa93757-e7e2-44b0-bc6c-470b5585cc7e,Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing,0.694067,"Despite their strong performance on many tasks, pre-trained language models
have been shown to struggle on out-of-distribution compositional
generalization. Meanwhile, recent work has shown considerable improvements on
many NLP tasks from model scaling. Can scaling up model size also improve
compositional generalization in semantic parsing? We evaluate encoder-decoder
models up to 11B parameters and decoder-only models up to 540B parameters, and
compare model scaling curves for three different methods for applying a
pre-trained language model to a new task: fine-tuning all parameters, prompt
tuning, and in-context learning. We observe that fine-tuning generally has flat
or negative scaling curves on out-of-distribution compositional generalization
in semantic parsing evaluations. In-context learning has positive scaling
curves, but is generally outperformed by much smaller fine-tuned models.
Prompt-tuning can outperform fine-tuning, suggesting further potential
improvements from scaling as it exhibits a more positive scaling curve.
Additionally, we identify several error trends that vary with model scale. For
example, larger models are generally better at modeling the syntax of the
output space, but are also more prone to certain types of overfitting. Overall,
our study highlights limitations of current techniques for effectively
leveraging model scale for compositional generalization, while our analysis
also suggests promising directions for future work.",https://github.com/microsoft/compositional-generalization-span-level-attention,20836
8c37bab3-cfc9-45e2-bcc3-9853bf9581a6,Photorealistic Monocular 3D Reconstruction of Humans Wearing Clothing,0.987249,"We present PHORHUM, a novel, end-to-end trainable, deep neural network
methodology for photorealistic 3D human reconstruction given just a monocular
RGB image. Our pixel-aligned method estimates detailed 3D geometry and, for the
first time, the unshaded surface color together with the scene illumination.
Observing that 3D supervision alone is not sufficient for high fidelity color
reconstruction, we introduce patch-based rendering losses that enable reliable
color reconstruction on visible parts of the human, and detailed and plausible
color estimation for the non-visible parts. Moreover, our method specifically
addresses methodological and practical limitations of prior work in terms of
representing geometry, albedo, and illumination effects, in an end-to-end model
where factors can be effectively disentangled. In extensive experiments, we
demonstrate the versatility and robustness of our approach. Our
state-of-the-art results validate the method qualitatively and for different
metrics, for both geometric and color reconstruction.",None,-1
08fc8c9f-76a4-42ca-8a3b-cb319234b5bc,Keke AI Competition: Solving puzzle levels in a dynamically changing mechanic space,0.24957,"The Keke AI Competition introduces an artificial agent competition for the
game Baba is You - a Sokoban-like puzzle game where players can create rules
that influence the mechanics of the game. Altering a rule can cause temporary
or permanent effects for the rest of the level that could be part of the
solution space. The nature of these dynamic rules and the deterministic aspect
of the game creates a challenge for AI to adapt to a variety of mechanic
combinations in order to solve a level. This paper describes the framework and
evaluation metrics used to rank submitted agents and baseline results from
sample tree search agents.",https://github.com/MasterMilkX/KekeCompetition/wiki/Baba-Simulation-Code,-1
f028bf45-3bad-476e-8f17-396c0c59ea6d,Augmentation Matters: A Simple-yet-Effective Approach to Semi-supervised Semantic Segmentation,0.889463,"Recent studies on semi-supervised semantic segmentation (SSS) have seen fast
progress. Despite their promising performance, current state-of-the-art methods
tend to increasingly complex designs at the cost of introducing more network
components and additional training procedures. Differently, in this work, we
follow a standard teacher-student framework and propose AugSeg, a simple and
clean approach that focuses mainly on data perturbations to boost the SSS
performance. We argue that various data augmentations should be adjusted to
better adapt to the semi-supervised scenarios instead of directly applying
these techniques from supervised learning. Specifically, we adopt a simplified
intensity-based augmentation that selects a random number of data
transformations with uniformly sampling distortion strengths from a continuous
space. Based on the estimated confidence of the model on different unlabeled
samples, we also randomly inject labelled information to augment the unlabeled
samples in an adaptive manner. Without bells and whistles, our simple AugSeg
can readily achieve new state-of-the-art performance on SSS benchmarks under
different partition protocols.",https://github.com/zhenzhao/AugSeg,-1
d52993a1-9859-49ee-b8b7-50a05e91b305,Deep Symbolic Learning: Discovering Symbols and Rules from Perceptions,0.483654,"Neuro-Symbolic (NeSy) integration combines symbolic reasoning with Neural
Networks (NNs) for tasks requiring perception and reasoning. Most NeSy systems
rely on continuous relaxation of logical knowledge, and no discrete decisions
are made within the model pipeline. Furthermore, these methods assume that the
symbolic rules are given. In this paper, we propose Deep Symbolic Learning
(DSL), a NeSy system that learns NeSy-functions, i.e., the composition of a
(set of) perception functions which map continuous data to discrete symbols,
and a symbolic function over the set of symbols. DSL learns simultaneously the
perception and symbolic functions while being trained only on their composition
(NeSy-function). The key novelty of DSL is that it can create internal
(interpretable) symbolic representations and map them to perception inputs
within a differentiable NN learning pipeline. The created symbols are
automatically selected to generate symbolic functions that best explain the
data. We provide experimental analysis to substantiate the efficacy of DSL in
simultaneously learning perception and symbolic functions.",None,-1
e9ef850c-8536-4160-8eb7-aef97a1f8503,Spatiality-guided Transformer for 3D Dense Captioning on Point Clouds,0.882995,"Dense captioning in 3D point clouds is an emerging vision-and-language task
involving object-level 3D scene understanding. Apart from coarse semantic class
prediction and bounding box regression as in traditional 3D object detection,
3D dense captioning aims at producing a further and finer instance-level label
of natural language description on visual appearance and spatial relations for
each scene object of interest. To detect and describe objects in a scene,
following the spirit of neural machine translation, we propose a
transformer-based encoder-decoder architecture, namely SpaCap3D, to transform
objects into descriptions, where we especially investigate the relative
spatiality of objects in 3D scenes and design a spatiality-guided encoder via a
token-to-token spatial relation learning objective and an object-centric
decoder for precise and spatiality-enhanced object caption generation.
Evaluated on two benchmark datasets, ScanRefer and ReferIt3D, our proposed
SpaCap3D outperforms the baseline method Scan2Cap by 4.94% and 9.61% in
CIDEr@0.5IoU, respectively. Our project page with source code and supplementary
files is available at https://SpaCap3D.github.io/ .",https://github.com/heng-hw/SpaCap3D,-1
ff827454-c92e-461d-9334-bcb419141cc2,Defending Person Detection Against Adversarial Patch Attack by using Universal Defensive Frame,0.23342,"Person detection has attracted great attention in the computer vision area
and is an imperative element in human-centric computer vision. Although the
predictive performances of person detection networks have been improved
dramatically, they are vulnerable to adversarial patch attacks. Changing the
pixels in a restricted region can easily fool the person detection network in
safety-critical applications such as autonomous driving and security systems.
Despite the necessity of countering adversarial patch attacks, very few efforts
have been dedicated to defending person detection against adversarial patch
attack. In this paper, we propose a novel defense strategy that defends against
an adversarial patch attack by optimizing a defensive frame for person
detection. The defensive frame alleviates the effect of the adversarial patch
while maintaining person detection performance with clean person. The proposed
defensive frame in the person detection is generated with a competitive
learning algorithm which makes an iterative competition between detection
threatening module and detection shielding module in person detection.
Comprehensive experimental results demonstrate that the proposed method
effectively defends person detection against adversarial patch attacks.",https://github.com/UMBCvision/Contextual-Adversarial-Patches,-1
022b079e-9f46-4c32-8b48-e72ea1ee06b0,Deep Vehicle Detection in Satellite Video,0.169957,"This work presents a deep learning approach for vehicle detection in
satellite video. Vehicle detection is perhaps impossible in single EO satellite
images due to the tininess of vehicles (4-10 pixel) and their similarity to the
background. Instead, we consider satellite video which overcomes the lack of
spatial information by temporal consistency of vehicle movement. A new
spatiotemporal model of a compact $3 \times 3$ convolutional, neural network is
proposed which neglects pooling layers and uses leaky ReLUs. Then we use a
reformulation of the output heatmap including Non-Maximum-Suppression (NMS) for
the final segmentation. Empirical results on two new annotated satellite videos
reconfirm the applicability of this approach for vehicle detection. They more
importantly indicate that pre-training on WAMI data and then fine-tuning on few
annotated video frames for a new video is sufficient. In our experiment only
five annotated images yield a $F_1$ score of 0.81 on a new video showing more
complex traffic patterns than the Las Vegas video. Our best result on Las Vegas
is a $F_1$ score of 0.87 which makes the proposed approach a leading method for
this benchmark.",None,6296
7ddbfea1-1a91-4850-9cc8-a27e8f12664f,Blockwise Streaming Transformer for Spoken Language Understanding and Simultaneous Speech Translation,0.104429,"Although Transformers have gained success in several speech processing tasks
like spoken language understanding (SLU) and speech translation (ST), achieving
online processing while keeping competitive performance is still essential for
real-world interaction. In this paper, we take the first step on streaming SLU
and simultaneous ST using a blockwise streaming Transformer, which is based on
contextual block processing and blockwise synchronous beam search. Furthermore,
we design an automatic speech recognition (ASR)-based intermediate loss
regularization for the streaming SLU task to improve the classification
performance further. As for the simultaneous ST task, we propose a
cross-lingual encoding method, which employs a CTC branch optimized with target
language translations. In addition, the CTC translation output is also used to
refine the search space with CTC prefix score, achieving joint CTC/attention
simultaneous translation for the first time. Experiments for SLU are conducted
on FSC and SLURP corpora, while the ST task is evaluated on Fisher-CallHome
Spanish and MuST-C En-De corpora. Experimental results show that the blockwise
streaming Transformer achieves competitive results compared to offline models,
especially with our proposed methods that further yield a 2.4% accuracy gain on
the SLU task and a 4.3 BLEU gain on the ST task over streaming baselines.",https://github.com/espnet/espnet/blob/master/espnet2/bin/asr_inference_streaming.py,-1
686726d5-b3ad-412c-be78-cf79de54ba5f,StepGame: A New Benchmark for Robust Multi-Hop Spatial Reasoning in Texts,0.65591,"Inferring spatial relations in natural language is a crucial ability an
intelligent system should possess. The bAbI dataset tries to capture tasks
relevant to this domain (task 17 and 19). However, these tasks have several
limitations. Most importantly, they are limited to fixed expressions, they are
limited in the number of reasoning steps required to solve them, and they fail
to test the robustness of models to input that contains irrelevant or redundant
information. In this paper, we present a new Question-Answering dataset called
StepGame for robust multi-hop spatial reasoning in texts. Our experiments
demonstrate that state-of-the-art models on the bAbI dataset struggle on the
StepGame dataset. Moreover, we propose a Tensor-Product based Memory-Augmented
Neural Network (TP-MANN) specialized for spatial reasoning tasks. Experimental
results on both datasets show that our model outperforms all the baselines with
superior generalization and robustness performance.",None,-1
64a662f3-7e5d-430c-a486-512e24d0d5c7,KD-MVS: Knowledge Distillation Based Self-supervised Learning for Multi-view Stereo,0.46226,"Supervised multi-view stereo (MVS) methods have achieved remarkable progress
in terms of reconstruction quality, but suffer from the challenge of collecting
large-scale ground-truth depth. In this paper, we propose a novel
self-supervised training pipeline for MVS based on knowledge distillation,
termed KD-MVS, which mainly consists of self-supervised teacher training and
distillation-based student training. Specifically, the teacher model is trained
in a self-supervised fashion using both photometric and featuremetric
consistency. Then we distill the knowledge of the teacher model to the student
model through probabilistic knowledge transferring. With the supervision of
validated knowledge, the student model is able to outperform its teacher by a
large margin. Extensive experiments performed on multiple datasets show our
method can even outperform supervised methods.",https://github.com/megvii-research/KD-MVS,-1
6fa824cd-5df0-4494-9b21-21d6e64682cf,Augmenting Knowledge Graphs for Better Link Prediction,0.374277,"Embedding methods have demonstrated robust performance on the task of link
prediction in knowledge graphs, by mostly encoding entity relationships. Recent
methods propose to enhance the loss function with a literal-aware term. In this
paper, we propose KGA: a knowledge graph augmentation method that incorporates
literals in an embedding model without modifying its loss function. KGA
discretizes quantity and year values into bins, and chains these bins both
horizontally, modeling neighboring values, and vertically, modeling multiple
levels of granularity. KGA is scalable and can be used as a pre-processing step
for any existing knowledge graph embedding model. Experiments on legacy
benchmarks and a new large benchmark, DWD, show that augmenting the knowledge
graph with quantities and years is beneficial for predicting both entities and
numbers, as KGA outperforms the vanilla models and other relevant baselines.
Our ablation studies confirm that both quantities and years contribute to KGA's
performance, and that its performance depends on the discretization and binning
settings. We make the code, models, and the DWD benchmark publicly available to
facilitate reproducibility and future research.",https://github.com/Otamio/KGA/,-1
4cd405d9-6467-49a5-b084-17fcec6966a1,Spacecraft Pose Estimation Based on Unsupervised Domain Adaptation and on a 3D-Guided Loss Combination,0.398691,"Spacecraft pose estimation is a key task to enable space missions in which
two spacecrafts must navigate around each other. Current state-of-the-art
algorithms for pose estimation employ data-driven techniques. However, there is
an absence of real training data for spacecraft imaged in space conditions due
to the costs and difficulties associated with the space environment. This has
motivated the introduction of 3D data simulators, solving the issue of data
availability but introducing a large gap between the training (source) and test
(target) domains. We explore a method that incorporates 3D structure into the
spacecraft pose estimation pipeline to provide robustness to intensity domain
shift and we present an algorithm for unsupervised domain adaptation with
robust pseudo-labelling. Our solution has ranked second in the two categories
of the 2021 Pose Estimation Challenge organised by the European Space Agency
and the Stanford University, achieving the lowest average error over the two
categories.",https://github.com/JotaBravo/spacecraft-uda,-1
b4855bcd-8c25-49e7-a740-d4f63d740254,Learning Probabilities of Causation from Finite Population Data,0.803088,"This paper deals with the problem of learning the probabilities of causation
of subpopulations given finite population data. The tight bounds of three basic
probabilities of causation, the probability of necessity and sufficiency (PNS),
the probability of sufficiency (PS), and the probability of necessity (PN),
were derived by Tian and Pearl. However, obtaining the bounds for each
subpopulation requires experimental and observational distributions of each
subpopulation, which is usually impractical to estimate given finite population
data. We propose a machine learning model that helps to learn the bounds of the
probabilities of causation for subpopulations given finite population data. We
further show by a simulated study that the machine learning model is able to
learn the bounds of PNS for 32768 subpopulations with only knowing roughly 500
of them from the finite population data.",None,-1
2ea9549b-2633-4d71-8421-6c064200ebbb,A Model for Multi-View Residual Covariances based on Perspective Deformation,0.388786,"In this work, we derive a model for the covariance of the visual residuals in
multi-view SfM, odometry and SLAM setups. The core of our approach is the
formulation of the residual covariances as a combination of geometric and
photometric noise sources. And our key novel contribution is the derivation of
a term modelling how local 2D patches suffer from perspective deformation when
imaging 3D surfaces around a point. Together, these add up to an efficient and
general formulation which not only improves the accuracy of both feature-based
and direct methods, but can also be used to estimate more accurate measures of
the state entropy and hence better founded point visibility thresholds. We
validate our model with synthetic and real data and integrate it into
photometric and feature-based Bundle Adjustment, improving their accuracy with
a negligible overhead.",None,-1
a976f2b4-c767-4d72-9381-0df205df655b,Visualizing Automatic Speech Recognition -- Means for a Better Understanding?,0.225079,"Automatic speech recognition (ASR) is improving ever more at mimicking human
speech processing. The functioning of ASR, however, remains to a large extent
obfuscated by the complex structure of the deep neural networks (DNNs) they are
based on. In this paper, we show how so-called attribution methods, that we
import from image recognition and suitably adapt to handle audio data, can help
to clarify the working of ASR. Taking DeepSpeech, an end-to-end model for ASR,
as a case study, we show how these techniques help to visualize which features
of the input are the most influential in determining the output. We focus on
three visualization techniques: Layer-wise Relevance Propagation (LRP),
Saliency Maps, and Shapley Additive Explanations (SHAP). We compare these
methods and discuss potential further applications, such as in the detection of
adversarial examples.",https://github.com/marcoancona/DeepExplain,-1
e8dd39df-d645-41c2-94df-e9f9a7c6aac6,Reinforcement Learning Textbook,0.0966252,"This textbook covers principles behind main modern deep reinforcement
learning algorithms that achieved breakthrough results in many domains from
game AI to robotics. All required theory is explained with proofs using unified
notation and emphasize on the differences between different types of algorithms
and the reasons why they are constructed the way they are.",None,-1
f24147dd-8817-45a1-a1b8-38d0f81500bb,"Mapping the Multilingual Margins: Intersectional Biases of Sentiment Analysis Systems in English, Spanish, and Arabic",0.672362,"As natural language processing systems become more widespread, it is
necessary to address fairness issues in their implementation and deployment to
ensure that their negative impacts on society are understood and minimized.
However, there is limited work that studies fairness using a multilingual and
intersectional framework or on downstream tasks. In this paper, we introduce
four multilingual Equity Evaluation Corpora, supplementary test sets designed
to measure social biases, and a novel statistical framework for studying
unisectional and intersectional social biases in natural language processing.
We use these tools to measure gender, racial, ethnic, and intersectional social
biases across five models trained on emotion regression tasks in English,
Spanish, and Arabic. We find that many systems demonstrate statistically
significant unisectional and intersectional social biases.",https://github.com/ascamara/,-1
8d4cd5cf-28f2-484f-84fa-a8c306458024,MMES: Mixture Model based Evolution Strategy for Large-Scale Optimization,0.371766,"This work provides an efficient sampling method for the covariance matrix
adaptation evolution strategy (CMA-ES) in large-scale settings. In contract to
the Gaussian sampling in CMA-ES, the proposed method generates mutation vectors
from a mixture model, which facilitates exploiting the rich variable
correlations of the problem landscape within a limited time budget. We analyze
the probability distribution of this mixture model and show that it
approximates the Gaussian distribution of CMA-ES with a controllable accuracy.
We use this sampling method, coupled with a novel method for mutation strength
adaptation, to formulate the mixture model based evolution strategy (MMES) -- a
CMA-ES variant for large-scale optimization. The numerical simulations show
that, while significantly reducing the time complexity of CMA-ES, MMES
preserves the rotational invariance, is scalable to high dimensional problems,
and is competitive against the state-of-the-arts in performing global
optimization.",https://github.com/hxyokokok/MMES,-1
d8da0d36-7db5-4f54-bd30-bb312e5861e5,FOAM: A Follower-aware Speaker Model For Vision-and-Language Navigation,0.361167,"The speaker-follower models have proven to be effective in
vision-and-language navigation, where a speaker model is used to synthesize new
instructions to augment the training data for a follower navigation model.
However, in many of the previous methods, the generated instructions are not
directly trained to optimize the performance of the follower. In this paper, we
present \textsc{foam}, a \textsc{Fo}llower-\textsc{a}ware speaker
\textsc{M}odel that is constantly updated given the follower feedback, so that
the generated instructions can be more suitable to the current learning state
of the follower. Specifically, we optimize the speaker using a bi-level
optimization framework and obtain its training signals by evaluating the
follower on labeled data. Experimental results on the Room-to-Room and
Room-across-Room datasets demonstrate that our methods can outperform strong
baseline models across settings. Analyses also reveal that our generated
instructions are of higher quality than the baselines.",https://github.com/PlusLabNLP/follower_aware_speaker,-1
211f32f2-b28b-4383-a510-4e6d7a474fce,CAD 3D Model classification by Graph Neural Networks: A new approach based on STEP format,0.282398,"In this paper, we introduce a new approach for retrieval and classification
of 3D models that directly performs in the Computer-Aided Design (CAD) format
without any conversion to other representations like point clouds or meshes,
thus avoiding any loss of information. Among the various CAD formats, we
consider the widely used STEP extension, which represents a standard for
product manufacturing information. This particular format represents a 3D model
as a set of primitive elements such as surfaces and vertices linked together.
In our approach, we exploit the linked structure of STEP files to create a
graph in which the nodes are the primitive elements and the arcs are the
connections between them. We then use Graph Neural Networks (GNNs) to solve the
problem of model classification. Finally, we created two datasets of 3D models
in native CAD format, respectively, by collecting data from the Traceparts
model library and from the Configurators software modeling company. We used
these datasets to test and compare our approach with respect to
state-of-the-art methods that consider other 3D formats. Our code is available
at https://github.com/divanoLetto/3D_STEP_Classification",https://github.com/divanoLetto/3D_STEP_Classification,-1
865156fd-8140-4c33-97b7-92143cfd1e78,Knowledge Unlearning for Mitigating Privacy Risks in Language Models,0.942763,"Pretrained Language Models (LMs) memorize a vast amount of knowledge during
initial pretraining, including information that may violate the privacy of
personal lives and identities. Previous work addressing privacy issues for
language models has mostly focused on data preprocessing and differential
privacy methods, both requiring re-training the underlying LM. We propose
knowledge unlearning as an alternative method to reduce privacy risks for LMs
post hoc. We show that simply performing gradient ascent on target token
sequences is effective at forgetting them with little to no degradation of
general language modeling performances for larger LMs; it sometimes even
substantially improves the underlying LM with just a few iterations. We also
find that sequential unlearning is better than trying to unlearn all the data
at once and that unlearning is highly dependent on which kind of data (domain)
is forgotten. By showing comparisons with a previous data preprocessing method
and a decoding method known to mitigate privacy risks for LMs, we show that
unlearning can give a stronger empirical privacy guarantee in scenarios where
the data vulnerable to extraction attacks are known a priori while being much
more efficient and robust. We release the code and dataset needed to replicate
our results at https://github.com/joeljang/knowledge-unlearning.",None,-1
bef53db0-6075-4a0d-a72e-3d57bc82afbe,Phone2Proc: Bringing Robust Robots Into Our Chaotic World,0.514767,"Training embodied agents in simulation has become mainstream for the embodied
AI community. However, these agents often struggle when deployed in the
physical world due to their inability to generalize to real-world environments.
In this paper, we present Phone2Proc, a method that uses a 10-minute phone scan
and conditional procedural generation to create a distribution of training
scenes that are semantically similar to the target environment. The generated
scenes are conditioned on the wall layout and arrangement of large objects from
the scan, while also sampling lighting, clutter, surface textures, and
instances of smaller objects with randomized placement and materials.
Leveraging just a simple RGB camera, training with Phone2Proc shows massive
improvements from 34.7% to 70.7% success rate in sim-to-real ObjectNav
performance across a test suite of over 200 trials in diverse real-world
environments, including homes, offices, and RoboTHOR. Furthermore, Phone2Proc's
diverse distribution of generated scenes makes agents remarkably robust to
changes in the real world, such as human movement, object rearrangement,
lighting changes, or clutter.",https://allenai.org/project/phone2proc,-1
f6ecad8c-dcda-436c-a673-1ec4e19acfda,CC-3DT: Panoramic 3D Object Tracking via Cross-Camera Fusion,0.936887,"To track the 3D locations and trajectories of the other traffic participants
at any given time, modern autonomous vehicles are equipped with multiple
cameras that cover the vehicle's full surroundings. Yet, camera-based 3D object
tracking methods prioritize optimizing the single-camera setup and resort to
post-hoc fusion in a multi-camera setup. In this paper, we propose a method for
panoramic 3D object tracking, called CC-3DT, that associates and models object
trajectories both temporally and across views, and improves the overall
tracking consistency. In particular, our method fuses 3D detections from
multiple cameras before association, reducing identity switches significantly
and improving motion modeling. Our experiments on large-scale driving datasets
show that fusion before association leads to a large margin of improvement over
post-hoc fusion. We set a new state-of-the-art with 12.6% improvement in
average multi-object tracking accuracy (AMOTA) among all camera-based methods
on the competitive NuScenes 3D tracking benchmark, outperforming previously
published methods by 6.5% in AMOTA with the same 3D detector.",None,-1
6a79bdda-c4bf-4dd2-8673-30f82d6ef18e,From Easy to Hard: Two-stage Selector and Reader for Multi-hop Question Answering,0.756422,"Multi-hop question answering (QA) is a challenging task requiring QA systems
to perform complex reasoning over multiple documents and provide supporting
facts together with the exact answer. Existing works tend to utilize
graph-based reasoning and question decomposition to obtain the reasoning chain,
which inevitably introduces additional complexity and cumulative error to the
system. To address the above issue, we propose a simple yet effective novel
framework, From Easy to Hard (FE2H), to remove distracting information and
obtain better contextual representations for the multi-hop QA task. Inspired by
the iterative document selection process and the progressive learning custom of
humans, FE2H divides both the document selector and reader into two stages
following an easy-to-hard manner. Specifically, we first select the document
most relevant to the question and then utilize the question together with this
document to select other pertinent documents. As for the QA phase, our reader
is first trained on a single-hop QA dataset and then transferred into the
multi-hop QA task. We comprehensively evaluate our model on the popular
multi-hop QA benchmark HotpotQA. Experimental results demonstrate that our
method ourperforms all other methods in the leaderboard of HotpotQA (distractor
setting).",None,-1
b5752d33-2d6c-41a4-bd0c-4089df54fe8b,Differentially Private Decoding in Large Language Models,0.898162,"Recent large-scale natural language processing (NLP) systems use a
pre-trained Large Language Model (LLM) on massive and diverse corpora as a
headstart. In practice, the pre-trained model is adapted to a wide array of
tasks via fine-tuning on task-specific datasets. LLMs, while effective, have
been shown to memorize instances of training data thereby potentially revealing
private information processed during pre-training. The potential leakage might
further propagate to the downstream tasks for which LLMs are fine-tuned. On the
other hand, privacy-preserving algorithms usually involve retraining from
scratch, which is prohibitively expensive for LLMs. In this work, we propose a
simple, easy to interpret, and computationally lightweight perturbation
mechanism to be applied to an already trained model at the decoding stage. Our
perturbation mechanism is model-agnostic and can be used in conjunction with
any LLM. We provide theoretical analysis showing that the proposed mechanism is
differentially private, and experimental results showing a privacy-utility
trade-off.",https://github.com/kingoflolz/mesh-transformer-jax,-1
1dfb3994-d946-431f-beea-e6f6d1099ab7,Cycle-Consistent Counterfactuals by Latent Transformations,0.593448,"CounterFactual (CF) visual explanations try to find images similar to the
query image that change the decision of a vision system to a specified outcome.
Existing methods either require inference-time optimization or joint training
with a generative adversarial model which makes them time-consuming and
difficult to use in practice. We propose a novel approach, Cycle-Consistent
Counterfactuals by Latent Transformations (C3LT), which learns a latent
transformation that automatically generates visual CFs by steering in the
latent space of generative models. Our method uses cycle consistency between
the query and CF latent representations which helps our training to find better
solutions. C3LT can be easily plugged into any state-of-the-art pretrained
generative network. This enables our method to generate high-quality and
interpretable CF images at high resolution such as those in ImageNet. In
addition to several established metrics for evaluating CF explanations, we
introduce a novel metric tailored to assess the quality of the generated CF
examples and validate the effectiveness of our method on an extensive set of
experiments.",https://github.com/IBM/Contrastive-Explanation-Method,8748
dead0be4-15ed-467c-882c-ac56427043f4,Multi-Attribute Open Set Recognition,0.598247,"Open Set Recognition (OSR) extends image classification to an open-world
setting, by simultaneously classifying known classes and identifying unknown
ones. While conventional OSR approaches can detect Out-of-Distribution (OOD)
samples, they cannot provide explanations indicating which underlying visual
attribute(s) (e.g., shape, color or background) cause a specific sample to be
unknown. In this work, we introduce a novel problem setup that generalizes
conventional OSR to a multi-attribute setting, where multiple visual attributes
are simultaneously recognized. Here, OOD samples can be not only identified but
also categorized by their unknown attribute(s). We propose simple extensions of
common OSR baselines to handle this novel scenario. We show that these
baselines are vulnerable to shortcuts when spurious correlations exist in the
training dataset. This leads to poor OOD performance which, according to our
experiments, is mainly due to unintended cross-attribute correlations of the
predicted confidence scores. We provide an empirical evidence showing that this
behavior is consistent across different baselines on both synthetic and real
world datasets.",None,-1
b677dce4-eace-4538-a325-ec2c972d4c02,Direct parsing to sentiment graphs,0.389379,"This paper demonstrates how a graph-based semantic parser can be applied to
the task of structured sentiment analysis, directly predicting sentiment graphs
from text. We advance the state of the art on 4 out of 5 standard benchmark
sets. We release the source code, models and predictions.",https://github.com/jerbarnes/direct_parsing_to_sent_graph,-1
83b577ff-3b3c-4338-8e4e-00ea581eedb0,Skeleton-based Action Recognition via Temporal-Channel Aggregation,0.883219,"Skeleton-based action recognition methods are limited by the semantic
extraction of spatio-temporal skeletal maps. However, current methods have
difficulty in effectively combining features from both temporal and spatial
graph dimensions and tend to be thick on one side and thin on the other. In
this paper, we propose a Temporal-Channel Aggregation Graph Convolutional
Networks (TCA-GCN) to learn spatial and temporal topologies dynamically and
efficiently aggregate topological features in different temporal and channel
dimensions for skeleton-based action recognition. We use the Temporal
Aggregation module to learn temporal dimensional features and the Channel
Aggregation module to efficiently combine spatial dynamic channel-wise
topological features with temporal dynamic topological features. In addition,
we extract multi-scale skeletal features on temporal modeling and fuse them
with an attention mechanism. Extensive experiments show that our model results
outperform state-of-the-art methods on the NTU RGB+D, NTU RGB+D 120, and
NW-UCLA datasets.",None,-1
bad79eee-e631-44ca-85ab-152864f75af0,On Text-based Personality Computing: Challenges and Future Directions,0.273428,"Text-based personality computing (TPC) has gained many research interests in
NLP. In this paper, we describe 15 challenges that we consider deserving the
attention of the research community. These challenges are organized by the
following topics: personality taxonomies, measurement quality, datasets,
performance evaluation, modelling choices, as well as ethics and fairness. When
addressing each challenge, not only do we combine perspectives from both NLP
and social sciences, but also offer concrete suggestions. We hope to inspire
more valid and reliable TPC research.",None,-1
62cc84e4-45ed-4c90-8a74-c4c51c3ac87e,Towards explainable evaluation of language models on the semantic similarity of visual concepts,0.193838,"Recent breakthroughs in NLP research, such as the advent of Transformer
models have indisputably contributed to major advancements in several tasks.
However, few works research robustness and explainability issues of their
evaluation strategies. In this work, we examine the behavior of high-performing
pre-trained language models, focusing on the task of semantic similarity for
visual vocabularies. First, we address the need for explainable evaluation
metrics, necessary for understanding the conceptual quality of retrieved
instances. Our proposed metrics provide valuable insights in local and global
level, showcasing the inabilities of widely used approaches. Secondly,
adversarial interventions on salient query semantics expose vulnerabilities of
opaque metrics and highlight patterns in learned linguistic representations.",None,-1
7e22d255-2493-49a5-968a-7d6a66169c47,Cybertrust: From Explainable to Actionable and Interpretable AI (AI2),0.0749092,"To benefit from AI advances, users and operators of AI systems must have
reason to trust it. Trust arises from multiple interactions, where predictable
and desirable behavior is reinforced over time. Providing the system's users
with some understanding of AI operations can support predictability, but
forcing AI to explain itself risks constraining AI capabilities to only those
reconcilable with human cognition. We argue that AI systems should be designed
with features that build trust by bringing decision-analytic perspectives and
formal tools into AI. Instead of trying to achieve explainable AI, we should
develop interpretable and actionable AI. Actionable and Interpretable AI (AI2)
will incorporate explicit quantifications and visualizations of user confidence
in AI recommendations. In doing so, it will allow examining and testing of AI
system predictions to establish a basis for trust in the systems' decision
making and ensure broad benefits from deploying and advancing its computational
capabilities.",None,-1
493833a1-a3d5-41eb-a606-89d66dad53cf,Leveraging Artificial Intelligence on Binary Code Comprehension,0.168652,"Understanding binary code is an essential but complex software engineering
task for reverse engineering, malware analysis, and compiler optimization.
Unlike source code, binary code has limited semantic information, which makes
it challenging for human comprehension. At the same time, compiling source to
binary code, or transpiling among different programming languages (PLs) can
provide a way to introduce external knowledge into binary comprehension. We
propose to develop Artificial Intelligence (AI) models that aid human
comprehension of binary code. Specifically, we propose to incorporate domain
knowledge from large corpora of source code (e.g., variable names, comments) to
build AI models that capture a generalizable representation of binary code.
Lastly, we will investigate metrics to assess the performance of models that
apply to binary code by using human studies of comprehension.",None,-1
288a7d8c-3122-4656-ba56-8f138524e830,Peano: Learning Formal Mathematical Reasoning,0.66256,"General mathematical reasoning is computationally undecidable, but humans
routinely solve new problems. Moreover, discoveries developed over centuries
are taught to subsequent generations quickly. What structure enables this, and
how might that inform automated mathematical reasoning? We posit that central
to both puzzles is the structure of procedural abstractions underlying
mathematics. We explore this idea in a case study on 5 sections of beginning
algebra on the Khan Academy platform. To define a computational foundation, we
introduce Peano, a theorem-proving environment where the set of valid actions
at any point is finite. We use Peano to formalize introductory algebra problems
and axioms, obtaining well-defined search problems. We observe existing
reinforcement learning methods for symbolic reasoning to be insufficient to
solve harder problems. Adding the ability to induce reusable abstractions
(""tactics"") from its own solutions allows an agent to make steady progress,
solving all problems. Furthermore, these abstractions induce an order to the
problems, seen at random during training. The recovered order has significant
agreement with the expert-designed Khan Academy curriculum, and
second-generation agents trained on the recovered curriculum learn
significantly faster. These results illustrate the synergistic role of
abstractions and curricula in the cultural transmission of mathematics.",https://github.com/gpoesia/peano,-1
340bff8b-89c2-45cf-82e7-72878ab58ca7,TripleRE: Knowledge Graph Embeddings via Tripled Relation Vectors,0.84798,"Translation-based knowledge graph embedding has been one of the most
important branches for knowledge representation learning since TransE came out.
Although many translation-based approaches have achieved some progress in
recent years, the performance was still unsatisfactory. This paper proposes a
novel knowledge graph embedding method named TripleRE with two versions. The
first version of TripleRE creatively divide the relationship vector into three
parts. The second version takes advantage of the concept of residual and
achieves better performance. In addition, attempts on using NodePiece to encode
entities achieved promising results in reducing the parametric size, and solved
the problems of scalability. Experiments show that our approach achieved
state-of-the-art performance on the large-scale knowledge graph dataset, and
competitive performance on other datasets.",https://github.com/ZJULearning/TransAt,360
7398cae7-9099-4c87-a061-2c3d11a55d9e,Batch Bayesian optimisation via density-ratio estimation with guarantees,0.278053,"Bayesian optimisation (BO) algorithms have shown remarkable success in
applications involving expensive black-box functions. Traditionally BO has been
set as a sequential decision-making process which estimates the utility of
query points via an acquisition function and a prior over functions, such as a
Gaussian process. Recently, however, a reformulation of BO via density-ratio
estimation (BORE) allowed reinterpreting the acquisition function as a
probabilistic binary classifier, removing the need for an explicit prior over
functions and increasing scalability. In this paper, we present a theoretical
analysis of BORE's regret and an extension of the algorithm with improved
uncertainty estimates. We also show that BORE can be naturally extended to a
batch optimisation setting by recasting the problem as approximate Bayesian
inference. The resulting algorithms come equipped with theoretical performance
guarantees and are assessed against other batch and sequential BO baselines in
a series of experiments.",https://github.com/rafaol/batch-bore-with-guarantees,-1
dfa92a4e-5a10-405f-bbe7-928a14a2a1d1,Tabula: Efficiently Computing Nonlinear Activation Functions for Secure Neural Network Inference,0.52395,"Multiparty computation approaches to secure neural network inference
traditionally rely on garbled circuits for securely executing nonlinear
activation functions. However, garbled circuits require excessive communication
between server and client, impose significant storage overheads, and incur
large runtime penalties. To eliminate these costs, we propose an alternative to
garbled circuits: Tabula, an algorithm based on secure lookup tables. Tabula
leverages neural networks' ability to be quantized and employs a secure lookup
table approach to efficiently, securely, and accurately compute neural network
nonlinear activation functions. Compared to garbled circuits with quantized
inputs, when computing individual nonlinear functions, our experiments show
Tabula uses between $35 \times$-$70 \times$ less communication, is over
$100\times$ faster, and uses a comparable amount of storage. This leads to
significant performance gains over garbled circuits with quantized inputs
during secure inference on neural networks: Tabula reduces overall
communication by up to $9 \times$ and achieves a speedup of up to $50 \times$,
while imposing comparable storage costs.",https://github.com/tabulainference/tabula,-1
15b852c6-1cbd-4afc-893b-6ffd6411a3a6,Neural Feature Fusion Fields: 3D Distillation of Self-Supervised 2D Image Representations,0.999692,"We present Neural Feature Fusion Fields (N3F), a method that improves dense
2D image feature extractors when the latter are applied to the analysis of
multiple images reconstructible as a 3D scene. Given an image feature
extractor, for example pre-trained using self-supervision, N3F uses it as a
teacher to learn a student network defined in 3D space. The 3D student network
is similar to a neural radiance field that distills said features and can be
trained with the usual differentiable rendering machinery. As a consequence,
N3F is readily applicable to most neural rendering formulations, including
vanilla NeRF and its extensions to complex dynamic scenes. We show that our
method not only enables semantic understanding in the context of scene-specific
neural fields without the use of manual labels, but also consistently improves
over the self-supervised 2D baselines. This is demonstrated by considering
various tasks, such as 2D object retrieval, 3D segmentation, and scene editing,
in diverse sequences, including long egocentric videos in the EPIC-KITCHENS
benchmark.",None,96096
f5aecae8-c1ac-464a-8016-a10b2799e664,Exploring the Value of Pre-trained Language Models for Clinical Named Entity Recognition,0.442272,"The practice of fine-tuning Pre-trained Language Models (PLMs) from general
or domain-specific data to a specific task with limited resources, has gained
popularity within the field of natural language processing (NLP). In this work,
we re-visit this assumption and carry out an investigation in clinical NLP,
specifically Named Entity Recognition on drugs and their related attributes. We
compare Transformer models that are trained from scratch to fine-tuned
BERT-based LLMs namely BERT, BioBERT, and ClinicalBERT. Furthermore, we examine
the impact of an additional CRF layer on such models to encourage contextual
learning. We use n2c2-2018 shared task data for model development and
evaluations. The experimental outcomes show that 1) CRF layers improved all
language models; 2) referring to BIO-strict span level evaluation using
macro-average F1 score, although the fine-tuned LLMs achieved 0.83+ scores, the
TransformerCRF model trained from scratch achieved 0.78+, demonstrating
comparable performances with much lower cost - e.g. with 39.80\% less training
parameters; 3) referring to BIO-strict span-level evaluation using
weighted-average F1 score, ClinicalBERT-CRF, BERT-CRF, and TransformerCRF
exhibited lower score differences, with 97.59\%/97.44\%/96.84\% respectively.
4) applying efficient training by down-sampling for better data distribution
further reduced the training cost and need for data, while maintaining similar
scores - i.e. around 0.02 points lower compared to using the full dataset. Our
models will be hosted at \url{https://github.com/HECTA-UoM/TransformerCRF}",https://github.com/HECTA-UoM/TransformerCRF,-1
2b630827-c68b-4a33-801a-67330c500b37,Conformance Checking with Uncertainty via SMT (Extended Version),0.513689,"Logs of real-life processes often feature uncertainty pertaining the recorded
timestamps, data values, and/or events. We consider the problem of checking
conformance of uncertain logs against data-aware reference processes.
Specifically, we show how to solve it via SMT encodings, lifting previous work
on data-aware SMT-based conformance checking to this more sophisticated
setting. Our approach is modular, in that it homogeneously accommodates for
different types of uncertainty. Moreover, using appropriate cost functions,
different conformance checking tasks can be addressed. We show the correctness
of our approach and witness feasibility through a proof-of-concept
implementation.",https://github.com/bytekid/cocomot,8569
6537b083-6490-4909-919a-0ebd3d10b06a,News Category Dataset,0.996538,"People rely on news to know what is happening around the world and inform
their daily lives. In today's world, when the proliferation of fake news is
rampant, having a large-scale and high-quality source of authentic news
articles with the published category information is valuable to learning
authentic news' Natural Language syntax and semantics. As part of this work, we
present a News Category Dataset that contains around 210k news headlines from
the year 2012 to 2022 obtained from HuffPost, along with useful metadata to
enable various NLP tasks. In this paper, we also produce some novel insights
from the dataset and describe various existing and potential applications of
our dataset.",None,-1
8644dc3f-f273-4b88-af24-5a59ae13bdc7,AARGH! End-to-end Retrieval-Generation for Task-Oriented Dialog,0.473217,"We introduce AARGH, an end-to-end task-oriented dialog system combining
retrieval and generative approaches in a single model, aiming at improving
dialog management and lexical diversity of outputs. The model features a new
response selection method based on an action-aware training objective and a
simplified single-encoder retrieval architecture which allow us to build an
end-to-end retrieval-enhanced generation model where retrieval and generation
share most of the parameters. On the MultiWOZ dataset, we show that our
approach produces more diverse outputs while maintaining or improving state
tracking and context-to-response generation performance, compared to
state-of-the-art baselines.",https://github.com/Tomiinek/Aargh,-1
ae6da2a9-f7cf-4b3f-8fa7-d02ef589be02,NaturalProver: Grounded Mathematical Proof Generation with Language Models,0.997389,"Theorem proving in natural mathematical language - the mixture of symbolic
and natural language used by humans - plays a central role in mathematical
advances and education, and tests aspects of reasoning that are core to
intelligence. Yet it has remained underexplored with modern generative models.
We study large-scale language models on two new generation tasks: suggesting
the next step in a mathematical proof, and full proof generation. We develop
NaturalProver, a language model that generates proofs by conditioning on
background references (e.g. theorems and definitions that are either retrieved
or human-provided), and optionally enforces their presence with constrained
decoding. On theorems from the NaturalProofs benchmark, NaturalProver improves
the quality of next-step suggestions and generated proofs over fine-tuned
GPT-3, according to human evaluations from university-level mathematics
students. NaturalProver is capable of proving some theorems that require short
(2-6 step) proofs, and providing next-step suggestions that are rated as
correct and useful over 40% of the time, which is to our knowledge the first
demonstration of these capabilities using neural language models.",https://github.com/wellecks/naturalprover,-1
11c42af2-1ea3-4c28-821e-f62f7740ce15,Rethinking Performance Gains in Image Dehazing Networks,0.863311,"Image dehazing is an active topic in low-level vision, and many image
dehazing networks have been proposed with the rapid development of deep
learning. Although these networks' pipelines work fine, the key mechanism to
improving image dehazing performance remains unclear. For this reason, we do
not target to propose a dehazing network with fancy modules; rather, we make
minimal modifications to popular U-Net to obtain a compact dehazing network.
Specifically, we swap out the convolutional blocks in U-Net for residual blocks
with the gating mechanism, fuse the feature maps of main paths and skip
connections using the selective kernel, and call the resulting U-Net variant
gUNet. As a result, with a significantly reduced overhead, gUNet is superior to
state-of-the-art methods on multiple image dehazing datasets. Finally, we
verify these key designs to the performance gain of image dehazing networks
through extensive ablation studies.",https://github.com/IDKiro/gUNet,6873
4b21a82f-39bf-43b2-912e-e8c070ec700f,BERT-Deep CNN: State-of-the-Art for Sentiment Analysis of COVID-19 Tweets,0.737404,"The free flow of information has been accelerated by the rapid development of
social media technology. There has been a significant social and psychological
impact on the population due to the outbreak of Coronavirus disease (COVID-19).
The COVID-19 pandemic is one of the current events being discussed on social
media platforms. In order to safeguard societies from this pandemic, studying
people's emotions on social media is crucial. As a result of their particular
characteristics, sentiment analysis of texts like tweets remains challenging.
Sentiment analysis is a powerful text analysis tool. It automatically detects
and analyzes opinions and emotions from unstructured data. Texts from a wide
range of sources are examined by a sentiment analysis tool, which extracts
meaning from them, including emails, surveys, reviews, social media posts, and
web articles. To evaluate sentiments, natural language processing (NLP) and
machine learning techniques are used, which assign weights to entities, topics,
themes, and categories in sentences or phrases. Machine learning tools learn
how to detect sentiment without human intervention by examining examples of
emotions in text. In a pandemic situation, analyzing social media texts to
uncover sentimental trends can be very helpful in gaining a better
understanding of society's needs and predicting future trends. We intend to
study society's perception of the COVID-19 pandemic through social media using
state-of-the-art BERT and Deep CNN models. The superiority of BERT models over
other deep models in sentiment analysis is evident and can be concluded from
the comparison of the various research studies mentioned in this article.",None,-1
3c26fe3d-2da4-4037-b2bc-a902840b768a,Distantly Supervised Named Entity Recognition via Confidence-Based Multi-Class Positive and Unlabeled Learning,0.940425,"In this paper, we study the named entity recognition (NER) problem under
distant supervision. Due to the incompleteness of the external dictionaries
and/or knowledge bases, such distantly annotated training data usually suffer
from a high false negative rate. To this end, we formulate the Distantly
Supervised NER (DS-NER) problem via Multi-class Positive and Unlabeled (MPU)
learning and propose a theoretically and practically novel CONFidence-based MPU
(Conf-MPU) approach. To handle the incomplete annotations, Conf-MPU consists of
two steps. First, a confidence score is estimated for each token of being an
entity token. Then, the proposed Conf-MPU risk estimation is applied to train a
multi-class classifier for the NER task. Thorough experiments on two benchmark
datasets labeled by various external knowledge demonstrate the superiority of
the proposed Conf-MPU over existing DS-NER methods.",https://github.com/shangjingbo1226/AutoNER,3269
42532919-0e90-4b27-8326-16aa653e5751,Thutmose Tagger: Single-pass neural model for Inverse Text Normalization,0.0240769,"Inverse text normalization (ITN) is an essential post-processing step in
automatic speech recognition (ASR). It converts numbers, dates, abbreviations,
and other semiotic classes from the spoken form generated by ASR to their
written forms. One can consider ITN as a Machine Translation task and use
neural sequence-to-sequence models to solve it. Unfortunately, such neural
models are prone to hallucinations that could lead to unacceptable errors. To
mitigate this issue, we propose a single-pass token classifier model that
regards ITN as a tagging task. The model assigns a replacement fragment to
every input token or marks it for deletion or copying without changes. We
present a dataset preparation method based on the granular alignment of ITN
examples. The proposed model is less prone to hallucination errors. The model
is trained on the Google Text Normalization dataset and achieves
state-of-the-art sentence accuracy on both English and Russian test sets.
One-to-one correspondence between tags and input words improves the
interpretability of the model's predictions, simplifies debugging, and allows
for post-processing corrections. The model is simpler than sequence-to-sequence
models and easier to optimize in production settings. The model and the code to
prepare the dataset is published as part of NeMo project.",https://github.com/NVIDIA/NeMo,-1
1e897a38-2269-4a51-b869-4751dc753328,Solutions for Fine-grained and Long-tailed Snake Species Recognition in SnakeCLEF 2022,0.576998,"Automatic snake species recognition is important because it has vast
potential to help lower deaths and disabilities caused by snakebites. We
introduce our solution in SnakeCLEF 2022 for fine-grained snake species
recognition on a heavy long-tailed class distribution. First, a network
architecture is designed to extract and fuse features from multiple modalities,
i.e. photograph from visual modality and geographic locality information from
language modality. Then, logit adjustment based methods are studied to relieve
the impact caused by the severe class imbalance. Next, a combination of
supervised and self-supervised learning method is proposed to make full use of
the dataset, including both labeled training data and unlabeled testing data.
Finally, post processing strategies, such as multi-scale and multi-crop
test-time-augmentation, location filtering and model ensemble, are employed for
better performance. With an ensemble of several different models, a private
score 82.65%, ranking the 3rd, is achieved on the final leaderboard.",None,13984
06b6d088-d627-4318-8be1-2be47e41ed62,Understanding Metrics for Paraphrasing,0.0273625,"Paraphrase generation is a difficult problem. This is not only because of the
limitations in text generation capabilities but also due that to the lack of a
proper definition of what qualifies as a paraphrase and corresponding metrics
to measure how good it is. Metrics for evaluation of paraphrasing quality is an
on going research problem. Most of the existing metrics in use having been
borrowed from other tasks do not capture the complete essence of a good
paraphrase, and often fail at borderline-cases. In this work, we propose a
novel metric $ROUGE_P$ to measure the quality of paraphrases along the
dimensions of adequacy, novelty and fluency. We also provide empirical evidence
to show that the current natural language generation metrics are insufficient
to measure these desired properties of a good paraphrase. We look at paraphrase
model fine-tuning and generation from the lens of metrics to gain a deeper
understanding of what it takes to generate and evaluate a good paraphrase.",None,-1
94a66700-df7d-4113-9609-0a245cbb3a2d,Backdoor Attacks in Federated Learning by Rare Embeddings and Gradient Ensembling,0.509038,"Recent advances in federated learning have demonstrated its promising
capability to learn on decentralized datasets. However, a considerable amount
of work has raised concerns due to the potential risks of adversaries
participating in the framework to poison the global model for an adversarial
purpose. This paper investigates the feasibility of model poisoning for
backdoor attacks through rare word embeddings of NLP models. In text
classification, less than 1% of adversary clients suffices to manipulate the
model output without any drop in the performance on clean sentences. For a less
complex dataset, a mere 0.1% of adversary clients is enough to poison the
global model effectively. We also propose a technique specialized in the
federated learning scheme called Gradient Ensemble, which enhances the backdoor
performance in all our experimental settings.",None,-1
71538419-70b8-4226-884c-b42a3a0af0fa,PolyHope: Two-Level Hope Speech Detection from Tweets,0.848905,"Hope is characterized as openness of spirit toward the future, a desire,
expectation, and wish for something to happen or to be true that remarkably
affects human's state of mind, emotions, behaviors, and decisions. Hope is
usually associated with concepts of desired expectations and
possibility/probability concerning the future. Despite its importance, hope has
rarely been studied as a social media analysis task. This paper presents a hope
speech dataset that classifies each tweet first into ""Hope"" and ""Not Hope"",
then into three fine-grained hope categories: ""Generalized Hope"", ""Realistic
Hope"", and ""Unrealistic Hope"" (along with ""Not Hope""). English tweets in the
first half of 2022 were collected to build this dataset. Furthermore, we
describe our annotation process and guidelines in detail and discuss the
challenges of classifying hope and the limitations of the existing hope speech
detection corpora. In addition, we reported several baselines based on
different learning approaches, such as traditional machine learning, deep
learning, and transformers, to benchmark our dataset. We evaluated our
baselines using weighted-averaged and macro-averaged F1-scores. Observations
show that a strict process for annotator selection and detailed annotation
guidelines enhanced the dataset's quality. This strict annotation process
resulted in promising performance for simple machine learning classifiers with
only bi-grams; however, binary and multiclass hope speech detection results
reveal that contextual embedding models have higher performance in this
dataset.",None,-1
9531ff98-3400-4ee9-9a2a-b68c2a963380,ReaRev: Adaptive Reasoning for Question Answering over Knowledge Graphs,0.286323,"Knowledge Graph Question Answering (KGQA) involves retrieving entities as
answers from a Knowledge Graph (KG) using natural language queries. The
challenge is to learn to reason over question-relevant KG facts that traverse
KG entities and lead to the question answers. To facilitate reasoning, the
question is decoded into instructions, which are dense question representations
used to guide the KG traversals. However, if the derived instructions do not
exactly match the underlying KG information, they may lead to reasoning under
irrelevant context. Our method, termed ReaRev, introduces a new way to KGQA
reasoning with respect to both instruction decoding and execution. To improve
instruction decoding, we perform reasoning in an adaptive manner, where
KG-aware information is used to iteratively update the initial instructions. To
improve instruction execution, we emulate breadth-first search (BFS) with graph
neural networks (GNNs). The BFS strategy treats the instructions as a set and
allows our method to decide on their execution order on the fly. Experimental
results on three KGQA benchmarks demonstrate the ReaRev's effectiveness
compared with previous state-of-the-art, especially when the KG is incomplete
or when we tackle complex questions. Our code is publicly available at
https://github.com/cmavro/ReaRev_KGQA.",https://github.com/cmavro/ReaRev_KGQA,-1
7b7b7e67-1576-44c7-9fe3-26096ce6af76,Less Is More: Linear Layers on CLIP Features as Powerful VizWiz Model,0.0188489,"Current architectures for multi-modality tasks such as visual question
answering suffer from their high complexity. As a result, these architectures
are difficult to train and require high computational resources. To address
these problems we present a CLIP-based architecture that does not require any
fine-tuning of the feature extractors. A simple linear classifier is used on
the concatenated features of the image and text encoder. During training an
auxiliary loss is added which operates on the answer types. The resulting
classification is then used as an attention gate on the answer class selection.
On the VizWiz 2022 Visual Question Answering Challenge we achieve 60.15 %
accuracy on Task 1: Predict Answer to a Visual Question and AP score of 83.78 %
on Task 2: Predict Answerability of a Visual Question.",None,-1
f3a819c0-4196-4b69-84e5-e6106be5cd98,A Proposal for Foley Sound Synthesis Challenge,0.838957,"""Foley"" refers to sound effects that are added to multimedia during
post-production to enhance its perceived acoustic properties, e.g., by
simulating the sounds of footsteps, ambient environmental sounds, or visible
objects on the screen. While foley is traditionally produced by foley artists,
there is increasing interest in automatic or machine-assisted techniques
building upon recent advances in sound synthesis and generative models. To
foster more participation in this growing research area, we propose a challenge
for automatic foley synthesis. Through case studies on successful previous
challenges in audio and machine learning, we set the goals of the proposed
challenge: rigorous, unified, and efficient evaluation of different foley
synthesis systems, with an overarching goal of drawing active participation
from the research community. We outline the details and design considerations
of a foley sound synthesis challenge, including task definition, dataset
requirements, and evaluation criteria.",None,-1
8c36d9f8-2198-4168-94ed-afce8cb2ebc5,On the link between conscious function and general intelligence in humans and machines,0.235021,"In popular media, there is often a connection drawn between the advent of
awareness in artificial agents and those same agents simultaneously achieving
human or superhuman level intelligence. In this work, we explore the validity
and potential application of this seemingly intuitive link between
consciousness and intelligence. We do so by examining the cognitive abilities
associated with three contemporary theories of conscious function: Global
Workspace Theory (GWT), Information Generation Theory (IGT), and Attention
Schema Theory (AST). We find that all three theories specifically relate
conscious function to some aspect of domain-general intelligence in humans.
With this insight, we turn to the field of Artificial Intelligence (AI) and
find that, while still far from demonstrating general intelligence, many
state-of-the-art deep learning methods have begun to incorporate key aspects of
each of the three functional theories. Having identified this trend, we use the
motivating example of mental time travel in humans to propose ways in which
insights from each of the three theories may be combined into a single unified
and implementable model. Given that it is made possible by cognitive abilities
underlying each of the three functional theories, artificial agents capable of
mental time travel would not only possess greater general intelligence than
current approaches, but also be more consistent with our current understanding
of the functional role of consciousness in humans, thus making it a promising
near-term goal for AI research.",None,-1
9820dafa-863f-42be-bd1b-1d34ea945234,Hierarchical Instance Mixing across Domains in Aerial Segmentation,0.648687,"We investigate the task of unsupervised domain adaptation in aerial semantic
segmentation and discover that the current state-of-the-art algorithms designed
for autonomous driving based on domain mixing do not translate well to the
aerial setting. This is due to two factors: (i) a large disparity in the
extension of the semantic categories, which causes a domain imbalance in the
mixed image, and (ii) a weaker structural consistency in aerial scenes than in
driving scenes since the same scene might be viewed from different perspectives
and there is no well-defined and repeatable structure of the semantic elements
in the images. Our solution to these problems is composed of: (i) a new mixing
strategy for aerial segmentation across domains called Hierarchical Instance
Mixing (HIMix), which extracts a set of connected components from each semantic
mask and mixes them according to a semantic hierarchy and, (ii) a twin-head
architecture in which two separate segmentation heads are fed with variations
of the same images in a contrastive fashion to produce finer segmentation maps.
We conduct extensive experiments on the LoveDA benchmark, where our solution
outperforms the current state-of-the-art.",None,-1
5cd0fb27-91e5-4e14-a73c-5da04478f266,Theory-Grounded Measurement of U.S. Social Stereotypes in English Language Models,0.958189,"NLP models trained on text have been shown to reproduce human stereotypes,
which can magnify harms to marginalized groups when systems are deployed at
scale. We adapt the Agency-Belief-Communion (ABC) stereotype model of Koch et
al. (2016) from social psychology as a framework for the systematic study and
discovery of stereotypic group-trait associations in language models (LMs). We
introduce the sensitivity test (SeT) for measuring stereotypical associations
from language models. To evaluate SeT and other measures using the ABC model,
we collect group-trait judgments from U.S.-based subjects to compare with
English LM stereotypes. Finally, we extend this framework to measure LM
stereotyping of intersectional identities.",https://github.com/TristaCao/U.S_Stereotypes,-1
0a703c6b-1dde-4fdf-83c6-25af6eb36f64,RAAT: Relation-Augmented Attention Transformer for Relation Modeling in Document-Level Event Extraction,0.908302,"In document-level event extraction (DEE) task, event arguments always scatter
across sentences (across-sentence issue) and multiple events may lie in one
document (multi-event issue). In this paper, we argue that the relation
information of event arguments is of great significance for addressing the
above two issues, and propose a new DEE framework which can model the relation
dependencies, called Relation-augmented Document-level Event Extraction
(ReDEE). More specifically, this framework features a novel and tailored
transformer, named as Relation-augmented Attention Transformer (RAAT). RAAT is
scalable to capture multi-scale and multi-amount argument relations. To further
leverage relation information, we introduce a separate event relation
prediction task and adopt multi-task learning method to explicitly enhance
event extraction performance. Extensive experiments demonstrate the
effectiveness of the proposed method, which can achieve state-of-the-art
performance on two public datasets. Our code is available at https://github.
com/TencentYoutuResearch/RAAT.",https://github.com/TencentYoutuResearch/RAAT,-1
9f027b82-59fd-470c-840c-acfd4df45c5d,Registration based Few-Shot Anomaly Detection,0.998717,"This paper considers few-shot anomaly detection (FSAD), a practical yet
under-studied setting for anomaly detection (AD), where only a limited number
of normal images are provided for each category at training. So far, existing
FSAD studies follow the one-model-per-category learning paradigm used for
standard AD, and the inter-category commonality has not been explored. Inspired
by how humans detect anomalies, i.e., comparing an image in question to normal
images, we here leverage registration, an image alignment task that is
inherently generalizable across categories, as the proxy task, to train a
category-agnostic anomaly detection model. During testing, the anomalies are
identified by comparing the registered features of the test image and its
corresponding support (normal) images. As far as we know, this is the first
FSAD method that trains a single generalizable model and requires no
re-training or parameter fine-tuning for new categories. Experimental results
have shown that the proposed method outperforms the state-of-the-art FSAD
methods by 3%-8% in AUC on the MVTec and MPDD benchmarks.",https://github.com/MediaBrain-SJTU/RegAD,-1
1cf6e153-148c-45e3-b0e0-fcac177563e6,Practical Network Acceleration with Tiny Sets,0.231149,"Due to data privacy issues, accelerating networks with tiny training sets has
become a critical need in practice. Previous methods mainly adopt filter-level
pruning to accelerate networks with scarce training samples. In this paper, we
reveal that dropping blocks is a fundamentally superior approach in this
scenario. It enjoys a higher acceleration ratio and results in a better
latency-accuracy performance under the few-shot setting. To choose which blocks
to drop, we propose a new concept namely recoverability to measure the
difficulty of recovering the compressed network. Our recoverability is
efficient and effective for choosing which blocks to drop. Finally, we propose
an algorithm named PRACTISE to accelerate networks using only tiny sets of
training images. PRACTISE outperforms previous methods by a significant margin.
For 22% latency reduction, PRACTISE surpasses previous methods by on average 7%
on ImageNet-1k. It also enjoys high generalization ability, working well under
data-free or out-of-domain data settings, too. Our code is at
https://github.com/DoctorKey/Practise.",https://github.com/DoctorKey/Practise,21492
6a810633-c255-4042-8bbb-1f56e53ab3b7,ACES: Translation Accuracy Challenge Sets for Evaluating Machine Translation Metrics,0.605246,"As machine translation (MT) metrics improve their correlation with human
judgement every year, it is crucial to understand the limitations of such
metrics at the segment level. Specifically, it is important to investigate
metric behaviour when facing accuracy errors in MT because these can have
dangerous consequences in certain contexts (e.g., legal, medical). We curate
ACES, a translation accuracy challenge set, consisting of 68 phenomena ranging
from simple perturbations at the word/character level to more complex errors
based on discourse and real-world knowledge. We use ACES to evaluate a wide
range of MT metrics including the submissions to the WMT 2022 metrics shared
task and perform several analyses leading to general recommendations for metric
developers. We recommend: a) combining metrics with different strengths, b)
developing metrics that give more weight to the source and less to
surface-level overlap with the reference and c) explicitly modelling additional
language-specific information beyond what is available via multilingual
embeddings.",https://github.com/EdinburghNLP/ACES,-1
9c8410c6-d809-4e32-83a8-e56ee7c942be,Predicting Protein-Ligand Binding Affinity via Joint Global-Local Interaction Modeling,0.649084,"The prediction of protein-ligand binding affinity is of great significance
for discovering lead compounds in drug research. Facing this challenging task,
most existing prediction methods rely on the topological and/or spatial
structure of molecules and the local interactions while ignoring the
multi-level inter-molecular interactions between proteins and ligands, which
often lead to sub-optimal performance. To solve this issue, we propose a novel
global-local interaction (GLI) framework to predict protein-ligand binding
affinity. In particular, our GLI framework considers the inter-molecular
interactions between proteins and ligands, which involve not only the
high-energy short-range interactions between closed atoms but also the
low-energy long-range interactions between non-bonded atoms. For each pair of
protein and ligand, our GLI embeds the long-range interactions globally and
aggregates local short-range interactions, respectively. Such a joint
global-local interaction modeling strategy helps to improve prediction
accuracy, and the whole framework is compatible with various neural
network-based modules. Experiments demonstrate that our GLI framework
outperforms state-of-the-art methods with simple neural network architectures
and moderate computational costs.",https://github.com/PaddlePaddle/PaddleHelix,-1
82b98032-30f3-436b-b572-b1b074c2ac90,In-Hand 3D Object Scanning from an RGB Sequence,0.968619,"We propose a method for in-hand 3D scanning of an unknown object with a
monocular camera. Our method relies on a neural implicit surface representation
that captures both the geometry and the appearance of the object, however, by
contrast with most NeRF-based methods, we do not assume that the camera-object
relative poses are known. Instead, we simultaneously optimize both the object
shape and the pose trajectory. As direct optimization over all shape and pose
parameters is prone to fail without coarse-level initialization, we propose an
incremental approach that starts by splitting the sequence into carefully
selected overlapping segments within which the optimization is likely to
succeed. We reconstruct the object shape and track its poses independently
within each segment, then merge all the segments before performing a global
optimization. We show that our method is able to reconstruct the shape and
color of both textured and challenging texture-less objects, outperforms
classical methods that rely only on appearance features, and that its
performance is close to recent methods that assume known camera poses.",None,-1
03ff2004-4640-4941-8e52-adf375b85fba,Chart Question Answering: State of the Art and Future Directions,0.516864,"Information visualizations such as bar charts and line charts are very common
for analyzing data and discovering critical insights. Often people analyze
charts to answer questions that they have in mind. Answering such questions can
be challenging as they often require a significant amount of perceptual and
cognitive effort. Chart Question Answering (CQA) systems typically take a chart
and a natural language question as input and automatically generate the answer
to facilitate visual data analysis. Over the last few years, there has been a
growing body of literature on the task of CQA. In this survey, we
systematically review the current state-of-the-art research focusing on the
problem of chart question answering. We provide a taxonomy by identifying
several important dimensions of the problem domain including possible inputs
and outputs of the task and discuss the advantages and limitations of proposed
solutions. We then summarize various evaluation techniques used in the surveyed
papers. Finally, we outline the open challenges and future research
opportunities related to chart question answering.",None,-1
4cba19b2-e1fd-43f3-8779-78a63cb72369,Automatic Detection of Entity-Manipulated Text using Factual Knowledge,0.686449,"In this work, we focus on the problem of distinguishing a human written news
article from a news article that is created by manipulating entities in a human
written news article (e.g., replacing entities with factually incorrect
entities). Such manipulated articles can mislead the reader by posing as a
human written news article. We propose a neural network based detector that
detects manipulated news articles by reasoning about the facts mentioned in the
article. Our proposed detector exploits factual knowledge via graph
convolutional neural network along with the textual information in the news
article. We also create challenging datasets for this task by considering
various strategies to generate the new replacement entity (e.g., entity
generation from GPT-2). In all the settings, our proposed model either matches
or outperforms the state-of-the-art detector in terms of accuracy. Our code and
data are available at https://github.com/UBC-NLP/manipulated_entity_detection.",https://github.com/UBC-NLP/manipulated_entity_detection,-1
6bf6cfe3-d9ef-4c07-b46b-fab2ec3b2547,TCTrack: Temporal Contexts for Aerial Tracking,0.991593,"Temporal contexts among consecutive frames are far from being fully utilized
in existing visual trackers. In this work, we present TCTrack, a comprehensive
framework to fully exploit temporal contexts for aerial tracking. The temporal
contexts are incorporated at \textbf{two levels}: the extraction of
\textbf{features} and the refinement of \textbf{similarity maps}. Specifically,
for feature extraction, an online temporally adaptive convolution is proposed
to enhance the spatial features using temporal information, which is achieved
by dynamically calibrating the convolution weights according to the previous
frames. For similarity map refinement, we propose an adaptive temporal
transformer, which first effectively encodes temporal knowledge in a
memory-efficient way, before the temporal knowledge is decoded for accurate
adjustment of the similarity map. TCTrack is effective and efficient:
evaluation on four aerial tracking benchmarks shows its impressive performance;
real-world UAV tests show its high speed of over 27 FPS on NVIDIA Jetson AGX
Xavier.",https://github.com/vision4robotics/TCTrack,-1
386e5d90-8bc1-44c2-beb5-aad72aca9ff4,CEIP: Combining Explicit and Implicit Priors for Reinforcement Learning with Demonstrations,0.0322677,"Although reinforcement learning has found widespread use in dense reward
settings, training autonomous agents with sparse rewards remains challenging.
To address this difficulty, prior work has shown promising results when using
not only task-specific demonstrations but also task-agnostic albeit somewhat
related demonstrations. In most cases, the available demonstrations are
distilled into an implicit prior, commonly represented via a single deep net.
Explicit priors in the form of a database that can be queried have also been
shown to lead to encouraging results. To better benefit from available
demonstrations, we develop a method to Combine Explicit and Implicit Priors
(CEIP). CEIP exploits multiple implicit priors in the form of normalizing flows
in parallel to form a single complex prior. Moreover, CEIP uses an effective
explicit retrieval and push-forward mechanism to condition the implicit priors.
In three challenging environments, we find the proposed CEIP method to improve
upon sophisticated state-of-the-art techniques.",https://github.com/289371298/CEIP,-1
1f643a27-dd81-49f1-a5da-602f9eb4bd66,PSFormer: Point Transformer for 3D Salient Object Detection,0.0202627,"We propose PSFormer, an effective point transformer model for 3D salient
object detection. PSFormer is an encoder-decoder network that takes full
advantage of transformers to model the contextual information in both
multi-scale point- and scene-wise manners. In the encoder, we develop a Point
Context Transformer (PCT) module to capture region contextual features at the
point level; PCT contains two different transformers to excavate the
relationship among points. In the decoder, we develop a Scene Context
Transformer (SCT) module to learn context representations at the scene level;
SCT contains both Upsampling-and-Transformer blocks and Multi-context
Aggregation units to integrate the global semantic and multi-level features
from the encoder into the global scene context. Experiments show clear
improvements of PSFormer over its competitors and validate that PSFormer is
more robust to challenging cases such as small objects, multiple objects, and
objects with complex structures.",None,-1
ccf2321b-62d2-4842-85dd-767da92b9cb5,Unsupervised Opinion Summarization Using Approximate Geodesics,0.409823,"Opinion summarization is the task of creating summaries capturing popular
opinions from user reviews. In this paper, we introduce Geodesic Summarizer
(GeoSumm), a novel system to perform unsupervised extractive opinion
summarization. GeoSumm involves an encoder-decoder based representation
learning model, that generates representations of text as a distribution over
latent semantic units. GeoSumm generates these representations by performing
dictionary learning over pre-trained text representations at multiple decoder
layers. We then use these representations to quantify the relevance of review
sentences using a novel approximate geodesic distance based scoring mechanism.
We use the relevance scores to identify popular opinions in order to compose
general and aspect-specific summaries. Our proposed model, GeoSumm, achieves
state-of-the-art performance on three opinion summarization datasets. We
perform additional experiments to analyze the functioning of our model and
showcase the generalization ability of {\X} across different domains.",None,-1
2260727c-a839-4320-967e-45fb51d68310,Track Before Detect of Low SNR Objects in a Sequence of Image Frames Using Particle Filter,0.0945512,"A multiple model track-before-detect (TBD) particle filter-based approach for
detection and tracking of low signal to noise ratio (SNR) objects based on a
sequence of image frames in the presence of noise and clutter is briefly
studied in this letter. At each time instance after receiving a frame of image,
first, some preprocessing approaches are applied to the image. Then, it is sent
to the multiple model TBD particle filter for detection and tracking of an
object. Performance of the approach is evaluated for detection and tracking of
an object in different scenarios including noise and clutter.",None,-1
261087bf-4179-4ddb-9587-b73be97b0fa1,On Explaining Multimodal Hateful Meme Detection Models,0.928746,"Hateful meme detection is a new multimodal task that has gained significant
traction in academic and industry research communities. Recently, researchers
have applied pre-trained visual-linguistic models to perform the multimodal
classification task, and some of these solutions have yielded promising
results. However, what these visual-linguistic models learn for the hateful
meme classification task remains unclear. For instance, it is unclear if these
models are able to capture the derogatory or slurs references in multimodality
(i.e., image and text) of the hateful memes. To fill this research gap, this
paper propose three research questions to improve our understanding of these
visual-linguistic models performing the hateful meme classification task. We
found that the image modality contributes more to the hateful meme
classification task, and the visual-linguistic models are able to perform
visual-text slurs grounding to a certain extent. Our error analysis also shows
that the visual-linguistic models have acquired biases, which resulted in
false-positive predictions.",https://gitlab.com/bottle_shop/safe/ExplainHatefulMeme,-1
2456bcab-99a2-4891-ad42-969c8ef8c8bd,Divert More Attention to Vision-Language Tracking,0.38206,"Relying on Transformer for complex visual feature learning, object tracking
has witnessed the new standard for state-of-the-arts (SOTAs). However, this
advancement accompanies by larger training data and longer training period,
making tracking increasingly expensive. In this paper, we demonstrate that the
Transformer-reliance is not necessary and the pure ConvNets are still
competitive and even better yet more economical and friendly in achieving SOTA
tracking. Our solution is to unleash the power of multimodal vision-language
(VL) tracking, simply using ConvNets. The essence lies in learning novel
unified-adaptive VL representations with our modality mixer (ModaMixer) and
asymmetrical ConvNet search. We show that our unified-adaptive VL
representation, learned purely with the ConvNets, is a simple yet strong
alternative to Transformer visual features, by unbelievably improving a
CNN-based Siamese tracker by 14.5% in SUC on challenging LaSOT (50.7% > 65.2%),
even outperforming several Transformer-based SOTA trackers. Besides empirical
results, we theoretically analyze our approach to evidence its effectiveness.
By revealing the potential of VL representation, we expect the community to
divert more attention to VL tracking and hope to open more possibilities for
future tracking beyond Transformer. Code and models will be released at
https://github.com/JudasDie/SOTS.",https://github.com/JudasDie/SOTS,5901
a672b220-b1d0-4057-b96e-b452106418da,Robust Anytime Learning of Markov Decision Processes,0.579167,"Markov decision processes (MDPs) are formal models commonly used in
sequential decision-making. MDPs capture the stochasticity that may arise, for
instance, from imprecise actuators via probabilities in the transition
function. However, in data-driven applications, deriving precise probabilities
from (limited) data introduces statistical errors that may lead to unexpected
or undesirable outcomes. Uncertain MDPs (uMDPs) do not require precise
probabilities but instead use so-called uncertainty sets in the transitions,
accounting for such limited data. Tools from the formal verification community
efficiently compute robust policies that provably adhere to formal
specifications, like safety constraints, under the worst-case instance in the
uncertainty set. We continuously learn the transition probabilities of an MDP
in a robust anytime-learning approach that combines a dedicated Bayesian
inference scheme with the computation of robust policies. In particular, our
method (1) approximates probabilities as intervals, (2) adapts to new data that
may be inconsistent with an intermediate model, and (3) may be stopped at any
time to compute a robust policy on the uMDP that faithfully captures the data
so far. Furthermore, our method is capable of adapting to changes in the
environment. We show the effectiveness of our approach and compare it to robust
policies computed on uMDPs learned by the UCRL2 reinforcement learning
algorithm in an experimental evaluation on several benchmarks.",https://github.com/LAVA-LAB/luiaard,-1
e4886392-ee39-475a-bdc1-a7442e3d145b,Physics-aware Differentiable Discrete Codesign for Diffractive Optical Neural Networks,0.733773,"Diffractive optical neural networks (DONNs) have attracted lots of attention
as they bring significant advantages in terms of power efficiency, parallelism,
and computational speed compared with conventional deep neural networks (DNNs),
which have intrinsic limitations when implemented on digital platforms.
However, inversely mapping algorithm-trained physical model parameters onto
real-world optical devices with discrete values is a non-trivial task as
existing optical devices have non-unified discrete levels and non-monotonic
properties. This work proposes a novel device-to-system hardware-software
codesign framework, which enables efficient physics-aware training of DONNs
w.r.t arbitrary experimental measured optical devices across layers.
Specifically, Gumbel-Softmax is employed to enable differentiable discrete
mapping from real-world device parameters into the forward function of DONNs,
where the physical parameters in DONNs can be trained by simply minimizing the
loss function of the ML task. The results have demonstrated that our proposed
framework offers significant advantages over conventional quantization-based
methods, especially with low-precision optical devices. Finally, the proposed
algorithm is fully verified with physical experimental optical systems in
low-precision settings.",None,-1
6720aeb6-0312-4349-ad8c-ba0456495b8e,Automatic Subspace Evoking for Efficient Neural Architecture Search,0.106628,"Neural Architecture Search (NAS) aims to automatically find effective
architectures from a predefined search space. However, the search space is
often extremely large. As a result, directly searching in such a large search
space is non-trivial and also very time-consuming. To address the above issues,
in each search step, we seek to limit the search space to a small but effective
subspace to boost both the search performance and search efficiency. To this
end, we propose a novel Neural Architecture Search method via Automatic
Subspace Evoking (ASE-NAS) that finds promising architectures in automatically
evoked subspaces. Specifically, we first perform a global search, i.e.,
automatic subspace evoking, to evoke/find a good subspace from a set of
candidates. Then, we perform a local search within the evoked subspace to find
an effective architecture. More critically, we further boost search performance
by taking well-designed/searched architectures as the initial candidate
subspaces. Extensive experiments show that our ASE-NAS not only greatly reduces
the search cost but also finds better architectures than state-of-the-art
methods in various benchmark search spaces.",None,-1
3a4da0c4-90fb-4a84-bec5-627c6dde1edf,End-to-End Rubbing Restoration Using Generative Adversarial Networks,0.0855765,"Rubbing restorations are significant for preserving world cultural history.
In this paper, we propose the RubbingGAN model for restoring incomplete rubbing
characters. Specifically, we collect characters from the Zhang Menglong Bei and
build up the first rubbing restoration dataset. We design the first generative
adversarial network for rubbing restoration. Based on the dataset we collect,
we apply the RubbingGAN to learn the Zhang Menglong Bei font style and restore
the characters. The results of experiments show that RubbingGAN can repair both
slightly and severely incomplete rubbing characters fast and effectively.",https://github.com/qingfengtommy/RubbingGAN,-1
110008fb-3888-4587-977f-8a326eeee013,Transition-based Semantic Role Labeling with Pointer Networks,0.12636,"Semantic role labeling (SRL) focuses on recognizing the predicate-argument
structure of a sentence and plays a critical role in many natural language
processing tasks such as machine translation and question answering.
Practically all available methods do not perform full SRL, since they rely on
pre-identified predicates, and most of them follow a pipeline strategy, using
specific models for undertaking one or several SRL subtasks. In addition,
previous approaches have a strong dependence on syntactic information to
achieve state-of-the-art performance, despite being syntactic trees equally
hard to produce. These simplifications and requirements make the majority of
SRL systems impractical for real-world applications. In this article, we
propose the first transition-based SRL approach that is capable of completely
processing an input sentence in a single left-to-right pass, with neither
leveraging syntactic information nor resorting to additional modules. Thanks to
our implementation based on Pointer Networks, full SRL can be accurately and
efficiently done in $O(n^2)$, achieving the best performance to date on the
majority of languages from the CoNLL-2009 shared task.",None,-1
84aad538-8961-4105-ad9f-9eb555cee5ec,"3MASSIV: Multilingual, Multimodal and Multi-Aspect dataset of Social Media Short Videos",0.660262,"We present 3MASSIV, a multilingual, multimodal and multi-aspect,
expertly-annotated dataset of diverse short videos extracted from short-video
social media platform - Moj. 3MASSIV comprises of 50k short videos (20 seconds
average duration) and 100K unlabeled videos in 11 different languages and
captures popular short video trends like pranks, fails, romance, comedy
expressed via unique audio-visual formats like self-shot videos, reaction
videos, lip-synching, self-sung songs, etc. 3MASSIV presents an opportunity for
multimodal and multilingual semantic understanding on these unique videos by
annotating them for concepts, affective states, media types, and audio
language. We present a thorough analysis of 3MASSIV and highlight the variety
and unique aspects of our dataset compared to other contemporary popular
datasets with strong baselines. We also show how the social media content in
3MASSIV is dynamic and temporal in nature, which can be used for semantic
understanding tasks and cross-lingual analysis.",None,-1
4d1ccc47-6576-4f28-974b-2b52529b9fe4,The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning,0.351071,"Does prompting a large language model (LLM) like GPT-3 with explanations
improve in-context learning? We study this question on two NLP tasks that
involve reasoning over text, namely question answering and natural language
inference. We test the performance of four LLMs on three textual reasoning
datasets using prompts that include explanations in multiple different styles.
For these tasks, we find that including explanations in the prompts for OPT,
GPT-3 (davinci), and InstructGPT (text-davinci-001) only yields small to
moderate accuracy improvements over standard few-show learning. However,
text-davinci-002 is able to benefit more substantially.
  We further show that explanations generated by the LLMs may not entail the
models' predictions nor be factually grounded in the input, even on simple
tasks with extractive explanations. However, these flawed explanations can
still be useful as a way to verify LLMs' predictions post-hoc. Through analysis
in our three settings, we show that explanations judged by humans to be
good--logically consistent with the input and the prediction--more likely
cooccur with accurate predictions. Following these observations, we train
calibrators using automatically extracted scores that assess the reliability of
explanations, allowing us to improve performance post-hoc across all of our
datasets.",https://github.com/xiye17/TextualExplInContext,-1
1cb0c20a-bad6-40cc-b3e8-26e1db4dce73,KappaFace: Adaptive Additive Angular Margin Loss for Deep Face Recognition,0.988297,"Feature learning is a widely used method employed for large-scale face
recognition. Recently, large-margin softmax loss methods have demonstrated
significant enhancements on deep face recognition. These methods propose fixed
positive margins in order to enforce intra-class compactness and inter-class
diversity. However, the majority of the proposed methods do not consider the
class imbalance issue, which is a major challenge in practice for developing
deep face recognition models. We hypothesize that it significantly affects the
generalization ability of the deep face models. Inspired by this observation,
we introduce a novel adaptive strategy, called KappaFace, to modulate the
relative importance based on class difficultness and imbalance. With the
support of the von Mises-Fisher distribution, our proposed KappaFace loss can
intensify the margin's magnitude for hard learning or low concentration classes
while relaxing it for counter classes. Experiments conducted on popular facial
benchmarks demonstrate that our proposed method achieves superior performance
to the state-of-the-art.",https://github.com/chingisooinar/KappaFace,2499
240df299-5efc-45c7-8d35-64f0effb7868,Benchmarking Generative Latent Variable Models for Speech,0.14284,"Stochastic latent variable models (LVMs) achieve state-of-the-art performance
on natural image generation but are still inferior to deterministic models on
speech. In this paper, we develop a speech benchmark of popular temporal LVMs
and compare them against state-of-the-art deterministic models. We report the
likelihood, which is a much used metric in the image domain, but rarely, or
incomparably, reported for speech models. To assess the quality of the learned
representations, we also compare their usefulness for phoneme recognition.
Finally, we adapt the Clockwork VAE, a state-of-the-art temporal LVM for video
generation, to the speech domain. Despite being autoregressive only in latent
space, we find that the Clockwork VAE can outperform previous LVMs and reduce
the gap to deterministic models by using a hierarchy of latent variables.",https://github.com/JakobHavtorn/benchmarking-lvms,-1
75e7818f-ca98-47ce-8481-b40b29bd9603,DialogUSR: Complex Dialogue Utterance Splitting and Reformulation for Multiple Intent Detection,0.572292,"While interacting with chatbots, users may elicit multiple intents in a
single dialogue utterance. Instead of training a dedicated multi-intent
detection model, we propose DialogUSR, a dialogue utterance splitting and
reformulation task that first splits multi-intent user query into several
single-intent sub-queries and then recovers all the coreferred and omitted
information in the sub-queries. DialogUSR can serve as a plug-in and
domain-agnostic module that empowers the multi-intent detection for the
deployed chatbots with minimal efforts. We collect a high-quality naturally
occurring dataset that covers 23 domains with a multi-step crowd-souring
procedure. To benchmark the proposed dataset, we propose multiple action-based
generative models that involve end-to-end and two-stage training, and conduct
in-depth analyses on the pros and cons of the proposed baselines.",https://github.com/MrZhengXin/multi_intent_2022,-1
b2f75d53-2aeb-4eb6-a944-a1b0c4b9fe64,Flow-Guided Transformer for Video Inpainting,0.617272,"We propose a flow-guided transformer, which innovatively leverage the motion
discrepancy exposed by optical flows to instruct the attention retrieval in
transformer for high fidelity video inpainting. More specially, we design a
novel flow completion network to complete the corrupted flows by exploiting the
relevant flow features in a local temporal window. With the completed flows, we
propagate the content across video frames, and adopt the flow-guided
transformer to synthesize the rest corrupted regions. We decouple transformers
along temporal and spatial dimension, so that we can easily integrate the
locally relevant completed flows to instruct spatial attention only.
Furthermore, we design a flow-reweight module to precisely control the impact
of completed flows on each spatial transformer. For the sake of efficiency, we
introduce window partition strategy to both spatial and temporal transformers.
Especially in spatial transformer, we design a dual perspective spatial MHSA,
which integrates the global tokens to the window-based attention. Extensive
experiments demonstrate the effectiveness of the proposed method qualitatively
and quantitatively. Codes are available at https://github.com/hitachinsk/FGT.",https://github.com/hitachinsk/FGT,-1
893cce87-512a-47ec-b7c9-6c9ccbf56ab9,Polymorphic-GAN: Generating Aligned Samples across Multiple Domains with Learned Morph Maps,0.160563,"Modern image generative models show remarkable sample quality when trained on
a single domain or class of objects. In this work, we introduce a generative
adversarial network that can simultaneously generate aligned image samples from
multiple related domains. We leverage the fact that a variety of object classes
share common attributes, with certain geometric differences. We propose
Polymorphic-GAN which learns shared features across all domains and a
per-domain morph layer to morph shared features according to each domain. In
contrast to previous works, our framework allows simultaneous modelling of
images with highly varying geometries, such as images of human faces, painted
and artistic faces, as well as multiple different animal faces. We demonstrate
that our model produces aligned samples for all domains and show how it can be
used for applications such as segmentation transfer and cross-domain image
editing, as well as training in low-data regimes. Additionally, we apply our
Polymorphic-GAN on image-to-image translation tasks and show that we can
greatly surpass previous approaches in cases where the geometric differences
between domains are large.",https://github.com/NVlabs/PMGAN,-1
98f90968-6ed8-4a41-b9e7-c7b718d1791e,Unifying Short and Long-Term Tracking with Graph Hierarchies,0.775434,"Tracking objects over long videos effectively means solving a spectrum of
problems, from short-term association for un-occluded objects to long-term
association for objects that are occluded and then reappear in the scene.
Methods tackling these two tasks are often disjoint and crafted for specific
scenarios, and top-performing approaches are often a mix of techniques, which
yields engineering-heavy solutions that lack generality. In this work, we
question the need for hybrid approaches and introduce SUSHI, a unified and
scalable multi-object tracker. Our approach processes long clips by splitting
them into a hierarchy of subclips, which enables high scalability. We leverage
graph neural networks to process all levels of the hierarchy, which makes our
model unified across temporal scales and highly general. As a result, we obtain
significant improvements over state-of-the-art on four diverse datasets. Our
code and models are available at bit.ly/sushi-mot.",None,-1
51900533-4610-4eef-a421-c9e5a900981b,Boosting human decision-making with AI-generated decision aids,0.285486,"Human decision-making is plagued by many systematic errors. Many of these
errors can be avoided by providing decision aids that guide decision-makers to
attend to the important information and integrate it according to a rational
decision strategy. Designing such decision aids used to be a tedious manual
process. Advances in cognitive science might make it possible to automate this
process in the future. We recently introduced machine learning methods for
discovering optimal strategies for human decision-making automatically and an
automatic method for explaining those strategies to people. Decision aids
constructed by this method were able to improve human decision-making. However,
following the descriptions generated by this method is very tedious. We
hypothesized that this problem can be overcome by conveying the automatically
discovered decision strategy as a series of natural language instructions for
how to reach a decision. Experiment 1 showed that people do indeed understand
such procedural instructions more easily than the decision aids generated by
our previous method. Encouraged by this finding, we developed an algorithm for
translating the output of our previous method into procedural instructions. We
applied the improved method to automatically generate decision aids for a
naturalistic planning task (i.e., planning a road trip) and a naturalistic
decision task (i.e., choosing a mortgage). Experiment 2 showed that these
automatically generated decision-aids significantly improved people's
performance in planning a road trip and choosing a mortgage. These findings
suggest that AI-powered boosting might have potential for improving human
decision-making in the real world.",https://github.com/RationalityEnhancement/InterpretableStrategyDiscovery,-1
89e6de5a-8a1d-4833-a11e-07b03b4a4099,Multi-Task Learning Framework for Extracting Emotion Cause Span and Entailment in Conversations,0.696856,"Predicting emotions expressed in text is a well-studied problem in the NLP
community. Recently there has been active research in extracting the cause of
an emotion expressed in text. Most of the previous work has done causal emotion
entailment in documents. In this work, we propose neural models to extract
emotion cause span and entailment in conversations. For learning such models,
we use RECCON dataset, which is annotated with cause spans at the utterance
level. In particular, we propose MuTEC, an end-to-end Multi-Task learning
framework for extracting emotions, emotion cause, and entailment in
conversations. This is in contrast to existing baseline models that use ground
truth emotions to extract the cause. MuTEC performs better than the baselines
for most of the data folds provided in the dataset.",https://github.com/Exploration-Lab/MuTEC,-1
5a762ba7-4d5a-4587-ba98-9d8301cfdc20,Reinforced Approximate Exploratory Data Analysis,0.545916,"Exploratory data analytics (EDA) is a sequential decision making process
where analysts choose subsequent queries that might lead to some interesting
insights based on the previous queries and corresponding results. Data
processing systems often execute the queries on samples to produce results with
low latency. Different downsampling strategy preserves different statistics of
the data and have different magnitude of latency reductions. The optimum choice
of sampling strategy often depends on the particular context of the analysis
flow and the hidden intent of the analyst. In this paper, we are the first to
consider the impact of sampling in interactive data exploration settings as
they introduce approximation errors. We propose a Deep Reinforcement Learning
(DRL) based framework which can optimize the sample selection in order to keep
the analysis and insight generation flow intact. Evaluations with 3 real
datasets show that our technique can preserve the original insight generation
flow while improving the interaction latency, compared to baseline methods.",https://anonymous.4open.science/r/approxEDA-53D3/,-1
64536f23-df4f-43bc-a0e4-10623edd72bd,Black-Box Attack against GAN-Generated Image Detector with Contrastive Perturbation,0.28664,"Visually realistic GAN-generated facial images raise obvious concerns on
potential misuse. Many effective forensic algorithms have been developed to
detect such synthetic images in recent years. It is significant to assess the
vulnerability of such forensic detectors against adversarial attacks. In this
paper, we propose a new black-box attack method against GAN-generated image
detectors. A novel contrastive learning strategy is adopted to train the
encoder-decoder network based anti-forensic model under a contrastive loss
function. GAN images and their simulated real counterparts are constructed as
positive and negative samples, respectively. Leveraging on the trained attack
model, imperceptible contrastive perturbation could be applied to input
synthetic images for removing GAN fingerprint to some extent. As such, existing
GAN-generated image detectors are expected to be deceived. Extensive
experimental results verify that the proposed attack effectively reduces the
accuracy of three state-of-the-art detectors on six popular GANs. High visual
quality of the attacked images is also achieved. The source code will be
available at https://github.com/ZXMMD/BAttGAND.",https://github.com/ZXMMD/BAttGAND,-1
0dc3eae2-ce37-42d0-8df0-41ab3ef4170b,Non-iterative optimization of pseudo-labeling thresholds for training object detection models from multiple datasets,0.121445,"We propose a non-iterative method to optimize pseudo-labeling thresholds for
learning object detection from a collection of low-cost datasets, each of which
is annotated for only a subset of all the object classes. A popular approach to
this problem is first to train teacher models and then to use their confident
predictions as pseudo ground-truth labels when training a student model. To
obtain the best result, however, thresholds for prediction confidence must be
adjusted. This process typically involves iterative search and repeated
training of student models and is time-consuming. Therefore, we develop a
method to optimize the thresholds without iterative optimization by maximizing
the $F_\beta$-score on a validation dataset, which measures the quality of
pseudo labels and can be measured without training a student model. We
experimentally demonstrate that our proposed method achieves an mAP comparable
to that of grid search on the COCO and VOC datasets.",None,286
1359ecd2-1a7d-47ad-98d2-6809bc5ab8c7,Low-complexity CNNs for Acoustic Scene Classification,0.416972,"This paper presents a low-complexity framework for acoustic scene
classification (ASC). Most of the frameworks designed for ASC use convolutional
neural networks (CNNs) due to their learning ability and improved performance
compared to hand-engineered features. However, CNNs are resource hungry due to
their large size and high computational complexity. Therefore, CNNs are
difficult to deploy on resource constrained devices. This paper addresses the
problem of reducing the computational complexity and memory requirement in
CNNs. We propose a low-complexity CNN architecture, and apply pruning and
quantization to further reduce the parameters and memory. We then propose an
ensemble framework that combines various low-complexity CNNs to improve the
overall performance. An experimental evaluation of the proposed framework is
performed on the publicly available DCASE 2022 Task 1 that focuses on ASC. The
proposed ensemble framework has approximately 60K parameters, requires 19M
multiply-accumulate operations and improves the performance by approximately
2-4 percentage points compared to the DCASE 2022 Task 1 baseline network.",None,17789
8bc4e8fb-2964-4750-8318-5307fe3f1f05,D'ARTAGNAN: Counterfactual Video Generation,0.399764,"Causally-enabled machine learning frameworks could help clinicians to
identify the best course of treatments by answering counterfactual questions.
We explore this path for the case of echocardiograms by looking into the
variation of the Left Ventricle Ejection Fraction, the most essential clinical
metric gained from these examinations. We combine deep neural networks, twin
causal networks and generative adversarial methods for the first time to build
D'ARTAGNAN (Deep ARtificial Twin-Architecture GeNerAtive Networks), a novel
causal generative model. We demonstrate the soundness of our approach on a
synthetic dataset before applying it to cardiac ultrasound videos to answer the
question: ""What would this echocardiogram look like if the patient had a
different ejection fraction?"". To do so, we generate new ultrasound videos,
retaining the video style and anatomy of the original patient, while modifying
the Ejection Fraction conditioned on a given input. We achieve an SSIM score of
0.79 and an R2 score of 0.51 on the counterfactual videos. Code and models are
available at: https://github.com/HReynaud/dartagnan.",https://github.com/HReynaud/dartagnan,-1
cc67d048-b15b-4f21-9823-be64f4a3642d,One-Shot Adaptation of GAN in Just One CLIP,0.843755,"There are many recent research efforts to fine-tune a pre-trained generator
with a few target images to generate images of a novel domain. Unfortunately,
these methods often suffer from overfitting or under-fitting when fine-tuned
with a single target image. To address this, here we present a novel
single-shot GAN adaptation method through unified CLIP space manipulations.
Specifically, our model employs a two-step training strategy: reference image
search in the source generator using a CLIP-guided latent optimization,
followed by generator fine-tuning with a novel loss function that imposes CLIP
space consistency between the source and adapted generators. To further improve
the adapted model to produce spatially consistent samples with respect to the
source generator, we also propose contrastive regularization for patchwise
relationships in the CLIP space. Experimental results show that our model
generates diverse outputs with the target texture and outperforms the baseline
models both qualitatively and quantitatively. Furthermore, we show that our
CLIP space manipulation strategy allows more effective attribute editing.",https://github.com/cyclomon/OneshotCLIP,-1
c766c5f2-7a24-4f15-8e9c-c78fa806cc27,UViM: A Unified Modeling Approach for Vision with Learned Guiding Codes,0.635325,"We introduce UViM, a unified approach capable of modeling a wide range of
computer vision tasks. In contrast to previous models, UViM has the same
functional form for all tasks; it requires no task-specific modifications which
require extensive human expertise. The approach involves two components: (I) a
base model (feed-forward) which is trained to directly predict raw vision
outputs, guided by a learned discrete code and (II) a language model
(autoregressive) that is trained to generate the guiding code. These components
complement each other: the language model is well-suited to modeling structured
interdependent data, while the base model is efficient at dealing with
high-dimensional outputs. We demonstrate the effectiveness of UViM on three
diverse and challenging vision tasks: panoptic segmentation, depth prediction
and image colorization, where we achieve competitive and near state-of-the-art
results. Our experimental results suggest that UViM is a promising candidate
for a unified modeling approach in computer vision.",https://github.com/google-research/big_vision,-1
990cb83b-3d0d-4a6a-a1b5-004733ea81c4,Realistic Defocus Blur for Multiplane Computer-Generated Holography,0.778965,"This paper introduces a new multiplane CGH computation method to reconstruct
artefact-free high-quality holograms with natural-looking defocus blur. Our
method introduces a new targeting scheme and a new loss function. While the
targeting scheme accounts for defocused parts of the scene at each depth plane,
the new loss function analyzes focused and defocused parts separately in
reconstructed images. Our method support phase-only CGH calculations using
various iterative (e.g., Gerchberg-Saxton, Gradient Descent) and non-iterative
(e.g., Double Phase) CGH techniques. We achieve our best image quality using a
modified gradient descent-based optimization recipe where we introduce a
constraint inspired by the double phase method. We validate our method
experimentally using our proof-of-concept holographic display, comparing
various algorithms, including multi-depth scenes with sparse and dense
contents.",None,-1
e0dd337e-9e83-417c-bbf9-ea0462dba3fc,Does Corpus Quality Really Matter for Low-Resource Languages?,0.326311,"The vast majority of non-English corpora are derived from automatically
filtered versions of CommonCrawl. While prior work has identified major issues
on the quality of these datasets (Kreutzer et al., 2021), it is not clear how
this impacts downstream performance. Taking representation learning in Basque
as a case study, we explore tailored crawling (manually identifying and
scraping websites with high-quality content) as an alternative to filtering
CommonCrawl. Our new corpus, called EusCrawl, is similar in size to the Basque
portion of popular multilingual corpora like CC100 and mC4, yet it has a much
higher quality according to native annotators. For instance, 66% of documents
are rated as high-quality for EusCrawl, in contrast with <33% for both mC4 and
CC100. Nevertheless, we obtain similar results on downstream NLU tasks
regardless of the corpus used for pre-training. Our work suggests that NLU
performance in low-resource languages is not primarily constrained by the
quality of the data, and other factors like corpus size and domain coverage can
play a more important role.",None,-1
aacc175c-0477-4675-8f5b-99d5f0986e14,Learning-based Motion Planning in Dynamic Environments Using GNNs and Temporal Encoding,0.583777,"Learning-based methods have shown promising performance for accelerating
motion planning, but mostly in the setting of static environments. For the more
challenging problem of planning in dynamic environments, such as multi-arm
assembly tasks and human-robot interaction, motion planners need to consider
the trajectories of the dynamic obstacles and reason about temporal-spatial
interactions in very large state spaces. We propose a GNN-based approach that
uses temporal encoding and imitation learning with data aggregation for
learning both the embeddings and the edge prioritization policies. Experiments
show that the proposed methods can significantly accelerate online planning
over state-of-the-art complete dynamic planning algorithms. The learned models
can often reduce costly collision checking operations by more than 1000x, and
thus accelerating planning by up to 95%, while achieving high success rates on
hard instances as well.",None,-1
a0482eb6-22be-4dab-815b-bc1e382fd9d9,ARST: Auto-Regressive Surgical Transformer for Phase Recognition from Laparoscopic Videos,0.83607,"Phase recognition plays an essential role for surgical workflow analysis in
computer assisted intervention. Transformer, originally proposed for sequential
data modeling in natural language processing, has been successfully applied to
surgical phase recognition. Existing works based on transformer mainly focus on
modeling attention dependency, without introducing auto-regression. In this
work, an Auto-Regressive Surgical Transformer, referred as ARST, is first
proposed for on-line surgical phase recognition from laparoscopic videos,
modeling the inter-phase correlation implicitly by conditional probability
distribution. To reduce inference bias and to enhance phase consistency, we
further develop a consistency constraint inference strategy based on
auto-regression. We conduct comprehensive validations on a well-known public
dataset Cholec80. Experimental results show that our method outperforms the
state-of-the-art methods both quantitatively and qualitatively, and achieves an
inference rate of 66 frames per second (fps).",None,-1
ec598a52-b12d-4681-bcc3-8154cd0fbb41,MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning,0.914962,"Instruction tuning, a new learning paradigm that fine-tunes pre-trained
language models on tasks specified through instructions, has shown promising
zero-shot performance on various natural language processing tasks. However, it
has yet to be explored for vision and multimodal tasks. In this work, we
introduce MUL-TIINSTRUCT, the first multimodal instruction tuning benchmark
dataset that consists of 62 diverse multimodal tasks in a unified seq-to-seq
format covering 10 broad categories. The tasks are derived from 21 existing
open-source datasets and each task is equipped with 5 expert-written
instructions. We take OFA as the base pre-trained model for multimodal
instruction tuning, and to further improve its zero-shot performance, we
explore multiple transfer learning strategies to leverage the large-scale
NATURAL INSTRUCTIONS dataset. Experimental results demonstrate strong zero-shot
performance on various unseen multimodal tasks and the benefit of transfer
learning from a text-only instruction dataset. We also design a new evaluation
metric - Sensitivity, to evaluate how sensitive the model is to the variety of
instructions. Our results indicate that fine-tuning the model on a diverse set
of tasks and instructions leads to a reduced sensitivity to variations in
instructions for each task.",https://github.com/VT-NLP/MultiInstruct,-1
1d08830b-c52a-4fee-b824-3fee31e477de,Self-supervised models of audio effectively explain human cortical responses to speech,0.815524,"Self-supervised language models are very effective at predicting high-level
cortical responses during language comprehension. However, the best current
models of lower-level auditory processing in the human brain rely on either
hand-constructed acoustic filters or representations from supervised audio
neural networks. In this work, we capitalize on the progress of self-supervised
speech representation learning (SSL) to create new state-of-the-art models of
the human auditory system. Compared against acoustic baselines, phonemic
features, and supervised models, representations from the middle layers of
self-supervised models (APC, wav2vec, wav2vec 2.0, and HuBERT) consistently
yield the best prediction performance for fMRI recordings within the auditory
cortex (AC). Brain areas involved in low-level auditory processing exhibit a
preference for earlier SSL model layers, whereas higher-level semantic areas
prefer later layers. We show that these trends are due to the models' ability
to encode information at multiple linguistic levels (acoustic, phonetic, and
lexical) along their representation depth. Overall, these results show that
self-supervised models effectively capture the hierarchy of information
relevant to different stages of speech processing in human cortex.",None,589
ae00bdba-1f4a-4ad2-a757-17eb420d7dfe,A Robust Document Image Watermarking Scheme using Deep Neural Network,0.610994,"Watermarking is an important copyright protection technology which generally
embeds the identity information into the carrier imperceptibly. Then the
identity can be extracted to prove the copyright from the watermarked carrier
even after suffering various attacks. Most of the existing watermarking
technologies take the nature images as carriers. Different from the natural
images, document images are not so rich in color and texture, and thus have
less redundant information to carry watermarks. This paper proposes an
end-to-end document image watermarking scheme using the deep neural network.
Specifically, an encoder and a decoder are designed to embed and extract the
watermark. A noise layer is added to simulate the various attacks that could be
encountered in reality, such as the Cropout, Dropout, Gaussian blur, Gaussian
noise, Resize, and JPEG Compression. A text-sensitive loss function is designed
to limit the embedding modification on characters. An embedding strength
adjustment strategy is proposed to improve the quality of watermarked image
with little loss of extraction accuracy. Experimental results show that the
proposed document image watermarking technology outperforms three
state-of-the-arts in terms of the robustness and image quality.",https://github.com/gslxr/Document-image-watermarking,-1
17fd2c50-58a5-46c4-9d55-0fdafb74e285,"Modeling Intention, Emotion and External World in Dialogue Systems",0.183284,"Intention, emotion and action are important elements in human activities.
Modeling the interaction process between individuals by analyzing the
relationships between these elements is a challenging task. However, previous
work mainly focused on modeling intention and emotion independently, and
neglected of exploring the mutual relationships between intention and emotion.
In this paper, we propose a RelAtion Interaction Network (RAIN), consisting of
Intention Relation Module and Emotion Relation Module, to jointly model mutual
relationships and explicitly integrate historical intention information. The
experiments on the dataset show that our model can take full advantage of the
intention, emotion and action between individuals and achieve a remarkable
improvement over BERT-style baselines. Qualitative analysis verifies the
importance of the mutual interaction between the intention and emotion.",None,269
335af2ca-3df3-4db1-8a60-f20f3a93ec4c,Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments,0.167908,"We present a human-in-the-loop evaluation framework for fact-checking novel
misinformation claims and identifying social media messages that support them.
Our approach extracts check-worthy claims, which are aggregated and ranked for
review. Stance classifiers are then used to identify tweets supporting novel
misinformation claims, which are further reviewed to determine whether they
violate relevant policies. To demonstrate the feasibility of our approach, we
develop a baseline system based on modern NLP methods for human-in-the-loop
fact-checking in the domain of COVID-19 treatments. We make our data and
detailed annotation guidelines available to support the evaluation of
human-in-the-loop systems that identify novel misinformation directly from raw
user-generated content.",https://github.com/ethanm88/hitl-eva,-1
497e8fa4-9824-4e3c-b1d7-21ae4c071412,MEAT: Maneuver Extraction from Agent Trajectories,0.0861104,"Advances in learning-based trajectory prediction are enabled by large-scale
datasets. However, in-depth analysis of such datasets is limited. Moreover, the
evaluation of prediction models is limited to metrics averaged over all samples
in the dataset. We propose an automated methodology that allows to extract
maneuvers (e.g., left turn, lane change) from agent trajectories in such
datasets. The methodology considers information about the agent dynamics and
information about the lane segments the agent traveled along. Although it is
possible to use the resulting maneuvers for training classification networks,
we exemplary use them for extensive trajectory dataset analysis and
maneuver-specific evaluation of multiple state-of-the-art trajectory prediction
models. Additionally, an analysis of the datasets and an evaluation of the
prediction models based on the agent dynamics is provided.",None,-1
534861c6-792c-430b-9d78-7c79460473d9,Shallow camera pipeline for night photography rendering,0.229337,"We introduce a camera pipeline for rendering visually pleasing photographs in
low light conditions, as part of the NTIRE2022 Night Photography Rendering
challenge. Given the nature of the task, where the objective is verbally
defined by an expert photographer instead of relying on explicit ground truth
images, we design an handcrafted solution, characterized by a shallow structure
and by a low parameter count. Our pipeline exploits a local light enhancer as a
form of high dynamic range correction, followed by a global adjustment of the
image histogram to prevent washed-out results. We proportionally apply image
denoising to darker regions, where it is more easily perceived, without losing
details on brighter regions. The solution reached the fifth place in the
competition, with a preference vote count comparable to those of other entries,
based on deep convolutional neural networks. Code is available at
www.github.com/AvailableAfterAcceptance.",https://github.com/AvailableAfterAcceptance,-1
56d2d4d5-7a86-4f2f-9140-57958f51959c,DeepCuts: Single-Shot Interpretability based Pruning for BERT,0.0838694,"As language models have grown in parameters and layers, it has become much
harder to train and infer with them on single GPUs. This is severely
restricting the availability of large language models such as GPT-3,
BERT-Large, and many others. A common technique to solve this problem is
pruning the network architecture by removing transformer heads, fully-connected
weights, and other modules. The main challenge is to discern the important
parameters from the less important ones. Our goal is to find strong metrics for
identifying such parameters. We thus propose two strategies: Cam-Cut based on
the GradCAM interpretations, and Smooth-Cut based on the SmoothGrad, for
calculating the importance scores. Through this work, we show that our scoring
functions are able to assign more relevant task-based scores to the network
parameters, and thus both our pruning approaches significantly outperform the
standard weight and gradient-based strategies, especially at higher compression
ratios in BERT-based models. We also analyze our pruning masks and find them to
be significantly different from the ones obtained using standard metrics.",https://github.com/RuskinMan/DeepCuts,-1
7edd5795-3e60-44a8-938d-b54f9b766e9b,Asking for Knowledge: Training RL Agents to Query External Knowledge Using Language,0.544912,"To solve difficult tasks, humans ask questions to acquire knowledge from
external sources. In contrast, classical reinforcement learning agents lack
such an ability and often resort to exploratory behavior. This is exacerbated
as few present-day environments support querying for knowledge. In order to
study how agents can be taught to query external knowledge via language, we
first introduce two new environments: the grid-world-based Q-BabyAI and the
text-based Q-TextWorld. In addition to physical interactions, an agent can
query an external knowledge source specialized for these environments to gather
information. Second, we propose the ""Asking for Knowledge"" (AFK) agent, which
learns to generate language commands to query for meaningful knowledge that
helps solve the tasks. AFK leverages a non-parametric memory, a pointer
mechanism and an episodic exploration bonus to tackle (1) irrelevant
information, (2) a large query language space, (3) delayed reward for making
meaningful queries. Extensive experiments demonstrate that the AFK agent
outperforms recent baselines on the challenging Q-BabyAI and Q-TextWorld
environments.",https://ioujenliu.github.io/AFK,-1
2ee82528-d7b7-43bd-973b-1599c1bcb24d,Masked Face Inpainting Through Residual Attention UNet,0.147111,"Realistic image restoration with high texture areas such as removing face
masks is challenging. The state-of-the-art deep learning-based methods fail to
guarantee high-fidelity, cause training instability due to vanishing gradient
problems (e.g., weights are updated slightly in initial layers) and spatial
information loss. They also depend on intermediary stage such as segmentation
meaning require external mask. This paper proposes a blind mask face inpainting
method using residual attention UNet to remove the face mask and restore the
face with fine details while minimizing the gap with the ground truth face
structure. A residual block feeds info to the next layer and directly into the
layers about two hops away to solve the gradient vanishing problem. Besides,
the attention unit helps the model focus on the relevant mask region, reducing
resources and making the model faster. Extensive experiments on the publicly
available CelebA dataset show the feasibility and robustness of our proposed
model. Code is available at
\url{https://github.com/mdhosen/Mask-Face-Inpainting-Using-Residual-Attention-Unet}",https://github.com/mdhosen/Mask-Face-Inpainting-Using-Residual-Attention-Unet,-1
e2ca0e4f-93be-4052-bf46-44abb4449d53,PTDE: Personalized Training with Distilled Execution for Multi-Agent Reinforcement Learning,0.418804,"Centralized Training with Decentralized Execution (CTDE) has emerged as a
widely adopted paradigm in multi-agent reinforcement learning, emphasizing the
utilization of global information for learning an enhanced joint $Q$-function
or centralized critic. In contrast, our investigation delves into harnessing
global information to directly enhance individual $Q$-functions or individual
actors. Notably, we discover that applying identical global information
universally across all agents proves insufficient for optimal performance.
Consequently, we advocate for the customization of global information tailored
to each agent, creating agent-personalized global information to bolster
overall performance. Furthermore, we introduce a novel paradigm named
Personalized Training with Distilled Execution (PTDE), wherein
agent-personalized global information is distilled into the agent's local
information. This distilled information is then utilized during decentralized
execution, resulting in minimal performance degradation. PTDE can be seamlessly
integrated with state-of-the-art algorithms, leading to notable performance
enhancements across diverse benchmarks, including the SMAC benchmark, Google
Research Football (GRF) benchmark, and Learning to Rank (LTR) task.",None,-1
e91d147c-d3b1-4cd7-aea8-f8d84f54a2a8,Locate Then Ask: Interpretable Stepwise Reasoning for Multi-hop Question Answering,0.321883,"Multi-hop reasoning requires aggregating multiple documents to answer a
complex question. Existing methods usually decompose the multi-hop question
into simpler single-hop questions to solve the problem for illustrating the
explainable reasoning process. However, they ignore grounding on the supporting
facts of each reasoning step, which tends to generate inaccurate
decompositions. In this paper, we propose an interpretable stepwise reasoning
framework to incorporate both single-hop supporting sentence identification and
single-hop question generation at each intermediate step, and utilize the
inference of the current hop for the next until reasoning out the final result.
We employ a unified reader model for both intermediate hop reasoning and final
hop inference and adopt joint optimization for more accurate and robust
multi-hop reasoning. We conduct experiments on two benchmark datasets HotpotQA
and 2WikiMultiHopQA. The results show that our method can effectively boost
performance and also yields a better interpretable reasoning process without
decomposition supervision.",https://github.com/WangsyGit/StepwiseQA,-1
4122cc56-2b20-406f-9128-8b1d8643ab0c,Model Cascading: Towards Jointly Improving Efficiency and Accuracy of NLP Systems,0.80854,"Do all instances need inference through the big models for a correct
prediction? Perhaps not; some instances are easy and can be answered correctly
by even small capacity models. This provides opportunities for improving the
computational efficiency of systems. In this work, we present an explorative
study on 'model cascading', a simple technique that utilizes a collection of
models of varying capacities to accurately yet efficiently output predictions.
Through comprehensive experiments in multiple task settings that differ in the
number of models available for cascading (K value), we show that cascading
improves both the computational efficiency and the prediction accuracy. For
instance, in K=3 setting, cascading saves up to 88.93% computation cost and
consistently achieves superior prediction accuracy with an improvement of up to
2.18%. We also study the impact of introducing additional models in the cascade
and show that it further increases the efficiency improvements. Finally, we
hope that our work will facilitate development of efficient NLP systems making
their widespread adoption in real-world applications possible.",None,-1
fbd4d746-6cd7-4169-9cff-9d6f93e7d13d,Stanceosaurus: Classifying Stance Towards Multilingual Misinformation,0.100892,"We present Stanceosaurus, a new corpus of 28,033 tweets in English, Hindi,
and Arabic annotated with stance towards 251 misinformation claims. As far as
we are aware, it is the largest corpus annotated with stance towards
misinformation claims. The claims in Stanceosaurus originate from 15
fact-checking sources that cover diverse geographical regions and cultures.
Unlike existing stance datasets, we introduce a more fine-grained 5-class
labeling strategy with additional subcategories to distinguish implicit stance.
Pre-trained transformer-based stance classifiers that are fine-tuned on our
corpus show good generalization on unseen claims and regional claims from
countries outside the training data. Cross-lingual experiments demonstrate
Stanceosaurus' capability of training multi-lingual models, achieving 53.1 F1
on Hindi and 50.4 F1 on Arabic without any target-language fine-tuning.
Finally, we show how a domain adaptation method can be used to improve
performance on Stanceosaurus using additional RumourEval-2019 data. We make
Stanceosaurus publicly available to the research community and hope it will
encourage further work on misinformation identification across languages and
cultures.",https://tinyurl.com/stanceosaurus,-1
428e40b0-fe67-4c7e-81f1-ab27b3500df2,Towards Unified Conversational Recommender Systems via Knowledge-Enhanced Prompt Learning,0.995101,"Conversational recommender systems (CRS) aim to proactively elicit user
preference and recommend high-quality items through natural language
conversations. Typically, a CRS consists of a recommendation module to predict
preferred items for users and a conversation module to generate appropriate
responses. To develop an effective CRS, it is essential to seamlessly integrate
the two modules. Existing works either design semantic alignment strategies, or
share knowledge resources and representations between the two modules. However,
these approaches still rely on different architectures or techniques to develop
the two modules, making it difficult for effective module integration.
  To address this problem, we propose a unified CRS model named UniCRS based on
knowledge-enhanced prompt learning. Our approach unifies the recommendation and
conversation subtasks into the prompt learning paradigm, and utilizes
knowledge-enhanced prompts based on a fixed pre-trained language model (PLM) to
fulfill both subtasks in a unified approach. In the prompt design, we include
fused knowledge representations, task-specific soft tokens, and the dialogue
context, which can provide sufficient contextual information to adapt the PLM
for the CRS task. Besides, for the recommendation subtask, we also incorporate
the generated response template as an important part of the prompt, to enhance
the information interaction between the two subtasks. Extensive experiments on
two public CRS datasets have demonstrated the effectiveness of our approach.",https://github.com/RUCAIBox/UniCRS,-1
3a3c5ab7-cb7c-4bdb-92e1-2fbcdaa2d63b,Analysis of Branch Specialization and its Application in Image Decomposition,0.101771,"Branched neural networks have been used extensively for a variety of tasks.
Branches are sub-parts of the model that perform independent processing
followed by aggregation. It is known that this setting induces a phenomenon
called Branch Specialization, where different branches become experts in
different sub-tasks. Such observations were qualitative by nature. In this
work, we present a methodological analysis of Branch Specialization. We explain
the role of gradient descent in this phenomenon. We show that branched
generative networks naturally decompose animal images to meaningful channels of
fur, whiskers and spots and face images to channels such as different
illumination components and face parts.",https://github.com/clovaai/stargan-v2,-1
a1702cce-fe28-432a-ac04-3fbd5881ee75,Sequential Causal Imitation Learning with Unobserved Confounders,0.903047,"""Monkey see monkey do"" is an age-old adage, referring to na\""ive imitation
without a deep understanding of a system's underlying mechanics. Indeed, if a
demonstrator has access to information unavailable to the imitator (monkey),
such as a different set of sensors, then no matter how perfectly the imitator
models its perceived environment (See), attempting to reproduce the
demonstrator's behavior (Do) can lead to poor outcomes. Imitation learning in
the presence of a mismatch between demonstrator and imitator has been studied
in the literature under the rubric of causal imitation learning (Zhang et al.,
2020), but existing solutions are limited to single-stage decision-making. This
paper investigates the problem of causal imitation learning in sequential
settings, where the imitator must make multiple decisions per episode. We
develop a graphical criterion that is necessary and sufficient for determining
the feasibility of causal imitation, providing conditions when an imitator can
match a demonstrator's performance despite differing capabilities. Finally, we
provide an efficient algorithm for determining imitability and corroborate our
theory with simulations.",None,-1
527e5409-1439-4890-9dc2-20d61bff6dd0,Content Popularity Prediction in Fog-RANs: A Clustered Federated Learning Based Approach,0.0214667,"In this paper, the content popularity prediction problem in fog radio access
networks (F-RANs) is investigated. Based on clustered federated learning, we
propose a novel mobility-aware popularity prediction policy, which integrates
content popularities in terms of local users and mobile users. For local users,
the content popularity is predicted by learning the hidden representations of
local users and contents. Initial features of local users and contents are
generated by incorporating neighbor information with self information. Then,
dual-channel neural network (DCNN) model is introduced to learn the hidden
representations by producing deep latent features from initial features. For
mobile users, the content popularity is predicted via user preference learning.
In order to distinguish regional variations of content popularity, clustered
federated learning (CFL) is employed, which enables fog access points (F-APs)
with similar regional types to benefit from one another and provides a more
specialized DCNN model for each F-AP. Simulation results show that our proposed
policy achieves significant performance improvement over the traditional
policies.",None,-1
77cc5721-97a0-489b-ab52-f76bb70507b1,Emergent Communication through Metropolis-Hastings Naming Game with Deep Generative Models,0.880075,"Constructive studies on symbol emergence systems seek to investigate
computational models that can better explain human language evolution, the
creation of symbol systems, and the construction of internal representations.
This study provides a new model for emergent communication, which is based on a
probabilistic generative model (PGM) instead of a discriminative model based on
deep reinforcement learning. We define the Metropolis-Hastings (MH) naming game
by generalizing previously proposed models. It is not a referential game with
explicit feedback, as assumed by many emergent communication studies. Instead,
it is a game based on joint attention without explicit feedback.
Mathematically, the MH naming game is proved to be a type of MH algorithm for
an integrative PGM that combines two agents that play the naming game. From
this viewpoint, symbol emergence is regarded as decentralized Bayesian
inference, and semiotic communication is regarded as inter-personal cross-modal
inference. This notion leads to the collective predictive coding hypothesis}
regarding language evolution and, in general, the emergence of symbols. We also
propose the inter-Gaussian mixture model (GMM)+ variational autoencoder (VAE),
a deep generative model for emergent communication based on the MH naming game.
The model has been validated on MNIST and Fruits 360 datasets. Experimental
findings demonstrate that categories are formed from real images observed by
agents, and signs are correctly shared across agents by successfully utilizing
both of the observations of agents via the MH naming game. Furthermore,
scholars verified that visual images were recalled from signs uttered by
agents. Notably, emergent communication without supervision and reward feedback
improved the performance of the unsupervised representation learning of agents.",https://github.com/is0383kk/SymbolEmergence-VAE-GMM,-1
2a76fdc4-c303-4302-9f35-f7acf9329249,Enhancing Deformable Convolution based Video Frame Interpolation with Coarse-to-fine 3D CNN,0.35693,"This paper presents a new deformable convolution-based video frame
interpolation (VFI) method, using a coarse to fine 3D CNN to enhance the
multi-flow prediction. This model first extracts spatio-temporal features at
multiple scales using a 3D CNN, and estimates multi-flows using these features
in a coarse-to-fine manner. The estimated multi-flows are then used to warp the
original input frames as well as context maps, and the warped results are fused
by a synthesis network to produce the final output. This VFI approach has been
fully evaluated against 12 state-of-the-art VFI methods on three commonly used
test databases. The results evidently show the effectiveness of the proposed
method, which offers superior interpolation performance over other state of the
art algorithms, with PSNR gains up to 0.19dB.",https://danier97.github.io/EDC,5466
4e177044-70d7-4389-942f-3287c7488268,polyBERT: A chemical language model to enable fully machine-driven ultrafast polymer informatics,0.979912,"Polymers are a vital part of everyday life. Their chemical universe is so
large that it presents unprecedented opportunities as well as significant
challenges to identify suitable application-specific candidates. We present a
complete end-to-end machine-driven polymer informatics pipeline that can search
this space for suitable candidates at unprecedented speed and accuracy. This
pipeline includes a polymer chemical fingerprinting capability called polyBERT
(inspired by Natural Language Processing concepts), and a multitask learning
approach that maps the polyBERT fingerprints to a host of properties. polyBERT
is a chemical linguist that treats the chemical structure of polymers as a
chemical language. The present approach outstrips the best presently available
concepts for polymer property prediction based on handcrafted fingerprint
schemes in speed by two orders of magnitude while preserving accuracy, thus
making it a strong candidate for deployment in scalable architectures including
cloud infrastructures.",https://github.com/Ramprasad-Group/polyBERT,-1
d90b3ae3-acbe-4aaf-b661-ab97604ef184,Learning Smooth Neural Functions via Lipschitz Regularization,0.879769,"Neural implicit fields have recently emerged as a useful representation for
3D shapes. These fields are commonly represented as neural networks which map
latent descriptors and 3D coordinates to implicit function values. The latent
descriptor of a neural field acts as a deformation handle for the 3D shape it
represents. Thus, smoothness with respect to this descriptor is paramount for
performing shape-editing operations. In this work, we introduce a novel
regularization designed to encourage smooth latent spaces in neural fields by
penalizing the upper bound on the field's Lipschitz constant. Compared with
prior Lipschitz regularized networks, ours is computationally fast, can be
implemented in four lines of code, and requires minimal hyperparameter tuning
for geometric applications. We demonstrate the effectiveness of our approach on
shape interpolation and extrapolation as well as partial shape reconstruction
from 3D point clouds, showing both qualitative and quantitative improvements
over existing state-of-the-art and non-regularized baselines.",http://github.com/google/jax,-1
9be62ad6-72b8-4f90-b1ce-e5171258f7c6,Robust Contrastive Learning against Noisy Views,0.566712,"Contrastive learning relies on an assumption that positive pairs contain
related views, e.g., patches of an image or co-occurring multimodal signals of
a video, that share certain underlying information about an instance. But what
if this assumption is violated? The literature suggests that contrastive
learning produces suboptimal representations in the presence of noisy views,
e.g., false positive pairs with no apparent shared information. In this work,
we propose a new contrastive loss function that is robust against noisy views.
We provide rigorous theoretical justifications by showing connections to robust
symmetric losses for noisy binary classification and by establishing a new
contrastive bound for mutual information maximization based on the Wasserstein
distance measure. The proposed loss is completely modality-agnostic and a
simple drop-in replacement for the InfoNCE loss, which makes it easy to apply
to existing contrastive frameworks. We show that our approach provides
consistent improvements over the state-of-the-art on image, video, and graph
contrastive learning benchmarks that exhibit a variety of real-world noise
patterns.",https://github.com/chingyaoc/RINCE,-1
5e067623-0d6f-4daf-878e-79496652c3d4,Retrieve-and-Fill for Scenario-based Task-Oriented Semantic Parsing,0.349869,"Task-oriented semantic parsing models have achieved strong results in recent
years, but unfortunately do not strike an appealing balance between model size,
runtime latency, and cross-domain generalizability. We tackle this problem by
introducing scenario-based semantic parsing: a variant of the original task
which first requires disambiguating an utterance's ""scenario"" (an intent-slot
template with variable leaf spans) before generating its frame, complete with
ontology and utterance tokens. This formulation enables us to isolate
coarse-grained and fine-grained aspects of the task, each of which we solve
with off-the-shelf neural modules, also optimizing for the axes outlined above.
Concretely, we create a Retrieve-and-Fill (RAF) architecture comprised of (1) a
retrieval module which ranks the best scenario given an utterance and (2) a
filling module which imputes spans into the scenario to create the frame. Our
model is modular, differentiable, interpretable, and allows us to garner extra
supervision from scenarios. RAF achieves strong results in high-resource,
low-resource, and multilingual settings, outperforming recent approaches by
wide margins despite, using base pre-trained encoders, small sequence lengths,
and parallel decoding.",None,-1
64bcf43c-ac0e-4920-89c8-587e294e10e5,Multiview Stereo with Cascaded Epipolar RAFT,0.877271,"We address multiview stereo (MVS), an important 3D vision task that
reconstructs a 3D model such as a dense point cloud from multiple calibrated
images. We propose CER-MVS (Cascaded Epipolar RAFT Multiview Stereo), a new
approach based on the RAFT (Recurrent All-Pairs Field Transforms) architecture
developed for optical flow. CER-MVS introduces five new changes to RAFT:
epipolar cost volumes, cost volume cascading, multiview fusion of cost volumes,
dynamic supervision, and multiresolution fusion of depth maps. CER-MVS is
significantly different from prior work in multiview stereo. Unlike prior work,
which operates by updating a 3D cost volume, CER-MVS operates by updating a
disparity field. Furthermore, we propose an adaptive thresholding method to
balance the completeness and accuracy of the reconstructed point clouds.
Experiments show that our approach achieves competitive performance on DTU (the
second best among known results) and state-of-the-art performance on the
Tanks-and-Temples benchmark (both the intermediate and advanced set). Code is
available at https://github.com/princeton-vl/CER-MVS",https://github.com/princeton-vl/CER-MVS,-1
e275bc30-ba16-4951-9727-7f1621fa5a5a,A Cooperation Graph Approach for Multiagent Sparse Reward Reinforcement Learning,0.237448,"Multiagent reinforcement learning (MARL) can solve complex cooperative tasks.
However, the efficiency of existing MARL methods relies heavily on well-defined
reward functions. Multiagent tasks with sparse reward feedback are especially
challenging not only because of the credit distribution problem, but also due
to the low probability of obtaining positive reward feedback. In this paper, we
design a graph network called Cooperation Graph (CG). The Cooperation Graph is
the combination of two simple bipartite graphs, namely, the Agent Clustering
subgraph (ACG) and the Cluster Designating subgraph (CDG). Next, based on this
novel graph structure, we propose a Cooperation Graph Multiagent Reinforcement
Learning (CG-MARL) algorithm, which can efficiently deal with the sparse reward
problem in multiagent tasks. In CG-MARL, agents are directly controlled by the
Cooperation Graph. And a policy neural network is trained to manipulate this
Cooperation Graph, guiding agents to achieve cooperation in an implicit way.
This hierarchical feature of CG-MARL provides space for customized
cluster-actions, an extensible interface for introducing fundamental
cooperation knowledge. In experiments, CG-MARL shows state-of-the-art
performance in sparse reward multiagent benchmarks, including the anti-invasion
interception task and the multi-cargo delivery task.",https://github.com/binary-husky/hmp2g,-1
66c0eee0-1755-464d-a84d-f231dc08f257,Dataless Knowledge Fusion by Merging Weights of Language Models,0.991309,"Fine-tuning pre-trained language models has become the prevalent paradigm for
building downstream NLP models. Oftentimes fine-tuned models are readily
available but their training data is not, due to data privacy or intellectual
property concerns. This creates a barrier to fusing knowledge across individual
models to yield a better single model. In this paper, we study the problem of
merging individual models built on different training data sets to obtain a
single model that performs well both across all data set domains and can
generalize on out-of-domain data. We propose a dataless knowledge fusion method
that merges models in their parameter space, guided by weights that minimize
prediction differences between the merged model and the individual models. Over
a battery of evaluation settings, we show that the proposed method
significantly outperforms baselines such as Fisher-weighted averaging or model
ensembling. Further, we find that our method is a promising alternative to
multi-task learning that can preserve or sometimes improve over the individual
models without access to the training data. Finally, model merging is more
efficient than training a multi-task model, thus making it applicable to a
wider set of scenarios.",https://github.com/bloomberg/dataless-model-merging,-1
77c5684a-610e-4e81-be65-56d30eef7ffa,Luminance-Guided Chrominance Image Enhancement for HEVC Intra Coding,0.0439739,"In this paper, we propose a luminance-guided chrominance image enhancement
convolutional neural network for HEVC intra coding. Specifically, we firstly
develop a gated recursive asymmetric-convolution block to restore each degraded
chrominance image, which generates an intermediate output. Then, guided by the
luminance image, the quality of this intermediate output is further improved,
which finally produces the high-quality chrominance image. When our proposed
method is adopted in the compression of color images with HEVC intra coding, it
achieves 28.96% and 16.74% BD-rate gains over HEVC for the U and V images,
respectively, which accordingly demonstrate its superiority.",https://github.com/Nickyang4900/Luminance-Guided-Chrominance-Enhancement-for-HEVC-Intra-Coding,-1
6492a1b1-fb63-42b5-8b1e-0af186c54570,Mono vs Multilingual BERT: A Case Study in Hindi and Marathi Named Entity Recognition,0.608526,"Named entity recognition (NER) is the process of recognising and classifying
important information (entities) in text. Proper nouns, such as a person's
name, an organization's name, or a location's name, are examples of entities.
The NER is one of the important modules in applications like human resources,
customer support, search engines, content classification, and academia. In this
work, we consider NER for low-resource Indian languages like Hindi and Marathi.
The transformer-based models have been widely used for NER tasks. We consider
different variations of BERT like base-BERT, RoBERTa, and AlBERT and benchmark
them on publicly available Hindi and Marathi NER datasets. We provide an
exhaustive comparison of different monolingual and multilingual
transformer-based models and establish simple baselines currently missing in
the literature. We show that the monolingual MahaRoBERTa model performs the
best for Marathi NER whereas the multilingual XLM-RoBERTa performs the best for
Hindi NER. We also perform cross-language evaluation and present mixed
observations.",None,-1
86fd0831-593a-430e-85b0-edc70b3270bc,Dynamic Dialogue Policy for Continual Reinforcement Learning,0.7011,"Continual learning is one of the key components of human learning and a
necessary requirement of artificial intelligence. As dialogue can potentially
span infinitely many topics and tasks, a task-oriented dialogue system must
have the capability to continually learn, dynamically adapting to new
challenges while preserving the knowledge it already acquired. Despite the
importance, continual reinforcement learning of the dialogue policy has
remained largely unaddressed. The lack of a framework with training protocols,
baseline models and suitable metrics, has so far hindered research in this
direction. In this work we fill precisely this gap, enabling research in
dialogue policy optimisation to go from static to dynamic learning. We provide
a continual learning algorithm, baseline architectures and metrics for
assessing continual learning models. Moreover, we propose the dynamic dialogue
policy transformer (DDPT), a novel dynamic architecture that can integrate new
knowledge seamlessly, is capable of handling large state spaces and obtains
significant zero-shot performance when being exposed to unseen domains, without
any growth in network parameter size.",None,-1
6fdab619-fdc6-4a57-81d3-df329b7279e4,Otsu based Differential Evolution Method for Image Segmentation,0.0281449,"This paper proposes an OTSU based differential evolution method for satellite
image segmentation and compares it with four other methods such as Modified
Artificial Bee Colony Optimizer (MABC), Artificial Bee Colony (ABC), Genetic
Algorithm (GA), and Particle Swarm Optimization (PSO) using the objective
function proposed by Otsu for optimal multilevel thresholding. The experiments
conducted and their results illustrate that our proposed DE and OTSU algorithm
segmentation can effectively and precisely segment the input image, close to
results obtained by the other methods. In the proposed DE and OTSU algorithm,
instead of passing the fitness function variables, the entire image is passed
as an input to the DE algorithm after obtaining the threshold values for the
input number of levels in the OTSU algorithm. The image segmentation results
are obtained after learning about the image instead of learning about the
fitness variables. In comparison to other segmentation methods examined, the
proposed DE and OTSU algorithm yields promising results with minimized
computational time compared to some algorithms.",None,-1
3eaa0c02-47ae-4d90-9aa7-e234393b6817,Identifying Electrocardiogram Abnormalities Using a Handcrafted-Rule-Enhanced Neural Network,0.132401,"A large number of people suffer from life-threatening cardiac abnormalities,
and electrocardiogram (ECG) analysis is beneficial to determining whether an
individual is at risk of such abnormalities. Automatic ECG classification
methods, especially the deep learning based ones, have been proposed to detect
cardiac abnormalities using ECG records, showing good potential to improve
clinical diagnosis and help early prevention of cardiovascular diseases.
However, the predictions of the known neural networks still do not
satisfactorily meet the needs of clinicians, and this phenomenon suggests that
some information used in clinical diagnosis may not be well captured and
utilized by these methods. In this paper, we introduce some rules into
convolutional neural networks, which help present clinical knowledge to deep
learning based ECG analysis, in order to improve automated ECG diagnosis
performance. Specifically, we propose a Handcrafted-Rule-enhanced Neural
Network (called HRNN) for ECG classification with standard 12-lead ECG input,
which consists of a rule inference module and a deep learning module.
Experiments on two large-scale public ECG datasets show that our new approach
considerably outperforms existing state-of-the-art methods. Further, our
proposed approach not only can improve the diagnosis performance, but also can
assist in detecting mislabelled ECG samples. Our codes are available at
https://github.com/alwaysbyx/ecg_processing.",https://github.com/alwaysbyx/ecg processing/,10744
93ef2775-d407-4697-88e1-de7e95a4abf2,SensatUrban: Learning Semantics from Urban-Scale Photogrammetric Point Clouds,0.818192,"With the recent availability and affordability of commercial depth sensors
and 3D scanners, an increasing number of 3D (i.e., RGBD, point cloud) datasets
have been publicized to facilitate research in 3D computer vision. However,
existing datasets either cover relatively small areas or have limited semantic
annotations. Fine-grained understanding of urban-scale 3D scenes is still in
its infancy. In this paper, we introduce SensatUrban, an urban-scale UAV
photogrammetry point cloud dataset consisting of nearly three billion points
collected from three UK cities, covering 7.6 km^2. Each point in the dataset
has been labelled with fine-grained semantic annotations, resulting in a
dataset that is three times the size of the previous existing largest
photogrammetric point cloud dataset. In addition to the more commonly
encountered categories such as road and vegetation, urban-level categories
including rail, bridge, and river are also included in our dataset. Based on
this dataset, we further build a benchmark to evaluate the performance of
state-of-the-art segmentation algorithms. In particular, we provide a
comprehensive analysis and identify several key challenges limiting urban-scale
point cloud understanding. The dataset is available at
http://point-cloud-analysis.cs.ox.ac.uk.",None,-1
55e7f9c0-c3b4-4dda-82d8-bad6a929cd1f,Abstraction not Memory: BERT and the English Article System,0.236813,"Article prediction is a task that has long defied accurate linguistic
description. As such, this task is ideally suited to evaluate models on their
ability to emulate native-speaker intuition. To this end, we compare the
performance of native English speakers and pre-trained models on the task of
article prediction set up as a three way choice (a/an, the, zero). Our
experiments with BERT show that BERT outperforms humans on this task across all
articles. In particular, BERT is far superior to humans at detecting the zero
article, possibly because we insert them using rules that the deep neural model
can easily pick up. More interestingly, we find that BERT tends to agree more
with annotators than with the corpus when inter-annotator agreement is high but
switches to agreeing more with the corpus as inter-annotator agreement drops.
We contend that this alignment with annotators, despite being trained on the
corpus, suggests that BERT is not memorising article use, but captures a high
level generalisation of article use akin to human intuition.",https://github.com/H-TayyarMadabushi/Abstraction-not-Memory-BERT-and-the-English-Article-System-NAACL-2022,-1
48421967-1e08-4b79-ad8c-0b215eabf889,SpeechCLIP: Integrating Speech with Pre-Trained Vision and Language Model,0.677774,"Data-driven speech processing models usually perform well with a large amount
of text supervision, but collecting transcribed speech data is costly.
Therefore, we propose SpeechCLIP, a novel framework bridging speech and text
through images to enhance speech models without transcriptions. We leverage
state-of-the-art pre-trained HuBERT and CLIP, aligning them via paired images
and spoken captions with minimal fine-tuning. SpeechCLIP outperforms prior
state-of-the-art on image-speech retrieval and performs zero-shot speech-text
retrieval without direct supervision from transcriptions. Moreover, SpeechCLIP
can directly retrieve semantically related keywords from speech.",https://github.com/atosystem/SpeechCLIP,-1
f33dcd74-f508-4a2c-b7bf-d85f20d76408,"Homomorphisms Between Transfer, Multi-Task, and Meta-Learning Systems",0.889802,"Transfer learning, multi-task learning, and meta-learning are well-studied
topics concerned with the generalization of knowledge across learning tasks and
are closely related to general intelligence. But, the formal, general systems
differences between them are underexplored in the literature. This lack of
systems-level formalism leads to difficulties in coordinating related,
inter-disciplinary engineering efforts. This manuscript formalizes transfer
learning, multi-task learning, and meta-learning as abstract learning systems,
consistent with the formal-minimalist abstract systems theory of Mesarovic and
Takahara. Moreover, it uses the presented formalism to relate the three
concepts of learning in terms of composition, hierarchy, and structural
homomorphism. Findings are readily depicted in terms of input-output systems,
highlighting the ease of delineating formal, general systems differences
between transfer, multi-task, and meta-learning.",None,-1
10c6600d-c901-4b4a-b183-5bf25b75646c,CommonsenseQA 2.0: Exposing the Limits of AI through Gamification,0.933969,"Constructing benchmarks that test the abilities of modern natural language
understanding models is difficult - pre-trained language models exploit
artifacts in benchmarks to achieve human parity, but still fail on adversarial
examples and make errors that demonstrate a lack of common sense. In this work,
we propose gamification as a framework for data construction. The goal of
players in the game is to compose questions that mislead a rival AI while using
specific phrases for extra points. The game environment leads to enhanced user
engagement and simultaneously gives the game designer control over the
collected data, allowing us to collect high-quality data at scale. Using our
method we create CommonsenseQA 2.0, which includes 14,343 yes/no questions, and
demonstrate its difficulty for models that are orders-of-magnitude larger than
the AI used in the game itself. Our best baseline, the T5-based Unicorn with
11B parameters achieves an accuracy of 70.2%, substantially higher than GPT-3
(52.9%) in a few-shot inference setup. Both score well below human performance
which is at 94.1%.",https://github.com/allenai/twentyquestions,46374
a358b8e0-5685-43ec-ab1c-462d36d51d24,Optimizing Elimination Templates by Greedy Parameter Search,0.522688,"We propose a new method for constructing elimination templates for efficient
polynomial system solving of minimal problems in structure from motion, image
matching, and camera tracking. We first construct a particular affine
parameterization of the elimination templates for systems with a finite number
of distinct solutions. Then, we use a heuristic greedy optimization strategy
over the space of parameters to get a template with a small size. We test our
method on 34 minimal problems in computer vision. For all of them, we found the
templates either of the same or smaller size compared to the state-of-the-art.
For some difficult examples, our templates are, e.g., 2.1, 2.5, 3.8, 6.6 times
smaller. For the problem of refractive absolute pose estimation with unknown
focal length, we have found a template that is 20 times smaller. Our
experiments on synthetic data also show that the new solvers are fast and
numerically accurate. We also present a fast and numerically accurate solver
for the problem of relative pose estimation with unknown common focal length
and radial distortion.",http://github.com/martyushev/EliminationTemplates,-1
6a40dbe8-51d6-4c13-b4f1-128c637196cb,Efficient Feature Extraction for High-resolution Video Frame Interpolation,0.227575,"Most deep learning methods for video frame interpolation consist of three
main components: feature extraction, motion estimation, and image synthesis.
Existing approaches are mainly distinguishable in terms of how these modules
are designed. However, when interpolating high-resolution images, e.g. at 4K,
the design choices for achieving high accuracy within reasonable memory
requirements are limited. The feature extraction layers help to compress the
input and extract relevant information for the latter stages, such as motion
estimation. However, these layers are often costly in parameters, computation
time, and memory. We show how ideas from dimensionality reduction combined with
a lightweight optimization can be used to compress the input representation
while keeping the extracted information suitable for frame interpolation.
Further, we require neither a pretrained flow network nor a synthesis network,
additionally reducing the number of trainable parameters and required memory.
When evaluating on three 4K benchmarks, we achieve state-of-the-art image
quality among the methods without pretrained flow while having the lowest
network complexity and memory requirements overall.",https://github.com/visinf/fldr-vfi,-1
108d19af-0c5c-4699-b41a-dc916e061bc1,CoRRPUS: Code-based Structured Prompting for Neurosymbolic Story Understanding,0.61224,"Story generation and understanding -- as with all NLG/NLU tasks -- has seen a
surge in neurosymbolic work. Researchers have recognized that, while large
language models (LLMs) have tremendous utility, they can be augmented with
symbolic means to be even better and to make up for any flaws that the neural
networks might have. However, symbolic methods are extremely costly in terms of
the amount of time and expertise needed to create them. In this work, we
capitalize on state-of-the-art Code-LLMs, such as Codex, to bootstrap the use
of symbolic methods for tracking the state of stories and aiding in story
understanding. We show that our CoRRPUS system and abstracted prompting
procedures can beat current state-of-the-art structured LLM techniques on
pre-existing story understanding tasks (bAbI Task 2 and Re^3) with minimal hand
engineering. We hope that this work can help highlight the importance of
symbolic representations and specialized prompting for LLMs as these models
require some guidance for performing reasoning tasks properly.",https://github.com/dong-river/CoRRPUS,-1
a798e184-174b-4a9e-8b4d-5b2e2ddc780b,Expanding Pretrained Models to Thousands More Languages via Lexicon-based Adaptation,0.447359,"The performance of multilingual pretrained models is highly dependent on the
availability of monolingual or parallel text present in a target language.
Thus, the majority of the world's languages cannot benefit from recent progress
in NLP as they have no or limited textual data. To expand possibilities of
using NLP technology in these under-represented languages, we systematically
study strategies that relax the reliance on conventional language resources
through the use of bilingual lexicons, an alternative resource with much better
language coverage. We analyze different strategies to synthesize textual or
labeled data using lexicons, and how this data can be combined with monolingual
or parallel text when available. For 19 under-represented languages across 3
tasks, our methods lead to consistent improvements of up to 5 and 15 points
with and without extra monolingual text respectively. Overall, our study
highlights how NLP methods can be adapted to thousands more languages that are
under-served by current technology",https://github.com/cindyxinyiwang/expand-via-lexicon-based-adaptation,-1
babd8a96-5252-49f8-94b1-b6b79257889a,Entropy- and Distance-Based Predictors From GPT-2 Attention Patterns Predict Reading Times Over and Above GPT-2 Surprisal,0.708596,"Transformer-based large language models are trained to make predictions about
the next word by aggregating representations of previous tokens through their
self-attention mechanism. In the field of cognitive modeling, such attention
patterns have recently been interpreted as embodying the process of cue-based
retrieval, in which attention over multiple targets is taken to generate
interference and latency during retrieval. Under this framework, this work
first defines an entropy-based predictor that quantifies the diffuseness of
self-attention, as well as distance-based predictors that capture the
incremental change in attention patterns across timesteps. Moreover, following
recent studies that question the informativeness of attention weights, we also
experiment with alternative methods for incorporating vector norms into
attention weights. Regression experiments using predictors calculated from the
GPT-2 language model show that these predictors deliver a substantially better
fit to held-out self-paced reading and eye-tracking data over a rigorous
baseline including GPT-2 surprisal. Additionally, the distance-based predictors
generally demonstrated higher predictive power, with effect sizes of up to 6.59
ms per standard deviation on self-paced reading times (compared to 2.82 ms for
surprisal) and 1.05 ms per standard deviation on eye-gaze durations (compared
to 3.81 ms for surprisal).",https://github.com/byungdoh/attn_dist,-1
4d4b63f1-02b3-4243-9305-941704d7f940,On Rate-Distortion Theory in Capacity-Limited Cognition & Reinforcement Learning,0.303438,"Throughout the cognitive-science literature, there is widespread agreement
that decision-making agents operating in the real world do so under limited
information-processing capabilities and without access to unbounded cognitive
or computational resources. Prior work has drawn inspiration from this fact and
leveraged an information-theoretic model of such behaviors or policies as
communication channels operating under a bounded rate constraint. Meanwhile, a
parallel line of work also capitalizes on the same principles from
rate-distortion theory to formalize capacity-limited decision making through
the notion of a learning target, which facilitates Bayesian regret bounds for
provably-efficient learning algorithms. In this paper, we aim to elucidate this
latter perspective by presenting a brief survey of these information-theoretic
models of capacity-limited decision making in biological and artificial agents.",None,-1
ae9e5351-7f4f-485b-8b9b-3010a8ccbc29,A Generative Approach for Script Event Prediction via Contrastive Fine-tuning,0.426601,"Script event prediction aims to predict the subsequent event given the
context. This requires the capability to infer the correlations between events.
Recent works have attempted to improve event correlation reasoning by using
pretrained language models and incorporating external knowledge~(e.g.,
discourse relations). Though promising results have been achieved, some
challenges still remain. First, the pretrained language models adopted by
current works ignore event-level knowledge, resulting in an inability to
capture the correlations between events well. Second, modeling correlations
between events with discourse relations is limited because it can only capture
explicit correlations between events with discourse markers, and cannot capture
many implicit correlations. To this end, we propose a novel generative approach
for this task, in which a pretrained language model is fine-tuned with an
event-centric pretraining objective and predicts the next event within a
generative paradigm. Specifically, we first introduce a novel event-level blank
infilling strategy as the learning objective to inject event-level knowledge
into the pretrained language model, and then design a likelihood-based
contrastive loss for fine-tuning the generative model. Instead of using an
additional prediction layer, we perform prediction by using sequence
likelihoods generated by the generative model. Our approach models correlations
between events in a soft way without any external knowledge. The
likelihood-based prediction eliminates the need to use additional networks to
make predictions and is somewhat interpretable since it scores each word in the
event. Experimental results on the multi-choice narrative cloze~(MCNC) task
demonstrate that our approach achieves better results than other
state-of-the-art baselines. Our code will be available at
https://github.com/zhufq00/mcnc.",https://github.com/zhufq00/mcnc,-1
887ea035-1900-4479-88d0-f1d9969adb76,The first neural machine translation system for the Erzya language,0.0962424,"We present the first neural machine translation system for translation
between the endangered Erzya language and Russian and the dataset collected by
us to train and evaluate it. The BLEU scores are 17 and 19 for translation to
Erzya and Russian respectively, and more than half of the translations are
rated as acceptable by native speakers. We also adapt our model to translate
between Erzya and 10 other languages, but without additional parallel data, the
quality on these directions remains low. We release the translation models
along with the collected text corpus, a new language identification model, and
a multilingual sentence encoder adapted for the Erzya language. These resources
will be available at https://github.com/slone-nlp/myv-nmt.",https://github.com/slone-nlp/myv-nmt,-1
0fecc4c7-09af-4b1f-b843-829ec93e1401,Near-Optimal Multi-Agent Learning for Safe Coverage Control,0.836703,"In multi-agent coverage control problems, agents navigate their environment
to reach locations that maximize the coverage of some density. In practice, the
density is rarely known $\textit{a priori}$, further complicating the original
NP-hard problem. Moreover, in many applications, agents cannot visit arbitrary
locations due to $\textit{a priori}$ unknown safety constraints. In this paper,
we aim to efficiently learn the density to approximately solve the coverage
problem while preserving the agents' safety. We first propose a conditionally
linear submodular coverage function that facilitates theoretical analysis.
Utilizing this structure, we develop MacOpt, a novel algorithm that efficiently
trades off the exploration-exploitation dilemma due to partial observability,
and show that it achieves sublinear regret. Next, we extend results on
single-agent safe exploration to our multi-agent setting and propose SafeMac
for safe coverage and exploration. We analyze SafeMac and give first of its
kind results: near optimal coverage in finite time while provably guaranteeing
safety. We extensively evaluate our algorithms on synthetic and real problems,
including a bio-diversity monitoring task under safety constraints, where
SafeMac outperforms competing methods.",https://github.com/manish-pra/SafeMaC,-1
3d7744ea-5f82-4237-88f8-811a3de83bb0,Universal Deep GNNs: Rethinking Residual Connection in GNNs from a Path Decomposition Perspective for Preventing the Over-smoothing,0.279285,"The performance of GNNs degrades as they become deeper due to the
over-smoothing. Among all the attempts to prevent over-smoothing, residual
connection is one of the promising methods due to its simplicity. However,
recent studies have shown that GNNs with residual connections only slightly
slow down the degeneration. The reason why residual connections fail in GNNs is
still unknown. In this paper, we investigate the forward and backward behavior
of GNNs with residual connections from a novel path decomposition perspective.
We find that the recursive aggregation of the median length paths from the
binomial distribution of residual connection paths dominates output
representation, resulting in over-smoothing as GNNs go deeper. Entangled
propagation and weight matrices cause gradient smoothing and prevent GNNs with
residual connections from optimizing to the identity mapping. Based on these
findings, we present a Universal Deep GNNs (UDGNN) framework with cold-start
adaptive residual connections (DRIVE) and feedforward modules. Extensive
experiments demonstrate the effectiveness of our method, which achieves
state-of-the-art results over non-smooth heterophily datasets by simply
stacking standard GNNs.",https://github.com/JC-202/UDGNNs,15017
7bbe9ef3-7a1f-42f8-a794-c22514e3c536,Unsupervised Learning of Efficient Geometry-Aware Neural Articulated Representations,0.793808,"We propose an unsupervised method for 3D geometry-aware representation
learning of articulated objects, in which no image-pose pairs or foreground
masks are used for training. Though photorealistic images of articulated
objects can be rendered with explicit pose control through existing 3D neural
representations, these methods require ground truth 3D pose and foreground
masks for training, which are expensive to obtain. We obviate this need by
learning the representations with GAN training. The generator is trained to
produce realistic images of articulated objects from random poses and latent
vectors by adversarial training. To avoid a high computational cost for GAN
training, we propose an efficient neural representation for articulated objects
based on tri-planes and then present a GAN-based framework for its unsupervised
training. Experiments demonstrate the efficiency of our method and show that
GAN-based training enables the learning of controllable 3D representations
without paired supervision.",https://github.com/open-mmlab/mmpose,-1
59ab8fd5-5d39-47cc-9840-24649ab46042,On the Importance of Hyperparameters and Data Augmentation for Self-Supervised Learning,0.312292,"Self-Supervised Learning (SSL) has become a very active area of Deep Learning
research where it is heavily used as a pre-training method for classification
and other tasks. However, the rapid pace of advancements in this area comes at
a price: training pipelines vary significantly across papers, which presents a
potentially crucial confounding factor. Here, we show that, indeed, the choice
of hyperparameters and data augmentation strategies can have a dramatic impact
on performance. To shed light on these neglected factors and help maximize the
power of SSL, we hyperparameterize these components and optimize them with
Bayesian optimization, showing improvements across multiple datasets for the
SimSiam SSL approach. Realizing the importance of data augmentations for SSL,
we also introduce a new automated data augmentation algorithm, GroupAugment,
which considers groups of augmentations and optimizes the sampling across
groups. In contrast to algorithms designed for supervised learning,
GroupAugment achieved consistently high linear evaluation accuracy across all
datasets we considered. Overall, our results indicate the importance and likely
underestimated role of data augmentation for SSL.",https://github.com/automl/neps,-1
454f7fda-8601-4290-891a-0a6455e0cbcc,Stacking Ensemble Learning in Deep Domain Adaptation for Ophthalmic Image Classification,0.104051,"Domain adaptation is an attractive approach given the availability of a large
amount of labeled data with similar properties but different domains. It is
effective in image classification tasks where obtaining sufficient label data
is challenging. We propose a novel method, named SELDA, for stacking ensemble
learning via extending three domain adaptation methods for effectively solving
real-world problems. The major assumption is that when base domain adaptation
models are combined, we can obtain a more accurate and robust model by
exploiting the ability of each of the base models. We extend Maximum Mean
Discrepancy (MMD), Low-rank coding, and Correlation Alignment (CORAL) to
compute the adaptation loss in three base models. Also, we utilize a two-fully
connected layer network as a meta-model to stack the output predictions of
these three well-performing domain adaptation models to obtain high accuracy in
ophthalmic image classification tasks. The experimental results using
Age-Related Eye Disease Study (AREDS) benchmark ophthalmic dataset demonstrate
the effectiveness of the proposed model.",None,-1
4a8ae470-9ae0-4351-861e-862b274d832d,Korean-Specific Dataset for Table Question Answering,0.0642198,"Existing question answering systems mainly focus on dealing with text data.
However, much of the data produced daily is stored in the form of tables that
can be found in documents and relational databases, or on the web. To solve the
task of question answering over tables, there exist many datasets for table
question answering written in English, but few Korean datasets. In this paper,
we demonstrate how we construct Korean-specific datasets for table question
answering: Korean tabular dataset is a collection of 1.4M tables with
corresponding descriptions for unsupervised pre-training language models.
Korean table question answering corpus consists of 70k pairs of questions and
answers created by crowd-sourced workers. Subsequently, we then build a
pre-trained language model based on Transformer and fine-tune the model for
table question answering with these datasets. We then report the evaluation
results of our model. We make our datasets publicly available via our GitHub
repository and hope that those datasets will help further studies for question
answering over tables, and for the transformation of table formats.",https://github.com/LG-NLP/KorWikiTableQuestions,-1
83bd75ec-1b8e-4bab-90d6-9e7367aace0f,Dataset Distillation via Factorization,0.942004,"In this paper, we study \xw{dataset distillation (DD)}, from a novel
perspective and introduce a \emph{dataset factorization} approach, termed
\emph{HaBa}, which is a plug-and-play strategy portable to any existing DD
baseline. Unlike conventional DD approaches that aim to produce distilled and
representative samples, \emph{HaBa} explores decomposing a dataset into two
components: data \emph{Ha}llucination networks and \emph{Ba}ses, where the
latter is fed into the former to reconstruct image samples. The flexible
combinations between bases and hallucination networks, therefore, equip the
distilled data with exponential informativeness gain, which largely increase
the representation capability of distilled datasets. To furthermore increase
the data efficiency of compression results, we further introduce a pair of
adversarial contrastive constraints on the resultant hallucination networks and
bases, which increase the diversity of generated images and inject more
discriminant information into the factorization. Extensive comparisons and
experiments demonstrate that our method can yield significant improvement on
downstream classification tasks compared with previous state of the arts, while
reducing the total number of compressed parameters by up to 65\%. Moreover,
distilled datasets by our approach also achieve \textasciitilde10\% higher
accuracy than baseline methods in cross-architecture generalization. Our code
is available \href{https://github.com/Huage001/DatasetFactorization}{here}.",None,-1
52626d56-dccf-4675-9b34-05ef09f4b292,SemAffiNet: Semantic-Affine Transformation for Point Cloud Segmentation,0.425696,"Conventional point cloud semantic segmentation methods usually employ an
encoder-decoder architecture, where mid-level features are locally aggregated
to extract geometric information. However, the over-reliance on these
class-agnostic local geometric representations may raise confusion between
local parts from different categories that are similar in appearance or
spatially adjacent. To address this issue, we argue that mid-level features can
be further enhanced with semantic information, and propose semantic-affine
transformation that transforms features of mid-level points belonging to
different categories with class-specific affine parameters. Based on this
technique, we propose SemAffiNet for point cloud semantic segmentation, which
utilizes the attention mechanism in the Transformer module to implicitly and
explicitly capture global structural knowledge within local parts for overall
comprehension of each category. We conduct extensive experiments on the
ScanNetV2 and NYUv2 datasets, and evaluate semantic-affine transformation on
various 3D point cloud and 2D image segmentation baselines, where both
qualitative and quantitative results demonstrate the superiority and
generalization ability of our proposed approach. Code is available at
https://github.com/wangzy22/SemAffiNet.",https://github.com/wangzy22/SemAffiNet,-1
d55b6b89-1e51-4374-8b67-b6d8b6e2152a,Code-Switching without Switching: Language Agnostic End-to-End Speech Translation,0.687652,"We propose a) a Language Agnostic end-to-end Speech Translation model (LAST),
and b) a data augmentation strategy to increase code-switching (CS)
performance. With increasing globalization, multiple languages are increasingly
used interchangeably during fluent speech. Such CS complicates traditional
speech recognition and translation, as we must recognize which language was
spoken first and then apply a language-dependent recognizer and subsequent
translation component to generate the desired target language output. Such a
pipeline introduces latency and errors. In this paper, we eliminate the need
for that, by treating speech recognition and translation as one unified
end-to-end speech translation problem. By training LAST with both input
languages, we decode speech into one target language, regardless of the input
language. LAST delivers comparable recognition and speech translation accuracy
in monolingual usage, while reducing latency and error rate considerably when
CS is observed.",None,-1
de7f2809-91d2-473b-8a8a-0221266ac00e,Deformable Butterfly: A Highly Structured and Sparse Linear Transform,0.715186,"We introduce a new kind of linear transform named Deformable Butterfly
(DeBut) that generalizes the conventional butterfly matrices and can be adapted
to various input-output dimensions. It inherits the fine-to-coarse-grained
learnable hierarchy of traditional butterflies and when deployed to neural
networks, the prominent structures and sparsity in a DeBut layer constitutes a
new way for network compression. We apply DeBut as a drop-in replacement of
standard fully connected and convolutional layers, and demonstrate its
superiority in homogenizing a neural network and rendering it favorable
properties such as light weight and low inference complexity, without
compromising accuracy. The natural complexity-accuracy tradeoff arising from
the myriad deformations of a DeBut layer also opens up new rooms for analytical
and practical research. The codes and Appendix are publicly available at:
https://github.com/ruilin0212/DeBut.",https://github.com/ruilin0212/DeBut,-1
634493cc-41b9-473a-8a09-6bf9828dee00,Encryption and encoding of facial images into quick response and high capacity color 2d code for biometric passport security system,0.427058,"In this thesis, a multimodal biometric, secure encrypted data and encrypted
biometric encoded into the QR code-based biometric-passport authentication
method is proposed for national security applications. Firstly, using the
Extended Profile - Local Binary Patterns (EP-LBP), a Canny edge detector, and
the Scale Invariant Feature Transform (SIFT) algorithm with Image File
Information (IMFINFO) process, the facial mark size recognition is initially
achieved. Secondly, by using the Active Shape Model (ASM) into Active
Appearance Model (AAM) to follow the hand and infusion the hand geometry
characteristics for verification and identification, hand geometry recognition
is achieved. Thirdly, the encrypted biometric passport information that is
publicly accessible is encoded into the QR code and inserted into the
electronic passport to improve protection. Further, Personal information and
biometric data are encrypted by applying the Advanced Encryption Standard (AES)
and the Secure Hash Algorithm (SHA) 256 algorithm. It will enhance the
biometric passport security system.",None,-1
10ccbf69-9c8b-4779-95c1-7f2f86f3fe04,Simpler is Better: off-the-shelf Continual Learning Through Pretrained Backbones,0.169946,"In this short paper, we propose a baseline (off-the-shelf) for Continual
Learning of Computer Vision problems, by leveraging the power of pretrained
models. By doing so, we devise a simple approach achieving strong performance
for most of the common benchmarks. Our approach is fast since requires no
parameters updates and has minimal memory requirements (order of KBytes). In
particular, the ""training"" phase reorders data and exploit the power of
pretrained models to compute a class prototype and fill a memory bank. At
inference time we match the closest prototype through a knn-like approach,
providing us the prediction. We will see how this naive solution can act as an
off-the-shelf continual learning system. In order to better consolidate our
results, we compare the devised pipeline with common CNN models and show the
superiority of Vision Transformers, suggesting that such architectures have the
ability to produce features of higher quality. Moreover, this simple pipeline,
raises the same questions raised by previous works \cite{gdumb} on the
effective progresses made by the CL community especially in the dataset
considered and the usage of pretrained models. Code is live at
https://github.com/francesco-p/off-the-shelf-cl",https://github.com/francesco-p/off-the-shelf-cl,-1
661853c9-c5b2-43dc-9fc2-a9bd04e6ab20,IGLU 2022: Interactive Grounded Language Understanding in a Collaborative Environment at NeurIPS 2022,0.697186,"Human intelligence has the remarkable ability to adapt to new tasks and
environments quickly. Starting from a very young age, humans acquire new skills
and learn how to solve new tasks either by imitating the behavior of others or
by following provided natural language instructions. To facilitate research in
this direction, we propose IGLU: Interactive Grounded Language Understanding in
a Collaborative Environment. The primary goal of the competition is to approach
the problem of how to develop interactive embodied agents that learn to solve a
task while provided with grounded natural language instructions in a
collaborative environment. Understanding the complexity of the challenge, we
split it into sub-tasks to make it feasible for participants.
  This research challenge is naturally related, but not limited, to two fields
of study that are highly relevant to the NeurIPS community: Natural Language
Understanding and Generation (NLU/G) and Reinforcement Learning (RL).
Therefore, the suggested challenge can bring two communities together to
approach one of the crucial challenges in AI. Another critical aspect of the
challenge is the dedication to perform a human-in-the-loop evaluation as a
final evaluation for the agents developed by contestants.",None,-1
479bb8c4-bc98-433f-908e-52a52fdd83b9,Procedural Image Programs for Representation Learning,0.750991,"Learning image representations using synthetic data allows training neural
networks without some of the concerns associated with real images, such as
privacy and bias. Existing work focuses on a handful of curated generative
processes which require expert knowledge to design, making it hard to scale up.
To overcome this, we propose training with a large dataset of twenty-one
thousand programs, each one generating a diverse set of synthetic images. These
programs are short code snippets, which are easy to modify and fast to execute
using OpenGL. The proposed dataset can be used for both supervised and
unsupervised representation learning, and reduces the gap between pre-training
with real and procedurally generated images by 38%.",https://github.com/mbaradad/shaders21k,-1
4279c715-4c21-49fb-b5bc-7eb0afbbd22c,Can Pre-trained Language Models Interpret Similes as Smart as Human?,0.644622,"Simile interpretation is a crucial task in natural language processing.
Nowadays, pre-trained language models (PLMs) have achieved state-of-the-art
performance on many tasks. However, it remains under-explored whether PLMs can
interpret similes or not. In this paper, we investigate the ability of PLMs in
simile interpretation by designing a novel task named Simile Property Probing,
i.e., to let the PLMs infer the shared properties of similes. We construct our
simile property probing datasets from both general textual corpora and
human-designed questions, containing 1,633 examples covering seven main
categories. Our empirical study based on the constructed datasets shows that
PLMs can infer similes' shared properties while still underperforming humans.
To bridge the gap with human performance, we additionally design a
knowledge-enhanced training objective by incorporating the simile knowledge
into PLMs via knowledge embedding methods. Our method results in a gain of
8.58% in the probing task and 1.37% in the downstream task of sentiment
classification. The datasets and code are publicly available at
https://github.com/Abbey4799/PLMs-Interpret-Simile.",https://github.com/Abbey4799/PLMs-Interpret-Simile,-1
2f3958c6-4f1b-4211-8fcc-092d779b5df8,Strong Instance Segmentation Pipeline for MMSports Challenge,0.159452,"The goal of ACM MMSports2022 DeepSportRadar Instance Segmentation Challenge
is to tackle the segmentation of individual humans including players, coaches
and referees on a basketball court. And the main characteristics of this
challenge are there is a high level of occlusions between players and the
amount of data is quite limited. In order to address these problems, we
designed a strong instance segmentation pipeline. Firstly, we employed a proper
data augmentation strategy for this task mainly including photometric
distortion transform and copy-paste strategy, which can generate more image
instances with a wider distribution. Secondly, we employed a strong
segmentation model, Hybrid Task Cascade based detector on the Swin-Base based
CBNetV2 backbone, and we add MaskIoU head to HTCMaskHead that can simply and
effectively improve the performance of instance segmentation. Finally, the SWA
training strategy was applied to improve the performance further. Experimental
results demonstrate the proposed pipeline can achieve a competitive result on
the DeepSportRadar challenge, with 0.768AP@0.50:0.95 on the challenge set.
Source code is available at
https://github.com/YJingyu/Instanc_Segmentation_Pro.",https://github.com/YJingyu/Instanc_Segmentation_Pro,297
51157c79-2525-40a9-9aac-5fa54e7de135,Report from the NSF Future Directions Workshop on Automatic Evaluation of Dialog: Research Directions and Challenges,0.547843,"This is a report on the NSF Future Directions Workshop on Automatic
Evaluation of Dialog. The workshop explored the current state of the art along
with its limitations and suggested promising directions for future work in this
important and very rapidly changing area of research.",None,-1
b56e075a-1f78-447a-be3d-b5a678a6fe32,"""This is Fake! Shared it by Mistake"": Assessing the Intent of Fake News Spreaders",0.887701,"Individuals can be misled by fake news and spread it unintentionally without
knowing it is false. This phenomenon has been frequently observed but has not
been investigated. Our aim in this work is to assess the intent of fake news
spreaders. To distinguish between intentional versus unintentional spreading,
we study the psychological explanations of unintentional spreading. With this
foundation, we then propose an influence graph, using which we assess the
intent of fake news spreaders. Our extensive experiments show that the assessed
intent can help significantly differentiate between intentional and
unintentional fake news spreaders. Furthermore, the estimated intent can
significantly improve the current techniques that detect fake news. To our best
knowledge, this is the first work to model individuals' intent in fake news
spreading.",https://github.com/flairNLP/flair,-1
dfa87f09-30da-4ea1-a834-c9de0b8e8bb5,Acquiring and Modelling Abstract Commonsense Knowledge via Conceptualization,0.766864,"Conceptualization, or viewing entities and situations as instances of
abstract concepts in mind and making inferences based on that, is a vital
component in human intelligence for commonsense reasoning. Although recent
artificial intelligence has made progress in acquiring and modelling
commonsense, attributed to large neural language models and commonsense
knowledge graphs (CKGs), conceptualization is yet to thoroughly be introduced,
making current approaches ineffective to cover knowledge about countless
diverse entities and situations in the real world. To address the problem, we
thoroughly study the possible role of conceptualization in commonsense
reasoning, and formulate a framework to replicate human conceptual induction
from acquiring abstract knowledge about abstract concepts. Aided by the
taxonomy Probase, we develop tools for contextualized conceptualization on
ATOMIC, a large-scale human annotated CKG. We annotate a dataset for the
validity of conceptualizations for ATOMIC on both event and triple level,
develop a series of heuristic rules based on linguistic features, and train a
set of neural models, so as to generate and verify abstract knowledge. Based on
these components, a pipeline to acquire abstract knowledge is built. A large
abstract CKG upon ATOMIC is then induced, ready to be instantiated to infer
about unseen entities or situations. Furthermore, experiments find directly
augmenting data with abstract triples to be helpful in commonsense modelling.",https://github.com/HKUST-KnowComp/atomic-conceptualization,-1
1a60ad92-bd33-4223-a52e-efe30818cbae,When to Use What: An In-Depth Comparative Empirical Analysis of OpenIE Systems for Downstream Applications,0.411692,"Open Information Extraction (OpenIE) has been used in the pipelines of
various NLP tasks. Unfortunately, there is no clear consensus on which models
to use in which tasks. Muddying things further is the lack of comparisons that
take differing training sets into account. In this paper, we present an
application-focused empirical survey of neural OpenIE models, training sets,
and benchmarks in an effort to help users choose the most suitable OpenIE
systems for their applications. We find that the different assumptions made by
different models and datasets have a statistically significant effect on
performance, making it important to choose the most appropriate model for one's
applications. We demonstrate the applicability of our recommendations on a
downstream Complex QA application.",None,-1
bc13a2d7-5e2b-4a01-82f6-54fbb979b4c3,Shuffle Augmentation of Features from Unlabeled Data for Unsupervised Domain Adaptation,0.0522426,"Unsupervised Domain Adaptation (UDA), a branch of transfer learning where
labels for target samples are unavailable, has been widely researched and
developed in recent years with the help of adversarially trained models.
Although existing UDA algorithms are able to guide neural networks to extract
transferable and discriminative features, classifiers are merely trained under
the supervision of labeled source data. Given the inevitable discrepancy
between source and target domains, the classifiers can hardly be aware of the
target classification boundaries. In this paper, Shuffle Augmentation of
Features (SAF), a novel UDA framework, is proposed to address the problem by
providing the classifier with supervisory signals from target feature
representations. SAF learns from the target samples, adaptively distills
class-aware target features, and implicitly guides the classifier to find
comprehensive class borders. Demonstrated by extensive experiments, the SAF
module can be integrated into any existing adversarial UDA models to achieve
performance improvements.",https://github.com/thuml/MDD/,-1
3ddcdb75-2477-4c3a-8a41-86c19b80a224,"Detecting and Mitigating Hallucinations in Machine Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even Better",0.536982,"While the problem of hallucinations in neural machine translation has long
been recognized, so far the progress on its alleviation is very little. Indeed,
recently it turned out that without artificially encouraging models to
hallucinate, previously existing methods fall short and even the standard
sequence log-probability is more informative. It means that characteristics
internal to the model can give much more information than we expect, and before
using external models and measures, we first need to ask: how far can we go if
we use nothing but the translation model itself ? We propose to use a method
that evaluates the percentage of the source contribution to a generated
translation. Intuitively, hallucinations are translations ""detached"" from the
source, hence they can be identified by low source contribution. This method
improves detection accuracy for the most severe hallucinations by a factor of 2
and is able to alleviate hallucinations at test time on par with the previous
best approach that relies on external models. Next, if we move away from
internal model characteristics and allow external tools, we show that using
sentence similarity from cross-lingual embeddings further improves these
results.",https://github.com/facebookresearch/stopes,2821
4c3193a2-ae0e-48f9-b192-218c06a90e6e,"Robustness in deep learning: The good (width), the bad (depth), and the ugly (initialization)",0.452609,"We study the average robustness notion in deep neural networks in (selected)
wide and narrow, deep and shallow, as well as lazy and non-lazy training
settings. We prove that in the under-parameterized setting, width has a
negative effect while it improves robustness in the over-parameterized setting.
The effect of depth closely depends on the initialization and the training
mode. In particular, when initialized with LeCun initialization, depth helps
robustness with the lazy training regime. In contrast, when initialized with
Neural Tangent Kernel (NTK) and He-initialization, depth hurts the robustness.
Moreover, under the non-lazy training regime, we demonstrate how the width of a
two-layer ReLU network benefits robustness. Our theoretical developments
improve the results by [Huang et al. NeurIPS21; Wu et al. NeurIPS21] and are
consistent with [Bubeck and Sellke NeurIPS21; Bubeck et al. COLT21].",https://github.com/bearpaw/pytorch-classification,-1
284c1c3d-bfc0-494a-a198-880673e5ece0,Hand-Object Interaction Image Generation,0.540229,"In this work, we are dedicated to a new task, i.e., hand-object interaction
image generation, which aims to conditionally generate the hand-object image
under the given hand, object and their interaction status. This task is
challenging and research-worthy in many potential application scenarios, such
as AR/VR games and online shopping, etc. To address this problem, we propose a
novel HOGAN framework, which utilizes the expressive model-aware hand-object
representation and leverages its inherent topology to build the unified surface
space. In this space, we explicitly consider the complex self- and mutual
occlusion during interaction. During final image synthesis, we consider
different characteristics of hand and object and generate the target image in a
split-and-combine manner. For evaluation, we build a comprehensive protocol to
access both the fidelity and structure preservation of the generated image.
Extensive experiments on two large-scale datasets, i.e., HO3Dv3 and DexYCB,
demonstrate the effectiveness and superiority of our framework both
quantitatively and qualitatively. The project page is available at
https://play-with-hoi-generation.github.io/.",None,25445
27030c5e-4ded-4ea3-b39c-003d78e672a7,Probing for the Usage of Grammatical Number,0.913343,"A central quest of probing is to uncover how pre-trained models encode a
linguistic property within their representations. An encoding, however, might
be spurious-i.e., the model might not rely on it when making predictions. In
this paper, we try to find encodings that the model actually uses, introducing
a usage-based probing setup. We first choose a behavioral task which cannot be
solved without using the linguistic property. Then, we attempt to remove the
property by intervening on the model's representations. We contend that, if an
encoding is used by the model, its removal should harm the performance on the
chosen behavioral task. As a case study, we focus on how BERT encodes
grammatical number, and on how it uses this encoding to solve the number
agreement task. Experimentally, we find that BERT relies on a linear encoding
of grammatical number to produce the correct behavioral output. We also find
that BERT uses a separate encoding of grammatical number for nouns and verbs.
Finally, we identify in which layers information about grammatical number is
transferred from a noun to its head verb.",None,-1
a612ef51-22d8-4e4f-986f-edf8eb102a28,Trinary Tools for Continuously Valued Binary Classifiers,0.0214648,"Classification methods for binary (yes/no) tasks often produce a continuously
valued score. Machine learning practitioners must perform model selection,
calibration, discretization, performance assessment, tuning, and fairness
assessment. Such tasks involve examining classifier results, typically using
summary statistics and manual examination of details. In this paper, we provide
an interactive visualization approach to support such continuously-valued
classifier examination tasks. Our approach addresses the three phases of these
tasks: calibration, operating point selection, and examination. We enhance
standard views and introduce task-specific views so that they can be integrated
into a multi-view coordination (MVC) system. We build on an existing
comparison-based approach, extending it to continuous classifiers by treating
the continuous values as trinary (positive, unsure, negative) even if the
classifier will not ultimately use the 3-way classification. We provide use
cases that demonstrate how our approach enables machine learning practitioners
to accomplish key tasks.",http://pages.graphics.cs.wisc.edu/Boxer,-1
4429733e-e905-47a6-aab4-f244a7730f78,Perceiver-Actor: A Multi-Task Transformer for Robotic Manipulation,1.0,"Transformers have revolutionized vision and natural language processing with
their ability to scale with large datasets. But in robotic manipulation, data
is both limited and expensive. Can manipulation still benefit from Transformers
with the right problem formulation? We investigate this question with PerAct, a
language-conditioned behavior-cloning agent for multi-task 6-DoF manipulation.
PerAct encodes language goals and RGB-D voxel observations with a Perceiver
Transformer, and outputs discretized actions by ``detecting the next best voxel
action''. Unlike frameworks that operate on 2D images, the voxelized 3D
observation and action space provides a strong structural prior for efficiently
learning 6-DoF actions. With this formulation, we train a single multi-task
Transformer for 18 RLBench tasks (with 249 variations) and 7 real-world tasks
(with 18 variations) from just a few demonstrations per task. Our results show
that PerAct significantly outperforms unstructured image-to-action agents and
3D ConvNet baselines for a wide range of tabletop tasks.",https://github.com/lucidrains/perceiver-pytorch,-1
ea2b092f-270a-4ee8-99ea-b4890ea7ae91,Learning Keypoints from Synthetic Data for Robotic Cloth Folding,0.166726,"Robotic cloth manipulation is challenging due to its deformability, which
makes determining its full state infeasible. However, for cloth folding, it
suffices to know the position of a few semantic keypoints. Convolutional neural
networks (CNN) can be used to detect these keypoints, but require large amounts
of annotated data, which is expensive to collect. To overcome this, we propose
to learn these keypoint detectors purely from synthetic data, enabling low-cost
data collection. In this paper, we procedurally generate images of towels and
use them to train a CNN. We evaluate the performance of this detector for
folding towels on a unimanual robot setup and find that the grasp and fold
success rates are 77% and 53%, respectively. We conclude that learning keypoint
detectors from synthetic data for cloth folding and related tasks is a
promising research direction, discuss some failures and relate them to future
work. A video of the system, as well as the codebase, more details on the CNN
architecture and the training setup can be found at
https://github.com/tlpss/workshop-icra-2022-cloth-keypoints.git.",https://github.com/tlpss/workshop-icra-2022-cloth-keypoints.git,-1
32c07578-699a-4b5d-b7b0-df6f1ef8e479,CCC-wav2vec 2.0: Clustering aided Cross Contrastive Self-supervised learning of speech representations,0.266346,"While Self-Supervised Learning has helped reap the benefit of the scale from
the available unlabeled data, the learning paradigms are continuously being
bettered. We present a new pre-training strategy named ccc-wav2vec 2.0, which
uses clustering and an augmentation-based cross-contrastive loss as its
self-supervised objective. Through the clustering module, we scale down the
influence of those negative examples that are highly similar to the positive.
The Cross-Contrastive loss is computed between the encoder output of the
original sample and the quantizer output of its augmentation and vice-versa,
bringing robustness to the pre-training strategy. ccc-wav2vec 2.0 achieves up
to 15.6% and 12.7% relative WER improvement over the baseline wav2vec 2.0 on
the test-clean and test-other sets, respectively, of LibriSpeech, without the
use of any language model. The proposed method also achieves up to 14.9%
relative WER improvement over the baseline wav2vec 2.0 when fine-tuned on
Switchboard data. We make all our codes publicly available on GitHub.",https://github.com/Speech-Lab-IITM/CCC-wav2vec-2.0,256
1feed4e7-0000-4677-91b4-b50d5f9416d2,Overlooked Implications of the Reconstruction Loss for VAE Disentanglement,0.135225,"Learning disentangled representations with variational autoencoders (VAEs) is
often attributed to the regularisation component of the loss. In this work, we
highlight the interaction between data and the reconstruction term of the loss
as the main contributor to disentanglement in VAEs. We show that standard
benchmark datasets have unintended correlations between their subjective
ground-truth factors and perceived axes in the data according to typical VAE
reconstruction losses. Our work exploits this relationship to provide a theory
for what constitutes an adversarial dataset under a given reconstruction loss.
We verify this by constructing an example dataset that prevents disentanglement
in state-of-the-art frameworks while maintaining human-intuitive ground-truth
factors. Finally, we re-enable disentanglement by designing an example
reconstruction loss that is once again able to perceive the ground-truth
factors. Our findings demonstrate the subjective nature of disentanglement and
the importance of considering the interaction between the ground-truth factors,
data and notably, the reconstruction loss, which is under-recognised in the
literature.",https://github.com/nmichlo/disent,-1
b0983932-d296-4021-82c4-a15e028cc73a,ReFactor GNNs: Revisiting Factorisation-based Models from a Message-Passing Perspective,0.238352,"Factorisation-based Models (FMs), such as DistMult, have enjoyed enduring
success for Knowledge Graph Completion (KGC) tasks, often outperforming Graph
Neural Networks (GNNs). However, unlike GNNs, FMs struggle to incorporate node
features and generalise to unseen nodes in inductive settings. Our work bridges
the gap between FMs and GNNs by proposing ReFactor GNNs. This new architecture
draws upon both modelling paradigms, which previously were largely thought of
as disjoint. Concretely, using a message-passing formalism, we show how FMs can
be cast as GNNs by reformulating the gradient descent procedure as
message-passing operations, which forms the basis of our ReFactor GNNs. Across
a multitude of well-established KGC benchmarks, our ReFactor GNNs achieve
comparable transductive performance to FMs, and state-of-the-art inductive
performance while using an order of magnitude fewer parameters.",None,-1
0c9eb1b5-33a1-4111-acae-3a074b3e8c48,Discrete Factorial Representations as an Abstraction for Goal Conditioned Reinforcement Learning,0.372448,"Goal-conditioned reinforcement learning (RL) is a promising direction for
training agents that are capable of solving multiple tasks and reach a diverse
set of objectives. How to \textit{specify} and \textit{ground} these goals in
such a way that we can both reliably reach goals during training as well as
generalize to new goals during evaluation remains an open area of research.
Defining goals in the space of noisy and high-dimensional sensory inputs poses
a challenge for training goal-conditioned agents, or even for generalization to
novel goals. We propose to address this by learning factorial representations
of goals and processing the resulting representation via a discretization
bottleneck, for coarser goal specification, through an approach we call DGRL.
We show that applying a discretizing bottleneck can improve performance in
goal-conditioned RL setups, by experimentally evaluating this method on tasks
ranging from maze environments to complex robotic navigation and manipulation.
Additionally, we prove a theorem lower-bounding the expected return on
out-of-distribution goals, while still allowing for specifying goals with
expressive combinatorial structure.",None,794065
4ba4bf6b-9296-4ef4-94e6-05fe1afcc1a0,ODE Transformer: An Ordinary Differential Equation-Inspired Model for Sequence Generation,0.112602,"Residual networks are an Euler discretization of solutions to Ordinary
Differential Equations (ODE). This paper explores a deeper relationship between
Transformer and numerical ODE methods. We first show that a residual block of
layers in Transformer can be described as a higher-order solution to ODE.
Inspired by this, we design a new architecture, {\it ODE Transformer}, which is
analogous to the Runge-Kutta method that is well motivated in ODE. As a natural
extension to Transformer, ODE Transformer is easy to implement and efficient to
use. Experimental results on the large-scale machine translation, abstractive
summarization, and grammar error correction tasks demonstrate the high
genericity of ODE Transformer. It can gain large improvements in model
performance over strong baselines (e.g., 30.77 and 44.11 BLEU scores on the
WMT'14 English-German and English-French benchmarks) at a slight cost in
inference efficiency.",https://github.com/libeineu/ODE-Transformer,-1
a3a6a461-95be-472c-b5a1-1948529fd45e,Compute Cost Amortized Transformer for Streaming ASR,0.317147,"We present a streaming, Transformer-based end-to-end automatic speech
recognition (ASR) architecture which achieves efficient neural inference
through compute cost amortization. Our architecture creates sparse computation
pathways dynamically at inference time, resulting in selective use of compute
resources throughout decoding, enabling significant reductions in compute with
minimal impact on accuracy. The fully differentiable architecture is trained
end-to-end with an accompanying lightweight arbitrator mechanism operating at
the frame-level to make dynamic decisions on each input while a tunable loss
function is used to regularize the overall level of compute against predictive
performance. We report empirical results from experiments using the compute
amortized Transformer-Transducer (T-T) model conducted on LibriSpeech data. Our
best model can achieve a 60% compute cost reduction with only a 3% relative
word error rate (WER) increase.",None,-1
0b0901e6-9be5-4231-bf90-28b5afea46b1,Goal Recognition as a Deep Learning Task: the GRNet Approach,0.315034,"In automated planning, recognising the goal of an agent from a trace of
observations is an important task with many applications. The state-of-the-art
approaches to goal recognition rely on the application of planning techniques,
which requires a model of the domain actions and of the initial domain state
(written, e.g., in PDDL). We study an alternative approach where goal
recognition is formulated as a classification task addressed by machine
learning. Our approach, called GRNet, is primarily aimed at making goal
recognition more accurate as well as faster by learning how to solve it in a
given domain. Given a planning domain specified by a set of propositions and a
set of action names, the goal classification instances in the domain are solved
by a Recurrent Neural Network (RNN). A run of the RNN processes a trace of
observed actions to compute how likely it is that each domain proposition is
part of the agent's goal, for the problem instance under considerations. These
predictions are then aggregated to choose one of the candidate goals. The only
information required as input of the trained RNN is a trace of action labels,
each one indicating just the name of an observed action. An experimental
analysis confirms that \our achieves good performance in terms of both goal
classification accuracy and runtime, obtaining better performance w.r.t. a
state-of-the-art goal recognition system over the considered benchmarks.",None,3062
a8cacc4b-960d-408d-8b9c-f71284b75266,Semantic Novelty Detection and Characterization in Factual Text Involving Named Entities,0.0613487,"Much of the existing work on text novelty detection has been studied at the
topic level, i.e., identifying whether the topic of a document or a sentence is
novel or not. Little work has been done at the fine-grained semantic level (or
contextual level). For example, given that we know Elon Musk is the CEO of a
technology company, the sentence ""Elon Musk acted in the sitcom The Big Bang
Theory"" is novel and surprising because normally a CEO would not be an actor.
Existing topic-based novelty detection methods work poorly on this problem
because they do not perform semantic reasoning involving relations between
named entities in the text and their background knowledge. This paper proposes
an effective model (called PAT-SND) to solve the problem, which can also
characterize the novelty. An annotated dataset is also created. Evaluation
shows that PAT-SND outperforms 10 baselines by large margins.",https://github.com/NianzuMa/PAT-SND,-1
d4260d10-4756-4fda-a75c-c72817f80000,DailyTalk: Spoken Dialogue Dataset for Conversational Text-to-Speech,0.965861,"The majority of current Text-to-Speech (TTS) datasets, which are collections
of individual utterances, contain few conversational aspects. In this paper, we
introduce DailyTalk, a high-quality conversational speech dataset designed for
conversational TTS. We sampled, modified, and recorded 2,541 dialogues from the
open-domain dialogue dataset DailyDialog inheriting its annotated attributes.
On top of our dataset, we extend prior work as our baseline, where a
non-autoregressive TTS is conditioned on historical information in a dialogue.
From the baseline experiment with both general and our novel metrics, we show
that DailyTalk can be used as a general TTS dataset, and more than that, our
baseline can represent contextual information from DailyTalk. The DailyTalk
dataset and baseline code are freely available for academic use with CC-BY-SA
4.0 license.",https://github.com/keonlee9420/DailyTalk,-1
a5f29a3e-9850-4fe1-b77e-70afd3214ebb,HumanGen: Generating Human Radiance Fields with Explicit Priors,0.46181,"Recent years have witnessed the tremendous progress of 3D GANs for generating
view-consistent radiance fields with photo-realism. Yet, high-quality
generation of human radiance fields remains challenging, partially due to the
limited human-related priors adopted in existing methods. We present HumanGen,
a novel 3D human generation scheme with detailed geometry and
$\text{360}^{\circ}$ realistic free-view rendering. It explicitly marries the
3D human generation with various priors from the 2D generator and 3D
reconstructor of humans through the design of ""anchor image"". We introduce a
hybrid feature representation using the anchor image to bridge the latent space
of HumanGen with the existing 2D generator. We then adopt a pronged design to
disentangle the generation of geometry and appearance. With the aid of the
anchor image, we adapt a 3D reconstructor for fine-grained details synthesis
and propose a two-stage blending scheme to boost appearance generation.
Extensive experiments demonstrate our effectiveness for state-of-the-art 3D
human generation regarding geometry details, texture quality, and free-view
performance. Notably, HumanGen can also incorporate various off-the-shelf 2D
latent editing methods, seamlessly lifting them into 3D.",None,-1
9c519ee7-efec-4a09-91c2-9677c289d5c0,PIE: a Parameter and Inference Efficient Solution for Large Scale Knowledge Graph Embedding Reasoning,0.464669,"Knowledge graph (KG) embedding methods which map entities and relations to
unique embeddings in the KG have shown promising results on many reasoning
tasks. However, the same embedding dimension for both dense entities and sparse
entities will cause either over parameterization (sparse entities) or under
fitting (dense entities). Normally, a large dimension is set to get better
performance. Meanwhile, the inference time grows log-linearly with the number
of entities for all entities are traversed and compared. Both the parameter and
inference become challenges when working with huge amounts of entities. Thus,
we propose PIE, a \textbf{p}arameter and \textbf{i}nference \textbf{e}fficient
solution. Inspired from tensor decomposition methods, we find that decompose
entity embedding matrix into low rank matrices can reduce more than half of the
parameters while maintaining comparable performance. To accelerate model
inference, we propose a self-supervised auxiliary task, which can be seen as
fine-grained entity typing. By randomly masking and recovering entities'
connected relations, the task learns the co-occurrence of entity and relations.
Utilizing the fine grained typing, we can filter unrelated entities during
inference and get targets with possibly sub-linear time requirement.
Experiments on link prediction benchmarks demonstrate the proposed key
capabilities. Moreover, we prove effectiveness of the proposed solution on the
Open Graph Benchmark large scale challenge dataset WikiKG90Mv2 and achieve the
state of the art performance.",https://github.com/alipay/Parameter_Inference_Efﬁcient_PIE,-1
a27f65c0-ee0c-46b9-a7b3-e1f1e1830b9b,Areas of Strategic Visibility: Disability Bias in Biometrics,0.518776,"This response to the RFI considers the potential for biometrics to help or
harm disabled people2. Biometrics are already integrated into many aspects of
daily life, from airport travel to mobile phone use. Yet many of these systems
are not accessible to people who experience different kinds of disability
exclusion . Different personal characteristics may impact any or all of the
physical (DNA, fingerprints, face or retina) and behavioral (gesture, gait,
voice) characteristics listed in the RFI as examples of biometric signals.",None,-1
1d219a0e-90ef-4c5d-923d-05357845afa2,Revisiting Facial Key Point Detection: An Efficient Approach Using Deep Neural Networks,0.462075,"Facial landmark detection is a widely researched field of deep learning as
this has a wide range of applications in many fields. These key points are
distinguishing characteristic points on the face, such as the eyes center, the
eye's inner and outer corners, the mouth center, and the nose tip from which
human emotions and intent can be explained. The focus of our work has been
evaluating transfer learning models such as MobileNetV2 and NasNetMobile,
including custom CNN architectures. The objective of the research has been to
develop efficient deep learning models in terms of model size, parameters, and
inference time and to study the effect of augmentation imputation and
fine-tuning on these models. It was found that while augmentation techniques
produced lower RMSE scores than imputation techniques, they did not affect the
inference time. MobileNetV2 architecture produced the lowest RMSE and inference
time. Moreover, our results indicate that manually optimized CNN architectures
performed similarly to Auto Keras tuned architecture. However, manually
optimized architectures yielded better inference time and training curves.",None,-1
472574c3-f35c-4228-b1d8-5d5289ebbd51,Multi-Task Option Learning and Discovery for Stochastic Path Planning,0.175759,"This paper addresses the problem of reliably and efficiently solving broad
classes of long-horizon stochastic path planning problems. Starting with a
vanilla RL formulation with a stochastic dynamics simulator and an occupancy
matrix of the environment, our approach computes useful options with policies
as well as high-level paths that compose the discovered options. Our main
contributions are (1) data-driven methods for creating abstract states that
serve as endpoints for helpful options, (2) methods for computing option
policies using auto-generated option guides in the form of dense pseudo-reward
functions, and (3) an overarching algorithm for composing the computed options.
We show that this approach yields strong guarantees of executability and
solvability: under fairly general conditions, the computed option guides lead
to composable option policies and consequently ensure downward refinability.
Empirical evaluation on a range of robots, environments, and tasks shows that
this approach effectively transfers knowledge across related tasks and that it
outperforms existing approaches by a significant margin.",None,-1
6997bec1-094c-40bf-8595-366fa3b63c08,TaxoCom: Topic Taxonomy Completion with Hierarchical Discovery of Novel Topic Clusters,0.361784,"Topic taxonomies, which represent the latent topic (or category) structure of
document collections, provide valuable knowledge of contents in many
applications such as web search and information filtering. Recently, several
unsupervised methods have been developed to automatically construct the topic
taxonomy from a text corpus, but it is challenging to generate the desired
taxonomy without any prior knowledge. In this paper, we study how to leverage
the partial (or incomplete) information about the topic structure as guidance
to find out the complete topic taxonomy. We propose a novel framework for topic
taxonomy completion, named TaxoCom, which recursively expands the topic
taxonomy by discovering novel sub-topic clusters of terms and documents. To
effectively identify novel topics within a hierarchical topic structure,
TaxoCom devises its embedding and clustering techniques to be closely-linked
with each other: (i) locally discriminative embedding optimizes the text
embedding space to be discriminative among known (i.e., given) sub-topics, and
(ii) novelty adaptive clustering assigns terms into either one of the known
sub-topics or novel sub-topics. Our comprehensive experiments on two real-world
datasets demonstrate that TaxoCom not only generates the high-quality topic
taxonomy in terms of term coherency and topic coverage but also outperforms all
other baselines for a downstream task.",https://github.com/joewandy/hlda,-1
78189e68-74bd-4899-a9dc-a239c5caee61,Score-based Generative Modeling Secretly Minimizes the Wasserstein Distance,0.516922,"Score-based generative models are shown to achieve remarkable empirical
performances in various applications such as image generation and audio
synthesis. However, a theoretical understanding of score-based diffusion models
is still incomplete. Recently, Song et al. showed that the training objective
of score-based generative models is equivalent to minimizing the
Kullback-Leibler divergence of the generated distribution from the data
distribution. In this work, we show that score-based models also minimize the
Wasserstein distance between them under suitable assumptions on the model.
Specifically, we prove that the Wasserstein distance is upper bounded by the
square root of the objective function up to multiplicative constants and a
fixed constant offset. Our proof is based on a novel application of the theory
of optimal transport, which can be of independent interest to the society. Our
numerical experiments support our findings. By analyzing our upper bounds, we
provide a few techniques to obtain tighter upper bounds.",https://github.com/UW-Madison-Lee-Lab/score-wasserstein,-1
fc5f69b0-fcea-4c6f-9677-bfa72d3baa06,Query-Based Keyphrase Extraction from Long Documents,0.142206,"Transformer-based architectures in natural language processing force input
size limits that can be problematic when long documents need to be processed.
This paper overcomes this issue for keyphrase extraction by chunking the long
documents while keeping a global context as a query defining the topic for
which relevant keyphrases should be extracted. The developed system employs a
pre-trained BERT model and adapts it to estimate the probability that a given
text span forms a keyphrase. We experimented using various context sizes on two
popular datasets, Inspec and SemEval, and a large novel dataset. The presented
results show that a shorter context with a query overcomes a longer one without
the query on long documents.",None,-1
145cba63-22a0-4597-9afd-e8f7e24e9b9c,Defending Black-box Skeleton-based Human Activity Classifiers,0.62166,"Skeletal motions have been heavily replied upon for human activity
recognition (HAR). Recently, a universal vulnerability of skeleton-based HAR
has been identified across a variety of classifiers and data, calling for
mitigation. To this end, we propose the first black-box defense method for
skeleton-based HAR to our best knowledge. Our method is featured by full
Bayesian treatments of the clean data, the adversaries and the classifier,
leading to (1) a new Bayesian Energy-based formulation of robust discriminative
classifiers, (2) a new adversary sampling scheme based on natural motion
manifolds, and (3) a new post-train Bayesian strategy for black-box defense. We
name our framework Bayesian Energy-based Adversarial Training or BEAT. BEAT is
straightforward but elegant, which turns vulnerable black-box classifiers into
robust ones without sacrificing accuracy. It demonstrates surprising and
universal effectiveness across a wide range of skeletal HAR classifiers and
datasets, under various attacks. Code is available at
https://github.com/realcrane/RobustActionRecogniser.",https://github.com/realcrane/Defending-Black-box-Skeleton-based-Human-Activity-Classiﬁers,1271
1c5e1fd0-8051-4296-8de0-4ce0f6a6a8bb,Design of High-Throughput Mixed-Precision CNN Accelerators on FPGA,0.52301,"Convolutional Neural Networks (CNNs) reach high accuracies in various
application domains, but require large amounts of computation and incur costly
data movements. One method to decrease these costs while trading accuracy is
weight and/or activation word-length reduction. Thereby, layer-wise
mixed-precision quantization allows for more efficient results while inflating
the design space. In this work, we present an in-depth quantitative methodology
to efficiently explore the design space considering the limited hardware
resources of a given FPGA. Our holistic exploration approach vertically
traverses the various design entry levels from the architectural down to the
logic level, and laterally covers optimization from processing elements to
dataflow for an efficient mixed-precision CNN accelerator. Our resulting
hardware accelerators implement truly mixed-precision operations that enable
efficient execution of layer-wise and channel-wise quantized CNNs. Mapping
feed-forward and identity-shortcut-connection mixed-precision CNNs result in
competitive accuracy-throughout trade-offs: 245 frames/s with 87.48% Top-5
accuracy for ResNet-18 and 92.9% Top-5 accuracy with 1.13 TOps/s for
ResNet-152, respectively. Thereby, the required memory footprint for parameters
is reduced by 4.9x and 9.4x compared to the respective floating-point baseline.",None,699
7ddfbae5-a180-45b9-b2e2-04b3befb085f,ViT-DD: Multi-Task Vision Transformer for Semi-Supervised Driver Distraction Detection,0.828128,"Ensuring traffic safety and mitigating accidents in modern driving is of
paramount importance, and computer vision technologies have the potential to
significantly contribute to this goal. This paper presents a multi-modal Vision
Transformer for Driver Distraction Detection (termed ViT-DD), which
incorporates inductive information from training signals related to both
distraction detection and driver emotion recognition. Additionally, a
self-learning algorithm is developed, allowing for the seamless integration of
driver data without emotion labels into the multi-task training process of
ViT-DD. Experimental results reveal that the proposed ViT-DD surpasses existing
state-of-the-art methods for driver distraction detection by 6.5% and 0.9% on
the SFDDD and AUCDD datasets, respectively.",None,-1
230b0985-574c-409a-90d4-5be47f5e91ad,Faithful Reasoning Using Large Language Models,0.969425,"Although contemporary large language models (LMs) demonstrate impressive
question-answering capabilities, their answers are typically the product of a
single call to the model. This entails an unwelcome degree of opacity and
compromises performance, especially on problems that are inherently multi-step.
To address these limitations, we show how LMs can be made to perform faithful
multi-step reasoning via a process whose causal structure mirrors the
underlying logical structure of the problem. Our approach works by chaining
together reasoning steps, where each step results from calls to two fine-tuned
LMs, one for selection and one for inference, to produce a valid reasoning
trace. Our method carries out a beam search through the space of reasoning
traces to improve reasoning quality. We demonstrate the effectiveness of our
model on multi-step logical deduction and scientific question-answering,
showing that it outperforms baselines on final answer accuracy, and generates
humanly interpretable reasoning traces whose validity can be checked by the
user.",None,13655
177cf1fc-ebdf-4143-802f-43c3b6454015,Approximating Constraint Manifolds Using Generative Models for Sampling-Based Constrained Motion Planning,0.114776,"Sampling-based motion planning under task constraints is challenging because
the null-measure constraint manifold in the configuration space makes rejection
sampling extremely inefficient, if not impossible. This paper presents a
learning-based sampling strategy for constrained motion planning problems. We
investigate the use of two well-known deep generative models, the Conditional
Variational Autoencoder (CVAE) and the Conditional Generative Adversarial Net
(CGAN), to generate constraint-satisfying sample configurations. Instead of
precomputed graphs, we use generative models conditioned on constraint
parameters for approximating the constraint manifold. This approach allows for
the efficient drawing of constraint-satisfying samples online without any need
for modification of available sampling-based motion planning algorithms. We
evaluate the efficiency of these two generative models in terms of their
sampling accuracy and coverage of sampling distribution. Simulations and
experiments are also conducted for different constraint tasks on two robotic
platforms.",None,9510
f7c5d775-c6c4-47d1-88f7-9ba1752ffb48,Privacy-Preserving Model Upgrades with Bidirectional Compatible Training in Image Retrieval,0.447372,"The task of privacy-preserving model upgrades in image retrieval desires to
reap the benefits of rapidly evolving new models without accessing the raw
gallery images. A pioneering work introduced backward-compatible training,
where the new model can be directly deployed in a backfill-free manner, i.e.,
the new query can be directly compared to the old gallery features. Despite a
possible solution, its improvement in sequential model upgrades is gradually
limited by the fixed and under-quality old gallery embeddings. To this end, we
propose a new model upgrade paradigm, termed Bidirectional Compatible Training
(BiCT), which will upgrade the old gallery embeddings by forward-compatible
training towards the embedding space of the backward-compatible new model. We
conduct comprehensive experiments to verify the prominent improvement by BiCT
and interestingly observe that the inconspicuous loss weight of backward
compatibility actually plays an essential role for both backward and forward
retrieval performance. To summarize, we introduce a new and valuable problem
named privacy-preserving model upgrades, with a proper solution BiCT. Several
intriguing insights are further proposed to get the most out of our method.",None,-1
0956de76-1270-46b3-be12-acd1714e6db3,Towards customizable reinforcement learning agents: Enabling preference specification through online vocabulary expansion,0.291826,"There is a growing interest in developing automated agents that can work
alongside humans. In addition to completing the assigned task, such an agent
will undoubtedly be expected to behave in a manner that is preferred by the
human. This requires the human to communicate their preferences to the agent.
To achieve this, the current approaches either require the users to specify the
reward function or the preference is interactively learned from queries that
ask the user to compare behavior. The former approach can be challenging if the
internal representation used by the agent is inscrutable to the human while the
latter is unnecessarily cumbersome for the user if their preference can be
specified more easily in symbolic terms. In this work, we propose PRESCA
(PREference Specification through Concept Acquisition), a system that allows
users to specify their preferences in terms of concepts that they understand.
PRESCA maintains a set of such concepts in a shared vocabulary. If the relevant
concept is not in the shared vocabulary, then it is learned. To make learning a
new concept more feedback efficient, PRESCA leverages causal associations
between the target concept and concepts that are already known. In addition, we
use a novel data augmentation approach to further reduce required feedback. We
evaluate PRESCA by using it on a Minecraft environment and show that it can
effectively align the agent with the user's preference.",None,17546
48e2481f-ff52-4c83-8bf2-88b965db5749,What do tokens know about their characters and how do they know it?,0.873198,"Pre-trained language models (PLMs) that use subword tokenization schemes can
succeed at a variety of language tasks that require character-level
information, despite lacking explicit access to the character composition of
tokens. Here, studying a range of models (e.g., GPT- J, BERT, RoBERTa, GloVe),
we probe what word pieces encode about character-level information by training
classifiers to predict the presence or absence of a particular alphabetical
character in a token, based on its embedding (e.g., probing whether the model
embedding for ""cat"" encodes that it contains the character ""a""). We find that
these models robustly encode character-level information and, in general,
larger models perform better at the task. We show that these results generalize
to characters from non-Latin alphabets (Arabic, Devanagari, and Cyrillic).
Then, through a series of experiments and analyses, we investigate the
mechanisms through which PLMs acquire English-language character information
during training and argue that this knowledge is acquired through multiple
phenomena, including a systematic relationship between particular characters
and particular parts of speech, as well as natural variability in the
tokenization of related strings.",https://github.com/ayushk4/character-probing-pytorch,-1
6522d3ae-56dd-448f-bd88-a451df7e35f9,Memorizing Transformers,0.746492,"Language models typically need to be trained or finetuned in order to acquire
new knowledge, which involves updating their weights. We instead envision
language models that can simply read and memorize new data at inference time,
thus acquiring new knowledge immediately. In this work, we extend language
models with the ability to memorize the internal representations of past
inputs. We demonstrate that an approximate kNN lookup into a non-differentiable
memory of recent (key, value) pairs improves language modeling across various
benchmarks and tasks, including generic webtext (C4), math papers (arXiv),
books (PG-19), code (Github), as well as formal theorems (Isabelle). We show
that the performance steadily improves when we increase the size of memory up
to 262K tokens. On benchmarks including code and mathematics, we find that the
model is capable of making use of newly defined functions and theorems during
test time.",None,-1
1dae1465-138c-4a23-b0ec-84dfcf005d4e,Using Argumentation Schemes to Model Legal Reasoning,0.106144,"We present argumentation schemes to model reasoning with legal cases. We
provide schemes for each of the three stages that take place after the facts
are established: factor ascription, issue resolution and outcome determination.
The schemes are illustrated with examples from a specific legal domain, US
Trade Secrets law, and the wider applicability of these schemes is discussed.",None,-1
36e55999-1663-424a-b9cf-0298c3298505,"Less Data, More Knowledge: Building Next Generation Semantic Communication Networks",0.999941,"Semantic communication is viewed as a revolutionary paradigm that can
potentially transform how we design and operate wireless communication systems.
However, despite a recent surge of research activities in this area, the
research landscape remains limited. In this tutorial, we present the first
rigorous vision of a scalable end-to-end semantic communication network that is
founded on novel concepts from artificial intelligence (AI), causal reasoning,
and communication theory. We first discuss how the design of semantic
communication networks requires a move from data-driven networks towards
knowledge-driven ones. Subsequently, we highlight the necessity of creating
semantic representations of data that satisfy the key properties of minimalism,
generalizability, and efficiency so as to do more with less. We then explain
how those representations can form the basis a so-called semantic language. By
using semantic representation and languages, we show that the traditional
transmitter and receiver now become a teacher and apprentice. Then, we define
the concept of reasoning by investigating the fundamentals of causal
representation learning and their role in designing semantic communication
networks. We demonstrate that reasoning faculties are majorly characterized by
the ability to capture causal and associational relationships in datastreams.
For such reasoning-driven networks, we propose novel and essential semantic
communication metrics that include new ""reasoning capacity"" measures that could
go beyond Shannon's bound to capture the convergence of computing and
communication. Finally, we explain how semantic communications can be scaled to
large-scale networks (6G and beyond). In a nutshell, we expect this tutorial to
provide a comprehensive reference on how to properly build, analyze, and deploy
future semantic communication networks.",None,70013
57cce177-4e92-4c4e-b406-774e3cda46f1,Arbitrary-Scale Image Synthesis,0.453418,"Positional encodings have enabled recent works to train a single adversarial
network that can generate images of different scales. However, these approaches
are either limited to a set of discrete scales or struggle to maintain good
perceptual quality at the scales for which the model is not trained explicitly.
We propose the design of scale-consistent positional encodings invariant to our
generator's layers transformations. This enables the generation of
arbitrary-scale images even at scales unseen during training. Moreover, we
incorporate novel inter-scale augmentations into our pipeline and partial
generation training to facilitate the synthesis of consistent images at
arbitrary scales. Lastly, we show competitive results for a continuum of scales
on various commonly used datasets for image synthesis.",https://github.com/open-mmlab/mmgeneration,-1
45c65db2-9e56-4876-8b80-bd290cca8a68,Grammar-Based Grounded Lexicon Learning,0.944362,"We present Grammar-Based Grounded Lexicon Learning (G2L2), a lexicalist
approach toward learning a compositional and grounded meaning representation of
language from grounded data, such as paired images and texts. At the core of
G2L2 is a collection of lexicon entries, which map each word to a tuple of a
syntactic type and a neuro-symbolic semantic program. For example, the word
shiny has a syntactic type of adjective; its neuro-symbolic semantic program
has the symbolic form {\lambda}x. filter(x, SHINY), where the concept SHINY is
associated with a neural network embedding, which will be used to classify
shiny objects. Given an input sentence, G2L2 first looks up the lexicon entries
associated with each token. It then derives the meaning of the sentence as an
executable neuro-symbolic program by composing lexical meanings based on
syntax. The recovered meaning programs can be executed on grounded inputs. To
facilitate learning in an exponentially-growing compositional space, we
introduce a joint parsing and expected execution algorithm, which does local
marginalization over derivations to reduce the training time. We evaluate G2L2
on two domains: visual reasoning and language-driven navigation. Results show
that G2L2 can generalize from small amounts of data to novel compositions of
words.",None,-1
3a28ab66-a454-42f6-8f0e-2a79c275df6e,SumREN: Summarizing Reported Speech about Events in News,0.558095,"A primary objective of news articles is to establish the factual record for
an event, frequently achieved by conveying both the details of the specified
event (i.e., the 5 Ws; Who, What, Where, When and Why regarding the event) and
how people reacted to it (i.e., reported statements). However, existing work on
news summarization almost exclusively focuses on the event details. In this
work, we propose the novel task of summarizing the reactions of different
speakers, as expressed by their reported statements, to a given event. To this
end, we create a new multi-document summarization benchmark, SUMREN, comprising
745 summaries of reported statements from various public figures obtained from
633 news articles discussing 132 events. We propose an automatic silver
training data generation approach for our task, which helps smaller models like
BART achieve GPT-3 level performance on this task. Finally, we introduce a
pipeline-based framework for summarizing reported speech, which we empirically
show to generate summaries that are more abstractive and factual than baseline
query-focused summarization approaches.",https://github.com/amazon-science/SumREN,-1
4199d0f8-edda-460c-bd39-a58ea8f1ed23,3D Moments from Near-Duplicate Photos,0.196075,"We introduce 3D Moments, a new computational photography effect. As input we
take a pair of near-duplicate photos, i.e., photos of moving subjects from
similar viewpoints, common in people's photo collections. As output, we produce
a video that smoothly interpolates the scene motion from the first photo to the
second, while also producing camera motion with parallax that gives a
heightened sense of 3D. To achieve this effect, we represent the scene as a
pair of feature-based layered depth images augmented with scene flow. This
representation enables motion interpolation along with independent control of
the camera viewpoint. Our system produces photorealistic space-time videos with
motion parallax and scene dynamics, while plausibly recovering regions occluded
in the original views. We conduct extensive experiments demonstrating superior
performance over baselines on public datasets and in-the-wild photos. Project
page: https://3d-moments.github.io/",https://3d-moments.github.io/,-1
7f4dc28b-4cba-47d4-a545-15df9b050617,Entailer: Answering Questions with Faithful and Truthful Chains of Reasoning,0.546475,"Our goal is a question-answering (QA) system that can show how its answers
are implied by its own internal beliefs via a systematic chain of reasoning.
Such a capability would allow better understanding of why a model produced the
answer it did. Our approach is to recursively combine a trained
backward-chaining model, capable of generating a set of premises entailing an
answer hypothesis, with a verifier that checks that the model itself believes
those premises (and the entailment itself) through self-querying. To our
knowledge, this is the first system to generate multistep chains that are both
faithful (the answer follows from the reasoning) and truthful (the chain
reflects the system's own internal beliefs). In evaluation using two different
datasets, users judge that a majority (70%+) of generated chains clearly show
how an answer follows from a set of facts - substantially better than a
high-performance baseline - while preserving answer accuracy. By materializing
model beliefs that systematically support an answer, new opportunities arise
for understanding the model's system of belief, and diagnosing and correcting
its misunderstandings when an answer is wrong.",None,-1
536305f6-58c2-44b0-bf08-c689ea358bb5,Transformer-based Entity Typing in Knowledge Graphs,0.741669,"We investigate the knowledge graph entity typing task which aims at inferring
plausible entity types. In this paper, we propose a novel Transformer-based
Entity Typing (TET) approach, effectively encoding the content of neighbors of
an entity. More precisely, TET is composed of three different mechanisms: a
local transformer allowing to infer missing types of an entity by independently
encoding the information provided by each of its neighbors; a global
transformer aggregating the information of all neighbors of an entity into a
single long sequence to reason about more complex entity types; and a context
transformer integrating neighbors content based on their contribution to the
type inference through information exchange between neighbor pairs.
Furthermore, TET uses information about class membership of types to
semantically strengthen the representation of an entity. Experiments on two
real-world datasets demonstrate the superior performance of TET compared to the
state-of-the-art.",https://github.com/zhiweihu1103/ET-TET,-1
a1d78bc0-c9f9-43b2-9096-9bf9304002c5,Multi-View Object Pose Refinement With Differentiable Renderer,0.491179,"This paper introduces a novel multi-view 6 DoF object pose refinement
approach focusing on improving methods trained on synthetic data. It is based
on the DPOD detector, which produces dense 2D-3D correspondences between the
model vertices and the image pixels in each frame. We have opted for the use of
multiple frames with known relative camera transformations, as it allows
introduction of geometrical constraints via an interpretable ICP-like loss
function. The loss function is implemented with a differentiable renderer and
is optimized iteratively. We also demonstrate that a full detection and
refinement pipeline, which is trained solely on synthetic data, can be used for
auto-labeling real data. We perform quantitative evaluation on LineMOD,
Occlusion, Homebrewed and YCB-V datasets and report excellent performance in
comparison to the state-of-the-art methods trained on the synthetic and real
data. We demonstrate empirically that our approach requires only a few frames
and is robust to close camera locations and noise in extrinsic camera
calibration, making its practical usage easier and more ubiquitous.",None,-1
86f7801d-dde4-4b45-8675-3e8f5130edf8,Measuring Cognitive Workload Using Multimodal Sensors,0.422435,"This study aims to identify a set of indicators to estimate cognitive
workload using a multimodal sensing approach and machine learning. A set of
three cognitive tests were conducted to induce cognitive workload in twelve
participants at two levels of task difficulty (Easy and Hard). Four sensors
were used to measure the participants' physiological change, including,
Electrocardiogram (ECG), electrodermal activity (EDA), respiration (RESP), and
blood oxygen saturation (SpO2). To understand the perceived cognitive workload,
NASA-TLX was used after each test and analysed using Chi-Square test. Three
well-know classifiers (LDA, SVM, and DT) were trained and tested independently
using the physiological data. The statistical analysis showed that
participants' perceived cognitive workload was significantly different
(p<0.001) between the tests, which demonstrated the validity of the
experimental conditions to induce different cognitive levels. Classification
results showed that a fusion of ECG and EDA presented good discriminating power
(acc=0.74) for cognitive workload detection. This study provides preliminary
results in the identification of a possible set of indicators of cognitive
workload. Future work needs to be carried out to validate the indicators using
more realistic scenarios and with a larger population.",None,-1
b1d3e427-a460-42ac-a157-e2275e313a57,An Intelligent Self-driving Truck System For Highway Transportation,0.658314,"Recently, there have been many advances in autonomous driving society,
attracting a lot of attention from academia and industry. However, existing
works mainly focus on cars, extra development is still required for
self-driving truck algorithms and models. In this paper, we introduce an
intelligent self-driving truck system. Our presented system consists of three
main components, 1) a realistic traffic simulation module for generating
realistic traffic flow in testing scenarios, 2) a high-fidelity truck model
which is designed and evaluated for mimicking real truck response in real-world
deployment, 3) an intelligent planning module with learning-based decision
making algorithm and multi-mode trajectory planner, taking into account the
truck's constraints, road slope changes, and the surrounding traffic flow. We
provide quantitative evaluations for each component individually to demonstrate
the fidelity and performance of each part. We also deploy our proposed system
on a real truck and conduct real world experiments which shows our system's
capacity of mitigating sim-to-real gap. Our code is available at
https://github.com/InceptioResearch/IITS",https://github.com/InceptioResearch/IITS,-1
d6237d87-93c7-4e90-99f2-950687c7dfc7,A Two-Stage Efficient 3-D CNN Framework for EEG Based Emotion Recognition,0.345428,"This paper proposes a novel two-stage framework for emotion recognition using
EEG data that outperforms state-of-the-art models while keeping the model size
small and computationally efficient. The framework consists of two stages; the
first stage involves constructing efficient models named EEGNet, which is
inspired by the state-of-the-art efficient architecture and employs
inverted-residual blocks that contain depthwise separable convolutional layers.
The EEGNet models on both valence and arousal labels achieve the average
classification accuracy of 90%, 96.6%, and 99.5% with only 6.4k, 14k, and 25k
parameters, respectively. In terms of accuracy and storage cost, these models
outperform the previous state-of-the-art result by up to 9%. In the second
stage, we binarize these models to further compress them and deploy them easily
on edge devices. Binary Neural Networks (BNNs) typically degrade model
accuracy. We improve the EEGNet binarized models in this paper by introducing
three novel methods and achieving a 20\% improvement over the baseline binary
models. The proposed binarized EEGNet models achieve accuracies of 81%, 95%,
and 99% with storage costs of 0.11Mbits, 0.28Mbits, and 0.46Mbits,
respectively. Those models help deploy a precise human emotion recognition
system on the edge environment.",None,-1
a761e557-5d89-43fa-81b7-c8a7d71a2a9c,Full-Text Argumentation Mining on Scientific Publications,0.476315,"Scholarly Argumentation Mining (SAM) has recently gained attention due to its
potential to help scholars with the rapid growth of published scientific
literature. It comprises two subtasks: argumentative discourse unit recognition
(ADUR) and argumentative relation extraction (ARE), both of which are
challenging since they require e.g. the integration of domain knowledge, the
detection of implicit statements, and the disambiguation of argument structure.
While previous work focused on dataset construction and baseline methods for
specific document sections, such as abstract or results, full-text scholarly
argumentation mining has seen little progress. In this work, we introduce a
sequential pipeline model combining ADUR and ARE for full-text SAM, and provide
a first analysis of the performance of pretrained language models (PLMs) on
both subtasks. We establish a new SotA for ADUR on the Sci-Arg corpus,
outperforming the previous best reported result by a large margin (+7% F1). We
also present the first results for ARE, and thus for the full AM pipeline, on
this benchmark dataset. Our detailed error analysis reveals that non-contiguous
ADUs as well as the interpretation of discourse connectors pose major
challenges and that data annotation needs to be more consistent.",https://github.com/DFKI-NLP/sam,-1
4e13b173-0742-4db9-8a44-9db4d1f5c011,Evaluating Feature Attribution Methods in the Image Domain,0.225253,"Feature attribution maps are a popular approach to highlight the most
important pixels in an image for a given prediction of a model. Despite a
recent growth in popularity and available methods, little attention is given to
the objective evaluation of such attribution maps. Building on previous work in
this domain, we investigate existing metrics and propose new variants of
metrics for the evaluation of attribution maps. We confirm a recent finding
that different attribution metrics seem to measure different underlying
concepts of attribution maps, and extend this finding to a larger selection of
attribution metrics. We also find that metric results on one dataset do not
necessarily generalize to other datasets, and methods with desirable
theoretical properties such as DeepSHAP do not necessarily outperform
computationally cheaper alternatives. Based on these findings, we propose a
general benchmarking approach to identify the ideal feature attribution method
for a given use case. Implementations of attribution metrics and our
experiments are available online.",https://github.com/zoeparman/benchmark-general-imaging,-1
89a08fae-fb3d-4089-9d6c-beb0aa806cc9,Knowledge-grounded Dialog State Tracking,0.317166,"Knowledge (including structured knowledge such as schema and ontology, and
unstructured knowledge such as web corpus) is a critical part of dialog
understanding, especially for unseen tasks and domains. Traditionally, such
domain-specific knowledge is encoded implicitly into model parameters for the
execution of downstream tasks, which makes training inefficient. In addition,
such models are not easily transferable to new tasks with different schemas. In
this work, we propose to perform dialog state tracking grounded on knowledge
encoded externally. We query relevant knowledge of various forms based on the
dialog context where such information can ground the prediction of dialog
states. We demonstrate superior performance of our proposed method over strong
baselines, especially in the few-shot learning setting.",https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md,-1
c6791eee-42a3-45a2-8490-d8d1a762279c,Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions,0.999957,"Prompting-based large language models (LLMs) are surprisingly powerful at
generating natural language reasoning steps or Chains-of-Thoughts (CoT) for
multi-step question answering (QA). They struggle, however, when the necessary
knowledge is either unavailable to the LLM or not up-to-date within its
parameters. While using the question to retrieve relevant text from an external
knowledge source helps LLMs, we observe that this one-step retrieve-and-read
approach is insufficient for multi-step QA. Here, \textit{what to retrieve}
depends on \textit{what has already been derived}, which in turn may depend on
\textit{what was previously retrieved}. To address this, we propose IRCoT, a
new approach for multi-step QA that interleaves retrieval with steps
(sentences) in a CoT, guiding the retrieval with CoT and in turn using
retrieved results to improve CoT. Using IRCoT with GPT3 substantially improves
retrieval (up to 21 points) as well as downstream QA (up to 15 points) on four
datasets: HotpotQA, 2WikiMultihopQA, MuSiQue, and IIRC. We observe similar
substantial gains in out-of-distribution (OOD) settings as well as with much
smaller models such as Flan-T5-large without additional training. IRCoT reduces
model hallucination, resulting in factually more accurate CoT reasoning. Code,
data, and prompts are available at \url{https://github.com/stonybrooknlp/ircot}",https://github.com/stonybrooknlp/ircot,-1
e5b5680d-39da-48af-9856-69c6fcc8c7ad,R2-Trans:Fine-Grained Visual Categorization with Redundancy Reduction,0.467106,"Fine-grained visual categorization (FGVC) aims to discriminate similar
subcategories, whose main challenge is the large intraclass diversities and
subtle inter-class differences. Existing FGVC methods usually select
discriminant regions found by a trained model, which is prone to neglect other
potential discriminant information. On the other hand, the massive interactions
between the sequence of image patches in ViT make the resulting class-token
contain lots of redundant information, which may also impacts FGVC performance.
In this paper, we present a novel approach for FGVC, which can simultaneously
make use of partial yet sufficient discriminative information in environmental
cues and also compress the redundant information in class-token with respect to
the target. Specifically, our model calculates the ratio of high-weight regions
in a batch, adaptively adjusts the masking threshold and achieves moderate
extraction of background information in the input space. Moreover, we also use
the Information Bottleneck~(IB) approach to guide our network to learn a
minimum sufficient representations in the feature space. Experimental results
on three widely-used benchmark datasets verify that our approach can achieve
outperforming performance than other state-of-the-art approaches and baseline
models.",None,-1
81d1fa03-3ce8-4f02-b068-c249aad5cae3,Multilingual Communication System with Deaf Individuals Utilizing Natural and Visual Languages,0.177328,"According to the World Federation of the Deaf, more than two hundred sign
languages exist. Therefore, it is challenging to understand deaf individuals,
even proficient sign language users, resulting in a barrier between the deaf
community and the rest of society. To bridge this language barrier, we propose
a novel multilingual communication system, namely MUGCAT, to improve the
communication efficiency of sign language users. By converting recognized
specific hand gestures into expressive pictures, which is universal usage and
language independence, our MUGCAT system significantly helps deaf people convey
their thoughts. To overcome the limitation of sign language usage, which is
mostly impossible to translate into complete sentences for ordinary people, we
propose to reconstruct meaningful sentences from the incomplete translation of
sign language. We also measure the semantic similarity of generated sentences
with fragmented recognized hand gestures to keep the original meaning.
Experimental results show that the proposed system can work in a real-time
manner and synthesize exquisite stunning illustrations and meaningful sentences
from a few hand gestures of sign language. This proves that our MUGCAT has
promising potential in assisting deaf communication.",None,-1
33d20390-66f7-4265-a385-25cb04f31527,RestoreFormer: High-Quality Blind Face Restoration from Undegraded Key-Value Pairs,0.855099,"Blind face restoration is to recover a high-quality face image from unknown
degradations. As face image contains abundant contextual information, we
propose a method, RestoreFormer, which explores fully-spatial attentions to
model contextual information and surpasses existing works that use local
operators. RestoreFormer has several benefits compared to prior arts. First,
unlike the conventional multi-head self-attention in previous Vision
Transformers (ViTs), RestoreFormer incorporates a multi-head cross-attention
layer to learn fully-spatial interactions between corrupted queries and
high-quality key-value pairs. Second, the key-value pairs in ResotreFormer are
sampled from a reconstruction-oriented high-quality dictionary, whose elements
are rich in high-quality facial features specifically aimed for face
reconstruction, leading to superior restoration results. Third, RestoreFormer
outperforms advanced state-of-the-art methods on one synthetic dataset and
three real-world datasets, as well as produces images with better visual
quality.",https://github.com/wzhouxiff/RestoreFormer.git,53489
d987055d-9fe1-44a7-93a1-79abc43ef8bc,Overview of The MediaEval 2022 Predicting Video Memorability Task,0.406176,"This paper describes the 5th edition of the Predicting Video Memorability
Task as part of MediaEval2022. This year we have reorganised and simplified the
task in order to lubricate a greater depth of inquiry. Similar to last year,
two datasets are provided in order to facilitate generalisation, however, this
year we have replaced the TRECVid2019 Video-to-Text dataset with the VideoMem
dataset in order to remedy underlying data quality issues, and to prioritise
short-term memorability prediction by elevating the Memento10k dataset as the
primary dataset. Additionally, a fully fledged electroencephalography
(EEG)-based prediction sub-task is introduced. In this paper, we outline the
core facets of the task and its constituent sub-tasks; describing the datasets,
evaluation metrics, and requirements for participant submissions.",None,-1
b5d5208b-9e62-42b9-8f9d-e496473c22f9,Algorithms for Weighted Pushdown Automata,0.872058,"Weighted pushdown automata (WPDAs) are at the core of many natural language
processing tasks, like syntax-based statistical machine translation and
transition-based dependency parsing. As most existing dynamic programming
algorithms are designed for context-free grammars (CFGs), algorithms for PDAs
often resort to a PDA-to-CFG conversion. In this paper, we develop novel
algorithms that operate directly on WPDAs. Our algorithms are inspired by
Lang's algorithm, but use a more general definition of pushdown automaton and
either reduce the space requirements by a factor of $|\Gamma|$ (the size of the
stack alphabet) or reduce the runtime by a factor of more than $|Q|$ (the
number of states). When run on the same class of PDAs as Lang's algorithm, our
algorithm is both more space-efficient by a factor of $|\Gamma|$ and more
time-efficient by a factor of $|Q| \cdot |\Gamma|$.",https://github.com/rycolab/wpda,-1
36936b4f-e605-4773-9750-c899df47704f,Counterfactual Plans under Distributional Ambiguity,0.535598,"Counterfactual explanations are attracting significant attention due to the
flourishing applications of machine learning models in consequential domains. A
counterfactual plan consists of multiple possibilities to modify a given
instance so that the model's prediction will be altered. As the predictive
model can be updated subject to the future arrival of new data, a
counterfactual plan may become ineffective or infeasible with respect to the
future values of the model parameters. In this work, we study the
counterfactual plans under model uncertainty, in which the distribution of the
model parameters is partially prescribed using only the first- and
second-moment information. First, we propose an uncertainty quantification tool
to compute the lower and upper bounds of the probability of validity for any
given counterfactual plan. We then provide corrective methods to adjust the
counterfactual plan to improve the validity measure. The numerical experiments
validate our bounds and demonstrate that our correction increases the
robustness of the counterfactual plans in different real-world datasets.",https://github.com/ngocbh/COPA,-1
8b4dc4f9-56db-4224-9bf8-e8655d1347ba,Statistical Attention Localization (SAL): Methodology and Application to Object Classification,0.042732,"A statistical attention localization (SAL) method is proposed to facilitate
the object classification task in this work. SAL consists of three steps: 1)
preliminary attention window selection via decision statistics, 2) attention
map refinement, and 3) rectangular attention region finalization. SAL computes
soft-decision scores of local squared windows and uses them to identify salient
regions in Step 1. To accommodate object of various sizes and shapes, SAL
refines the preliminary result and obtain an attention map of more flexible
shape in Step 2. Finally, SAL yields a rectangular attention region using the
refined attention map and bounding box regularization in Step 3. As an
application, we adopt E-PixelHop, which is an object classification solution
based on successive subspace learning (SSL), as the baseline. We apply SAL so
as to obtain a cropped-out and resized attention region as an alternative
input. Classification results of the whole image as well as the attention
region are ensembled to achieve the highest classification accuracy.
Experiments on the CIFAR-10 dataset are given to demonstrate the advantage of
the SAL-assisted object classification method.",None,-1
6ec2a947-5e21-4a01-9c4b-c81179736ed0,Power Grid Congestion Management via Topology Optimization with AlphaZero,0.902478,"The energy sector is facing rapid changes in the transition towards clean
renewable sources. However, the growing share of volatile, fluctuating
renewable generation such as wind or solar energy has already led to an
increase in power grid congestion and network security concerns. Grid operators
mitigate these by modifying either generation or demand (redispatching,
curtailment, flexible loads). Unfortunately, redispatching of fossil generators
leads to excessive grid operation costs and higher emissions, which is in
direct opposition to the decarbonization of the energy sector. In this paper,
we propose an AlphaZero-based grid topology optimization agent as a non-costly,
carbon-free congestion management alternative. Our experimental evaluation
confirms the potential of topology optimization for power grid operation,
achieves a reduction of the average amount of required redispatching by 60%,
and shows the interoperability with traditional congestion management methods.
Our approach also ranked 1st in the WCCI 2022 Learning to Run a Power Network
(L2RPN) competition. Based on our findings, we identify and discuss open
research problems as well as technical challenges for a productive system on a
real power grid.",https://github.com/enlite-ai/maze-l2rpn-2022-submission,-1
a7a61e5e-ea34-465e-8d90-3ab3bec08412,Zero-shot Cross-lingual Transfer is Under-specified Optimization,0.31641,"Pretrained multilingual encoders enable zero-shot cross-lingual transfer, but
often produce unreliable models that exhibit high performance variance on the
target language. We postulate that this high variance results from zero-shot
cross-lingual transfer solving an under-specified optimization problem. We show
that any linear-interpolated model between the source language monolingual
model and source + target bilingual model has equally low source language
generalization error, yet the target language generalization error reduces
smoothly and linearly as we move from the monolingual to bilingual model,
suggesting that the model struggles to identify good solutions for both source
and target languages using the source language alone. Additionally, we show
that zero-shot solution lies in non-flat region of target language error
generalization surface, causing the high variance.",https://github.com/shijie-wu/crosslingual-nlp,-1
3f51a76d-c5d6-4239-851b-8ab0f9d4346a,Registering Explicit to Implicit: Towards High-Fidelity Garment mesh Reconstruction from Single Images,0.869975,"Fueled by the power of deep learning techniques and implicit shape learning,
recent advances in single-image human digitalization have reached unprecedented
accuracy and could recover fine-grained surface details such as garment
wrinkles. However, a common problem for the implicit-based methods is that they
cannot produce separated and topology-consistent mesh for each garment piece,
which is crucial for the current 3D content creation pipeline. To address this
issue, we proposed a novel geometry inference framework ReEF that reconstructs
topology-consistent layered garment mesh by registering the explicit garment
template to the whole-body implicit fields predicted from single images.
Experiments demonstrate that our method notably outperforms its counterparts on
single-image layered garment reconstruction and could bring high-quality
digital assets for further content creation.",None,-1
5bb86b4a-0546-4c21-bfab-7514559ab9c3,Supporting Medical Relation Extraction via Causality-Pruned Semantic Dependency Forest,0.437841,"Medical Relation Extraction (MRE) task aims to extract relations between
entities in medical texts. Traditional relation extraction methods achieve
impressive success by exploring the syntactic information, e.g., dependency
tree. However, the quality of the 1-best dependency tree for medical texts
produced by an out-of-domain parser is relatively limited so that the
performance of medical relation extraction method may degenerate. To this end,
we propose a method to jointly model semantic and syntactic information from
medical texts based on causal explanation theory. We generate dependency
forests consisting of the semantic-embedded 1-best dependency tree. Then, a
task-specific causal explainer is adopted to prune the dependency forests,
which are further fed into a designed graph convolutional network to learn the
corresponding representation for downstream task. Empirically, the various
comparisons on benchmark medical datasets demonstrate the effectiveness of our
model.",None,-1
976333ef-b10d-4332-bdc0-f07944ac1796,OPD: Single-view 3D Openable Part Detection,0.470841,"We address the task of predicting what parts of an object can open and how
they move when they do so. The input is a single image of an object, and as
output we detect what parts of the object can open, and the motion parameters
describing the articulation of each openable part. To tackle this task, we
create two datasets of 3D objects: OPDSynth based on existing synthetic
objects, and OPDReal based on RGBD reconstructions of real objects. We then
design OPDRCNN, a neural architecture that detects openable parts and predicts
their motion parameters. Our experiments show that this is a challenging task
especially when considering generalization across object categories, and the
limited amount of information in a single image. Our architecture outperforms
baselines and prior work especially for RGB image inputs. Short video summary
at https://www.youtube.com/watch?v=P85iCaD0rfc",https://github.com/facebookresearch/detectron2,-1
d06ee1dd-a20e-4c46-9408-089a2a113c4b,Attribute-based Representations for Accurate and Interpretable Video Anomaly Detection,0.779454,"Video anomaly detection (VAD) is a challenging computer vision task with many
practical applications. As anomalies are inherently ambiguous, it is essential
for users to understand the reasoning behind a system's decision in order to
determine if the rationale is sound. In this paper, we propose a simple but
highly effective method that pushes the boundaries of VAD accuracy and
interpretability using attribute-based representations. Our method represents
every object by its velocity and pose. The anomaly scores are computed using a
density-based approach. Surprisingly, we find that this simple representation
is sufficient to achieve state-of-the-art performance in ShanghaiTech, the
largest and most complex VAD dataset. Combining our interpretable
attribute-based representations with implicit, deep representation yields
state-of-the-art performance with a $99.1\%, 93.3\%$, and $85.9\%$ AUROC on
Ped2, Avenue, and ShanghaiTech, respectively. Our method is accurate,
interpretable, and easy to implement.",https://github.com/talreiss/Accurate-Interpretable-VAD,-1
5ed41d31-663d-4dad-9f0d-0c1165013c03,"Sampling-based inference for large linear models, with application to linearised Laplace",0.636314,"Large-scale linear models are ubiquitous throughout machine learning, with
contemporary application as surrogate models for neural network uncertainty
quantification; that is, the linearised Laplace method. Alas, the computational
cost associated with Bayesian linear models constrains this method's
application to small networks, small output spaces and small datasets. We
address this limitation by introducing a scalable sample-based Bayesian
inference method for conjugate Gaussian multi-output linear models, together
with a matching method for hyperparameter (regularisation) selection.
Furthermore, we use a classic feature normalisation method (the g-prior) to
resolve a previously highlighted pathology of the linearised Laplace method.
Together, these contributions allow us to perform linearised neural network
inference with ResNet-18 on CIFAR100 (11M parameters, 100 outputs x 50k
datapoints), with ResNet-50 on Imagenet (50M parameters, 1000 outputs x 1.2M
datapoints) and with a U-Net on a high-resolution tomographic reconstruction
task (2M parameters, 251k output~dimensions).",None,-1
8f11b222-822a-4207-871f-1a409abe1a0f,Informed Multi-context Entity Alignment,0.556485,"Entity alignment is a crucial step in integrating knowledge graphs (KGs) from
multiple sources. Previous attempts at entity alignment have explored different
KG structures, such as neighborhood-based and path-based contexts, to learn
entity embeddings, but they are limited in capturing the multi-context
features. Moreover, most approaches directly utilize the embedding similarity
to determine entity alignment without considering the global interaction among
entities and relations. In this work, we propose an Informed Multi-context
Entity Alignment (IMEA) model to address these issues. In particular, we
introduce Transformer to flexibly capture the relation, path, and neighborhood
contexts, and design holistic reasoning to estimate alignment probabilities
based on both embedding similarity and the relation/entity functionality. The
alignment evidence obtained from holistic reasoning is further injected back
into the Transformer via the proposed soft label editing to inform embedding
learning. Experimental results on several benchmark datasets demonstrate the
superiority of our IMEA model compared with existing state-of-the-art entity
alignment methods.",https://github.com/JadeXIN/IMEA,-1
0a338d1d-eaa7-4137-9cef-0c0d39c9843a,Motion Prediction via Joint Dependency Modeling in Phase Space,0.40532,"Motion prediction is a classic problem in computer vision, which aims at
forecasting future motion given the observed pose sequence. Various deep
learning models have been proposed, achieving state-of-the-art performance on
motion prediction. However, existing methods typically focus on modeling
temporal dynamics in the pose space. Unfortunately, the complicated and high
dimensionality nature of human motion brings inherent challenges for dynamic
context capturing. Therefore, we move away from the conventional pose based
representation and present a novel approach employing a phase space trajectory
representation of individual joints. Moreover, current methods tend to only
consider the dependencies between physically connected joints. In this paper,
we introduce a novel convolutional neural model to effectively leverage
explicit prior knowledge of motion anatomy, and simultaneously capture both
spatial and temporal information of joint trajectory dynamics. We then propose
a global optimization module that learns the implicit relationships between
individual joint features.
  Empirically, our method is evaluated on large-scale 3D human motion benchmark
datasets (i.e., Human3.6M, CMU MoCap). These results demonstrate that our
method sets the new state-of-the-art on the benchmark datasets. Our code will
be available at https://github.com/Pose-Group/TEID.",https://github.com/Pose-Group/TEID,3258
46dd9a15-5e88-4613-9975-614c4e650807,Backdoor Attack is a Devil in Federated GAN-based Medical Image Synthesis,0.564873,"Deep Learning-based image synthesis techniques have been applied in
healthcare research for generating medical images to support open research.
Training generative adversarial neural networks (GAN) usually requires large
amounts of training data. Federated learning (FL) provides a way of training a
central model using distributed data from different medical institutions while
keeping raw data locally. However, FL is vulnerable to backdoor attack, an
adversarial by poisoning training data, given the central server cannot access
the original data directly. Most backdoor attack strategies focus on
classification models and centralized domains. In this study, we propose a way
of attacking federated GAN (FedGAN) by treating the discriminator with a
commonly used data poisoning strategy in backdoor attack classification models.
We demonstrate that adding a small trigger with size less than 0.5 percent of
the original image size can corrupt the FL-GAN model. Based on the proposed
attack, we provide two effective defense strategies: global malicious detection
and local training regularization. We show that combining the two defense
strategies yields a robust medical image generation.",None,-1
53c57875-4093-4dce-b7f2-bbabe1cf54d0,"""Dummy Grandpa, do you know anything?"": Identifying and Characterizing Ad hominem Fallacy Usage in the Wild",0.164708,"Today, participating in discussions on online forums is extremely commonplace
and these discussions have started rendering a strong influence on the overall
opinion of online users. Naturally, twisting the flow of the argument can have
a strong impact on the minds of naive users, which in the long run might have
socio-political ramifications, for example, winning an election or spreading
targeted misinformation. Thus, these platforms are potentially highly
vulnerable to malicious players who might act individually or as a cohort to
breed fallacious arguments with a motive to sway public opinion. Ad hominem
arguments are one of the most effective forms of such fallacies. Although a
simple fallacy, it is effective enough to sway public debates in offline world
and can be used as a precursor to shutting down the voice of opposition by
slander.
  In this work, we take a first step in shedding light on the usage of ad
hominem fallacies in the wild. First, we build a powerful ad hominem detector
with high accuracy (F1 more than 83%, showing a significant improvement over
prior work), even for datasets for which annotated instances constitute a very
small fraction. We then used our detector on 265k arguments collected from the
online debate forum - CreateDebate. Our crowdsourced surveys validate our
in-the-wild predictions on CreateDebate data (94% match with manual
annotation). Our analysis revealed that a surprising 31.23% of CreateDebate
content contains ad hominem fallacy, and a cohort of highly active users post
significantly more ad hominem to suppress opposing views. Then, our temporal
analysis revealed that ad hominem argument usage increased significantly since
the 2016 US Presidential election, not only for topics like Politics, but also
for Science and Law. We conclude by discussing important implications of our
work to detect and defend against ad hominem fallacies.",None,-1
a516e3cc-c80f-48ff-900c-75a2e38b348c,BadPrompt: Backdoor Attacks on Continuous Prompts,0.861906,"The prompt-based learning paradigm has gained much research attention
recently. It has achieved state-of-the-art performance on several NLP tasks,
especially in the few-shot scenarios. While steering the downstream tasks, few
works have been reported to investigate the security problems of the
prompt-based models. In this paper, we conduct the first study on the
vulnerability of the continuous prompt learning algorithm to backdoor attacks.
We observe that the few-shot scenarios have posed a great challenge to backdoor
attacks on the prompt-based models, limiting the usability of existing NLP
backdoor methods. To address this challenge, we propose BadPrompt, a
lightweight and task-adaptive algorithm, to backdoor attack continuous prompts.
Specially, BadPrompt first generates candidate triggers which are indicative
for predicting the targeted label and dissimilar to the samples of the
non-targeted labels. Then, it automatically selects the most effective and
invisible trigger for each sample with an adaptive trigger optimization
algorithm. We evaluate the performance of BadPrompt on five datasets and two
continuous prompt models. The results exhibit the abilities of BadPrompt to
effectively attack continuous prompts while maintaining high performance on the
clean test sets, outperforming the baseline models by a large margin. The
source code of BadPrompt is publicly available at
https://github.com/papersPapers/BadPrompt.",https://github.com/papersPapers/BadPrompt,-1
0b03ebc8-0c60-4eda-848e-d0210badf4f4,Exploring Diversity-based Active Learning for 3D Object Detection in Autonomous Driving,0.443109,"3D object detection has recently received much attention due to its great
potential in autonomous vehicle (AV). The success of deep learning based object
detectors relies on the availability of large-scale annotated datasets, which
is time-consuming and expensive to compile, especially for 3D bounding box
annotation. In this work, we investigate diversity-based active learning (AL)
as a potential solution to alleviate the annotation burden. Given limited
annotation budget, only the most informative frames and objects are
automatically selected for human to annotate. Technically, we take the
advantage of the multimodal information provided in an AV dataset, and propose
a novel acquisition function that enforces spatial and temporal diversity in
the selected samples. We benchmark the proposed method against other AL
strategies under realistic annotation cost measurement, where the realistic
costs for annotating a frame and a 3D bounding box are both taken into
consideration. We demonstrate the effectiveness of the proposed method on the
nuScenes dataset and show that it outperforms existing AL strategies
significantly.",https://github.com/poodarchu/Det3D,1317
8e383c86-2725-452f-8f59-8030a4261e9d,Point Cloud Registration of non-rigid objects in sparse 3D Scans with applications in Mixed Reality,0.0823035,"Point Cloud Registration is the problem of aligning the corresponding points
of two 3D point clouds referring to the same object. The challenges include
dealing with noise and partial match of real-world 3D scans. For non-rigid
objects, there is an additional challenge of accounting for deformations in the
object shape that happen to the object in between the two 3D scans. In this
project, we study the problem of non-rigid point cloud registration for use
cases in the Augmented/Mixed Reality domain. We focus our attention on a
special class of non-rigid deformations that happen in rigid objects with parts
that move relative to one another about joints, for example, robots with hands
and machines with hinges. We propose an efficient and robust point-cloud
registration workflow for such objects and evaluate it on real-world data
collected using Microsoft Hololens 2, a leading Mixed Reality device.",https://github.com/rabbityl/lepard,-1
9ee64677-dae0-45cc-876d-07735c256346,On Vision Features in Multimodal Machine Translation,0.882987,"Previous work on multimodal machine translation (MMT) has focused on the way
of incorporating vision features into translation but little attention is on
the quality of vision models. In this work, we investigate the impact of vision
models on MMT. Given the fact that Transformer is becoming popular in computer
vision, we experiment with various strong models (such as Vision Transformer)
and enhanced features (such as object-detection and image captioning). We
develop a selective attention model to study the patch-level contribution of an
image in MMT. On detailed probing tasks, we find that stronger vision models
are helpful for learning translation from the visual modality. Our results also
suggest the need of carefully examining MMT models, especially when current
benchmarks are small-scale and biased. Our code could be found at
\url{https://github.com/libeineu/fairseq_mmt}.",https://github.com/libeineu/fairseq_mmt,-1
665b22f9-4f4d-4b8a-bd71-24aabe0fef08,A Time Series is Worth 64 Words: Long-term Forecasting with Transformers,1.0,"We propose an efficient design of Transformer-based models for multivariate
time series forecasting and self-supervised representation learning. It is
based on two key components: (i) segmentation of time series into
subseries-level patches which are served as input tokens to Transformer; (ii)
channel-independence where each channel contains a single univariate time
series that shares the same embedding and Transformer weights across all the
series. Patching design naturally has three-fold benefit: local semantic
information is retained in the embedding; computation and memory usage of the
attention maps are quadratically reduced given the same look-back window; and
the model can attend longer history. Our channel-independent patch time series
Transformer (PatchTST) can improve the long-term forecasting accuracy
significantly when compared with that of SOTA Transformer-based models. We also
apply our model to self-supervised pre-training tasks and attain excellent
fine-tuning performance, which outperforms supervised training on large
datasets. Transferring of masked pre-trained representation on one dataset to
others also produces SOTA forecasting accuracy. Code is available at:
https://github.com/yuqinie98/PatchTST.",None,-1
9c860c40-b483-457b-a419-89ce381b314e,A Perspective on K-12 AI Education,0.384484,"Artificial intelligence (AI), which enables machines to learn to perform a
task by training on diverse datasets, is one of the most revolutionary
developments in scientific history. Although AI and especially deep learning is
relatively new, it has already had transformative impact on medicine, biology,
transportation, entertainment, and beyond. As AI changes our daily lives at an
increasingly fast pace, we are challenged with preparing our society for an
AI-driven future. To this end, a critical step is to ensure an AI-ready
workforce through education. Advocates of beginning instruction of AI basics at
the K-12 level typically note benefits to the workforce, economy, and national
security. In this complementary perspective, we discuss why learning AI is
beneficial for motivating students and promoting creative thinking, and how to
develop a module-based approach that optimizes learning outcomes. We hope to
excite and engage more members of the education community to join the effort to
advance K-12 AI education in the USA and worldwide.",None,-1
4ad00a04-fa37-498e-9965-b9b13b749148,Safety Verification for Neural Networks Based on Set-boundary Analysis,0.416675,"Neural networks (NNs) are increasingly applied in safety-critical systems
such as autonomous vehicles. However, they are fragile and are often
ill-behaved. Consequently, their behaviors should undergo rigorous guarantees
before deployment in practice. In this paper we propose a set-boundary
reachability method to investigate the safety verification problem of NNs from
a topological perspective. Given an NN with an input set and a safe set, the
safety verification problem is to determine whether all outputs of the NN
resulting from the input set fall within the safe set. In our method, the
homeomorphism property of NNs is mainly exploited, which establishes a
relationship mapping boundaries to boundaries. The exploitation of this
property facilitates reachability computations via extracting subsets of the
input set rather than the entire input set, thus controlling the wrapping
effect in reachability analysis and facilitating the reduction of computation
burdens for safety verification. The homeomorphism property exists in some
widely used NNs such as invertible NNs. Notable representations are invertible
residual networks (i-ResNets) and Neural ordinary differential equations
(Neural ODEs). For these NNs, our set-boundary reachability method only needs
to perform reachability analysis on the boundary of the input set. For NNs
which do not feature this property with respect to the input set, we explore
subsets of the input set for establishing the local homeomorphism property, and
then abandon these subsets for reachability computations. Finally, some
examples demonstrate the performance of the proposed method.",https://github.com/laode2022/BoundaryNN,-1
1534019f-265e-4f26-9b45-8ec04d6f7549,Machine learning model to project the impact of Ukraine crisis,0.332383,"Russia's attack on Ukraine on Thursday 24 February 2022 hitched financial
markets and the increased geopolitical crisis. In this paper, we select some
main economic indexes, such as Gold, Oil (WTI), NDAQ, and known currency which
are involved in this crisis and try to find the quantitative effect of this war
on them. To quantify the war effect, we use the correlation feature and the
relationships between these economic indices, create datasets, and compare the
results of forecasts with real data. To study war effects, we use Machine
Learning Linear Regression. We carry on empirical experiments and perform on
these economic indices datasets to evaluate and predict this war tolls and its
effects on main economics indexes.",None,-1
097443f4-45fd-437d-b5f5-49154af7177e,PixelGame: Infrared small target segmentation as a Nash equilibrium,0.580486,"A key challenge of infrared small target segmentation (ISTS) is to balance
false negative pixels (FNs) and false positive pixels (FPs). Traditional
methods combine FNs and FPs into a single objective by weighted sum, and the
optimization process is decided by one actor. Minimizing FNs and FPs with the
same strategy leads to antagonistic decisions. To address this problem, we
propose a competitive game framework (pixelGame) from a novel perspective for
ISTS. In pixelGame, FNs and FPs are controlled by different player whose goal
is to minimize their own utility function. FNs-player and FPs-player are
designed with different strategies: One is to minimize FNs and the other is to
minimize FPs. The utility function drives the evolution of the two participants
in competition. We consider the Nash equilibrium of pixelGame as the optimal
solution. In addition, we propose maximum information modulation (MIM) to
highlight the tar-get information. MIM effectively focuses on the salient
region including small targets. Extensive experiments on two standard public
datasets prove the effectiveness of our method. Compared with other
state-of-the-art methods, our method achieves better performance in terms of
F1-measure (F1) and the intersection of union (IoU).",None,-1
5dca96e9-7aff-43c0-ae2e-72cd611db47b,Magpie: Automatically Tuning Static Parameters for Distributed File Systems using Deep Reinforcement Learning,0.597459,"Distributed file systems are widely used nowadays, yet using their default
configurations is often not optimal. At the same time, tuning configuration
parameters is typically challenging and time-consuming. It demands expertise
and tuning operations can also be expensive. This is especially the case for
static parameters, where changes take effect only after a restart of the system
or workloads. We propose a novel approach, Magpie, which utilizes deep
reinforcement learning to tune static parameters by strategically exploring and
exploiting configuration parameter spaces. To boost the tuning of the static
parameters, our method employs both server and client metrics of distributed
file systems to understand the relationship between static parameters and
performance. Our empirical evaluation results show that Magpie can noticeably
improve the performance of the distributed file system Lustre, where our
approach on average achieves 91.8% throughput gains against default
configuration after tuning towards single performance indicator optimization,
while it reaches 39.7% more throughput gains against the baseline.",https://github.com/dos-group/magpie,-1
30b93130-91ea-484c-9623-bd5fcac4954d,Normal and Visibility Estimation of Human Face from a Single Image,0.0309371,"Recent work on the intrinsic image of humans starts to consider the
visibility of incident illumination and encodes the light transfer function by
spherical harmonics. In this paper, we show that such a light transfer function
can be further decomposed into visibility and cosine terms related to surface
normal. Such decomposition allows us to recover the surface normal in addition
to visibility. We propose a deep learning-based approach with a reconstruction
loss for training on real-world images. Results show that compared with
previous works, the reconstruction of human face from our method better reveals
the surface normal and shading details especially around regions where
visibility effect is strong.",None,-1
2920a34d-0687-4f79-b37b-3b2548fb0aec,Privacy-Friendly Peer-to-Peer Energy Trading: A Game Theoretical Approach,0.362125,"In this paper, we propose a decentralized, privacy-friendly energy trading
platform (PFET) based on game theoretical approach - specifically Stackelberg
competition. Unlike existing trading schemes, PFET provides a competitive
market in which prices and demands are determined based on competition, and
computations are performed in a decentralized manner which does not rely on
trusted third parties. It uses homomorphic encryption cryptosystem to encrypt
sensitive information of buyers and sellers such as sellers$'$ prices and
buyers$'$ demands. Buyers calculate total demand on particular seller using an
encrypted data and sensitive buyer profile data is hidden from sellers. Hence,
privacy of both sellers and buyers is preserved. Through privacy analysis and
performance evaluation, we show that PFET preserves users$'$ privacy in an
efficient manner.",None,-1
5e7e08bf-5f7a-4786-b252-43a23049517c,Character-Aware Models Improve Visual Text Rendering,0.746574,"Current image generation models struggle to reliably produce well-formed
visual text. In this paper, we investigate a key contributing factor: popular
text-to-image models lack character-level input features, making it much harder
to predict a word's visual makeup as a series of glyphs. To quantify this
effect, we conduct a series of experiments comparing character-aware vs.
character-blind text encoders. In the text-only domain, we find that
character-aware models provide large gains on a novel spelling task
(WikiSpell). Applying our learnings to the visual domain, we train a suite of
image generation models, and show that character-aware variants outperform
their character-blind counterparts across a range of novel text rendering tasks
(our DrawText benchmark). Our models set a much higher state-of-the-art on
visual spelling, with 30+ point accuracy gains over competitors on rare words,
despite training on far fewer examples.",None,-1
910bcbe3-b454-424c-a1f0-19a1bfcd039f,Omni-Granular Ego-Semantic Propagation for Self-Supervised Graph Representation Learning,0.498948,"Unsupervised/self-supervised graph representation learning is critical for
downstream node- and graph-level classification tasks. Global structure of
graphs helps discriminating representations and existing methods mainly utilize
the global structure by imposing additional supervisions. However, their global
semantics are usually invariant for all nodes/graphs and they fail to
explicitly embed the global semantics to enrich the representations. In this
paper, we propose Omni-Granular Ego-Semantic Propagation for Self-Supervised
Graph Representation Learning (OEPG). Specifically, we introduce
instance-adaptive global-aware ego-semantic descriptors, leveraging the first-
and second-order feature differences between each node/graph and hierarchical
global clusters of the entire graph dataset. The descriptors can be explicitly
integrated into local graph convolution as new neighbor nodes. Besides, we
design an omni-granular normalization on the whole scales and hierarchies of
the ego-semantic to assign attentional weight to each descriptor from an
omni-granular perspective. Specialized pretext tasks and cross-iteration
momentum update are further developed for local-global mutual adaptation. In
downstream tasks, OEPG consistently achieves the best performance with a 2%~6%
accuracy gain on multiple datasets cross scales and domains. Notably, OEPG also
generalizes to quantity- and topology-imbalance scenarios.",None,-1
a5651004-9eeb-41ff-8b42-9079625598e1,Towards Efficient Use of Multi-Scale Features in Transformer-Based Object Detectors,0.583465,"Multi-scale features have been proven highly effective for object detection
but often come with huge and even prohibitive extra computation costs,
especially for the recent Transformer-based detectors. In this paper, we
propose Iterative Multi-scale Feature Aggregation (IMFA) -- a generic paradigm
that enables efficient use of multi-scale features in Transformer-based object
detectors. The core idea is to exploit sparse multi-scale features from just a
few crucial locations, and it is achieved with two novel designs. First, IMFA
rearranges the Transformer encoder-decoder pipeline so that the encoded
features can be iteratively updated based on the detection predictions. Second,
IMFA sparsely samples scale-adaptive features for refined detection from just a
few keypoint locations under the guidance of prior detection predictions. As a
result, the sampled multi-scale features are sparse yet still highly beneficial
for object detection. Extensive experiments show that the proposed IMFA boosts
the performance of multiple Transformer-based object detectors significantly
yet with only slight computational overhead.",https://github.com/ZhangGongjie/IMFA,-1
145bf36e-147c-47dc-b838-a1811baf7149,MolScribe: Robust Molecular Structure Recognition with Image-To-Graph Generation,0.669867,"Molecular structure recognition is the task of translating a molecular image
into its graph structure. Significant variation in drawing styles and
conventions exhibited in chemical literature poses a significant challenge for
automating this task. In this paper, we propose MolScribe, a novel
image-to-graph generation model that explicitly predicts atoms and bonds, along
with their geometric layouts, to construct the molecular structure. Our model
flexibly incorporates symbolic chemistry constraints to recognize chirality and
expand abbreviated structures. We further develop data augmentation strategies
to enhance the model robustness against domain shifts. In experiments on both
synthetic and realistic molecular images, MolScribe significantly outperforms
previous models, achieving 76-93% accuracy on public benchmarks. Chemists can
also easily verify MolScribe's prediction, informed by its confidence
estimation and atom-level alignment with the input image. MolScribe is publicly
available through Python and web interfaces:
https://github.com/thomas0809/MolScribe.",https://github.com/thomas0809/MolScribe,-1
d533e4be-fc3e-4eba-932b-1a256ead9ebb,ToKen: Task Decomposition and Knowledge Infusion for Few-Shot Hate Speech Detection,0.913479,"Hate speech detection is complex; it relies on commonsense reasoning,
knowledge of stereotypes, and an understanding of social nuance that differs
from one culture to the next. It is also difficult to collect a large-scale
hate speech annotated dataset. In this work, we frame this problem as a
few-shot learning task, and show significant gains with decomposing the task
into its ""constituent"" parts. In addition, we see that infusing knowledge from
reasoning datasets (e.g. Atomic2020) improves the performance even further.
Moreover, we observe that the trained models generalize to out-of-distribution
datasets, showing the superiority of task decomposition and knowledge infusion
compared to previously used methods. Concretely, our method outperforms the
baseline by 17.83% absolute gain in the 16-shot case.",None,-1
8d578da3-7c67-4a69-9fb4-bc3aaa6b4013,Distillation-Resistant Watermarking for Model Protection in NLP,0.64474,"How can we protect the intellectual property of trained NLP models? Modern
NLP models are prone to stealing by querying and distilling from their publicly
exposed APIs. However, existing protection methods such as watermarking only
work for images but are not applicable to text. We propose
Distillation-Resistant Watermarking (DRW), a novel technique to protect NLP
models from being stolen via distillation. DRW protects a model by injecting
watermarks into the victim's prediction probability corresponding to a secret
key and is able to detect such a key by probing a suspect model. We prove that
a protected model still retains the original accuracy within a certain bound.
We evaluate DRW on a diverse set of NLP tasks including text classification,
part-of-speech tagging, and named entity recognition. Experiments show that DRW
protects the original model and detects stealing suspects at 100% mean average
precision for all four tasks while the prior method fails on two.",https://github.com/XuandongZhao/DRW,-1
d0afe25d-b696-42b5-a602-bfc005d26e95,Systems Challenges for Trustworthy Embodied Systems,0.0923611,"A new generation of increasingly autonomous and self-learning embodied
systems is about to be developed. When deploying embodied systems into a
real-life context we face various engineering challenges, as it is crucial to
coordinate the behavior of embodied systems in a beneficial manner, ensure
their compatibility with our human-centered social values, and design
verifiably safe and reliable human-machine interaction. We are arguing that
traditional systems engineering is coming to a climacteric from embedded to
embodied systems, and with assuring the trustworthiness of dynamic federations
of situationally aware, intent-driven, explorative, ever-evolving, largely
non-predictable, and increasingly autonomous embodied systems in uncertain,
complex, and unpredictable real-world contexts. We are therefore identifying a
number of urgent systems challenges for trustworthy embodied systems, including
robust and human-centric AI, cognitive architectures, uncertainty
quantification, trustworthy self-integration, and continual analysis and
assurance.",None,-1
4053632c-370f-4de9-a5c0-720a079d8ebf,LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding,0.999998,"Structured document understanding has attracted considerable attention and
made significant progress recently, owing to its crucial role in intelligent
document processing. However, most existing related models can only deal with
the document data of specific language(s) (typically English) included in the
pre-training collection, which is extremely limited. To address this issue, we
propose a simple yet effective Language-independent Layout Transformer (LiLT)
for structured document understanding. LiLT can be pre-trained on the
structured documents of a single language and then directly fine-tuned on other
languages with the corresponding off-the-shelf monolingual/multilingual
pre-trained textual models. Experimental results on eight languages have shown
that LiLT can achieve competitive or even superior performance on diverse
widely-used downstream benchmarks, which enables language-independent benefit
from the pre-training of document layout structure. Code and model are publicly
available at https://github.com/jpWang/LiLT.",https://github.com/jpWang/LiLT,-1
8d552aed-21f8-4b3b-8104-fbed686c3118,Do Language Models Learn Position-Role Mappings?,0.18696,"How is knowledge of position-role mappings in natural language learned? We
explore this question in a computational setting, testing whether a variety of
well-performing pertained language models (BERT, RoBERTa, and DistilBERT)
exhibit knowledge of these mappings, and whether this knowledge persists across
alternations in syntactic, structural, and lexical alternations. In Experiment
1, we show that these neural models do indeed recognize distinctions between
theme and recipient roles in ditransitive constructions, and that these
distinct patterns are shared across construction type. We strengthen this
finding in Experiment 2 by showing that fine-tuning these language models on
novel theme- and recipient-like tokens in one paradigm allows the models to
make correct predictions about their placement in other paradigms, suggesting
that the knowledge of these mappings is shared rather than independently
learned. We do, however, observe some limitations of this generalization when
tasks involve constructions with novel ditransitive verbs, hinting at a degree
of lexical specificity which underlies model performance.",None,-1
d11a5a80-237b-4b37-a681-9754d6dc0c9d,Attention-Based Lip Audio-Visual Synthesis for Talking Face Generation in the Wild,0.540495,"Talking face generation with great practical significance has attracted more
attention in recent audio-visual studies. How to achieve accurate lip
synchronization is a long-standing challenge to be further investigated.
Motivated by xxx, in this paper, an AttnWav2Lip model is proposed by
incorporating spatial attention module and channel attention module into
lip-syncing strategy. Rather than focusing on the unimportant regions of the
face image, the proposed AttnWav2Lip model is able to pay more attention on the
lip region reconstruction. To our limited knowledge, this is the first attempt
to introduce attention mechanism to the scheme of talking face generation. An
extensive experiments have been conducted to evaluate the effectiveness of the
proposed model. Compared to the baseline measured by LSE-D and LSE-C metrics, a
superior performance has been demonstrated on the benchmark lip synthesis
datasets, including LRW, LRS2 and LRS3.",None,-1
9a0cd6b4-de12-4ce2-9bc5-1adef0c114ff,Bag of Tricks for Out-of-Distribution Generalization,0.0793185,"Recently, out-of-distribution (OOD) generalization has attracted attention to
the robustness and generalization ability of deep learning based models, and
accordingly, many strategies have been made to address different aspects
related to this issue. However, most existing algorithms for OOD generalization
are complicated and specifically designed for certain dataset. To alleviate
this problem, nicochallenge-2022 provides NICO++, a large-scale dataset with
diverse context information. In this paper, based on systematic analysis of
different schemes on NICO++ dataset, we propose a simple but effective learning
framework via coupling bag of tricks, including multi-objective framework
design, data augmentations, training and inference strategies. Our algorithm is
memory-efficient and easily-equipped, without complicated modules and does not
require for large pre-trained models. It achieves an excellent performance with
Top-1 accuracy of 88.16% on public test set and 75.65% on private test set, and
ranks 1st in domain generalization task of nicochallenge-2022.",None,-1
1cefc448-241c-46ef-b349-60a96b98b5a3,PALT: Parameter-Lite Transfer of Language Models for Knowledge Graph Completion,0.417023,"This paper presents a parameter-lite transfer learning approach of pretrained
language models (LM) for knowledge graph (KG) completion. Instead of
finetuning, which modifies all LM parameters, we only tune a few new parameters
while keeping the original LM parameters fixed. We establish this via
reformulating KG completion as a ""fill-in-the-blank"" task, and introducing a
parameter-lite encoder on top of the original LMs. We show that, by tuning far
fewer parameters than finetuning, LMs transfer non-trivially to most tasks and
reach competitiveness with prior state-of-the-art approaches. For instance, we
outperform the fully finetuning approaches on a KG completion benchmark by
tuning only 1% of the parameters. The code and datasets are available at
\url{https://github.com/yuanyehome/PALT}.",https://github.com/yuanyehome/PALT,-1
ea81c571-4437-4e9e-89df-14209afff4c2,Error Correction Code Transformer,0.469642,"Error correction code is a major part of the communication physical layer,
ensuring the reliable transfer of data over noisy channels. Recently, neural
decoders were shown to outperform classical decoding techniques. However, the
existing neural approaches present strong overfitting due to the exponential
training complexity, or a restrictive inductive bias due to reliance on Belief
Propagation. Recently, Transformers have become methods of choice in many
applications thanks to their ability to represent complex interactions between
elements. In this work, we propose to extend for the first time the Transformer
architecture to the soft decoding of linear codes at arbitrary block lengths.
We encode each channel's output dimension to high dimension for better
representation of the bits information to be processed separately. The
element-wise processing allows the analysis of the channel output reliability,
while the algebraic code and the interaction between the bits are inserted into
the model via an adapted masked self-attention module. The proposed approach
demonstrates the extreme power and flexibility of Transformers and outperforms
existing state-of-the-art neural decoders by large margins at a fraction of
their time complexity.",https://github.com/yoniLc/ECCT,-1
ddb9976c-86e8-4260-b2ec-aaa52d2c7b27,Provable Safe Reinforcement Learning with Binary Feedback,0.221671,"Safety is a crucial necessity in many applications of reinforcement learning
(RL), whether robotic, automotive, or medical. Many existing approaches to safe
RL rely on receiving numeric safety feedback, but in many cases this feedback
can only take binary values; that is, whether an action in a given state is
safe or unsafe. This is particularly true when feedback comes from human
experts. We therefore consider the problem of provable safe RL when given
access to an offline oracle providing binary feedback on the safety of state,
action pairs. We provide a novel meta algorithm, SABRE, which can be applied to
any MDP setting given access to a blackbox PAC RL algorithm for that setting.
SABRE applies concepts from active learning to reinforcement learning to
provably control the number of queries to the safety oracle. SABRE works by
iteratively exploring the state space to find regions where the agent is
currently uncertain about safety. Our main theoretical results shows that,
under appropriate technical assumptions, SABRE never takes unsafe actions
during training, and is guaranteed to return a near-optimal safe policy with
high probability. We provide a discussion of how our meta-algorithm may be
applied to various settings studied in both theoretical and empirical
frameworks.",None,-1
c0db5b3d-0e4e-4695-84d6-8acb96ee63e5,Understanding Translationese in Cross-Lingual Summarization,0.864011,"Given a document in a source language, cross-lingual summarization (CLS) aims
at generating a concise summary in a different target language. Unlike
monolingual summarization (MS), naturally occurring source-language documents
paired with target-language summaries are rare. To collect large-scale CLS
data, existing datasets typically involve translation in their creation.
However, the translated text is distinguished from the text originally written
in that language, i.e., translationese. In this paper, we first confirm that
different approaches of constructing CLS datasets will lead to different
degrees of translationese. Then we systematically investigate how
translationese affects CLS model evaluation and performance when it appears in
source documents or target summaries. In detail, we find that (1) the
translationese in documents or summaries of test sets might lead to the
discrepancy between human judgment and automatic evaluation; (2) the
translationese in training sets would harm model performance in real-world
applications; (3) though machine-translated documents involve translationese,
they are very useful for building CLS systems on low-resource languages under
specific training strategies. Lastly, we give suggestions for future CLS
research including dataset and model developments. We hope that our work could
let researchers notice the phenomenon of translationese in CLS and take it into
account in the future.",https://github.com/xcfcode/MSAMSum,-1
bb15be99-4ab7-496a-a455-83ffaa18615b,Integrating Diverse Knowledge Sources for Online One-shot Learning of Novel Tasks,0.380695,"Autonomous agents are able to draw on a wide variety of potential sources of
task knowledge; however current approaches invariably focus on only one or two.
Here we investigate the challenges and impact of exploiting diverse knowledge
sources to learn online, in one-shot, new tasks for a simulated office mobile
robot. The resulting agent, developed in the Soar cognitive architecture, uses
the following sources of domain and task knowledge: interaction with the
environment, task execution and search knowledge, human natural language
instruction, and responses retrieved from a large language model (GPT-3). We
explore the distinct contributions of these knowledge sources and evaluate the
performance of different combinations in terms of learning correct task
knowledge and human workload. Results show that an agent's online integration
of diverse knowledge sources improves one-shot task learning overall, reducing
human feedback needed for rapid and reliable task learning.",None,-1
0abd457c-32f8-4139-b814-d373aca9ac59,Mere Contrastive Learning for Cross-Domain Sentiment Analysis,0.262643,"Cross-domain sentiment analysis aims to predict the sentiment of texts in the
target domain using the model trained on the source domain to cope with the
scarcity of labeled data. Previous studies are mostly cross-entropy-based
methods for the task, which suffer from instability and poor generalization. In
this paper, we explore contrastive learning on the cross-domain sentiment
analysis task. We propose a modified contrastive objective with in-batch
negative samples so that the sentence representations from the same class will
be pushed close while those from the different classes become further apart in
the latent space. Experiments on two widely used datasets show that our model
can achieve state-of-the-art performance in both cross-domain and multi-domain
sentiment analysis tasks. Meanwhile, visualizations demonstrate the
effectiveness of transferring knowledge learned in the source domain to the
target domain and the adversarial test verifies the robustness of our model.",https://github.com/LuoXiaoHeics/COBE,3063
e1618f89-f475-420a-8b13-eb052e7bdc1d,Region Aware Video Object Segmentation with Deep Motion Modeling,0.34186,"Current semi-supervised video object segmentation (VOS) methods usually
leverage the entire features of one frame to predict object masks and update
memory. This introduces significant redundant computations. To reduce
redundancy, we present a Region Aware Video Object Segmentation (RAVOS)
approach that predicts regions of interest (ROIs) for efficient object
segmentation and memory storage. RAVOS includes a fast object motion tracker to
predict their ROIs in the next frame. For efficient segmentation, object
features are extracted according to the ROIs, and an object decoder is designed
for object-level segmentation. For efficient memory storage, we propose motion
path memory to filter out redundant context by memorizing the features within
the motion path of objects between two frames. Besides RAVOS, we also propose a
large-scale dataset, dubbed OVOS, to benchmark the performance of VOS models
under occlusions. Evaluation on DAVIS and YouTube-VOS benchmarks and our new
OVOS dataset show that our method achieves state-of-the-art performance with
significantly faster inference time, e.g., 86.1 J&F at 42 FPS on DAVIS and 84.4
J&F at 23 FPS on YouTube-VOS.",None,-1
1c7cbd4c-2226-48c7-8aa7-70291928222c,AST-Probe: Recovering abstract syntax trees from hidden representations of pre-trained language models,0.849964,"The objective of pre-trained language models is to learn contextual
representations of textual data. Pre-trained language models have become
mainstream in natural language processing and code modeling. Using probes, a
technique to study the linguistic properties of hidden vector spaces, previous
works have shown that these pre-trained language models encode simple
linguistic properties in their hidden representations. However, none of the
previous work assessed whether these models encode the whole grammatical
structure of a programming language. In this paper, we prove the existence of a
syntactic subspace, lying in the hidden representations of pre-trained language
models, which contain the syntactic information of the programming language. We
show that this subspace can be extracted from the models' representations and
define a novel probing method, the AST-Probe, that enables recovering the whole
abstract syntax tree (AST) of an input code snippet. In our experimentations,
we show that this syntactic subspace exists in five state-of-the-art
pre-trained language models. In addition, we highlight that the middle layers
of the models are the ones that encode most of the AST information. Finally, we
estimate the optimal size of this syntactic subspace and show that its
dimension is substantially lower than those of the models' representation
spaces. This suggests that pre-trained language models use a small part of
their representation spaces to encode syntactic information of the programming
languages.",https://doi.org/10.5281/zenodo.7032076,-1
3021f713-6064-4f7c-a52c-8c8e244dd783,kogito: A Commonsense Knowledge Inference Toolkit,0.387911,"In this paper, we present kogito, an open-source tool for generating
commonsense inferences about situations described in text. kogito provides an
intuitive and extensible interface to interact with natural language generation
models that can be used for hypothesizing commonsense knowledge inference from
a textual input. In particular, kogito offers several features for targeted,
multi-granularity knowledge generation. These include a standardized API for
training and evaluating knowledge models, and generating and filtering
inferences from them. We also include helper functions for converting natural
language texts into a format ingestible by knowledge models - intermediate
pipeline stages such as knowledge head extraction from text, heuristic and
model-based knowledge head-relation matching, and an ability to define and use
custom knowledge relations. We make the code for kogito available at
https://github.com/epfl-nlp/kogito along with thorough documentation at
https://kogito.readthedocs.io.",https://github.com/epfl-nlp/kogito,-1
48609af0-4de0-4068-8b82-4fe6338f278d,Visual Fault Detection of Multi-scale Key Components in Freight Trains,0.689047,"Fault detection for key components in the braking system of freight trains is
critical for ensuring railway transportation safety. Despite the frequently
employed methods based on deep learning, these fault detectors are highly
reliant on hardware resources and are complex to implement. In addition, no
train fault detectors consider the drop in accuracy induced by scale variation
of fault parts. This paper proposes a lightweight anchor-free framework to
solve the above problems. Specifically, to reduce the amount of computation and
model size, we introduce a lightweight backbone and adopt an anchor-free method
for localization and regression. To improve detection accuracy for multi-scale
parts, we design a feature pyramid network to generate rectangular layers of
different sizes to map parts with similar aspect ratios. Experiments on four
fault datasets show that our framework achieves 98.44% accuracy while the model
size is only 22.5 MB, outperforming state-of-the-art detectors.",None,-1
c86c21bb-ad39-4987-8511-a926fd9f52ae,Conformal Risk Control,0.999878,"We extend conformal prediction to control the expected value of any monotone
loss function. The algorithm generalizes split conformal prediction together
with its coverage guarantee. Like conformal prediction, the conformal risk
control procedure is tight up to an $\mathcal{O}(1/n)$ factor. We also
introduce extensions of the idea to distribution shift, quantile risk control,
multiple and adversarial risk control, and expectations of U-statistics. Worked
examples from computer vision and natural language processing demonstrate the
usage of our algorithm to bound the false negative rate, graph distance, and
token-level F1-score.",None,-1
11164bf5-f788-4dfe-84c1-0bb6ee2826e4,SpikiLi: A Spiking Simulation of LiDAR based Real-time Object Detection for Autonomous Driving,0.123002,"Spiking Neural Networks are a recent and new neural network design approach
that promises tremendous improvements in power efficiency, computation
efficiency, and processing latency. They do so by using asynchronous
spike-based data flow, event-based signal generation, processing, and modifying
the neuron model to resemble biological neurons closely. While some initial
works have shown significant initial evidence of applicability to common deep
learning tasks, their applications in complex real-world tasks has been
relatively low. In this work, we first illustrate the applicability of spiking
neural networks to a complex deep learning task namely Lidar based 3D object
detection for automated driving. Secondly, we make a step-by-step demonstration
of simulating spiking behavior using a pre-trained convolutional neural
network. We closely model essential aspects of spiking neural networks in
simulation and achieve equivalent run-time and accuracy on a GPU. When the
model is realized on a neuromorphic hardware, we expect to have significantly
improved power efficiency.",None,7435
02bb0a51-df73-4eb4-ac85-deb57070d34f,ConvMAE: Masked Convolution Meets Masked Autoencoders,0.768117,"Vision Transformers (ViT) become widely-adopted architectures for various
vision tasks. Masked auto-encoding for feature pretraining and multi-scale
hybrid convolution-transformer architectures can further unleash the potentials
of ViT, leading to state-of-the-art performances on image classification,
detection and semantic segmentation. In this paper, our ConvMAE framework
demonstrates that multi-scale hybrid convolution-transformer can learn more
discriminative representations via the mask auto-encoding scheme. However,
directly using the original masking strategy leads to the heavy computational
cost and pretraining-finetuning discrepancy. To tackle the issue, we adopt the
masked convolution to prevent information leakage in the convolution blocks. A
simple block-wise masking strategy is proposed to ensure computational
efficiency. We also propose to more directly supervise the multi-scale features
of the encoder to boost multi-scale features. Based on our pretrained ConvMAE
models, ConvMAE-Base improves ImageNet-1K finetuning accuracy by 1.4% compared
with MAE-Base. On object detection, ConvMAE-Base finetuned for only 25 epochs
surpasses MAE-Base fined-tuned for 100 epochs by 2.9% box AP and 2.2% mask AP
respectively. Code and pretrained models are available at
https://github.com/Alpha-VL/ConvMAE.",https://github.com/Alpha-VL/ConvMAE,-1
0322ef16-3205-46ba-a6e2-9a57ed1ab012,Continual Contrastive Finetuning Improves Low-Resource Relation Extraction,0.0903025,"Relation extraction (RE), which has relied on structurally annotated corpora
for model training, has been particularly challenging in low-resource scenarios
and domains. Recent literature has tackled low-resource RE by self-supervised
learning, where the solution involves pretraining the entity pair embedding by
RE-based objective and finetuning on labeled data by classification-based
objective. However, a critical challenge to this approach is the gap in
objectives, which prevents the RE model from fully utilizing the knowledge in
pretrained representations. In this paper, we aim at bridging the gap and
propose to pretrain and finetune the RE model using consistent objectives of
contrastive learning. Since in this kind of representation learning paradigm,
one relation may easily form multiple clusters in the representation space, we
further propose a multi-center contrastive loss that allows one relation to
form multiple clusters to better align with pretraining. Experiments on two
document-level RE datasets, BioRED and Re-DocRED, demonstrate the effectiveness
of our method. Particularly, when using 1% end-task training data, our method
outperforms PLM-based RE classifier by 10.5% and 6.1% on the two datasets,
respectively.",None,10388
75c0ddec-595f-4c78-b8ae-93392389e3a4,Generalised Implicit Neural Representations,0.350687,"We consider the problem of learning implicit neural representations (INRs)
for signals on non-Euclidean domains. In the Euclidean case, INRs are trained
on a discrete sampling of a signal over a regular lattice. Here, we assume that
the continuous signal exists on some unknown topological space from which we
sample a discrete graph. In the absence of a coordinate system to identify the
sampled nodes, we propose approximating their location with a spectral
embedding of the graph. This allows us to train INRs without knowing the
underlying continuous domain, which is the case for most graph signals in
nature, while also making the INRs independent of any choice of coordinate
system. We show experiments with our method on various real-world signals on
non-Euclidean domains.",https://github.com/danielegrattarola/GINR,-1
70830ad8-ed1f-4cc5-88eb-f0384e2410e8,Transparent Shape from a Single View Polarization Image,0.357746,"This paper presents a learning-based method for transparent surface
estimation from a single view polarization image. Existing shape from
polarization(SfP) methods have the difficulty in estimating transparent shape
since the inherent transmission interference heavily reduces the reliability of
physics-based prior. To address this challenge, we propose the concept of
physics-based prior, which is inspired by the characteristic that the
transmission component in the polarization image has more noise than
reflection. The confidence is used to determine the contribution of the
interfered physics-based prior. Then, we build a network(TransSfP) with
multi-branch architecture to avoid the destruction of relationships between
different hierarchical inputs. To train and test our method, we construct a
dataset for transparent shape from polarization with paired polarization images
and ground-truth normal maps. Extensive experiments and comparisons demonstrate
the superior accuracy of our method.",https://github.com/shaomq2187/TransSfP,-1
2498e99d-3cc5-4893-95c1-61447c57abb8,Detection of Fights in Videos: A Comparison Study of Anomaly Detection and Action Recognition,0.308443,"Detection of fights is an important surveillance application in videos. Most
existing methods use supervised binary action recognition. Since frame-level
annotations are very hard to get for anomaly detection, weakly supervised
learning using multiple instance learning is widely used. This paper explores
the detection of fights in videos as one special type of anomaly detection and
as binary action recognition. We use the UBI-Fight and NTU-CCTV-Fight datasets
for most of the study since they have frame-level annotations. We find that the
anomaly detection has similar or even better performance than the action
recognition. Furthermore, we study to use anomaly detection as a toolbox to
generate training datasets for action recognition in an iterative way
conditioned on the performance of the anomaly detection. Experiment results
should show that we achieve state-of-the-art performance on three fight
detection datasets.",None,-1
b64d216c-9a8b-424d-9d25-e614b2ad319a,JRDB-Pose: A Large-scale Dataset for Multi-Person Pose Estimation and Tracking,0.952795,"Autonomous robotic systems operating in human environments must understand
their surroundings to make accurate and safe decisions. In crowded human scenes
with close-up human-robot interaction and robot navigation, a deep
understanding requires reasoning about human motion and body dynamics over time
with human body pose estimation and tracking. However, existing datasets either
do not provide pose annotations or include scene types unrelated to robotic
applications. Many datasets also lack the diversity of poses and occlusions
found in crowded human scenes. To address this limitation we introduce
JRDB-Pose, a large-scale dataset and benchmark for multi-person pose estimation
and tracking using videos captured from a social navigation robot. The dataset
contains challenge scenes with crowded indoor and outdoor locations and a
diverse range of scales and occlusion types. JRDB-Pose provides human pose
annotations with per-keypoint occlusion labels and track IDs consistent across
the scene. A public evaluation server is made available for fair evaluation on
a held-out test set. JRDB-Pose is available at https://jrdb.erc.monash.edu/ .",None,-1
cfc800d8-d106-4ac9-814a-525a662b7e6c,HM3D-ABO: A Photo-realistic Dataset for Object-centric Multi-view 3D Reconstruction,0.101875,"Reconstructing 3D objects is an important computer vision task that has wide
application in AR/VR. Deep learning algorithm developed for this task usually
relies on an unrealistic synthetic dataset, such as ShapeNet and Things3D. On
the other hand, existing real-captured object-centric datasets usually do not
have enough annotation to enable supervised training or reliable evaluation. In
this technical report, we present a photo-realistic object-centric dataset
HM3D-ABO. It is constructed by composing realistic indoor scene and realistic
object. For each configuration, we provide multi-view RGB observations, a
water-tight mesh model for the object, ground truth depth map and object mask.
The proposed dataset could also be useful for tasks such as camera pose
estimation and novel-view synthesis. The dataset generation code is released at
https://github.com/zhenpeiyang/HM3D-ABO.",https://github.com/zhenpeiyang/HM3D-ABO,-1
cd7d28d8-0b0a-41fb-8beb-5bfba65d8d20,Reinforcement Learning under Partial Observability Guided by Learned Environment Models,0.205068,"In practical applications, we can rarely assume full observability of a
system's environment, despite such knowledge being important for determining a
reactive control system's precise interaction with its environment. Therefore,
we propose an approach for reinforcement learning (RL) in partially observable
environments. While assuming that the environment behaves like a partially
observable Markov decision process with known discrete actions, we assume no
knowledge about its structure or transition probabilities.
  Our approach combines Q-learning with IoAlergia, a method for learning Markov
decision processes (MDP). By learning MDP models of the environment from
episodes of the RL agent, we enable RL in partially observable domains without
explicit, additional memory to track previous interactions for dealing with
ambiguities stemming from partial observability. We instead provide RL with
additional observations in the form of abstract environment states by
simulating new experiences on learned environment models to track the explored
states. In our evaluation, we report on the validity of our approach and its
promising performance in comparison to six state-of-the-art deep RL techniques
with recurrent neural networks and fixed memory.",https://github.com/hill-a/stable-baselines,-1
4c141d05-9437-4c84-927c-0cc2671ea81f,Deep Normed Embeddings for Patient Representation,0.146516,"We introduce a novel contrastive representation learning objective and a
training scheme for clinical time series. Specifically, we project high
dimensional EHR. data to a closed unit ball of low dimension, encoding
geometric priors so that the origin represents an idealized perfect health
state and the Euclidean norm is associated with the patient's mortality risk.
Moreover, using septic patients as an example, we show how we could learn to
associate the angle between two vectors with the different organ system
failures, thereby, learning a compact representation which is indicative of
both mortality risk and specific organ failure. We show how the learned
embedding can be used for online patient monitoring, can supplement clinicians
and improve performance of downstream machine learning tasks. This work was
partially motivated from the desire and the need to introduce a systematic way
of defining intermediate rewards for Reinforcement Learning in critical care
medicine. Hence, we also show how such a design in terms of the learned
embedding can result in qualitatively different policies and value
distributions, as compared with using only terminal rewards.",None,-1
a6acb4d3-6c0c-4eb6-9338-c4d108631d1b,Alterfactual Explanations -- The Relevance of Irrelevance for Explaining AI Systems,0.259863,"Explanation mechanisms from the field of Counterfactual Thinking are a
widely-used paradigm for Explainable Artificial Intelligence (XAI), as they
follow a natural way of reasoning that humans are familiar with. However, all
common approaches from this field are based on communicating information about
features or characteristics that are especially important for an AI's decision.
We argue that in order to fully understand a decision, not only knowledge about
relevant features is needed, but that the awareness of irrelevant information
also highly contributes to the creation of a user's mental model of an AI
system. Therefore, we introduce a new way of explaining AI systems. Our
approach, which we call Alterfactual Explanations, is based on showing an
alternative reality where irrelevant features of an AI's input are altered. By
doing so, the user directly sees which characteristics of the input data can
change arbitrarily without influencing the AI's decision. We evaluate our
approach in an extensive user study, revealing that it is able to significantly
contribute to the participants' understanding of an AI. We show that
alterfactual explanations are suited to convey an understanding of different
aspects of the AI's reasoning than established counterfactual explanation
methods.",None,-1
6bb3ba21-9577-4586-8a9c-213724624a67,Similarity and Content-based Phonetic Self Attention for Speech Recognition,0.101172,"Transformer-based speech recognition models have achieved great success due
to the self-attention (SA) mechanism that utilizes every frame in the feature
extraction process. Especially, SA heads in lower layers capture various
phonetic characteristics by the query-key dot product, which is designed to
compute the pairwise relationship between frames. In this paper, we propose a
variant of SA to extract more representative phonetic features. The proposed
phonetic self-attention (phSA) is composed of two different types of phonetic
attention; one is similarity-based and the other is content-based. In short,
similarity-based attention captures the correlation between frames while
content-based attention only considers each frame without being affected by
other frames. We identify which parts of the original dot product equation are
related to two different attention patterns and improve each part with simple
modifications. Our experiments on phoneme classification and speech recognition
show that replacing SA with phSA for lower layers improves the recognition
performance without increasing the latency and the parameter size.",None,-1
c098db9b-1479-440c-818e-439845b85e06,Fine-tuned Sentiment Analysis of COVID-19 Vaccine-Related Social Media Data: Comparative Study,0.61043,"This study investigated and compared public sentiment related to COVID-19
vaccines expressed on two popular social media platforms, Reddit and Twitter,
harvested from January 1, 2020, to March 1, 2022. To accomplish this task, we
created a fine-tuned DistilRoBERTa model to predict sentiments of approximately
9.5 million Tweets and 70 thousand Reddit comments. To fine-tune our model, our
team manually labeled the sentiment of 3600 Tweets and then augmented our
dataset by the method of back-translation. Text sentiment for each social media
platform was then classified with our fine-tuned model using Python and the
Huggingface sentiment analysis pipeline. Our results determined that the
average sentiment expressed on Twitter was more negative (52% positive) than
positive and the sentiment expressed on Reddit was more positive than negative
(53% positive). Though average sentiment was found to vary between these social
media platforms, both displayed similar behavior related to sentiment shared at
key vaccine-related developments during the pandemic. Considering this similar
trend in shared sentiment demonstrated across social media platforms, Twitter
and Reddit continue to be valuable data sources that public health officials
can utilize to strengthen vaccine confidence and combat misinformation. As the
spread of misinformation poses a range of psychological and psychosocial risks
(anxiety, fear, etc.), there is an urgency in understanding the public
perspective and attitude toward shared falsities. Comprehensive educational
delivery systems tailored to the population's expressed sentiments that
facilitate digital literacy, health information-seeking behavior, and precision
health promotion could aid in clarifying such misinformation.",None,-1
37901a8d-f8e5-4e76-8e24-38b9d956c01a,On Gap-dependent Bounds for Offline Reinforcement Learning,0.325363,"This paper presents a systematic study on gap-dependent sample complexity in
offline reinforcement learning. Prior work showed when the density ratio
between an optimal policy and the behavior policy is upper bounded (the optimal
policy coverage assumption), then the agent can achieve an
$O\left(\frac{1}{\epsilon^2}\right)$ rate, which is also minimax optimal. We
show under the optimal policy coverage assumption, the rate can be improved to
$O\left(\frac{1}{\epsilon}\right)$ when there is a positive sub-optimality gap
in the optimal $Q$-function. Furthermore, we show when the visitation
probabilities of the behavior policy are uniformly lower bounded for states
where an optimal policy's visitation probabilities are positive (the uniform
optimal policy coverage assumption), the sample complexity of identifying an
optimal policy is independent of $\frac{1}{\epsilon}$. Lastly, we present
nearly-matching lower bounds to complement our gap-dependent upper bounds.",None,-1
6ec98720-7a3d-4a34-a6ed-f57ec84e4d76,A*Net: A Scalable Path-based Reasoning Approach for Knowledge Graphs,0.267909,"Reasoning on large-scale knowledge graphs has been long dominated by
embedding methods. While path-based methods possess the inductive capacity that
embeddings lack, their scalability is limited by the exponential number of
paths. Here we present A*Net, a scalable path-based method for knowledge graph
reasoning. Inspired by the A* algorithm for shortest path problems, our A*Net
learns a priority function to select important nodes and edges at each
iteration, to reduce time and memory footprint for both training and inference.
The ratio of selected nodes and edges can be specified to trade off between
performance and efficiency. Experiments on both transductive and inductive
knowledge graph reasoning benchmarks show that A*Net achieves competitive
performance with existing state-of-the-art path-based methods, while merely
visiting 10% nodes and 10% edges at each iteration. On a million-scale dataset
ogbl-wikikg2, A*Net not only achieves a new state-of-the-art result, but also
converges faster than embedding methods. A*Net is the first path-based method
for knowledge graph reasoning at such scale.",https://github.com/DeepGraphLearning/AStarNet,-1
217a3480-b47d-4919-af55-21ce2b2398aa,Domain-Adaptive Text Classification with Structured Knowledge from Unlabeled Data,0.361962,"Domain adaptive text classification is a challenging problem for the
large-scale pretrained language models because they often require expensive
additional labeled data to adapt to new domains. Existing works usually fails
to leverage the implicit relationships among words across domains. In this
paper, we propose a novel method, called Domain Adaptation with Structured
Knowledge (DASK), to enhance domain adaptation by exploiting word-level
semantic relationships. DASK first builds a knowledge graph to capture the
relationship between pivot terms (domain-independent words) and non-pivot terms
in the target domain. Then during training, DASK injects pivot-related
knowledge graph information into source domain texts. For the downstream task,
these knowledge-injected texts are fed into a BERT variant capable of
processing knowledge-injected textual data. Thanks to the knowledge injection,
our model learns domain-invariant features for non-pivots according to their
relationships with pivots. DASK ensures the pivots to have domain-invariant
behaviors by dynamically inferring via the polarity scores of candidate pivots
during training with pseudo-labels. We validate DASK on a wide range of
cross-domain sentiment classification tasks and observe up to 2.9% absolute
performance improvement over baselines for 20 different domain pairs. Code will
be made available at https://github.com/hikaru-nara/DASK.",https://github.com/hikaru-nara/DASK,-1
a08574af-9f09-4350-88c3-f5f2857cc46c,NeuPhysics: Editable Neural Geometry and Physics from Monocular Videos,0.790482,"We present a method for learning 3D geometry and physics parameters of a
dynamic scene from only a monocular RGB video input. To decouple the learning
of underlying scene geometry from dynamic motion, we represent the scene as a
time-invariant signed distance function (SDF) which serves as a reference
frame, along with a time-conditioned deformation field. We further bridge this
neural geometry representation with a differentiable physics simulator by
designing a two-way conversion between the neural field and its corresponding
hexahedral mesh, enabling us to estimate physics parameters from the source
video by minimizing a cycle consistency loss. Our method also allows a user to
interactively edit 3D objects from the source video by modifying the recovered
hexahedral mesh, and propagating the operation back to the neural field
representation. Experiments show that our method achieves superior mesh and
video reconstruction of dynamic scenes compared to competing Neural Field
approaches, and we provide extensive examples which demonstrate its ability to
extract useful 3D representations from videos captured with consumer-grade
cameras.",https://sites.google.com/view/neuphysics,-1
3dbaffc3-32ad-4e22-9d3a-23cd4ea69aad,"Adversarial Pretraining of Self-Supervised Deep Networks: Past, Present and Future",0.109741,"In this paper, we review adversarial pretraining of self-supervised deep
networks including both convolutional neural networks and vision transformers.
Unlike the adversarial training with access to labeled examples, adversarial
pretraining is complicated as it only has access to unlabeled examples. To
incorporate adversaries into pretraining models on either input or feature
level, we find that existing approaches are largely categorized into two
groups: memory-free instance-wise attacks imposing worst-case perturbations on
individual examples, and memory-based adversaries shared across examples over
iterations. In particular, we review several representative adversarial
pretraining models based on Contrastive Learning (CL) and Masked Image Modeling
(MIM), respectively, two popular self-supervised pretraining methods in
literature. We also review miscellaneous issues about computing overheads,
input-/feature-level adversaries, as well as other adversarial pretraining
approaches beyond the above two groups. Finally, we discuss emerging trends and
future directions about the relations between adversarial and cooperative
pretraining, unifying adversarial CL and MIM pretraining, and the trade-off
between accuracy and robustness in adversarial pretraining.",https://github.com/LijieFan/AdvCL,-1
8d34b306-d9ee-40d9-bb8e-8d66b64c95e5,Tencent AI Lab - Shanghai Jiao Tong University Low-Resource Translation System for the WMT22 Translation Task,0.515415,"This paper describes Tencent AI Lab - Shanghai Jiao Tong University
(TAL-SJTU) Low-Resource Translation systems for the WMT22 shared task. We
participate in the general translation task on
English$\Leftrightarrow$Livonian. Our system is based on M2M100 with novel
techniques that adapt it to the target language pair. (1) Cross-model word
embedding alignment: inspired by cross-lingual word embedding alignment, we
successfully transfer a pre-trained word embedding to M2M100, enabling it to
support Livonian. (2) Gradual adaptation strategy: we exploit Estonian and
Latvian as auxiliary languages for many-to-many translation training and then
adapt to English-Livonian. (3) Data augmentation: to enlarge the parallel data
for English-Livonian, we construct pseudo-parallel data with Estonian and
Latvian as pivot languages. (4) Fine-tuning: to make the most of all available
data, we fine-tune the model with the validation set and online
back-translation, further boosting the performance. In model evaluation: (1) We
find that previous work underestimated the translation performance of Livonian
due to inconsistent Unicode normalization, which may cause a discrepancy of up
to 14.9 BLEU score. (2) In addition to the standard validation set, we also
employ round-trip BLEU to evaluate the models, which we find more appropriate
for this task. Finally, our unconstrained system achieves BLEU scores of 17.0
and 30.4 for English to/from Livonian.",https://github.com/zwhe99/WMT22-En-Liv,-1
3909de61-4311-478d-a6bd-c20a3469775a,Evaluation of Pre-Trained CNN Models for Geographic Fake Image Detection,0.22356,"Thanks to the remarkable advances in generative adversarial networks (GANs),
it is becoming increasingly easy to generate/manipulate images. The existing
works have mainly focused on deepfake in face images and videos. However, we
are currently witnessing the emergence of fake satellite images, which can be
misleading or even threatening to national security. Consequently, there is an
urgent need to develop detection methods capable of distinguishing between real
and fake satellite images. To advance the field, in this paper, we explore the
suitability of several convolutional neural network (CNN) architectures for
fake satellite image detection. Specifically, we benchmark four CNN models by
conducting extensive experiments to evaluate their performance and robustness
against various image distortions. This work allows the establishment of new
baselines and may be useful for the development of CNN-based methods for fake
satellite image detection.",None,24565
64223718-0251-4936-a16d-b8dd0f500d96,Generative Pretraining for Black-Box Optimization,0.566485,"Many problems in science and engineering involve optimizing an expensive
black-box function over a high-dimensional space. For such black-box
optimization (BBO) problems, we typically assume a small budget for online
function evaluations, but also often have access to a fixed, offline dataset
for pretraining. Prior approaches seek to utilize the offline data to
approximate the function or its inverse but are not sufficiently accurate far
from the data distribution. We propose BONET, a generative framework for
pretraining a novel black-box optimizer using offline datasets. In BONET, we
train an autoregressive model on fixed-length trajectories derived from an
offline dataset. We design a sampling strategy to synthesize trajectories from
offline data using a simple heuristic of rolling out monotonic transitions from
low-fidelity to high-fidelity samples. Empirically, we instantiate BONET using
a causally masked Transformer and evaluate it on Design-Bench, where we rank
the best on average, outperforming state-of-the-art baselines.",https://github.com/siddarthk97/bonet,-1
2ee39fcb-4c5f-463e-955a-1c50a5e76fad,Object Segmentation of Cluttered Airborne LiDAR Point Clouds,0.128563,"Airborne topographic LiDAR is an active remote sensing technology that emits
near-infrared light to map objects on the Earth's surface. Derived products of
LiDAR are suitable to service a wide range of applications because of their
rich three-dimensional spatial information and their capacity to obtain
multiple returns. However, processing point cloud data still requires a
significant effort in manual editing. Certain human-made objects are difficult
to detect because of their variety of shapes, irregularly-distributed point
clouds, and low number of class samples. In this work, we propose an efficient
end-to-end deep learning framework to automatize the detection and segmentation
of objects defined by an arbitrary number of LiDAR points surrounded by
clutter. Our method is based on a light version of PointNet that achieves good
performance on both object recognition and segmentation tasks. The results are
tested against manually delineated power transmission towers and show promising
accuracy.",https://github.com/marionacaros/3d-object-segmentation,-1
a05517a9-6413-41d5-a091-c14f68902879,Towards Abstractive Grounded Summarization of Podcast Transcripts,0.472924,"Podcasts have recently shown a rapid rise in popularity. Summarization of
podcast transcripts is of practical benefit to both content providers and
consumers. It helps consumers to quickly decide whether they will listen to the
podcasts and reduces the cognitive load of content providers to write
summaries. Nevertheless, podcast summarization faces significant challenges
including factual inconsistencies with respect to the inputs. The problem is
exacerbated by speech disfluencies and recognition errors in transcripts of
spoken language. In this paper, we explore a novel abstractive summarization
method to alleviate these challenges. Specifically, our approach learns to
produce an abstractive summary while grounding summary segments in specific
portions of the transcript to allow for full inspection of summary details. We
conduct a series of analyses of the proposed approach on a large podcast
dataset and show that the approach can achieve promising results. Grounded
summaries bring clear benefits in locating the summary and transcript segments
that contain inconsistent information, and hence significantly improve
summarization quality in both automatic and human evaluation metrics.",https://github.com/tencent-ailab/GrndPodcastSum,-1
d01e0379-dca5-4e7c-a590-0de83abd0fce,DSI++: Updating Transformer Memory with New Documents,0.641119,"Differentiable Search Indices (DSIs) encode a corpus of documents in model
parameters and use the same model to answer user queries directly. Despite the
strong performance of DSI models, deploying them in situations where the corpus
changes over time is computationally expensive because reindexing the corpus
requires re-training the model. In this work, we introduce DSI++, a continual
learning challenge for DSI to incrementally index new documents while being
able to answer queries related to both previously and newly indexed documents.
Across different model scales and document identifier representations, we show
that continual indexing of new documents leads to considerable forgetting of
previously indexed documents. We also hypothesize and verify that the model
experiences forgetting events during training, leading to unstable learning. To
mitigate these issues, we investigate two approaches. The first focuses on
modifying the training dynamics. Flatter minima implicitly alleviate
forgetting, so we optimize for flatter loss basins and show that the model
stably memorizes more documents ($+12\%$). Next, we introduce a generative
memory to sample pseudo-queries for documents and supplement them during
continual indexing to prevent forgetting for the retrieval task. Extensive
experiments on novel continual indexing benchmarks based on Natural Questions
(NQ) and MS MARCO demonstrate that our proposed solution mitigates forgetting
significantly. Concretely, it improves the average Hits@10 by $+21.1\%$ over
competitive baselines for NQ and requires $6$ times fewer model updates
compared to re-training the DSI model for incrementally indexing five corpora
in a sequence.",None,-1
5faaccf1-51c0-4a94-91b9-f37777d08cee,AugTriever: Unsupervised Dense Retrieval by Scalable Data Augmentation,0.665693,"Dense retrievers have made significant strides in text retrieval and
open-domain question answering, even though most achievements were made
possible only with large amounts of human supervision. In this work, we aim to
develop unsupervised methods by proposing two methods that create pseudo
query-document pairs and train dense retrieval models in an annotation-free and
scalable manner: query extraction and transferred query generation. The former
method produces pseudo queries by selecting salient spans from the original
document. The latter utilizes generation models trained for other NLP tasks
(e.g., summarization) to produce pseudo queries. Extensive experiments show
that models trained with the proposed augmentation methods can perform
comparably well (or better) to multiple strong baselines. Combining those
strategies leads to further improvements, achieving the state-of-the-art
performance of unsupervised dense retrieval on both BEIR and ODQA datasets.",None,-1
64863d57-f718-4f2c-b479-ab101a47abce,A Comparison Between Tsetlin Machines and Deep Neural Networks in the Context of Recommendation Systems,0.105515,"Recommendation Systems (RSs) are ubiquitous in modern society and are one of
the largest points of interaction between humans and AI. Modern RSs are often
implemented using deep learning models, which are infamously difficult to
interpret. This problem is particularly exasperated in the context of
recommendation scenarios, as it erodes the user's trust in the RS. In contrast,
the newly introduced Tsetlin Machines (TM) possess some valuable properties due
to their inherent interpretability. TMs are still fairly young as a technology.
As no RS has been developed for TMs before, it has become necessary to perform
some preliminary research regarding the practicality of such a system. In this
paper, we develop the first RS based on TMs to evaluate its practicality in
this application domain. This paper compares the viability of TMs with other
machine learning models prevalent in the field of RS. We train and investigate
the performance of the TM compared with a vanilla feed-forward deep learning
model. These comparisons are based on model performance,
interpretability/explainability, and scalability. Further, we provide some
benchmark performance comparisons to similar machine learning solutions
relevant to RSs.",https://github.com/cair/,-1
71f79d1e-32e3-48bf-bb23-ae3b191bd0f1,Evaluating Step-by-Step Reasoning through Symbolic Verification,0.477801,"Pre-trained language models (LMs) have shown remarkable reasoning performance
using explanations or chain-of-thoughts (CoT)) for in-context learning. On the
other hand, these reasoning tasks are usually presumed to be more approachable
for symbolic programming. To understand the mechanism of reasoning of LMs, we
curate synthetic datasets containing equivalent (natural, symbolic) data pairs,
where symbolic examples contain first-order logic rules and predicates from
non-parametric knowledge bases (KBs), supporting automated verification of
intermediate reasoning results. Then we revisit neuro-symbolic approaches and
propose to learn from demonstrations containing logic rules and corresponding
examples to iteratively reason over KBs, recovering Prolog's backward chaining
algorithm and supporting automated verification of LMs' outputs. Comprehensive
experiments are included to systematically compare LMLP with CoT in deductive
reasoning settings, showing that LMLP enjoys more than $25\%$ higher accuracy
than CoT on length generalization benchmarks even with smaller model sizes.",None,-1
589f856b-590c-49d7-acdb-2bfca533f99f,EventGraph: Event Extraction as Semantic Graph Parsing,0.330405,"Event extraction involves the detection and extraction of both the event
triggers and corresponding event arguments. Existing systems often decompose
event extraction into multiple subtasks, without considering their possible
interactions. In this paper, we propose EventGraph, a joint framework for event
extraction, which encodes events as graphs. We represent event triggers and
arguments as nodes in a semantic graph. Event extraction therefore becomes a
graph parsing problem, which provides the following advantages: 1) performing
event detection and argument extraction jointly; 2) detecting and extracting
multiple events from a piece of text; and 3) capturing the complicated
interaction between event arguments and triggers. Experimental results on
ACE2005 show that our model is competitive to state-of-the-art systems and has
substantially improved the results on argument extraction. Additionally, we
create two new datasets from ACE2005 where we keep the entire text spans for
event arguments, instead of just the head word(s). Our code and models are
released as open-source.",https://github.com/huiling-y/EventGraph,-1
21f14ac2-2a49-42f1-95c9-ad3bb54a9c6a,textless-lib: a Library for Textless Spoken Language Processing,0.976723,"Textless spoken language processing research aims to extend the applicability
of standard NLP toolset onto spoken language and languages with few or no
textual resources. In this paper, we introduce textless-lib, a PyTorch-based
library aimed to facilitate research in this research area. We describe the
building blocks that the library provides and demonstrate its usability by
discuss three different use-case examples: (i) speaker probing, (ii) speech
resynthesis and compression, and (iii) speech continuation. We believe that
textless-lib substantially simplifies research the textless setting and will be
handful not only for speech researchers but also for the NLP community at
large. The code, documentation, and pre-trained models are available at
https://github.com/facebookresearch/textlesslib/ .",https://github.com/facebookresearch/textlesslib/,-1
96412aff-270f-4eaa-89d7-ce9c4cc2514c,Computing and Exploiting Document Structure to Improve Unsupervised Extractive Summarization of Legal Case Decisions,0.554215,"Though many algorithms can be used to automatically summarize legal case
decisions, most fail to incorporate domain knowledge about how important
sentences in a legal decision relate to a representation of its document
structure. For example, analysis of a legal case summarization dataset
demonstrates that sentences serving different types of argumentative roles in
the decision appear in different sections of the document. In this work, we
propose an unsupervised graph-based ranking model that uses a reweighting
algorithm to exploit properties of the document structure of legal case
decisions. We also explore the impact of using different methods to compute the
document structure. Results on the Canadian Legal Case Law dataset show that
our proposed method outperforms several strong baselines.",https://github.com/cs329yangzhong/DocumentStructureLegalSum,-1
a82b58e7-5b20-4ed0-aa02-bfb36c2ab658,CaMEL: Case Marker Extraction without Labels,0.339922,"We introduce CaMEL (Case Marker Extraction without Labels), a novel and
challenging task in computational morphology that is especially relevant for
low-resource languages. We propose a first model for CaMEL that uses a
massively multilingual corpus to extract case markers in 83 languages based
only on a noun phrase chunker and an alignment system. To evaluate CaMEL, we
automatically construct a silver standard from UniMorph. The case markers
extracted by our model can be used to detect and visualise similarities and
differences between the case systems of different languages as well as to
annotate fine-grained deep cases in languages in which they are not overtly
marked.",https://github.com/LeonieWeissweiler/CaMEL,-1
012e6cb5-42be-4180-880f-5de639f1cf35,Exploring Target Representations for Masked Autoencoders,0.889032,"Masked autoencoders have become popular training paradigms for
self-supervised visual representation learning. These models randomly mask a
portion of the input and reconstruct the masked portion according to the target
representations. In this paper, we first show that a careful choice of the
target representation is unnecessary for learning good representations, since
different targets tend to derive similarly behaved models. Driven by this
observation, we propose a multi-stage masked distillation pipeline and use a
randomly initialized model as the teacher, enabling us to effectively train
high-capacity models without any efforts to carefully design target
representations. Interestingly, we further explore using teachers of larger
capacity, obtaining distilled students with remarkable transferring ability. On
different tasks of classification, transfer learning, object detection, and
semantic segmentation, the proposed method to perform masked knowledge
distillation with bootstrapped teachers (dBOT) outperforms previous
self-supervised methods by nontrivial margins. We hope our findings, as well as
the proposed method, could motivate people to rethink the roles of target
representations in pre-training masked autoencoders.The code and pre-trained
models are publicly available at https://github.com/liuxingbin/dbot.",https://github.com/liuxingbin/dbot,28838
35fab2f5-6d71-4687-bb6c-9a0dfc512530,Structured access: an emerging paradigm for safe AI deployment,0.7871,"Structured access is an emerging paradigm for the safe deployment of
artificial intelligence (AI). Instead of openly disseminating AI systems,
developers facilitate controlled, arm's length interactions with their AI
systems. The aim is to prevent dangerous AI capabilities from being widely
accessible, whilst preserving access to AI capabilities that can be used
safely. The developer must both restrict how the AI system can be used, and
prevent the user from circumventing these restrictions through modification or
reverse engineering of the AI system. Structured access is most effective when
implemented through cloud-based AI services, rather than disseminating AI
software that runs locally on users' hardware. Cloud-based interfaces provide
the AI developer greater scope for controlling how the AI system is used, and
for protecting against unauthorized modifications to the system's design. This
chapter expands the discussion of ""publication norms"" in the AI community,
which to date has focused on the question of how the informational content of
AI research projects should be disseminated (e.g., code and models). Although
this is an important question, there are limits to what can be achieved through
the control of information flows. Structured access views AI software not only
as information that can be shared but also as a tool with which users can have
arm's length interactions. There are early examples of structured access being
practiced by AI developers, but there is much room for further development,
both in the functionality of cloud-based interfaces and in the wider
institutional framework.",None,-1
2185e60b-32a0-4913-870b-db376155504c,Join-Chain Network: A Logical Reasoning View of the Multi-head Attention in Transformer,0.0270334,"Developing neural architectures that are capable of logical reasoning has
become increasingly important for a wide range of applications (e.g., natural
language processing). Towards this grand objective, we propose a symbolic
reasoning architecture that chains many join operators together to model output
logical expressions. In particular, we demonstrate that such an ensemble of
join-chains can express a broad subset of ''tree-structured'' first-order
logical expressions, named FOET, which is particularly useful for modeling
natural languages. To endow it with differentiable learning capability, we
closely examine various neural operators for approximating the symbolic
join-chains. Interestingly, we find that the widely used multi-head
self-attention module in transformer can be understood as a special neural
operator that implements the union bound of the join operator in probabilistic
predicate space. Our analysis not only provides a new perspective on the
mechanism of the pretrained models such as BERT for natural language
understanding but also suggests several important future improvement
directions.",None,620
3c928125-865c-4158-bf6f-12a1ddde73a7,Controllable Augmentations for Video Representation Learning,0.132705,"This paper focuses on self-supervised video representation learning. Most
existing approaches follow the contrastive learning pipeline to construct
positive and negative pairs by sampling different clips. However, this
formulation tends to bias to static background and have difficulty establishing
global temporal structures. The major reason is that the positive pairs, i.e.,
different clips sampled from the same video, have limited temporal receptive
field, and usually share similar background but differ in motions. To address
these problems, we propose a framework to jointly utilize local clips and
global videos to learn from detailed region-level correspondence as well as
general long-term temporal relations. Based on a set of controllable
augmentations, we achieve accurate appearance and motion pattern alignment
through soft spatio-temporal region contrast. Our formulation is able to avoid
the low-level redundancy shortcut by mutual information minimization to improve
the generalization. We also introduce local-global temporal order dependency to
further bridge the gap between clip-level and video-level representations for
robust temporal modeling. Extensive experiments demonstrate that our framework
is superior on three video benchmarks in action recognition and video
retrieval, capturing more accurate temporal dynamics.",None,-1
5efb802f-8c69-41a0-8798-1468cc15c790,Quantifying syntax similarity with a polynomial representation of dependency trees,0.533744,"We introduce a graph polynomial that distinguishes tree structures to
represent dependency grammar and a measure based on the polynomial
representation to quantify syntax similarity. The polynomial encodes accurate
and comprehensive information about the dependency structure and dependency
relations of words in a sentence. We apply the polynomial-based methods to
analyze sentences in the Parallel Universal Dependencies treebanks.
Specifically, we compare the syntax of sentences and their translations in
different languages, and we perform a syntactic typology study of available
languages in the Parallel Universal Dependencies treebanks. We also demonstrate
and discuss the potential of the methods in measuring syntax diversity of
corpora.",https://github.com/pliumath/dependencies,-1
292fa82f-badb-442f-ae81-e5b179db9f6b,QUIC-FL: Quick Unbiased Compression for Federated Learning,0.256254,"Distributed Mean Estimation (DME), in which $n$ clients communicate vectors
to a parameter server that estimates their average, is a fundamental building
block in communication-efficient federated learning. In this paper, we improve
on previous DME techniques that achieve the optimal $O(1/n)$ Normalized Mean
Squared Error (NMSE) guarantee by asymptotically improving the complexity for
either encoding or decoding (or both). To achieve this, we formalize the
problem in a novel way that allows us to use off-the-shelf mathematical solvers
to design the quantization.",None,-1
6753d187-9c26-4d2c-bd1b-0d0890dedd4c,Biometric Signature Verification Using Recurrent Neural Networks,0.737732,"Architectures based on Recurrent Neural Networks (RNNs) have been
successfully applied to many different tasks such as speech or handwriting
recognition with state-of-the-art results. The main contribution of this work
is to analyse the feasibility of RNNs for on-line signature verification in
real practical scenarios. We have considered a system based on Long Short-Term
Memory (LSTM) with a Siamese architecture whose goal is to learn a similarity
metric from pairs of signatures. For the experimental work, the BiosecurID
database comprised of 400 users and 4 separated acquisition sessions are
considered. Our proposed LSTM RNN system has outperformed the results of recent
published works on the BiosecurID benchmark in figures ranging from 17.76% to
28.00% relative verification performance improvement for skilled forgeries.",None,-1
6b78f405-1d4a-467a-a02f-0727ca735272,CORL: Research-oriented Deep Offline Reinforcement Learning Library,0.652544,"CORL is an open-source library that provides thoroughly benchmarked
single-file implementations of both deep offline and offline-to-online
reinforcement learning algorithms. It emphasizes a simple developing experience
with a straightforward codebase and a modern analysis tracking tool. In CORL,
we isolate methods implementation into separate single files, making
performance-relevant details easier to recognize. Additionally, an experiment
tracking feature is available to help log metrics, hyperparameters,
dependencies, and more to the cloud. Finally, we have ensured the reliability
of the implementations by benchmarking commonly employed D4RL datasets
providing a transparent source of results that can be reused for robust
evaluation tools such as performance profiles, probability of improvement, or
expected online performance.",https://github.com/corl-team/CORL,-1
85e91acd-e147-4151-983c-a70f6e8528df,Transductive Decoupled Variational Inference for Few-Shot Classification,0.276674,"The versatility to learn from a handful of samples is the hallmark of human
intelligence. Few-shot learning is an endeavour to transcend this capability
down to machines. Inspired by the promise and power of probabilistic deep
learning, we propose a novel variational inference network for few-shot
classification (coined as TRIDENT) to decouple the representation of an image
into semantic and label latent variables, and simultaneously infer them in an
intertwined fashion. To induce task-awareness, as part of the inference
mechanics of TRIDENT, we exploit information across both query and support
images of a few-shot task using a novel built-in attention-based transductive
feature extraction module (we call AttFEX). Our extensive experimental results
corroborate the efficacy of TRIDENT and demonstrate that, using the simplest of
backbones, it sets a new state-of-the-art in the most commonly adopted datasets
miniImageNet and tieredImageNet (offering up to 4% and 5% improvements,
respectively), as well as for the recent challenging cross-domain miniImagenet
--> CUB scenario offering a significant margin (up to 20% improvement) beyond
the best existing cross-domain baselines. Code and experimentation can be found
in our GitHub repository: https://github.com/anujinho/trident",https://github.com/anujinho/trident,-1
ef288dc4-4f08-4a85-885e-ab3147df2283,Momentum Calibration for Text Generation,0.519748,"The input and output of most text generation tasks can be transformed to two
sequences of tokens and they can be modeled using sequence-to-sequence learning
modeling tools such as Transformers. These models are usually trained by
maximizing the likelihood the output text sequence and assumes the input
sequence and all gold preceding tokens are given during training, while during
inference the model suffers from the exposure bias problem (i.e., it only has
access to its previously predicted tokens rather gold tokens during beam
search). In this paper, we propose MoCa ({\bf Mo}mentum {\bf Ca}libration) for
text generation. MoCa is an online method that dynamically generates slowly
evolving (but consistent) samples using a momentum moving average generator
with beam search and MoCa learns to align its model scores of these samples
with their actual qualities. Experiments on four text generation datasets
(i.e., CNN/DailyMail, XSum, SAMSum and Gigaword) show MoCa consistently
improves strong pre-trained transformers using vanilla fine-tuning and we
achieve the state-of-the-art results on CNN/DailyMail and SAMSum datasets.",None,-1
0258bee3-16ad-4821-abdc-b0754bf22404,Exploring Dimensionality Reduction Techniques in Multilingual Transformers,0.213116,"Both in scientific literature and in industry,, Semantic and context-aware
Natural Language Processing-based solutions have been gaining importance in
recent years. The possibilities and performance shown by these models when
dealing with complex Language Understanding tasks is unquestionable, from
conversational agents to the fight against disinformation in social networks.
In addition, considerable attention is also being paid to developing
multilingual models to tackle the language bottleneck. The growing need to
provide more complex models implementing all these features has been
accompanied by an increase in their size, without being conservative in the
number of dimensions required. This paper aims to give a comprehensive account
of the impact of a wide variety of dimensional reduction techniques on the
performance of different state-of-the-art multilingual Siamese Transformers,
including unsupervised dimensional reduction techniques such as linear and
nonlinear feature extraction, feature selection, and manifold techniques. In
order to evaluate the effects of these techniques, we considered the
multilingual extended version of Semantic Textual Similarity Benchmark (mSTSb)
and two different baseline approaches, one using the pre-trained version of
several models and another using their fine-tuned STS version. The results
evidence that it is possible to achieve an average reduction in the number of
dimensions of $91.58\% \pm 2.59\%$ and $54.65\% \pm 32.20\%$, respectively.
This work has also considered the consequences of dimensionality reduction for
visualization purposes. The results of this study will significantly contribute
to the understanding of how different tuning approaches affect performance on
semantic-aware tasks and how dimensional reduction techniques deal with the
high-dimensional embeddings computed for the STS task and their potential for
highly demanding NLP tasks",None,-1
83f157d5-b6f9-4091-8d4a-10ee8195ad62,An Interpretability Evaluation Benchmark for Pre-trained Language Models,0.0802763,"While pre-trained language models (LMs) have brought great improvements in
many NLP tasks, there is increasing attention to explore capabilities of LMs
and interpret their predictions. However, existing works usually focus only on
a certain capability with some downstream tasks. There is a lack of datasets
for directly evaluating the masked word prediction performance and the
interpretability of pre-trained LMs. To fill in the gap, we propose a novel
evaluation benchmark providing with both English and Chinese annotated data. It
tests LMs abilities in multiple dimensions, i.e., grammar, semantics,
knowledge, reasoning and computation. In addition, it provides carefully
annotated token-level rationales that satisfy sufficiency and compactness. It
contains perturbed instances for each original instance, so as to use the
rationale consistency under perturbations as the metric for faithfulness, a
perspective of interpretability. We conduct experiments on several widely-used
pre-trained LMs. The results show that they perform very poorly on the
dimensions of knowledge and computation. And their plausibility in all
dimensions is far from satisfactory, especially when the rationale is short. In
addition, the pre-trained LMs we evaluated are not robust on syntax-aware data.
We will release this evaluation benchmark at \url{http://xyz}, and hope it can
facilitate the research progress of pre-trained LMs.",None,-1
74af7c23-30f9-460c-84d2-1254cf6a31a3,Generate rather than Retrieve: Large Language Models are Strong Context Generators,0.815401,"Knowledge-intensive tasks, such as open-domain question answering (QA),
require access to a large amount of world or domain knowledge. A common
approach for knowledge-intensive tasks is to employ a retrieve-then-read
pipeline that first retrieves a handful of relevant contextual documents from
an external corpus such as Wikipedia and then predicts an answer conditioned on
the retrieved documents. In this paper, we present a novel perspective for
solving knowledge-intensive tasks by replacing document retrievers with large
language model generators. We call our method generate-then-read (GenRead),
which first prompts a large language model to generate contextutal documents
based on a given question, and then reads the generated documents to produce
the final answer. Furthermore, we propose a novel clustering-based prompting
method that selects distinct prompts, resulting in the generated documents that
cover different perspectives, leading to better recall over acceptable answers.
We conduct extensive experiments on three different knowledge-intensive tasks,
including open-domain QA, fact checking, and dialogue system. Notably, GenRead
achieves 71.6 and 54.4 exact match scores on TriviaQA and WebQ, significantly
outperforming the state-of-the-art retrieve-then-read pipeline DPR-FiD by +4.0
and +3.9, without retrieving any documents from any external knowledge source.
Lastly, we demonstrate the model performance can be further improved by
combining retrieval and generation. Our code and generated documents can be
found at https://github.com/wyu97/GenRead.",https://github.com/wyu97/GenRead,-1
a2d9f8c2-318d-42dc-afdb-119052f9de0c,Out-Of-Distribution Detection In Unsupervised Continual Learning,0.426876,"Unsupervised continual learning aims to learn new tasks incrementally without
requiring human annotations. However, most existing methods, especially those
targeted on image classification, only work in a simplified scenario by
assuming all new data belong to new tasks, which is not realistic if the class
labels are not provided. Therefore, to perform unsupervised continual learning
in real life applications, an out-of-distribution detector is required at
beginning to identify whether each new data corresponds to a new task or
already learned tasks, which still remains under-explored yet. In this work, we
formulate the problem for Out-of-distribution Detection in Unsupervised
Continual Learning (OOD-UCL) with the corresponding evaluation protocol. In
addition, we propose a novel OOD detection method by correcting the output bias
at first and then enhancing the output confidence for in-distribution data
based on task discriminativeness, which can be applied directly without
modifying the learning procedures and objectives of continual learning. Our
method is evaluated on CIFAR-100 dataset by following the proposed evaluation
protocol and we show improved performance compared with existing OOD detection
methods under the unsupervised continual learning scenario.",None,-1
cd5f14eb-60ab-43d7-b32f-3da9f482d88f,"Generated Faces in the Wild: Quantitative Comparison of Stable Diffusion, Midjourney and DALL-E 2",0.884732,"The field of image synthesis has made great strides in the last couple of
years. Recent models are capable of generating images with astonishing quality.
Fine-grained evaluation of these models on some interesting categories such as
faces is still missing. Here, we conduct a quantitative comparison of three
popular systems including Stable Diffusion, Midjourney, and DALL-E 2 in their
ability to generate photorealistic faces in the wild. We find that Stable
Diffusion generates better faces than the other systems, according to the FID
score. We also introduce a dataset of generated faces in the wild dubbed GFW,
including a total of 15,076 faces. Furthermore, we hope that our study spurs
follow-up research in assessing the generative models and improving them. Data
and code are available at data and code, respectively.",None,-1
1422a914-0235-4af1-b161-918170c5adbb,Towards a Grounded Theory of Causation for Embodied AI,0.212008,"There exist well-developed frameworks for causal modelling, but these require
rather a lot of human domain expertise to define causal variables and perform
interventions. In order to enable autonomous agents to learn abstract causal
models through interactive experience, the existing theoretical foundations
need to be extended and clarified. Existing frameworks give no guidance
regarding variable choice / representation, and more importantly, give no
indication as to which behaviour policies or physical transformations of state
space shall count as interventions. The framework sketched in this paper
describes actions as transformations of state space, for instance induced by an
agent running a policy. This makes it possible to describe in a uniform way
both transformations of the micro-state space and abstract models thereof, and
say when the latter is veridical / grounded / natural. We then introduce
(causal) variables, define a mechanism as an invariant predictor, and say when
an action can be viewed as a ``surgical intervention'', thus bringing the
objective of causal representation \& intervention skill learning into clearer
focus.",None,-1
824cb229-33a0-4c6e-9f17-2c0133c0ba4c,Are Sample-Efficient NLP Models More Robust?,0.242371,"Recent results in image classification and extractive question answering have
observed that pre-trained models trained on less in-distribution data have
better out-of-distribution performance. However, it is unclear how broadly
these trends hold. We conduct a large empirical study across three tasks, three
broadly-applicable modeling interventions (increasing model size, using a
different adaptation method, and pre-training on more data), and 14 diverse
datasets to investigate the relationship between sample efficiency (amount of
data needed to reach a given ID accuracy) and robustness (how models fare on
OOD evaluation). We find that higher sample efficiency is only correlated with
better average OOD robustness on some modeling interventions and tasks, but not
others. On individual datasets, models with lower sample efficiency can even be
more robust. These results suggest that general-purpose methods for improving
sample efficiency are unlikely to yield universal OOD robustness improvements,
since such improvements are highly dataset- and task-dependent. Even in an era
of large, multi-purpose pretrained models, task-specific decisions may often be
necessary for OOD generalization.",None,-1
0f28f945-a95e-4e3f-b15e-bbaf7b3a3ee4,Prompt Consistency for Zero-Shot Task Generalization,0.569058,"One of the most impressive results of recent NLP history is the ability of
pre-trained language models to solve new tasks in a zero-shot setting. To
achieve this, NLP tasks are framed as natural language prompts, generating a
response indicating the predicted output. Nonetheless, the performance in such
settings often lags far behind its supervised counterpart, suggesting a large
space for potential improvement. In this paper, we explore methods to utilize
unlabeled data to improve zero-shot performance. Specifically, we take
advantage of the fact that multiple prompts can be used to specify a single
task, and propose to regularize prompt consistency, encouraging consistent
predictions over this diverse set of prompts. Our method makes it possible to
fine-tune the model either with extra unlabeled training data, or directly on
test input at inference time in an unsupervised manner. In experiments, our
approach outperforms the state-of-the-art zero-shot learner, T0 (Sanh et al.,
2022), on 9 out of 11 datasets across 4 NLP tasks by up to 10.6 absolute points
in terms of accuracy. The gains are often attained with a small number of
unlabeled examples.",https://github.com/violet-zct/swarm-distillation-zero-shot,33484
be893813-1bca-4bb2-b432-bab4c507292c,Semantic Guided Level-Category Hybrid Prediction Network for Hierarchical Image Classification,0.163349,"Hierarchical classification (HC) assigns each object with multiple labels
organized into a hierarchical structure. The existing deep learning based HC
methods usually predict an instance starting from the root node until a leaf
node is reached. However, in the real world, images interfered by noise,
occlusion, blur, or low resolution may not provide sufficient information for
the classification at subordinate levels. To address this issue, we propose a
novel semantic guided level-category hybrid prediction network (SGLCHPN) that
can jointly perform the level and category prediction in an end-to-end manner.
SGLCHPN comprises two modules: a visual transformer that extracts feature
vectors from the input images, and a semantic guided cross-attention module
that uses categories word embeddings as queries to guide learning
category-specific representations. In order to evaluate the proposed method, we
construct two new datasets in which images are at a broad range of quality and
thus are labeled to different levels (depths) in the hierarchy according to
their individual quality. Experimental results demonstrate the effectiveness of
our proposed HC method.",None,-1
f520624f-d225-48b9-a2e0-5588dc15e7d3,Multimodal Transformer for Nursing Activity Recognition,0.805429,"In an aging population, elderly patient safety is a primary concern at
hospitals and nursing homes, which demands for increased nurse care. By
performing nurse activity recognition, we can not only make sure that all
patients get an equal desired care, but it can also free nurses from manual
documentation of activities they perform, leading to a fair and safe place of
care for the elderly. In this work, we present a multimodal transformer-based
network, which extracts features from skeletal joints and acceleration data,
and fuses them to perform nurse activity recognition. Our method achieves
state-of-the-art performance of 81.8% accuracy on the benchmark dataset
available for nurse activity recognition from the Nurse Care Activity
Recognition Challenge. We perform ablation studies to show that our fusion
model is better than single modality transformer variants (using only
acceleration or skeleton joints data). Our solution also outperforms
state-of-the-art ST-GCN, GRU and other classical hand-crafted-feature-based
classifier solutions by a margin of 1.6%, on the NCRC dataset. Code is
available at \url{https://github.com/Momilijaz96/MMT_for_NCRC}.",https://github.com/Momilijaz96/MMT_for_NCRC,-1
9381c5ce-d97d-40f4-801c-c25647908de3,LightX3ECG: A Lightweight and eXplainable Deep Learning System for 3-lead Electrocardiogram Classification,0.964725,"Cardiovascular diseases (CVDs) are a group of heart and blood vessel
disorders that is one of the most serious dangers to human health, and the
number of such patients is still growing. Early and accurate detection plays a
key role in successful treatment and intervention. Electrocardiogram (ECG) is
the gold standard for identifying a variety of cardiovascular abnormalities. In
clinical practices and most of the current research, standard 12-lead ECG is
mainly used. However, using a lower number of leads can make ECG more prevalent
as it can be conveniently recorded by portable or wearable devices. In this
research, we develop a novel deep learning system to accurately identify
multiple cardiovascular abnormalities by using only three ECG leads.",https://github.com/lhkhiem28/LightX3ECG,-1
4dba6289-693a-4c17-82f8-d26666075f90,Randomized Sharpness-Aware Training for Boosting Computational Efficiency in Deep Learning,0.0419788,"By driving models to converge to flat minima, sharpness-aware learning
algorithms (such as SAM) have shown the power to achieve state-of-the-art
performances. However, these algorithms will generally incur one extra
forward-backward propagation at each training iteration, which largely burdens
the computation especially for scalable models. To this end, we propose a
simple yet efficient training scheme, called Randomized Sharpness-Aware
Training (RST). Optimizers in RST would perform a Bernoulli trial at each
iteration to choose randomly from base algorithms (SGD) and sharpness-aware
algorithms (SAM) with a probability arranged by a predefined scheduling
function. Due to the mixture of base algorithms, the overall count of
propagation pairs could be largely reduced. Also, we give theoretical analysis
on the convergence of RST. Then, we empirically study the computation cost and
effect of various types of scheduling functions, and give directions on setting
appropriate scheduling functions. Further, we extend the RST to a general
framework (G-RST), where we can adjust regularization degree on sharpness
freely for any scheduling function. We show that G-RST can outperform SAM in
most cases while saving 50\% extra computation cost.",https://github.com/Mi-Peng/Sparse-Sharpness-Aware-Minimization,-1
810a66dd-0e09-4bfb-93ca-08d2dcb801ce,Track Targets by Dense Spatio-Temporal Position Encoding,0.693672,"In this work, we propose a novel paradigm to encode the position of targets
for target tracking in videos using transformers. The proposed paradigm, Dense
Spatio-Temporal (DST) position encoding, encodes spatio-temporal position
information in a pixel-wise dense fashion. The provided position encoding
provides location information to associate targets across frames beyond
appearance matching by comparing objects in two bounding boxes. Compared to the
typical transformer positional encoding, our proposed encoding is applied to
the 2D CNN features instead of the projected feature vectors to avoid losing
positional information. Moreover, the designed DST encoding can represent the
location of a single-frame object and the evolution of the location of the
trajectory among frames uniformly. Integrated with the DST encoding, we build a
transformer-based multi-object tracking model. The model takes a video clip as
input and conducts the target association in the clip. It can also perform
online inference by associating existing trajectories with objects from the
new-coming frames. Experiments on video multi-object tracking (MOT) and
multi-object tracking and segmentation (MOTS) datasets demonstrate the
effectiveness of the proposed DST position encoding.",https://github.com/open-mmlab/mmtracking,-1
0c409e0a-63f2-4779-8841-a33fa73793e5,MTEB: Massive Text Embedding Benchmark,0.985442,"Text embeddings are commonly evaluated on a small set of datasets from a
single task not covering their possible applications to other tasks. It is
unclear whether state-of-the-art embeddings on semantic textual similarity
(STS) can be equally well applied to other tasks like clustering or reranking.
This makes progress in the field difficult to track, as various models are
constantly being proposed without proper evaluation. To solve this problem, we
introduce the Massive Text Embedding Benchmark (MTEB). MTEB spans 8 embedding
tasks covering a total of 58 datasets and 112 languages. Through the
benchmarking of 33 models on MTEB, we establish the most comprehensive
benchmark of text embeddings to date. We find that no particular text embedding
method dominates across all tasks. This suggests that the field has yet to
converge on a universal text embedding method and scale it up sufficiently to
provide state-of-the-art results on all embedding tasks. MTEB comes with
open-source code and a public leaderboard at
https://github.com/embeddings-benchmark/mteb.",None,-1
aecdf56b-3035-4533-8a44-0e74a8bea6a6,EasyNLP: A Comprehensive and Easy-to-use Toolkit for Natural Language Processing,0.418941,"The success of Pre-Trained Models (PTMs) has reshaped the development of
Natural Language Processing (NLP). Yet, it is not easy to obtain
high-performing models and deploy them online for industrial practitioners. To
bridge this gap, EasyNLP is designed to make it easy to build NLP applications,
which supports a comprehensive suite of NLP algorithms. It further features
knowledge-enhanced pre-training, knowledge distillation and few-shot learning
functionalities for large-scale PTMs, and provides a unified framework of model
training, inference and deployment for real-world applications. Currently,
EasyNLP has powered over ten business units within Alibaba Group and is
seamlessly integrated to the Platform of AI (PAI) products on Alibaba Cloud.
The source code of our EasyNLP toolkit is released at GitHub
(https://github.com/alibaba/EasyNLP).",https://github.com/alibaba/EasyNLP,-1
7ba53a1c-3231-416b-a8c3-9e75c8656a85,GanLM: Encoder-Decoder Pre-training with an Auxiliary Discriminator,0.652066,"Pre-trained models have achieved remarkable success in natural language
processing (NLP). However, existing pre-training methods underutilize the
benefits of language understanding for generation. Inspired by the idea of
Generative Adversarial Networks (GANs), we propose a GAN-style model for
encoder-decoder pre-training by introducing an auxiliary discriminator,
unifying the ability of language understanding and generation in a single
model. Our model, named as GanLM, is trained with two pre-training objectives:
replaced token detection and replaced token denoising. Specifically, given
masked source sentences, the generator outputs the target distribution and the
discriminator predicts whether the target sampled tokens from distribution are
incorrect. The target sentence is replaced with misclassified tokens to
construct noisy previous context, which is used to generate the gold sentence.
In general, both tasks improve the ability of language understanding and
generation by selectively using the denoising data. Extensive experiments in
language generation benchmarks show that GanLM with the powerful language
understanding capability outperforms various strong pre-trained language models
(PLMs) and achieves state-of-the-art performance.",https://github.com/CSJianYang/GanLM,-1
ee98548c-763c-4b30-b0de-4dbff1822302,SEAT: Stable and Explainable Attention,0.3239,"Currently, attention mechanism becomes a standard fixture in most
state-of-the-art natural language processing (NLP) models, not only due to
outstanding performance it could gain, but also due to plausible innate
explanation for the behaviors of neural architectures it provides, which is
notoriously difficult to analyze. However, recent studies show that attention
is unstable against randomness and perturbations during training or testing,
such as random seeds and slight perturbation of embedding vectors, which
impedes it from becoming a faithful explanation tool. Thus, a natural question
is whether we can find some substitute of the current attention which is more
stable and could keep the most important characteristics on explanation and
prediction of attention. In this paper, to resolve the problem, we provide a
first rigorous definition of such alternate namely SEAT (Stable and Explainable
Attention). Specifically, a SEAT should has the following three properties: (1)
Its prediction distribution is enforced to be close to the distribution based
on the vanilla attention; (2) Its top-k indices have large overlaps with those
of the vanilla attention; (3) It is robust w.r.t perturbations, i.e., any
slight perturbation on SEAT will not change the prediction distribution too
much, which implicitly indicates that it is stable to randomness and
perturbations. Finally, through intensive experiments on various datasets, we
compare our SEAT with other baseline methods using RNN, BiLSTM and BERT
architectures via six different evaluation metrics for model interpretation,
stability and accuracy. Results show that SEAT is more stable against different
perturbations and randomness while also keeps the explainability of attention,
which indicates it is a more faithful explanation. Moreover, compared with
vanilla attention, there is almost no utility (accuracy) degradation for SEAT.",None,-1
56335260-5663-487c-bf78-5c594f8cb63a,How can NLP Help Revitalize Endangered Languages? A Case Study and Roadmap for the Cherokee Language,0.136946,"More than 43% of the languages spoken in the world are endangered, and
language loss currently occurs at an accelerated rate because of globalization
and neocolonialism. Saving and revitalizing endangered languages has become
very important for maintaining the cultural diversity on our planet. In this
work, we focus on discussing how NLP can help revitalize endangered languages.
We first suggest three principles that may help NLP practitioners to foster
mutual understanding and collaboration with language communities, and we
discuss three ways in which NLP can potentially assist in language education.
We then take Cherokee, a severely-endangered Native American language, as a
case study. After reviewing the language's history, linguistic features, and
existing resources, we (in collaboration with Cherokee community members)
arrive at a few meaningful ways NLP practitioners can collaborate with
community partners. We suggest two approaches to enrich the Cherokee language's
resources with machine-in-the-loop processing, and discuss several NLP tools
that people from the Cherokee community have shown interest in. We hope that
our work serves not only to inform the NLP community about Cherokee, but also
to provide inspiration for future work on endangered languages in general. Our
code and data will be open-sourced at
https://github.com/ZhangShiyue/RevitalizeCherokee",https://github.com/ZhangShiyue/RevitalizeCherokee,-1
4ff88da4-03b8-413e-884c-ffc44e69a82c,Decoupling Makes Weakly Supervised Local Feature Better,0.90894,"Weakly supervised learning can help local feature methods to overcome the
obstacle of acquiring a large-scale dataset with densely labeled
correspondences. However, since weak supervision cannot distinguish the losses
caused by the detection and description steps, directly conducting weakly
supervised learning within a joint describe-then-detect pipeline suffers
limited performance. In this paper, we propose a decoupled describe-then-detect
pipeline tailored for weakly supervised local feature learning. Within our
pipeline, the detection step is decoupled from the description step and
postponed until discriminative and robust descriptors are learned. In addition,
we introduce a line-to-window search strategy to explicitly use the camera pose
information for better descriptor learning. Extensive experiments show that our
method, namely PoSFeat (Camera Pose Supervised Feature), outperforms previous
fully and weakly supervised methods and achieves state-of-the-art performance
on a wide range of downstream tasks.",https://github.com/The-Learning-And-Vision-Atelier-LAVA/PoSFeat,-1
b4ede44d-3da9-4441-b628-dbe94408c0b3,Learning Controllable 3D Level Generators,0.598215,"Procedural Content Generation via Reinforcement Learning (PCGRL) foregoes the
need for large human-authored data-sets and allows agents to train explicitly
on functional constraints, using computable, user-defined measures of quality
instead of target output. We explore the application of PCGRL to 3D domains, in
which content-generation tasks naturally have greater complexity and potential
pertinence to real-world applications. Here, we introduce several PCGRL tasks
for the 3D domain, Minecraft (Mojang Studios, 2009). These tasks will challenge
RL-based generators using affordances often found in 3D environments, such as
jumping, multiple dimensional movement, and gravity. We train an agent to
optimize each of these tasks to explore the capabilities of previous research
in PCGRL. This agent is able to generate relatively complex and diverse levels,
and generalize to random initial states and control targets. Controllability
tests in the presented tasks demonstrate their utility to analyze success and
failure for 3D generators.",https://github.com/smearle/control-pcgrl,-1
84e8aa5c-7482-4a82-9426-05f68d250e2b,Type-aware Embeddings for Multi-Hop Reasoning over Knowledge Graphs,0.695082,"Multi-hop reasoning over real-life knowledge graphs (KGs) is a highly
challenging problem as traditional subgraph matching methods are not capable to
deal with noise and missing information. To address this problem, it has been
recently introduced a promising approach based on jointly embedding logical
queries and KGs into a low-dimensional space to identify answer entities.
However, existing proposals ignore critical semantic knowledge inherently
available in KGs, such as type information. To leverage type information, we
propose a novel TypE-aware Message Passing (TEMP) model, which enhances the
entity and relation representations in queries, and simultaneously improves
generalization, deductive and inductive reasoning. Remarkably, TEMP is a
plug-and-play model that can be easily incorporated into existing
embedding-based models to improve their performance. Extensive experiments on
three real-world datasets demonstrate TEMP's effectiveness.",https://github.com/zhiweihu1103/QE-TEMP,-1
cd9eb521-ec4b-4f06-87b9-69f98f279a7c,Model Criticism for Long-Form Text Generation,0.0636916,"Language models have demonstrated the ability to generate highly fluent text;
however, it remains unclear whether their output retains coherent high-level
structure (e.g., story progression). Here, we propose to apply a statistical
tool, model criticism in latent space, to evaluate the high-level structure of
the generated text. Model criticism compares the distributions between real and
generated data in a latent space obtained according to an assumptive generative
process. Different generative processes identify specific failure modes of the
underlying model. We perform experiments on three representative aspects of
high-level discourse -- coherence, coreference, and topicality -- and find that
transformer-based language models are able to capture topical structures but
have a harder time maintaining structural coherence or modeling coreference.",None,-1
3a80b5af-2a81-4653-8d90-68e312fba8e2,Probabilistic Warp Consistency for Weakly-Supervised Semantic Correspondences,0.816864,"We propose Probabilistic Warp Consistency, a weakly-supervised learning
objective for semantic matching. Our approach directly supervises the dense
matching scores predicted by the network, encoded as a conditional probability
distribution. We first construct an image triplet by applying a known warp to
one of the images in a pair depicting different instances of the same object
class. Our probabilistic learning objectives are then derived using the
constraints arising from the resulting image triplet. We further account for
occlusion and background clutter present in real image pairs by extending our
probabilistic output space with a learnable unmatched state. To supervise it,
we design an objective between image pairs depicting different object classes.
We validate our method by applying it to four recent semantic matching
architectures. Our weakly-supervised approach sets a new state-of-the-art on
four challenging semantic matching benchmarks. Lastly, we demonstrate that our
objective also brings substantial improvements in the strongly-supervised
regime, when combined with keypoint annotations.",https://github.com/PruneTruong/DenseMatching,-1
e2bb01d6-a2ee-4164-8c29-9cdfc9447dc6,Finding the optimal human strategy for Wordle using maximum correct letter probabilities and reinforcement learning,0.297163,"Wordle is an online word puzzle game that gained viral popularity in January
2022. The goal is to guess a hidden five letter word. After each guess, the
player gains information about whether the letters they guessed are present in
the word, and whether they are in the correct position. Numerous blogs have
suggested guessing strategies and starting word lists that improve the chance
of winning. Optimized algorithms can win 100% of games within five of the six
allowed trials. However, it is infeasible for human players to use these
algorithms due to an inability to perfectly recall all known 5-letter words and
perform complex calculations that optimize information gain. Here, we present
two different methods for choosing starting words along with a framework for
discovering the optimal human strategy based on reinforcement learning. Human
Wordle players can use the rules we discover to optimize their chance of
winning.",https://github.com/benton-anderson/wordle-opt,-1
4953dd6a-adc1-43d8-b712-1350fcf34ef1,SeqZero: Few-shot Compositional Semantic Parsing with Sequential Prompts and Zero-shot Models,0.787109,"Recent research showed promising results on combining pretrained language
models (LMs) with canonical utterance for few-shot semantic parsing. The
canonical utterance is often lengthy and complex due to the compositional
structure of formal languages. Learning to generate such canonical utterance
requires significant amount of data to reach high performance. Fine-tuning with
only few-shot samples, the LMs can easily forget pretrained knowledge, overfit
spurious biases, and suffer from compositionally out-of-distribution
generalization errors. To tackle these issues, we propose a novel few-shot
semantic parsing method -- SeqZero. SeqZero decomposes the problem into a
sequence of sub-problems, which correspond to the sub-clauses of the formal
language. Based on the decomposition, the LMs only need to generate short
answers using prompts for predicting sub-clauses. Thus, SeqZero avoids
generating a long canonical utterance at once. Moreover, SeqZero employs not
only a few-shot model but also a zero-shot model to alleviate the overfitting.
In particular, SeqZero brings out the merits from both models via ensemble
equipped with our proposed constrained rescaling. SeqZero achieves SOTA
performance of BART-based models on GeoQuery and EcommerceQuery, which are two
few-shot datasets with compositional data split.",https://github.com/amzn/SeqZero,-1
43eea4b4-7e90-4bf2-ab08-345ece8f9d84,Improving Chinese Story Generation via Awareness of Syntactic Dependencies and Semantics,0.784396,"Story generation aims to generate a long narrative conditioned on a given
input. In spite of the success of prior works with the application of
pre-trained models, current neural models for Chinese stories still struggle to
generate high-quality long text narratives. We hypothesise that this stems from
ambiguity in syntactically parsing the Chinese language, which does not have
explicit delimiters for word segmentation. Consequently, neural models suffer
from the inefficient capturing of features in Chinese narratives. In this
paper, we present a new generation framework that enhances the feature
capturing mechanism by informing the generation model of dependencies between
words and additionally augmenting the semantic representation learning through
synonym denoising training. We conduct a range of experiments, and the results
demonstrate that our framework outperforms the state-of-the-art Chinese
generation models on all evaluation metrics, demonstrating the benefits of
enhanced dependency and semantic representation learning.",https://github.com/hehedaozuiteng/Chinese-Story-Generation,-1
d469dd03-7a84-4b36-ae46-0530a82f3499,GreaseLM: Graph REASoning Enhanced Language Models for Question Answering,0.99987,"Answering complex questions about textual narratives requires reasoning over
both stated context and the world knowledge that underlies it. However,
pretrained language models (LM), the foundation of most modern QA systems, do
not robustly represent latent relationships between concepts, which is
necessary for reasoning. While knowledge graphs (KG) are often used to augment
LMs with structured representations of world knowledge, it remains an open
question how to effectively fuse and reason over the KG representations and the
language context, which provides situational constraints and nuances. In this
work, we propose GreaseLM, a new model that fuses encoded representations from
pretrained LMs and graph neural networks over multiple layers of modality
interaction operations. Information from both modalities propagates to the
other, allowing language context representations to be grounded by structured
world knowledge, and allowing linguistic nuances (e.g., negation, hedging) in
the context to inform the graph representations of knowledge. Our results on
three benchmarks in the commonsense reasoning (i.e., CommonsenseQA, OpenbookQA)
and medical question answering (i.e., MedQA-USMLE) domains demonstrate that
GreaseLM can more reliably answer questions that require reasoning over both
situational constraints and structured knowledge, even outperforming models 8x
larger.",https://github.com/snap-stanford/GreaseLM,-1
2cb29cc0-2638-4b56-92fb-72bfd1b43fc9,The Open corpus of the Veps and Karelian languages: overview and applications,0.148962,"A growing priority in the study of Baltic-Finnic languages of the Republic of
Karelia has been the methods and tools of corpus linguistics. Since 2016,
linguists, mathematicians, and programmers at the Karelian Research Centre have
been working with the Open Corpus of the Veps and Karelian Languages (VepKar),
which is an extension of the Veps Corpus created in 2009. The VepKar corpus
comprises texts in Karelian and Veps, multifunctional dictionaries linked to
them, and software with an advanced system of search using various criteria of
the texts (language, genre, etc.) and numerous linguistic categories (lexical
and grammatical search in texts was implemented thanks to the generator of word
forms that we created earlier). A corpus of 3000 texts was compiled, texts were
uploaded and marked up, the system for classifying texts into languages,
dialects, types and genres was introduced, and the word-form generator was
created. Future plans include developing a speech module for working with audio
recordings and a syntactic tagging module using morphological analysis outputs.
Owing to continuous functional advancements in the corpus manager and ongoing
VepKar enrichment with new material and text markup, users can handle a wide
range of scientific and applied tasks. In creating the universal national
VepKar corpus, its developers and managers strive to preserve and exhibit as
fully as possible the state of the Veps and Karelian languages in the 19th-21st
centuries.",https://github.com/componavt/sanahelmi,-1
859cef92-9adf-4aae-848a-40146f849186,Efficient Representations of Object Geometry for Reinforcement Learning of Interactive Grasping Policies,0.239879,"Grasping objects of different shapes and sizes - a foundational, effortless
skill for humans - remains a challenging task in robotics. Although model-based
approaches can predict stable grasp configurations for known object models,
they struggle to generalize to novel objects and often operate in a
non-interactive open-loop manner. In this work, we present a reinforcement
learning framework that learns the interactive grasping of various
geometrically distinct real-world objects by continuously controlling an
anthropomorphic robotic hand. We explore several explicit representations of
object geometry as input to the policy. Moreover, we propose to inform the
policy implicitly through signed distances and show that this is naturally
suited to guide the search through a shaped reward component. Finally, we
demonstrate that the proposed framework is able to learn even in more
challenging conditions, such as targeted grasping from a cluttered bin.
Necessary pre-grasping behaviors such as object reorientation and utilization
of environmental constraints emerge in this case. Videos of learned interactive
policies are available at https://maltemosbach.github.
io/geometry_aware_grasping_policies.",https://maltemosbach.github.io/geometry_aware_grasping_policies,-1
d22a3bc2-d10e-435d-be8e-d49f4cadcc79,MHMS: Multimodal Hierarchical Multimedia Summarization,0.67204,"Multimedia summarization with multimodal output can play an essential role in
real-world applications, i.e., automatically generating cover images and titles
for news articles or providing introductions to online videos. In this work, we
propose a multimodal hierarchical multimedia summarization (MHMS) framework by
interacting visual and language domains to generate both video and textual
summaries. Our MHMS method contains video and textual segmentation and
summarization module, respectively. It formulates a cross-domain alignment
objective with optimal transport distance which leverages cross-domain
interaction to generate the representative keyframe and textual summary. We
evaluated MHMS on three recent multimodal datasets and demonstrated the
effectiveness of our method in producing high-quality multimodal summaries.",None,-1
a81d5119-7972-4cd6-8d64-766964dac260,Large vocabulary speech recognition for languages of Africa: multilingual modeling and self-supervised learning,0.31767,"Almost none of the 2,000+ languages spoken in Africa have widely available
automatic speech recognition systems, and the required data is also only
available for a few languages. We have experimented with two techniques which
may provide pathways to large vocabulary speech recognition for African
languages: multilingual modeling and self-supervised learning. We gathered
available open source data and collected data for 15 languages, and trained
experimental models using these techniques. Our results show that pooling the
small amounts of data available in multilingual end-to-end models, and
pre-training on unsupervised data can help improve speech recognition quality
for many African languages.",None,-1
25f71a7d-e01b-4ab5-b63e-e812c59d6cce,Multi-Event-Camera Depth Estimation and Outlier Rejection by Refocused Events Fusion,0.825855,"Event cameras are bio-inspired sensors that offer advantages over traditional
cameras. They operate asynchronously, sampling the scene at microsecond
resolution and producing a stream of brightness changes. This unconventional
output has sparked novel computer vision methods to unlock the camera's
potential. Here, the problem of event-based stereo 3D reconstruction for SLAM
is considered. Most event-based stereo methods attempt to exploit the high
temporal resolution of the camera and the simultaneity of events across cameras
to establish matches and estimate depth. By contrast, this work investigates
how to estimate depth without explicit data association by fusing Disparity
Space Images (DSIs) originated in efficient monocular methods. Fusion theory is
developed and applied to design multi-camera 3D reconstruction algorithms that
produce state-of-the-art results, as confirmed by comparisons with four
baseline methods and tests on a variety of available datasets.",https://github.com/tub-rip/dvs mcemvs,-1
ab262d17-e9ef-4e5f-a544-46352d1bc170,MoSE: Modality Split and Ensemble for Multimodal Knowledge Graph Completion,0.821856,"Multimodal knowledge graph completion (MKGC) aims to predict missing entities
in MKGs. Previous works usually share relation representation across
modalities. This results in mutual interference between modalities during
training, since for a pair of entities, the relation from one modality probably
contradicts that from another modality. Furthermore, making a unified
prediction based on the shared relation representation treats the input in
different modalities equally, while their importance to the MKGC task should be
different. In this paper, we propose MoSE, a Modality Split representation
learning and Ensemble inference framework for MKGC. Specifically, in the
training phase, we learn modality-split relation embeddings for each modality
instead of a single modality-shared one, which alleviates the modality
interference. Based on these embeddings, in the inference phase, we first make
modality-split predictions and then exploit various ensemble methods to combine
the predictions with different weights, which models the modality importance
dynamically. Experimental results on three KG datasets show that MoSE
outperforms state-of-the-art MKGC methods. Codes are available at
https://github.com/OreOZhao/MoSE4MKGC.",https://github.com/OreOZhao/MoSE4MKGC,-1
28b89579-f1a3-49e7-9376-21769bb46703,Task Grouping for Multilingual Text Recognition,0.227352,"Most existing OCR methods focus on alphanumeric characters due to the
popularity of English and numbers, as well as their corresponding datasets. On
extending the characters to more languages, recent methods have shown that
training different scripts with different recognition heads can greatly improve
the end-to-end recognition accuracy compared to combining characters from all
languages in the same recognition head. However, we postulate that similarities
between some languages could allow sharing of model parameters and benefit from
joint training. Determining language groupings, however, is not immediately
obvious. To this end, we propose an automatic method for multilingual text
recognition with a task grouping and assignment module using Gumbel-Softmax,
introducing a task grouping loss and weighted recognition loss to allow for
simultaneous training of the models and grouping modules. Experiments on MLT19
lend evidence to our hypothesis that there is a middle ground between combining
every task together and separating every task that achieves a better
configuration of task grouping/separation.",https://github.com/facebookresearch/MultiplexedOCR,18752
6a04b37f-b8b3-4fc9-a368-9f00205cd447,Towards a Theory of Faithfulness: Faithful Explanations of Differentiable Classifiers over Continuous Data,0.0961315,"There is broad agreement in the literature that explanation methods should be
faithful to the model that they explain, but faithfulness remains a rather
vague term. We revisit faithfulness in the context of continuous data and
propose two formal definitions of faithfulness for feature attribution methods.
Qualitative faithfulness demands that scores reflect the true qualitative
effect (positive vs. negative) of the feature on the model and quanitative
faithfulness that the magnitude of scores reflect the true quantitative effect.
We discuss under which conditions these requirements can be satisfied to which
extent (local vs global). As an application of the conceptual idea, we look at
differentiable classifiers over continuous data and characterize
Gradient-scores as follows: every qualitatively faithful feature attribution
method is qualitatively equivalent to Gradient-scores. Furthermore, if an
attribution method is quantitatively faithful in the sense that changes of the
output of the classifier are proportional to the scores of features, then it is
either equivalent to gradient-scoring or it is based on an inferior
approximation of the classifier. To illustrate the practical relevance of the
theory, we experimentally demonstrate that popular attribution methods can fail
to give faithful explanations in the setting where the data is continuous and
the classifier differentiable.",https://github.com/XiangYin2021/Revisit-Faithfulness,-1
05a5fd7b-2e2d-4f8c-b2d0-08b809ede502,Self-Supervised Visual Place Recognition by Mining Temporal and Feature Neighborhoods,0.42838,"Visual place recognition (VPR) using deep networks has achieved
state-of-the-art performance. However, most of them require a training set with
ground truth sensor poses to obtain positive and negative samples of each
observation's spatial neighborhood for supervised learning. When such
information is unavailable, temporal neighborhoods from a sequentially
collected data stream could be exploited for self-supervised training, although
we find its performance suboptimal. Inspired by noisy label learning, we
propose a novel self-supervised framework named \textit{TF-VPR} that uses
temporal neighborhoods and learnable feature neighborhoods to discover unknown
spatial neighborhoods. Our method follows an iterative training paradigm which
alternates between: (1) representation learning with data augmentation, (2)
positive set expansion to include the current feature space neighbors, and (3)
positive set contraction via geometric verification. We conduct comprehensive
experiments on both simulated and real datasets, with either RGB images or
point clouds as inputs. The results show that our method outperforms our
baselines in recall rate, robustness, and heading diversity, a novel metric we
propose for VPR. Our code and datasets can be found at
https://ai4ce.github.io/TF-VPR/.",https://ai4ce.github.io/TF-VPR/,-1
9dc49c8d-b0c7-473f-847a-d5b7abd11f5f,Experiencer-Specific Emotion and Appraisal Prediction,0.685414,"Emotion classification in NLP assigns emotions to texts, such as sentences or
paragraphs. With texts like ""I felt guilty when he cried"", focusing on the
sentence level disregards the standpoint of each participant in the situation:
the writer (""I"") and the other entity (""he"") could in fact have different
affective states. The emotions of different entities have been considered only
partially in emotion semantic role labeling, a task that relates semantic roles
to emotion cue words. Proposing a related task, we narrow the focus on the
experiencers of events, and assign an emotion (if any holds) to each of them.
To this end, we represent each emotion both categorically and with appraisal
variables, as a psychological access to explaining why a person develops a
particular emotion. On an event description corpus, our experiencer-aware
models of emotions and appraisals outperform the experiencer-agnostic
baselines, showing that disregarding event participants is an
oversimplification for the emotion detection task.",https://www.ims.uni-stuttgart.de/data/appraisalemotion,-1
58568e53-8614-4a9e-b97f-8e21224a72ae,JParaCrawl v3.0: A Large-scale English-Japanese Parallel Corpus,0.818451,"Most current machine translation models are mainly trained with parallel
corpora, and their translation accuracy largely depends on the quality and
quantity of the corpora. Although there are billions of parallel sentences for
a few language pairs, effectively dealing with most language pairs is difficult
due to a lack of publicly available parallel corpora. This paper creates a
large parallel corpus for English-Japanese, a language pair for which only
limited resources are available, compared to such resource-rich languages as
English-German. It introduces a new web-based English-Japanese parallel corpus
named JParaCrawl v3.0. Our new corpus contains more than 21 million unique
parallel sentence pairs, which is more than twice as many as the previous
JParaCrawl v2.0 corpus. Through experiments, we empirically show how our new
corpus boosts the accuracy of machine translation models on various domains.
The JParaCrawl v3.0 corpus will eventually be publicly available online for
research purposes.",https://github.com/paracrawl/,-1
7975afd9-75dd-4981-befa-ea7e6ff23212,Delving into Out-of-Distribution Detection with Vision-Language Representations,0.999835,"Recognizing out-of-distribution (OOD) samples is critical for machine
learning systems deployed in the open world. The vast majority of OOD detection
methods are driven by a single modality (e.g., either vision or language),
leaving the rich information in multi-modal representations untapped. Inspired
by the recent success of vision-language pre-training, this paper enriches the
landscape of OOD detection from a single-modal to a multi-modal regime.
Particularly, we propose Maximum Concept Matching (MCM), a simple yet effective
zero-shot OOD detection method based on aligning visual features with textual
concepts. We contribute in-depth analysis and theoretical insights to
understand the effectiveness of MCM. Extensive experiments demonstrate that MCM
achieves superior performance on a wide variety of real-world tasks. MCM with
vision-language features outperforms a common baseline with pure visual
features on a hard OOD task with semantically similar classes by 13.1% (AUROC).
Code is available at https://github.com/deeplearning-wisc/MCM.",https://github.com/deeplearning-wisc/MCM,-1
3e1e7850-0a64-4b99-b89a-16f263d5837a,Federated Non-negative Matrix Factorization for Short Texts Topic Modeling with Mutual Information,0.124915,"Non-negative matrix factorization (NMF) based topic modeling is widely used
in natural language processing (NLP) to uncover hidden topics of short text
documents. Usually, training a high-quality topic model requires large amount
of textual data. In many real-world scenarios, customer textual data should be
private and sensitive, precluding uploading to data centers. This paper
proposes a Federated NMF (FedNMF) framework, which allows multiple clients to
collaboratively train a high-quality NMF based topic model with locally stored
data. However, standard federated learning will significantly undermine the
performance of topic models in downstream tasks (e.g., text classification)
when the data distribution over clients is heterogeneous. To alleviate this
issue, we further propose FedNMF+MI, which simultaneously maximizes the mutual
information (MI) between the count features of local texts and their topic
weight vectors to mitigate the performance degradation. Experimental results
show that our FedNMF+MI methods outperform Federated Latent Dirichlet
Allocation (FedLDA) and the FedNMF without MI methods for short texts by a
significant margin on both coherence score and classification F1 score.",None,-1
809a632d-5c83-4e0c-875f-0b1825df7400,ClearPose: Large-scale Transparent Object Dataset and Benchmark,0.877727,"Transparent objects are ubiquitous in household settings and pose distinct
challenges for visual sensing and perception systems. The optical properties of
transparent objects leave conventional 3D sensors alone unreliable for object
depth and pose estimation. These challenges are highlighted by the shortage of
large-scale RGB-Depth datasets focusing on transparent objects in real-world
settings. In this work, we contribute a large-scale real-world RGB-Depth
transparent object dataset named ClearPose to serve as a benchmark dataset for
segmentation, scene-level depth completion and object-centric pose estimation
tasks. The ClearPose dataset contains over 350K labeled real-world RGB-Depth
frames and 5M instance annotations covering 63 household objects. The dataset
includes object categories commonly used in daily life under various lighting
and occluding conditions as well as challenging test scenarios such as cases of
occlusion by opaque or translucent objects, non-planar orientations, presence
of liquids, etc. We benchmark several state-of-the-art depth completion and
object pose estimation deep neural networks on ClearPose. The dataset and
benchmarking source code is available at https://github.com/opipari/ClearPose.",https://github.com/opipari/ClearPose,-1
3d5ef2ed-39e9-4d5e-ab19-e0691d96aff3,A new Hyper-heuristic based on Adaptive Simulated Annealing and Reinforcement Learning for the Capacitated Electric Vehicle Routing Problem,0.724777,"Electric vehicles (EVs) have been adopted in urban areas to reduce
environmental pollution and global warming as a result of the increasing number
of freight vehicles. However, there are still deficiencies in routing the
trajectories of last-mile logistics that continue to impact social and economic
sustainability. For that reason, in this paper, a hyper-heuristic (HH) approach
called Hyper-heuristic Adaptive Simulated Annealing with Reinforcement Learning
(HHASA$_{RL}$) is proposed. It is composed of a multi-armed bandit method and
the self-adaptive Simulated Annealing (SA) metaheuristic algorithm for solving
the problem called Capacitated Electric Vehicle Routing Problem (CEVRP). Due to
the limited number of charging stations and the travel range of EVs, the EVs
must require battery recharging moments in advance and reduce travel times and
costs. The HH implemented improves multiple minimum best-known solutions and
obtains the best mean values for some high-dimensional instances for the
proposed benchmark for the IEEE WCCI2020 competition.",None,4806
1e676ae6-dd3c-4434-befe-1da8f4d2c8d6,Memory-Efficient Sequential Pattern Mining with Hybrid Tries,0.105128,"As modern data sets continue to grow exponentially in size, the demand for
efficient mining algorithms capable of handling such large data sets becomes
increasingly imperative. This paper develops a memory-efficient approach for
Sequential Pattern Mining (SPM), a fundamental topic in knowledge discovery
that faces a well-known memory bottleneck for large data sets. Our methodology
involves a novel hybrid trie data structure that exploits recurring patterns to
compactly store the data set in memory; and a corresponding mining algorithm
designed to effectively extract patterns from this compact representation.
Numerical results on real-life test instances show an average improvement of
88% in memory consumption and 41% in computation time for small to medium-sized
data sets compared to the state of the art. Furthermore, our algorithm stands
out as the only capable SPM approach for large data sets within 256GB of system
memory.",https://github.com/aminhn/BDTrie,-1
3e83ca9d-682b-47fe-bf75-9db30af2ada6,FolkScope: Intention Knowledge Graph Construction for E-commerce Commonsense Discovery,0.454229,"Understanding users' intentions in e-commerce platforms requires commonsense
knowledge. In this paper, we present FolkScope, an intention knowledge graph
construction framework to reveal the structure of humans' minds about
purchasing items. As commonsense knowledge is usually ineffable and not
expressed explicitly, it is challenging to perform information extraction.
Thus, we propose a new approach that leverages the generation power of large
language models~(LLMs) and human-in-the-loop annotation to semi-automatically
construct the knowledge graph. LLMs first generate intention assertions via
e-commerce-specific prompts to explain shopping behaviors, where the intention
can be an open reason or a predicate falling into one of 18 categories aligning
with ConceptNet, e.g., IsA, MadeOf, UsedFor, etc. Then we annotate plausibility
and typicality labels of sampled intentions as training data in order to
populate human judgments to all automatic generations. Last, to structurize the
assertions, we propose pattern mining and conceptualization to form more
condensed and abstract knowledge. Extensive evaluations and studies demonstrate
that our constructed knowledge graph can well model e-commerce knowledge and
have many potential applications.",https://github.com/HKUST-KnowComp/FolkScope,14329
c73e516e-cb87-45b7-8c81-c258feba2e44,PointInst3D: Segmenting 3D Instances by Points,0.691061,"The current state-of-the-art methods in 3D instance segmentation typically
involve a clustering step, despite the tendency towards heuristics, greedy
algorithms, and a lack of robustness to the changes in data statistics. In
contrast, we propose a fully-convolutional 3D point cloud instance segmentation
method that works in a per-point prediction fashion. In doing so it avoids the
challenges that clustering-based methods face: introducing dependencies among
different tasks of the model. We find the key to its success is assigning a
suitable target to each sampled point. Instead of the commonly used static or
distance-based assignment strategies, we propose to use an Optimal Transport
approach to optimally assign target masks to the sampled points according to
the dynamic matching costs. Our approach achieves promising results on both
ScanNet and S3DIS benchmarks. The proposed approach removes intertask
dependencies and thus represents a simpler and more flexible 3D instance
segmentation framework than other competing methods, while achieving improved
segmentation accuracy.",None,-1
39b57dfd-5d98-4ce9-8c69-3d64448b7282,ContraCLM: Contrastive Learning For Causal Language Model,0.160125,"Despite exciting progress in causal language models, the expressiveness of
the representations is largely limited due to poor discrimination ability. To
remedy this issue, we present ContraCLM, a novel contrastive learning framework
at both token-level and sequence-level. We assess ContraCLM on a variety of
downstream tasks. We show that ContraCLM enhances discrimination of the
representations and bridges the gap with the encoder-only models, which makes
causal language models better suited for tasks beyond language generation.
Specifically, we attain $44\%$ relative improvement on the Semantic Textual
Similarity tasks and $34\%$ on Code-to-Code Search tasks. Furthermore, by
improving the expressiveness of the representations, ContraCLM also boosts the
source code generation capability with $9\%$ relative improvement on execution
accuracy on the HumanEval benchmark.",https://github.com/microsoft/CodeBERT/tree/master/UniXcoder/downstream-tasks,13562
9e35788e-ff51-4ca1-8ea7-3100f479d923,Realistic Blur Synthesis for Learning Image Deblurring,0.737305,"Training learning-based deblurring methods demands a tremendous amount of
blurred and sharp image pairs. Unfortunately, existing synthetic datasets are
not realistic enough, and deblurring models trained on them cannot handle real
blurred images effectively. While real datasets have recently been proposed,
they provide limited diversity of scenes and camera settings, and capturing
real datasets for diverse settings is still challenging. To resolve this, this
paper analyzes various factors that introduce differences between real and
synthetic blurred images. To this end, we present RSBlur, a novel dataset with
real blurred images and the corresponding sharp image sequences to enable a
detailed analysis of the difference between real and synthetic blur. With the
dataset, we reveal the effects of different factors in the blur generation
process. Based on the analysis, we also present a novel blur synthesis pipeline
to synthesize more realistic blur. We show that our synthesis pipeline can
improve the deblurring performance on real blurred images.",None,-1
6e89ed1c-e664-4b2d-83a4-9c331973d7ee,Deep Learning-based Facial Appearance Simulation Driven by Surgically Planned Craniomaxillofacial Bony Movement,0.308497,"Simulating facial appearance change following bony movement is a critical
step in orthognathic surgical planning for patients with jaw deformities.
Conventional biomechanics-based methods such as the finite-element method (FEM)
are labor intensive and computationally inefficient. Deep learning-based
approaches can be promising alternatives due to their high computational
efficiency and strong modeling capability. However, the existing deep
learning-based method ignores the physical correspondence between facial soft
tissue and bony segments and thus is significantly less accurate compared to
FEM. In this work, we propose an Attentive Correspondence assisted Movement
Transformation network (ACMT-Net) to estimate the facial appearance by
transforming the bony movement to facial soft tissue through a point-to-point
attentive correspondence matrix. Experimental results on patients with jaw
deformity show that our proposed method can achieve comparable facial change
prediction accuracy compared with the state-of-the-art FEM-based approach with
significantly improved computational efficiency.",None,-1
f33b9c78-41c6-44ec-8427-4c27f20038a0,MOCHA: A Multi-Task Training Approach for Coherent Text Generation from Cognitive Perspective,0.0567198,"Teaching neural models to generate narrative coherent texts is a critical
problem. Recent pre-trained language models have achieved promising results,
but there is still a gap between human written texts and machine-generated
outputs. In this work, we propose a novel multi-task training strategy for
coherent text generation grounded on the cognitive theory of writing, which
empowers the model to learn essential subskills needed for writing including
planning and reviewing besides end-to-end generation. We extensively evaluate
our model on three open-ended generation tasks including story generation, news
article writing and argument generation. Experiments show that our model
achieves better results on both few-shot and fully-supervised settings than
strong baselines, and human evaluations confirm that our model can generate
more coherent outputs.",https://github.com/Derekkk/Mocha-EMNLP22,-1
b19cef97-27b8-4761-b892-babf685c20c4,Multi-Agent Chance-Constrained Stochastic Shortest Path with Application to Risk-Aware Intelligent Intersection,0.688597,"In transportation networks, where traffic lights have traditionally been used
for vehicle coordination, intersections act as natural bottlenecks. A
formidable challenge for existing automated intersections lies in detecting and
reasoning about uncertainty from the operating environment and human-driven
vehicles. In this paper, we propose a risk-aware intelligent intersection
system for autonomous vehicles (AVs) as well as human-driven vehicles (HVs). We
cast the problem as a novel class of Multi-agent Chance-Constrained Stochastic
Shortest Path (MCC-SSP) problems and devise an exact Integer Linear Programming
(ILP) formulation that is scalable in the number of agents' interaction points
(e.g., potential collision points at the intersection). In particular, when the
number of agents within an interaction point is small, which is often the case
in intersections, the ILP has a polynomial number of variables and constraints.
To further improve the running time performance, we show that the collision
risk computation can be performed offline. Additionally, a trajectory
optimization workflow is provided to generate risk-aware trajectories for any
given intersection. The proposed framework is implemented in CARLA simulator
and evaluated under a fully autonomous intersection with AVs only as well as in
a hybrid setup with a signalized intersection for HVs and an intelligent scheme
for AVs. As verified via simulations, the featured approach improves
intersection's efficiency by up to $200\%$ while also conforming to the
specified tunable risk threshold.",None,-1
1509a384-f204-4993-b0e4-9d4c28ba9953,Acceptability Judgements via Examining the Topology of Attention Maps,0.777936,"The role of the attention mechanism in encoding linguistic knowledge has
received special interest in NLP. However, the ability of the attention heads
to judge the grammatical acceptability of a sentence has been underexplored.
This paper approaches the paradigm of acceptability judgments with topological
data analysis (TDA), showing that the geometric properties of the attention
graph can be efficiently exploited for two standard practices in linguistics:
binary judgments and linguistic minimal pairs. Topological features enhance the
BERT-based acceptability classifier scores by $8$%-$24$% on CoLA in three
languages (English, Italian, and Swedish). By revealing the topological
discrepancy between attention maps of minimal pairs, we achieve the human-level
performance on the BLiMP benchmark, outperforming nine statistical and
Transformer LM baselines. At the same time, TDA provides the foundation for
analyzing the linguistic functions of attention heads and interpreting the
correspondence between the graph features and grammatical phenomena.",https://github.com/danchern97/tda4la,-1
701c41cb-c7e1-475a-b38d-35626fc1848d,Balancing Stability and Plasticity through Advanced Null Space in Continual Learning,0.483086,"Continual learning is a learning paradigm that learns tasks sequentially with
resources constraints, in which the key challenge is stability-plasticity
dilemma, i.e., it is uneasy to simultaneously have the stability to prevent
catastrophic forgetting of old tasks and the plasticity to learn new tasks
well. In this paper, we propose a new continual learning approach, Advanced
Null Space (AdNS), to balance the stability and plasticity without storing any
old data of previous tasks. Specifically, to obtain better stability, AdNS
makes use of low-rank approximation to obtain a novel null space and projects
the gradient onto the null space to prevent the interference on the past tasks.
To control the generation of the null space, we introduce a non-uniform
constraint strength to further reduce forgetting. Furthermore, we present a
simple but effective method, intra-task distillation, to improve the
performance of the current task. Finally, we theoretically find that null space
plays a key role in plasticity and stability, respectively. Experimental
results show that the proposed method can achieve better performance compared
to state-of-the-art continual learning approaches.",None,-1
df305a25-6145-419d-b079-627817c4bbce,Dual-Geometric Space Embedding Model for Two-View Knowledge Graphs,0.692489,"Two-view knowledge graphs (KGs) jointly represent two components: an ontology
view for abstract and commonsense concepts, and an instance view for specific
entities that are instantiated from ontological concepts. As such, these KGs
contain heterogeneous structures that are hierarchical, from the ontology-view,
and cyclical, from the instance-view. Despite these various structures in KGs,
most recent works on embedding KGs assume that the entire KG belongs to only
one of the two views but not both simultaneously. For works that seek to put
both views of the KG together, the instance and ontology views are assumed to
belong to the same geometric space, such as all nodes embedded in the same
Euclidean space or non-Euclidean product space, an assumption no longer
reasonable for two-view KGs where different portions of the graph exhibit
different structures. To address this issue, we define and construct a
dual-geometric space embedding model (DGS) that models two-view KGs using a
complex non-Euclidean geometric space, by embedding different portions of the
KG in different geometric spaces. DGS utilizes the spherical space, hyperbolic
space, and their intersecting space in a unified framework for learning
embeddings. Furthermore, for the spherical space, we propose novel closed
spherical space operators that directly operate in the spherical space without
the need for mapping to an approximate tangent space. Experiments on public
datasets show that DGS significantly outperforms previous state-of-the-art
baseline models on KG completion tasks, demonstrating its ability to better
model heterogeneous structures in KGs.",https://github.com/roshnigiyer/dgs,-1
30aa34b2-34f5-4baa-a417-8128047eaea0,"RoMQA: A Benchmark for Robust, Multi-evidence, Multi-answer Question Answering",0.698401,"We introduce RoMQA, the first benchmark for robust, multi-evidence,
multi-answer question answering (QA). RoMQA contains clusters of questions that
are derived from related constraints mined from the Wikidata knowledge graph.
RoMQA evaluates robustness of QA models to varying constraints by measuring
worst-case performance within each question cluster. Compared to prior QA
datasets, RoMQA has more human-written questions that require reasoning over
more evidence text and have, on average, many more correct answers. In
addition, human annotators rate RoMQA questions as more natural or likely to be
asked by people. We evaluate state-of-the-art large language models in
zero-shot, few-shot, and fine-tuning settings, and find that RoMQA is
challenging: zero-shot and few-shot models perform similarly to naive
baselines, while supervised retrieval methods perform well below gold evidence
upper bounds. Moreover, existing models are not robust to variations in
question constraints, but can be made more robust by tuning on clusters of
related questions. Our results show that RoMQA is a challenging benchmark for
large language models, and provides a quantifiable test to build more robust QA
methods.",https://github.com/facebookresearch/romqa,-1
d0a45eba-2105-4705-8ac2-2b238e4c70fd,A Scalable Workflow to Build Machine Learning Classifiers with Clinician-in-the-Loop to Identify Patients in Specific Diseases,0.0708009,"Clinicians may rely on medical coding systems such as International
Classification of Diseases (ICD) to identify patients with diseases from
Electronic Health Records (EHRs). However, due to the lack of detail and
specificity as well as a probability of miscoding, recent studies suggest the
ICD codes often cannot characterise patients accurately for specific diseases
in real clinical practice, and as a result, using them to find patients for
studies or trials can result in high failure rates and missing out on uncoded
patients. Manual inspection of all patients at scale is not feasible as it is
highly costly and slow.
  This paper proposes a scalable workflow which leverages both structured data
and unstructured textual notes from EHRs with techniques including NLP, AutoML
and Clinician-in-the-Loop mechanism to build machine learning classifiers to
identify patients at scale with given diseases, especially those who might
currently be miscoded or missed by ICD codes.
  Case studies in the MIMIC-III dataset were conducted where the proposed
workflow demonstrates a higher classification performance in terms of F1 scores
compared to simply using ICD codes on gold testing subset to identify patients
with Ovarian Cancer (0.901 vs 0.814), Lung Cancer (0.859 vs 0.828), Cancer
Cachexia (0.862 vs 0.650), and Lupus Nephritis (0.959 vs 0.855). Also, the
proposed workflow that leverages unstructured notes consistently outperforms
the baseline that uses structured data only with an increase of F1 (Ovarian
Cancer 0.901 vs 0.719, Lung Cancer 0.859 vs 0.787, Cancer Cachexia 0.862 vs
0.838 and Lupus Nephritis 0.959 vs 0.785). Experiments on the large testing set
also demonstrate the proposed workflow can find more patients who are miscoded
or missed by ICD codes. Moreover, interpretability studies are also conducted
to clinically validate the top impact features of the classifiers.",None,-1
c34c802c-0418-4d6f-a12c-5a4c90608978,Automatic Speech Recognition of Low-Resource Languages Based on Chukchi,0.111858,"The following paper presents a project focused on the research and creation
of a new Automatic Speech Recognition (ASR) based in the Chukchi language.
There is no one complete corpus of the Chukchi language, so most of the work
consisted in collecting audio and texts in the Chukchi language from open
sources and processing them. We managed to collect 21:34:23 hours of audio
recordings and 112,719 sentences (or 2,068,273 words) of text in the Chukchi
language. The XLSR model was trained on the obtained data, which showed good
results even with a small amount of data. Besides the fact that the Chukchi
language is a low-resource language, it is also polysynthetic, which
significantly complicates any automatic processing. Thus, the usual WER metric
for evaluating ASR becomes less indicative for a polysynthetic language.
However, the CER metric showed good results. The question of metrics for
polysynthetic languages remains open.",https://github.com/ftyers/fieldasr/blob/main/DATA.md,-1
7843c206-f8c9-45f4-bcd8-94c8615ab980,Distill the Image to Nowhere: Inversion Knowledge Distillation for Multimodal Machine Translation,0.468744,"Past works on multimodal machine translation (MMT) elevate bilingual setup by
incorporating additional aligned vision information. However, an image-must
requirement of the multimodal dataset largely hinders MMT's development --
namely that it demands an aligned form of [image, source text, target text].
This limitation is generally troublesome during the inference phase especially
when the aligned image is not provided as in the normal NMT setup. Thus, in
this work, we introduce IKD-MMT, a novel MMT framework to support the
image-free inference phase via an inversion knowledge distillation scheme. In
particular, a multimodal feature generator is executed with a knowledge
distillation module, which directly generates the multimodal feature from
(only) source texts as the input. While there have been a few prior works
entertaining the possibility to support image-free inference for machine
translation, their performances have yet to rival the image-must translation.
In our experiments, we identify our method as the first image-free approach to
comprehensively rival or even surpass (almost) all image-must frameworks, and
achieved the state-of-the-art result on the often-used Multi30k benchmark. Our
code and data are available at: https://github.com/pengr/IKD-mmt/tree/master..",https://github.com/pengr/IKD-mmt/tree/master,-1
33d514fc-4f1f-4755-80e6-cf7e2e103f3f,Generating Scientific Claims for Zero-Shot Scientific Fact Checking,0.994545,"Automated scientific fact checking is difficult due to the complexity of
scientific language and a lack of significant amounts of training data, as
annotation requires domain expertise. To address this challenge, we propose
scientific claim generation, the task of generating one or more atomic and
verifiable claims from scientific sentences, and demonstrate its usefulness in
zero-shot fact checking for biomedical claims. We propose CLAIMGEN-BART, a new
supervised method for generating claims supported by the literature, as well as
KBIN, a novel method for generating claim negations. Additionally, we adapt an
existing unsupervised entity-centric method of claim generation to biomedical
claims, which we call CLAIMGEN-ENTITY. Experiments on zero-shot fact checking
demonstrate that both CLAIMGEN-ENTITY and CLAIMGEN-BART, coupled with KBIN,
achieve up to 90% performance of fully supervised models trained on manually
annotated claims and evidence. A rigorous evaluation study demonstrates
significant improvement in generated claim and negation quality over existing
baselines",https://github.com/allenai/scientiﬁc-claim-generation,-1
a90b9025-f71e-46d5-8536-0feecb036809,The Isabelle ENIGMA,0.765013,"We significantly improve the performance of the E automated theorem prover on
the Isabelle Sledgehammer problems by combining learning and theorem proving in
several ways. In particular, we develop targeted versions of the ENIGMA
guidance for the Isabelle problems, targeted versions of neural premise
selection, and targeted strategies for E. The methods are trained in several
iterations over hundreds of thousands untyped and typed first-order problems
extracted from Isabelle. Our final best single-strategy ENIGMA and premise
selection system improves the best previous version of E by 25.3% in 15
seconds, outperforming also all other previous ATP and SMT systems.",https://github.com/ai4reason/ATP_Proofs,-1
6289ede6-c015-457c-9cd5-50de4676e627,Auto-ViT-Acc: An FPGA-Aware Automatic Acceleration Framework for Vision Transformer with Mixed-Scheme Quantization,0.814644,"Vision transformers (ViTs) are emerging with significantly improved accuracy
in computer vision tasks. However, their complex architecture and enormous
computation/storage demand impose urgent needs for new hardware accelerator
design methodology. This work proposes an FPGA-aware automatic ViT acceleration
framework based on the proposed mixed-scheme quantization. To the best of our
knowledge, this is the first FPGA-based ViT acceleration framework exploring
model quantization. Compared with state-of-the-art ViT quantization work
(algorithmic approach only without hardware acceleration), our quantization
achieves 0.47% to 1.36% higher Top-1 accuracy under the same bit-width.
Compared with the 32-bit floating-point baseline FPGA accelerator, our
accelerator achieves around 5.6x improvement on the frame rate (i.e., 56.8 FPS
vs. 10.0 FPS) with 0.71% accuracy drop on ImageNet dataset for DeiT-base.",None,-1
7f97240f-93fe-4eaf-9fb3-4d9725094444,Neural Grapheme-to-Phoneme Conversion with Pre-trained Grapheme Models,0.826226,"Neural network models have achieved state-of-the-art performance on
grapheme-to-phoneme (G2P) conversion. However, their performance relies on
large-scale pronunciation dictionaries, which may not be available for a lot of
languages. Inspired by the success of the pre-trained language model BERT, this
paper proposes a pre-trained grapheme model called grapheme BERT (GBERT), which
is built by self-supervised training on a large, language-specific word list
with only grapheme information. Furthermore, two approaches are developed to
incorporate GBERT into the state-of-the-art Transformer-based G2P model, i.e.,
fine-tuning GBERT or fusing GBERT into the Transformer model by attention.
Experimental results on the Dutch, Serbo-Croatian, Bulgarian and Korean
datasets of the SIGMORPHON 2021 G2P task confirm the effectiveness of our
GBERT-based G2P models under both medium-resource and low-resource data
conditions.",https://github.com/ldong1111/GraphemeBERT,-1
c210d292-3b0f-4394-b7ea-240d17b69c41,Unbiased Heterogeneous Scene Graph Generation with Relation-aware Message Passing Neural Network,0.762315,"Recent scene graph generation (SGG) frameworks have focused on learning
complex relationships among multiple objects in an image. Thanks to the nature
of the message passing neural network (MPNN) that models high-order
interactions between objects and their neighboring objects, they are dominant
representation learning modules for SGG. However, existing MPNN-based
frameworks assume the scene graph as a homogeneous graph, which restricts the
context-awareness of visual relations between objects. That is, they overlook
the fact that the relations tend to be highly dependent on the objects with
which the relations are associated. In this paper, we propose an unbiased
heterogeneous scene graph generation (HetSGG) framework that captures
relation-aware context using message passing neural networks. We devise a novel
message passing layer, called relation-aware message passing neural network
(RMP), that aggregates the contextual information of an image considering the
predicate type between objects. Our extensive evaluations demonstrate that
HetSGG outperforms state-of-the-art methods, especially outperforming on tail
predicate classes.",https://github.com/KanghoonYoon/hetsgg-torch,-1
cb0236bb-897d-4dec-b2ff-90740427d0f2,Weight Predictor Network with Feature Selection for Small Sample Tabular Biomedical Data,0.456113,"Tabular biomedical data is often high-dimensional but with a very small
number of samples. Although recent work showed that well-regularised simple
neural networks could outperform more sophisticated architectures on tabular
data, they are still prone to overfitting on tiny datasets with many
potentially irrelevant features. To combat these issues, we propose Weight
Predictor Network with Feature Selection (WPFS) for learning neural networks
from high-dimensional and small sample data by reducing the number of learnable
parameters and simultaneously performing feature selection. In addition to the
classification network, WPFS uses two small auxiliary networks that together
output the weights of the first layer of the classification model. We evaluate
on nine real-world biomedical datasets and demonstrate that WPFS outperforms
other standard as well as more recent methods typically applied to tabular
data. Furthermore, we investigate the proposed feature selection mechanism and
show that it improves performance while providing useful insights into the
learning task.",https://github.com/andreimargeloiu/WPFS,-1
885c1ae5-8a16-4dc8-920c-e276f6f84e26,Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search,0.596257,"Nonlinear dynamics is ubiquitous in nature and commonly seen in various
science and engineering disciplines. Distilling analytical expressions that
govern nonlinear dynamics from limited data remains vital but challenging. To
tackle this fundamental issue, we propose a novel Symbolic Physics Learner
(SPL) machine to discover the mathematical structure of nonlinear dynamics. The
key concept is to interpret mathematical operations and system state variables
by computational rules and symbols, establish symbolic reasoning of
mathematical formulas via expression trees, and employ a Monte Carlo tree
search (MCTS) agent to explore optimal expression trees based on measurement
data. The MCTS agent obtains an optimistic selection policy through the
traversal of expression trees, featuring the one that maps to the arithmetic
expression of underlying physics. Salient features of the proposed framework
include search flexibility and enforcement of parsimony for discovered
equations. The efficacy and superiority of the SPL machine are demonstrated by
numerical examples, compared with state-of-the-art baselines.",https://github.com/brendenpetersen/deep-symbolic-optimization/tree/master/dso/dso,-1
9d9eba74-39b3-4327-81dc-810a589284c4,A study on cross-corpus speech emotion recognition and data augmentation,0.371757,"Models that can handle a wide range of speakers and acoustic conditions are
essential in speech emotion recognition (SER). Often, these models tend to show
mixed results when presented with speakers or acoustic conditions that were not
visible during training. This paper investigates the impact of cross-corpus
data complementation and data augmentation on the performance of SER models in
matched (test-set from same corpus) and mismatched (test-set from different
corpus) conditions. Investigations using six emotional speech corpora that
include single and multiple speakers as well as variations in emotion style
(acted, elicited, natural) and recording conditions are presented. Observations
show that, as expected, models trained on single corpora perform best in
matched conditions while performance decreases between 10-40% in mismatched
conditions, depending on corpus specific features. Models trained on mixed
corpora can be more stable in mismatched contexts, and the performance
reductions range from 1 to 8% when compared with single corpus models in
matched conditions. Data augmentation yields additional gains up to 4% and seem
to benefit mismatched conditions more than matched ones.",https://github.com/ludwig-ai/ludwig,-1
a44449ca-0912-4661-9b1c-92eaa260298b,DeepInteraction: 3D Object Detection via Modality Interaction,0.998371,"Existing top-performance 3D object detectors typically rely on the
multi-modal fusion strategy. This design is however fundamentally restricted
due to overlooking the modality-specific useful information and finally
hampering the model performance. To address this limitation, in this work we
introduce a novel modality interaction strategy where individual per-modality
representations are learned and maintained throughout for enabling their unique
characteristics to be exploited during object detection. To realize this
proposed strategy, we design a DeepInteraction architecture characterized by a
multi-modal representational interaction encoder and a multi-modal predictive
interaction decoder. Experiments on the large-scale nuScenes dataset show that
our proposed method surpasses all prior arts often by a large margin.
Crucially, our method is ranked at the first position at the highly competitive
nuScenes object detection leaderboard.",https://github.com/fudan-zvg/DeepInteraction,-1
0baf7a80-cc0b-4655-ba0e-0498e7189154,TranS: Transition-based Knowledge Graph Embedding with Synthetic Relation Representation,0.597776,"Knowledge graph embedding (KGE) aims to learn continuous vectors of relations
and entities in knowledge graph. Recently, transition-based KGE methods have
achieved promising performance, where the single relation vector learns to
translate head entity to tail entity. However, this scoring pattern is not
suitable for complex scenarios where the same entity pair has different
relations. Previous models usually focus on the improvement of entity
representation for 1-to-N, N-to-1 and N-to-N relations, but ignore the single
relation vector. In this paper, we propose a novel transition-based method,
TranS, for knowledge graph embedding. The single relation vector in traditional
scoring patterns is replaced with synthetic relation representation, which can
solve these issues effectively and efficiently. Experiments on a large
knowledge graph dataset, ogbl-wikikg2, show that our model achieves
state-of-the-art results.",None,-1
fbfa6ab6-569e-4db2-ac01-50f6bdcd4a00,RepMix: Representation Mixing for Robust Attribution of Synthesized Images,0.779171,"Rapid advances in Generative Adversarial Networks (GANs) raise new challenges
for image attribution; detecting whether an image is synthetic and, if so,
determining which GAN architecture created it. Uniquely, we present a solution
to this task capable of 1) matching images invariant to their semantic content;
2) robust to benign transformations (changes in quality, resolution, shape,
etc.) commonly encountered as images are re-shared online. In order to
formalize our research, a challenging benchmark, Attribution88, is collected
for robust and practical image attribution. We then propose RepMix, our GAN
fingerprinting technique based on representation mixing and a novel loss. We
validate its capability of tracing the provenance of GAN-generated images
invariant to the semantic content of the image and also robust to
perturbations. We show our approach improves significantly from existing GAN
fingerprinting works on both semantic generalization and robustness. Data and
code are available at https://github.com/TuBui/image_attribution.",https://github.com/TuBui/image-attribution,-1
80ff701b-bc14-4cbd-b835-bde928341c30,"DiRA: Discriminative, Restorative, and Adversarial Learning for Self-supervised Medical Image Analysis",0.971302,"Discriminative learning, restorative learning, and adversarial learning have
proven beneficial for self-supervised learning schemes in computer vision and
medical imaging. Existing efforts, however, omit their synergistic effects on
each other in a ternary setup, which, we envision, can significantly benefit
deep semantic representation learning. To realize this vision, we have
developed DiRA, the first framework that unites discriminative, restorative,
and adversarial learning in a unified manner to collaboratively glean
complementary visual information from unlabeled medical images for fine-grained
semantic representation learning. Our extensive experiments demonstrate that
DiRA (1) encourages collaborative learning among three learning ingredients,
resulting in more generalizable representation across organs, diseases, and
modalities; (2) outperforms fully supervised ImageNet models and increases
robustness in small data regimes, reducing annotation cost across multiple
medical imaging applications; (3) learns fine-grained semantic representation,
facilitating accurate lesion localization with only image-level annotation; and
(4) enhances state-of-the-art restorative approaches, revealing that DiRA is a
general mechanism for united representation learning. All code and pre-trained
models are available at https: //github.com/JLiangLab/DiRA.",https://github.com/JLiangLab/DiRA,-1
05f5e88a-b3a5-411c-894f-fa471285b018,Optimal Private Payoff Manipulation against Commitment in Extensive-form Games,0.228693,"To take advantage of strategy commitment, a useful tactic of playing games, a
leader must learn enough information about the follower's payoff function.
However, this leaves the follower a chance to provide fake information and
influence the final game outcome. Through a carefully contrived payoff function
misreported to the learning leader, the follower may induce an outcome that
benefits him more, compared to the ones when he truthfully behaves.
  We study the follower's optimal manipulation via such strategic behaviors in
extensive-form games. Followers' different attitudes are taken into account. An
optimistic follower maximizes his true utility among all game outcomes that can
be induced by some payoff function. A pessimistic follower only considers
misreporting payoff functions that induce a unique game outcome. For all the
settings considered in this paper, we characterize all the possible game
outcomes that can be induced successfully. We show that it is polynomial-time
tractable for the follower to find the optimal way of misreporting his private
payoff information. Our work completely resolves this follower's optimal
manipulation problem on an extensive-form game tree.",None,-1
2dbe8fd4-e6f9-4ff0-9790-687aad1590a1,Recognising the importance of preference change: A call for a coordinated multidisciplinary research effort in the age of AI,0.726568,"As artificial intelligence becomes more powerful and a ubiquitous presence in
daily life, it is imperative to understand and manage the impact of AI systems
on our lives and decisions. Modern ML systems often change user behavior (e.g.
personalized recommender systems learn user preferences to deliver
recommendations that change online behavior). An externality of behavior change
is preference change. This article argues for the establishment of a
multidisciplinary endeavor focused on understanding how AI systems change
preference: Preference Science. We operationalize preference to incorporate
concepts from various disciplines, outlining the importance of meta-preferences
and preference-change preferences, and proposing a preliminary framework for
how preferences change. We draw a distinction between preference change,
permissible preference change, and outright preference manipulation. A
diversity of disciplines contribute unique insights to this framework.",None,2326
6b7505aa-9b18-4a9c-8a2c-e0415e1e3638,RangeUDF: Semantic Surface Reconstruction from 3D Point Clouds,0.574875,"We present RangeUDF, a new implicit representation based framework to recover
the geometry and semantics of continuous 3D scene surfaces from point clouds.
Unlike occupancy fields or signed distance fields which can only model closed
3D surfaces, our approach is not restricted to any type of topology. Being
different from the existing unsigned distance fields, our framework does not
suffer from any surface ambiguity. In addition, our RangeUDF can jointly
estimate precise semantics for continuous surfaces. The key to our approach is
a range-aware unsigned distance function together with a surface-oriented
semantic segmentation module. Extensive experiments show that RangeUDF clearly
surpasses state-of-the-art approaches for surface reconstruction on four point
cloud datasets. Moreover, RangeUDF demonstrates superior generalization
capability across multiple unseen datasets, which is nearly impossible for all
existing approaches.",https://github.com/vLAR-group/RangeUDF,-1
6d419bb8-73a7-4400-a233-5d3755488359,Neural Forecasting of the Italian Sovereign Bond Market with Economic News,0.101968,"In this paper we employ economic news within a neural network framework to
forecast the Italian 10-year interest rate spread. We use a big, open-source,
database known as Global Database of Events, Language and Tone to extract
topical and emotional news content linked to bond markets dynamics. We deploy
such information within a probabilistic forecasting framework with
autoregressive recurrent networks (DeepAR). Our findings suggest that a deep
learning network based on Long-Short Term Memory cells outperforms classical
machine learning techniques and provides a forecasting performance that is over
and above that obtained by using conventional determinants of interest rates
alone.",None,-1
73c2f340-73df-4110-8fe7-8de2b83ece83,Human Activity Recognition from Wi-Fi CSI Data Using Principal Component-Based Wavelet CNN,0.833996,"Human Activity Recognition (HAR) is an emerging technology with several
applications in surveillance, security, and healthcare sectors. Noninvasive HAR
systems based on Wi-Fi Channel State Information (CSI) signals can be developed
leveraging the quick growth of ubiquitous Wi-Fi technologies, and the
correlation between CSI dynamics and body motions. In this paper, we propose
Principal Component-based Wavelet Convolutional Neural Network (or PCWCNN) -- a
novel approach that offers robustness and efficiency for practical real-time
applications. Our proposed method incorporates two efficient preprocessing
algorithms -- the Principal Component Analysis (PCA) and the Discrete Wavelet
Transform (DWT). We employ an adaptive activity segmentation algorithm that is
accurate and computationally light. Additionally, we used the Wavelet CNN for
classification, which is a deep convolutional network analogous to the
well-studied ResNet and DenseNet networks. We empirically show that our
proposed PCWCNN model performs very well on a real dataset, outperforming
existing approaches.",None,-1
04cd98da-df11-44f4-91d5-8634648421b7,mSLAM: Massively multilingual joint pre-training for speech and text,0.998731,"We present mSLAM, a multilingual Speech and LAnguage Model that learns
cross-lingual cross-modal representations of speech and text by pre-training
jointly on large amounts of unlabeled speech and text in multiple languages.
mSLAM combines w2v-BERT pre-training on speech with SpanBERT pre-training on
character-level text, along with Connectionist Temporal Classification (CTC)
losses on paired speech and transcript data, to learn a single model capable of
learning from and representing both speech and text signals in a shared
representation space. We evaluate mSLAM on several downstream speech
understanding tasks and find that joint pre-training with text improves quality
on speech translation, speech intent classification and speech language-ID
while being competitive on multilingual ASR, when compared against speech-only
pre-training. Our speech translation model demonstrates zero-shot text
translation without seeing any text translation data, providing evidence for
cross-modal alignment of representations. mSLAM also benefits from multi-modal
fine-tuning, further improving the quality of speech translation by directly
leveraging text translation data during the fine-tuning process. Our empirical
analysis highlights several opportunities and challenges arising from
large-scale multimodal pre-training, suggesting directions for future research.",None,18269
5501642b-f8c7-4743-844c-310ed35666f9,Quantifying the Effect of Feedback Frequency in Interactive Reinforcement Learning for Robotic Tasks,0.123078,"Reinforcement learning (RL) has become widely adopted in robot control.
Despite many successes, one major persisting problem can be very low data
efficiency. One solution is interactive feedback, which has been shown to speed
up RL considerably. As a result, there is an abundance of different strategies,
which are, however, primarily tested on discrete grid-world and small scale
optimal control scenarios. In the literature, there is no consensus about which
feedback frequency is optimal or at which time the feedback is most beneficial.
To resolve these discrepancies we isolate and quantify the effect of feedback
frequency in robotic tasks with continuous state and action spaces. The
experiments encompass inverse kinematics learning for robotic manipulator arms
of different complexity. We show that seemingly contradictory reported
phenomena occur at different complexity levels. Furthermore, our results
suggest that no single ideal feedback frequency exists. Rather that feedback
frequency should be changed as the agent's proficiency in the task increases.",None,-1
5db2b96c-bc50-460e-be20-fb1b25264f26,Prototypical VoteNet for Few-Shot 3D Point Cloud Object Detection,0.351018,"Most existing 3D point cloud object detection approaches heavily rely on
large amounts of labeled training data. However, the labeling process is costly
and time-consuming. This paper considers few-shot 3D point cloud object
detection, where only a few annotated samples of novel classes are needed with
abundant samples of base classes. To this end, we propose Prototypical VoteNet
to recognize and localize novel instances, which incorporates two new modules:
Prototypical Vote Module (PVM) and Prototypical Head Module (PHM).
Specifically, as the 3D basic geometric structures can be shared among
categories, PVM is designed to leverage class-agnostic geometric prototypes,
which are learned from base classes, to refine local features of novel
categories.Then PHM is proposed to utilize class prototypes to enhance the
global feature of each object, facilitating subsequent object localization and
classification, which is trained by the episodic training strategy. To evaluate
the model in this new setting, we contribute two new benchmark datasets,
FS-ScanNet and FS-SUNRGBD. We conduct extensive experiments to demonstrate the
effectiveness of Prototypical VoteNet, and our proposed method shows
significant and consistent improvements compared to baselines on two benchmark
datasets.",https://shizhen-zhao.github.io/FS3D_page/,-1
0637099a-ead1-481f-bf4f-f5c03f9aeccb,Document-Level Event Extraction via Human-Like Reading Process,0.38576,"Document-level Event Extraction (DEE) is particularly tricky due to the two
challenges it poses: scattering-arguments and multi-events. The first challenge
means that arguments of one event record could reside in different sentences in
the document, while the second one reflects one document may simultaneously
contain multiple such event records. Motivated by humans' reading cognitive to
extract information of interests, in this paper, we propose a method called HRE
(Human Reading inspired Extractor for Document Events), where DEE is decomposed
into these two iterative stages, rough reading and elaborate reading.
Specifically, the first stage browses the document to detect the occurrence of
events, and the second stage serves to extract specific event arguments. For
each concrete event role, elaborate reading hierarchically works from sentences
to characters to locate arguments across sentences, thus the
scattering-arguments problem is tackled. Meanwhile, rough reading is explored
in a multi-round manner to discover undetected events, thus the multi-events
problem is handled. Experiment results show the superiority of HRE over prior
competitive methods.",None,-1
58a83dbf-912c-4c2f-9c71-774fe3684777,Deep neural networks for fine-grained surveillance of overdose mortality,0.42305,"Surveillance of drug overdose deaths relies on death certificates for
identification of the substances that caused death. Drugs and drug classes can
be identified through the International Classification of Diseases, 10th
Revision (ICD-10) codes present on death certificates. However, ICD-10 codes do
not always provide high levels of specificity in drug identification. To
achieve more fine-grained identification of substances on a death certificate,
the free-text cause of death section, completed by the medical certifier, must
be analyzed. Current methods for analyzing free-text death certificates rely
solely on look-up tables for identifying specific substances, which must be
frequently updated and maintained. To improve identification of drugs on death
certificates, a deep learning named-entity recognition model was developed,
which achieved an F1-score of 99.13%. This model can identify new drug
misspellings and novel substances that are not present on current surveillance
look-up tables, enhancing the surveillance of drug overdose deaths.",https://github.com/pjward5656/DC_flair,-1
7d88d0c9-693a-4136-98da-1963a547e18c,Safe Reinforcement Learning via Shielding under Partial Observability,0.675844,"Safe exploration is a common problem in reinforcement learning (RL) that aims
to prevent agents from making disastrous decisions while exploring their
environment. A family of approaches to this problem assume domain knowledge in
the form of a (partial) model of this environment to decide upon the safety of
an action. A so-called shield forces the RL agent to select only safe actions.
However, for adoption in various applications, one must look beyond enforcing
safety and also ensure the applicability of RL with good performance. We extend
the applicability of shields via tight integration with state-of-the-art deep
RL, and provide an extensive, empirical study in challenging, sparse-reward
environments under partial observability. We show that a carefully integrated
shield ensures safety and can improve the convergence rate and final
performance of RL agents. We furthermore show that a shield can be used to
bootstrap state-of-the-art RL agents: they remain safe after initial learning
in a shielded setting, allowing us to disable a potentially too conservative
shield eventually.",https://github.com/tensorflow/agents,-1
16ee8f1f-2d2d-4cb5-9cf0-bf083dbe2a71,Confidence Score for Source-Free Unsupervised Domain Adaptation,0.956563,"Source-free unsupervised domain adaptation (SFUDA) aims to obtain high
performance in the unlabeled target domain using the pre-trained source model,
not the source data. Existing SFUDA methods assign the same importance to all
target samples, which is vulnerable to incorrect pseudo-labels. To
differentiate between sample importance, in this study, we propose a novel
sample-wise confidence score, the Joint Model-Data Structure (JMDS) score for
SFUDA. Unlike existing confidence scores that use only one of the source or
target domain knowledge, the JMDS score uses both knowledge. We then propose a
Confidence score Weighting Adaptation using the JMDS (CoWA-JMDS) framework for
SFUDA. CoWA-JMDS consists of the JMDS scores as sample weights and weight Mixup
that is our proposed variant of Mixup. Weight Mixup promotes the model make
more use of the target domain knowledge. The experimental results show that the
JMDS score outperforms the existing confidence scores. Moreover, CoWA-JMDS
achieves state-of-the-art performance on various SFUDA scenarios: closed, open,
and partial-set scenarios.",https://github.com/Jhyun17/CoWA-JMDS,-1
b7afc19c-9f61-46d5-b633-6aff4f0cd243,Guess What Moves: Unsupervised Video and Image Segmentation by Anticipating Motion,0.610219,"Motion, measured via optical flow, provides a powerful cue to discover and
learn objects in images and videos. However, compared to using appearance, it
has some blind spots, such as the fact that objects become invisible if they do
not move. In this work, we propose an approach that combines the strengths of
motion-based and appearance-based segmentation. We propose to supervise an
image segmentation network with the pretext task of predicting regions that are
likely to contain simple motion patterns, and thus likely to correspond to
objects. As the model only uses a single image as input, we can apply it in two
settings: unsupervised video segmentation, and unsupervised image segmentation.
We achieve state-of-the-art results for videos, and demonstrate the viability
of our approach on still images containing novel objects. Additionally we
experiment with different motion models and optical flow backbones and find the
method to be robust to these change. Project page and code available at
https://www.robots.ox.ac.uk/~vgg/research/gwm.",https://www.robots.ox.ac.uk/~vgg/research/gwm,-1
62adb28b-10e6-4317-b59f-bb6cd07ee94e,SWFormer: Sparse Window Transformer for 3D Object Detection in Point Clouds,0.990203,"3D object detection in point clouds is a core component for modern robotics
and autonomous driving systems. A key challenge in 3D object detection comes
from the inherent sparse nature of point occupancy within the 3D scene. In this
paper, we propose Sparse Window Transformer (SWFormer ), a scalable and
accurate model for 3D object detection, which can take full advantage of the
sparsity of point clouds. Built upon the idea of window-based Transformers,
SWFormer converts 3D points into sparse voxels and windows, and then processes
these variable-length sparse windows efficiently using a bucketing scheme. In
addition to self-attention within each spatial window, our SWFormer also
captures cross-window correlation with multi-scale feature fusion and window
shifting operations. To further address the unique challenge of detecting 3D
objects accurately from sparse features, we propose a new voxel diffusion
technique. Experimental results on the Waymo Open Dataset show our SWFormer
achieves state-of-the-art 73.36 L2 mAPH on vehicle and pedestrian for 3D object
detection on the official test set, outperforming all previous single-stage and
two-stage models, while being much more efficient.",None,-1
5562c574-5013-4cc6-a9e9-e8ef1ba7869b,IDEAL: Query-Efficient Data-Free Learning from Black-box Models,0.382572,"Knowledge Distillation (KD) is a typical method for training a lightweight
student model with the help of a well-trained teacher model. However, most KD
methods require access to either the teacher's training data or model
parameters, which is unrealistic. To tackle this problem, recent works study KD
under data-free and black-box settings. Nevertheless, these works require a
large number of queries to the teacher model, which incurs significant monetary
and computational costs. To address these problems, we propose a novel method
called \emph{query-effIcient Data-free lEarning from blAck-box modeLs} (IDEAL),
which aims to query-efficiently learn from black-box model APIs to train a good
student without any real data. In detail, IDEAL trains the student model in two
stages: data generation and model distillation. Note that IDEAL does not
require any query in the data generation stage and queries the teacher only
once for each sample in the distillation stage. Extensive experiments on
various real-world datasets show the effectiveness of the proposed IDEAL. For
instance, IDEAL can improve the performance of the best baseline method DFME by
5.83% on CIFAR10 dataset with only 0.02x the query budget of DFME.",None,-1
a3b09b33-9416-4401-a43b-857e84a62ffe,3DeformRS: Certifying Spatial Deformations on Point Clouds,0.224989,"3D computer vision models are commonly used in security-critical applications
such as autonomous driving and surgical robotics. Emerging concerns over the
robustness of these models against real-world deformations must be addressed
practically and reliably. In this work, we propose 3DeformRS, a method to
certify the robustness of point cloud Deep Neural Networks (DNNs) against
real-world deformations. We developed 3DeformRS by building upon recent work
that generalized Randomized Smoothing (RS) from pixel-intensity perturbations
to vector-field deformations. In particular, we specialized RS to certify DNNs
against parameterized deformations (e.g. rotation, twisting), while enjoying
practical computational costs. We leverage the virtues of 3DeformRS to conduct
a comprehensive empirical study on the certified robustness of four
representative point cloud DNNs on two datasets and against seven different
deformations. Compared to previous approaches for certifying point cloud DNNs,
3DeformRS is fast, scales well with point cloud size, and provides
comparable-to-better certificates. For instance, when certifying a plain
PointNet against a 3{\deg} z-rotation on 1024-point clouds, 3DeformRS grants a
certificate 3x larger and 20x faster than previous work.",https://github.com/gaperezsa/3DeformRS,-1
51be6d72-fa8e-4bee-8331-8a0b9908150f,Avoid Overthinking in Self-Supervised Models for Speech Recognition,0.152822,"Self-supervised learning (SSL) models reshaped our approach to speech,
language and vision. However their huge size and the opaque relations between
their layers and tasks result in slow inference and network overthinking, where
predictions made from the last layer of large models is worse than those made
from intermediate layers. Early exit (EE) strategies can solve both issues by
dynamically reducing computations at inference time for certain samples.
Although popular for classification tasks in vision and language, EE has seen
less use for sequence-to-sequence speech recognition (ASR) tasks where outputs
from early layers are often degenerate. This challenge is further compounded
when speech SSL models are applied on out-of-distribution (OOD) data. This
paper first shows that SSL models do overthinking in ASR. We then motivate
further research in EE by computing an optimal bound for performance versus
speed trade-offs. To approach this bound we propose two new strategies for ASR:
(1) we adapt the recently proposed patience strategy to ASR; and (2) we design
a new EE strategy specific to ASR that performs better than all strategies
previously introduced.",None,-1
b7164889-f9ae-4ceb-a32c-898c5c644784,Vision-based Large-scale 3D Semantic Mapping for Autonomous Driving Applications,0.126535,"In this paper, we present a complete pipeline for 3D semantic mapping solely
based on a stereo camera system. The pipeline comprises a direct sparse visual
odometry front-end as well as a back-end for global optimization including GNSS
integration, and semantic 3D point cloud labeling. We propose a simple but
effective temporal voting scheme which improves the quality and consistency of
the 3D point labels. Qualitative and quantitative evaluations of our pipeline
are performed on the KITTI-360 dataset. The results show the effectiveness of
our proposed voting scheme and the capability of our pipeline for efficient
large-scale 3D semantic mapping. The large-scale mapping capabilities of our
pipeline is furthermore demonstrated by presenting a very large-scale semantic
map covering 8000 km of roads generated from data collected by a fleet of
vehicles.",https://github.com/NVIDIA/semantic-segmentation/tree/sdcnet,-1
f5f4e0ac-8273-4033-9898-3321a4a1e453,"Data Smells: Categories, Causes and Consequences, and Detection of Suspicious Data in AI-based Systems",0.544129,"High data quality is fundamental for today's AI-based systems. However,
although data quality has been an object of research for decades, there is a
clear lack of research on potential data quality issues (e.g., ambiguous,
extraneous values). These kinds of issues are latent in nature and thus often
not obvious. Nevertheless, they can be associated with an increased risk of
future problems in AI-based systems (e.g., technical debt, data-induced
faults). As a counterpart to code smells in software engineering, we refer to
such issues as Data Smells. This article conceptualizes data smells and
elaborates on their causes, consequences, detection, and use in the context of
AI-based systems. In addition, a catalogue of 36 data smells divided into three
categories (i.e., Believability Smells, Understandability Smells, Consistency
Smells) is presented. Moreover, the article outlines tool support for detecting
data smells and presents the result of an initial smell detection on more than
240 real-world datasets.",https://github.com/mkerschbaumer/rb-data-smell-detection,-1
350860ca-4e7d-4d6f-81c9-95aea8034db8,Planes vs. Chairs: Category-guided 3D shape learning without any 3D cues,0.328445,"We present a novel 3D shape reconstruction method which learns to predict an
implicit 3D shape representation from a single RGB image. Our approach uses a
set of single-view images of multiple object categories without viewpoint
annotation, forcing the model to learn across multiple object categories
without 3D supervision. To facilitate learning with such minimal supervision,
we use category labels to guide shape learning with a novel categorical metric
learning approach. We also utilize adversarial and viewpoint regularization
techniques to further disentangle the effects of viewpoint and shape. We obtain
the first results for large-scale (more than 50 categories) single-viewpoint
shape prediction using a single model without any 3D cues. We are also the
first to examine and quantify the benefit of class information in single-view
supervised 3D shape reconstruction. Our method achieves superior performance
over state-of-the-art methods on ShapeNet-13, ShapeNet-55 and Pascal3D+.",https://github.com/chenhsuanlin/signed-distance-SRN,11842
53f84974-bf35-45cd-b79e-47fc8a34df10,A hybrid quantum image edge detector for the NISQ era,0.326619,"Edges are image locations where the gray value intensity changes suddenly.
They are among the most important features to understand and segment an image.
Edge detection is a standard task in digital image processing, solved for
example using filtering techniques. However, the amount of data to be processed
grows rapidly and pushes even supercomputers to their limits. Quantum computing
promises exponentially lower memory usage in terms of the number of qubits
compared to the number of classical bits. In this paper, we propose a hybrid
method for quantum edge detection based on the idea of a quantum artificial
neuron. Our method can be practically implemented on quantum computers,
especially on those of the current noisy intermediate-scale quantum era. We
compare six variants of the method to reduce the number of circuits and thus
the time required for the quantum edge detection. Taking advantage of the
scalability of our method, we can practically detect edges in images
considerably larger than reached before.",None,-1
10487b90-4195-493e-adea-b8f246b23ce4,Multi-level Fusion of Wav2vec 2.0 and BERT for Multimodal Emotion Recognition,0.77845,"The research and applications of multimodal emotion recognition have become
increasingly popular recently. However, multimodal emotion recognition faces
the challenge of lack of data. To solve this problem, we propose to use
transfer learning which leverages state-of-the-art pre-trained models including
wav2vec 2.0 and BERT for this task. Multi-level fusion approaches including
coattention-based early fusion and late fusion with the models trained on both
embeddings are explored. Also, a multi-granularity framework which extracts not
only frame-level speech embeddings but also segment-level embeddings including
phone, syllable and word-level speech embeddings is proposed to further boost
the performance. By combining our coattention-based early fusion model and late
fusion model with the multi-granularity feature extraction framework, we obtain
result that outperforms best baseline approaches by 1.3% unweighted accuracy
(UA) on the IEMOCAP dataset.",None,-1
9aba4f07-8b57-4aa2-9d22-9aef580065a8,Uncertainty-Aware Search Framework for Multi-Objective Bayesian Optimization,0.858423,"We consider the problem of multi-objective (MO) blackbox optimization using
expensive function evaluations, where the goal is to approximate the true
Pareto set of solutions while minimizing the number of function evaluations.
For example, in hardware design optimization, we need to find the designs that
trade-off performance, energy, and area overhead using expensive simulations.
We propose a novel uncertainty-aware search framework referred to as USeMO to
efficiently select the sequence of inputs for evaluation to solve this problem.
The selection method of USeMO consists of solving a cheap MO optimization
problem via surrogate models of the true functions to identify the most
promising candidates and picking the best candidate based on a measure of
uncertainty. We also provide theoretical analysis to characterize the efficacy
of our approach. Our experiments on several synthetic and six diverse
real-world benchmark problems show that USeMO consistently outperforms the
state-of-the-art algorithms.",https://github.com/belakaria/USeMO,-1
4ca5cc6a-b595-4b01-b533-9674bb8f80f5,Scaling up and Stabilizing Differentiable Planning with Implicit Differentiation,0.221472,"Differentiable planning promises end-to-end differentiability and adaptivity.
However, an issue prevents it from scaling up to larger-scale problems: they
need to differentiate through forward iteration layers to compute gradients,
which couples forward computation and backpropagation, and needs to balance
forward planner performance and computational cost of the backward pass. To
alleviate this issue, we propose to differentiate through the Bellman
fixed-point equation to decouple forward and backward passes for Value
Iteration Network and its variants, which enables constant backward cost (in
planning horizon) and flexible forward budget and helps scale up to large
tasks. We study the convergence stability, scalability, and efficiency of the
proposed implicit version of VIN and its variants and demonstrate their
superiorities on a range of planning tasks: 2D navigation, visual navigation,
and 2-DOF manipulation in configuration space and workspace.",None,-1
be6801a7-98eb-4448-8bc1-eef5ca0027b7,Distance-Aware Occlusion Detection with Focused Attention,0.218159,"For humans, understanding the relationships between objects using visual
signals is intuitive. For artificial intelligence, however, this task remains
challenging. Researchers have made significant progress studying semantic
relationship detection, such as human-object interaction detection and visual
relationship detection. We take the study of visual relationships a step
further from semantic to geometric. In specific, we predict relative occlusion
and relative distance relationships. However, detecting these relationships
from a single image is challenging. Enforcing focused attention to
task-specific regions plays a critical role in successfully detecting these
relationships. In this work, (1) we propose a novel three-decoder architecture
as the infrastructure for focused attention; 2) we use the generalized
intersection box prediction task to effectively guide our model to focus on
occlusion-specific regions; 3) our model achieves a new state-of-the-art
performance on distance-aware relationship detection. Specifically, our model
increases the distance F1-score from 33.8% to 38.6% and boosts the occlusion
F1-score from 34.4% to 41.2%. Our code is publicly available.",https://github.com/Yang-Li-2000/Distance-Aware-Occlusion-Detection-with-Focused-Attention.git,-1
60fab58f-ebbc-4219-9a68-d3e61dc3c60e,Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models,0.907968,"Pre-trained vision-language models (e.g., CLIP) have shown promising
zero-shot generalization in many downstream tasks with properly designed text
prompts. Instead of relying on hand-engineered prompts, recent works learn
prompts using the training data from downstream tasks. While effective,
training on domain-specific data reduces a model's generalization capability to
unseen new domains. In this work, we propose test-time prompt tuning (TPT), a
method that can learn adaptive prompts on the fly with a single test sample.
For image classification, TPT optimizes the prompt by minimizing the entropy
with confidence selection so that the model has consistent predictions across
different augmented views of each test sample. In evaluating generalization to
natural distribution shifts, TPT improves the zero-shot top-1 accuracy of CLIP
by 3.6% on average, surpassing previous prompt tuning approaches that require
additional task-specific training data. In evaluating cross-dataset
generalization with unseen categories, TPT performs on par with the
state-of-the-art approaches that use additional training data. Project page:
https://azshue.github.io/TPT.",https://tinyurl.com/yr3zmhma,-1
2029933c-741c-4e82-b880-36b7496d0161,MonoNeuralFusion: Online Monocular Neural 3D Reconstruction with Geometric Priors,0.332917,"High-fidelity 3D scene reconstruction from monocular videos continues to be
challenging, especially for complete and fine-grained geometry reconstruction.
The previous 3D reconstruction approaches with neural implicit representations
have shown a promising ability for complete scene reconstruction, while their
results are often over-smooth and lack enough geometric details. This paper
introduces a novel neural implicit scene representation with volume rendering
for high-fidelity online 3D scene reconstruction from monocular videos. For
fine-grained reconstruction, our key insight is to incorporate geometric priors
into both the neural implicit scene representation and neural volume rendering,
thus leading to an effective geometry learning mechanism based on volume
rendering optimization. Benefiting from this, we present MonoNeuralFusion to
perform the online neural 3D reconstruction from monocular videos, by which the
3D scene geometry is efficiently generated and optimized during the on-the-fly
3D monocular scanning. The extensive comparisons with state-of-the-art
approaches show that our MonoNeuralFusion consistently generates much better
complete and fine-grained reconstruction results, both quantitatively and
qualitatively.",https://github.com/AljazBozic/TransformerFusion,-1
9790e377-bf8b-4b9b-acce-da883a783586,A Human Rights-Based Approach to Responsible AI,0.63646,"Research on fairness, accountability, transparency and ethics of AI-based
interventions in society has gained much-needed momentum in recent years.
However it lacks an explicit alignment with a set of normative values and
principles that guide this research and interventions. Rather, an implicit
consensus is often assumed to hold for the values we impart into our models -
something that is at odds with the pluralistic world we live in. In this paper,
we put forth the doctrine of universal human rights as a set of globally
salient and cross-culturally recognized set of values that can serve as a
grounding framework for explicit value alignment in responsible AI - and
discuss its efficacy as a framework for civil society partnership and
participation. We argue that a human rights framework orients the research in
this space away from the machines and the risks of their biases, and towards
humans and the risks to their rights, essentially helping to center the
conversation around who is harmed, what harms they face, and how those harms
may be mitigated.",None,-1
ddefa8d8-956d-4421-92cf-907f7e2fec5f,Improving End-to-End Contextual Speech Recognition with Fine-Grained Contextual Knowledge Selection,0.815495,"Nowadays, most methods in end-to-end contextual speech recognition bias the
recognition process towards contextual knowledge. Since all-neural contextual
biasing methods rely on phrase-level contextual modeling and attention-based
relevance modeling, they may encounter confusion between similar
context-specific phrases, which hurts predictions at the token level. In this
work, we focus on mitigating confusion problems with fine-grained contextual
knowledge selection (FineCoS). In FineCoS, we introduce fine-grained knowledge
to reduce the uncertainty of token predictions. Specifically, we first apply
phrase selection to narrow the range of phrase candidates, and then conduct
token attention on the tokens in the selected phrase candidates. Moreover, we
re-normalize the attention weights of most relevant phrases in inference to
obtain more focused phrase-level contextual representations, and inject
position information to better discriminate phrases or tokens. On LibriSpeech
and an in-house 160,000-hour dataset, we explore the proposed methods based on
a controllable all-neural biasing method, collaborative decoding (ColDec). The
proposed methods provide at most 6.1% relative word error rate reduction on
LibriSpeech and 16.4% relative character error rate reduction on the in-house
dataset over ColDec.",https://github.com/MingLunHan/CIF-ColDec,-1
21528574-8ad1-498f-99a5-e279cd5d5278,POEM: Out-of-Distribution Detection with Posterior Sampling,0.997484,"Out-of-distribution (OOD) detection is indispensable for machine learning
models deployed in the open world. Recently, the use of an auxiliary outlier
dataset during training (also known as outlier exposure) has shown promising
performance. As the sample space for potential OOD data can be prohibitively
large, sampling informative outliers is essential. In this work, we propose a
novel posterior sampling-based outlier mining framework, POEM, which
facilitates efficient use of outlier data and promotes learning a compact
decision boundary between ID and OOD data for improved detection. We show that
POEM establishes state-of-the-art performance on common benchmarks. Compared to
the current best method that uses a greedy sampling strategy, POEM improves the
relative performance by 42.0% and 24.2% (FPR95) on CIFAR-10 and CIFAR-100,
respectively. We further provide theoretical insights on the effectiveness of
POEM for OOD detection.",https://github.com/deeplearning-wisc/poem,746
cfce1c54-541f-401a-9fe7-55c7ff93f4ec,Privacy-Preserving Image Classification Using Vision Transformer,0.864702,"In this paper, we propose a privacy-preserving image classification method
that is based on the combined use of encrypted images and the vision
transformer (ViT). The proposed method allows us not only to apply images
without visual information to ViT models for both training and testing but to
also maintain a high classification accuracy. ViT utilizes patch embedding and
position embedding for image patches, so this architecture is shown to reduce
the influence of block-wise image transformation. In an experiment, the
proposed method for privacy-preserving image classification is demonstrated to
outperform state-of-the-art methods in terms of classification accuracy and
robustness against various attacks.",None,-1
70080d58-2ebe-4be5-b770-ee666664cf21,Dual-former: Hybrid Self-attention Transformer for Efficient Image Restoration,0.370225,"Recently, image restoration transformers have achieved comparable performance
with previous state-of-the-art CNNs. However, how to efficiently leverage such
architectures remains an open problem. In this work, we present Dual-former
whose critical insight is to combine the powerful global modeling ability of
self-attention modules and the local modeling ability of convolutions in an
overall architecture. With convolution-based Local Feature Extraction modules
equipped in the encoder and the decoder, we only adopt a novel Hybrid
Transformer Block in the latent layer to model the long-distance dependence in
spatial dimensions and handle the uneven distribution between channels. Such a
design eliminates the substantial computational complexity in previous image
restoration transformers and achieves superior performance on multiple image
restoration tasks. Experiments demonstrate that Dual-former achieves a 1.91dB
gain over the state-of-the-art MAXIM method on the Indoor dataset for single
image dehazing while consuming only 4.2% GFLOPs as MAXIM. For single image
deraining, it exceeds the SOTA method by 0.1dB PSNR on the average results of
five datasets with only 21.5% GFLOPs. Dual-former also substantially surpasses
the latest desnowing method on various datasets, with fewer parameters.",None,-1
0b1dc11a-655b-4410-bf4f-5f2e2565b1f8,Few-Shot Diffusion Models,0.456698,"Denoising diffusion probabilistic models (DDPM) are powerful hierarchical
latent variable models with remarkable sample generation quality and training
stability. These properties can be attributed to parameter sharing in the
generative hierarchy, as well as a parameter-free diffusion-based inference
procedure. In this paper, we present Few-Shot Diffusion Models (FSDM), a
framework for few-shot generation leveraging conditional DDPMs. FSDMs are
trained to adapt the generative process conditioned on a small set of images
from a given class by aggregating image patch information using a set-based
Vision Transformer (ViT). At test time, the model is able to generate samples
from previously unseen classes conditioned on as few as 5 samples from that
class. We empirically show that FSDM can perform few-shot generation and
transfer to new datasets. We benchmark variants of our method on complex vision
datasets for few-shot learning and compare to unconditional and conditional
DDPM baselines. Additionally, we show how conditioning the model on patch-based
input set information improves training convergence.",None,-1
bae0eeec-9b7c-44b1-965d-327b7f889bad,A Transparency Index Framework for AI in Education,0.469098,"Numerous AI ethics checklists and frameworks have been proposed focusing on
different dimensions of ethical AI such as fairness, explainability, and
safety. Yet, no such work has been done on developing transparent AI systems
for real-world educational scenarios. This paper presents a Transparency Index
framework that has been iteratively co-designed with different stakeholders of
AI in education, including educators, ed-tech experts, and AI practitioners. We
map the requirements of transparency for different categories of stakeholders
of AI in education and demonstrate that transparency considerations are
embedded in the entire AI development process from the data collection stage
until the AI system is deployed in the real world and iteratively improved. We
also demonstrate how transparency enables the implementation of other ethical
AI dimensions in Education like interpretability, accountability, and safety.
In conclusion, we discuss the directions for future research in this newly
emerging field. The main contribution of this study is that it highlights the
importance of transparency in developing AI-powered educational technologies
and proposes an index framework for its conceptualization for AI in education.",None,-1
4ce68478-e79e-4daf-8c24-acdba2a44d3a,A Systematic Evaluation of Response Selection for Open Domain Dialogue,0.787324,"Recent progress on neural approaches for language processing has triggered a
resurgence of interest on building intelligent open-domain chatbots. However,
even the state-of-the-art neural chatbots cannot produce satisfying responses
for every turn in a dialog. A practical solution is to generate multiple
response candidates for the same context, and then perform response
ranking/selection to determine which candidate is the best. Previous work in
response selection typically trains response rankers using synthetic data that
is formed from existing dialogs by using a ground truth response as the single
appropriate response and constructing inappropriate responses via random
selection or using adversarial methods. In this work, we curated a dataset
where responses from multiple response generators produced for the same dialog
context are manually annotated as appropriate (positive) and inappropriate
(negative). We argue that such training data better matches the actual use case
examples, enabling the models to learn to rank responses effectively. With this
new dataset, we conduct a systematic evaluation of state-of-the-art methods for
response selection, and demonstrate that both strategies of using multiple
positive candidates and using manually verified hard negative candidates can
bring in significant performance improvement in comparison to using the
adversarial training data, e.g., increase of 3% and 13% in Recall@1 score,
respectively.",https://github.com/golsun/DialogRPT/,-1
217d6db8-ecc5-4afc-8053-c966d2fcfe6c,Weakly-supervised segmentation of referring expressions,0.463169,"Visual grounding localizes regions (boxes or segments) in the image
corresponding to given referring expressions. In this work we address image
segmentation from referring expressions, a problem that has so far only been
addressed in a fully-supervised setting. A fully-supervised setup, however,
requires pixel-wise supervision and is hard to scale given the expense of
manual annotation. We therefore introduce a new task of weakly-supervised image
segmentation from referring expressions and propose Text grounded semantic
SEGgmentation (TSEG) that learns segmentation masks directly from image-level
referring expressions without pixel-level annotations. Our transformer-based
method computes patch-text similarities and guides the classification objective
during training with a new multi-label patch assignment mechanism. The
resulting visual grounding model segments image regions corresponding to given
natural language expressions. Our approach TSEG demonstrates promising results
for weakly-supervised referring expression segmentation on the challenging
PhraseCut and RefCOCO datasets. TSEG also shows competitive performance when
evaluated in a zero-shot setting for semantic segmentation on Pascal VOC.",None,-1
78ed3318-2451-4e3e-837f-a0805a35de08,Unsupervised Anomaly Detection from Time-of-Flight Depth Images,0.256081,"Video anomaly detection (VAD) addresses the problem of automatically finding
anomalous events in video data. The primary data modalities on which current
VAD systems work on are monochrome or RGB images. Using depth data in this
context instead is still hardly explored in spite of depth images being a
popular choice in many other computer vision research areas and the increasing
availability of inexpensive depth camera hardware. We evaluate the application
of existing autoencoder-based methods on depth video and propose how the
advantages of using depth data can be leveraged by integration into the loss
function. Training is done unsupervised using normal sequences without need for
any additional annotations. We show that depth allows easy extraction of
auxiliary information for scene analysis in the form of a foreground mask and
demonstrate its beneficial effect on the anomaly detection performance through
evaluation on a large public dataset, for which we are also the first ones to
present results on.",None,-1
8fe7bbd7-7e78-4154-9544-62f2b60cd3bc,The Self-Optimal-Transport Feature Transform,0.71508,"The Self-Optimal-Transport (SOT) feature transform is designed to upgrade the
set of features of a data instance to facilitate downstream matching or
grouping related tasks. The transformed set encodes a rich representation of
high order relations between the instance features. Distances between
transformed features capture their direct original similarity and their third
party agreement regarding similarity to other features in the set. A particular
min-cost-max-flow fractional matching problem, whose entropy regularized
version can be approximated by an optimal transport (OT) optimization, results
in our transductive transform which is efficient, differentiable, equivariant,
parameterless and probabilistically interpretable. Empirically, the transform
is highly effective and flexible in its use, consistently improving networks it
is inserted into, in a variety of tasks and training schemes. We demonstrate
its merits through the problem of unsupervised clustering and its efficiency
and wide applicability for few-shot-classification, with state-of-the-art
results, and large-scale person re-identification.",None,-1
4fc877a8-fd84-455b-be49-b09099c79b6a,Perception Prioritized Training of Diffusion Models,0.903955,"Diffusion models learn to restore noisy data, which is corrupted with
different levels of noise, by optimizing the weighted sum of the corresponding
loss terms, i.e., denoising score matching loss. In this paper, we show that
restoring data corrupted with certain noise levels offers a proper pretext task
for the model to learn rich visual concepts. We propose to prioritize such
noise levels over other levels during training, by redesigning the weighting
scheme of the objective function. We show that our simple redesign of the
weighting scheme significantly improves the performance of diffusion models
regardless of the datasets, architectures, and sampling strategies.",https://github.com/jychoi118/P2-weighting,-1
f3ea3b0c-b346-45cc-9b64-57492aad986f,Attentive Task Interaction Network for Multi-Task Learning,0.0207436,"Multitask learning (MTL) has recently gained a lot of popularity as a
learning paradigm that can lead to improved per-task performance while also
using fewer per-task model parameters compared to single task learning. One of
the biggest challenges regarding MTL networks involves how to share features
across tasks. To address this challenge, we propose the Attentive Task
Interaction Network (ATI-Net). ATI-Net employs knowledge distillation of the
latent features for each task, then combines the feature maps to provide
improved contextualized information to the decoder. This novel approach to
introducing knowledge distillation into an attention based multitask network
outperforms state of the art MTL baselines such as the standalone MTAN and
PAD-Net, with roughly the same number of model parameters.",https://github.com/Armanfard-Lab/ATI-Net,-1
1c3e242d-60a6-4c7d-9a4c-e1486bcc731d,POQue: Asking Participant-specific Outcome Questions for a Deeper Understanding of Complex Events,0.126722,"Knowledge about outcomes is critical for complex event understanding but is
hard to acquire. We show that by pre-identifying a participant in a complex
event, crowd workers are able to (1) infer the collective impact of salient
events that make up the situation, (2) annotate the volitional engagement of
participants in causing the situation, and (3) ground the outcome of the
situation in state changes of the participants. By creating a multi-step
interface and a careful quality control strategy, we collect a high quality
annotated dataset of 8K short newswire narratives and ROCStories with high
inter-annotator agreement (0.74-0.96 weighted Fleiss Kappa). Our dataset, POQue
(Participant Outcome Questions), enables the exploration and development of
models that address multiple aspects of semantic understanding. Experimentally,
we show that current language models lag behind human performance in subtle
ways through our task formulations that target abstract and specific
comprehension of a complex event, its outcome, and a participant's influence
over the event culmination.",https://github.com/saiumbc/POQue,-1
4dd15a0b-d38a-4855-8d8d-9ae9e8885659,EnvEdit: Environment Editing for Vision-and-Language Navigation,0.72194,"In Vision-and-Language Navigation (VLN), an agent needs to navigate through
the environment based on natural language instructions. Due to limited
available data for agent training and finite diversity in navigation
environments, it is challenging for the agent to generalize to new, unseen
environments. To address this problem, we propose EnvEdit, a data augmentation
method that creates new environments by editing existing environments, which
are used to train a more generalizable agent. Our augmented environments can
differ from the seen environments in three diverse aspects: style, object
appearance, and object classes. Training on these edit-augmented environments
prevents the agent from overfitting to existing environments and helps
generalize better to new, unseen environments. Empirically, on both the
Room-to-Room and the multi-lingual Room-Across-Room datasets, we show that our
proposed EnvEdit method gets significant improvements in all metrics on both
pre-trained and non-pre-trained VLN agents, and achieves the new
state-of-the-art on the test leaderboard. We further ensemble the VLN agents
augmented on different edited environments and show that these edit methods are
complementary. Code and data are available at
https://github.com/jialuli-luka/EnvEdit",https://github.com/jialuli-luka/EnvEdit,-1
b1b97e1e-2e2d-4efb-874c-b9d3bb939be4,Quantum Motion Segmentation,0.353905,"Motion segmentation is a challenging problem that seeks to identify
independent motions in two or several input images. This paper introduces the
first algorithm for motion segmentation that relies on adiabatic quantum
optimization of the objective function. The proposed method achieves on-par
performance with the state of the art on problem instances which can be mapped
to modern quantum annealers.",None,-1
78bc5cf4-92e0-4576-8eaf-92a99e00a1c1,Image Super-resolution with An Enhanced Group Convolutional Neural Network,0.913283,"CNNs with strong learning abilities are widely chosen to resolve
super-resolution problem. However, CNNs depend on deeper network architectures
to improve performance of image super-resolution, which may increase
computational cost in general. In this paper, we present an enhanced
super-resolution group CNN (ESRGCNN) with a shallow architecture by fully
fusing deep and wide channel features to extract more accurate low-frequency
information in terms of correlations of different channels in single image
super-resolution (SISR). Also, a signal enhancement operation in the ESRGCNN is
useful to inherit more long-distance contextual information for resolving
long-term dependency. An adaptive up-sampling operation is gathered into a CNN
to obtain an image super-resolution model with low-resolution images of
different sizes. Extensive experiments report that our ESRGCNN surpasses the
state-of-the-arts in terms of SISR performance, complexity, execution speed,
image quality evaluation and visual effect in SISR. Code is found at
https://github.com/hellloxiaotian/ESRGCNN.",https://github.com/hellloxiaotian/ESRGCNN,-1
2af058b2-3999-40b6-a302-9f00c75d64ca,PCRED: Zero-shot Relation Triplet Extraction with Potential Candidate Relation Selection and Entity Boundary Detection,0.864665,"Zero-shot relation triplet extraction (ZeroRTE) aims to extract relation
triplets from unstructured texts under the zero-shot setting, where the
relation sets at the training and testing stages are disjoint. Previous
state-of-the-art method handles this challenging task by leveraging pretrained
language models to generate data as additional training samples, which
increases the training cost and severely constrains the model performance. To
address the above issues, we propose a novel method named PCRED for ZeroRTE
with Potential Candidate Relation Selection and Entity Boundary Detection. The
remarkable characteristic of PCRED is that it does not rely on additional data
and still achieves promising performance. The model adopts a relation-first
paradigm, recognizing unseen relations through candidate relation selection.
With this approach, the semantics of relations are naturally infused in the
context. Entities are extracted based on the context and the semantics of
relations subsequently. We evaluate our model on two ZeroRTE datasets. The
experiment results show that our method consistently outperforms previous
works. Our code will be available at https://anonymous.4open.science/r/PCRED.",https://anonymous.4open.science/r/PCRED,-1
a6c7e885-bc4f-4f98-83bb-c7f931025213,Transformers are Sample-Efficient World Models,0.792866,"Deep reinforcement learning agents are notoriously sample inefficient, which
considerably limits their application to real-world problems. Recently, many
model-based methods have been designed to address this issue, with learning in
the imagination of a world model being one of the most prominent approaches.
However, while virtually unlimited interaction with a simulated environment
sounds appealing, the world model has to be accurate over extended periods of
time. Motivated by the success of Transformers in sequence modeling tasks, we
introduce IRIS, a data-efficient agent that learns in a world model composed of
a discrete autoencoder and an autoregressive Transformer. With the equivalent
of only two hours of gameplay in the Atari 100k benchmark, IRIS achieves a mean
human normalized score of 1.046, and outperforms humans on 10 out of 26 games,
setting a new state of the art for methods without lookahead search. To foster
future research on Transformers and world models for sample-efficient
reinforcement learning, we release our code and models at
https://github.com/eloialonso/iris.",https://github.com/eloialonso/iris,-1
b358abcd-5651-4f12-b8be-372fa558eb2f,Training a T5 Using Lab-sized Resources,0.110752,"Training large neural language models on large datasets is resource- and
time-intensive. These requirements create a barrier to entry, where those with
fewer resources cannot build competitive models. This paper presents various
techniques for making it possible to (a) train a large language model using
resources that a modest research lab might have, and (b) train it in a
reasonable amount of time. We provide concrete recommendations for
practitioners, which we illustrate with a case study: a T5 model for Danish,
the first for this language.",None,-1
8b6f39ce-e520-4a1a-a8d4-a4d33d4c5725,GPT Takes the Bar Exam,0.999797,"Nearly all jurisdictions in the United States require a professional license
exam, commonly referred to as ""the Bar Exam,"" as a precondition for law
practice. To even sit for the exam, most jurisdictions require that an
applicant completes at least seven years of post-secondary education, including
three years at an accredited law school. In addition, most test-takers also
undergo weeks to months of further, exam-specific preparation. Despite this
significant investment of time and capital, approximately one in five
test-takers still score under the rate required to pass the exam on their first
try. In the face of a complex task that requires such depth of knowledge, what,
then, should we expect of the state of the art in ""AI?"" In this research, we
document our experimental evaluation of the performance of OpenAI's
`text-davinci-003` model, often-referred to as GPT-3.5, on the multistate
multiple choice (MBE) section of the exam. While we find no benefit in
fine-tuning over GPT-3.5's zero-shot performance at the scale of our training
data, we do find that hyperparameter optimization and prompt engineering
positively impacted GPT-3.5's zero-shot performance. For best prompt and
parameters, GPT-3.5 achieves a headline correct rate of 50.3% on a complete
NCBE MBE practice exam, significantly in excess of the 25% baseline guessing
rate, and performs at a passing rate for both Evidence and Torts. GPT-3.5's
ranking of responses is also highly-correlated with correctness; its top two
and top three choices are correct 71% and 88% of the time, respectively,
indicating very strong non-entailment performance. While our ability to
interpret these results is limited by nascent scientific understanding of LLMs
and the proprietary nature of GPT, we believe that these results strongly
suggest that an LLM will pass the MBE component of the Bar Exam in the near
future.",https://github.com/mjbommar/gpt-takes-the-bar-exam,-1
e594feb9-a2b3-4cc4-aee4-4d57a2de1703,Online Decision Transformer,0.999009,"Recent work has shown that offline reinforcement learning (RL) can be
formulated as a sequence modeling problem (Chen et al., 2021; Janner et al.,
2021) and solved via approaches similar to large-scale language modeling.
However, any practical instantiation of RL also involves an online component,
where policies pretrained on passive offline datasets are finetuned via
taskspecific interactions with the environment. We propose Online Decision
Transformers (ODT), an RL algorithm based on sequence modeling that blends
offline pretraining with online finetuning in a unified framework. Our
framework uses sequence-level entropy regularizers in conjunction with
autoregressive modeling objectives for sample-efficient exploration and
finetuning. Empirically, we show that ODT is competitive with the
state-of-the-art in absolute performance on the D4RL benchmark but shows much
more significant gains during the finetuning procedure.",https://github.com/kzl/decision-transformer,-1
b9502d7e-daed-4b38-9972-09d7035dfc2e,Consistency Learning via Decoding Path Augmentation for Transformers in Human Object Interaction Detection,0.643643,"Human-Object Interaction detection is a holistic visual recognition task that
entails object detection as well as interaction classification. Previous works
of HOI detection has been addressed by the various compositions of subset
predictions, e.g., Image -> HO -> I, Image -> HI -> O. Recently, transformer
based architecture for HOI has emerged, which directly predicts the HOI
triplets in an end-to-end fashion (Image -> HOI). Motivated by various
inference paths for HOI detection, we propose cross-path consistency learning
(CPC), which is a novel end-to-end learning strategy to improve HOI detection
for transformers by leveraging augmented decoding paths. CPC learning enforces
all the possible predictions from permuted inference sequences to be
consistent. This simple scheme makes the model learn consistent
representations, thereby improving generalization without increasing model
capacity. Our experiments demonstrate the effectiveness of our method, and we
achieved significant improvement on V-COCO and HICO-DET compared to the
baseline models. Our code is available at https://github.com/mlvlab/CPChoi.",https://github.com/mlvlab/CPChoi,-1
b7bca2f2-c121-45d0-b4ef-73861e5e8432,Disentangling Identity and Pose for Facial Expression Recognition,0.798104,"Facial expression recognition (FER) is a challenging problem because the
expression component is always entangled with other irrelevant factors, such as
identity and head pose. In this work, we propose an identity and pose
disentangled facial expression recognition (IPD-FER) model to learn more
discriminative feature representation. We regard the holistic facial
representation as the combination of identity, pose and expression. These three
components are encoded with different encoders. For identity encoder, a well
pre-trained face recognition model is utilized and fixed during training, which
alleviates the restriction on specific expression training data in previous
works and makes the disentanglement practicable on in-the-wild datasets. At the
same time, the pose and expression encoder are optimized with corresponding
labels. Combining identity and pose feature, a neutral face of input individual
should be generated by the decoder. When expression feature is added, the input
image should be reconstructed. By comparing the difference between synthesized
neutral and expressional images of the same individual, the expression
component is further disentangled from identity and pose. Experimental results
verify the effectiveness of our method on both lab-controlled and in-the-wild
databases and we achieve state-of-the-art recognition performance.",https://github.com/WIKI2020/FacePose,-1
ad06944a-e472-45b7-be79-b7a2b5a8eae9,Human-Object Interaction Detection via Disentangled Transformer,0.830849,"Human-Object Interaction Detection tackles the problem of joint localization
and classification of human object interactions. Existing HOI transformers
either adopt a single decoder for triplet prediction, or utilize two parallel
decoders to detect individual objects and interactions separately, and compose
triplets by a matching process. In contrast, we decouple the triplet prediction
into human-object pair detection and interaction classification. Our main
motivation is that detecting the human-object instances and classifying
interactions accurately needs to learn representations that focus on different
regions. To this end, we present Disentangled Transformer, where both encoder
and decoder are disentangled to facilitate learning of two sub-tasks. To
associate the predictions of disentangled decoders, we first generate a unified
representation for HOI triplets with a base decoder, and then utilize it as
input feature of each disentangled decoder. Extensive experiments show that our
method outperforms prior work on two public HOI benchmarks by a sizeable
margin. Code will be available.",https://github.com/facebookresearch/detectron2,-1
2c574df1-2965-4f30-b564-1604dd3aec46,HARP: Autoregressive Latent Video Prediction with High-Fidelity Image Generator,0.819026,"Video prediction is an important yet challenging problem; burdened with the
tasks of generating future frames and learning environment dynamics. Recently,
autoregressive latent video models have proved to be a powerful video
prediction tool, by separating the video prediction into two sub-problems:
pre-training an image generator model, followed by learning an autoregressive
prediction model in the latent space of the image generator. However,
successfully generating high-fidelity and high-resolution videos has yet to be
seen. In this work, we investigate how to train an autoregressive latent video
prediction model capable of predicting high-fidelity future frames with minimal
modification to existing models, and produce high-resolution (256x256) videos.
Specifically, we scale up prior models by employing a high-fidelity image
generator (VQ-GAN) with a causal transformer model, and introduce additional
techniques of top-k sampling and data augmentation to further improve video
prediction quality. Despite the simplicity, the proposed method achieves
competitive performance to state-of-the-art approaches on standard video
prediction benchmarks with fewer parameters, and enables high-resolution video
prediction on complex and large-scale datasets. Videos are available at
https://sites.google.com/view/harp-videos/home.",None,-1
678ac7ca-dca4-4a03-8677-30ee8d569f81,Disentangling Confidence Score Distribution for Out-of-Domain Intent Detection with Energy-Based Learning,0.404598,"Detecting Out-of-Domain (OOD) or unknown intents from user queries is
essential in a task-oriented dialog system. Traditional softmax-based
confidence scores are susceptible to the overconfidence issue. In this paper,
we propose a simple but strong energy-based score function to detect OOD where
the energy scores of OOD samples are higher than IND samples. Further, given a
small set of labeled OOD samples, we introduce an energy-based margin objective
for supervised OOD detection to explicitly distinguish OOD samples from INDs.
Comprehensive experiments and analysis prove our method helps disentangle
confidence score distributions of IND and OOD data.\footnote{Our code is
available at \url{https://github.com/pris-nlp/EMNLP2022-energy_for_OOD/}.}",https://github.com/pris-nlp/EMNLP2022-energy_for_OOD/,-1
0da71ac1-12dd-4616-b624-3f90d09a7a84,On the Principles of Parsimony and Self-Consistency for the Emergence of Intelligence,0.98567,"Ten years into the revival of deep networks and artificial intelligence, we
propose a theoretical framework that sheds light on understanding deep networks
within a bigger picture of Intelligence in general. We introduce two
fundamental principles, Parsimony and Self-consistency, that address two
fundamental questions regarding Intelligence: what to learn and how to learn,
respectively. We believe the two principles are the cornerstones for the
emergence of Intelligence, artificial or natural. While these two principles
have rich classical roots, we argue that they can be stated anew in entirely
measurable and computable ways. More specifically, the two principles lead to
an effective and efficient computational framework, compressive closed-loop
transcription, that unifies and explains the evolution of modern deep networks
and many artificial intelligence practices. While we mainly use modeling of
visual data as an example, we believe the two principles will unify
understanding of broad families of autonomous intelligent systems and provide a
framework for understanding the brain.",None,-1
88d3bca3-18fd-4653-a6cc-cbf4878f88f6,Unknown-Aware Domain Adversarial Learning for Open-Set Domain Adaptation,0.896969,"Open-Set Domain Adaptation (OSDA) assumes that a target domain contains
unknown classes, which are not discovered in a source domain. Existing domain
adversarial learning methods are not suitable for OSDA because distribution
matching with $\textit{unknown}$ classes leads to negative transfer. Previous
OSDA methods have focused on matching the source and the target distribution by
only utilizing $\textit{known}$ classes. However, this $\textit{known}$-only
matching may fail to learn the target-$\textit{unknown}$ feature space.
Therefore, we propose Unknown-Aware Domain Adversarial Learning (UADAL), which
$\textit{aligns}$ the source and the target-$\textit{known}$ distribution while
simultaneously $\textit{segregating}$ the target-$\textit{unknown}$
distribution in the feature alignment procedure. We provide theoretical
analyses on the optimized state of the proposed $\textit{unknown-aware}$
feature alignment, so we can guarantee both $\textit{alignment}$ and
$\textit{segregation}$ theoretically. Empirically, we evaluate UADAL on the
benchmark datasets, which shows that UADAL outperforms other methods with
better feature alignments by reporting state-of-the-art performances.",https://github.com/JoonHo-Jang/UADAL,-1
28ed08fb-6b67-4ea6-be79-aa0b5e1cf713,Phrase-level Textual Adversarial Attack with Label Preservation,0.571138,"Generating high-quality textual adversarial examples is critical for
investigating the pitfalls of natural language processing (NLP) models and
further promoting their robustness. Existing attacks are usually realized
through word-level or sentence-level perturbations, which either limit the
perturbation space or sacrifice fluency and textual quality, both affecting the
attack effectiveness. In this paper, we propose Phrase-Level Textual
Adversarial aTtack (PLAT) that generates adversarial samples through
phrase-level perturbations. PLAT first extracts the vulnerable phrases as
attack targets by a syntactic parser, and then perturbs them by a pre-trained
blank-infilling model. Such flexible perturbation design substantially expands
the search space for more effective attacks without introducing too many
modifications, and meanwhile maintaining the textual fluency and grammaticality
via contextualized generation using surrounding texts. Moreover, we develop a
label-preservation filter leveraging the likelihoods of language models
fine-tuned on each class, rather than textual similarity, to rule out those
perturbations that potentially alter the original class label for humans.
Extensive experiments and human evaluation demonstrate that PLAT has a superior
attack effectiveness as well as a better label consistency than strong
baselines.",https://github.com/Yibin-Lei/PLAT,15597
45fb04c4-2cd7-4df1-a6aa-d70e100626b7,Unsupervised Image-to-Image Translation with Generative Prior,0.839001,"Unsupervised image-to-image translation aims to learn the translation between
two visual domains without paired data. Despite the recent progress in image
translation models, it remains challenging to build mappings between complex
domains with drastic visual discrepancies. In this work, we present a novel
framework, Generative Prior-guided UNsupervised Image-to-image Translation
(GP-UNIT), to improve the overall quality and applicability of the translation
algorithm. Our key insight is to leverage the generative prior from pre-trained
class-conditional GANs (e.g., BigGAN) to learn rich content correspondences
across various domains. We propose a novel coarse-to-fine scheme: we first
distill the generative prior to capture a robust coarse-level content
representation that can link objects at an abstract semantic level, based on
which fine-level content features are adaptively learned for more accurate
multi-level content correspondences. Extensive experiments demonstrate the
superiority of our versatile framework over state-of-the-art methods in robust,
high-quality and diversified translations, even for challenging and distant
domains.",https://github.com/williamyang1991/GP-UNIT,-1
020c6e12-1493-4ea9-98e2-f2f0fb308ff1,Learning Texture Transformer Network for Light Field Super-Resolution,0.17142,"Hand-held light field cameras suffer from low spatial resolution due to the
inherent spatio-angular tradeoff. In this paper, we propose a method to improve
the spatial resolution of light field images with the aid of the Texture
Transformer Network (TTSR). The proposed method consists of three modules: the
first module produces an all-in focus high-resolution perspective image which
serves as a reference image for the second module, i.e. TTSR, which in turn
produces a high-resolution light field. The last module refines the spatial
resolution by imposing a light field prior. The results demonstrate around 4 dB
to 6 dB PSNR gain over a bicubically resized light field image",None,-1
9639ff9a-d739-4a00-9584-b5483ed48875,Robust Double-Encoder Network for RGB-D Panoptic Segmentation,0.66072,"Perception is crucial for robots that act in real-world environments, as
autonomous systems need to see and understand the world around them to act
properly. Panoptic segmentation provides an interpretation of the scene by
computing a pixelwise semantic label together with instance IDs. In this paper,
we address panoptic segmentation using RGB-D data of indoor scenes. We propose
a novel encoder-decoder neural network that processes RGB and depth separately
through two encoders. The features of the individual encoders are progressively
merged at different resolutions, such that the RGB features are enhanced using
complementary depth information. We propose a novel merging approach called
ResidualExcite, which reweighs each entry of the feature map according to its
importance. With our double-encoder architecture, we are robust to missing
cues. In particular, the same model can train and infer on RGB-D, RGB-only, and
depth-only input data, without the need to train specialized models. We
evaluate our method on publicly available datasets and show that our approach
achieves superior results compared to other common approaches for panoptic
segmentation.",https://github.com/PRBonn/PS-res-excite,-1
0826fe71-6e7a-4d62-a4a8-d475eb2d0d36,Enhancing Diffusion-Based Image Synthesis with Robust Classifier Guidance,0.567207,"Denoising diffusion probabilistic models (DDPMs) are a recent family of
generative models that achieve state-of-the-art results. In order to obtain
class-conditional generation, it was suggested to guide the diffusion process
by gradients from a time-dependent classifier. While the idea is theoretically
sound, deep learning-based classifiers are infamously susceptible to
gradient-based adversarial attacks. Therefore, while traditional classifiers
may achieve good accuracy scores, their gradients are possibly unreliable and
might hinder the improvement of the generation results. Recent work discovered
that adversarially robust classifiers exhibit gradients that are aligned with
human perception, and these could better guide a generative process towards
semantically meaningful images. We utilize this observation by defining and
training a time-dependent adversarially robust classifier and use it as
guidance for a generative diffusion model. In experiments on the highly
challenging and diverse ImageNet dataset, our scheme introduces significantly
more intelligible intermediate gradients, better alignment with theoretical
findings, as well as improved generation results under several evaluation
metrics. Furthermore, we conduct an opinion survey whose findings indicate that
human raters prefer our method's results.",https://github.com/bahjat-kawar/enhancing-diffusion-robust,82994
52606f6e-5948-4df4-9550-2a4c41ecb9c1,Unsupervised Domain Adaptation for Point Cloud Semantic Segmentation via Graph Matching,0.34518,"Unsupervised domain adaptation for point cloud semantic segmentation has
attracted great attention due to its effectiveness in learning with unlabeled
data. Most of existing methods use global-level feature alignment to transfer
the knowledge from the source domain to the target domain, which may cause the
semantic ambiguity of the feature space. In this paper, we propose a
graph-based framework to explore the local-level feature alignment between the
two domains, which can reserve semantic discrimination during adaptation.
Specifically, in order to extract local-level features, we first dynamically
construct local feature graphs on both domains and build a memory bank with the
graphs from the source domain. In particular, we use optimal transport to
generate the graph matching pairs. Then, based on the assignment matrix, we can
align the feature distributions between the two domains with the graph-based
local feature loss. Furthermore, we consider the correlation between the
features of different categories and formulate a category-guided contrastive
loss to guide the segmentation model to learn discriminative features on the
target domain. Extensive experiments on different synthetic-to-real and
real-to-real domain adaptation scenarios demonstrate that our method can
achieve state-of-the-art performance.",https://github.com/BianYikai/PointUDA,-1
e6fb63e0-a40e-45f4-8e7e-22f4c0624350,g2pW: A Conditional Weighted Softmax BERT for Polyphone Disambiguation in Mandarin,0.705446,"Polyphone disambiguation is the most crucial task in Mandarin
grapheme-to-phoneme (g2p) conversion. Previous studies have approached this
problem using pre-trained language models, restricted output, and extra
information from Part-Of-Speech (POS) tagging. Inspired by these strategies, we
propose a novel approach, called g2pW, which adapts learnable softmax-weights
to condition the outputs of BERT with the polyphonic character of interest and
its POS tagging. Rather than using the hard mask as in previous works, our
experiments show that learning a soft-weighting function for the candidate
phonemes benefits performance. In addition, our proposed g2pW does not require
extra pre-trained POS tagging models while using POS tags as auxiliary features
since we train the POS tagging model simultaneously with the unified encoder.
Experimental results show that our g2pW outperforms existing methods on the
public CPP dataset. All codes, model weights, and a user-friendly package are
publicly available.",https://github.com/GitYCC/g2pW,-1
22226f67-f463-4dd6-87df-c93a614be7a1,DeepTOP: Deep Threshold-Optimal Policy for MDPs and RMABs,0.159987,"We consider the problem of learning the optimal threshold policy for control
problems. Threshold policies make control decisions by evaluating whether an
element of the system state exceeds a certain threshold, whose value is
determined by other elements of the system state. By leveraging the monotone
property of threshold policies, we prove that their policy gradients have a
surprisingly simple expression. We use this simple expression to build an
off-policy actor-critic algorithm for learning the optimal threshold policy.
Simulation results show that our policy significantly outperforms other
reinforcement learning algorithms due to its ability to exploit the monotone
property. In addition, we show that the Whittle index, a powerful tool for
restless multi-armed bandit problems, is equivalent to the optimal threshold
policy for an alternative problem. This observation leads to a simple algorithm
that finds the Whittle index by learning the optimal threshold policy in the
alternative problem. Simulation results show that our algorithm learns the
Whittle index much faster than several recent studies that learn the Whittle
index through indirect means.",https://github.com/khalednakhleh/deeptop,-1
17a4711a-56e5-4360-8265-9db5ca5874ca,Multilingual Machine Translation with Hyper-Adapters,0.917915,"Multilingual machine translation suffers from negative interference across
languages. A common solution is to relax parameter sharing with
language-specific modules like adapters. However, adapters of related languages
are unable to transfer information, and their total number of parameters
becomes prohibitively expensive as the number of languages grows. In this work,
we overcome these drawbacks using hyper-adapters -- hyper-networks that
generate adapters from language and layer embeddings. While past work had poor
results when scaling hyper-networks, we propose a rescaling fix that
significantly improves convergence and enables training larger hyper-networks.
We find that hyper-adapters are more parameter efficient than regular adapters,
reaching the same performance with up to 12 times less parameters. When using
the same number of parameters and FLOPS, our approach consistently outperforms
regular adapters. Also, hyper-adapters converge faster than alternative
approaches and scale better than regular dense networks. Our analysis shows
that hyper-adapters learn to encode language relatedness, enabling positive
transfer across languages.",https://github.com/cbaziotis/fairseq,9766
3db32823-5ed1-42f5-bd3d-3a0f080e0ca7,GloCAL: Glocalized Curriculum-Aided Learning of Multiple Tasks with Application to Robotic Grasping,0.0804053,"The domain of robotics is challenging to apply deep reinforcement learning
due to the need for large amounts of data and for ensuring safety during
learning. Curriculum learning has shown good performance in terms of sample-
efficient deep learning. In this paper, we propose an algorithm (named GloCAL)
that creates a curriculum for an agent to learn multiple discrete tasks, based
on clustering tasks according to their evaluation scores. From the
highest-performing cluster, a global task representative of the cluster is
identified for learning a global policy that transfers to subsequently formed
new clusters, while the remaining tasks in the cluster are learned as local
policies. The efficacy and efficiency of our GloCAL algorithm are compared with
other approaches in the domain of grasp learning for 49 objects with varied
object complexity and grasp difficulty from the EGAD! dataset. The results show
that GloCAL is able to learn to grasp 100% of the objects, whereas other
approaches achieve at most 86% despite being given 1.5 times longer training
time.",https://github.com/hill-a/stable-baselines,-1
9e443305-26d2-444b-a16d-048b379a1ad3,"Two ways to make your robot proactive: reasoning about human intentions, or reasoning about possible futures",0.441924,"Robots sharing their space with humans need to be proactive in order to be
helpful. Proactive robots are able to act on their own initiative in an
anticipatory way to benefit humans. In this work, we investigate two ways to
make robots proactive. One way is to recognize humans' intentions and to act to
fulfill them, like opening the door that you are about to cross. The other way
is to reason about possible future threats or opportunities and to act to
prevent or to foster them, like recommending you to take an umbrella since rain
has been forecasted. In this paper, we present approaches to realize these two
types of proactive behavior. We then present an integrated system that can
generate proactive robot behavior by reasoning on both factors: intentions and
predictions. We illustrate our system on a sample use case including a domestic
robot and a human. We first run this use case with the two separate proactive
systems, intention-based and prediction-based, and then run it with our
integrated system. The results show that the integrated system is able to take
into account a broader variety of aspects that are needed for proactivity.",None,-1
dad3f858-1e4a-4f22-8aa5-28f898450ea9,gBuilder: A Scalable Knowledge Graph Construction System for Unstructured Corpus,0.35939,"We design a user-friendly and scalable knowledge graph construction (KGC)
system for extracting structured knowledge from the unstructured corpus.
Different from existing KGC systems, gBuilder provides a flexible and
user-defined pipeline to embrace the rapid development of IE models. More
built-in template-based or heuristic operators and programmable operators are
available for adapting to data from different domains. Furthermore, we also
design a cloud-based self-adaptive task scheduling for gBuilder to ensure its
scalability on large-scale knowledge graph construction. Experimental
evaluation demonstrates the ability of gBuilder to organize multiple
information extraction models for knowledge graph construction in a uniform
platform, and confirms its high scalability on large-scale KGC tasks.",None,-1
41402635-1f84-4c20-8ff5-110c0f7e881c,Whodunit? Learning to Contrast for Authorship Attribution,0.773398,"Authorship attribution is the task of identifying the author of a given text.
The key is finding representations that can differentiate between authors.
Existing approaches typically use manually designed features that capture a
dataset's content and style, but these approaches are dataset-dependent and
yield inconsistent performance across corpora. In this work, we propose
\textit{learning} author-specific representations by fine-tuning pre-trained
generic language representations with a contrastive objective (Contra-X). We
show that Contra-X learns representations that form highly separable clusters
for different authors. It advances the state-of-the-art on multiple human and
machine authorship attribution benchmarks, enabling improvements of up to 6.8%
over cross-entropy fine-tuning. However, we find that Contra-X improves overall
accuracy at the cost of sacrificing performance for some authors. Resolving
this tension will be an important direction for future work. To the best of our
knowledge, we are the first to integrate contrastive learning with pre-trained
language model fine-tuning for authorship attribution.",https://github.com/BoAi01/Contra-X.git,-1
3f91487e-11db-4262-929c-5af558381fb9,A Theoretical Framework for AI Models Explainability with Application in Biomedicine,0.161416,"EXplainable Artificial Intelligence (XAI) is a vibrant research topic in the
artificial intelligence community, with growing interest across methods and
domains. Much has been written about the subject, yet XAI still lacks shared
terminology and a framework capable of providing structural soundness to
explanations. In our work, we address these issues by proposing a novel
definition of explanation that is a synthesis of what can be found in the
literature. We recognize that explanations are not atomic but the combination
of evidence stemming from the model and its input-output mapping, and the human
interpretation of this evidence. Furthermore, we fit explanations into the
properties of faithfulness (i.e., the explanation being a true description of
the model's inner workings and decision-making process) and plausibility (i.e.,
how much the explanation looks convincing to the user). Using our proposed
theoretical framework simplifies how these properties are operationalized and
it provides new insight into common explanation methods that we analyze as case
studies.",None,-1
4e9f5f0d-3169-499f-9051-50c3d977dbcf,Detect Hate Speech in Unseen Domains using Multi-Task Learning: A Case Study of Political Public Figures,0.345046,"Automatic identification of hateful and abusive content is vital in combating
the spread of harmful online content and its damaging effects. Most existing
works evaluate models by examining the generalization error on train-test
splits on hate speech datasets. These datasets often differ in their
definitions and labeling criteria, leading to poor model performance when
predicting across new domains and datasets. In this work, we propose a new
Multi-task Learning (MTL) pipeline that utilizes MTL to train simultaneously
across multiple hate speech datasets to construct a more encompassing
classification model. We simulate evaluation on new previously unseen datasets
by adopting a leave-one-out scheme in which we omit a target dataset from
training and jointly train on the other datasets. Our results consistently
outperform a large sample of existing work. We show strong results when
examining generalization error in train-test splits and substantial
improvements when predicting on previously unseen datasets. Furthermore, we
assemble a novel dataset, dubbed PubFigs, focusing on the problematic speech of
American Public Political Figures. We automatically detect problematic speech
in the $305,235$ tweets in PubFigs, and we uncover insights into the posting
behaviors of public figures.",None,-1
5650267e-d8b2-4cd1-b35c-f1d15e1c9ac0,ER: Equivariance Regularizer for Knowledge Graph Completion,0.471523,"Tensor factorization and distanced based models play important roles in
knowledge graph completion (KGC). However, the relational matrices in KGC
methods often induce a high model complexity, bearing a high risk of
overfitting. As a remedy, researchers propose a variety of different
regularizers such as the tensor nuclear norm regularizer. Our motivation is
based on the observation that the previous work only focuses on the ""size"" of
the parametric space, while leaving the implicit semantic information widely
untouched. To address this issue, we propose a new regularizer, namely,
Equivariance Regularizer (ER), which can suppress overfitting by leveraging the
implicit semantic information. Specifically, ER can enhance the generalization
ability of the model by employing the semantic equivariance between the head
and tail entities. Moreover, it is a generic solution for both distance based
models and tensor factorization based models. The experimental results indicate
a clear and substantial improvement over the state-of-the-art relation
prediction methods.",https://github.com/Lion-ZS/ER,-1
51cc8798-c656-411d-ac6d-e02dfd32843c,Calibrate and Refine! A Novel and Agile Framework for ASR-error Robust Intent Detection,0.293151,"The past ten years have witnessed the rapid development of text-based intent
detection, whose benchmark performances have already been taken to a remarkable
level by deep learning techniques. However, automatic speech recognition (ASR)
errors are inevitable in real-world applications due to the environment noise,
unique speech patterns and etc, leading to sharp performance drop in
state-of-the-art text-based intent detection models. Essentially, this
phenomenon is caused by the semantic drift brought by ASR errors and most
existing works tend to focus on designing new model structures to reduce its
impact, which is at the expense of versatility and flexibility. Different from
previous one-piece model, in this paper, we propose a novel and agile framework
called CR-ID for ASR error robust intent detection with two plug-and-play
modules, namely semantic drift calibration module (SDCM) and phonemic
refinement module (PRM), which are both model-agnostic and thus could be easily
integrated to any existing intent detection models without modifying their
structures. Experimental results on SNIPS dataset show that, our proposed CR-ID
framework achieves competitive performance and outperform all the baseline
methods on ASR outputs, which verifies that CR-ID can effectively alleviate the
semantic drift caused by ASR errors.",https://github.com/MiuLab/SpokenVec,-1
7b50250a-ab4c-4f2d-82f0-2ee53569da80,Enhancing Document-level Relation Extraction by Entity Knowledge Injection,0.490073,"Document-level relation extraction (RE) aims to identify the relations
between entities throughout an entire document. It needs complex reasoning
skills to synthesize various knowledge such as coreferences and commonsense.
Large-scale knowledge graphs (KGs) contain a wealth of real-world facts, and
can provide valuable knowledge to document-level RE. In this paper, we propose
an entity knowledge injection framework to enhance current document-level RE
models. Specifically, we introduce coreference distillation to inject
coreference knowledge, endowing an RE model with the more general capability of
coreference reasoning. We also employ representation reconciliation to inject
factual knowledge and aggregate KG representations and document representations
into a unified space. The experiments on two benchmark datasets validate the
generalization of our entity knowledge injection framework and the consistent
improvement to several document-level RE models.",https://github.com/nju-websoft/KIRE,-1
17579b19-810d-4f89-898a-606b9ae7af06,Findings of the The RuATD Shared Task 2022 on Artificial Text Detection in Russian,0.505969,"We present the shared task on artificial text detection in Russian, which is
organized as a part of the Dialogue Evaluation initiative, held in 2022. The
shared task dataset includes texts from 14 text generators, i.e., one human
writer and 13 text generative models fine-tuned for one or more of the
following generation tasks: machine translation, paraphrase generation, text
summarization, text simplification. We also consider back-translation and
zero-shot generation approaches. The human-written texts are collected from
publicly available resources across multiple domains. The shared task consists
of two sub-tasks: (i) to determine if a given text is automatically generated
or written by a human; (ii) to identify the author of a given text. The first
task is framed as a binary classification problem. The second task is a
multi-class classification problem. We provide count-based and BERT-based
baselines, along with the human evaluation on the first sub-task. A total of 30
and 8 systems have been submitted to the binary and multi-class sub-tasks,
correspondingly. Most teams outperform the baselines by a wide margin. We
publicly release our codebase, human evaluation results, and other materials in
our GitHub repository (https://github.com/dialogue-evaluation/RuATD).",https://github.com/dialogue-evaluation/RuATD,2091
fb57a366-bd97-4cef-b0c8-7b009a579e8e,B-SMART: A Reference Architecture for Artificially Intelligent Autonomic Smart Buildings,0.884224,"The pervasive application of artificial intelligence and machine learning
algorithms is transforming many industries and aspects of the human experience.
One very important industry trend is the move to convert existing human
dwellings to smart buildings, and to create new smart buildings. Smart
buildings aim to mitigate climate change by reducing energy consumption and
associated carbon emissions. To accomplish this, they leverage artificial
intelligence, big data, and machine learning algorithms to learn and optimize
system performance. These fields of research are currently very rapidly
evolving and advancing, but there has been very little guidance to help
engineers and architects working on smart buildings apply artificial
intelligence algorithms and technologies in a systematic and effective manner.
In this paper we present B-SMART: the first reference architecture for
autonomic smart buildings. B-SMART facilitates the application of artificial
intelligence techniques and technologies to smart buildings by decoupling
conceptually distinct layers of functionality and organizing them into an
autonomic control loop. We also present a case study illustrating how B-SMART
can be applied to accelerate the introduction of artificial intelligence into
an existing smart building.",None,-1
61e581df-e00a-4d55-a44f-1c2aa5b4e46c,Measuring Inconsistency in Declarative Process Specifications,0.342388,"We address the problem of measuring inconsistency in declarative process
specifications, with an emphasis on linear temporal logic on fixed traces
(LTLff). As we will show, existing inconsistency measures for classical logic
cannot provide a meaningful assessment of inconsistency in LTL in general, as
they cannot adequately handle the temporal operators. We therefore propose a
novel paraconsistent semantics as a framework for inconsistency measurement. We
then present two new inconsistency measures based on these semantics and show
that they satisfy important desirable properties. We show how these measures
can be applied to declarative process models and investigate the computational
complexity of the introduced approach.",None,-1
13269ce4-359c-4f86-af17-f41d73d31130,Medicinal Boxes Recognition on a Deep Transfer Learning Augmented Reality Mobile Application,0.134613,"Taking medicines is a fundamental aspect to cure illnesses. However, studies
have shown that it can be hard for patients to remember the correct posology.
More aggravating, a wrong dosage generally causes the disease to worsen.
Although, all relevant instructions for a medicine are summarized in the
corresponding patient information leaflet, the latter is generally difficult to
navigate and understand. To address this problem and help patients with their
medication, in this paper we introduce an augmented reality mobile application
that can present to the user important details on the framed medicine. In
particular, the app implements an inference engine based on a deep neural
network, i.e., a densenet, fine-tuned to recognize a medicinal from its
package. Subsequently, relevant information, such as posology or a simplified
leaflet, is overlaid on the camera feed to help a patient when taking a
medicine. Extensive experiments to select the best hyperparameters were
performed on a dataset specifically collected to address this task; ultimately
obtaining up to 91.30\% accuracy as well as real-time capabilities.",None,-1
3ccd0e53-c633-4d06-b84a-904fc967ae0d,Improving Simultaneous Machine Translation with Monolingual Data,0.448988,"Simultaneous machine translation (SiMT) is usually done via sequence-level
knowledge distillation (Seq-KD) from a full-sentence neural machine translation
(NMT) model. However, there is still a significant performance gap between NMT
and SiMT. In this work, we propose to leverage monolingual data to improve
SiMT, which trains a SiMT student on the combination of bilingual data and
external monolingual data distilled by Seq-KD. Preliminary experiments on En-Zh
and En-Ja news domain corpora demonstrate that monolingual data can
significantly improve translation quality (e.g., +3.15 BLEU on En-Zh). Inspired
by the behavior of human simultaneous interpreters, we propose a novel
monolingual sampling strategy for SiMT, considering both chunk length and
monotonicity. Experimental results show that our sampling strategy consistently
outperforms the random sampling strategy (and other conventional typical NMT
monolingual sampling strategies) by avoiding the key problem of SiMT --
hallucination, and has better scalability. We achieve +0.72 BLEU improvements
on average against random sampling on En-Zh and En-Ja. Data and codes can be
found at https://github.com/hexuandeng/Mono4SiMT.",https://github.com/hexuandeng/Mono4SiMT,123783
a12920e9-1684-4ecf-8ab5-dad097bd35f0,Towards automatic generation of Piping and Instrumentation Diagrams (P&IDs) with Artificial Intelligence,0.736403,"Developing Piping and Instrumentation Diagrams (P&IDs) is a crucial step
during the development of chemical processes. Currently, this is a tedious,
manual, and time-consuming task. We propose a novel, completely data-driven
method for the prediction of control structures. Our methodology is inspired by
end-to-end transformer-based human language translation models. We cast the
control structure prediction as a translation task where Process Flow Diagrams
(PFDs) are translated to P&IDs. To use established transformer-based language
translation models, we represent the P&IDs and PFDs as strings using our
recently proposed SFILES 2.0 notation. Model training is performed in a
transfer learning approach. Firstly, we pre-train our model using generated
P&IDs to learn the grammatical structure of the process diagrams. Thereafter,
the model is fine-tuned leveraging transfer learning on real P&IDs. The model
achieved a top-5 accuracy of 74.8% on 10,000 generated P&IDs and 89.2% on
100,000 generated P&IDs. These promising results show great potential for
AI-assisted process engineering. The tests on a dataset of 312 real P&IDs
indicate the need of a larger P&IDs dataset for industry applications.",None,-1
85c37304-4c83-4264-a797-a136c478d046,Video Prediction by Efficient Transformers,0.830643,"Video prediction is a challenging computer vision task that has a wide range
of applications. In this work, we present a new family of Transformer-based
models for video prediction. Firstly, an efficient local spatial-temporal
separation attention mechanism is proposed to reduce the complexity of standard
Transformers. Then, a full autoregressive model, a partial autoregressive model
and a non-autoregressive model are developed based on the new efficient
Transformer. The partial autoregressive model has a similar performance with
the full autoregressive model but a faster inference speed. The
non-autoregressive model not only achieves a faster inference speed but also
mitigates the quality degradation problem of the autoregressive counterparts,
but it requires additional parameters and loss function for learning. Given the
same attention mechanism, we conducted a comprehensive study to compare the
proposed three video prediction variants. Experiments show that the proposed
video prediction models are competitive with more complex state-of-the-art
convolutional-LSTM based models. The source code is available at
https://github.com/XiYe20/VPTR.",https://github.com/XiYe20/VPTR,-1
28b18714-8539-44e1-bb17-c68de4a79b30,Leveraging Social Influence based on Users Activity Centers for Point-of-Interest Recommendation,0.914576,"Recommender Systems (RSs) aim to model and predict the user preference while
interacting with items, such as Points of Interest (POIs). These systems face
several challenges, such as data sparsity, limiting their effectiveness. In
this paper, we address this problem by incorporating social, geographical, and
temporal information into the Matrix Factorization (MF) technique. To this end,
we model social influence based on two factors: similarities between users in
terms of common check-ins and the friendships between them. We introduce two
levels of friendship based on explicit friendship networks and high check-in
overlap between users. We base our friendship algorithm on users' geographical
activity centers. The results show that our proposed model outperforms the
state-of-the-art on two real-world datasets. More specifically, our ablation
study shows that the social model improves the performance of our proposed POI
recommendation system by 31% and 14% on the Gowalla and Yelp datasets in terms
of Precision@10, respectively.",https://github.com/Seyedhosseinzadeh/SUCP,12
c17067e1-8d3d-4d75-911b-e37b9f0edb60,Splatting-based Synthesis for Video Frame Interpolation,0.620001,"Frame interpolation is an essential video processing technique that adjusts
the temporal resolution of an image sequence. While deep learning has brought
great improvements to the area of video frame interpolation, techniques that
make use of neural networks can typically not easily be deployed in practical
applications like a video editor since they are either computationally too
demanding or fail at high resolutions. In contrast, we propose a deep learning
approach that solely relies on splatting to synthesize interpolated frames.
This splatting-based synthesis for video frame interpolation is not only much
faster than similar approaches, especially for multi-frame interpolation, but
can also yield new state-of-the-art results at high resolutions.",None,-1
7eacbb29-4569-4397-a9da-60c939b16922,Error Correction in ASR using Sequence-to-Sequence Models,0.203869,"Post-editing in Automatic Speech Recognition (ASR) entails automatically
correcting common and systematic errors produced by the ASR system. The outputs
of an ASR system are largely prone to phonetic and spelling errors. In this
paper, we propose to use a powerful pre-trained sequence-to-sequence model,
BART, further adaptively trained to serve as a denoising model, to correct
errors of such types. The adaptive training is performed on an augmented
dataset obtained by synthetically inducing errors as well as by incorporating
actual errors from an existing ASR system. We also propose a simple approach to
rescore the outputs using word level alignments. Experimental results on
accented speech data demonstrate that our strategy effectively rectifies a
significant number of ASR errors and produces improved WER results when
compared against a competitive baseline. We also highlight a negative result
obtained on the related grammatical error correction task in Hindi language
showing the limitation in capturing wider context by our proposed model.",None,-1
7d9785bc-fb0c-45fa-b504-8dc529e36647,Multi-Agent Reinforcement Learning with Graph Convolutional Neural Networks for optimal Bidding Strategies of Generation Units in Electricity Markets,0.114822,"Finding optimal bidding strategies for generation units in electricity
markets would result in higher profit. However, it is a challenging problem due
to the system uncertainty which is due to the unknown other generation units'
strategies. Distributed optimization, where each entity or agent decides on its
bid individually, has become state of the art. However, it cannot overcome the
challenges of system uncertainties. Deep reinforcement learning is a promising
approach to learn the optimal strategy in uncertain environments. Nevertheless,
it is not able to integrate the information on the spatial system topology in
the learning process. This paper proposes a distributed learning algorithm
based on deep reinforcement learning (DRL) combined with a graph convolutional
neural network (GCN). In fact, the proposed framework helps the agents to
update their decisions by getting feedback from the environment so that it can
overcome the challenges of the uncertainties. In this proposed algorithm, the
state and connection between nodes are the inputs of the GCN, which can make
agents aware of the structure of the system. This information on the system
topology helps the agents to improve their bidding strategies and increase the
profit. We evaluate the proposed algorithm on the IEEE 30-bus system under
different scenarios. Also, to investigate the generalization ability of the
proposed approach, we test the trained model on IEEE 39-bus system. The results
show that the proposed algorithm has more generalization abilities compare to
the DRL and can result in higher profit when changing the topology of the
system.",None,-1
0e5e2322-4dd5-4447-b9d3-e805a3bba5f5,Adaptable Adapters,0.682991,"State-of-the-art pretrained NLP models contain a hundred million to trillion
parameters. Adapters provide a parameter-efficient alternative for the full
finetuning in which we can only finetune lightweight neural network layers on
top of pretrained weights. Adapter layers are initialized randomly. However,
existing work uses the same adapter architecture -- i.e., the same adapter
layer on top of each layer of the pretrained model -- for every dataset,
regardless of the properties of the dataset or the amount of available training
data. In this work, we introduce adaptable adapters that contain (1) learning
different activation functions for different layers and different input data,
and (2) a learnable switch to select and only use the beneficial adapter
layers. We show that adaptable adapters achieve on-par performances with the
standard adapter architecture while using a considerably smaller number of
adapter layers. In addition, we show that the selected adapter architecture by
adaptable adapters transfers well across different data settings and similar
tasks. We propose to use adaptable adapters for designing efficient and
effective adapter architectures. The resulting adapters (a) contain about 50%
of the learning parameters of the standard adapter and are therefore more
efficient at training and inference, and require less storage space, and (b)
achieve considerably higher performances in low-data settings.",https://github.com/UKPLab/adaptable-adapters,-1
3728d4dc-7de4-4856-80a9-fdf7fe404eb3,Towards 3D Object Detection with 2D Supervision,0.247241,"The great progress of 3D object detectors relies on large-scale data and 3D
annotations. The annotation cost for 3D bounding boxes is extremely expensive
while the 2D ones are easier and cheaper to collect. In this paper, we
introduce a hybrid training framework, enabling us to learn a visual 3D object
detector with massive 2D (pseudo) labels, even without 3D annotations. To break
through the information bottleneck of 2D clues, we explore a new perspective:
Temporal 2D Supervision. We propose a temporal 2D transformation to bridge the
3D predictions with temporal 2D labels. Two steps, including homography wraping
and 2D box deduction, are taken to transform the 3D predictions into 2D ones
for supervision. Experiments conducted on the nuScenes dataset show strong
results (nearly 90% of its fully-supervised performance) with only 25% 3D
annotations. We hope our findings can provide new insights for using a large
number of 2D annotations for 3D perception.",None,306651
14782a33-aa1b-4fa6-9c5b-8375f1cc9c9c,Learning Implicit Templates for Point-Based Clothed Human Modeling,0.986355,"We present FITE, a First-Implicit-Then-Explicit framework for modeling human
avatars in clothing. Our framework first learns implicit surface templates
representing the coarse clothing topology, and then employs the templates to
guide the generation of point sets which further capture pose-dependent
clothing deformations such as wrinkles. Our pipeline incorporates the merits of
both implicit and explicit representations, namely, the ability to handle
varying topology and the ability to efficiently capture fine details. We also
propose diffused skinning to facilitate template training especially for loose
clothing, and projection-based pose-encoding to extract pose information from
mesh templates without predefined UV map or connectivity. Our code is publicly
available at https://github.com/jsnln/fite.",https://github.com/jsnln/fite,-1
58584ef8-c796-4bb1-825e-9eb5ffeab3ce,Long-tailed Instance Segmentation using Gumbel Optimized Loss,0.720271,"Major advancements have been made in the field of object detection and
segmentation recently. However, when it comes to rare categories, the
state-of-the-art methods fail to detect them, resulting in a significant
performance gap between rare and frequent categories. In this paper, we
identify that Sigmoid or Softmax functions used in deep detectors are a major
reason for low performance and are sub-optimal for long-tailed detection and
segmentation. To address this, we develop a Gumbel Optimized Loss (GOL), for
long-tailed detection and segmentation. It aligns with the Gumbel distribution
of rare classes in imbalanced datasets, considering the fact that most classes
in long-tailed detection have low expected probability. The proposed GOL
significantly outperforms the best state-of-the-art method by 1.1% on AP , and
boosts the overall segmentation by 9.0% and detection by 8.0%, particularly
improving detection of rare classes by 20.3%, compared to Mask-RCNN, on LVIS
dataset. Code available at: https://github.com/kostas1515/GOL",https://github.com/kostas1515/GOL,-1
0debcd85-b90d-4bb7-93dd-033017b51929,Mining Error Templates for Grammatical Error Correction,0.222005,"Some grammatical error correction (GEC) systems incorporate hand-crafted
rules and achieve positive results. However, manually defining rules is
time-consuming and laborious. In view of this, we propose a method to mine
error templates for GEC automatically. An error template is a regular
expression aiming at identifying text errors. We use the web crawler to acquire
such error templates from the Internet. For each template, we further select
the corresponding corrective action by using the language model perplexity as a
criterion. We have accumulated 1,119 error templates for Chinese GEC based on
this method. Experimental results on the newly proposed CTC-2021 Chinese GEC
benchmark show that combing our error templates can effectively improve the
performance of a strong GEC system, especially on two error types with very
little training data. Our error templates are available at
\url{https://github.com/HillZhang1999/gec_error_template}.",https://github.com/HillZhang1999/gec_error_template,-1
309bb2ae-1f56-4514-8062-d6da9f44c0f4,DGraph: A Large-Scale Financial Dataset for Graph Anomaly Detection,0.814973,"Graph Anomaly Detection (GAD) has recently become a hot research spot due to
its practicability and theoretical value. Since GAD emphasizes the application
and the rarity of anomalous samples, enriching the varieties of its datasets is
fundamental work. Thus, this paper present DGraph, a real-world dynamic graph
in the finance domain. DGraph overcomes many limitations of current GAD
datasets. It contains about 3M nodes, 4M dynamic edges, and 1M ground-truth
nodes. We provide a comprehensive observation of DGraph, revealing that
anomalous nodes and normal nodes generally have different structures, neighbor
distribution, and temporal dynamics. Moreover, it suggests that unlabeled nodes
are also essential for detecting fraudsters. Furthermore, we conduct extensive
experiments on DGraph. Observation and experiments demonstrate that DGraph is
propulsive to advance GAD research and enable in-depth exploration of anomalous
nodes.",https://github.com/hxttkl/DGraph_Experiments,-1
7e7f6ca0-590a-49a7-89b0-4ac0f85799b1,"This is the way: designing and compiling LEPISZCZE, a comprehensive NLP benchmark for Polish",0.328077,"The availability of compute and data to train larger and larger language
models increases the demand for robust methods of benchmarking the true
progress of LM training. Recent years witnessed significant progress in
standardized benchmarking for English. Benchmarks such as GLUE, SuperGLUE, or
KILT have become de facto standard tools to compare large language models.
Following the trend to replicate GLUE for other languages, the KLEJ benchmark
has been released for Polish. In this paper, we evaluate the progress in
benchmarking for low-resourced languages. We note that only a handful of
languages have such comprehensive benchmarks. We also note the gap in the
number of tasks being evaluated by benchmarks for resource-rich English/Chinese
and the rest of the world. In this paper, we introduce LEPISZCZE (the Polish
word for glew, the Middle English predecessor of glue), a new, comprehensive
benchmark for Polish NLP with a large variety of tasks and high-quality
operationalization of the benchmark. We design LEPISZCZE with flexibility in
mind. Including new models, datasets, and tasks is as simple as possible while
still offering data versioning and model tracking. In the first run of the
benchmark, we test 13 experiments (task and dataset pairs) based on the five
most recent LMs for Polish. We use five datasets from the Polish benchmark and
add eight novel datasets. As the paper's main contribution, apart from
LEPISZCZE, we provide insights and experiences learned while creating the
benchmark for Polish as the blueprint to design similar benchmarks for other
low-resourced languages.",https://github.com/CLARIN-PL/LEPISZCZE,-1
2ce84109-36ac-4bee-b88e-bd89f3b5d3c0,Why we do need Explainable AI for Healthcare,0.501396,"The recent spike in certified Artificial Intelligence (AI) tools for
healthcare has renewed the debate around adoption of this technology. One
thread of such debate concerns Explainable AI and its promise to render AI
devices more transparent and trustworthy. A few voices active in the medical AI
space have expressed concerns on the reliability of Explainable AI techniques,
questioning their use and inclusion in guidelines and standards. Revisiting
such criticisms, this article offers a balanced and comprehensive perspective
on the utility of Explainable AI, focusing on the specificity of clinical
applications of AI and placing them in the context of healthcare interventions.
Against its detractors and despite valid concerns, we argue that the
Explainable AI research program is still central to human-machine interaction
and ultimately our main tool against loss of control, a danger that cannot be
prevented by rigorous clinical validation alone.",None,-1
10b7bd11-e93b-4ac9-bc99-838deb34a0c0,Generalizing to New Physical Systems via Context-Informed Dynamics Model,0.904573,"Data-driven approaches to modeling physical systems fail to generalize to
unseen systems that share the same general dynamics with the learning domain,
but correspond to different physical contexts. We propose a new framework for
this key problem, context-informed dynamics adaptation (CoDA), which takes into
account the distributional shift across systems for fast and efficient
adaptation to new dynamics. CoDA leverages multiple environments, each
associated to a different dynamic, and learns to condition the dynamics model
on contextual parameters, specific to each environment. The conditioning is
performed via a hypernetwork, learned jointly with a context vector from
observed data. The proposed formulation constrains the search hypothesis space
to foster fast adaptation and better generalization across environments. We
theoretically motivate our approach and show state-of-the-art generalization
results on a set of nonlinear dynamics, representative of a variety of
application domains. We also show, on these systems, that new system parameters
can be inferred from context vectors with minimal supervision. Code is
available at https://github.com/yuan-yin/CoDA .",None,-1
c1c8550d-f07f-4ea3-a942-5c8f305c53d1,Low-rank lottery tickets: finding efficient low-rank neural networks via matrix differential equations,0.674969,"Neural networks have achieved tremendous success in a large variety of
applications. However, their memory footprint and computational demand can
render them impractical in application settings with limited hardware or energy
resources. In this work, we propose a novel algorithm to find efficient
low-rank subnetworks. Remarkably, these subnetworks are determined and adapted
already during the training phase and the overall time and memory resources
required by both training and evaluating them are significantly reduced. The
main idea is to restrict the weight matrices to a low-rank manifold and to
update the low-rank factors rather than the full matrix during training. To
derive training updates that are restricted to the prescribed manifold, we
employ techniques from dynamic model order reduction for matrix differential
equations. This allows us to provide approximation, stability, and descent
guarantees. Moreover, our method automatically and dynamically adapts the ranks
during training to achieve the desired approximation accuracy. The efficiency
of the proposed method is demonstrated through a variety of numerical
experiments on fully-connected and convolutional networks.",https://github.com/COMPiLELab/DLRT,-1
3a047336-77bf-4627-9fcb-fdcca23f9e82,SummScore: A Comprehensive Evaluation Metric for Summary Quality Based on Cross-Encoder,0.171948,"Text summarization models are often trained to produce summaries that meet
human quality requirements. However, the existing evaluation metrics for
summary text are only rough proxies for summary quality, suffering from low
correlation with human scoring and inhibition of summary diversity. To solve
these problems, we propose SummScore, a comprehensive metric for summary
quality evaluation based on CrossEncoder. Firstly, by adopting the
original-summary measurement mode and comparing the semantics of the original
text, SummScore gets rid of the inhibition of summary diversity. With the help
of the text-matching pre-training Cross-Encoder, SummScore can effectively
capture the subtle differences between the semantics of summaries. Secondly, to
improve the comprehensiveness and interpretability, SummScore consists of four
fine-grained submodels, which measure Coherence, Consistency, Fluency, and
Relevance separately. We use semi-supervised multi-rounds of training to
improve the performance of our model on extremely limited annotated data.
Extensive experiments show that SummScore significantly outperforms existing
evaluation metrics in the above four dimensions in correlation with human
scoring. We also provide the quality evaluation results of SummScore on 16
mainstream summarization models for later research.",None,4451
849945f2-0906-49c3-9658-40d7c77e7431,"Breaking the ""Object"" in Video Object Segmentation",0.939254,"The appearance of an object can be fleeting when it transforms. As eggs are
broken or paper is torn, their color, shape and texture can change
dramatically, preserving virtually nothing of the original except for the
identity itself. Yet, this important phenomenon is largely absent from existing
video object segmentation (VOS) benchmarks. In this work, we close the gap by
collecting a new dataset for Video Object Segmentation under Transformations
(VOST). It consists of more than 700 high-resolution videos, captured in
diverse environments, which are 21 seconds long on average and densely labeled
with instance masks. A careful, multi-step approach is adopted to ensure that
these videos focus on complex object transformations, capturing their full
temporal extent. We then extensively evaluate state-of-the-art VOS methods and
make a number of important discoveries. In particular, we show that existing
methods struggle when applied to this novel task and that their main limitation
lies in over-reliance on static appearance cues. This motivates us to propose a
few modifications for the top-performing baseline that improve its capabilities
by better modeling spatio-temporal information. But more broadly, the hope is
to stimulate discussion on learning more robust video object representations.",None,-1
74ad4e43-2399-493e-af23-b7ad286a1fd4,Reinforcement Learning Your Way: Agent Characterization through Policy Regularization,0.23589,"The increased complexity of state-of-the-art reinforcement learning (RL)
algorithms have resulted in an opacity that inhibits explainability and
understanding. This has led to the development of several post-hoc
explainability methods that aim to extract information from learned policies
thus aiding explainability. These methods rely on empirical observations of the
policy and thus aim to generalize a characterization of agents' behaviour. In
this study, we have instead developed a method to imbue a characteristic
behaviour into agents' policies through regularization of their objective
functions. Our method guides the agents' behaviour during learning which
results in an intrinsic characterization; it connects the learning process with
model explanation. We provide a formal argument and empirical evidence for the
viability of our method. In future work, we intend to employ it to develop
agents that optimize individual financial customers' investment portfolios
based on their spending personalities.",None,-1
5d5028c5-782f-4711-ad3a-30ca645f4466,Ultra-high-resolution unpaired stain transformation via Kernelized Instance Normalization,0.150183,"While hematoxylin and eosin (H&E) is a standard staining procedure,
immunohistochemistry (IHC) staining further serves as a diagnostic and
prognostic method. However, acquiring special staining results requires
substantial costs.
  Hence, we proposed a strategy for ultra-high-resolution unpaired
image-to-image translation: Kernelized Instance Normalization (KIN), which
preserves local information and successfully achieves seamless stain
transformation with constant GPU memory usage. Given a patch, corresponding
position, and a kernel, KIN computes local statistics using convolution
operation. In addition, KIN can be easily plugged into most currently developed
frameworks without re-training.
  We demonstrate that KIN achieves state-of-the-art stain transformation by
replacing instance normalization (IN) layers with KIN layers in three popular
frameworks and testing on two histopathological datasets. Furthermore, we
manifest the generalizability of KIN with high-resolution natural images.
Finally, human evaluation and several objective metrics are used to compare the
performance of different approaches.
  Overall, this is the first successful study for the ultra-high-resolution
unpaired image-to-image translation with constant space complexity. Code is
available at: https://github.com/Kaminyou/URUST",https://github.com/Kaminyou/URUST,-1
ae0c3382-fe9b-4593-8a09-53cf9dcd6db5,DialAug: Mixing up Dialogue Contexts in Contrastive Learning for Robust Conversational Modeling,0.0732905,"Retrieval-based conversational systems learn to rank response candidates for
a given dialogue context by computing the similarity between their vector
representations. However, training on a single textual form of the multi-turn
context limits the ability of a model to learn representations that generalize
to natural perturbations seen during inference. In this paper we propose a
framework that incorporates augmented versions of a dialogue context into the
learning objective. We utilize contrastive learning as an auxiliary objective
to learn robust dialogue context representations that are invariant to
perturbations injected through the augmentation method. We experiment with four
benchmark dialogue datasets and demonstrate that our framework combines well
with existing augmentation methods and can significantly improve over baseline
BERT-based ranking architectures. Furthermore, we propose a novel data
augmentation method, ConMix, that adds token level perturbations through
stochastic mixing of tokens from other contexts in the batch. We show that our
proposed augmentation method outperforms previous data augmentation approaches,
and provides dialogue representations that are more robust to common
perturbations seen during inference.",https://github.com/rkadlec/ubuntu-ranking-dataset-,-1
408cd507-cc62-4fdb-9358-d50b02cf47da,Asynchronous Optimisation for Event-based Visual Odometry,0.794295,"Event cameras open up new possibilities for robotic perception due to their
low latency and high dynamic range. On the other hand, developing effective
event-based vision algorithms that fully exploit the beneficial properties of
event cameras remains work in progress. In this paper, we focus on event-based
visual odometry (VO). While existing event-driven VO pipelines have adopted
continuous-time representations to asynchronously process event data, they
either assume a known map, restrict the camera to planar trajectories, or
integrate other sensors into the system. Towards map-free event-only monocular
VO in SE(3), we propose an asynchronous structure-from-motion optimisation
back-end. Our formulation is underpinned by a principled joint optimisation
problem involving non-parametric Gaussian Process motion modelling and
incremental maximum a posteriori inference. A high-performance incremental
computation engine is employed to reason about the camera trajectory with every
incoming event. We demonstrate the robustness of our asynchronous back-end in
comparison to frame-based methods which depend on accurate temporal
accumulation of measurements.",None,-1
53427804-ea9a-4eee-a826-0fd24eecc97d,On the Use of BERT for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation,0.990629,"In recent years, pre-trained models have become dominant in most natural
language processing (NLP) tasks. However, in the area of Automated Essay
Scoring (AES), pre-trained models such as BERT have not been properly used to
outperform other deep learning models such as LSTM. In this paper, we introduce
a novel multi-scale essay representation for BERT that can be jointly learned.
We also employ multiple losses and transfer learning from out-of-domain essays
to further improve the performance. Experiment results show that our approach
derives much benefit from joint learning of multi-scale essay representation
and obtains almost the state-of-the-art result among all deep learning models
in the ASAP task. Our multi-scale essay representation also generalizes well to
CommonLit Readability Prize data set, which suggests that the novel text
representation proposed in this paper may be a new and effective choice for
long-text tasks.",https://github.com/lingochamp/Multi-Scale-BERT-AES,-1
95ab52f8-2163-426d-9e36-cdc910b68aac,Learning Physical Dynamics with Subequivariant Graph Neural Networks,0.575253,"Graph Neural Networks (GNNs) have become a prevailing tool for learning
physical dynamics. However, they still encounter several challenges: 1)
Physical laws abide by symmetry, which is a vital inductive bias accounting for
model generalization and should be incorporated into the model design. Existing
simulators either consider insufficient symmetry, or enforce excessive
equivariance in practice when symmetry is partially broken by gravity. 2)
Objects in the physical world possess diverse shapes, sizes, and properties,
which should be appropriately processed by the model. To tackle these
difficulties, we propose a novel backbone, Subequivariant Graph Neural Network,
which 1) relaxes equivariance to subequivariance by considering external fields
like gravity, where the universal approximation ability holds theoretically; 2)
introduces a new subequivariant object-aware message passing for learning
physical interactions between multiple objects of various shapes in the
particle-based representation; 3) operates in a hierarchical fashion, allowing
for modeling long-range and complex interactions. Our model achieves on average
over 3% enhancement in contact prediction accuracy across 8 scenarios on
Physion and 2X lower rollout MSE on RigidFall compared with state-of-the-art
GNN simulators, while exhibiting strong generalization and data efficiency.",https://hanjq17.github.io/SGNN/,-1
c6d04389-c8c5-4cfb-8cd5-72825cef2eea,Taxonomy Enrichment with Text and Graph Vector Representations,0.263362,"Knowledge graphs such as DBpedia, Freebase or Wikidata always contain a
taxonomic backbone that allows the arrangement and structuring of various
concepts in accordance with the hypo-hypernym (""class-subclass"") relationship.
With the rapid growth of lexical resources for specific domains, the problem of
automatic extension of the existing knowledge bases with new words is becoming
more and more widespread. In this paper, we address the problem of taxonomy
enrichment which aims at adding new words to the existing taxonomy.
  We present a new method that allows achieving high results on this task with
little effort. It uses the resources which exist for the majority of languages,
making the method universal. We extend our method by incorporating deep
representations of graph structures like node2vec, Poincar\'e embeddings, GCN
etc. that have recently demonstrated promising results on various NLP tasks.
Furthermore, combining these representations with word embeddings allows us to
beat the state of the art.
  We conduct a comprehensive study of the existing approaches to taxonomy
enrichment based on word and graph vector representations and their fusion
approaches. We also explore the ways of using deep learning architectures to
extend the taxonomic backbones of knowledge graphs. We create a number of
datasets for taxonomy extension for English and Russian. We achieve
state-of-the-art results across different datasets and provide an in-depth
error analysis of mistakes.",None,-1
9e76accc-d852-41d5-97a3-50199e15e4d5,Don't Copy the Teacher: Data and Model Challenges in Embodied Dialogue,0.169317,"Embodied dialogue instruction following requires an agent to complete a
complex sequence of tasks from a natural language exchange. The recent
introduction of benchmarks (Padmakumar et al., 2022) raises the question of how
best to train and evaluate models for this multi-turn, multi-agent,
long-horizon task. This paper contributes to that conversation, by arguing that
imitation learning (IL) and related low-level metrics are actually misleading
and do not align with the goals of embodied dialogue research and may hinder
progress. We provide empirical comparisons of metrics, analysis of three
models, and make suggestions for how the field might best progress. First, we
observe that models trained with IL take spurious actions during evaluation.
Second, we find that existing models fail to ground query utterances, which are
essential for task completion. Third, we argue evaluation should focus on
higher-level semantic goals.",https://github.com/soyeonm/TEACh_FILM,-1
9e13edfb-390c-41a8-99d4-690be4d226c4,"LightEA: A Scalable, Robust, and Interpretable Entity Alignment Framework via Three-view Label Propagation",0.325216,"Entity Alignment (EA) aims to find equivalent entity pairs between KGs, which
is the core step of bridging and integrating multi-source KGs. In this paper,
we argue that existing GNN-based EA methods inherit the inborn defects from
their neural network lineage: weak scalability and poor interpretability.
Inspired by recent studies, we reinvent the Label Propagation algorithm to
effectively run on KGs and propose a non-neural EA framework -- LightEA,
consisting of three efficient components: (i) Random Orthogonal Label
Generation, (ii) Three-view Label Propagation, and (iii) Sparse Sinkhorn
Iteration. According to the extensive experiments on public datasets, LightEA
has impressive scalability, robustness, and interpretability. With a mere tenth
of time consumption, LightEA achieves comparable results to state-of-the-art
methods across all datasets and even surpasses them on many.",https://github.com/MaoXinn/LightEA,-1
31a7ea13-e4df-4de9-b407-547d88066586,Attention Option-Critic,0.448617,"Temporal abstraction in reinforcement learning is the ability of an agent to
learn and use high-level behaviors, called options. The option-critic
architecture provides a gradient-based end-to-end learning method to construct
options. We propose an attention-based extension to this framework, which
enables the agent to learn to focus different options on different aspects of
the observation space. We show that this leads to behaviorally diverse options
which are also capable of state abstraction, and prevents the degeneracy
problems of option domination and frequent option switching that occur in
option-critic, while achieving a similar sample complexity. We also demonstrate
the more efficient, interpretable, and reusable nature of the learned options
in comparison with option-critic, through different transfer learning tasks.
Experimental results in a relatively simple four-rooms environment and the more
complex ALE (Arcade Learning Environment) showcase the efficacy of our
approach.",None,33465
64646df3-d228-4919-b8bb-9ba9800112f6,Rank-N-Contrast: Learning Continuous Representations for Regression,0.708021,"Deep regression models typically learn in an end-to-end fashion without
explicitly emphasizing a regression-aware representation. Consequently, the
learned representations exhibit fragmentation and fail to capture the
continuous nature of sample orders, inducing suboptimal results across a wide
range of regression tasks. To fill the gap, we propose Rank-N-Contrast (RNC), a
framework that learns continuous representations for regression by contrasting
samples against each other based on their rankings in the target space. We
demonstrate, theoretically and empirically, that RNC guarantees the desired
order of learned representations in accordance with the target orders, enjoying
not only better performance but also significantly improved robustness,
efficiency, and generalization. Extensive experiments using five real-world
regression datasets that span computer vision, human-computer interaction, and
healthcare verify that RNC achieves state-of-the-art performance, highlighting
its intriguing properties including better data efficiency, robustness to
spurious targets and data corruptions, and generalization to distribution
shifts. Code is available at: https://github.com/kaiwenzha/Rank-N-Contrast.",https://github.com/kaiwenzha/Rank-N-Contrast,-1
603efffb-2e0f-4961-99e6-3d75e1325362,PointSCNet: Point Cloud Structure and Correlation Learning Based on Space Filling Curve-Guided Sampling,0.422746,"Geometrical structures and the internal local region relationship, such as
symmetry, regular array, junction, etc., are essential for understanding a 3D
shape. This paper proposes a point cloud feature extraction network named
PointSCNet, to capture the geometrical structure information and local region
correlation information of a point cloud. The PointSCNet consists of three main
modules: the space-filling curve-guided sampling module, the information fusion
module, and the channel-spatial attention module. The space-filling
curve-guided sampling module uses Z-order curve coding to sample points that
contain geometrical correlation. The information fusion module uses a
correlation tensor and a set of skip connections to fuse the structure and
correlation information. The channel-spatial attention module enhances the
representation of key points and crucial feature channels to refine the
network. The proposed PointSCNet is evaluated on shape classification and part
segmentation tasks. The experimental results demonstrate that the PointSCNet
outperforms or is on par with state-of-the-art methods by learning the
structure and correlation of point clouds effectively.",https://github.com/Chenguoz/PointSCNet,-1
01da5db6-29c3-4516-9e4d-fd211635708c,Data-driven prediction of Air Traffic Controllers reactions to resolving conflicts,0.692534,"With the aim to enhance automation in conflict detection and resolution
(CD&R) tasks in the Air Traffic Management domain, in this paper we propose
deep learning techniques (DL) that can learn models of Air Traffic Controllers'
(ATCO) reactions in resolving conflicts that can violate separation minimum
constraints among aircraft trajectories: This implies learning when the ATCO
will react towards resolving a conflict, and how he/she will react. Timely
reactions, to which this paper aims, focus on when do reactions happen, aiming
to predict the trajectory points, as the trajectory evolves, that the ATCO
issues a conflict resolution action, while also predicting the type of
resolution action (if any). Towards this goal, the paper formulates the ATCO
reactions prediction problem for CD&R, and presents DL methods that can model
ATCO timely reactions and evaluates these methods in real-world data sets,
showing their efficacy in prediction with very high accuracy.",None,4539
c06b4141-066b-4ce4-bfb5-5338157e2423,Speeding Up Question Answering Task of Language Models via Inverted Index,0.0382962,"Natural language processing applications, such as conversational agents and
their question-answering capabilities, are widely used in the real world.
Despite the wide popularity of large language models (LLMs), few real-world
conversational agents take advantage of LLMs. Extensive resources consumed by
LLMs disable developers from integrating them into end-user applications. In
this study, we leverage an inverted indexing mechanism combined with LLMs to
improve the efficiency of question-answering models for closed-domain
questions. Our experiments show that using the index improves the average
response time by 97.44%. In addition, due to the reduced search scope, the
average BLEU score improved by 0.23 while using the inverted index.",None,-1
196d14bb-5d41-4cea-8c0f-275431c83cba,QuadTree Attention for Vision Transformers,0.766959,"Transformers have been successful in many vision tasks, thanks to their
capability of capturing long-range dependency. However, their quadratic
computational complexity poses a major obstacle for applying them to vision
tasks requiring dense predictions, such as object detection, feature matching,
stereo, etc. We introduce QuadTree Attention, which reduces the computational
complexity from quadratic to linear. Our quadtree transformer builds token
pyramids and computes attention in a coarse-to-fine manner. At each level, the
top K patches with the highest attention scores are selected, such that at the
next level, attention is only evaluated within the relevant regions
corresponding to these top K patches. We demonstrate that quadtree attention
achieves state-of-the-art performance in various vision tasks, e.g. with 4.0%
improvement in feature matching on ScanNet, about 50% flops reduction in stereo
matching, 0.4-1.5% improvement in top-1 accuracy on ImageNet classification,
1.2-1.8% improvement on COCO object detection, and 0.7-2.4% improvement on
semantic segmentation over previous state-of-the-art transformers. The codes
are available at https://github.com/Tangshitao/QuadtreeAttention.",https://github.com/Tangshitao/QuadtreeAttention,-1
86a86ddc-3aeb-4772-87db-8495d53efc3a,Strong-TransCenter: Improved Multi-Object Tracking based on Transformers with Dense Representations,0.261722,"Transformer networks have been a focus of research in many fields in recent
years, being able to surpass the state-of-the-art performance in different
computer vision tasks. A few attempts have been made to apply this method to
the task of Multiple Object Tracking (MOT), among those the state-of-the-art
was TransCenter, a transformer-based MOT architecture with dense object queries
for accurately tracking all the objects while keeping reasonable runtime.
TransCenter is the first center-based transformer framework for MOT, and is
also among the first to show the benefits of using transformer-based
architectures for MOT. In this paper we show an improvement to this tracker
using post processing mechanism based in the Track-by-Detection paradigm:
motion model estimation using Kalman filter and target Re-identification using
an embedding network. Our new tracker shows significant improvements in the
IDF1 and HOTA metrics and comparable results on the MOTA metric (70.9%, 59.8%
and 75.8% respectively) on the MOTChallenge MOT17 test dataset and improvement
on all 3 metrics (67.5%, 56.3% and 73.0%) on the MOT20 test dataset. Our
tracker is currently ranked first among transformer-based trackers in these
datasets. The code is publicly available at:
https://github.com/amitgalor18/STC_Tracker",https://github.com/amitgalor18/STC_Tracker,-1
6b577ddf-048c-47e6-970d-edc291ea4956,Fault Diagnosis using eXplainable AI: a Transfer Learning-based Approach for Rotating Machinery exploiting Augmented Synthetic Data,0.557199,"Artificial Intelligence (AI) is one of the approaches that has been proposed
to analyze the collected data (e.g., vibration signals) providing a diagnosis
of the asset's operating condition. It is known that models trained with
labeled data (supervised) achieve excellent results, but two main problems make
their application in production processes difficult: (i) impossibility or long
time to obtain a sample of all operational conditions (since faults seldom
happen) and (ii) high cost of experts to label all acquired data. Another
limitating factor for the applicability of AI approaches in this context is the
lack of interpretability of the models (black-boxes), which reduces the
confidence of the diagnosis and trust/adoption from users. To overcome these
problems, a new generic and interpretable approach for classifying faults in
rotating machinery based on transfer learning from augmented synthetic data to
real rotating machinery is here proposed, namelly FaultD-XAI (Fault Diagnosis
using eXplainable AI). To provide scalability using transfer learning,
synthetic vibration signals are created mimicking the characteristic behavior
of failures in operation. The application of Gradient-weighted Class Activation
Mapping (Grad-CAM) with 1D Convolutional Neural Network (1D CNN) allows the
interpretation of results, supporting the user in decision making and
increasing diagnostic confidence. The proposed approach not only obtained
promising diagnostic performance, but was also able to learn characteristics
used by experts to identify conditions in a source domain and apply them in
another target domain. The experimental results suggest a promising approach on
exploiting transfer learning, synthetic data and explainable artificial
intelligence for fault diagnosis. Lastly, to guarantee reproducibility and
foster research in the field, the developed dataset is made publicly available.",None,-1
260f86a3-70c2-44a7-afde-66442b936c9e,Detecting Shortcuts in Medical Images -- A Case Study in Chest X-rays,0.11616,"The availability of large public datasets and the increased amount of
computing power have shifted the interest of the medical community to
high-performance algorithms. However, little attention is paid to the quality
of the data and their annotations. High performance on benchmark datasets may
be reported without considering possible shortcuts or artifacts in the data,
besides, models are not tested on subpopulation groups. With this work, we aim
to raise awareness about shortcuts problems. We validate previous findings, and
present a case study on chest X-rays using two publicly available datasets. We
share annotations for a subset of pneumothorax images with drains. We conclude
with general recommendations for medical image classification.",https://github.com/ameliajimenez/shortcuts-chest-xray,3542
58bdb750-54e5-473e-9f0d-2fa19abc0612,"Dynamic Sparse Network for Time Series Classification: Learning What to ""see''",0.872512,"The receptive field (RF), which determines the region of time series to be
``seen'' and used, is critical to improve the performance for time series
classification (TSC). However, the variation of signal scales across and within
time series data, makes it challenging to decide on proper RF sizes for TSC. In
this paper, we propose a dynamic sparse network (DSN) with sparse connections
for TSC, which can learn to cover various RF without cumbersome
hyper-parameters tuning. The kernels in each sparse layer are sparse and can be
explored under the constraint regions by dynamic sparse training, which makes
it possible to reduce the resource cost. The experimental results show that the
proposed DSN model can achieve state-of-art performance on both univariate and
multivariate TSC datasets with less than 50\% computational cost compared with
recent baseline methods, opening the path towards more accurate resource-aware
methods for time series analyses. Our code is publicly available at:
https://github.com/QiaoXiao7282/DSN.",https://github.com/QiaoXiao7282/DSN,-1
4c561c1e-0c94-42ec-84e5-cc5f27e4f03f,Comparative layer-wise analysis of self-supervised speech models,0.837552,"Many self-supervised speech models, varying in their pre-training objective,
input modality, and pre-training data, have been proposed in the last few
years. Despite impressive successes on downstream tasks, we still have a
limited understanding of the properties encoded by the models and the
differences across models. In this work, we examine the intermediate
representations for a variety of recent models. Specifically, we measure
acoustic, phonetic, and word-level properties encoded in individual layers,
using a lightweight analysis tool based on canonical correlation analysis
(CCA). We find that these properties evolve across layers differently depending
on the model, and the variations relate to the choice of pre-training
objective. We further investigate the utility of our analyses for downstream
tasks by comparing the property trends with performance on speech recognition
and spoken language understanding tasks. We discover that CCA trends provide
reliable guidance to choose layers of interest for downstream tasks and that
single-layer performance often matches or improves upon using all layers,
suggesting implications for more efficient use of pre-trained models.",https://github.com/ankitapasad/layerwise-analysis/,-1
a4de5503-c210-4f2f-a8f3-d8d3b2635d9b,An Explainable Regression Framework for Predicting Remaining Useful Life of Machines,0.351911,"Prediction of a machine's Remaining Useful Life (RUL) is one of the key tasks
in predictive maintenance. The task is treated as a regression problem where
Machine Learning (ML) algorithms are used to predict the RUL of machine
components. These ML algorithms are generally used as a black box with a total
focus on the performance without identifying the potential causes behind the
algorithms' decisions and their working mechanism. We believe, the performance
(in terms of Mean Squared Error (MSE), etc.,) alone is not enough to build the
trust of the stakeholders in ML prediction rather more insights on the causes
behind the predictions are needed. To this aim, in this paper, we explore the
potential of Explainable AI (XAI) techniques by proposing an explainable
regression framework for the prediction of machines' RUL. We also evaluate
several ML algorithms including classical and Neural Networks (NNs) based
solutions for the task. For the explanations, we rely on two model agnostic XAI
methods namely Local Interpretable Model-Agnostic Explanations (LIME) and
Shapley Additive Explanations (SHAP). We believe, this work will provide a
baseline for future research in the domain.",None,-1
bcbd311b-30dd-4fbe-b14c-c4ba655aaeee,RuCoLA: Russian Corpus of Linguistic Acceptability,0.738787,"Linguistic acceptability (LA) attracts the attention of the research
community due to its many uses, such as testing the grammatical knowledge of
language models and filtering implausible texts with acceptability classifiers.
However, the application scope of LA in languages other than English is limited
due to the lack of high-quality resources. To this end, we introduce the
Russian Corpus of Linguistic Acceptability (RuCoLA), built from the ground up
under the well-established binary LA approach. RuCoLA consists of $9.8$k
in-domain sentences from linguistic publications and $3.6$k out-of-domain
sentences produced by generative models. The out-of-domain set is created to
facilitate the practical use of acceptability for improving language
generation. Our paper describes the data collection protocol and presents a
fine-grained analysis of acceptability classification experiments with a range
of baseline approaches. In particular, we demonstrate that the most widely used
language models still fall behind humans by a large margin, especially when
detecting morphological and semantic errors. We release RuCoLA, the code of
experiments, and a public leaderboard (rucola-benchmark.com) to assess the
linguistic competence of language models for Russian.",https://github.com/RussianNLP/RuCoLA,-1
ccca76bc-5531-4d33-a69d-ca94ca64f833,Transformation-Equivariant 3D Object Detection for Autonomous Driving,0.880815,"3D object detection received increasing attention in autonomous driving
recently. Objects in 3D scenes are distributed with diverse orientations.
Ordinary detectors do not explicitly model the variations of rotation and
reflection transformations. Consequently, large networks and extensive data
augmentation are required for robust detection. Recent equivariant networks
explicitly model the transformation variations by applying shared networks on
multiple transformed point clouds, showing great potential in object geometry
modeling. However, it is difficult to apply such networks to 3D object
detection in autonomous driving due to its large computation cost and slow
reasoning speed. In this work, we present TED, an efficient
Transformation-Equivariant 3D Detector to overcome the computation cost and
speed issues. TED first applies a sparse convolution backbone to extract
multi-channel transformation-equivariant voxel features; and then aligns and
aggregates these equivariant features into lightweight and compact
representations for high-performance 3D object detection. On the highly
competitive KITTI 3D car detection leaderboard, TED ranked 1st among all
submissions with competitive efficiency.",None,-1
7b047a22-d26d-4c2b-aef9-5b77ccaf3d67,Ray Priors through Reprojection: Improving Neural Radiance Fields for Novel View Extrapolation,0.55764,"Neural Radiance Fields (NeRF) have emerged as a potent paradigm for
representing scenes and synthesizing photo-realistic images. A main limitation
of conventional NeRFs is that they often fail to produce high-quality
renderings under novel viewpoints that are significantly different from the
training viewpoints. In this paper, instead of exploiting few-shot image
synthesis, we study the novel view extrapolation setting that (1) the training
images can well describe an object, and (2) there is a notable discrepancy
between the training and test viewpoints' distributions. We present RapNeRF
(RAy Priors) as a solution. Our insight is that the inherent appearances of a
3D surface's arbitrary visible projections should be consistent. We thus
propose a random ray casting policy that allows training unseen views using
seen views. Furthermore, we show that a ray atlas pre-computed from the
observed rays' viewing directions could further enhance the rendering quality
for extrapolated views. A main limitation is that RapNeRF would remove the
strong view-dependent effects because it leverages the multi-view consistency
property.",None,-1
7c887590-a9ce-4f4d-8259-6916fc7dbdd0,GeONet: a neural operator for learning the Wasserstein geodesic,0.261085,"Optimal transport (OT) offers a versatile framework to compare complex data
distributions in a geometrically meaningful way. Traditional methods for
computing the Wasserstein distance and geodesic between probability measures
require mesh-dependent domain discretization and suffer from the
curse-of-dimensionality. We present GeONet, a mesh-invariant deep neural
operator network that learns the non-linear mapping from the input pair of
initial and terminal distributions to the Wasserstein geodesic connecting the
two endpoint distributions. In the offline training stage, GeONet learns the
saddle point optimality conditions for the dynamic formulation of the OT
problem in the primal and dual spaces that are characterized by a coupled PDE
system. The subsequent inference stage is instantaneous and can be deployed for
real-time predictions in the online learning setting. We demonstrate that
GeONet achieves comparable testing accuracy to the standard OT solvers on
simulation examples and the MNIST dataset with considerably reduced
inference-stage computational cost by orders of magnitude.",None,-1
521a6d5d-2d64-4bd2-a920-ff5f71b20427,Improved Consistency Training for Semi-Supervised Sequence-to-Sequence ASR via Speech Chain Reconstruction and Self-Transcribing,0.0787474,"Consistency regularization has recently been applied to semi-supervised
sequence-to-sequence (S2S) automatic speech recognition (ASR). This principle
encourages an ASR model to output similar predictions for the same input speech
with different perturbations. The existing paradigm of semi-supervised S2S ASR
utilizes SpecAugment as data augmentation and requires a static teacher model
to produce pseudo transcripts for untranscribed speech. However, this paradigm
fails to take full advantage of consistency regularization. First, the masking
operations of SpecAugment may damage the linguistic contents of the speech,
thus influencing the quality of pseudo labels. Second, S2S ASR requires both
input speech and prefix tokens to make the next prediction. The static prefix
tokens made by the offline teacher model cannot match dynamic pseudo labels
during consistency training. In this work, we propose an improved consistency
training paradigm of semi-supervised S2S ASR. We utilize speech chain
reconstruction as the weak augmentation to generate high-quality pseudo labels.
Moreover, we demonstrate that dynamic pseudo transcripts produced by the
student ASR model benefit the consistency training. Experiments on LJSpeech and
LibriSpeech corpora show that compared to supervised baselines, our improved
paradigm achieves a 12.2% CER improvement in the single-speaker setting and
38.6% in the multi-speaker setting.",None,-1
6c70ace1-e32a-4d93-af34-4f21884bd73a,VS-CAM: Vertex Semantic Class Activation Mapping to Interpret Vision Graph Neural Network,0.15256,"Graph convolutional neural network (GCN) has drawn increasing attention and
attained good performance in various computer vision tasks, however, there
lacks a clear interpretation of GCN's inner mechanism. For standard
convolutional neural networks (CNNs), class activation mapping (CAM) methods
are commonly used to visualize the connection between CNN's decision and image
region by generating a heatmap. Nonetheless, such heatmap usually exhibits
semantic-chaos when these CAMs are applied to GCN directly. In this paper, we
proposed a novel visualization method particularly applicable to GCN, Vertex
Semantic Class Activation Mapping (VS-CAM). VS-CAM includes two independent
pipelines to produce a set of semantic-probe maps and a semantic-base map,
respectively. Semantic-probe maps are used to detect the semantic information
from semantic-base map to aggregate a semantic-aware heatmap. Qualitative
results show that VS-CAM can obtain heatmaps where the highlighted regions
match the objects much more precisely than CNN-based CAM. The quantitative
evaluation further demonstrates the superiority of VS-CAM.",None,-1
a5a5c8cb-c8e4-4d2a-a92d-a6ff30a82900,Personalizing Sustainable Agriculture with Causal Machine Learning,0.572473,"To fight climate change and accommodate the increasing population, global
crop production has to be strengthened. To achieve the ""sustainable
intensification"" of agriculture, transforming it from carbon emitter to carbon
sink is a priority, and understanding the environmental impact of agricultural
management practices is a fundamental prerequisite to that. At the same time,
the global agricultural landscape is deeply heterogeneous, with differences in
climate, soil, and land use inducing variations in how agricultural systems
respond to farmer actions. The ""personalization"" of sustainable agriculture
with the provision of locally adapted management advice is thus a necessary
condition for the efficient uplift of green metrics, and an integral
development in imminent policies. Here, we formulate personalized sustainable
agriculture as a Conditional Average Treatment Effect estimation task and use
Causal Machine Learning for tackling it. Leveraging climate data, land use
information and employing Double Machine Learning, we estimate the
heterogeneous effect of sustainable practices on the field-level Soil Organic
Carbon content in Lithuania. We thus provide a data-driven perspective for
targeting sustainable practices and effectively expanding the global carbon
sink.",None,-1
ba1468fc-ed8c-42c3-9604-b4543eaa29c7,Domain Adaptation for Time-Series Classification to Mitigate Covariate Shift,0.592017,"The performance of a machine learning model degrades when it is applied to
data from a similar but different domain than the data it has initially been
trained on. To mitigate this domain shift problem, domain adaptation (DA)
techniques search for an optimal transformation that converts the (current)
input data from a source domain to a target domain to learn a domain-invariant
representation that reduces domain discrepancy. This paper proposes a novel
supervised DA based on two steps. First, we search for an optimal
class-dependent transformation from the source to the target domain from a few
samples. We consider optimal transport methods such as the earth mover's
distance, Sinkhorn transport and correlation alignment. Second, we use
embedding similarity techniques to select the corresponding transformation at
inference. We use correlation metrics and higher-order moment matching
techniques. We conduct an extensive evaluation on time-series datasets with
domain shift including simulated and various online handwriting datasets to
demonstrate the performance.",None,-1
b180d468-796a-4173-90fd-7bbc87476624,Unbiased Knowledge Distillation for Recommendation,0.478845,"As a promising solution for model compression, knowledge distillation (KD)
has been applied in recommender systems (RS) to reduce inference latency.
Traditional solutions first train a full teacher model from the training data,
and then transfer its knowledge (\ie \textit{soft labels}) to supervise the
learning of a compact student model. However, we find such a standard
distillation paradigm would incur serious bias issue -- popular items are more
heavily recommended after the distillation. This effect prevents the student
model from making accurate and fair recommendations, decreasing the
effectiveness of RS.
  In this work, we identify the origin of the bias in KD -- it roots in the
biased soft labels from the teacher, and is further propagated and intensified
during the distillation. To rectify this, we propose a new KD method with a
stratified distillation strategy. It first partitions items into multiple
groups according to their popularity, and then extracts the ranking knowledge
within each group to supervise the learning of the student. Our method is
simple and teacher-agnostic -- it works on distillation stage without affecting
the training of the teacher model. We conduct extensive theoretical and
empirical studies to validate the effectiveness of our proposal. We release our
code at: https://github.com/chengang95/UnKD.",None,-1
1ecef006-33cf-405a-8a22-4926adf785ab,Empirical Bayes approach to Truth Discovery problems,0.0399116,"When aggregating information from conflicting sources, one's goal is to find
the truth. Most real-value \emph{truth discovery} (TD) algorithms try to
achieve this goal by estimating the competence of each source and then
aggregating the conflicting information by weighing each source's answer
proportionally to her competence. However, each of those algorithms requires
more than a single source for such estimation and usually does not consider
different estimation methods other than a weighted mean. Therefore, in this
work we formulate, prove, and empirically test the conditions for an Empirical
Bayes Estimator (EBE) to dominate the weighted mean aggregation. Our main
result demonstrates that EBE, under mild conditions, can be used as a second
step of any TD algorithm in order to reduce the expected error.",None,1961
744f3038-35a8-4d4b-9ea9-3385c1786776,Metaphorical User Simulators for Evaluating Task-oriented Dialogue Systems,0.618841,"Task-oriented dialogue systems (TDSs) are assessed mainly in an offline
setting or through human evaluation. The evaluation is often limited to
single-turn or is very time-intensive. As an alternative, user simulators that
mimic user behavior allow us to consider a broad set of user goals to generate
human-like conversations for simulated evaluation. Employing existing user
simulators to evaluate TDSs is challenging as user simulators are primarily
designed to optimize dialogue policies for TDSs and have limited evaluation
capabilities. Moreover, the evaluation of user simulators is an open challenge.
  In this work, we propose a metaphorical user simulator for end-to-end TDS
evaluation, where we define a simulator to be metaphorical if it simulates
user's analogical thinking in interactions with systems. We also propose a
tester-based evaluation framework to generate variants, i.e., dialogue systems
with different capabilities. Our user simulator constructs a metaphorical user
model that assists the simulator in reasoning by referring to prior knowledge
when encountering new items. We estimate the quality of simulators by checking
the simulated interactions between simulators and variants. Our experiments are
conducted using three TDS datasets. The proposed user simulator demonstrates
better consistency with manual evaluation than an agenda-based simulator and a
seq2seq model on three datasets; our tester framework demonstrates efficiency
and has been tested on multiple tasks, such as conversational recommendation
and e-commerce dialogues.",https://github.com/Superbooming/simtester,-1
6e878338-4fde-4e70-8e39-b7470e477aa1,Controllable Fake Document Infilling for Cyber Deception,0.532892,"Recent works in cyber deception study how to deter malicious intrusion by
generating multiple fake versions of a critical document to impose costs on
adversaries who need to identify the correct information. However, existing
approaches are context-agnostic, resulting in sub-optimal and unvaried outputs.
We propose a novel context-aware model, Fake Document Infilling (FDI), by
converting the problem to a controllable mask-then-infill procedure. FDI masks
important concepts of varied lengths in the document, then infills a realistic
but fake alternative considering both the previous and future contexts. We
conduct comprehensive evaluations on technical documents and news stories.
Results show that FDI outperforms the baselines in generating highly believable
fakes with moderate modification to protect critical information and deceive
adversaries.",https://github.com/snowood1/FDI,-1
4c1c2465-eedb-44a0-b437-0f5490b6735b,Transfer Learning with Synthetic Corpora for Spatial Role Labeling and Reasoning,0.720484,"Recent research shows synthetic data as a source of supervision helps
pretrained language models (PLM) transfer learning to new target tasks/domains.
However, this idea is less explored for spatial language. We provide two new
data resources on multiple spatial language processing tasks. The first dataset
is synthesized for transfer learning on spatial question answering (SQA) and
spatial role labeling (SpRL). Compared to previous SQA datasets, we include a
larger variety of spatial relation types and spatial expressions. Our data
generation process is easily extendable with new spatial expression lexicons.
The second one is a real-world SQA dataset with human-generated questions built
on an existing corpus with SPRL annotations. This dataset can be used to
evaluate spatial language processing models in realistic situations. We show
pretraining with automatically generated data significantly improves the SOTA
results on several SQA and SPRL benchmarks, particularly when the training data
in the target domain is small.",https://github.com/HLR/SpaRTUN,-1
a8d92015-20df-4951-ac9b-0331e6a66e40,SPECTRE: Spectral Conditioning Helps to Overcome the Expressivity Limits of One-shot Graph Generators,0.601672,"We approach the graph generation problem from a spectral perspective by first
generating the dominant parts of the graph Laplacian spectrum and then building
a graph matching these eigenvalues and eigenvectors. Spectral conditioning
allows for direct modeling of the global and local graph structure and helps to
overcome the expressivity and mode collapse issues of one-shot graph
generators. Our novel GAN, called SPECTRE, enables the one-shot generation of
much larger graphs than previously possible with one-shot models. SPECTRE
outperforms state-of-the-art deep autoregressive generators in terms of
modeling fidelity, while also avoiding expensive sequential generation and
dependence on node ordering. A case in point, in sizable synthetic and
real-world graphs SPECTRE achieves a 4-to-170 fold improvement over the best
competitor that does not overfit and is 23-to-30 times faster than
autoregressive generators.",https://github.com/KarolisMart/SPECTRE,-1
82cb002c-1471-4fca-b890-0b47cd221ef7,USTC-NELSLIP at SemEval-2022 Task 11: Gazetteer-Adapted Integration Network for Multilingual Complex Named Entity Recognition,0.862492,"This paper describes the system developed by the USTC-NELSLIP team for
SemEval-2022 Task 11 Multilingual Complex Named Entity Recognition
(MultiCoNER). We propose a gazetteer-adapted integration network (GAIN) to
improve the performance of language models for recognizing complex named
entities. The method first adapts the representations of gazetteer networks to
those of language models by minimizing the KL divergence between them. After
adaptation, these two networks are then integrated for backend supervised named
entity recognition (NER) training. The proposed method is applied to several
state-of-the-art Transformer-based NER models with a gazetteer built from
Wikidata, and shows great generalization ability across them. The final
predictions are derived from an ensemble of these trained models. Experimental
results and detailed analysis verify the effectiveness of the proposed method.
The official results show that our system ranked 1st on three tracks (Chinese,
Code-mixed and Bangla) and 2nd on the other ten tracks in this task.",https://github.com/Mckysse/GAIN,-1
24bc7093-2338-49a6-a5ec-6b0dd84c0958,First-Order Context-Specific Likelihood Weighting in Hybrid Probabilistic Logic Programs,0.148481,"Statistical relational AI and probabilistic logic programming have so far
mostly focused on discrete probabilistic models. The reasons for this is that
one needs to provide constructs to succinctly model the independencies in such
models, and also provide efficient inference.
  Three types of independencies are important to represent and exploit for
scalable inference in hybrid models: conditional independencies elegantly
modeled in Bayesian networks, context-specific independencies naturally
represented by logical rules, and independencies amongst attributes of related
objects in relational models succinctly expressed by combining rules.
  This paper introduces a hybrid probabilistic logic programming language, DC#,
which integrates distributional clauses' syntax and semantics principles of
Bayesian logic programs. It represents the three types of independencies
qualitatively. More importantly, we also introduce the scalable inference
algorithm FO-CS-LW for DC#. FO-CS-LW is a first-order extension of the
context-specific likelihood weighting algorithm (CS-LW), a novel sampling
method that exploits conditional independencies and context-specific
independencies in ground models. The FO-CS-LW algorithm upgrades CS-LW with
unification and combining rules to the first-order case.",https://github.com/niteshroyal/DC-Sharp,-1
9f20a40d-82b7-47c0-ad2f-3a8887ea8863,Target-Guided Open-Domain Conversation Planning,0.204206,"Prior studies addressing target-oriented conversational tasks lack a crucial
notion that has been intensively studied in the context of goal-oriented
artificial intelligence agents, namely, planning. In this study, we propose the
task of Target-Guided Open-Domain Conversation Planning (TGCP) task to evaluate
whether neural conversational agents have goal-oriented conversation planning
abilities. Using the TGCP task, we investigate the conversation planning
abilities of existing retrieval models and recent strong generative models. The
experimental results reveal the challenges facing current technology.",https://github.com/y-kishinami/TGCP,-1
6046fbd8-0219-4832-9afb-0aeff2582a1e,MLP-Hash: Protecting Face Templates via Hashing of Randomized Multi-Layer Perceptron,0.396402,"Applications of face recognition systems for authentication purposes are
growing rapidly. Although state-of-the-art (SOTA) face recognition systems have
high recognition accuracy, the features which are extracted for each user and
are stored in the system's database contain privacy-sensitive information.
Accordingly, compromising this data would jeopardize users' privacy. In this
paper, we propose a new cancelable template protection method, dubbed MLP-hash,
which generates protected templates by passing the extracted features through a
user-specific randomly-weighted multi-layer perceptron (MLP) and binarizing the
MLP output. We evaluated the unlinkability, irreversibility, and recognition
accuracy of our proposed biometric template protection method to fulfill the
ISO/IEC 30136 standard requirements. Our experiments with SOTA face recognition
systems on the MOBIO and LFW datasets show that our method has competitive
performance with the BioHashing and IoM Hashing (IoM-GRP and IoM-URP) template
protection algorithms. We provide an open-source implementation of all the
experiments presented in this paper so that other researchers can verify our
findings and build upon our work.",https://gitlab.idiap.ch/bob/bob.bio.face,-1
7328f234-d6b5-47f4-8ae0-1f7245310fa1,MixSKD: Self-Knowledge Distillation from Mixup for Image Recognition,0.780982,"Unlike the conventional Knowledge Distillation (KD), Self-KD allows a network
to learn knowledge from itself without any guidance from extra networks. This
paper proposes to perform Self-KD from image Mixture (MixSKD), which integrates
these two techniques into a unified framework. MixSKD mutually distills feature
maps and probability distributions between the random pair of original images
and their mixup images in a meaningful way. Therefore, it guides the network to
learn cross-image knowledge by modelling supervisory signals from mixup images.
Moreover, we construct a self-teacher network by aggregating multi-stage
feature maps for providing soft labels to supervise the backbone classifier,
further improving the efficacy of self-boosting. Experiments on image
classification and transfer learning to object detection and semantic
segmentation demonstrate that MixSKD outperforms other state-of-the-art Self-KD
and data augmentation methods. The code is available at
https://github.com/winycg/Self-KD-Lib.",https://github.com/winycg/Self-KD-Lib,-1
8d651294-1ee4-4977-8adf-daf2a9a2df11,Concrete Score Matching: Generalized Score Matching for Discrete Data,0.95781,"Representing probability distributions by the gradient of their density
functions has proven effective in modeling a wide range of continuous data
modalities. However, this representation is not applicable in discrete domains
where the gradient is undefined. To this end, we propose an analogous score
function called the ""Concrete score"", a generalization of the (Stein) score for
discrete settings. Given a predefined neighborhood structure, the Concrete
score of any input is defined by the rate of change of the probabilities with
respect to local directional changes of the input. This formulation allows us
to recover the (Stein) score in continuous domains when measuring such changes
by the Euclidean distance, while using the Manhattan distance leads to our
novel score function in discrete domains. Finally, we introduce a new framework
to learn such scores from samples called Concrete Score Matching (CSM), and
propose an efficient training objective to scale our approach to high
dimensions. Empirically, we demonstrate the efficacy of CSM on density
estimation tasks on a mixture of synthetic, tabular, and high-dimensional image
datasets, and demonstrate that it performs favorably relative to existing
baselines for modeling discrete data.",None,-1
1870a56a-401f-471d-9c43-41915e7d4bf2,Lightweight Monocular Depth Estimation with an Edge Guided Network,0.254361,"Monocular depth estimation is an important task that can be applied to many
robotic applications. Existing methods focus on improving depth estimation
accuracy via training increasingly deeper and wider networks, however these
suffer from large computational complexity. Recent studies found that edge
information are important cues for convolutional neural networks (CNNs) to
estimate depth. Inspired by the above observations, we present a novel
lightweight Edge Guided Depth Estimation Network (EGD-Net) in this study. In
particular, we start out with a lightweight encoder-decoder architecture and
embed an edge guidance branch which takes as input image gradients and
multi-scale feature maps from the backbone to learn the edge attention
features. In order to aggregate the context information and edge attention
features, we design a transformer-based feature aggregation module (TRFA). TRFA
captures the long-range dependencies between the context information and edge
attention features through cross-attention mechanism. We perform extensive
experiments on the NYU depth v2 dataset. Experimental results show that the
proposed method runs about 96 fps on a Nvidia GTX 1080 GPU whilst achieving the
state-of-the-art performance in terms of accuracy.",None,10318
b5d12435-c327-4fe7-a780-b495f8a8a2df,HSGNet: Object Re-identification with Hierarchical Similarity Graph Network,0.562526,"Object re-identification method is made up of backbone network, feature
aggregation, and loss function. However, most backbone networks lack a special
mechanism to handle rich scale variations and mine discriminative feature
representations. In this paper, we firstly design a hierarchical similarity
graph module (HSGM) to reduce the conflict of backbone and re-identification
networks. The designed HSGM builds a rich hierarchical graph to mine the
mapping relationships between global-local and local-local. Secondly, we divide
the feature map along with the spatial and channel directions in each
hierarchical graph. The HSGM applies the spatial features and channel features
extracted from different locations as nodes, respectively, and utilizes the
similarity scores between nodes to construct spatial and channel similarity
graphs. During the learning process of HSGM, we utilize a learnable parameter
to re-optimize the importance of each position, as well as evaluate the
correlation between different nodes. Thirdly, we develop a novel hierarchical
similarity graph network (HSGNet) by embedding the HSGM in the backbone
network. Furthermore, HSGM can be easily embedded into backbone networks of any
depth to improve object re-identification ability. Finally, extensive
experiments on three large-scale object datasets demonstrate that the proposed
HSGNet is superior to state-of-the-art object re-identification approaches.",None,-1
245f5764-5dff-4f8e-bb00-18d6584561cc,IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation metrics for Indian Languages,0.672191,"The rapid growth of machine translation (MT) systems has necessitated
comprehensive studies to meta-evaluate evaluation metrics being used, which
enables a better selection of metrics that best reflect MT quality.
Unfortunately, most of the research focuses on high-resource languages, mainly
English, the observations for which may not always apply to other languages.
Indian languages, having over a billion speakers, are linguistically different
from English, and to date, there has not been a systematic study of evaluating
MT systems from English into Indian languages. In this paper, we fill this gap
by creating an MQM dataset consisting of 7000 fine-grained annotations,
spanning 5 Indian languages and 7 MT systems, and use it to establish
correlations between annotator scores and scores obtained using existing
automatic metrics. Our results show that pre-trained metrics, such as COMET,
have the highest correlations with annotator scores. Additionally, we find that
the metrics do not adequately capture fluency-based errors in Indian languages,
and there is a need to develop metrics focused on Indian languages. We hope
that our dataset and analysis will help promote further research in this area.",https://github.com/AI4Bharat/IndicMT-Eval,-1
39bf4838-e9eb-497a-987c-a7226201ca18,Compositional Law Parsing with Latent Random Functions,0.603469,"Human cognition has compositionality. We understand a scene by decomposing
the scene into different concepts (e.g., shape and position of an object) and
learning the respective laws of these concepts, which may be either natural
(e.g., laws of motion) or man-made (e.g., laws of a game). The automatic
parsing of these laws indicates the model's ability to understand the scene,
which makes law parsing play a central role in many visual tasks. This paper
proposes a deep latent variable model for Compositional LAw Parsing (CLAP),
which achieves the human-like compositionality ability through an
encoding-decoding architecture to represent concepts in the scene as latent
variables. CLAP employs concept-specific latent random functions instantiated
with Neural Processes to capture the law of concepts. Our experimental results
demonstrate that CLAP outperforms the baseline methods in multiple visual tasks
such as intuitive physics, abstract visual reasoning, and scene representation.
The law manipulation experiments illustrate CLAP's interpretability by
modifying specific latent random functions on samples. For example, CLAP learns
the laws of position-changing and appearance constancy from the moving balls in
a scene, making it possible to exchange laws between samples or compose
existing laws into novel laws.",https://github.com/FudanVI/generative-abstract-reasoning/tree/main/clap,-1
54a32a81-4eb6-42dd-8b92-d910b95e4a22,Towards Involving End-users in Interactive Human-in-the-loop AI Fairness,0.745923,"Ensuring fairness in artificial intelligence (AI) is important to counteract
bias and discrimination in far-reaching applications. Recent work has started
to investigate how humans judge fairness and how to support machine learning
(ML) experts in making their AI models fairer. Drawing inspiration from an
Explainable AI (XAI) approach called \emph{explanatory debugging} used in
interactive machine learning, our work explores designing interpretable and
interactive human-in-the-loop interfaces that allow ordinary end-users without
any technical or domain background to identify potential fairness issues and
possibly fix them in the context of loan decisions. Through workshops with
end-users, we co-designed and implemented a prototype system that allowed
end-users to see why predictions were made, and then to change weights on
features to ""debug"" fairness issues. We evaluated the use of this prototype
system through an online study. To investigate the implications of diverse
human values about fairness around the globe, we also explored how cultural
dimensions might play a role in using this prototype. Our results contribute to
the design of interfaces to allow end-users to be involved in judging and
addressing AI fairness through a human-in-the-loop approach.",None,-1
b9a94be4-f9c6-46ef-9ebb-d914f21f5ab6,Machine Learning-Powered Course Allocation,0.441048,"We study the course allocation problem, where universities assign course
schedules to students. The current state-of-the-art mechanism, Course Match,
has one major shortcoming: students make significant mistakes when reporting
their preferences, which negatively affects welfare and fairness. To address
this issue, we introduce a new mechanism, Machine Learning-powered Course Match
(MLCM). At the core of MLCM is a machine learning-powered preference
elicitation module that iteratively asks personalized pairwise comparison
queries to alleviate students' reporting mistakes. Extensive computational
experiments, grounded in real-world data, demonstrate that MLCM, with only ten
comparison queries, significantly increases both average and minimum student
utility by 7%-11% and 17%-29%, respectively. Finally, we highlight MLCM's
robustness to changes in the environment and show how our design minimizes the
risk of upgrading to MLCM while making the upgrade process simple for
universities and seamless for their students.",None,-1
56841793-693e-4ad5-a7f7-733ecb5d41fe,Spread Love Not Hate: Undermining the Importance of Hateful Pre-training for Hate Speech Detection,0.629676,"Pre-training large neural language models, such as BERT, has led to
impressive gains on many natural language processing (NLP) tasks. Although this
method has proven to be effective for many domains, it might not always provide
desirable benefits. In this paper, we study the effects of hateful pre-training
on low-resource hate speech classification tasks. While previous studies on the
English language have emphasized its importance, we aim to augment their
observations with some non-obvious insights. We evaluate different variations
of tweet-based BERT models pre-trained on hateful, non-hateful, and mixed
subsets of a 40M tweet dataset. This evaluation is carried out for the Indian
languages Hindi and Marathi. This paper is empirical evidence that hateful
pre-training is not the best pre-training option for hate speech detection. We
show that pre-training on non-hateful text from the target domain provides
similar or better results. Further, we introduce HindTweetBERT and
MahaTweetBERT, the first publicly available BERT models pre-trained on Hindi
and Marathi tweets, respectively. We show that they provide state-of-the-art
performance on hate speech classification tasks. We also release hateful BERT
for the two languages and a gold hate speech evaluation benchmark HateEval-Hi
and HateEval-Mr consisting of manually labeled 2000 tweets each. The models and
data are available at https://github.com/l3cube-pune/MarathiNLP .",https://github.com/l3cube-pune/MarathiNLP,-1
5b917f6b-9457-408f-930b-65270d138b3a,Longtonotes: OntoNotes with Longer Coreference Chains,0.0336702,"Ontonotes has served as the most important benchmark for coreference
resolution. However, for ease of annotation, several long documents in
Ontonotes were split into smaller parts. In this work, we build a corpus of
coreference-annotated documents of significantly longer length than what is
currently available. We do so by providing an accurate, manually-curated,
merging of annotations from documents that were split into multiple parts in
the original Ontonotes annotation process. The resulting corpus, which we call
LongtoNotes contains documents in multiple genres of the English language with
varying lengths, the longest of which are up to 8x the length of documents in
Ontonotes, and 2x those in Litbank. We evaluate state-of-the-art neural
coreference systems on this new corpus, analyze the relationships between model
architectures/hyperparameters and document length on performance and efficiency
of the models, and demonstrate areas of improvement in long-document
coreference modeling revealed by our new corpus. Our data and code is available
at: https://github.com/kumar-shridhar/LongtoNotes.",https://github.com/kumar-shridhar/LongtoNotes,-1
ece30420-e35c-4c70-9480-367ff4ef4dfc,On the State of the Art in Authorship Attribution and Authorship Verification,0.834999,"Despite decades of research on authorship attribution (AA) and authorship
verification (AV), inconsistent dataset splits/filtering and mismatched
evaluation methods make it difficult to assess the state of the art. In this
paper, we present a survey of the fields, resolve points of confusion,
introduce Valla that standardizes and benchmarks AA/AV datasets and metrics,
provide a large-scale empirical evaluation, and provide apples-to-apples
comparisons between existing methods. We evaluate eight promising methods on
fifteen datasets (including distribution-shifted challenge sets) and introduce
a new large-scale dataset based on texts archived by Project Gutenberg.
Surprisingly, we find that a traditional Ngram-based model performs best on 5
(of 7) AA tasks, achieving an average macro-accuracy of $76.50\%$ (compared to
$66.71\%$ for a BERT-based model). However, on the two AA datasets with the
greatest number of words per author, as well as on the AV datasets, BERT-based
models perform best. While AV methods are easily applied to AA, they are seldom
included as baselines in AA papers. We show that through the application of
hard-negative mining, AV methods are competitive alternatives to AA methods.
Valla and all experiment code can be found here:
https://github.com/JacobTyo/Valla",https://github.com/JacobTyo/Valla,-1
533a90b8-b823-4cef-beba-66303dc4f953,Open- and Closed-Loop Neural Network Verification using Polynomial Zonotopes,0.727531,"We present a novel approach to efficiently compute tight non-convex
enclosures of the image through neural networks with ReLU, sigmoid, or
hyperbolic tangent activation functions. In particular, we abstract the
input-output relation of each neuron by a polynomial approximation, which is
evaluated in a set-based manner using polynomial zonotopes. While our approach
can also can be beneficial for open-loop neural network verification, our main
application is reachability analysis of neural network controlled systems,
where polynomial zonotopes are able to capture the non-convexity caused by the
neural network as well as the system dynamics. This results in a superior
performance compared to other methods, as we demonstrate on various benchmarks.",None,-1
2a023d85-71f8-4711-9b88-d2602103e2a3,HLT-MT: High-resource Language-specific Training for Multilingual Neural Machine Translation,0.620594,"Multilingual neural machine translation (MNMT) trained in multiple language
pairs has attracted considerable attention due to fewer model parameters and
lower training costs by sharing knowledge among multiple languages.
Nonetheless, multilingual training is plagued by language interference
degeneration in shared parameters because of the negative interference among
different translation directions, especially on high-resource languages. In
this paper, we propose the multilingual translation model with the
high-resource language-specific training (HLT-MT) to alleviate the negative
interference, which adopts the two-stage training with the language-specific
selection mechanism. Specifically, we first train the multilingual model only
with the high-resource pairs and select the language-specific modules at the
top of the decoder to enhance the translation quality of high-resource
directions. Next, the model is further trained on all available corpora to
transfer knowledge from high-resource languages (HRLs) to low-resource
languages (LRLs). Experimental results show that HLT-MT outperforms various
strong baselines on WMT-10 and OPUS-100 benchmarks. Furthermore, the analytic
experiments validate the effectiveness of our method in mitigating the negative
interference in multilingual training.",None,97925
4b902efa-f5db-45fd-a504-e21a6f729e47,Is it all a cluster game? -- Exploring Out-of-Distribution Detection based on Clustering in the Embedding Space,0.229091,"It is essential for safety-critical applications of deep neural networks to
determine when new inputs are significantly different from the training
distribution. In this paper, we explore this out-of-distribution (OOD)
detection problem for image classification using clusters of semantically
similar embeddings of the training data and exploit the differences in distance
relationships to these clusters between in- and out-of-distribution data. We
study the structure and separation of clusters in the embedding space and find
that supervised contrastive learning leads to well-separated clusters while its
self-supervised counterpart fails to do so. In our extensive analysis of
different training methods, clustering strategies, distance metrics, and
thresholding approaches, we observe that there is no clear winner. The optimal
approach depends on the model architecture and selected datasets for in- and
out-of-distribution. While we could reproduce the outstanding results for
contrastive training on CIFAR-10 as in-distribution data, we find standard
cross-entropy paired with cosine similarity outperforms all contrastive
training methods when training on CIFAR-100 instead. Cross-entropy provides
competitive results as compared to expensive contrastive training methods.",None,-1
019529ea-7424-4d35-8909-8d79a06261ec,Causes of Catastrophic Forgetting in Class-Incremental Semantic Segmentation,0.221345,"Class-incremental learning for semantic segmentation (CiSS) is presently a
highly researched field which aims at updating a semantic segmentation model by
sequentially learning new semantic classes. A major challenge in CiSS is
overcoming the effects of catastrophic forgetting, which describes the sudden
drop of accuracy on previously learned classes after the model is trained on a
new set of classes. Despite latest advances in mitigating catastrophic
forgetting, the underlying causes of forgetting specifically in CiSS are not
well understood. Therefore, in a set of experiments and representational
analyses, we demonstrate that the semantic shift of the background class and a
bias towards new classes are the major causes of forgetting in CiSS.
Furthermore, we show that both causes mostly manifest themselves in deeper
classification layers of the network, while the early layers of the model are
not affected. Finally, we demonstrate how both causes are effectively mitigated
utilizing the information contained in the background, with the help of
knowledge distillation and an unbiased cross-entropy loss.",https://github.com/Eromera/erfnet,-1
11eab018-bda6-49a6-b054-3f560687ce57,Coupling User Preference with External Rewards to Enable Driver-centered and Resource-aware EV Charging Recommendation,0.32696,"Electric Vehicle (EV) charging recommendation that both accommodates user
preference and adapts to the ever-changing external environment arises as a
cost-effective strategy to alleviate the range anxiety of private EV drivers.
Previous studies focus on centralized strategies to achieve optimized resource
allocation, particularly useful for privacy-indifferent taxi fleets and
fixed-route public transits. However, private EV driver seeks a more
personalized and resource-aware charging recommendation that is tailor-made to
accommodate the user preference (when and where to charge) yet sufficiently
adaptive to the spatiotemporal mismatch between charging supply and demand.
Here we propose a novel Regularized Actor-Critic (RAC) charging recommendation
approach that would allow each EV driver to strike an optimal balance between
the user preference (historical charging pattern) and the external reward
(driving distance and wait time). Experimental results on two real-world
datasets demonstrate the unique features and superior performance of our
approach to the competing methods.",https://github.com/cyli2019/RAC-for-EV-Charging-Rec.,-1
2dd66878-d58f-4923-8d5b-6b4616ba38a4,NL2INTERFACE: Interactive Visualization Interface Generation from Natural Language Queries,0.609083,"We develop NL2INTERFACE to explore the potential of generating usable
interactive multi-visualization interfaces from natural language queries. With
NL2INTERFACE, users can directly write natural language queries to
automatically generate a fully interactive multi-visualization interface
without any extra effort of learning a tool or programming language. Further,
users can interact with the interfaces to easily transform the data and quickly
see the results in the visualizations.",None,11020
88cb942d-aef3-40f4-8c7a-c1d068ee4382,Adaptive Mean-Residue Loss for Robust Facial Age Estimation,0.565704,"Automated facial age estimation has diverse real-world applications in
multimedia analysis, e.g., video surveillance, and human-computer interaction.
However, due to the randomness and ambiguity of the aging process, age
assessment is challenging. Most research work over the topic regards the task
as one of age regression, classification, and ranking problems, and cannot well
leverage age distribution in representing labels with age ambiguity. In this
work, we propose a simple yet effective loss function for robust facial age
estimation via distribution learning, i.e., adaptive mean-residue loss, in
which, the mean loss penalizes the difference between the estimated age
distribution's mean and the ground-truth age, whereas the residue loss
penalizes the entropy of age probability out of dynamic top-K in the
distribution. Experimental results in the datasets FG-NET and CLAP2016 have
validated the effectiveness of the proposed loss. Our code is available at
https://github.com/jacobzhaoziyuan/AMR-Loss.",None,-1
4ce27c3e-3f91-4ad9-ad2d-98c15e44f623,Generating natural images with direct Patch Distributions Matching,0.777994,"Many traditional computer vision algorithms generate realistic images by
requiring that each patch in the generated image be similar to a patch in a
training image and vice versa. Recently, this classical approach has been
replaced by adversarial training with a patch discriminator. The adversarial
approach avoids the computational burden of finding nearest neighbors of
patches but often requires very long training times and may fail to match the
distribution of patches. In this paper we leverage the recently developed
Sliced Wasserstein Distance and develop an algorithm that explicitly and
efficiently minimizes the distance between patch distributions in two images.
Our method is conceptually simple, requires no training and can be implemented
in a few lines of codes. On a number of image generation tasks we show that our
results are often superior to single-image-GANs, require no training, and can
generate high quality images in a few seconds. Our implementation is available
at https://github.com/ariel415el/GPDM",https://github.com/ariel415el/GPDM,-1
078b8eed-f9e6-4930-ae99-5098a8a0a46b,DUAL: Discrete Spoken Unit Adaptive Learning for Textless Spoken Question Answering,0.705743,"Spoken Question Answering (SQA) is to find the answer from a spoken document
given a question, which is crucial for personal assistants when replying to the
queries from the users. Existing SQA methods all rely on Automatic Speech
Recognition (ASR) transcripts. Not only does ASR need to be trained with
massive annotated data that are time and cost-prohibitive to collect for
low-resourced languages, but more importantly, very often the answers to the
questions include name entities or out-of-vocabulary words that cannot be
recognized correctly. Also, ASR aims to minimize recognition errors equally
over all words, including many function words irrelevant to the SQA task.
Therefore, SQA without ASR transcripts (textless) is always highly desired,
although known to be very difficult.
  This work proposes Discrete Spoken Unit Adaptive Learning (DUAL), leveraging
unlabeled data for pre-training and fine-tuned by the SQA downstream task. The
time intervals of spoken answers can be directly predicted from spoken
documents. We also release a new SQA benchmark corpus, NMSQA, for data with
more realistic scenarios. We empirically showed that DUAL yields results
comparable to those obtained by cascading ASR and text QA model and robust to
real-world data. Our code and model will be open-sourced.",None,-1
75bbb2af-a7a3-47be-a6b2-9c77367517c9,Co-design of Embodied Neural Intelligence via Constrained Evolution,0.0570519,"We introduce a novel co-design method for autonomous moving agents' shape
attributes and locomotion by combining deep reinforcement learning and
evolution with user control. Our main inspiration comes from evolution, which
has led to wide variability and adaptation in Nature and has the potential to
significantly improve design and behavior simultaneously. Our method takes an
input agent with optional simple constraints such as leg parts that should not
evolve or allowed ranges of changes. It uses physics-based simulation to
determine its locomotion and finds a behavior policy for the input design,
later used as a baseline for comparison. The agent is then randomly modified
within the allowed ranges creating a new generation of several hundred agents.
The generation is trained by transferring the previous policy, which
significantly speeds up the training. The best-performing agents are selected,
and a new generation is formed using their crossover and mutations. The next
generations are then trained until satisfactory results are reached. We show a
wide variety of evolved agents, and our results show that even with only 10% of
changes, the overall performance of the evolved agents improves 50%. If more
significant changes to the initial design are allowed, our experiments'
performance improves even more to 150%. Contrary to related work, our co-design
works on a single GPU and provides satisfactory results by training thousands
of agents within one hour.",None,-1
ed477016-e408-4877-b190-c5ab4dffda82,Occluded Person Re-Identification via Relational Adaptive Feature Correction Learning,0.828262,"Occluded person re-identification (Re-ID) in images captured by multiple
cameras is challenging because the target person is occluded by pedestrians or
objects, especially in crowded scenes. In addition to the processes performed
during holistic person Re-ID, occluded person Re-ID involves the removal of
obstacles and the detection of partially visible body parts. Most existing
methods utilize the off-the-shelf pose or parsing networks as pseudo labels,
which are prone to error. To address these issues, we propose a novel Occlusion
Correction Network (OCNet) that corrects features through relational-weight
learning and obtains diverse and representative features without using external
networks. In addition, we present a simple concept of a center feature in order
to provide an intuitive solution to pedestrian occlusion scenarios.
Furthermore, we suggest the idea of Separation Loss (SL) for focusing on
different parts between global features and part features. We conduct extensive
experiments on five challenging benchmark datasets for occluded and holistic
Re-ID tasks to demonstrate that our method achieves superior performance to
state-of-the-art methods especially on occluded scene.",None,-1
3e52b90f-e576-47ae-ac8a-74f4b69af953,BIC: Twitter Bot Detection with Text-Graph Interaction and Semantic Consistency,0.893296,"Twitter bots are automatic programs operated by malicious actors to
manipulate public opinion and spread misinformation. Research efforts have been
made to automatically identify bots based on texts and networks on social
media. Existing methods only leverage texts or networks alone, and while few
works explored the shallow combination of the two modalities, we hypothesize
that the interaction and information exchange between texts and graphs could be
crucial for holistically evaluating bot activities on social media. In
addition, according to a recent survey (Cresci, 2020), Twitter bots are
constantly evolving while advanced bots steal genuine users' tweets and dilute
their malicious content to evade detection. This results in greater
inconsistency across the timeline of novel Twitter bots, which warrants more
attention. In light of these challenges, we propose BIC, a Twitter Bot
detection framework with text-graph Interaction and semantic Consistency.
Specifically, in addition to separately modeling the two modalities on social
media, BIC employs a text-graph interaction module to enable information
exchange across modalities in the learning process. In addition, given the
stealing behavior of novel Twitter bots, BIC proposes to model semantic
consistency in tweets based on attention weights while using it to augment the
decision process. Extensive experiments demonstrate that BIC consistently
outperforms state-of-the-art baselines on two widely adopted datasets. Further
analyses reveal that text-graph interactions and modeling semantic consistency
are essential improvements and help combat bot evolution.",https://github.com/Bjarten/early-stopping-pytorch,-1
4a169a9a-9542-4e49-940a-a068f22af8c1,Subgraph Retrieval Enhanced Model for Multi-hop Knowledge Base Question Answering,0.900871,"Recent works on knowledge base question answering (KBQA) retrieve subgraphs
for easier reasoning. A desired subgraph is crucial as a small one may exclude
the answer but a large one might introduce more noises. However, the existing
retrieval is either heuristic or interwoven with the reasoning, causing
reasoning on the partial subgraphs, which increases the reasoning bias when the
intermediate supervision is missing. This paper proposes a trainable subgraph
retriever (SR) decoupled from the subsequent reasoning process, which enables a
plug-and-play framework to enhance any subgraph-oriented KBQA model. Extensive
experiments demonstrate SR achieves significantly better retrieval and QA
performance than existing retrieval methods. Via weakly supervised pre-training
as well as the end-to-end fine-tuning, SRl achieves new state-of-the-art
performance when combined with NSM, a subgraph-oriented reasoner, for
embedding-based KBQA methods.",https://github.com/RUCKBReasoning/SubgraphRetrievalKBQA,-1
8204e5ef-325f-4f15-8785-a534a3fd6c5e,"Video Question Answering: Datasets, Algorithms and Challenges",0.856297,"Video Question Answering (VideoQA) aims to answer natural language questions
according to the given videos. It has earned increasing attention with recent
research trends in joint vision and language understanding. Yet, compared with
ImageQA, VideoQA is largely underexplored and progresses slowly. Although
different algorithms have continually been proposed and shown success on
different VideoQA datasets, we find that there lacks a meaningful survey to
categorize them, which seriously impedes its advancements. This paper thus
provides a clear taxonomy and comprehensive analyses to VideoQA, focusing on
the datasets, algorithms, and unique challenges. We then point out the research
trend of studying beyond factoid QA to inference QA towards the cognition of
video contents, Finally, we conclude some promising directions for future
exploration.",https://github.com/VRU-NExT/VideoQA,-1
a2250ee1-4771-4e71-b0bb-f159fc92359c,Reference Resolution and Context Change in Multimodal Situated Dialogue for Exploring Data Visualizations,0.0663935,"Reference resolution, which aims to identify entities being referred to by a
speaker, is more complex in real world settings: new referents may be created
by processes the agents engage in and/or be salient only because they belong to
the shared physical setting. Our focus is on resolving references to
visualizations on a large screen display in multimodal dialogue; crucially,
reference resolution is directly involved in the process of creating new
visualizations. We describe our annotations for user references to
visualizations appearing on a large screen via language and hand gesture and
also new entity establishment, which results from executing the user request to
create a new visualization. We also describe our reference resolution pipeline
which relies on an information-state architecture to maintain dialogue context.
We report results on detecting and resolving references, effectiveness of
contextual information on the model, and under-specified requests for creating
visualizations. We also experiment with conventional CRF and deep learning /
transformer models (BiLSTM-CRF and BERT-CRF) for tagging references in user
utterance text. Our results show that transfer learning significantly boost
performance of the deep learning methods, although CRF still out-performs them,
suggesting that conventional methods may generalize better for low resource
data.",None,-1
bb0b97cc-6461-4630-a657-b01b2feb175c,Fast Light-Weight Near-Field Photometric Stereo,0.381422,"We introduce the first end-to-end learning-based solution to near-field
Photometric Stereo (PS), where the light sources are close to the object of
interest. This setup is especially useful for reconstructing large immobile
objects. Our method is fast, producing a mesh from 52 512$\times$384 resolution
images in about 1 second on a commodity GPU, thus potentially unlocking several
AR/VR applications. Existing approaches rely on optimization coupled with a
far-field PS network operating on pixels or small patches. Using optimization
makes these approaches slow and memory intensive (requiring 17GB GPU and 27GB
of CPU memory) while using only pixels or patches makes them highly susceptible
to noise and calibration errors. To address these issues, we develop a
recursive multi-resolution scheme to estimate surface normal and depth maps of
the whole image at each step. The predicted depth map at each scale is then
used to estimate `per-pixel lighting' for the next scale. This design makes our
approach almost 45$\times$ faster and 2$^{\circ}$ more accurate (11.3$^{\circ}$
vs. 13.3$^{\circ}$ Mean Angular Error) than the state-of-the-art near-field PS
reconstruction technique, which uses iterative optimization.",None,-1
1521fe70-22fb-49a7-b0ed-3dc010220047,Anticipative Feature Fusion Transformer for Multi-Modal Action Anticipation,0.86545,"Although human action anticipation is a task which is inherently multi-modal,
state-of-the-art methods on well known action anticipation datasets leverage
this data by applying ensemble methods and averaging scores of unimodal
anticipation networks. In this work we introduce transformer based modality
fusion techniques, which unify multi-modal data at an early stage. Our
Anticipative Feature Fusion Transformer (AFFT) proves to be superior to popular
score fusion approaches and presents state-of-the-art results outperforming
previous methods on EpicKitchens-100 and EGTEA Gaze+. Our model is easily
extensible and allows for adding new modalities without architectural changes.
Consequently, we extracted audio features on EpicKitchens-100 which we add to
the set of commonly used features in the community.",https://github.com/zeyun-zhong/AFFT,21427
94ccbc76-0588-45f9-889e-0f5469efc745,DProQ: A Gated-Graph Transformer for Protein Complex Structure Assessment,0.342773,"Proteins interact to form complexes to carry out essential biological
functions. Computational methods have been developed to predict the structures
of protein complexes. However, an important challenge in protein complex
structure prediction is to estimate the quality of predicted protein complex
structures without any knowledge of the corresponding native structures. Such
estimations can then be used to select high-quality predicted complex
structures to facilitate biomedical research such as protein function analysis
and drug discovery. We challenge this significant task with DProQ, which
introduces a gated neighborhood-modulating Graph Transformer (GGT) designed to
predict the quality of 3D protein complex structures. Notably, we incorporate
node and edge gates within a novel Graph Transformer framework to control
information flow during graph message passing. We train and evaluate DProQ on
four newly-developed datasets that we make publicly available in this work. Our
rigorous experiments demonstrate that DProQ achieves state-of-the-art
performance in ranking protein complex structures.",https://github.com/BioinfoMachineLearning/DProQ,-1
6a458e74-88a3-44d7-b48a-34e583c39b46,Trustworthy Social Bias Measurement,0.812324,"How do we design measures of social bias that we trust? While prior work has
introduced several measures, no measure has gained widespread trust: instead,
mounting evidence argues we should distrust these measures. In this work, we
design bias measures that warrant trust based on the cross-disciplinary theory
of measurement modeling. To combat the frequently fuzzy treatment of social
bias in NLP, we explicitly define social bias, grounded in principles drawn
from social science research. We operationalize our definition by proposing a
general bias measurement framework DivDist, which we use to instantiate 5
concrete bias measures. To validate our measures, we propose a rigorous testing
protocol with 8 testing criteria (e.g. predictive validity: do measures predict
biases in US employment?). Through our testing, we demonstrate considerable
evidence to trust our measures, showing they overcome conceptual, technical,
and empirical deficiencies present in prior measures.",https://github.com/rishibommasani/BiasMeasures,-1
8ce7dc71-7b86-47a2-aceb-9bca1e67cb69,MPA: MultiPath++ Based Architecture for Motion Prediction,0.668082,"Autonomous driving technology is developing rapidly and nowadays first
autonomous rides are being provided in city areas. This requires the highest
standards for the safety and reliability of the technology. Motion prediction
part of the general self-driving pipeline plays a crucial role in providing
these qualities. In this work we present one of the solutions for Waymo Motion
Prediction Challenge 2022 based on MultiPath++ ranked the 3rd as of May, 26
2022. Our source code is publicly available on GitHub.",https://github.com/stepankonev/waymo-motion-prediction-challenge-2022-multipath-plus-plus,-1
757587c5-aae1-4872-8594-c652eeb72097,Plumber: A Modular Framework to Create Information Extraction Pipelines,0.0839421,"Information Extraction (IE) tasks are commonly studied topics in various
domains of research. Hence, the community continuously produces multiple
techniques, solutions, and tools to perform such tasks. However, running those
tools and integrating them within existing infrastructure requires time,
expertise, and resources. One pertinent task here is triples extraction and
linking, where structured triples are extracted from a text and aligned to an
existing Knowledge Graph (KG). In this paper, we present PLUMBER, the first
framework that allows users to manually and automatically create suitable IE
pipelines from a community-created pool of tools to perform triple extraction
and alignment on unstructured text. Our approach provides an interactive medium
to alter the pipelines and perform IE tasks. A short video to show the working
of the framework for different use-cases is available online under:
https://www.youtube.com/watch?v=XC9rJNIUv8g",https://github.com/YaserJaradeh/ThePlumber,-1
f056f704-a750-4520-af2b-215782943d64,Investigating Information Inconsistency in Multilingual Open-Domain Question Answering,0.0349883,"Retrieval based open-domain QA systems use retrieved documents and
answer-span selection over retrieved documents to find best-answer candidates.
We hypothesize that multilingual Question Answering (QA) systems are prone to
information inconsistency when it comes to documents written in different
languages, because these documents tend to provide a model with varying
information about the same topic. To understand the effects of the biased
availability of information and cultural influence, we analyze the behavior of
multilingual open-domain question answering models with a focus on retrieval
bias. We analyze if different retriever models present different passages given
the same question in different languages on TyDi QA and XOR-TyDi QA, two
multilingualQA datasets. We speculate that the content differences in documents
across languages might reflect cultural divergences and/or social biases.",https://github.com/mia-workshop/MIA-Shared-Task-2022,-1
89e8b9d0-2434-492a-a985-d815cf4101b0,"Generative Long-form Question Answering: Relevance, Faithfulness and Succinctness",0.121643,"In this thesis, we investigated the relevance, faithfulness, and succinctness
aspects of Long Form Question Answering (LFQA). LFQA aims to generate an
in-depth, paragraph-length answer for a given question, to help bridge the gap
between real scenarios and the existing open-domain QA models which can only
extract short-span answers. LFQA is quite challenging and under-explored. Few
works have been done to build an effective LFQA system. It is even more
challenging to generate a good-quality long-form answer relevant to the query
and faithful to facts, since a considerable amount of redundant, complementary,
or contradictory information will be contained in the retrieved documents.
Moreover, no prior work has been investigated to generate succinct answers. We
are among the first to research the LFQA task. We pioneered the research
direction to improve the answer quality in terms of 1) query-relevance, 2)
answer faithfulness, and 3) answer succinctness.",None,-1
55bc8842-ce56-49e7-ab8a-3ff3908eff47,Fairly Accurate: Learning Optimal Accuracy vs. Fairness Tradeoffs for Hate Speech Detection,0.0911082,"Recent work has emphasized the importance of balancing competing objectives
in model training (e.g., accuracy vs. fairness, or competing measures of
fairness). Such trade-offs reflect a broader class of multi-objective
optimization (MOO) problems in which optimization methods seek Pareto optimal
trade-offs between competing goals. In this work, we first introduce a
differentiable measure that enables direct optimization of group fairness
(specifically, balancing accuracy across groups) in model training. Next, we
demonstrate two model-agnostic MOO frameworks for learning Pareto optimal
parameterizations over different groups of neural classification models. We
evaluate our methods on the specific task of hate speech detection, in which
prior work has shown lack of group fairness across speakers of different
English dialects. Empirical results across convolutional, sequential, and
transformer-based neural architectures show superior empirical accuracy vs.
fairness trade-offs over prior work. More significantly, our measure enables
the Pareto machinery to ensure that each architecture achieves the best
possible trade-off between fairness and accuracy w.r.t. the dataset, given
user-prescribed error tolerance bounds.",None,-1
0e0c6c70-c6b0-48ac-aca3-709c8f14e927,Efficient universal shuffle attack for visual object tracking,0.622087,"Recently, adversarial attacks have been applied in visual object tracking to
deceive deep trackers by injecting imperceptible perturbations into video
frames. However, previous work only generates the video-specific perturbations,
which restricts its application scenarios. In addition, existing attacks are
difficult to implement in reality due to the real-time of tracking and the
re-initialization mechanism. To address these issues, we propose an offline
universal adversarial attack called Efficient Universal Shuffle Attack. It
takes only one perturbation to cause the tracker malfunction on all videos. To
improve the computational efficiency and attack performance, we propose a
greedy gradient strategy and a triple loss to efficiently capture and attack
model-specific feature representations through the gradients. Experimental
results show that EUSA can significantly reduce the performance of
state-of-the-art trackers on OTB2015 and VOT2018.",None,-1
3c237491-8413-4514-a07b-2103e410bd0c,Optimal estimation of Gaussian DAG models,0.761446,"We study the optimal sample complexity of learning a Gaussian directed
acyclic graph (DAG) from observational data. Our main results establish the
minimax optimal sample complexity for learning the structure of a linear
Gaussian DAG model in two settings of interest: 1) Under equal variances
without knowledge of the true ordering, and 2) For general linear models given
knowledge of the ordering. In both cases the sample complexity is $n\asymp
q\log(d/q)$, where $q$ is the maximum number of parents and $d$ is the number
of nodes. We further make comparisons with the classical problem of learning
(undirected) Gaussian graphical models, showing that under the equal variance
assumption, these two problems share the same optimal sample complexity. In
other words, at least for Gaussian models with equal error variances, learning
a directed graphical model is statistically no more difficult than learning an
undirected graphical model. Our results also extend to more general
identification assumptions as well as subgaussian errors.",https://github.com/WY-Chen/EqVarDAG/blob/master/R/EqVarDAG_HD_TD.R,-1
82fac479-a8f1-45c7-8b64-c353dc680f46,MorphTE: Injecting Morphology in Tensorized Embeddings,0.2987,"In the era of deep learning, word embeddings are essential when dealing with
text tasks. However, storing and accessing these embeddings requires a large
amount of space. This is not conducive to the deployment of these models on
resource-limited devices. Combining the powerful compression capability of
tensor products, we propose a word embedding compression method with
morphological augmentation, Morphologically-enhanced Tensorized Embeddings
(MorphTE). A word consists of one or more morphemes, the smallest units that
bear meaning or have a grammatical function. MorphTE represents a word
embedding as an entangled form of its morpheme vectors via the tensor product,
which injects prior semantic and grammatical knowledge into the learning of
embeddings. Furthermore, the dimensionality of the morpheme vector and the
number of morphemes are much smaller than those of words, which greatly reduces
the parameters of the word embeddings. We conduct experiments on tasks such as
machine translation and question answering. Experimental results on four
translation datasets of different languages show that MorphTE can compress word
embedding parameters by about 20 times without performance loss and
significantly outperforms related embedding compression methods.",https://github.com/aboSamoor/polyglot,-1
0b1cc74b-6861-498c-ab17-3d83e6c7471e,Named Entity Recognition in Twitter: A Dataset and Analysis on Short-Term Temporal Shifts,0.951533,"Recent progress in language model pre-training has led to important
improvements in Named Entity Recognition (NER). Nonetheless, this progress has
been mainly tested in well-formatted documents such as news, Wikipedia, or
scientific articles. In social media the landscape is different, in which it
adds another layer of complexity due to its noisy and dynamic nature. In this
paper, we focus on NER in Twitter, one of the largest social media platforms,
and construct a new NER dataset, TweetNER7, which contains seven entity types
annotated over 11,382 tweets from September 2019 to August 2021. The dataset
was constructed by carefully distributing the tweets over time and taking
representative trends as a basis. Along with the dataset, we provide a set of
language model baselines and perform an analysis on the language model
performance on the task, especially analyzing the impact of different time
periods. In particular, we focus on three important temporal aspects in our
analysis: short-term degradation of NER models over time, strategies to
fine-tune a language model over different periods, and self-labeling as an
alternative to lack of recently-labeled data. TweetNER7 is released publicly
(https://huggingface.co/datasets/tner/tweetner7) along with the models
fine-tuned on it.",https://github.com/asahi417/tner/tree/master/examples/tweetner7_paper,-1
1319c8ed-e922-402d-9906-0f8fc2b63857,A Self-Guided Framework for Radiology Report Generation,0.715289,"Automatic radiology report generation is essential to computer-aided
diagnosis. Through the success of image captioning, medical report generation
has been achievable. However, the lack of annotated disease labels is still the
bottleneck of this area. In addition, the image-text data bias problem and
complex sentences make it more difficult to generate accurate reports. To
address these gaps, we pre-sent a self-guided framework (SGF), a suite of
unsupervised and supervised deep learning methods to mimic the process of human
learning and writing. In detail, our framework obtains the domain knowledge
from medical reports with-out extra disease labels and guides itself to extract
fined-grain visual features as-sociated with the text. Moreover, SGF
successfully improves the accuracy and length of medical report generation by
incorporating a similarity comparison mechanism that imitates the process of
human self-improvement through compar-ative practice. Extensive experiments
demonstrate the utility of our SGF in the majority of cases, showing its
superior performance over state-of-the-art meth-ods. Our results highlight the
capacity of the proposed framework to distinguish fined-grained visual details
between words and verify its advantage in generating medical reports.",None,2284
7ae389e4-17a8-46a1-b2b3-057b17756a6e,Threat Detection In Self-Driving Vehicles Using Computer Vision,0.205922,"On-road obstacle detection is an important field of research that falls in
the scope of intelligent transportation infrastructure systems. The use of
vision-based approaches results in an accurate and cost-effective solution to
such systems. In this research paper, we propose a threat detection mechanism
for autonomous self-driving cars using dashcam videos to ensure the presence of
any unwanted obstacle on the road that falls within its visual range. This
information can assist the vehicle's program to en route safely. There are four
major components, namely, YOLO to identify the objects, advanced lane detection
algorithm, multi regression model to measure the distance of the object from
the camera, the two-second rule for measuring the safety, and limiting speed.
In addition, we have used the Car Crash Dataset(CCD) for calculating the
accuracy of the model. The YOLO algorithm gives an accuracy of around 93%. The
final accuracy of our proposed Threat Detection Model (TDM) is 82.65%.",None,-1
97053c34-cffc-47a3-8954-899495408744,"You can't pick your neighbors, or can you? When and how to rely on retrieval in the $k$NN-LM",0.297603,"Retrieval-enhanced language models (LMs), which condition their predictions
on text retrieved from large external datastores, have recently shown
significant perplexity improvements compared to standard LMs. One such
approach, the $k$NN-LM, interpolates any existing LM's predictions with the
output of a $k$-nearest neighbors model and requires no additional training. In
this paper, we explore the importance of lexical and semantic matching in the
context of items retrieved by $k$NN-LM. We find two trends: (1) the presence of
large overlapping $n$-grams between the datastore and evaluation set plays an
important factor in strong performance, even when the datastore is derived from
the training data; and (2) the $k$NN-LM is most beneficial when retrieved items
have high semantic similarity with the query. Based on our analysis, we define
a new formulation of the $k$NN-LM that uses retrieval quality to assign the
interpolation coefficient. We empirically measure the effectiveness of our
approach on two English language modeling datasets, Wikitext-103 and PG-19. Our
re-formulation of the $k$NN-LM is beneficial in both cases, and leads to nearly
4% improvement in perplexity on the Wikitext-103 test set.",https://github.com/iesl/knnlm-retrieval-quality,-1
20b677f9-5a19-4de4-a171-98c39c4d9080,Exploiting Embodied Simulation to Detect Novel Object Classes Through Interaction,0.229217,"In this paper we present a novel method for a naive agent to detect novel
objects it encounters in an interaction. We train a reinforcement learning
policy on a stacking task given a known object type, and then observe the
results of the agent attempting to stack various other objects based on the
same trained policy. By extracting embedding vectors from a convolutional
neural net trained over the results of the aforementioned stacking play, we can
determine the similarity of a given object to known object types, and determine
if the given object is likely dissimilar enough to the known types to be
considered a novel class of object. We present the results of this method on
two datasets gathered using two different policies and demonstrate what
information the agent needs to extract from its environment to make these
novelty judgments.",None,-1
210219ff-fe21-4d75-9c75-db0795fa686c,Does BERT really agree ? Fine-grained Analysis of Lexical Dependence on a Syntactic Task,0.676742,"Although transformer-based Neural Language Models demonstrate impressive
performance on a variety of tasks, their generalization abilities are not well
understood. They have been shown to perform strongly on subject-verb number
agreement in a wide array of settings, suggesting that they learned to track
syntactic dependencies during their training even without explicit supervision.
In this paper, we examine the extent to which BERT is able to perform
lexically-independent subject-verb number agreement (NA) on targeted syntactic
templates. To do so, we disrupt the lexical patterns found in naturally
occurring stimuli for each targeted structure in a novel fine-grained analysis
of BERT's behavior. Our results on nonce sentences suggest that the model
generalizes well for simple templates, but fails to perform
lexically-independent syntactic generalization when as little as one attractor
is present.",https://github.com/karimlasri/does-bert-really-agree,8215
bb1d6353-0682-49a8-bc3d-bd6ecc831d09,TimeLMs: Diachronic Language Models from Twitter,0.849355,"Despite its importance, the time variable has been largely neglected in the
NLP and language model literature. In this paper, we present TimeLMs, a set of
language models specialized on diachronic Twitter data. We show that a
continual learning strategy contributes to enhancing Twitter-based language
models' capacity to deal with future and out-of-distribution tweets, while
making them competitive with standardized and more monolithic benchmarks. We
also perform a number of qualitative analyses showing how they cope with trends
and peaks in activity involving specific named entities or concept drift.",https://github.com/cardiffnlp/timelms,-1
6409863a-4b7f-47b2-8ccf-bc70e25368a2,Real-time Full-stack Traffic Scene Perception for Autonomous Driving with Roadside Cameras,0.906484,"We propose a novel and pragmatic framework for traffic scene perception with
roadside cameras. The proposed framework covers a full-stack of roadside
perception pipeline for infrastructure-assisted autonomous driving, including
object detection, object localization, object tracking, and multi-camera
information fusion. Unlike previous vision-based perception frameworks rely
upon depth offset or 3D annotation at training, we adopt a modular decoupling
design and introduce a landmark-based 3D localization method, where the
detection and localization can be well decoupled so that the model can be
easily trained based on only 2D annotations. The proposed framework applies to
either optical or thermal cameras with pinhole or fish-eye lenses. Our
framework is deployed at a two-lane roundabout located at Ellsworth Rd. and
State St., Ann Arbor, MI, USA, providing 7x24 real-time traffic flow monitoring
and high-precision vehicle trajectory extraction. The whole system runs
efficiently on a low-power edge computing device with all-component end-to-end
delay of less than 20ms.",None,-1
2a3eedc4-2127-4141-aef4-13c69cc12a43,Enhanced Vehicle Re-identification for ITS: A Feature Fusion approach using Deep Learning,0.12148,"In recent years, the development of robust Intelligent transportation systems
(ITS) is tackled across the globe to provide better traffic efficiency by
reducing frequent traffic problems. As an application of ITS, vehicle
re-identification has gained ample interest in the domain of computer vision
and robotics. Convolutional neural network (CNN) based methods are developed to
perform vehicle re-identification to address key challenges such as occlusion,
illumination change, scale, etc. The advancement of transformers in computer
vision has opened an opportunity to explore the re-identification process
further to enhance performance. In this paper, a framework is developed to
perform the re-identification of vehicles across CCTV cameras. To perform
re-identification, the proposed framework fuses the vehicle representation
learned using a CNN and a transformer model. The framework is tested on a
dataset that contains 81 unique vehicle identities observed across 20 CCTV
cameras. From the experiments, the fused vehicle re-identification framework
yields an mAP of 61.73% which is significantly better when compared with the
standalone CNN or transformer model.",None,2569
859d0b23-d0fd-4c32-9f84-c8416864fbd2,Word Order Matters when you Increase Masking,0.523553,"Word order, an essential property of natural languages, is injected in
Transformer-based neural language models using position encoding. However,
recent experiments have shown that explicit position encoding is not always
useful, since some models without such feature managed to achieve state-of-the
art performance on some tasks. To understand better this phenomenon, we examine
the effect of removing position encodings on the pre-training objective itself
(i.e., masked language modelling), to test whether models can reconstruct
position information from co-occurrences alone. We do so by controlling the
amount of masked tokens in the input sentence, as a proxy to affect the
importance of position information for the task. We find that the necessity of
position information increases with the amount of masking, and that masked
language models without position encodings are not able to reconstruct this
information on the task. These findings point towards a direct relationship
between the amount of masking and the ability of Transformers to capture
order-sensitive aspects of language using position encoding.",https://github.com/rycolab/artificial-languages,-1
d2237030-83fd-4c0e-9a30-3bae5ec14887,Quantitative AI Risk Assessments: Opportunities and Challenges,0.768873,"Although AI-based systems are increasingly being leveraged to provide value
to organizations, individuals, and society, significant attendant risks have
been identified. These risks have led to proposed regulations, litigation, and
general societal concerns.
  As with any promising technology, organizations want to benefit from the
positive capabilities of AI technology while reducing the risks. The best way
to reduce risks is to implement comprehensive AI lifecycle governance where
policies and procedures are described and enforced during the design,
development, deployment, and monitoring of an AI system. While support for
comprehensive governance is beginning to emerge, organizations often need to
identify the risks of deploying an already-built model without knowledge of how
it was constructed or access to its original developers.
  Such an assessment will quantitatively assess the risks of an existing model
in a manner analogous to how a home inspector might assess the energy
efficiency of an already-built home or a physician might assess overall patient
health based on a battery of tests. This paper explores the concept of a
quantitative AI Risk Assessment, exploring the opportunities, challenges, and
potential impacts of such an approach, and discussing how it might improve AI
regulations.",None,-1
335bfdb7-df7d-492b-a80b-eb700742ea44,"Markov categories, causal theories, and the do-calculus",0.07146,"We give a category-theoretic treatment of causal models that formalizes the
syntax for causal reasoning over a directed acyclic graph (DAG) by associating
a free Markov category with the DAG in a canonical way. This framework enables
us to define and study important concepts in causal reasoning from an abstract
and ""purely causal"" point of view, such as causal independence/separation,
causal conditionals, and decomposition of intervention effects. Our results
regarding these concepts abstract away from the details of the commonly adopted
causal models such as (recursive) structural equation models or causal Bayesian
networks. They are therefore more widely applicable and in a way conceptually
clearer. Our results are also intimately related to Judea Pearl's celebrated
do-calculus, and yield a syntactic version of a core part of the calculus that
is inherited in all causal models. In particular, it induces a simpler and
specialized version of Pearl's do-calculus in the context of causal Bayesian
networks, which we show is as strong as the full version.",None,-1
6188c9b1-2a5f-48b8-a17e-f3e10358fed0,FusionVAE: A Deep Hierarchical Variational Autoencoder for RGB Image Fusion,0.069257,"Sensor fusion can significantly improve the performance of many computer
vision tasks. However, traditional fusion approaches are either not data-driven
and cannot exploit prior knowledge nor find regularities in a given dataset or
they are restricted to a single application. We overcome this shortcoming by
presenting a novel deep hierarchical variational autoencoder called FusionVAE
that can serve as a basis for many fusion tasks. Our approach is able to
generate diverse image samples that are conditioned on multiple noisy,
occluded, or only partially visible input images. We derive and optimize a
variational lower bound for the conditional log-likelihood of FusionVAE. In
order to assess the fusion capabilities of our model thoroughly, we created
three novel datasets for image fusion based on popular computer vision
datasets. In our experiments, we show that FusionVAE learns a representation of
aggregated information that is relevant to fusion tasks. The results
demonstrate that our approach outperforms traditional methods significantly.
Furthermore, we present the advantages and disadvantages of different design
choices.",None,-1
e59dcaaf-6ecc-4ad6-baed-f03e2ed103df,Dual-Scale Single Image Dehazing Via Neural Augmentation,0.927653,"Model-based single image dehazing algorithms restore haze-free images with
sharp edges and rich details for real-world hazy images at the expense of low
PSNR and SSIM values for synthetic hazy images. Data-driven ones restore
haze-free images with high PSNR and SSIM values for synthetic hazy images but
with low contrast, and even some remaining haze for real world hazy images. In
this paper, a novel single image dehazing algorithm is introduced by combining
model-based and data-driven approaches. Both transmission map and atmospheric
light are first estimated by the model-based methods, and then refined by
dual-scale generative adversarial networks (GANs) based approaches. The
resultant algorithm forms a neural augmentation which converges very fast while
the corresponding data-driven approach might not converge. Haze-free images are
restored by using the estimated transmission map and atmospheric light as well
as the Koschmiederlaw. Experimental results indicate that the proposed
algorithm can remove haze well from real-world and synthetic hazy images.",None,-1
6d352eed-75eb-482c-a1f8-f9b7c5c0560b,Perceiver-VL: Efficient Vision-and-Language Modeling with Iterative Latent Attention,0.110867,"We present Perceiver-VL, a vision-and-language framework that efficiently
handles high-dimensional multimodal inputs such as long videos and text.
Powered by the iterative latent cross-attention of Perceiver, our framework
scales with linear complexity, in contrast to the quadratic complexity of
self-attention used in many state-of-the-art transformer-based models. To
further improve the efficiency of our framework, we also study applying
LayerDrop on cross-attention layers and introduce a mixed-stream architecture
for cross-modal retrieval. We evaluate Perceiver-VL on diverse video-text and
image-text benchmarks, where Perceiver-VL achieves the lowest GFLOPs and
latency while maintaining competitive performance. In addition, we also provide
comprehensive analyses of various aspects of our framework, including
pretraining data, scalability of latent size and input size, dropping
cross-attention layers at inference to reduce latency, modality aggregation
strategy, positional encoding, and weight initialization strategy. Our code and
checkpoints are available at: https://github.com/zinengtang/Perceiver_VL",https://github.com/zinengtang/Perceiver_VL,-1
05f4d825-0879-46a9-82df-dc7b378f9830,On the Evaluation of Answer-Agnostic Paragraph-level Multi-Question Generation,0.0283878,"We study the task of predicting a set of salient questions from a given
paragraph without any prior knowledge of the precise answer. We make two main
contributions. First, we propose a new method to evaluate a set of predicted
questions against the set of references by using the Hungarian algorithm to
assign predicted questions to references before scoring the assigned pairs. We
show that our proposed evaluation strategy has better theoretical and practical
properties compared to prior methods because it can properly account for the
coverage of references. Second, we compare different strategies to utilize a
pre-trained seq2seq model to generate and select a set of questions related to
a given paragraph. The code is available.",https://github.com/JRC1995/QuestionGenerationPub,-1
9c9b153b-caa5-4ee0-aad5-6da8ea046e4d,Symlink: A New Dataset for Scientific Symbol-Description Linking,0.584314,"Mathematical symbols and descriptions appear in various forms across document
section boundaries without explicit markup. In this paper, we present a new
large-scale dataset that emphasizes extracting symbols and descriptions in
scientific documents. Symlink annotates scientific papers of 5 different
domains (i.e., computer science, biology, physics, mathematics, and economics).
Our experiments on Symlink demonstrate the challenges of the symbol-description
linking task for existing models and call for further research effort in this
area. We will publicly release Symlink to facilitate future research.",None,-1
87a06c61-3363-4490-81e3-12413e7fc893,Learning Semantics for Visual Place Recognition through Multi-Scale Attention,0.279395,"In this paper we address the task of visual place recognition (VPR), where
the goal is to retrieve the correct GPS coordinates of a given query image
against a huge geotagged gallery. While recent works have shown that building
descriptors incorporating semantic and appearance information is beneficial,
current state-of-the-art methods opt for a top down definition of the
significant semantic content. Here we present the first VPR algorithm that
learns robust global embeddings from both visual appearance and semantic
content of the data, with the segmentation process being dynamically guided by
the recognition of places through a multi-scale attention module. Experiments
on various scenarios validate this new approach and demonstrate its performance
against state-of-the-art methods. Finally, we propose the first synthetic-world
dataset suited for both place recognition and segmentation tasks.",None,-1
8a1104d4-4357-4a8d-b626-53344f8f5735,Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning,0.798955,"Prompt learning approaches have made waves in natural language processing by
inducing better few-shot performance while they still follow a parametric-based
learning paradigm; the oblivion and rote memorization problems in learning may
encounter unstable generalization issues. Specifically, vanilla prompt learning
may struggle to utilize atypical instances by rote during fully-supervised
training or overfit shallow patterns with low-shot data. To alleviate such
limitations, we develop RetroPrompt with the motivation of decoupling knowledge
from memorization to help the model strike a balance between generalization and
memorization. In contrast with vanilla prompt learning, RetroPrompt constructs
an open-book knowledge-store from training instances and implements a retrieval
mechanism during the process of input, training and inference, thus equipping
the model with the ability to retrieve related contexts from the training
corpus as cues for enhancement. Extensive experiments demonstrate that
RetroPrompt can obtain better performance in both few-shot and zero-shot
settings. Besides, we further illustrate that our proposed RetroPrompt can
yield better generalization abilities with new datasets. Detailed analysis of
memorization indeed reveals RetroPrompt can reduce the reliance of language
models on memorization; thus, improving generalization for downstream tasks.
Code is available in
https://github.com/zjunlp/PromptKG/tree/main/research/RetroPrompt.",https://github.com/zjunlp/PromptKG/tree/main/research/RetroPrompt,-1
5c9b6ccf-c6cc-4a46-b3b8-56f7d77ac997,SVL-Adapter: Self-Supervised Adapter for Vision-Language Pretrained Models,0.58979,"Vision-language models such as CLIP are pretrained on large volumes of
internet sourced image and text pairs, and have been shown to sometimes exhibit
impressive zero- and low-shot image classification performance. However, due to
their size, fine-tuning these models on new datasets can be prohibitively
expensive, both in terms of the supervision and compute required. To combat
this, a series of light-weight adaptation methods have been proposed to
efficiently adapt such models when limited supervision is available. In this
work, we show that while effective on internet-style datasets, even those
remedies under-deliver on classification tasks with images that differ
significantly from those commonly found online. To address this issue, we
present a new approach called SVL-Adapter that combines the complementary
strengths of both vision-language pretraining and self-supervised
representation learning. We report an average classification accuracy
improvement of 10% in the low-shot setting when compared to existing methods,
on a set of challenging visual classification tasks. Further, we present a
fully automatic way of selecting an important blending hyperparameter for our
model that does not require any held-out labeled validation data. Code for our
project is available here: https://github.com/omipan/svl_adapter.",https://github.com/omipan/svl_adapter,-1
d4269711-d940-4753-9d2b-f6c02d39edb6,Deep Learning for Short-term Instant Energy Consumption Forecasting in the Manufacturing Sector,0.169021,"Electricity is a volatile power source that requires great planning and
resource management for both short and long term. More specifically, in the
short-term, accurate instant energy consumption forecasting contributes greatly
to improve the efficiency of buildings, opening new avenues for the adoption of
renewable energy. In that regard, data-driven approaches, namely the ones based
on machine learning, are begin to be preferred over more traditional ones since
they provide not only more simplified ways of deployment but also state of the
art results. In that sense, this work applies and compares the performance of
several deep learning algorithms, LSTM, CNN, mixed CNN-LSTM and TCN, in a real
testbed within the manufacturing sector. The experimental results suggest that
the TCN is the most reliable method for predicting instant energy consumption
in the short-term.",None,-1
b4e37f5e-e6ea-4e3a-9cb9-0e4542ee85ca,A2: Efficient Automated Attacker for Boosting Adversarial Training,0.448265,"Based on the significant improvement of model robustness by AT (Adversarial
Training), various variants have been proposed to further boost the
performance. Well-recognized methods have focused on different components of AT
(e.g., designing loss functions and leveraging additional unlabeled data). It
is generally accepted that stronger perturbations yield more robust models.
However, how to generate stronger perturbations efficiently is still missed. In
this paper, we propose an efficient automated attacker called A2 to boost AT by
generating the optimal perturbations on-the-fly during training. A2 is a
parameterized automated attacker to search in the attacker space for the best
attacker against the defense model and examples. Extensive experiments across
different datasets demonstrate that A2 generates stronger perturbations with
low extra cost and reliably improves the robustness of various AT methods
against different attacks.",https://github.com/huyvnphan/PyTorch_CIFAR10,-1
d3563bed-29b3-49c2-8b1a-1c9f13c6700a,AmsterTime: A Visual Place Recognition Benchmark Dataset for Severe Domain Shift,0.221109,"We introduce AmsterTime: a challenging dataset to benchmark visual place
recognition (VPR) in presence of a severe domain shift. AmsterTime offers a
collection of 2,500 well-curated images matching the same scene from a street
view matched to historical archival image data from Amsterdam city. The image
pairs capture the same place with different cameras, viewpoints, and
appearances. Unlike existing benchmark datasets, AmsterTime is directly
crowdsourced in a GIS navigation platform (Mapillary). We evaluate various
baselines, including non-learning, supervised and self-supervised methods,
pre-trained on different relevant datasets, for both verification and retrieval
tasks. Our result credits the best accuracy to the ResNet-101 model pre-trained
on the Landmarks dataset for both verification and retrieval tasks by 84% and
24%, respectively. Additionally, a subset of Amsterdam landmarks is collected
for feature evaluation in a classification task. Classification labels are
further used to extract the visual explanations using Grad-CAM for inspection
of the learned similar visuals in a deep metric learning models.",https://github.com/seyrankhademi/AmsterTime,-1
996e4b89-85ad-49bf-9ee3-d8679cbfd8ea,Academic Resource Text Level Multi-label Classification based on Attention,0.0364364,"Hierarchical multi-label academic text classification (HMTC) is to assign
academic texts into a hierarchically structured labeling system. We propose an
attention-based hierarchical multi-label classification algorithm of academic
texts (AHMCA) by integrating features such as text, keywords, and hierarchical
structure, the academic documents are classified into the most relevant
categories. We utilize word2vec and BiLSTM to obtain embedding and latent
vector representations of text, keywords, and hierarchies. We use hierarchical
attention mechanism to capture the associations between keywords, label
hierarchies, and text word vectors to generate hierarchical-specific document
embedding vectors to replace the original text embeddings in HMCN-F. The
experimental results on the academic text dataset demonstrate the effectiveness
of the AHMCA algorithm.",None,-1
1b912c64-2fd8-43d5-85ae-c7a35c299517,CoHS-CQG: Context and History Selection for Conversational Question Generation,0.348421,"Conversational question generation (CQG) serves as a vital task for machines
to assist humans, such as interactive reading comprehension, through
conversations. Compared to traditional single-turn question generation (SQG),
CQG is more challenging in the sense that the generated question is required
not only to be meaningful, but also to align with the occurred conversation
history. While previous studies mainly focus on how to model the flow and
alignment of the conversation, there has been no thorough study to date on
which parts of the context and history are necessary for the model. We argue
that shortening the context and history is crucial as it can help the model to
optimise more on the conversational alignment property. To this end, we propose
CoHS-CQG, a two-stage CQG framework, which adopts a CoHS module to shorten the
context and history of the input. In particular, CoHS selects contiguous
sentences and history turns according to their relevance scores by a top-p
strategy. Our model achieves state-of-the-art performances on CoQA in both the
answer-aware and answer-unaware settings.",https://github.com/dxlong2000/CoHS-CQG,11730
c4535629-251a-4034-8b56-54f7c00b4e34,Controlled Language Generation for Language Learning Items,0.0551641,"This work aims to employ natural language generation (NLG) to rapidly
generate items for English language learning applications: this requires both
language models capable of generating fluent, high-quality English, and to
control the output of the generation to match the requirements of the relevant
items. We experiment with deep pretrained models for this task, developing
novel methods for controlling items for factors relevant in language learning:
diverse sentences for different proficiency levels and argument structure to
test grammar. Human evaluation demonstrates high grammatically scores for all
models (3.4 and above out of 4), and higher length (24%) and complexity (9%)
over the baseline for the advanced proficiency model. Our results show that we
can achieve strong performance while adding additional control to ensure
diverse, tailored content for individual users.",https://github.com/EducationalTestingService/concept-control-gen,-1
9501737a-b4b5-453e-be78-67224436afaf,Self-Supervision Can Be a Good Few-Shot Learner,0.756771,"Existing few-shot learning (FSL) methods rely on training with a large
labeled dataset, which prevents them from leveraging abundant unlabeled data.
From an information-theoretic perspective, we propose an effective unsupervised
FSL method, learning representations with self-supervision. Following the
InfoMax principle, our method learns comprehensive representations by capturing
the intrinsic structure of the data. Specifically, we maximize the mutual
information (MI) of instances and their representations with a low-bias MI
estimator to perform self-supervised pre-training. Rather than supervised
pre-training focusing on the discriminable features of the seen classes, our
self-supervised model has less bias toward the seen classes, resulting in
better generalization for unseen classes. We explain that supervised
pre-training and self-supervised pre-training are actually maximizing different
MI objectives. Extensive experiments are further conducted to analyze their FSL
performance with various training settings. Surprisingly, the results show that
self-supervised pre-training can outperform supervised pre-training under the
appropriate conditions. Compared with state-of-the-art FSL methods, our
approach achieves comparable performance on widely used FSL benchmarks without
any labels of the base classes.",None,-1
67297abf-94f6-4f5d-8218-8a941546748b,WATCH: Wasserstein Change Point Detection for High-Dimensional Time Series Data,0.458342,"Detecting relevant changes in dynamic time series data in a timely manner is
crucially important for many data analysis tasks in real-world settings. Change
point detection methods have the ability to discover changes in an unsupervised
fashion, which represents a desirable property in the analysis of unbounded and
unlabeled data streams. However, one limitation of most of the existing
approaches is represented by their limited ability to handle multivariate and
high-dimensional data, which is frequently observed in modern applications such
as traffic flow prediction, human activity recognition, and smart grids
monitoring. In this paper, we attempt to fill this gap by proposing WATCH, a
novel Wasserstein distance-based change point detection approach that models an
initial distribution and monitors its behavior while processing new data
points, providing accurate and robust detection of change points in dynamic
high-dimensional data. An extensive experimental evaluation involving a large
number of benchmark datasets shows that WATCH is capable of accurately
identifying change points and outperforming state-of-the-art methods.",None,-1
0551bcd2-aa86-4d9d-9370-5d53c5dee033,UC-OWOD: Unknown-Classified Open World Object Detection,0.879053,"Open World Object Detection (OWOD) is a challenging computer vision problem
that requires detecting unknown objects and gradually learning the identified
unknown classes. However, it cannot distinguish unknown instances as multiple
unknown classes. In this work, we propose a novel OWOD problem called
Unknown-Classified Open World Object Detection (UC-OWOD). UC-OWOD aims to
detect unknown instances and classify them into different unknown classes.
Besides, we formulate the problem and devise a two-stage object detector to
solve UC-OWOD. First, unknown label-aware proposal and unknown-discriminative
classification head are used to detect known and unknown objects. Then,
similarity-based unknown classification and unknown clustering refinement
modules are constructed to distinguish multiple unknown classes. Moreover, two
novel evaluation protocols are designed to evaluate unknown-class detection.
Abundant experiments and visualizations prove the effectiveness of the proposed
method. Code is available at https://github.com/JohnWuzh/UC-OWOD.",https://github.com/JohnWuzh/UC-OWOD,11164
5e7d80ab-bef2-4ab8-a604-b0cb8a1faee7,Towards Climate Awareness in NLP Research,0.669303,"The climate impact of AI, and NLP research in particular, has become a
serious issue given the enormous amount of energy that is increasingly being
used for training and running computational models. Consequently, increasing
focus is placed on efficient NLP. However, this important initiative lacks
simple guidelines that would allow for systematic climate reporting of NLP
research. We argue that this deficiency is one of the reasons why very few
publications in NLP report key figures that would allow a more thorough
examination of environmental impact. As a remedy, we propose a climate
performance model card with the primary purpose of being practically usable
with only limited information about experiments and the underlying computer
hardware. We describe why this step is essential to increase awareness about
the environmental impact of NLP research and, thereby, paving the way for more
thorough discussions.",https://github.com/danielhers/climate-awareness-nlp,-1
d7666ed0-11f1-41bc-b911-717d4a678fa7,Hybrid Multimodal Fusion for Humor Detection,0.675339,"In this paper, we present our solution to the MuSe-Humor sub-challenge of the
Multimodal Emotional Challenge (MuSe) 2022. The goal of the MuSe-Humor
sub-challenge is to detect humor and calculate AUC from audiovisual recordings
of German football Bundesliga press conferences. It is annotated for humor
displayed by the coaches. For this sub-challenge, we first build a discriminant
model using the transformer module and BiLSTM module, and then propose a hybrid
fusion strategy to use the prediction results of each modality to improve the
performance of the model. Our experiments demonstrate the effectiveness of our
proposed model and hybrid fusion strategy on multimodal fusion, and the AUC of
our proposed model on the test set is 0.8972.",None,-1
8a656159-9904-423b-841e-b3be00cb66d5,Domain Adaptation in Neural Machine Translation using a Qualia-Enriched FrameNet,0.0875263,"In this paper we present Scylla, a methodology for domain adaptation of
Neural Machine Translation (NMT) systems that make use of a multilingual
FrameNet enriched with qualia relations as an external knowledge base. Domain
adaptation techniques used in NMT usually require fine-tuning and in-domain
training data, which may pose difficulties for those working with
lesser-resourced languages and may also lead to performance decay of the NMT
system for out-of-domain sentences. Scylla does not require fine-tuning of the
NMT model, avoiding the risk of model over-fitting and consequent decrease in
performance for out-of-domain translations. Two versions of Scylla are
presented: one using the source sentence as input, and another one using the
target sentence. We evaluate Scylla in comparison to a state-of-the-art
commercial NMT system in an experiment in which 50 sentences from the Sports
domain are translated from Brazilian Portuguese to English. The two versions of
Scylla significantly outperform the baseline commercial system in HTER.",https://github.com/FrameNetBrasil/scylla_lr,-1
67030e47-61b2-480a-a048-698300836d82,Counterfactual Explanations for Predictive Business Process Monitoring,0.890314,"Predictive business process monitoring increasingly leverages sophisticated
prediction models. Although sophisticated models achieve consistently higher
prediction accuracy than simple models, one major drawback is their lack of
interpretability, which limits their adoption in practice. We thus see growing
interest in explainable predictive business process monitoring, which aims to
increase the interpretability of prediction models. Existing solutions focus on
giving factual explanations.While factual explanations can be helpful, humans
typically do not ask why a particular prediction was made, but rather why it
was made instead of another prediction, i.e., humans are interested in
counterfactual explanations. While research in explainable AI produced several
promising techniques to generate counterfactual explanations, directly applying
them to predictive process monitoring may deliver unrealistic explanations,
because they ignore the underlying process constraints. We propose LORELEY, a
counterfactual explanation technique for predictive process monitoring, which
extends LORE, a recent explainable AI technique. We impose control flow
constraints to the explanation generation process to ensure realistic
counterfactual explanations. Moreover, we extend LORE to enable explaining
multi-class classification models. Experimental results using a real, public
dataset indicate that LORELEY can approximate the prediction models with an
average fidelity of 97.69\% and generate realistic counterfactual explanations.",https://git.uni-due.de/adi645f/cf4bpm-artifacts,-1
36675047-8f65-416c-988a-da447ff2dc73,A Data-Driven Slip Estimation Approach for Effective Braking Control under Varying Road Conditions,0.0390671,"The performances of braking control systems for robotic platforms, e.g.,
assisted and autonomous vehicles, airplanes and drones, are deeply influenced
by the road-tire friction experienced during the maneuver. Therefore, the
availability of accurate estimation algorithms is of major importance in the
development of advanced control schemes. The focus of this paper is on the
estimation problem. In particular, a novel estimation algorithm is proposed,
based on a multi-layer neural network. The training is based on a synthetic
data set, derived from a widely used friction model. The open loop performances
of the proposed algorithm are evaluated in a number of simulated scenarios.
Moreover, different control schemes are used to test the closed loop scenario,
where the estimated optimal slip is used as the set-point. The experimental
results and the comparison with a model based baseline show that the proposed
approach can provide an effective best slip estimation.",None,-1
94f8bccf-6883-4863-a56b-97f35010bdc8,Multimodal Hate Speech Detection from Bengali Memes and Texts,0.888433,"Numerous machine learning (ML) and deep learning (DL)-based approaches have
been proposed to utilize textual data from social media for anti-social
behavior analysis like cyberbullying, fake news detection, and identification
of hate speech mainly for highly-resourced languages such as English. However,
despite having a lot of diversity and millions of native speakers, some
languages like Bengali are under-resourced, which is due to a lack of
computational resources for natural language processing (NLP). Similar to other
languages, Bengali social media contents also include images along with texts
(e.g., multimodal memes are posted by embedding short texts into images on
Facebook). Therefore, only the textual data is not enough to judge them since
images might give extra context to make a proper judgement. This paper is about
hate speech detection from multimodal Bengali memes and texts. We prepared the
only multimodal hate speech dataset for-a-kind of problem for Bengali, which we
use to train state-of-the-art neural architectures (e.g., Bi-LSTM/Conv-LSTM
with word embeddings, ConvNets + pre-trained language models, e.g., monolingual
Bangla BERT, multilingual BERT-cased/uncased, and XLM-RoBERTa) to jointly
analyze textual and visual information for hate speech detection. Conv-LSTM and
XLM-RoBERTa models performed best for texts, yielding F1 scores of 0.78 and
0.82, respectively. As of memes, ResNet-152 and DenseNet-161 models yield F1
scores of 0.78 and 0.79, respectively. As for multimodal fusion, XLM-RoBERTa +
DenseNet-161 performed the best, yielding an F1 score of 0.83. Our study
suggests that text modality is most useful for hate speech detection, while
memes are moderately useful.",https://github.com/rezacsedu/Multimodal-Hate-Speech-Bengali,-1
bfc2a81f-e675-4f1c-9d34-4cddcb0ac2aa,Concept Bottleneck Model with Additional Unsupervised Concepts,0.645908,"With the increasing demands for accountability, interpretability is becoming
an essential capability for real-world AI applications. However, most methods
utilize post-hoc approaches rather than training the interpretable model. In
this article, we propose a novel interpretable model based on the concept
bottleneck model (CBM). CBM uses concept labels to train an intermediate layer
as the additional visible layer. However, because the number of concept labels
restricts the dimension of this layer, it is difficult to obtain high accuracy
with a small number of labels. To address this issue, we integrate supervised
concepts with unsupervised ones trained with self-explaining neural networks
(SENNs). By seamlessly training these two types of concepts while reducing the
amount of computation, we can obtain both supervised and unsupervised concepts
simultaneously, even for large-sized images. We refer to the proposed model as
the concept bottleneck model with additional unsupervised concepts (CBM-AUC).
We experimentally confirmed that the proposed model outperformed CBM and SENN.
We also visualized the saliency map of each concept and confirmed that it was
consistent with the semantic meanings.",https://github.com/yewsiang/ConceptBottleneck,-1
80a78edc-f676-4de2-8a1d-f6c484dab13d,IDEAL: Improved DEnse locAL Contrastive Learning for Semi-Supervised Medical Image Segmentation,0.219909,"Due to the scarcity of labeled data, Contrastive Self-Supervised Learning
(SSL) frameworks have lately shown great potential in several medical image
analysis tasks. However, the existing contrastive mechanisms are sub-optimal
for dense pixel-level segmentation tasks due to their inability to mine local
features. To this end, we extend the concept of metric learning to the
segmentation task, using a dense (dis)similarity learning for pre-training a
deep encoder network, and employing a semi-supervised paradigm to fine-tune for
the downstream task. Specifically, we propose a simple convolutional projection
head for obtaining dense pixel-level features, and a new contrastive loss to
utilize these dense projections thereby improving the local representations. A
bidirectional consistency regularization mechanism involving two-stream model
training is devised for the downstream task. Upon comparison, our IDEAL method
outperforms the SoTA methods by fair margins on cardiac MRI segmentation. Code
available: https://github.com/hritam-98/IDEAL-ICASSP23",https://github.com/Rohit-Kundu/IDEAL-ICASSP23,-1
da084bc5-97e3-495d-9650-2d47c0188c2c,Concentration Network for Reinforcement Learning of Large-Scale Multi-Agent Systems,0.468815,"When dealing with a series of imminent issues, humans can naturally
concentrate on a subset of these concerning issues by prioritizing them
according to their contributions to motivational indices, e.g., the probability
of winning a game. This idea of concentration offers insights into
reinforcement learning of sophisticated Large-scale Multi-Agent Systems (LMAS)
participated by hundreds of agents. In such an LMAS, each agent receives a long
series of entity observations at each step, which can overwhelm existing
aggregation networks such as graph attention networks and cause inefficiency.
In this paper, we propose a concentration network called ConcNet. First,
ConcNet scores the observed entities considering several motivational indices,
e.g., expected survival time and state value of the agents, and then ranks,
prunes, and aggregates the encodings of observed entities to extract features.
Second, distinct from the well-known attention mechanism, ConcNet has a unique
motivational subnetwork to explicitly consider the motivational indices when
scoring the observed entities. Furthermore, we present a concentration policy
gradient architecture that can learn effective policies in LMAS from scratch.
Extensive experiments demonstrate that the presented architecture has excellent
scalability and flexibility, and significantly outperforms existing methods on
LMAS benchmarks.",https://github.com/binary-husky/hmp2g/tree/aaai-conc,-1
2b7b6efc-2deb-45f7-83e6-566d4a99ec9e,"When classifying grammatical role, BERT doesn't care about word order... except when it matters",0.742317,"Because meaning can often be inferred from lexical semantics alone, word
order is often a redundant cue in natural language. For example, the words
chopped, chef, and onion are more likely used to convey ""The chef chopped the
onion,"" not ""The onion chopped the chef."" Recent work has shown large language
models to be surprisingly word order invariant, but crucially has largely
considered natural prototypical inputs, where compositional meaning mostly
matches lexical expectations. To overcome this confound, we probe grammatical
role representation in English BERT and GPT-2, on instances where lexical
expectations are not sufficient, and word order knowledge is necessary for
correct classification. Such non-prototypical instances are naturally occurring
English sentences with inanimate subjects or animate objects, or sentences
where we systematically swap the arguments to make sentences like ""The onion
chopped the chef"". We find that, while early layer embeddings are largely
lexical, word order is in fact crucial in defining the later-layer
representations of words in semantically non-prototypical positions. Our
experiments isolate the effect of word order on the contextualization process,
and highlight how models use context in the uncommon, but critical, instances
where it matters.",https://github.com/toizzy/except-when-it-matters,4825
016ae676-d168-48c1-918b-8210cbdc35af,Controllable Dynamic Multi-Task Architectures,0.549198,"Multi-task learning commonly encounters competition for resources among
tasks, specifically when model capacity is limited. This challenge motivates
models which allow control over the relative importance of tasks and total
compute cost during inference time. In this work, we propose such a
controllable multi-task network that dynamically adjusts its architecture and
weights to match the desired task preference as well as the resource
constraints. In contrast to the existing dynamic multi-task approaches that
adjust only the weights within a fixed architecture, our approach affords the
flexibility to dynamically control the total computational cost and match the
user-preferred task importance better. We propose a disentangled training of
two hypernetworks, by exploiting task affinity and a novel branching
regularized loss, to take input preferences and accordingly predict
tree-structured models with adapted weights. Experiments on three multi-task
benchmarks, namely PASCAL-Context, NYU-v2, and CIFAR-100, show the efficacy of
our approach. Project page is available at https://www.nec-labs.com/~mas/DYMU.",https://www.nec-labs.com/˜mas/DYMU,-1
04e67efb-b515-46cd-b589-73c4f399f698,InstaFormer: Instance-Aware Image-to-Image Translation with Transformer,0.885141,"We present a novel Transformer-based network architecture for instance-aware
image-to-image translation, dubbed InstaFormer, to effectively integrate
global- and instance-level information. By considering extracted content
features from an image as tokens, our networks discover global consensus of
content features by considering context information through a self-attention
module in Transformers. By augmenting such tokens with an instance-level
feature extracted from the content feature with respect to bounding box
information, our framework is capable of learning an interaction between object
instances and the global image, thus boosting the instance-awareness. We
replace layer normalization (LayerNorm) in standard Transformers with adaptive
instance normalization (AdaIN) to enable a multi-modal translation with style
codes. In addition, to improve the instance-awareness and translation quality
at object regions, we present an instance-level content contrastive loss
defined between input and translated image. We conduct experiments to
demonstrate the effectiveness of our InstaFormer over the latest methods and
provide extensive ablation studies.",None,-1
3dad7f7b-8e93-44bc-84f4-c45372f55947,Meta-Referential Games to Learn Compositional Learning Behaviours,0.0710019,"Human beings use compositionality to generalise from past experiences to
novel experiences. We assume a separation of our experiences into fundamental
atomic components that can be recombined in novel ways to support our ability
to engage with novel experiences. We frame this as the ability to learn to
generalise compositionally, and we will refer to behaviours making use of this
ability as compositional learning behaviours (CLBs). A central problem to
learning CLBs is the resolution of a binding problem (BP). While it is another
feat of intelligence that human beings perform with ease, it is not the case
for state-of-the-art artificial agents. Thus, in order to build artificial
agents able to collaborate with human beings, we propose to develop a novel
benchmark to investigate agents' abilities to exhibit CLBs by solving a
domain-agnostic version of the BP. We take inspiration from the language
emergence and grounding framework of referential games and propose a
meta-learning extension of referential games, entitled Meta-Referential Games,
and use this framework to build our benchmark, the Symbolic Behaviour Benchmark
(S2B). We provide baseline results and error analysis showing that our
benchmark is a compelling challenge that we hope will spur the research
community towards developing more capable artificial agents.",https://github.com/Near32/Regym/tree/develop/benchmark/R2D2/SymbolicBehaviourBenchmark,-1
9c50156d-ce8f-4763-97cf-7951231c8e6e,TableFormer: Robust Transformer Modeling for Table-Text Encoding,0.92446,"Understanding tables is an important aspect of natural language
understanding. Existing models for table understanding require linearization of
the table structure, where row or column order is encoded as an unwanted bias.
Such spurious biases make the model vulnerable to row and column order
perturbations. Additionally, prior work has not thoroughly modeled the table
structures or table-text alignments, hindering the table-text understanding
ability. In this work, we propose a robust and structurally aware table-text
encoding architecture TableFormer, where tabular structural biases are
incorporated completely through learnable attention biases. TableFormer is (1)
strictly invariant to row and column orders, and, (2) could understand tables
better due to its tabular inductive biases. Our evaluations showed that
TableFormer outperforms strong baselines in all settings on SQA, WTQ and
TabFact table reasoning datasets, and achieves state-of-the-art performance on
SQA, especially when facing answer-invariant row and column order perturbations
(6% improvement over the best baseline), because previous SOTA models'
performance drops by 4% - 6% when facing such perturbations while TableFormer
is not affected.",https://github.com/google-research/tapas/blob/master/TABLEFORMER.md,-1
97a33ed9-51f6-469f-981c-93e8b09e7016,VideoDex: Learning Dexterity from Internet Videos,0.842396,"To build general robotic agents that can operate in many environments, it is
often imperative for the robot to collect experience in the real world.
However, this is often not feasible due to safety, time, and hardware
restrictions. We thus propose leveraging the next best thing as real-world
experience: internet videos of humans using their hands. Visual priors, such as
visual features, are often learned from videos, but we believe that more
information from videos can be utilized as a stronger prior. We build a
learning algorithm, VideoDex, that leverages visual, action, and physical
priors from human video datasets to guide robot behavior. These actions and
physical priors in the neural network dictate the typical human behavior for a
particular robot task. We test our approach on a robot arm and dexterous
hand-based system and show strong results on various manipulation tasks,
outperforming various state-of-the-art methods. Videos at
https://video-dex.github.io",https://github.com/AGI-Labs/robot_baselines,-1
18c70acd-257c-4641-88e5-02821ed9ceff,FastClass: A Time-Efficient Approach to Weakly-Supervised Text Classification,0.118311,"Weakly-supervised text classification aims to train a classifier using only
class descriptions and unlabeled data. Recent research shows that
keyword-driven methods can achieve state-of-the-art performance on various
tasks. However, these methods not only rely on carefully-crafted class
descriptions to obtain class-specific keywords but also require substantial
amount of unlabeled data and takes a long time to train. This paper proposes
FastClass, an efficient weakly-supervised classification approach. It uses
dense text representation to retrieve class-relevant documents from external
unlabeled corpus and selects an optimal subset to train a classifier. Compared
to keyword-driven methods, our approach is less reliant on initial class
descriptions as it no longer needs to expand each class description into a set
of class-specific keywords. Experiments on a wide range of classification tasks
show that the proposed approach frequently outperforms keyword-driven models in
terms of classification accuracy and often enjoys orders-of-magnitude faster
training speed.",https://github.com/xiatingyu/FastClass,-1
92f7d906-54ec-41bc-98c6-caa9e37da69d,Federated Multilingual Models for Medical Transcript Analysis,0.191355,"Federated Learning (FL) is a novel machine learning approach that allows the
model trainer to access more data samples, by training the model across
multiple decentralized data sources, while data access constraints are in
place. Such trained models can achieve significantly higher performance beyond
what can be done when trained on a single data source. As part of FL's
promises, none of the training data is ever transmitted to any central
location, ensuring that sensitive data remains local and private. These
characteristics make FL perfectly suited for large-scale applications in
healthcare, where a variety of compliance constraints restrict how data may be
handled, processed, and stored. Despite the apparent benefits of federated
learning, the heterogeneity in the local data distributions pose significant
challenges, and such challenges are even more pronounced in the case of
multilingual data providers. In this paper we present a federated learning
system for training a large-scale multi-lingual model suitable for fine-tuning
on downstream tasks such as medical entity tagging. Our work represents one of
the first such production-scale systems, capable of training across multiple
highly heterogeneous data providers, and achieving levels of accuracy that
could not be otherwise achieved by using central training with public data.
Finally, we show that the global model performance can be further improved by a
training step performed locally.",https://github.com/Azure-Samples/azure-ml-federated-learning,-1
422bc89e-4fa2-4d48-98da-9c4e5f6d654a,Semantic Probabilistic Layers for Neuro-Symbolic Learning,0.98409,"We design a predictive layer for structured-output prediction (SOP) that can
be plugged into any neural network guaranteeing its predictions are consistent
with a set of predefined symbolic constraints. Our Semantic Probabilistic Layer
(SPL) can model intricate correlations, and hard constraints, over a structured
output space all while being amenable to end-to-end learning via maximum
likelihood. SPLs combine exact probabilistic inference with logical reasoning
in a clean and modular way, learning complex distributions and restricting
their support to solutions of the constraint. As such, they can faithfully, and
efficiently, model complex SOP tasks beyond the reach of alternative
neuro-symbolic approaches. We empirically demonstrate that SPLs outperform
these competitors in terms of accuracy on challenging SOP tasks including
hierarchical multi-label classification, pathfinding and preference learning,
while retaining perfect constraint satisfaction.",https://github.com/takemaru/graphillion,-1
a781c793-471c-48bf-a3ed-737f77890383,TokenFlow: Rethinking Fine-grained Cross-modal Alignment in Vision-Language Retrieval,0.0964232,"Most existing methods in vision-language retrieval match two modalities by
either comparing their global feature vectors which misses sufficient
information and lacks interpretability, detecting objects in images or videos
and aligning the text with fine-grained features which relies on complicated
model designs, or modeling fine-grained interaction via cross-attention upon
visual and textual tokens which suffers from inferior efficiency. To address
these limitations, some recent works simply aggregate the token-wise
similarities to achieve fine-grained alignment, but they lack intuitive
explanations as well as neglect the relationships between token-level features
and global representations with high-level semantics. In this work, we rethink
fine-grained cross-modal alignment and devise a new model-agnostic formulation
for it. We additionally demystify the recent popular works and subsume them
into our scheme. Furthermore, inspired by optimal transport theory, we
introduce TokenFlow, an instantiation of the proposed scheme. By modifying only
the similarity function, the performance of our method is comparable to the
SoTA algorithms with heavy model designs on major video-text retrieval
benchmarks. The visualization further indicates that TokenFlow successfully
leverages the fine-grained information and achieves better interpretability.",None,-1
9c33ff9e-4b47-4d06-8654-2ec6d21b23c1,Entity Disambiguation with Entity Definitions,0.0779985,"Local models have recently attained astounding performances in Entity
Disambiguation (ED), with generative and extractive formulations being the most
promising research directions. However, previous works limited their studies to
using, as the textual representation of each candidate, only its Wikipedia
title. Although certainly effective, this strategy presents a few critical
issues, especially when titles are not sufficiently informative or
distinguishable from one another. In this paper, we address this limitation and
investigate to what extent more expressive textual representations can mitigate
it. We thoroughly evaluate our approach against standard benchmarks in ED and
find extractive formulations to be particularly well-suited to these
representations: we report a new state of the art on 2 out of 6 benchmarks we
consider and strongly improve the generalization capability over unseen
patterns. We release our code, data and model checkpoints at
https://github.com/SapienzaNLP/extend.",https://github.com/SapienzaNLP/extend,-1
e77e635c-ceeb-4dfc-88a6-8bc27b74adfb,An Anomaly Detection Method for Satellites Using Monte Carlo Dropout,0.539047,"Recently, there has been a significant amount of interest in satellite
telemetry anomaly detection (AD) using neural networks (NN). For AD purposes,
the current approaches focus on either forecasting or reconstruction of the
time series, and they cannot measure the level of reliability or the
probability of correct detection. Although the Bayesian neural network
(BNN)-based approaches are well known for time series uncertainty estimation,
they are computationally intractable. In this paper, we present a tractable
approximation for BNN based on the Monte Carlo (MC) dropout method for
capturing the uncertainty in the satellite telemetry time series, without
sacrificing accuracy. For time series forecasting, we employ an NN, which
consists of several Long Short-Term Memory (LSTM) layers followed by various
dense layers. We employ the MC dropout inside each LSTM layer and before the
dense layers for uncertainty estimation. With the proposed uncertainty region
and by utilizing a post-processing filter, we can effectively capture the
anomaly points. Numerical results show that our proposed time series AD
approach outperforms the existing methods from both prediction accuracy and AD
perspectives.",None,-1
53f916f7-8690-4005-b88f-a105e7cfc965,CoMER: Modeling Coverage for Transformer-based Handwritten Mathematical Expression Recognition,0.986571,"The Transformer-based encoder-decoder architecture has recently made
significant advances in recognizing handwritten mathematical expressions.
However, the transformer model still suffers from the lack of coverage problem,
making its expression recognition rate (ExpRate) inferior to its RNN
counterpart. Coverage information, which records the alignment information of
the past steps, has proven effective in the RNN models. In this paper, we
propose CoMER, a model that adopts the coverage information in the transformer
decoder. Specifically, we propose a novel Attention Refinement Module (ARM) to
refine the attention weights with past alignment information without hurting
its parallelism. Furthermore, we take coverage information to the extreme by
proposing self-coverage and cross-coverage, which utilize the past alignment
information from the current and previous layers. Experiments show that CoMER
improves the ExpRate by 0.61%/2.09%/1.59% compared to the current
state-of-the-art model, and reaches 59.33%/59.81%/62.97% on the CROHME
2014/2016/2019 test sets.",https://github.com/Green-Wood/CoMER,-1
07789a37-09d3-45d8-aef6-636c90f7f1d8,Dual Progressive Transformations for Weakly Supervised Semantic Segmentation,0.307241,"Weakly supervised semantic segmentation (WSSS), which aims to mine the object
regions by merely using class-level labels, is a challenging task in computer
vision. The current state-of-the-art CNN-based methods usually adopt
Class-Activation-Maps (CAMs) to highlight the potential areas of the object,
however, they may suffer from the part-activated issues. To this end, we try an
early attempt to explore the global feature attention mechanism of vision
transformer in WSSS task. However, since the transformer lacks the inductive
bias as in CNN models, it can not boost the performance directly and may yield
the over-activated problems. To tackle these drawbacks, we propose a
Convolutional Neural Networks Refined Transformer (CRT) to mine a globally
complete and locally accurate class activation maps in this paper. To validate
the effectiveness of our proposed method, extensive experiments are conducted
on PASCAL VOC 2012 and CUB-200-2011 datasets. Experimental evaluations show
that our proposed CRT achieves the new state-of-the-art performance on both the
weakly supervised semantic segmentation task the weakly supervised object
localization task, which outperform others by a large margin.",https://github.com/huodongjian0603/crt,5685
76241298-3e68-4c17-a43b-a0585f6758aa,Retrieval Augmentation for Commonsense Reasoning: A Unified Approach,0.448554,"A common thread of retrieval-augmented methods in the existing literature
focuses on retrieving encyclopedic knowledge, such as Wikipedia, which
facilitates well-defined entity and relation spaces that can be modeled.
However, applying such methods to commonsense reasoning tasks faces two unique
challenges, i.e., the lack of a general large-scale corpus for retrieval and a
corresponding effective commonsense retriever. In this paper, we systematically
investigate how to leverage commonsense knowledge retrieval to improve
commonsense reasoning tasks. We proposed a unified framework of
retrieval-augmented commonsense reasoning (called RACo), including a newly
constructed commonsense corpus with over 20 million documents and novel
strategies for training a commonsense retriever. We conducted experiments on
four different commonsense reasoning tasks. Extensive evaluation results showed
that our proposed RACo can significantly outperform other knowledge-enhanced
method counterparts, achieving new SoTA performance on the CommonGen and CREAK
leaderboards.",https://github.com/wyu97/RACo,-1
1deaecf4-defb-47eb-9df4-eafd4c0b278b,ReFinED: An Efficient Zero-shot-capable Approach to End-to-End Entity Linking,0.985847,"We introduce ReFinED, an efficient end-to-end entity linking model which uses
fine-grained entity types and entity descriptions to perform linking. The model
performs mention detection, fine-grained entity typing, and entity
disambiguation for all mentions within a document in a single forward pass,
making it more than 60 times faster than competitive existing approaches.
ReFinED also surpasses state-of-the-art performance on standard entity linking
datasets by an average of 3.7 F1. The model is capable of generalising to
large-scale knowledge bases such as Wikidata (which has 15 times more entities
than Wikipedia) and of zero-shot entity linking. The combination of speed,
accuracy and scale makes ReFinED an effective and cost-efficient system for
extracting entities from web-scale datasets, for which the model has been
successfully deployed. Our code and pre-trained models are available at
https://github.com/alexa/ReFinED",https://github.com/alexa/ReFinED,-1
034d9d61-e6fc-46ea-acac-49779bb315f2,SRFeat: Learning Locally Accurate and Globally Consistent Non-Rigid Shape Correspondence,0.591346,"In this work, we present a novel learning-based framework that combines the
local accuracy of contrastive learning with the global consistency of geometric
approaches, for robust non-rigid matching. We first observe that while
contrastive learning can lead to powerful point-wise features, the learned
correspondences commonly lack smoothness and consistency, owing to the purely
combinatorial nature of the standard contrastive losses. To overcome this
limitation we propose to boost contrastive feature learning with two types of
smoothness regularization that inject geometric information into correspondence
learning. With this novel combination in hand, the resulting features are both
highly discriminative across individual points, and, at the same time, lead to
robust and consistent correspondences, through simple proximity queries. Our
framework is general and is applicable to local feature learning in both the 3D
and 2D domains. We demonstrate the superiority of our approach through
extensive experiments on a wide range of challenging matching benchmarks,
including 3D non-rigid shape correspondence and 2D image keypoint matching.",https://github.com/craigleili/SRFeat,-1
6d3d9b06-22ad-45a1-96ba-f11e8e7fb65c,Semi-automatic WordNet Linking using Word Embeddings,0.0919875,"Wordnets are rich lexico-semantic resources. Linked wordnets are extensions
of wordnets, which link similar concepts in wordnets of different languages.
Such resources are extremely useful in many Natural Language Processing (NLP)
applications, primarily those based on knowledge-based approaches. In such
approaches, these resources are considered as gold standard/oracle. Thus, it is
crucial that these resources hold correct information. Thereby, they are
created by human experts. However, manual maintenance of such resources is a
tedious and costly affair. Thus techniques that can aid the experts are
desirable. In this paper, we propose an approach to link wordnets. Given a
synset of the source language, the approach returns a ranked list of potential
candidate synsets in the target language from which the human expert can choose
the correct one(s). Our technique is able to retrieve a winner synset in the
top 10 ranked list for 60% of all synsets and 70% of noun synsets.",None,-1
21d19b58-b4e0-4ea1-9c6f-dc09b4269bb2,Scheduling Algorithms for Federated Learning with Minimal Energy Consumption,0.465696,"Federated Learning (FL) has opened the opportunity for collaboratively
training machine learning models on heterogeneous mobile or Edge devices while
keeping local data private.With an increase in its adoption, a growing concern
is related to its economic and environmental cost (as is also the case for
other machine learning techniques).Unfortunately, little work has been done to
optimize its energy consumption or emissions of carbon dioxide or equivalents,
as energy minimization is usually left as a secondary objective.In this paper,
we investigate the problem of minimizing the energy consumption of FL training
on heterogeneous devices by controlling the workload distribution.We model this
as the Minimal Cost FL Schedule problem, a total cost minimization problem with
identical, independent, and atomic tasks that have to be assigned to
heterogeneous resources with arbitrary cost functions.We propose a
pseudo-polynomial optimal solution to the problem based on the previously
unexplored Multiple-Choice Minimum-Cost Maximal Knapsack Packing Problem.We
also provide four algorithms for scenarios where cost functions are
monotonically increasing and follow the same behavior.These solutions are
likewise applicable on the minimization of other kinds of costs, and in other
one-dimensional data partition problems.",https://hal.archives-ouvertes.fr/hal-03601230,-1
9b9187d7-78a9-41c4-bca3-f1a4a242f425,The Whole Truth and Nothing But the Truth: Faithful and Controllable Dialogue Response Generation with Dataflow Transduction and Constrained Decoding,0.42494,"In a real-world dialogue system, generated text must be truthful and
informative while remaining fluent and adhering to a prescribed style.
Satisfying these constraints simultaneously is difficult for the two
predominant paradigms in language generation: neural language modeling and
rule-based generation. We describe a hybrid architecture for dialogue response
generation that combines the strengths of both paradigms. The first component
of this architecture is a rule-based content selection model defined using a
new formal framework called dataflow transduction, which uses declarative rules
to transduce a dialogue agent's actions and their results (represented as
dataflow graphs) into context-free grammars representing the space of
contextually acceptable responses. The second component is a constrained
decoding procedure that uses these grammars to constrain the output of a neural
language model, which selects fluent utterances. Our experiments show that this
system outperforms both rule-based and learned approaches in human evaluations
of fluency, relevance, and truthfulness.",https://github.com/microsoft/dataflow2text,-1
9245db9b-4818-45e7-824b-15ca3d9c4482,An Exploration of Hierarchical Attention Transformers for Efficient Long Document Classification,0.493819,"Non-hierarchical sparse attention Transformer-based models, such as
Longformer and Big Bird, are popular approaches to working with long documents.
There are clear benefits to these approaches compared to the original
Transformer in terms of efficiency, but Hierarchical Attention Transformer
(HAT) models are a vastly understudied alternative. We develop and release
fully pre-trained HAT models that use segment-wise followed by cross-segment
encoders and compare them with Longformer models and partially pre-trained
HATs. In several long document downstream classification tasks, our best HAT
model outperforms equally-sized Longformer models while using 10-20% less GPU
memory and processing documents 40-45% faster. In a series of ablation studies,
we find that HATs perform best with cross-segment contextualization throughout
the model than alternative configurations that implement either early or late
cross-segment contextualization. Our code is on GitHub:
https://github.com/coastalcph/hierarchical-transformers.",https://github.com/coastalcph/hierarchical-transformers,-1
0439dd2b-a402-41d9-9c8b-b35b3210d809,Self-directed Learning of Action Models using Exploratory Planning,0.0413488,"Complex, real-world domains may not be fully modeled for an agent, especially
if the agent has never operated in the domain before. The agent's ability to
effectively plan and act in such a domain is influenced by its knowledge of
when it can perform specific actions and the effects of those actions. We
describe a novel exploratory planning agent that is capable of learning action
preconditions and effects without expert traces or a given goal. The agent's
architecture allows it to perform both exploratory actions as well as
goal-directed actions, which opens up important considerations for how
exploratory planning and goal planning should be controlled, as well as how the
agent's behavior should be explained to any teammates it may have. The
contributions of this work include a new representation for contexts called
Lifted Linked Clauses, a novel exploration action selection approach using
these clauses, an exploration planner that uses lifted linked clauses as goals
in order to reach new states, and an empirical evaluation in a scenario from an
exploration-focused video game demonstrating that lifted linked clauses improve
exploration and action model learning against non-planning baseline agents.",None,24302
89e1a713-8216-4e65-8345-42f50733f395,Multi-focus thermal image fusion,0.513198,"This paper proposes a novel algorithm for multi-focus thermal image fusion.
The algorithm is based on local activity analysis and advanced pre-selection of
images into fusion process. The algorithm improves the object temperature
measurement error up to 5 Celsius degrees. The proposed algorithm is evaluated
by half total error rate, root mean squared error, cross correlation and visual
inspection. To the best of our knowledge, this is the first work devoted to
multi-focus thermal image fusion. For testing of proposed algorithm we acquire
six thermal image set with objects at different focal depth.",None,-1
76f76d25-6415-447a-a1d0-916583d66f05,Alleviating Representational Shift for Continual Fine-tuning,0.166911,"We study a practical setting of continual learning: fine-tuning on a
pre-trained model continually. Previous work has found that, when training on
new tasks, the features (penultimate layer representations) of previous data
will change, called representational shift. Besides the shift of features, we
reveal that the intermediate layers' representational shift (IRS) also matters
since it disrupts batch normalization, which is another crucial cause of
catastrophic forgetting. Motivated by this, we propose ConFiT, a fine-tuning
method incorporating two components, cross-convolution batch normalization
(Xconv BN) and hierarchical fine-tuning. Xconv BN maintains pre-convolution
running means instead of post-convolution, and recovers post-convolution ones
before testing, which corrects the inaccurate estimates of means under IRS.
Hierarchical fine-tuning leverages a multi-stage strategy to fine-tune the
pre-trained network, preventing massive changes in Conv layers and thus
alleviating IRS. Experimental results on four datasets show that our method
remarkably outperforms several state-of-the-art methods with lower storage
overhead.",http://github.com/JieShibo/ConFiT,-1
4911b6db-35a2-4387-9699-998a90c5b4b8,Pre-Trained Multilingual Sequence-to-Sequence Models: A Hope for Low-Resource Language Translation?,0.925171,"What can pre-trained multilingual sequence-to-sequence models like mBART
contribute to translating low-resource languages? We conduct a thorough
empirical experiment in 10 languages to ascertain this, considering five
factors: (1) the amount of fine-tuning data, (2) the noise in the fine-tuning
data, (3) the amount of pre-training data in the model, (4) the impact of
domain mismatch, and (5) language typology. In addition to yielding several
heuristics, the experiments form a framework for evaluating the data
sensitivities of machine translation systems. While mBART is robust to domain
differences, its translations for unseen and typologically distant languages
remain below 3.0 BLEU. In answer to our title's question, mBART is not a
low-resource panacea; we therefore encourage shifting the emphasis from new
models to new data.",https://github.com/LRLNMT/,-1
e07b5857-b28e-47bd-abc7-4d00e0f0a8de,A Contrario multi-scale anomaly detection method for industrial quality inspection,0.0489017,"Anomalies can be defined as any non-random structure which deviates from
normality. Anomaly detection methods reported in the literature are numerous
and diverse, as what is considered anomalous usually varies depending on
particular scenarios and applications. In this work we propose an a contrario
framework to detect anomalies in images applying statistical analysis to
feature maps obtained via convolutions. We evaluate filters learned from the
image under analysis via patch PCA, Gabor filters and the feature maps obtained
from a pre-trained deep neural network (Resnet). The proposed method is
multi-scale and fully unsupervised and is able to detect anomalies in a wide
variety of scenarios. While the end goal of this work is the detection of
subtle defects in leather samples for the automotive industry, we show that the
same algorithm achieves state-of-the-art results in public anomalies datasets.",None,-1
aad2b48f-57bb-4590-af70-9e4438ecf177,A Study on Self-Supervised Object Detection Pretraining,0.0844284,"In this work, we study different approaches to self-supervised pretraining of
object detection models. We first design a general framework to learn a
spatially consistent dense representation from an image, by randomly sampling
and projecting boxes to each augmented view and maximizing the similarity
between corresponding box features. We study existing design choices in the
literature, such as box generation, feature extraction strategies, and using
multiple views inspired by its success on instance-level image representation
learning techniques. Our results suggest that the method is robust to different
choices of hyperparameters, and using multiple views is not as effective as
shown for instance-level image representation learning. We also design two
auxiliary tasks to predict boxes in one view from their features in the other
view, by (1) predicting boxes from the sampled set by using a contrastive loss,
and (2) predicting box coordinates using a transformer, which potentially
benefits downstream object detection tasks. We found that these tasks do not
lead to better object detection performance when finetuning the pretrained
model on labeled data.",None,-1
44146c7a-cc69-413c-ab08-172c10bd1678,Characterizing the Action-Generalization Gap in Deep Q-Learning,0.0276883,"We study the action generalization ability of deep Q-learning in discrete
action spaces. Generalization is crucial for efficient reinforcement learning
(RL) because it allows agents to use knowledge learned from past experiences on
new tasks. But while function approximation provides deep RL agents with a
natural way to generalize over state inputs, the same generalization mechanism
does not apply to discrete action outputs. And yet, surprisingly, our
experiments indicate that Deep Q-Networks (DQN), which use exactly this type of
function approximator, are still able to achieve modest action generalization.
Our main contribution is twofold: first, we propose a method of evaluating
action generalization using expert knowledge of action similarity, and
empirically confirm that action generalization leads to faster learning;
second, we characterize the action-generalization gap (the difference in
learning performance between DQN and the expert) in different domains. We find
that DQN can indeed generalize over actions in several simple domains, but that
its ability to do so decreases as the action space grows larger.",None,-1
8572ca64-f63d-4a9d-a2c3-3a7144bdc339,Policy Architectures for Compositional Generalization in Control,0.320262,"Many tasks in control, robotics, and planning can be specified using desired
goal configurations for various entities in the environment. Learning
goal-conditioned policies is a natural paradigm to solve such tasks. However,
current approaches struggle to learn and generalize as task complexity
increases, such as variations in number of environment entities or compositions
of goals. In this work, we introduce a framework for modeling entity-based
compositional structure in tasks, and create suitable policy designs that can
leverage this structure. Our policies, which utilize architectures like Deep
Sets and Self Attention, are flexible and can be trained end-to-end without
requiring any action primitives. When trained using standard reinforcement and
imitation learning methods on a suite of simulated robot manipulation tasks, we
find that these architectures achieve significantly higher success rates with
less data. We also find these architectures enable broader and compositional
generalization, producing policies that extrapolate to different numbers of
entities than seen in training, and stitch together (i.e. compose) learned
skills in novel ways. Videos of the results can be found at
https://sites.google.com/view/comp-gen-rl.",https://github.com/TianhongDai/hindsight-experience-replay,-1
734c517d-3f54-44b5-a378-b3e38450bd36,Policy Distillation with Selective Input Gradient Regularization for Efficient Interpretability,0.150804,"Although deep Reinforcement Learning (RL) has proven successful in a wide
range of tasks, one challenge it faces is interpretability when applied to
real-world problems. Saliency maps are frequently used to provide
interpretability for deep neural networks. However, in the RL domain, existing
saliency map approaches are either computationally expensive and thus cannot
satisfy the real-time requirement of real-world scenarios or cannot produce
interpretable saliency maps for RL policies. In this work, we propose an
approach of Distillation with selective Input Gradient Regularization (DIGR)
which uses policy distillation and input gradient regularization to produce new
policies that achieve both high interpretability and computation efficiency in
generating saliency maps. Our approach is also found to improve the robustness
of RL policies to multiple adversarial attacks. We conduct experiments on three
tasks, MiniGrid (Fetch Object), Atari (Breakout) and CARLA Autonomous Driving,
to demonstrate the importance and effectiveness of our approach.",None,-1
dd58f012-c842-41ce-9bf3-9a3cfa741292,Provable Defense against Backdoor Policies in Reinforcement Learning,0.820057,"We propose a provable defense mechanism against backdoor policies in
reinforcement learning under subspace trigger assumption. A backdoor policy is
a security threat where an adversary publishes a seemingly well-behaved policy
which in fact allows hidden triggers. During deployment, the adversary can
modify observed states in a particular way to trigger unexpected actions and
harm the agent. We assume the agent does not have the resources to re-train a
good policy. Instead, our defense mechanism sanitizes the backdoor policy by
projecting observed states to a 'safe subspace', estimated from a small number
of interactions with a clean (non-triggered) environment. Our sanitized policy
achieves $\epsilon$ approximate optimality in the presence of triggers,
provided the number of clean interactions is $O\left(\frac{D}{(1-\gamma)^4
\epsilon^2}\right)$ where $\gamma$ is the discounting factor and $D$ is the
dimension of state space. Empirically, we show that our sanitization defense
performs well on two Atari game environments.",https://github.com/skbharti/Provable-Defense-in-RL,-1
6ddfb2b4-9b7d-44f5-bcb7-7930e150948e,Prompting Is Programming: A Query Language for Large Language Models,0.741358,"Large language models have demonstrated outstanding performance on a wide
range of tasks such as question answering and code generation. On a high level,
given an input, a language model can be used to automatically complete the
sequence in a statistically-likely way. Based on this, users prompt these
models with language instructions or examples, to implement a variety of
downstream tasks. Advanced prompting methods can even imply interaction between
the language model, a user, and external tools such as calculators. However, to
obtain state-of-the-art performance or adapt language models for specific
tasks, complex task- and model-specific programs have to be implemented, which
may still require ad-hoc interaction.
  Based on this, we present the novel idea of Language Model Programming (LMP).
LMP generalizes language model prompting from pure text prompts to an intuitive
combination of text prompting and scripting. Additionally, LMP allows
constraints to be specified over the language model output. This enables easy
adaption to many tasks while abstracting language model internals and providing
high-level semantics.
  To enable LMP, we implement LMQL(short for Language Model Query Language),
which leverages the constraints and control flow from an LMP prompt to generate
an efficient inference procedure that minimizes the number of expensive calls
to the underlying language model.
  We show that LMQL can capture a wide range of state-of-the-art prompting
methods in an intuitive way, especially facilitating interactive flows that are
challenging to implement with existing high-level APIs. Our evaluation shows
that we retain or increase the accuracy on several downstream tasks, while also
significantly reducing the required amount of computation or cost in the case
of pay-to-use APIs (26-85% cost savings).",https://github.com/eth-sri/lmql,-1
899a63c5-4afc-4e2c-9aa1-fd32efbcc97e,A Novel Self-Knowledge Distillation Approach with Siamese Representation Learning for Action Recognition,0.339619,"Knowledge distillation is an effective transfer of knowledge from a heavy
network (teacher) to a small network (student) to boost students' performance.
Self-knowledge distillation, the special case of knowledge distillation, has
been proposed to remove the large teacher network training process while
preserving the student's performance. This paper introduces a novel
Self-knowledge distillation approach via Siamese representation learning, which
minimizes the difference between two representation vectors of the two
different views from a given sample. Our proposed method, SKD-SRL, utilizes
both soft label distillation and the similarity of representation vectors.
Therefore, SKD-SRL can generate more consistent predictions and representations
in various views of the same data point. Our benchmark has been evaluated on
various standard datasets. The experimental results have shown that SKD-SRL
significantly improves the accuracy compared to existing supervised learning
and knowledge distillation methods regardless of the networks.",None,-1
64106600-6c23-4ef1-bf8e-f176ea89ddba,Admissible Policy Teaching through Reward Design,0.682902,"We study reward design strategies for incentivizing a reinforcement learning
agent to adopt a policy from a set of admissible policies. The goal of the
reward designer is to modify the underlying reward function cost-efficiently
while ensuring that any approximately optimal deterministic policy under the
new reward function is admissible and performs well under the original reward
function. This problem can be viewed as a dual to the problem of optimal reward
poisoning attacks: instead of forcing an agent to adopt a specific policy, the
reward designer incentivizes an agent to avoid taking actions that are
inadmissible in certain states. Perhaps surprisingly, and in contrast to the
problem of optimal reward poisoning attacks, we first show that the reward
design problem for admissible policy teaching is computationally challenging,
and it is NP-hard to find an approximately optimal reward modification. We then
proceed by formulating a surrogate problem whose optimal solution approximates
the optimal solution to the reward design problem in our setting, but is more
amenable to optimization techniques and analysis. For this surrogate problem,
we present characterization results that provide bounds on the value of the
optimal solution. Finally, we design a local search algorithm to solve the
surrogate problem and showcase its utility using simulation-based experiments.",None,-1
5347fe17-12c7-4335-9bed-c2e267ad2e3d,Distilling Causal Effect from Miscellaneous Other-Class for Continual Named Entity Recognition,0.382229,"Continual Learning for Named Entity Recognition (CL-NER) aims to learn a
growing number of entity types over time from a stream of data. However, simply
learning Other-Class in the same way as new entity types amplifies the
catastrophic forgetting and leads to a substantial performance drop. The main
cause behind this is that Other-Class samples usually contain old entity types,
and the old knowledge in these Other-Class samples is not preserved properly.
Thanks to the causal inference, we identify that the forgetting is caused by
the missing causal effect from the old data. To this end, we propose a unified
causal framework to retrieve the causality from both new entity types and
Other-Class. Furthermore, we apply curriculum learning to mitigate the impact
of label noise and introduce a self-adaptive weight for balancing the causal
effects between new entity types and Other-Class. Experimental results on three
benchmark datasets show that our method outperforms the state-of-the-art method
by a large margin. Moreover, our method can be combined with the existing
state-of-the-art methods to improve the performance in CL-NER",https://github.com/zzz47zzz/CFNER,-1
3a26708a-469e-46ae-92c4-f8f7eb91d56d,BILP-Q: Quantum Coalition Structure Generation,0.687694,"Quantum AI is an emerging field that uses quantum computing to solve typical
complex problems in AI. In this work, we propose BILP-Q, the first-ever general
quantum approach for solving the Coalition Structure Generation problem (CSGP),
which is notably NP-hard. In particular, we reformulate the CSGP in terms of a
Quadratic Binary Combinatorial Optimization (QUBO) problem to leverage existing
quantum algorithms (e.g., QAOA) to obtain the best coalition structure. Thus,
we perform a comparative analysis in terms of time complexity between the
proposed quantum approach and the most popular classical baselines.
Furthermore, we consider standard benchmark distributions for coalition values
to test the BILP-Q on small-scale experiments using the IBM Qiskit environment.
Finally, since QUBO problems can be solved operating with quantum annealing, we
run BILP-Q on medium-size problems using a real quantum annealer (D-Wave).",https://github.com/supreethmv/BILP-Q,-1
d9effd32-ad8e-4441-ac9c-853bbefe9a0b,Using Pre-Trained Language Models for Producing Counter Narratives Against Hate Speech: a Comparative Study,0.957513,"In this work, we present an extensive study on the use of pre-trained
language models for the task of automatic Counter Narrative (CN) generation to
fight online hate speech in English. We first present a comparative study to
determine whether there is a particular Language Model (or class of LMs) and a
particular decoding mechanism that are the most appropriate to generate CNs.
Findings show that autoregressive models combined with stochastic decodings are
the most promising. We then investigate how an LM performs in generating a CN
with regard to an unseen target of hate. We find out that a key element for
successful `out of target' experiments is not an overall similarity with the
training data but the presence of a specific subset of training data, i.e. a
target that shares some commonalities with the test target that can be defined
a-priori. We finally introduce the idea of a pipeline based on the addition of
an automatic post-editing step to refine generated CNs.",None,-1
9e707ee6-deb8-4bf8-8e4e-d00e61040dfb,DyNCA: Real-time Dynamic Texture Synthesis Using Neural Cellular Automata,0.615552,"Current Dynamic Texture Synthesis (DyTS) models can synthesize realistic
videos. However, they require a slow iterative optimization process to
synthesize a single fixed-size short video, and they do not offer any
post-training control over the synthesis process. We propose Dynamic Neural
Cellular Automata (DyNCA), a framework for real-time and controllable dynamic
texture synthesis. Our method is built upon the recently introduced NCA models
and can synthesize infinitely long and arbitrary-sized realistic video textures
in real time. We quantitatively and qualitatively evaluate our model and show
that our synthesized videos appear more realistic than the existing results. We
improve the SOTA DyTS performance by $2\sim 4$ orders of magnitude. Moreover,
our model offers several real-time video controls including motion speed,
motion direction, and an editing brush tool. We exhibit our trained models in
an online interactive demo that runs on local hardware and is accessible on
personal computers and smartphones.",None,-1
9a641430-28cd-44b4-914c-ebf9f89dafb6,Adapting the Exploration Rate for Value-of-Information-Based Reinforcement Learning,0.413733,"In this paper, we consider the problem of adjusting the exploration rate when
using value-of-information-based exploration. We do this by converting the
value-of-information optimization into a problem of finding equilibria of a
flow for a changing exploration rate. We then develop an efficient
path-following scheme for converging to these equilibria and hence uncovering
optimal action-selection policies. Under this scheme, the exploration rate is
automatically adapted according to the agent's experiences. Global convergence
is theoretically assured.
  We first evaluate our exploration-rate adaptation on the Nintendo GameBoy
games Centipede and Millipede. We demonstrate aspects of the search process,
like that it yields a hierarchy of state abstractions. We also show that our
approach returns better policies in fewer episodes than conventional search
strategies relying on heuristic, annealing-based exploration-rate adjustments.
We then illustrate that these trends hold for deep, value-of-information-based
agents that learn to play ten simple games and over forty more complicated
games for the Nintendo GameBoy system. Performance either near or well above
the level of human play is observed.",None,-1
2090c115-4783-4284-a643-e5dba4763035,DisCup: Discriminator Cooperative Unlikelihood Prompt-tuning for Controllable Text Generation,0.372294,"Prompt learning with immensely large Casual Language Models (CLMs) has been
shown promising for attribute-controllable text generation (CTG). However,
vanilla prompt tuning tends to imitate training corpus characteristics beyond
the control attributes, resulting in a poor generalization ability. Moreover,
it is less able to capture the relationship between different attributes,
further limiting the control performance. In this paper, we propose a new CTG
approach, namely DisCup, which incorporates the attribute knowledge of
discriminator to optimize the control-prompts, steering a frozen CLM to produce
attribute-specific texts. Specifically, the frozen CLM model, capable of
producing multitudinous texts, is first used to generate the next-token
candidates based on the context, so as to ensure the diversity of tokens to be
predicted. Then, we leverage an attribute-discriminator to select
desired/undesired tokens from those candidates, providing the inter-attribute
knowledge. Finally, we bridge the above two traits by an unlikelihood objective
for prompt-tuning. Extensive experimental results show that DisCup can achieve
a new state-of-the-art control performance while maintaining an efficient and
high-quality text generation, only relying on around 10 virtual tokens.",https://github.com/littlehacker26/disc-cooperative-up-tuning,403
b068b793-141e-4c0e-98f2-2e013315ad31,Code-DKT: A Code-based Knowledge Tracing Model for Programming Tasks,0.66959,"Knowledge tracing (KT) models are a popular approach for predicting students'
future performance at practice problems using their prior attempts. Though many
innovations have been made in KT, most models including the state-of-the-art
Deep KT (DKT) mainly leverage each student's response either as correct or
incorrect, ignoring its content. In this work, we propose Code-based Deep
Knowledge Tracing (Code-DKT), a model that uses an attention mechanism to
automatically extract and select domain-specific code features to extend DKT.
We compared the effectiveness of Code-DKT against Bayesian and Deep Knowledge
Tracing (BKT and DKT) on a dataset from a class of 50 students attempting to
solve 5 introductory programming assignments. Our results show that Code-DKT
consistently outperforms DKT by 3.07-4.00% AUC across the 5 assignments, a
comparable improvement to other state-of-the-art domain-general KT models over
DKT. Finally, we analyze problem-specific performance through a set of case
studies for one assignment to demonstrate when and how code features improve
Code-DKT's predictions.",https://github.com/YangAzure/Code-DKT,-1
ba083ae0-0d43-46cb-bca1-dde6f2e561a2,"Human Detection of Political Speech Deepfakes across Transcripts, Audio, and Video",0.333658,"Recent advances in technology for hyper-realistic visual and audio effects
provoke the concern that deepfake videos of political speeches will soon be
indistinguishable from authentic video recordings. The conventional wisdom in
communication theory predicts people will fall for fake news more often when
the same version of a story is presented as a video versus text. We conduct 5
pre-registered randomized experiments with 2,215 participants to evaluate how
accurately humans distinguish real political speeches from fabrications across
base rates of misinformation, audio sources, question framings, and media
modalities. We find base rates of misinformation minimally influence
discernment and deepfakes with audio produced by the state-of-the-art
text-to-speech algorithms are harder to discern than the same deepfakes with
voice actor audio. Moreover across all experiments, we find audio and visual
information enables more accurate discernment than text alone: human
discernment relies more on how something is said, the audio-visual cues, than
what is said, the speech content.",https://researchbox.org/1723&PEER_REVIEW_passcode=EGVULE,-1
d7660443-73c0-465c-b185-1b918cc1964b,ELIC: Efficient Learned Image Compression with Unevenly Grouped Space-Channel Contextual Adaptive Coding,1.0,"Recently, learned image compression techniques have achieved remarkable
performance, even surpassing the best manually designed lossy image coders.
They are promising to be large-scale adopted. For the sake of practicality, a
thorough investigation of the architecture design of learned image compression,
regarding both compression performance and running speed, is essential. In this
paper, we first propose uneven channel-conditional adaptive coding, motivated
by the observation of energy compaction in learned image compression. Combining
the proposed uneven grouping model with existing context models, we obtain a
spatial-channel contextual adaptive model to improve the coding performance
without damage to running speed. Then we study the structure of the main
transform and propose an efficient model, ELIC, to achieve state-of-the-art
speed and compression ability. With superior performance, the proposed model
also supports extremely fast preview decoding and progressive decoding, which
makes the coming application of learning-based image compression more
promising.",https://github.com/InterDigitalInc/CompressAI/blob/v1.1.8/results/kodak/vtm.json,-1
a658d714-588a-435a-a82a-894edbbf47c7,Blackbox Post-Processing for Multiclass Fairness,0.413096,"Applying standard machine learning approaches for classification can produce
unequal results across different demographic groups. When then used in
real-world settings, these inequities can have negative societal impacts. This
has motivated the development of various approaches to fair classification with
machine learning models in recent years. In this paper, we consider the problem
of modifying the predictions of a blackbox machine learning classifier in order
to achieve fairness in a multiclass setting. To accomplish this, we extend the
'post-processing' approach in Hardt et al. 2016, which focuses on fairness for
binary classification, to the setting of fair multiclass classification. We
explore when our approach produces both fair and accurate predictions through
systematic synthetic experiments and also evaluate discrimination-fairness
tradeoffs on several publicly available real-world application datasets. We
find that overall, our approach produces minor drops in accuracy and enforces
fairness when the number of individuals in the dataset is high relative to the
number of classes and protected groups.",https://github.com/scotthlee/fairness/tree/aaai,-1
dc346381-a0f4-4f69-9971-2ea8c83ad00e,Controllable User Dialogue Act Augmentation for Dialogue State Tracking,0.561887,"Prior work has demonstrated that data augmentation is useful for improving
dialogue state tracking. However, there are many types of user utterances,
while the prior method only considered the simplest one for augmentation,
raising the concern about poor generalization capability. In order to better
cover diverse dialogue acts and control the generation quality, this paper
proposes controllable user dialogue act augmentation (CUDA-DST) to augment user
utterances with diverse behaviors. With the augmented data, different state
trackers gain improvement and show better robustness, achieving the
state-of-the-art performance on MultiWOZ 2.1",https://github.com/MiuLab/CUDA-DST,-1
e404a12c-273e-4d14-95c7-90b49d24277e,Audiogram Digitization Tool for Audiological Reports,0.227893,"A number of private and public insurers compensate workers whose hearing loss
can be directly attributed to excessive exposure to noise in the workplace. The
claim assessment process is typically lengthy and requires significant effort
from human adjudicators who must interpret hand-recorded audiograms, often sent
via fax or equivalent. In this work, we present a solution developed in
partnership with the Workplace Safety Insurance Board of Ontario to streamline
the adjudication process. In particular, we present the first audiogram
digitization algorithm capable of automatically extracting the hearing
thresholds from a scanned or faxed audiology report as a proof-of-concept. The
algorithm extracts most thresholds within 5 dB accuracy, allowing to
substantially lessen the time required to convert an audiogram into digital
format in a semi-supervised fashion, and is a first step towards the automation
of the adjudication process. The source code for the digitization algorithm and
a desktop-based implementation of our NIHL annotation portal is publicly
available on GitHub (https://github.com/GreenCUBIC/AudiogramDigitization).",https://github.com/GreenCUBIC/AudiogramDigitization,-1
38afa70e-004b-455b-a6f6-c9fd11515a11,Solving Math Word Problems via Cooperative Reasoning induced Language Models,0.975062,"Large-scale pre-trained language models (PLMs) bring new opportunities to
challenging problems, especially those that need high-level intelligence, such
as the math word problem (MWPs). However, directly applying existing PLMs to
MWPs can fail as the generation process lacks sufficient supervision and thus
lacks fast adaptivity as humans. We notice that human reasoning has a dual
reasoning framework that consists of an immediate reaction system (system 1)
and a delicate reasoning system (system 2), where the entire reasoning is
determined by their interaction. This inspires us to develop a cooperative
reasoning-induced PLM for solving MWPs, called Cooperative Reasoning (CoRe),
resulting in a human-like reasoning architecture with system 1 as the generator
and system 2 as the verifier. In our approach, the generator is responsible for
generating reasoning paths, and the verifiers are used to supervise the
evaluation in order to obtain reliable feedback for the generator. We evaluate
our CoRe framework on several mathematical reasoning datasets and achieve
decent improvement over state-of-the-art methods, up to 9.6% increase over best
baselines. Our codes are available at https://github.com/TianHongZXY/CoRe",https://github.com/TianHongZXY/CoRe,-1
7b734501-08b0-4e29-82e0-6d2de7ea7706,Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small,1.0,"Research in mechanistic interpretability seeks to explain behaviors of
machine learning models in terms of their internal components. However, most
previous work either focuses on simple behaviors in small models, or describes
complicated behaviors in larger models with broad strokes. In this work, we
bridge this gap by presenting an explanation for how GPT-2 small performs a
natural language task called indirect object identification (IOI). Our
explanation encompasses 26 attention heads grouped into 7 main classes, which
we discovered using a combination of interpretability approaches relying on
causal interventions. To our knowledge, this investigation is the largest
end-to-end attempt at reverse-engineering a natural behavior ""in the wild"" in a
language model. We evaluate the reliability of our explanation using three
quantitative criteria--faithfulness, completeness and minimality. Though these
criteria support our explanation, they also point to remaining gaps in our
understanding. Our work provides evidence that a mechanistic understanding of
large ML models is feasible, opening opportunities to scale our understanding
to both larger models and more complex tasks.",https://github.com/redwoodresearch/Easy-Transformer,-1
62fe11e9-ce80-4223-a335-1df0c81dd372,FixMatchSeg: Fixing FixMatch for Semi-Supervised Semantic Segmentation,0.340588,"Supervised deep learning methods for semantic medical image segmentation are
getting increasingly popular in the past few years.However, in resource
constrained settings, getting large number of annotated images is very
difficult as it mostly requires experts, is expensive and
time-consuming.Semi-supervised segmentation can be an attractive solution where
a very few labeled images are used along with a large number of unlabeled ones.
While the gap between supervised and semi-supervised methods have been
dramatically reduced for classification problems in the past couple of years,
there still remains a larger gap in segmentation methods. In this work, we
adapt a state-of-the-art semi-supervised classification method FixMatch to
semantic segmentation task, introducing FixMatchSeg. FixMatchSeg is evaluated
in four different publicly available datasets of different anatomy and
different modality: cardiac ultrasound, chest X-ray, retinal fundus image, and
skin images. When there are few labels, we show that FixMatchSeg performs on
par with strong supervised baselines.",https://github.com/qubvel/segmentation_models.pytorch,-1
7704e40c-3f17-4132-8dd6-bb1db82432f6,Speech Resources in the Tamasheq Language,0.715946,"In this paper we present two datasets for Tamasheq, a developing language
mainly spoken in Mali and Niger. These two datasets were made available for the
IWSLT 2022 low-resource speech translation track, and they consist of
collections of radio recordings from daily broadcast news in Niger (Studio
Kalangou) and Mali (Studio Tamani). We share (i) a massive amount of unlabeled
audio data (671 hours) in five languages: French from Niger, Fulfulde, Hausa,
Tamasheq and Zarma, and (ii) a smaller 17 hours parallel corpus of audio
recordings in Tamasheq, with utterance-level translations in the French
language. All this data is shared under the Creative Commons BY-NC-ND 3.0
license. We hope these resources will inspire the speech community to develop
and benchmark models using the Tamasheq language.",https://github.com/mzboito/IWSLT2022 Tamasheq data.,-1
5cb857a9-4b21-4831-8c37-c3a4ab99da18,"Knowledge Distillation as Efficient Pre-training: Faster Convergence, Higher Data-efficiency, and Better Transferability",0.745813,"Large-scale pre-training has been proven to be crucial for various computer
vision tasks. However, with the increase of pre-training data amount, model
architecture amount, and the private/inaccessible data, it is not very
efficient or possible to pre-train all the model architectures on large-scale
datasets. In this work, we investigate an alternative strategy for
pre-training, namely Knowledge Distillation as Efficient Pre-training (KDEP),
aiming to efficiently transfer the learned feature representation from existing
pre-trained models to new student models for future downstream tasks. We
observe that existing Knowledge Distillation (KD) methods are unsuitable
towards pre-training since they normally distill the logits that are going to
be discarded when transferred to downstream tasks. To resolve this problem, we
propose a feature-based KD method with non-parametric feature dimension
aligning. Notably, our method performs comparably with supervised pre-training
counterparts in 3 downstream tasks and 9 downstream datasets requiring 10x less
data and 5x less pre-training time. Code is available at
https://github.com/CVMI-Lab/KDEP.",https://github.com/CVMI-Lab/KDEP,-1
2251fc8e-9d77-4b09-afa8-07a2c8507161,Injecting Domain Knowledge in Language Models for Task-Oriented Dialogue Systems,0.904422,"Pre-trained language models (PLM) have advanced the state-of-the-art across
NLP applications, but lack domain-specific knowledge that does not naturally
occur in pre-training data. Previous studies augmented PLMs with symbolic
knowledge for different downstream NLP tasks. However, knowledge bases (KBs)
utilized in these studies are usually large-scale and static, in contrast to
small, domain-specific, and modifiable knowledge bases that are prominent in
real-world task-oriented dialogue (TOD) systems. In this paper, we showcase the
advantages of injecting domain-specific knowledge prior to fine-tuning on TOD
tasks. To this end, we utilize light-weight adapters that can be easily
integrated with PLMs and serve as a repository for facts learned from different
KBs. To measure the efficacy of proposed knowledge injection methods, we
introduce Knowledge Probing using Response Selection (KPRS) -- a probe designed
specifically for TOD models. Experiments on KPRS and the response generation
task show improvements of knowledge injection with adapters over strong
baselines.",https://github.com/amazon-research/domain-knowledge-injection,-1
863ada7c-d3e5-4da4-925d-38b6111d1bef,Hyperbolic Image Segmentation,0.748847,"For image segmentation, the current standard is to perform pixel-level
optimization and inference in Euclidean output embedding spaces through linear
hyperplanes. In this work, we show that hyperbolic manifolds provide a valuable
alternative for image segmentation and propose a tractable formulation of
hierarchical pixel-level classification in hyperbolic space. Hyperbolic Image
Segmentation opens up new possibilities and practical benefits for
segmentation, such as uncertainty estimation and boundary information for free,
zero-label generalization, and increased performance in low-dimensional output
embeddings.",https://github.com/MinaGhadimiAtigh/HyperbolicImageSegmentation,-1
2ab95d94-998c-4fb0-9100-6078682892fe,CrossRE: A Cross-Domain Dataset for Relation Extraction,0.638642,"Relation Extraction (RE) has attracted increasing attention, but current RE
evaluation is limited to in-domain evaluation setups. Little is known on how
well a RE system fares in challenging, but realistic out-of-distribution
evaluation setups. To address this gap, we propose CrossRE, a new,
freely-available cross-domain benchmark for RE, which comprises six distinct
text domains and includes multi-label annotations. An additional innovation is
that we release meta-data collected during annotation, to include explanations
and flags of difficult instances. We provide an empirical evaluation with a
state-of-the-art model for relation classification. As the meta-data enables us
to shed new light on the state-of-the-art model, we provide a comprehensive
analysis on the impact of difficult cases and find correlations between model
and human annotations. Overall, our empirical investigation highlights the
difficulty of cross-domain RE. We release our dataset, to spur more research in
this direction.",https://github.com/mainlp/CrossRE,-1
852184c7-959c-4297-8d83-d9ba32bd7dab,Learning Semantic Segmentation from Multiple Datasets with Label Shifts,0.235065,"With increasing applications of semantic segmentation, numerous datasets have
been proposed in the past few years. Yet labeling remains expensive, thus, it
is desirable to jointly train models across aggregations of datasets to enhance
data volume and diversity. However, label spaces differ across datasets and may
even be in conflict with one another. This paper proposes UniSeg, an effective
approach to automatically train models across multiple datasets with differing
label spaces, without any manual relabeling efforts. Specifically, we propose
two losses that account for conflicting and co-occurring labels to achieve
better generalization performance in unseen domains. First, a gradient conflict
in training due to mismatched label spaces is identified and a
class-independent binary cross-entropy loss is proposed to alleviate such label
conflicts. Second, a loss function that considers class-relationships across
datasets is proposed for a better multi-dataset training scheme. Extensive
quantitative and qualitative analyses on road-scene datasets show that UniSeg
improves over multi-dataset baselines, especially on unseen datasets, e.g.,
achieving more than 8% gain in IoU on KITTI averaged over all the settings.",None,-1
0d918816-6c45-4ac9-9036-477a54614f03,SiNeRF: Sinusoidal Neural Radiance Fields for Joint Pose Estimation and Scene Reconstruction,0.618825,"NeRFmm is the Neural Radiance Fields (NeRF) that deal with Joint Optimization
tasks, i.e., reconstructing real-world scenes and registering camera parameters
simultaneously. Despite NeRFmm producing precise scene synthesis and pose
estimations, it still struggles to outperform the full-annotated baseline on
challenging scenes. In this work, we identify that there exists a systematic
sub-optimality in joint optimization and further identify multiple potential
sources for it. To diminish the impacts of potential sources, we propose
Sinusoidal Neural Radiance Fields (SiNeRF) that leverage sinusoidal activations
for radiance mapping and a novel Mixed Region Sampling (MRS) for selecting ray
batch efficiently. Quantitative and qualitative results show that compared to
NeRFmm, SiNeRF achieves comprehensive significant improvements in image
synthesis quality and pose estimation accuracy. Codes are available at
https://github.com/yitongx/sinerf.",https://github.com/yitongx/sinerf,-1
6904ee29-51e1-48fd-9af2-86cda2e49f73,A Visual Navigation Perspective for Category-Level Object Pose Estimation,0.2605,"This paper studies category-level object pose estimation based on a single
monocular image. Recent advances in pose-aware generative models have paved the
way for addressing this challenging task using analysis-by-synthesis. The idea
is to sequentially update a set of latent variables, e.g., pose, shape, and
appearance, of the generative model until the generated image best agrees with
the observation. However, convergence and efficiency are two challenges of this
inference procedure. In this paper, we take a deeper look at the inference of
analysis-by-synthesis from the perspective of visual navigation, and
investigate what is a good navigation policy for this specific task. We
evaluate three different strategies, including gradient descent, reinforcement
learning and imitation learning, via thorough comparisons in terms of
convergence, robustness and efficiency. Moreover, we show that a simple hybrid
approach leads to an effective and efficient solution. We further compare these
strategies to state-of-the-art methods, and demonstrate superior performance on
synthetic and real-world datasets leveraging off-the-shelf pose-aware
generative models.",https://github.com/wrld/visual-navigation-pose-estimation.git,-1
276b3014-008e-42e4-b689-b1f3b1abdf9c,"Interventions, Where and How? Experimental Design for Causal Models at Scale",0.738378,"Causal discovery from observational and interventional data is challenging
due to limited data and non-identifiability: factors that introduce uncertainty
in estimating the underlying structural causal model (SCM). Selecting
experiments (interventions) based on the uncertainty arising from both factors
can expedite the identification of the SCM. Existing methods in experimental
design for causal discovery from limited data either rely on linear assumptions
for the SCM or select only the intervention target. This work incorporates
recent advances in Bayesian causal discovery into the Bayesian optimal
experimental design framework, allowing for active causal discovery of large,
nonlinear SCMs while selecting both the interventional target and the value. We
demonstrate the performance of the proposed method on synthetic graphs
(Erdos-R\`enyi, Scale Free) for both linear and nonlinear SCMs as well as on
the \emph{in-silico} single-cell gene regulatory network dataset, DREAM.",https://github.com/yannadani/cbed,-1
3043e978-6b85-438e-b6ae-13eb3c2a1a06,Meta-Learning Based Knowledge Extrapolation for Knowledge Graphs in the Federated Setting,0.898452,"We study the knowledge extrapolation problem to embed new components (i.e.,
entities and relations) that come with emerging knowledge graphs (KGs) in the
federated setting. In this problem, a model trained on an existing KG needs to
embed an emerging KG with unseen entities and relations. To solve this problem,
we introduce the meta-learning setting, where a set of tasks are sampled on the
existing KG to mimic the link prediction task on the emerging KG. Based on
sampled tasks, we meta-train a graph neural network framework that can
construct features for unseen components based on structural information and
output embeddings for them. Experimental results show that our proposed method
can effectively embed unseen components and outperforms models that consider
inductive settings for KGs and baselines that directly use conventional KG
embedding methods.",https://github.com/zjukg/MaKEr,-1
b31850c4-eb18-4343-a73c-43997dc777fa,Transferability Estimation Based On Principal Gradient Expectation,0.156821,"Transfer learning aims to improve the performance of target tasks by
transferring knowledge acquired in source tasks. The standard approach is
pre-training followed by fine-tuning or linear probing. Especially, selecting a
proper source domain for a specific target domain under predefined tasks is
crucial for improving efficiency and effectiveness. It is conventional to solve
this problem via estimating transferability. However, existing methods can not
reach a trade-off between performance and cost. To comprehensively evaluate
estimation methods, we summarize three properties: stability, reliability and
efficiency. Building upon them, we propose Principal Gradient Expectation(PGE),
a simple yet effective method for assessing transferability. Specifically, we
calculate the gradient over each weight unit multiple times with a restart
scheme, and then we compute the expectation of all gradients. Finally, the
transferability between the source and target is estimated by computing the gap
of normalized principal gradients. Extensive experiments show that the proposed
metric is superior to state-of-the-art methods on all properties.",None,-1
a59f734a-d686-4865-9de4-099989a5a7ac,Fusing Local Similarities for Retrieval-based 3D Orientation Estimation of Unseen Objects,0.536357,"In this paper, we tackle the task of estimating the 3D orientation of
previously-unseen objects from monocular images. This task contrasts with the
one considered by most existing deep learning methods which typically assume
that the testing objects have been observed during training. To handle the
unseen objects, we follow a retrieval-based strategy and prevent the network
from learning object-specific features by computing multi-scale local
similarities between the query image and synthetically-generated reference
images. We then introduce an adaptive fusion module that robustly aggregates
the local similarities into a global similarity score of pairwise images.
Furthermore, we speed up the retrieval process by developing a fast retrieval
strategy. Our experiments on the LineMOD, LineMOD-Occluded, and T-LESS datasets
show that our method yields a significantly better generalization to unseen
objects than previous works. Our code and pre-trained models are available at
https://sailor-z.github.io/projects/Unseen_Object_Pose.html.",https://sailor-z.github.io/projects/Unseen_Object_Pose.html,-1
35711953-ecd6-4d3a-8351-7b5ae9758d6d,Efficient yet Competitive Speech Translation: FBK@IWSLT2022,0.688462,"The primary goal of this FBK's systems submission to the IWSLT 2022 offline
and simultaneous speech translation tasks is to reduce model training costs
without sacrificing translation quality. As such, we first question the need of
ASR pre-training, showing that it is not essential to achieve competitive
results. Second, we focus on data filtering, showing that a simple method that
looks at the ratio between source and target characters yields a quality
improvement of 1 BLEU. Third, we compare different methods to reduce the
detrimental effect of the audio segmentation mismatch between training data
manually segmented at sentence level and inference data that is automatically
segmented. Towards the same goal of training cost reduction, we participate in
the simultaneous task with the same model trained for offline ST. The
effectiveness of our lightweight training strategy is shown by the high score
obtained on the MuST-C en-de corpus (26.7 BLEU) and is confirmed in
high-resource data conditions by a 1.6 BLEU improvement on the IWSLT2020 test
set over last year's winning system.",https://github.com/hlt-mt/FBK-fairseq,-1
46096239-88fc-4614-a99f-c2e8095080b0,Deep Attentive Belief Propagation: Integrating Reasoning and Learning for Solving Constraint Optimization Problems,0.0592309,"Belief Propagation (BP) is an important message-passing algorithm for various
reasoning tasks over graphical models, including solving the Constraint
Optimization Problems (COPs). It has been shown that BP can achieve
state-of-the-art performance on various benchmarks by mixing old and new
messages before sending the new one, i.e., damping. However, existing methods
of tuning a static damping factor for BP not only are laborious but also harm
their performance. Moreover, existing BP algorithms treat each variable node's
neighbors equally when composing a new message, which also limits their
exploration ability. To address these issues, we seamlessly integrate BP, Gated
Recurrent Units (GRUs), and Graph Attention Networks (GATs) within the
message-passing framework to reason about dynamic weights and damping factors
for composing new BP messages. Our model, Deep Attentive Belief Propagation
(DABP), takes the factor graph and the BP messages in each iteration as the
input and infers the optimal weights and damping factors through GRUs and GATs,
followed by a multi-head attention layer. Furthermore, unlike existing
neural-based BP variants, we propose a novel self-supervised learning algorithm
for DABP with a smoothed solution cost, which does not require expensive
training labels and also avoids the common out-of-distribution issue through
efficient online learning. Extensive experiments show that our model
significantly outperforms state-of-the-art baselines.",None,-1
7c689472-8c9a-4982-95ef-57b6cbe7bcad,Measuring and Improving the Use of Graph Information in Graph Neural Networks,0.709562,"Graph neural networks (GNNs) have been widely used for representation
learning on graph data. However, there is limited understanding on how much
performance GNNs actually gain from graph data. This paper introduces a
context-surrounding GNN framework and proposes two smoothness metrics to
measure the quantity and quality of information obtained from graph data. A new
GNN model, called CS-GNN, is then designed to improve the use of graph
information based on the smoothness values of a graph. CS-GNN is shown to
achieve better performance than existing methods in different types of real
graphs.",None,-1
8e03f137-8f36-4118-92d7-74fc508c301b,Explanations as Programs in Probabilistic Logic Programming,0.208357,"The generation of comprehensible explanations is an essential feature of
modern artificial intelligence systems. In this work, we consider probabilistic
logic programming, an extension of logic programming which can be useful to
model domains with relational structure and uncertainty. Essentially, a program
specifies a probability distribution over possible worlds (i.e., sets of
facts). The notion of explanation is typically associated with that of a world,
so that one often looks for the most probable world as well as for the worlds
where the query is true. Unfortunately, such explanations exhibit no causal
structure. In particular, the chain of inferences required for a specific
prediction (represented by a query) is not shown. In this paper, we propose a
novel approach where explanations are represented as programs that are
generated from a given query by a number of unfolding-like transformations.
Here, the chain of inferences that proves a given query is made explicit.
Furthermore, the generated explanations are minimal (i.e., contain no
irrelevant information) and can be parameterized w.r.t. a specification of
visible predicates, so that the user may hide uninteresting details from
explanations.",None,-1
a8e210fc-9a57-43d1-ab98-bf2f74e77564,Towards Inter-character Relationship-driven Story Generation,0.731222,"In this paper, we introduce the task of modeling interpersonal relationships
for story generation. For addressing this task, we propose Relationships as
Latent Variables for Story Generation, (ReLiSt). ReLiSt generates stories
sentence by sentence and has two major components - a relationship selector and
a story continuer. The relationship selector specifies a latent variable to
pick the relationship to exhibit in the next sentence and the story continuer
generates the next sentence while expressing the selected relationship in a
coherent way. Our automatic and human evaluations demonstrate that ReLiSt is
able to generate stories with relationships that are more faithful to desired
relationships while maintaining the content quality. The relationship
assignments to sentences during inference bring interpretability to ReLiSt.",https://github.com/dbamman/book-nlp,-1
d6c8b6ad-ba33-4035-8fb9-6fa32c691911,Zero Experience Required: Plug & Play Modular Transfer Learning for Semantic Visual Navigation,0.561553,"In reinforcement learning for visual navigation, it is common to develop a
model for each new task, and train that model from scratch with task-specific
interactions in 3D environments. However, this process is expensive; massive
amounts of interactions are needed for the model to generalize well. Moreover,
this process is repeated whenever there is a change in the task type or the
goal modality. We present a unified approach to visual navigation using a novel
modular transfer learning model. Our model can effectively leverage its
experience from one source task and apply it to multiple target tasks (e.g.,
ObjectNav, RoomNav, ViewNav) with various goal modalities (e.g., image, sketch,
audio, label). Furthermore, our model enables zero-shot experience learning,
whereby it can solve the target tasks without receiving any task-specific
interactive training. Our experiments on multiple photorealistic datasets and
challenging tasks show that our approach learns faster, generalizes better, and
outperforms SoTA models by a significant margin.",https://vision.cs.utexas.edu/projects/zsel/,-1
bc45c70e-4adb-4738-b2ed-2c251c593121,Talking About Large Language Models,0.490064,"Thanks to rapid progress in artificial intelligence, we have entered an era
when technology and philosophy intersect in interesting ways. Sitting squarely
at the centre of this intersection are large language models (LLMs). The more
adept LLMs become at mimicking human language, the more vulnerable we become to
anthropomorphism, to seeing the systems in which they are embedded as more
human-like than they really are. This trend is amplified by the natural
tendency to use philosophically loaded terms, such as ""knows"", ""believes"", and
""thinks"", when describing these systems. To mitigate this trend, this paper
advocates the practice of repeatedly stepping back to remind ourselves of how
LLMs, and the systems of which they form a part, actually work. The hope is
that increased scientific precision will encourage more philosophical nuance in
the discourse around artificial intelligence, both within the field and in the
public sphere.",None,-1
cbad9711-4396-48c4-8e45-d2676f0d2eba,Adversarially-Aware Robust Object Detector,0.641784,"Object detection, as a fundamental computer vision task, has achieved a
remarkable progress with the emergence of deep neural networks. Nevertheless,
few works explore the adversarial robustness of object detectors to resist
adversarial attacks for practical applications in various real-world scenarios.
Detectors have been greatly challenged by unnoticeable perturbation, with sharp
performance drop on clean images and extremely poor performance on adversarial
images. In this work, we empirically explore the model training for adversarial
robustness in object detection, which greatly attributes to the conflict
between learning clean images and adversarial images. To mitigate this issue,
we propose a Robust Detector (RobustDet) based on adversarially-aware
convolution to disentangle gradients for model learning on clean and
adversarial images. RobustDet also employs the Adversarial Image Discriminator
(AID) and Consistent Features with Reconstruction (CFR) to ensure a reliable
robustness. Extensive experiments on PASCAL VOC and MS-COCO demonstrate that
our model effectively disentangles gradients and significantly enhances the
detection robustness with maintaining the detection ability on clean images.",https://github.com/7eu7d7/RobustDet,-1
f97fe304-7fcf-4ba6-9c6a-fefa4519f6aa,"Fewer Errors, but More Stereotypes? The Effect of Model Size on Gender Bias",0.719545,"The size of pretrained models is increasing, and so is their performance on a
variety of NLP tasks. However, as their memorization capacity grows, they might
pick up more social biases. In this work, we examine the connection between
model size and its gender bias (specifically, occupational gender bias). We
measure bias in three masked language model families (RoBERTa, DeBERTa, and T5)
in two setups: directly using prompt based method, and using a downstream task
(Winogender). We find on the one hand that larger models receive higher bias
scores on the former task, but when evaluated on the latter, they make fewer
gender errors. To examine these potentially conflicting results, we carefully
investigate the behavior of the different models on Winogender. We find that
while larger models outperform smaller ones, the probability that their
mistakes are caused by gender bias is higher. Moreover, we find that the
proportion of stereotypical errors compared to anti-stereotypical ones grows
with the model size. Our findings highlight the potential risks that can arise
from increasing model size.",https://github.com/schwartz-lab-NLP/model_size_and_gender_bias,-1
ab5b9980-57fd-4d85-8e5b-9d835cc67b8a,Parameter-Efficient Finetuning for Robust Continual Multilingual Learning,0.165661,"We introduce and study the problem of Continual Multilingual Learning (CML)
where a previously trained multilingual model is periodically updated using new
data arriving in stages. If the new data is present only in a subset of
languages, we find that the resulting model shows improved performance only on
the languages included in the latest update (and a few closely related
languages) while its performance on all the remaining languages degrade
significantly. We address this challenge by proposing LAFT-URIEL, a
parameter-efficient finetuning strategy which aims to increase the number of
languages on which the model improves after an update, while reducing the
magnitude of loss in performance for the remaining languages. LAFT-URIEL uses
linguistic knowledge to balance overfitting and knowledge sharing across
languages, allowing for an additional 25% of task languages to see an
improvement in performance after an update, while also reducing the average
magnitude of losses on the remaining languages by 78% relative.",None,-1
23094c27-887d-467e-baad-37ce52857f0c,Towards Realistic Low-resource Relation Extraction: A Benchmark with Empirical Baseline Study,0.30678,"This paper presents an empirical study to build relation extraction systems
in low-resource settings. Based upon recent pre-trained language models, we
comprehensively investigate three schemes to evaluate the performance in
low-resource settings: (i) different types of prompt-based methods with
few-shot labeled data; (ii) diverse balancing methods to address the
long-tailed distribution issue; (iii) data augmentation technologies and
self-training to generate more labeled in-domain data. We create a benchmark
with 8 relation extraction (RE) datasets covering different languages, domains
and contexts and perform extensive comparisons over the proposed schemes with
combinations. Our experiments illustrate: (i) Though prompt-based tuning is
beneficial in low-resource RE, there is still much potential for improvement,
especially in extracting relations from cross-sentence contexts with multiple
relational triples; (ii) Balancing methods are not always helpful for RE with
long-tailed distribution; (iii) Data augmentation complements existing
baselines and can bring much performance gain, while self-training may not
consistently achieve advancement to low-resource RE. Code and datasets are in
https://github.com/zjunlp/LREBench.",https://github.com/zjunlp/LREBench,16796
0e2ca77c-f56f-4759-93dc-a326da602321,3D-CSL: self-supervised 3D context similarity learning for Near-Duplicate Video Retrieval,0.230504,"In this paper, we introduce 3D-CSL, a compact pipeline for Near-Duplicate
Video Retrieval (NDVR), and explore a novel self-supervised learning strategy
for video similarity learning. Most previous methods only extract video spatial
features from frames separately and then design kinds of complex mechanisms to
learn the temporal correlations among frame features. However, parts of
spatiotemporal dependencies have already been lost. To address this, our 3D-CSL
extracts global spatiotemporal dependencies in videos end-to-end with a 3D
transformer and find a good balance between efficiency and effectiveness by
matching on clip-level. Furthermore, we propose a two-stage self-supervised
similarity learning strategy to optimize the entire network. Firstly, we
propose PredMAE to pretrain the 3D transformer with video prediction task;
Secondly, ShotMix, a novel video-specific augmentation, and FCS loss, a novel
triplet loss, are proposed further promote the similarity learning results. The
experiments on FIVR-200K and CC_WEB_VIDEO demonstrate the superiority and
reliability of our method, which achieves the state-of-the-art performance on
clip-level NDVR.",None,171
568e1748-b0a8-4307-9115-d2ef2315bbbd,Fast Event-based Optical Flow Estimation by Triplet Matching,0.887678,"Event cameras are novel bio-inspired sensors that offer advantages over
traditional cameras (low latency, high dynamic range, low power, etc.). Optical
flow estimation methods that work on packets of events trade off speed for
accuracy, while event-by-event (incremental) methods have strong assumptions
and have not been tested on common benchmarks that quantify progress in the
field. Towards applications on resource-constrained devices, it is important to
develop optical flow algorithms that are fast, light-weight and accurate. This
work leverages insights from neuroscience, and proposes a novel optical flow
estimation scheme based on triplet matching. The experiments on publicly
available benchmarks demonstrate its capability to handle complex scenes with
comparable results as prior packet-based algorithms. In addition, the proposed
method achieves the fastest execution time (> 10 kHz) on standard CPUs as it
requires only three events in estimation. We hope that our research opens the
door to real-time, incremental motion estimation methods and applications in
real-world scenarios.",None,-1
30885cf3-56b3-4c27-a973-85635f62cee0,An Intermediate-level Attack Framework on The Basis of Linear Regression,0.420282,"This paper substantially extends our work published at ECCV, in which an
intermediate-level attack was proposed to improve the transferability of some
baseline adversarial examples. Specifically, we advocate a framework in which a
direct linear mapping from the intermediate-level discrepancies (between
adversarial features and benign features) to prediction loss of the adversarial
example is established. By delving deep into the core components of such a
framework, we show that 1) a variety of linear regression models can all be
considered in order to establish the mapping, 2) the magnitude of the finally
obtained intermediate-level adversarial discrepancy is correlated with the
transferability, 3) further boost of the performance can be achieved by
performing multiple runs of the baseline attack with random initialization. In
addition, by leveraging these findings, we achieve new state-of-the-arts on
transfer-based $\ell_\infty$ and $\ell_2$ attacks. Our code is publicly
available at https://github.com/qizhangli/ila-plus-plus-lr.",https://github.com/qizhangli/ila-plus-plus-lr,60691
a1d6f42e-8c30-41fb-90d9-868640c41ac9,Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning,0.284067,"The rapidly-developing intersection of machine learning (ML) with high-energy
physics (HEP) presents both opportunities and challenges to our community. Far
beyond applications of standard ML tools to HEP problems, genuinely new and
potentially revolutionary approaches are being developed by a generation of
talent literate in both fields. There is an urgent need to support the needs of
the interdisciplinary community driving these developments, including funding
dedicated research at the intersection of the two fields, investing in
high-performance computing at universities and tailoring allocation policies to
support this work, developing of community tools and standards, and providing
education and career paths for young researchers attracted by the intellectual
vitality of machine learning for high energy physics.",None,-1
e6f16b2a-6402-4a28-8045-131996f6e302,Class-Incremental Learning for Action Recognition in Videos,0.871464,"We tackle catastrophic forgetting problem in the context of class-incremental
learning for video recognition, which has not been explored actively despite
the popularity of continual learning. Our framework addresses this challenging
task by introducing time-channel importance maps and exploiting the importance
maps for learning the representations of incoming examples via knowledge
distillation. We also incorporate a regularization scheme in our objective
function, which encourages individual features obtained from different time
steps in a video to be uncorrelated and eventually improves accuracy by
alleviating catastrophic forgetting. We evaluate the proposed approach on
brand-new splits of class-incremental action recognition benchmarks constructed
upon the UCF101, HMDB51, and Something-Something V2 datasets, and demonstrate
the effectiveness of our algorithm in comparison to the existing continual
learning methods that are originally designed for image data.",https://github.com/mit-han-lab/temporal-shift-module,-1
778fe56d-386c-4502-8c00-75365859a891,Relation-Specific Attentions over Entity Mentions for Enhanced Document-Level Relation Extraction,0.912085,"Compared with traditional sentence-level relation extraction, document-level
relation extraction is a more challenging task where an entity in a document
may be mentioned multiple times and associated with multiple relations.
However, most methods of document-level relation extraction do not distinguish
between mention-level features and entity-level features, and just apply simple
pooling operation for aggregating mention-level features into entity-level
features. As a result, the distinct semantics between the different mentions of
an entity are overlooked. To address this problem, we propose RSMAN in this
paper which performs selective attentions over different entity mentions with
respect to candidate relations. In this manner, the flexible and
relation-specific representations of entities are obtained which indeed benefit
relation classification. Our extensive experiments upon two benchmark datasets
show that our RSMAN can bring significant improvements for some backbone models
to achieve state-of-the-art performance, especially when an entity have
multiple mentions in the document.",https://github.com/FDUyjx/RSMAN,-1
559d5786-8323-4067-9ee5-7edb7d2a581f,Positive Unlabeled Contrastive Learning,0.531131,"Self-supervised pretraining on unlabeled data followed by supervised
fine-tuning on labeled data is a popular paradigm for learning from limited
labeled examples. We extend this paradigm to the classical positive unlabeled
(PU) setting, where the task is to learn a binary classifier given only a few
labeled positive samples, and (often) a large amount of unlabeled samples
(which could be positive or negative).
  We first propose a simple extension of standard infoNCE family of contrastive
losses, to the PU setting; and show that this learns superior representations,
as compared to existing unsupervised and supervised approaches. We then develop
a simple methodology to pseudo-label the unlabeled samples using a new
PU-specific clustering scheme; these pseudo-labels can then be used to train
the final (positive vs. negative) classifier. Our method handily outperforms
state-of-the-art PU methods over several standard PU benchmark datasets, while
not requiring a-priori knowledge of any class prior (which is a common
assumption in other PU methods). We also provide a simple theoretical analysis
that motivates our methods.",None,-1
99bb0c9c-d2cc-4522-8179-1fc2d1042163,TAPE: Task-Agnostic Prior Embedding for Image Restoration,0.746813,"Learning a generalized prior for natural image restoration is an important
yet challenging task. Early methods mostly involved handcrafted priors
including normalized sparsity, l_0 gradients, dark channel priors, etc.
Recently, deep neural networks have been used to learn various image priors but
do not guarantee to generalize. In this paper, we propose a novel approach that
embeds a task-agnostic prior into a transformer. Our approach, named
Task-Agnostic Prior Embedding (TAPE), consists of two stages, namely,
task-agnostic pre-training and task-specific fine-tuning, where the first stage
embeds prior knowledge about natural images into the transformer and the second
stage extracts the knowledge to assist downstream image restoration.
Experiments on various types of degradation validate the effectiveness of TAPE.
The image restoration performance in terms of PSNR is improved by as much as
1.45dB and even outperforms task-specific algorithms. More importantly, TAPE
shows the ability of disentangling generalized image priors from degraded
images, which enjoys favorable transfer ability to unknown downstream tasks.",None,-1
04d87ead-1cac-402a-97c4-0d130802f891,Pretrained Domain-Specific Language Model for General Information Retrieval Tasks in the AEC Domain,0.539876,"As an essential task for the architecture, engineering, and construction
(AEC) industry, information retrieval (IR) from unstructured textual data based
on natural language processing (NLP) is gaining increasing attention. Although
various deep learning (DL) models for IR tasks have been investigated in the
AEC domain, it is still unclear how domain corpora and domain-specific
pretrained DL models can improve performance in various IR tasks. To this end,
this work systematically explores the impacts of domain corpora and various
transfer learning techniques on the performance of DL models for IR tasks and
proposes a pretrained domain-specific language model for the AEC domain. First,
both in-domain and close-domain corpora are developed. Then, two types of
pretrained models, including traditional wording embedding models and
BERT-based models, are pretrained based on various domain corpora and transfer
learning strategies. Finally, several widely used DL models for IR tasks are
further trained and tested based on various configurations and pretrained
models. The result shows that domain corpora have opposite effects on
traditional word embedding models for text classification and named entity
recognition tasks but can further improve the performance of BERT-based models
in all tasks. Meanwhile, BERT-based models dramatically outperform traditional
methods in all IR tasks, with maximum improvements of 5.4% and 10.1% in the F1
score, respectively. This research contributes to the body of knowledge in two
ways: 1) demonstrating the advantages of domain corpora and pretrained DL
models and 2) opening the first domain-specific dataset and pretrained language
model for the AEC domain, to the best of our knowledge. Thus, this work sheds
light on the adoption and application of pretrained models in the AEC domain.",None,1701
a3f20dd6-1a10-4573-84a7-e2efdeb34d0b,LiteVL: Efficient Video-Language Learning with Enhanced Spatial-Temporal Modeling,0.373974,"Recent large-scale video-language pre-trained models have shown appealing
performance on various downstream tasks. However, the pre-training process is
computationally expensive due to the requirement of millions of video-text
pairs and the redundant data structure of each video. To mitigate these
problems, we propose LiteVL, which adapts a pre-trained image-language model
BLIP into a video-text model directly on downstream tasks, without heavy
pre-training. To enhance the temporal modeling lacking in the image-language
model, we propose to add temporal attention modules in the image encoder of
BLIP with dynamic temporal scaling. Besides the model-wise adaptation, we also
propose a non-parametric pooling mechanism to adaptively reweight the
fine-grained video embedding conditioned on the text. Experimental results on
text-video retrieval and video question answering show that the proposed LiteVL
even outperforms previous video-language pre-trained models by a clear margin,
though without any video-language pre-training.",None,-1
48cbb439-7ea0-4b69-b7c2-b6b441f745f4,Low-resource Accent Classification in Geographically-proximate Settings: A Forensic and Sociophonetics Perspective,0.0375739,"Accented speech recognition and accent classification are relatively
under-explored research areas in speech technology. Recently, deep
learning-based methods and Transformer-based pretrained models have achieved
superb performances in both areas. However, most accent classification tasks
focused on classifying different kinds of English accents and little attention
was paid to geographically-proximate accent classification, especially under a
low-resource setting where forensic speech science tasks usually encounter. In
this paper, we explored three main accent modelling methods combined with two
different classifiers based on 105 speaker recordings retrieved from five urban
varieties in Northern England. Although speech representations generated from
pretrained models generally have better performances in downstream
classification, traditional methods like Mel Frequency Cepstral Coefficients
(MFCCs) and formant measurements are equipped with specific strengths. These
results suggest that in forensic phonetics scenario where data are relatively
scarce, a simple modelling method and classifier could be competitive with
state-of-the-art pretrained speech models as feature extractors, which could
enhance a sooner estimation for the accent information in practices. Besides,
our findings also cross-validated a new methodology in quantifying
sociophonetic changes.",None,-1
c3b245d9-e1dc-4106-8526-9cb5ad695d09,Representation and Synthesis of C++ Programs for Generalized Planning,0.132558,"The paper introduces a novel representation for Generalized Planning (GP)
problems, and their solutions, as C++ programs. Our C++ representation allows
to formally proving the termination of generalized plans, and to specifying
their asymptotic complexity w.r.t. the number of world objects. Characterizing
the complexity of C++ generalized plans enables the application of a
combinatorial search that enumerates the space of possible GP solutions in
order of complexity. Experimental results show that our implementation of this
approach, which we call BFGP++, outperforms the previous GP as heuristic search
approach for the computation of generalized plans represented as
compiler-styled programs. Last but not least, the execution of a C++ program on
a classical planning instance is a deterministic grounding-free and search-free
process, so our C++ representation allows us to automatically validate the
computed solutions on large test instances of thousands of objects, where
off-the-shelf classical planners get stuck either in the pre-processing or in
the search.",None,-1
8b930b21-9f4c-43da-82d9-7c3767d429f2,A temporal chrominance trigger for clean-label backdoor attack against anti-spoof rebroadcast detection,0.243719,"We propose a stealthy clean-label video backdoor attack against Deep Learning
(DL)-based models aiming at detecting a particular class of spoofing attacks,
namely video rebroadcast attacks. The injected backdoor does not affect
spoofing detection in normal conditions, but induces a misclassification in the
presence of a specific triggering signal. The proposed backdoor relies on a
temporal trigger altering the average chrominance of the video sequence. The
backdoor signal is designed by taking into account the peculiarities of the
Human Visual System (HVS) to reduce the visibility of the trigger, thus
increasing the stealthiness of the backdoor. To force the network to look at
the presence of the trigger in the challenging clean-label scenario, we choose
the poisoned samples used for the injection of the backdoor following a
so-called Outlier Poisoning Strategy (OPS). According to OPS, the triggering
signal is inserted in the training samples that the network finds more
difficult to classify. The effectiveness of the proposed backdoor attack and
its generality are validated experimentally on different datasets and
anti-spoofing rebroadcast detection architectures.",None,-1
1913851b-a9dc-4490-9439-d421ec1dfb75,DISCO: Distilling Counterfactuals with Large Language Models,0.287149,"Models trained with counterfactually augmented data learn representations of
the causal structure of tasks, enabling robust generalization. However,
high-quality counterfactual data is scarce for most tasks and not easily
generated at scale. When crowdsourced, such data is typically limited in scale
and diversity; when generated using supervised methods, it is computationally
expensive to extend to new counterfactual dimensions. In this work, we
introduce DISCO (DIStilled COunterfactual Data), a new method for automatically
generating high quality counterfactual data at scale. DISCO engineers prompts
to generate phrasal perturbations with a large general language model. Then, a
task-specific teacher model filters these generations to distill high-quality
counterfactual data. While task-agnostic, we apply our pipeline to the task of
natural language inference (NLI) and find that on challenging evaluations such
as the NLI stress test, comparatively smaller student models trained with DISCO
generated counterfactuals are more robust (6% absolute) and generalize better
across distributions (2%) compared to models trained without data augmentation.
Furthermore, DISCO augmented models are 10% more consistent between
counterfactual pairs on three evaluation sets, demonstrating that DISCO
augmentation enables models to more reliably learn causal representations. Our
repository is available at: https://github.com/eric11eca/disco",https://github.com/eric11eca/disco,-1
0ed998e4-0de6-4c55-b95d-aeaeffb5bb18,A Compacted Structure for Cross-domain learning on Monocular Depth and Flow Estimation,0.0638427,"Accurate motion and depth recovery is important for many robot vision tasks
including autonomous driving. Most previous studies have achieved cooperative
multi-task interaction via either pre-defined loss functions or cross-domain
prediction. This paper presents a multi-task scheme that achieves mutual
assistance by means of our Flow to Depth (F2D), Depth to Flow (D2F), and
Exponential Moving Average (EMA). F2D and D2F mechanisms enable multi-scale
information integration between optical flow and depth domain based on
differentiable shallow nets. A dual-head mechanism is used to predict optical
flow for rigid and non-rigid motion based on a divide-and-conquer manner, which
significantly improves the optical flow estimation performance. Furthermore, to
make the prediction more robust and stable, EMA is used for our multi-task
training. Experimental results on KITTI datasets show that our multi-task
scheme outperforms other multi-task schemes and provide marked improvements on
the prediction results.",None,26399
64319bc7-3248-4f5d-bfef-4ff100de4bc4,A sequence-to-sequence approach for document-level relation extraction,0.99205,"Motivated by the fact that many relations cross the sentence boundary, there
has been increasing interest in document-level relation extraction (DocRE).
DocRE requires integrating information within and across sentences, capturing
complex interactions between mentions of entities. Most existing methods are
pipeline-based, requiring entities as input. However, jointly learning to
extract entities and relations can improve performance and be more efficient
due to shared parameters and training steps. In this paper, we develop a
sequence-to-sequence approach, seq2rel, that can learn the subtasks of DocRE
(entity extraction, coreference resolution and relation extraction) end-to-end,
replacing a pipeline of task-specific components. Using a simple strategy we
call entity hinting, we compare our approach to existing pipeline-based methods
on several popular biomedical datasets, in some cases exceeding their
performance. We also report the first end-to-end results on these datasets for
future comparison. Finally, we demonstrate that, under our model, an end-to-end
approach outperforms a pipeline-based approach. Our code, data and trained
models are available at {\url{https://github.com/johngiorgi/seq2rel}}. An
online demo is available at
{\url{https://share.streamlit.io/johngiorgi/seq2rel/main/demo.py}}.",https://github.com/johngiorgi/seq2rel,-1
5d8b0570-dc65-4d11-8c6f-caf7b1391c71,A Close Look into the Calibration of Pre-trained Language Models,0.846799,"Pre-trained language models (PLMs) may fail in giving reliable estimates of
their predictive uncertainty. We take a close look into this problem, aiming to
answer two questions: (1) Do PLMs learn to become calibrated in the training
process? (2) How effective are existing calibration methods? For the first
question, we conduct fine-grained control experiments to study the dynamic
change in PLMs' calibration performance in training. We consider six factors as
control variables, including dataset difficulty, available training samples,
training steps, the number of tunable parameters, model scale, and pretraining.
We observe a consistent change in calibration performance across six factors.
We find that PLMs don't learn to become calibrated in training, evidenced by
the continual increase in confidence, no matter whether the predictions are
correct or not. We highlight that our finding somewhat contradicts two
established conclusions: (a) Larger PLMs are more calibrated; (b) Pretraining
improves model calibration. Next, we study the effectiveness of existing
calibration methods in mitigating the overconfidence issue. Besides unlearnable
calibration methods (e.g., label smoothing), we adapt and extend two recently
proposed learnable methods that directly collect data to train models to have
reasonable confidence estimations. Experimental results show that learnable
methods significantly reduce PLMs' confidence in wrong predictions. The code is
available at \url{https://github.com/lifan-yuan/PLMCalibration}.",https://github.com/lifan-yuan/PLMCalibration,-1
a21813d8-82b4-4a97-870e-fa9fdac5215d,Hierarchical Transformer Model for Scientific Named Entity Recognition,0.146224,"The task of Named Entity Recognition (NER) is an important component of many
natural language processing systems, such as relation extraction and knowledge
graph construction. In this work, we present a simple and effective approach
for Named Entity Recognition. The main idea of our approach is to encode the
input subword sequence with a pre-trained transformer such as BERT, and then,
instead of directly classifying the word labels, another layer of transformer
is added to the subword representation to better encode the word-level
interaction. We evaluate our approach on three benchmark datasets for
scientific NER, particularly in the computer science and biomedical domains.
Experimental results show that our model outperforms the current
state-of-the-art on SciERC and TDM datasets without requiring external
resources or specific data augmentation. Code is available at
\url{https://github.com/urchade/HNER}.",https://github.com/urchade/HNER,-1
4e76cc0a-d55d-445f-81bb-2681bd0f9983,Generative Aspect-Based Sentiment Analysis with Contrastive Learning and Expressive Structure,0.86535,"Generative models have demonstrated impressive results on Aspect-based
Sentiment Analysis (ABSA) tasks, particularly for the emerging task of
extracting Aspect-Category-Opinion-Sentiment (ACOS) quadruples. However, these
models struggle with implicit sentiment expressions, which are commonly
observed in opinionated content such as online reviews. In this work, we
introduce GEN-SCL-NAT, which consists of two techniques for improved structured
generation for ACOS quadruple extraction. First, we propose GEN-SCL, a
supervised contrastive learning objective that aids quadruple prediction by
encouraging the model to produce input representations that are discriminable
across key input attributes, such as sentiment polarity and the existence of
implicit opinions and aspects. Second, we introduce GEN-NAT, a new structured
generation format that better adapts autoregressive encoder-decoder models to
extract quadruples in a generative fashion. Experimental results show that
GEN-SCL-NAT achieves top performance across three ACOS datasets, averaging
1.48% F1 improvement, with a maximum 1.73% increase on the LAPTOP-L1 dataset.
Additionally, we see significant gains on implicit aspect and opinion splits
that have been shown as challenging for existing ACOS approaches.",https://github.com/jpeper/GEN_SCL_NAT,-1
2cef28ec-d750-4874-82b5-3cc33957a719,Streaming Radiance Fields for 3D Video Synthesis,0.592729,"We present an explicit-grid based method for efficiently reconstructing
streaming radiance fields for novel view synthesis of real world dynamic
scenes. Instead of training a single model that combines all the frames, we
formulate the dynamic modeling problem with an incremental learning paradigm in
which per-frame model difference is trained to complement the adaption of a
base model on the current frame. By exploiting the simple yet effective tuning
strategy with narrow bands, the proposed method realizes a feasible framework
for handling video sequences on-the-fly with high training efficiency. The
storage overhead induced by using explicit grid representations can be
significantly reduced through the use of model difference based compression. We
also introduce an efficient strategy to further accelerate model optimization
for each frame. Experiments on challenging video sequences demonstrate that our
approach is capable of achieving a training speed of 15 seconds per-frame with
competitive rendering quality, which attains $1000 \times$ speedup over the
state-of-the-art implicit methods. Code is available at
https://github.com/AlgoHunt/StreamRF.",https://github.com/AlgoHunt/StreamRF,-1
746e5305-687e-4693-9e1f-0aa69907d5c1,Playing Tic-Tac-Toe Games with Intelligent Single-pixel Imaging,0.0934564,"Single-pixel imaging (SPI) is a novel optical imaging technique by replacing
a two-dimensional pixelated sensor with a single-pixel detector and pattern
illuminations. SPI have been extensively used for various tasks related to
image acquisition and processing. In this work, a novel non-image-based task of
playing Tic-Tac-Toe games interactively is merged into the framework of SPI. An
optoelectronic artificial intelligent (AI) player with minimal digital
computation can detect the game states, generate optimal moves and display
output results mainly by pattern illumination and single-pixel detection.
Simulated and experimental results demonstrate the feasibility of proposed
scheme and its unbeatable performance against human players.",None,-1
0ea37169-5847-445c-bb2d-789246342f0a,Feature Engineering vs BERT on Twitter Data,0.123915,"In this paper, we compare the performances of traditional machine learning
models using feature engineering and word vectors and the state-of-the-art
language model BERT using word embeddings on three datasets. We also consider
the time and cost efficiency of feature engineering compared to BERT. From our
results we conclude that the use of the BERT model was only worth the time and
cost trade-off for one of the three datasets we used for comparison, where the
BERT model significantly outperformed any kind of traditional classifier that
uses feature vectors, instead of embeddings. Using the BERT model for the other
datasets only achieved an increase of 0.03 and 0.05 of accuracy and F1 score
respectively, which could be argued makes its use not worth the time and cost
of GPU.",None,180
71a1acce-cabf-4ea9-8177-5bd19eb2eeb5,SimpleTrack: Rethinking and Improving the JDE Approach for Multi-Object Tracking,0.605118,"Joint detection and embedding (JDE) based methods usually estimate bounding
boxes and embedding features of objects with a single network in Multi-Object
Tracking (MOT). In the tracking stage, JDE-based methods fuse the target motion
information and appearance information by applying the same rule, which could
fail when the target is briefly lost or blocked. To overcome this problem, we
propose a new association matrix, the Embedding and Giou matrix, which combines
embedding cosine distance and Giou distance of objects. To further improve the
performance of data association, we develop a simple, effective tracker named
SimpleTrack, which designs a bottom-up fusion method for Re-identity and
proposes a new tracking strategy based on our EG matrix. The experimental
results indicate that SimpleTrack has powerful data association capability,
e.g., 61.6 HOTA and 76.3 IDF1 on MOT17. In addition, we apply the EG matrix to
5 different state-of-the-art JDE-based methods and achieve significant
improvements in IDF1, HOTA and IDsw metrics, and increase the tracking speed of
these methods by about 20%.",https://github.com/JonathonLuiten/TrackEval,-1
a97c8998-5204-4fb6-918c-ba12a21dc2e0,SmartFPS: Neural Network based Wireless-inertial fusion positioning system,0.387862,"The current fusion positioning systems are mainly based on filtering
algorithms, such as Kalman filtering or particle filtering. However, the system
complexity of practical application scenarios is often very high, such as noise
modeling in pedestrian inertial navigation systems, or environmental noise
modeling in fingerprint matching and localization algorithms. To solve this
problem, this paper proposes a fusion positioning system based on deep learning
and proposes a transfer learning strategy for improving the performance of
neural network models for samples with different distributions. The results
show that in the whole floor scenario, the average positioning accuracy of the
fusion network is 0.506m. The experiment results of transfer learning show that
the estimation accuracy of the inertial navigation positioning step size and
rotation angle of different pedestrians can be improved by 53.3% on average,
the Bluetooth positioning accuracy of different devices can be improved by
33.4%, and the fusion can be improved by 31.6%.",None,-1
9421cb9d-0fb4-4d4a-8334-a885001a25ce,Classifying Unstructured Clinical Notes via Automatic Weak Supervision,0.372204,"Healthcare providers usually record detailed notes of the clinical care
delivered to each patient for clinical, research, and billing purposes. Due to
the unstructured nature of these narratives, providers employ dedicated staff
to assign diagnostic codes to patients' diagnoses using the International
Classification of Diseases (ICD) coding system. This manual process is not only
time-consuming but also costly and error-prone. Prior work demonstrated
potential utility of Machine Learning (ML) methodology in automating this
process, but it has relied on large quantities of manually labeled data to
train the models. Additionally, diagnostic coding systems evolve with time,
which makes traditional supervised learning strategies unable to generalize
beyond local applications. In this work, we introduce a general
weakly-supervised text classification framework that learns from class-label
descriptions only, without the need to use any human-labeled documents. It
leverages the linguistic domain knowledge stored within pre-trained language
models and the data programming framework to assign code labels to individual
texts. We demonstrate the efficacy and flexibility of our method by comparing
it to state-of-the-art weak text classifiers across four real-world text
classification datasets, in addition to assigning ICD codes to medical notes in
the publicly available MIMIC-III database.",https://github.com/autonlab/KeyClass,-1
5da1538b-14fa-4f3b-a9cb-2ae515fc6183,Public Wisdom Matters! Discourse-Aware Hyperbolic Fourier Co-Attention for Social-Text Classification,0.582176,"Social media has become the fulcrum of all forms of communication.
Classifying social texts such as fake news, rumour, sarcasm, etc. has gained
significant attention. The surface-level signals expressed by a social-text
itself may not be adequate for such tasks; therefore, recent methods attempted
to incorporate other intrinsic signals such as user behavior and the underlying
graph structure. Oftentimes, the `public wisdom' expressed through the
comments/replies to a social-text acts as a surrogate of crowd-sourced view and
may provide us with complementary signals. State-of-the-art methods on
social-text classification tend to ignore such a rich hierarchical signal.
Here, we propose Hyphen, a discourse-aware hyperbolic spectral co-attention
network. Hyphen is a fusion of hyperbolic graph representation learning with a
novel Fourier co-attention mechanism in an attempt to generalise the
social-text classification tasks by incorporating public discourse. We parse
public discourse as an Abstract Meaning Representation (AMR) graph and use the
powerful hyperbolic geometric representation to model graphs with hierarchical
structure. Finally, we equip it with a novel Fourier co-attention mechanism to
capture the correlation between the source post and public discourse. Extensive
experiments on four different social-text classification tasks, namely
detecting fake news, hate speech, rumour, and sarcasm, show that Hyphen
generalises well, and achieves state-of-the-art results on ten benchmark
datasets. We also employ a sentence-level fact-checked and annotated dataset to
evaluate how Hyphen is capable of producing explanations as analogous evidence
to the final prediction.",https://github.com/LCS2-IIITD/Hyphen,-1
639b313d-5869-45dd-b89e-8375f932b532,SI-GAT: A method based on improved Graph Attention Network for sonar image classification,0.0589829,"The existing sonar image classification methods based on deep learning are
often analyzed in Euclidean space, only considering the local image features.
For this reason, this paper presents a sonar classification method based on
improved Graph Attention Network (GAT), namely SI-GAT, which is applicable to
multiple types imaging sonar. This method quantifies the correlation
relationship between nodes based on the joint calculation of color proximity
and spatial proximity that represent the sonar characteristics in non-Euclidean
space, then the KNN (K-Nearest Neighbor) algorithm is used to determine the
neighborhood range and adjacency matrix in the graph attention mechanism, which
are jointly considered with the attention coefficient matrix to construct the
key part of the SI-GAT. This SI-GAT is superior to several CNN (Convolutional
Neural Network) methods based on Euclidean space through validation of real
data.",https://github.com/huoguanying/SeabedObjects-Ship-and-Airplane-dataset.git,-1
1da933f4-e005-4840-8825-98678f25d14b,SubeventWriter: Iterative Sub-event Sequence Generation with Coherence Controller,0.698318,"In this paper, we propose a new task of sub-event generation for an unseen
process to evaluate the understanding of the coherence of sub-event actions and
objects. To solve the problem, we design SubeventWriter, a sub-event sequence
generation framework with a coherence controller. Given an unseen process, the
framework can iteratively construct the sub-event sequence by generating one
sub-event at each iteration. We also design a very effective coherence
controller to decode more coherent sub-events. As our extensive experiments and
analysis indicate, SubeventWriter can generate more reliable and meaningful
sub-event sequences for unseen processes.",https://github.com/HKUST-KnowComp/SubeventWriter,-1
996ba743-87e1-4c68-85de-e5c343e94cd9,RA-Depth: Resolution Adaptive Self-Supervised Monocular Depth Estimation,0.906333,"Existing self-supervised monocular depth estimation methods can get rid of
expensive annotations and achieve promising results. However, these methods
suffer from severe performance degradation when directly adopting a model
trained on a fixed resolution to evaluate at other different resolutions. In
this paper, we propose a resolution adaptive self-supervised monocular depth
estimation method (RA-Depth) by learning the scale invariance of the scene
depth. Specifically, we propose a simple yet efficient data augmentation method
to generate images with arbitrary scales for the same scene. Then, we develop a
dual high-resolution network that uses the multi-path encoder and decoder with
dense interactions to aggregate multi-scale features for accurate depth
inference. Finally, to explicitly learn the scale invariance of the scene
depth, we formulate a cross-scale depth consistency loss on depth predictions
with different scales. Extensive experiments on the KITTI, Make3D and NYU-V2
datasets demonstrate that RA-Depth not only achieves state-of-the-art
performance, but also exhibits a good ability of resolution adaptation.",https://github.com/hmhemu/RA-Depth,-1
19401553-0036-4474-a5d9-4bc11f5ca1bb,Continual Learning with Recursive Gradient Optimization,0.38371,"Learning multiple tasks sequentially without forgetting previous knowledge,
called Continual Learning(CL), remains a long-standing challenge for neural
networks. Most existing methods rely on additional network capacity or data
replay. In contrast, we introduce a novel approach which we refer to as
Recursive Gradient Optimization(RGO). RGO is composed of an iteratively updated
optimizer that modifies the gradient to minimize forgetting without data replay
and a virtual Feature Encoding Layer(FEL) that represents different long-term
structures with only task descriptors. Experiments demonstrate that RGO has
significantly better performance on popular continual classification benchmarks
when compared to the baselines and achieves new state-of-the-art performance on
20-split-CIFAR100(82.22%) and 20-split-miniImageNet(72.63%). With higher
average accuracy than Single-Task Learning(STL), this method is flexible and
reliable to provide continual learning capabilities for learning models that
rely on gradient descent.",None,-1
7bd04d70-b4cf-4078-885e-01ae466b28b7,Color Image Inpainting via Robust Pure Quaternion Matrix Completion: Error Bound and Weighted Loss,0.626417,"In this paper, we study color image inpainting as a pure quaternion matrix
completion problem. In the literature, the theoretical guarantee for quaternion
matrix completion is not well-established. Our main aim is to propose a new
minimization problem with an objective combining nuclear norm and a quadratic
loss weighted among three channels. To fill the theoretical vacancy, we obtain
the error bound in both clean and corrupted regimes, which relies on some new
results of quaternion matrices. A general Gaussian noise is considered in
robust completion where all observations are corrupted. Motivated by the error
bound, we propose to handle unbalanced or correlated noise via a cross-channel
weight in the quadratic loss, with the main purpose of rebalancing noise level,
or removing noise correlation. Extensive experimental results on synthetic and
color image data are presented to confirm and demonstrate our theoretical
findings.",None,-1
1409a0b3-919b-443d-93ee-0857eb83c006,Discourse Analysis for Evaluating Coherence in Video Paragraph Captions,0.288711,"Video paragraph captioning is the task of automatically generating a coherent
paragraph description of the actions in a video. Previous linguistic studies
have demonstrated that coherence of a natural language text is reflected by its
discourse structure and relations. However, existing video captioning methods
evaluate the coherence of generated paragraphs by comparing them merely against
human paragraph annotations and fail to reason about the underlying discourse
structure. At UCLA, we are currently exploring a novel discourse based
framework to evaluate the coherence of video paragraphs. Central to our
approach is the discourse representation of videos, which helps in modeling
coherence of paragraphs conditioned on coherence of videos. We also introduce
DisNet, a novel dataset containing the proposed visual discourse annotations of
3000 videos and their paragraphs. Our experiment results have shown that the
proposed framework evaluates coherence of video paragraphs significantly better
than all the baseline methods. We believe that many other multi-discipline
Artificial Intelligence problems such as Visual Dialog and Visual Storytelling
would also greatly benefit from the proposed visual discourse framework and the
DisNet dataset.",None,-1
79c2a4b0-5a33-4a82-92da-8ac4df7dc881,Adaptive Transformers for Robust Few-shot Cross-domain Face Anti-spoofing,0.681298,"While recent face anti-spoofing methods perform well under the intra-domain
setups, an effective approach needs to account for much larger appearance
variations of images acquired in complex scenes with different sensors for
robust performance. In this paper, we present adaptive vision transformers
(ViT) for robust cross-domain face antispoofing. Specifically, we adopt ViT as
a backbone to exploit its strength to account for long-range dependencies among
pixels. We further introduce the ensemble adapters module and feature-wise
transformation layers in the ViT to adapt to different domains for robust
performance with a few samples. Experiments on several benchmark datasets show
that the proposed models achieve both robust and competitive performance
against the state-of-the-art methods for cross-domain face anti-spoofing using
a few samples.",None,-1
17f88e41-72e1-472c-981a-fb019ca41dd0,Contrastive Learning of Coarse-Grained Force Fields,0.644812,"Coarse-grained models have proven helpful for simulating complex systems over
long timescales to provide molecular insights into various processes.
Methodologies for systematic parameterization of the underlying energy
function, or force field that describes the interactions among different
components of the system are of great interest for ensuring simulation
accuracy. We present a new method, potential contrasting, to enable efficient
learning of force fields that can accurately reproduce the conformational
distribution produced with all-atom simulations. Potential contrasting
generalizes the noise contrastive estimation method with umbrella sampling to
better learn the complex energy landscape of molecular systems. When applied to
the Trp-cage protein, we found that the technique produces force fields that
thoroughly capture the thermodynamics of the folding process despite the use of
only $\alpha$-Carbons in the coarse-grained model. We further showed that
potential contrasting could be applied over large datasets that combine the
conformational ensembles of many proteins to ensure the transferability of
coarse-grained force fields. We anticipate potential contrasting to be a
powerful tool for building general-purpose coarse-grained force fields.",None,-1
07c22fc3-f818-4db8-b835-f5110e3b5698,A Vocabulary-Free Multilingual Neural Tokenizer for End-to-End Task Learning,0.117033,"Subword tokenization is a commonly used input pre-processing step in most
recent NLP models. However, it limits the models' ability to leverage
end-to-end task learning. Its frequency-based vocabulary creation compromises
tokenization in low-resource languages, leading models to produce suboptimal
representations. Additionally, the dependency on a fixed vocabulary limits the
subword models' adaptability across languages and domains. In this work, we
propose a vocabulary-free neural tokenizer by distilling segmentation
information from heuristic-based subword tokenization. We pre-train our
character-based tokenizer by processing unique words from multilingual corpus,
thereby extensively increasing word diversity across languages. Unlike the
predefined and fixed vocabularies in subword methods, our tokenizer allows
end-to-end task learning, resulting in optimal task-specific tokenization. The
experimental results show that replacing the subword tokenizer with our neural
tokenizer consistently improves performance on multilingual (NLI) and
code-switching (sentiment analysis) tasks, with larger gains in low-resource
languages. Additionally, our neural tokenizer exhibits a robust performance on
downstream tasks when adversarial noise is present (typos and misspelling),
further increasing the initial improvements over statistical subword
tokenizers.",None,3040
3439d365-4bfb-47d7-908f-ead36413d531,Turning Stocks into Memes: A Dataset for Understanding How Social Communities Can Drive Wall Street,0.148272,"Who actually expresses an intent to buy GameStop shares on Reddit? What
convinces people to buy stocks? Are people convinced to support a coordinated
plan to adversely impact Wall Street investors? Existing literature on
understanding intent has mainly relied on surveys and self reporting; however
there are limitations to these methodologies. Hence, in this paper, we develop
an annotated dataset of communications centered on the GameStop phenomenon to
analyze the subscriber intentions behaviors within the r/WallStreetBets
community to buy (or not buy) stocks. Likewise, we curate a dataset to better
understand how intent interacts with a user's general support towards the
coordinated actions of the community for GameStop. Overall, our dataset can
provide insight to social scientists on the persuasive power to buy into social
movements online by adopting common language and narrative. WARNING: This paper
contains offensive language that commonly appears on Reddit's r/WallStreetBets
subreddit.",None,-1
564e6873-17f9-4679-9738-7de21530064e,Harnessing Multilingual Resources to Question Answering in Arabic,0.0350951,"The goal of the paper is to predict answers to questions given a passage of
Qur'an. The answers are always found in the passage, so the task of the model
is to predict where an answer starts and where it ends. As the initial data set
is rather small for training, we make use of multilingual BERT so that we can
augment the training data by using data available for languages other than
Arabic. Furthermore, we crawl a large Arabic corpus that is domain specific to
religious discourse. Our approach consists of two steps, first we train a BERT
model to predict a set of possible answers in a passage. Finally, we use
another BERT based model to rank the candidate answers produced by the first
BERT model.",https://github.com/aliftype/quran-data,-1
352024c3-1a18-4893-882e-6bbade80fddf,Dataset Distillation by Matching Training Trajectories,0.992013,"Dataset distillation is the task of synthesizing a small dataset such that a
model trained on the synthetic set will match the test accuracy of the model
trained on the full dataset. In this paper, we propose a new formulation that
optimizes our distilled data to guide networks to a similar state as those
trained on real data across many training steps. Given a network, we train it
for several iterations on our distilled data and optimize the distilled data
with respect to the distance between the synthetically trained parameters and
the parameters trained on real data. To efficiently obtain the initial and
target network parameters for large-scale datasets, we pre-compute and store
training trajectories of expert networks trained on the real dataset. Our
method handily outperforms existing methods and also allows us to distill
higher-resolution visual data.",None,133896
1f62d087-f006-4fdf-b9d2-f4a7fc3375b6,SimCURL: Simple Contrastive User Representation Learning from Command Sequences,0.130495,"User modeling is crucial to understanding user behavior and essential for
improving user experience and personalized recommendations. When users interact
with software, vast amounts of command sequences are generated through logging
and analytics systems. These command sequences contain clues to the users'
goals and intents. However, these data modalities are highly unstructured and
unlabeled, making it difficult for standard predictive systems to learn from.
We propose SimCURL, a simple yet effective contrastive self-supervised deep
learning framework that learns user representation from unlabeled command
sequences. Our method introduces a user-session network architecture, as well
as session dropout as a novel way of data augmentation. We train and evaluate
our method on a real-world command sequence dataset of more than half a billion
commands. Our method shows significant improvement over existing methods when
the learned representation is transferred to downstream tasks such as
experience and expertise classification.",None,4963
d6463ca0-2100-4597-895e-dd6834837127,Data Contamination: From Memorization to Exploitation,0.955182,"Pretrained language models are typically trained on massive web-based
datasets, which are often ""contaminated"" with downstream test sets. It is not
clear to what extent models exploit the contaminated data for downstream tasks.
We present a principled method to study this question. We pretrain BERT models
on joint corpora of Wikipedia and labeled downstream datasets, and fine-tune
them on the relevant task. Comparing performance between samples seen and
unseen during pretraining enables us to define and quantify levels of
memorization and exploitation. Experiments with two models and three downstream
tasks show that exploitation exists in some cases, but in others the models
memorize the contaminated data, but do not exploit it. We show that these two
measures are affected by different factors such as the number of duplications
of the contaminated data and the model size. Our results highlight the
importance of analyzing massive web-scale datasets to verify that progress in
NLP is obtained by better language understanding and not better data
exploitation.",https://github.com/schwartz-lab-NLP/data_contamination,-1
a87c18ba-6067-4528-a9a2-0033f58ef020,Learning Non-target Knowledge for Few-shot Semantic Segmentation,0.977019,"Existing studies in few-shot semantic segmentation only focus on mining the
target object information, however, often are hard to tell ambiguous regions,
especially in non-target regions, which include background (BG) and Distracting
Objects (DOs). To alleviate this problem, we propose a novel framework, namely
Non-Target Region Eliminating (NTRE) network, to explicitly mine and eliminate
BG and DO regions in the query. First, a BG Mining Module (BGMM) is proposed to
extract the BG region via learning a general BG prototype. To this end, we
design a BG loss to supervise the learning of BGMM only using the known target
object segmentation ground truth. Then, a BG Eliminating Module and a DO
Eliminating Module are proposed to successively filter out the BG and DO
information from the query feature, based on which we can obtain a BG and
DO-free target object segmentation result. Furthermore, we propose a
prototypical contrastive learning algorithm to improve the model ability of
distinguishing the target object from DOs. Extensive experiments on both
PASCAL-5i and COCO-20i datasets show that our approach is effective despite its
simplicity.",https://github.com/LIUYUANWEI98/NERTNet,-1
a15640d5-924e-4a16-bf68-178df5fd391d,Hybrid Deep Learning Model using SPCAGAN Augmentation for Insider Threat Analysis,0.140912,"Cyberattacks from within an organization's trusted entities are known as
insider threats. Anomaly detection using deep learning requires comprehensive
data, but insider threat data is not readily available due to confidentiality
concerns of organizations. Therefore, there arises demand to generate synthetic
data to explore enhanced approaches for threat analysis. We propose a linear
manifold learning-based generative adversarial network, SPCAGAN, that takes
input from heterogeneous data sources and adds a novel loss function to train
the generator to produce high-quality data that closely resembles the original
data distribution. Furthermore, we introduce a deep learning-based hybrid model
for insider threat analysis. We provide extensive experiments for data
synthesis, anomaly detection, adversarial robustness, and synthetic data
quality analysis using benchmark datasets. In this context, empirical
comparisons show that GAN-based oversampling is competitive with numerous
typical oversampling regimes. For synthetic data generation, our SPCAGAN model
overcame the problem of mode collapse and converged faster than previous GAN
models. Results demonstrate that our proposed approach has a lower error, is
more accurate, and generates substantially superior synthetic insider threat
data than previous models.",None,-1
686383b9-5438-41e2-9606-8ac5ef6242de,Unsupervised Scene Sketch to Photo Synthesis,0.798104,"Sketches make an intuitive and powerful visual expression as they are fast
executed freehand drawings. We present a method for synthesizing realistic
photos from scene sketches. Without the need for sketch and photo pairs, our
framework directly learns from readily available large-scale photo datasets in
an unsupervised manner. To this end, we introduce a standardization module that
provides pseudo sketch-photo pairs during training by converting photos and
sketches to a standardized domain, i.e. the edge map. The reduced domain gap
between sketch and photo also allows us to disentangle them into two
components: holistic scene structures and low-level visual styles such as color
and texture. Taking this advantage, we synthesize a photo-realistic image by
combining the structure of a sketch and the visual style of a reference photo.
Extensive experimental results on perceptual similarity metrics and human
perceptual studies show the proposed method could generate realistic photos
with high fidelity from scene sketches and outperform state-of-the-art photo
synthesis baselines. We also demonstrate that our framework facilitates a
controllable manipulation of photo synthesis by editing strokes of
corresponding sketches, delivering more fine-grained details than previous
approaches that rely on region-level editing.",None,-1
96dbf247-7367-4a3b-a7c9-ae42d71033e8,Spatiotemporal Costmap Inference for MPC via Deep Inverse Reinforcement Learning,0.777634,"It can be difficult to autonomously produce driver behavior so that it
appears natural to other traffic participants. Through Inverse Reinforcement
Learning (IRL), we can automate this process by learning the underlying reward
function from human demonstrations. We propose a new IRL algorithm that learns
a goal-conditioned spatiotemporal reward function. The resulting costmap is
used by Model Predictive Controllers (MPCs) to perform a task without any
hand-designing or hand-tuning of the cost function. We evaluate our proposed
Goal-conditioned SpatioTemporal Zeroing Maximum Entropy Deep IRL (GSTZ)-MEDIRL
framework together with MPC in the CARLA simulator for autonomous driving, lane
keeping, and lane changing tasks in a challenging dense traffic highway
scenario. Our proposed methods show higher success rates compared to other
baseline methods including behavior cloning, state-of-the-art RL policies, and
MPC with a learning-based behavior prediction model.",None,-1
4c0a92e5-a933-4b42-8b20-759c4e528e06,Model-Free Reinforcement Learning for Symbolic Automata-encoded Objectives,0.401398,"Reinforcement learning (RL) is a popular approach for robotic path planning
in uncertain environments. However, the control policies trained for an RL
agent crucially depend on user-defined, state-based reward functions. Poorly
designed rewards can lead to policies that do get maximal rewards but fail to
satisfy desired task objectives or are unsafe. There are several examples of
the use of formal languages such as temporal logics and automata to specify
high-level task specifications for robots (in lieu of Markovian rewards).
Recent efforts have focused on inferring state-based rewards from formal
specifications; here, the goal is to provide (probabilistic) guarantees that
the policy learned using RL (with the inferred rewards) satisfies the
high-level formal specification. A key drawback of several of these techniques
is that the rewards that they infer are sparse: the agent receives positive
rewards only upon completion of the task and no rewards otherwise. This
naturally leads to poor convergence properties and high variance during RL. In
this work, we propose using formal specifications in the form of symbolic
automata: these serve as a generalization of both bounded-time temporal
logic-based specifications as well as automata. Furthermore, our use of
symbolic automata allows us to define non-sparse potential-based rewards which
empirically shape the reward surface, leading to better convergence during RL.
We also show that our potential-based rewarding strategy still allows us to
obtain the policy that maximizes the satisfaction of the given specification.",None,-1
f501973d-d80a-4868-9849-d75e02a5bb0b,InBiaseD: Inductive Bias Distillation to Improve Generalization and Robustness through Shape-awareness,0.159579,"Humans rely less on spurious correlations and trivial cues, such as texture,
compared to deep neural networks which lead to better generalization and
robustness. It can be attributed to the prior knowledge or the high-level
cognitive inductive bias present in the brain. Therefore, introducing
meaningful inductive bias to neural networks can help learn more generic and
high-level representations and alleviate some of the shortcomings. We propose
InBiaseD to distill inductive bias and bring shape-awareness to the neural
networks. Our method includes a bias alignment objective that enforces the
networks to learn more generic representations that are less vulnerable to
unintended cues in the data which results in improved generalization
performance. InBiaseD is less susceptible to shortcut learning and also
exhibits lower texture bias. The better representations also aid in improving
robustness to adversarial attacks and we hence plugin InBiaseD seamlessly into
the existing adversarial training schemes to show a better trade-off between
generalization and robustness.",https://github.com/NeurAI-Lab/InBiaseD,-1
d334d860-54c3-48a4-a2ad-3d11118c06cb,Using Natural Language and Program Abstractions to Instill Human Inductive Biases in Machines,0.615549,"Strong inductive biases give humans the ability to quickly learn to perform a
variety of tasks. Although meta-learning is a method to endow neural networks
with useful inductive biases, agents trained by meta-learning may sometimes
acquire very different strategies from humans. We show that co-training these
agents on predicting representations from natural language task descriptions
and programs induced to generate such tasks guides them toward more human-like
inductive biases. Human-generated language descriptions and program induction
models that add new learned primitives both contain abstract concepts that can
compress description length. Co-training on these representations result in
more human-like behavior in downstream meta-reinforcement learning agents than
less abstract controls (synthetic language descriptions, program induction
without learned primitives), suggesting that the abstraction supported by these
representations is key.",None,-1
1ed7686f-3cf0-4206-be79-d626d8a6d726,Document-Level Relation Extraction with Adaptive Focal Loss and Knowledge Distillation,0.999812,"Document-level Relation Extraction (DocRE) is a more challenging task
compared to its sentence-level counterpart. It aims to extract relations from
multiple sentences at once. In this paper, we propose a semi-supervised
framework for DocRE with three novel components. Firstly, we use an axial
attention module for learning the interdependency among entity-pairs, which
improves the performance on two-hop relations. Secondly, we propose an adaptive
focal loss to tackle the class imbalance problem of DocRE. Lastly, we use
knowledge distillation to overcome the differences between human annotated data
and distantly supervised data. We conducted experiments on two DocRE datasets.
Our model consistently outperforms strong baselines and its performance exceeds
the previous SOTA by 1.36 F1 and 1.46 Ign_F1 score on the DocRED leaderboard.
Our code and data will be released at https://github.com/tonytan48/KD-DocRE.",https://github.com/tonytan48/KD-DocRE,18583
0ede90d7-6602-4f5a-bb8c-f53ac387cedc,SPBERTQA: A Two-Stage Question Answering System Based on Sentence Transformers for Medical Texts,0.220079,"Question answering (QA) systems have gained explosive attention in recent
years. However, QA tasks in Vietnamese do not have many datasets.
Significantly, there is mostly no dataset in the medical domain. Therefore, we
built a Vietnamese Healthcare Question Answering dataset (ViHealthQA),
including 10,015 question-answer passage pairs for this task, in which
questions from health-interested users were asked on prestigious health
websites and answers from highly qualified experts. This paper proposes a
two-stage QA system based on Sentence-BERT (SBERT) using multiple negatives
ranking (MNR) loss combined with BM25. Then, we conduct diverse experiments
with many bag-of-words models to assess our system's performance. With the
obtained results, this system achieves better performance than traditional
methods.",None,2352
8954fa3c-ae16-4f93-b6d2-b9614c990979,Positive-Unlabeled Learning with Adversarial Data Augmentation for Knowledge Graph Completion,0.812222,"Most real-world knowledge graphs (KG) are far from complete and
comprehensive. This problem has motivated efforts in predicting the most
plausible missing facts to complete a given KG, i.e., knowledge graph
completion (KGC). However, existing KGC methods suffer from two main issues, 1)
the false negative issue, i.e., the sampled negative training instances may
include potential true facts; and 2) the data sparsity issue, i.e., true facts
account for only a tiny part of all possible facts. To this end, we propose
positive-unlabeled learning with adversarial data augmentation (PUDA) for KGC.
In particular, PUDA tailors positive-unlabeled risk estimator for the KGC task
to deal with the false negative issue. Furthermore, to address the data
sparsity issue, PUDA achieves a data augmentation strategy by unifying
adversarial training and positive-unlabeled learning under the
positive-unlabeled minimax game. Extensive experimental results on real-world
benchmark datasets demonstrate the effectiveness and compatibility of our
proposed method.",https://github.com/lilv98/PUDA-IJCAI22,-1
4725d4ce-2db0-4e98-8632-14e985774f31,Sensor Data Fusion in Top-View Grid Maps using Evidential Reasoning with Advanced Conflict Resolution,0.0709213,"We present a new method to combine evidential top-view grid maps estimated
based on heterogeneous sensor sources. Dempster's combination rule that is
usually applied in this context provides undesired results with highly
conflicting inputs. Therefore, we use more advanced evidential reasoning
techniques and improve the conflict resolution by modeling the reliability of
the evidence sources. We propose a data-driven reliability estimation to
optimize the fusion quality using the Kitti-360 dataset. We apply the proposed
method to the fusion of LiDAR and stereo camera data and evaluate the results
qualitatively and quantitatively. The results demonstrate that our proposed
method robustly combines measurements from heterogeneous sensors and
successfully resolves sensor conflicts.",None,-1
3cb3efaa-5a0f-48e3-bad5-6198a2ae7df7,Image-based Automatic Dial Meter Reading in Unconstrained Scenarios,0.312052,"The replacement of analog meters with smart meters is costly, laborious, and
far from complete in developing countries. The Energy Company of Parana (Copel)
(Brazil) performs more than 4 million meter readings (almost entirely of
non-smart devices) per month, and we estimate that 850 thousand of them are
from dial meters. Therefore, an image-based automatic reading system can reduce
human errors, create a proof of reading, and enable the customers to perform
the reading themselves through a mobile application. We propose novel
approaches for Automatic Dial Meter Reading (ADMR) and introduce a new dataset
for ADMR in unconstrained scenarios, called UFPR-ADMR-v2. Our best-performing
method combines YOLOv4 with a novel regression approach (AngReg), and explores
several postprocessing techniques. Compared to previous works, it decreased the
Mean Absolute Error (MAE) from 1,343 to 129 and achieved a meter recognition
rate (MRR) of 98.90% -- with an error tolerance of 1 Kilowatt-hour (kWh).",None,6178
6932aa1a-5ff3-4113-abd8-c577ca893adc,Monant Medical Misinformation Dataset: Mapping Articles to Fact-Checked Claims,0.604618,"False information has a significant negative influence on individuals as well
as on the whole society. Especially in the current COVID-19 era, we witness an
unprecedented growth of medical misinformation. To help tackle this problem
with machine learning approaches, we are publishing a feature-rich dataset of
approx. 317k medical news articles/blogs and 3.5k fact-checked claims. It also
contains 573 manually and more than 51k automatically labelled mappings between
claims and articles. Mappings consist of claim presence, i.e., whether a claim
is contained in a given article, and article stance towards the claim. We
provide several baselines for these two tasks and evaluate them on the manually
labelled part of the dataset. The dataset enables a number of additional tasks
related to medical misinformation, such as misinformation characterisation
studies or studies of misinformation diffusion between sources.",None,-1
07b9e0b0-05a8-4461-91b6-0d7307c37795,Improving Multilingual Neural Machine Translation System for Indic Languages,0.741898,"Machine Translation System (MTS) serves as an effective tool for
communication by translating text or speech from one language to another
language. The need of an efficient translation system becomes obvious in a
large multilingual environment like India, where English and a set of Indian
Languages (ILs) are officially used. In contrast with English, ILs are still
entreated as low-resource languages due to unavailability of corpora. In order
to address such asymmetric nature, multilingual neural machine translation
(MNMT) system evolves as an ideal approach in this direction. In this paper, we
propose a MNMT system to address the issues related to low-resource language
translation. Our model comprises of two MNMT systems i.e. for English-Indic
(one-to-many) and the other for Indic-English (many-to-one) with a shared
encoder-decoder containing 15 language pairs (30 translation directions). Since
most of IL pairs have scanty amount of parallel corpora, not sufficient for
training any machine translation model. We explore various augmentation
strategies to improve overall translation quality through the proposed model. A
state-of-the-art transformer architecture is used to realize the proposed
model. Trials over a good amount of data reveal its superiority over the
conventional models. In addition, the paper addresses the use of language
relationships (in terms of dialect, script, etc.), particularly about the role
of high-resource languages of the same family in boosting the performance of
low-resource languages. Moreover, the experimental results also show the
advantage of backtranslation and domain adaptation for ILs to enhance the
translation quality of both source and target languages. Using all these key
approaches, our proposed model emerges to be more efficient than the baseline
model in terms of evaluation metrics i.e BLEU (BiLingual Evaluation Understudy)
score for a set of ILs.",None,50
5e32f7a2-6e43-4de8-a266-adaa54b43f87,HPT: Hierarchy-aware Prompt Tuning for Hierarchical Text Classification,0.761262,"Hierarchical text classification (HTC) is a challenging subtask of
multi-label classification due to its complex label hierarchy. Recently, the
pretrained language models (PLM)have been widely adopted in HTC through a
fine-tuning paradigm. However, in this paradigm, there exists a huge gap
between the classification tasks with sophisticated label hierarchy and the
masked language model (MLM) pretraining tasks of PLMs and thus the potentials
of PLMs can not be fully tapped. To bridge the gap, in this paper, we propose
HPT, a Hierarchy-aware Prompt Tuning method to handle HTC from a multi-label
MLM perspective. Specifically, we construct a dynamic virtual template and
label words that take the form of soft prompts to fuse the label hierarchy
knowledge and introduce a zero-bounded multi-label cross entropy loss to
harmonize the objectives of HTC and MLM. Extensive experiments show HPT
achieves state-of-the-art performances on 3 popular HTC datasets and is adept
at handling the imbalance and low resource situations. Our code is available at
https://github.com/wzh9969/HPT.",https://github.com/wzh9969/HPT,-1
2e9238af-c529-4a8c-98d7-ef9dc6665ee8,Dialogue Meaning Representation for Task-Oriented Dialogue Systems,0.404541,"Dialogue meaning representation formulates natural language utterance
semantics in their conversational context in an explicit and machine-readable
form. Previous work typically follows the intent-slot framework, which is easy
for annotation yet limited in scalability for complex linguistic expressions. A
line of works alleviates the representation issue by introducing hierarchical
structures but challenging to express complex compositional semantics, such as
negation and coreference. We propose Dialogue Meaning Representation (DMR), a
pliable and easily extendable representation for task-oriented dialogue. Our
representation contains a set of nodes and edges to represent rich
compositional semantics. Moreover, we propose an inheritance hierarchy
mechanism focusing on domain extensibility. Additionally, we annotated
DMR-FastFood, a multi-turn dialogue dataset with more than 70k utterances, with
DMR. We propose two evaluation tasks to evaluate different dialogue models and
a novel coreference resolution model GNNCoref for the graph-based coreference
resolution task. Experiments show that DMR can be parsed well with pre-trained
Seq2Seq models, and GNNCoref outperforms the baseline models by a large margin.",https://github.com/amazon-research/dialogue-meaning-representation,20692
e4c03f7f-df48-471a-9c6a-2cc2eb723573,C-SENN: Contrastive Self-Explaining Neural Network,0.461481,"In this study, we use a self-explaining neural network (SENN), which learns
unsupervised concepts, to acquire concepts that are easy for people to
understand automatically. In concept learning, the hidden layer retains
verbalizable features relevant to the output, which is crucial when adapting to
real-world environments where explanations are required. However, it is known
that the interpretability of concepts output by SENN is reduced in general
settings, such as autonomous driving scenarios. Thus, this study combines
contrastive learning with concept learning to improve the readability of
concepts and the accuracy of tasks. We call this model Contrastive
Self-Explaining Neural Network (C-SENN).",None,-1
494f3a3d-79b7-4959-809d-45a172582e84,Multi-Document Summarization with Centroid-Based Pretraining,0.882681,"In Multi-Document Summarization (MDS), the input can be modeled as a set of
documents, and the output is its summary. In this paper, we focus on
pretraining objectives for MDS. Specifically, we introduce a novel pretraining
objective, which involves selecting the ROUGE-based centroid of each document
cluster as a proxy for its summary. Our objective thus does not require human
written summaries and can be utilized for pretraining on a dataset consisting
solely of document sets. Through zero-shot, few-shot, and fully supervised
experiments on multiple MDS datasets, we show that our model Centrum is better
or comparable to a state-of-the-art model. We make the pretrained and
fine-tuned models freely available to the research community
https://github.com/ratishsp/centrum.",https://github.com/ratishsp/centrum,-1
b1ad5f2a-57e2-4382-955d-4ba318ef7b0b,Items from Psychometric Tests as Training Data for Personality Profiling Models of Twitter Users,0.678684,"Machine-learned models for author profiling in social media often rely on
data acquired via self-reporting-based psychometric tests (questionnaires)
filled out by social media users. This is an expensive but accurate data
collection strategy. Another, less costly alternative, which leads to
potentially more noisy and biased data, is to rely on labels inferred from
publicly available information in the profiles of the users, for instance
self-reported diagnoses or test results. In this paper, we explore a third
strategy, namely to directly use a corpus of items from validated psychometric
tests as training data. Items from psychometric tests often consist of
sentences from an I-perspective (e.g., ""I make friends easily.""). Such corpora
of test items constitute 'small data', but their availability for many concepts
is a rich resource. We investigate this approach for personality profiling, and
evaluate BERT classifiers fine-tuned on such psychometric test items for the
big five personality traits (openness, conscientiousness, extraversion,
agreeableness, neuroticism) and analyze various augmentation strategies
regarding their potential to address the challenges coming with such a small
corpus. Our evaluation on a publicly available Twitter corpus shows a
comparable performance to in-domain training for 4/5 personality traits with
T5-based data augmentation.",None,-1
1ce2b83b-6cd8-4b58-bfb2-6d6af471cd45,Inference and dynamic decision-making for deteriorating systems with probabilistic dependencies through Bayesian networks and deep reinforcement learning,0.912096,"In the context of modern environmental and societal concerns, there is an
increasing demand for methods able to identify management strategies for civil
engineering systems, minimizing structural failure risks while optimally
planning inspection and maintenance (I&M) processes. Most available methods
simplify the I&M decision problem to the component level due to the
computational complexity associated with global optimization methodologies
under joint system-level state descriptions. In this paper, we propose an
efficient algorithmic framework for inference and decision-making under
uncertainty for engineering systems exposed to deteriorating environments,
providing optimal management strategies directly at the system level. In our
approach, the decision problem is formulated as a factored partially observable
Markov decision process, whose dynamics are encoded in Bayesian network
conditional structures. The methodology can handle environments under equal or
general, unequal deterioration correlations among components, through Gaussian
hierarchical structures and dynamic Bayesian networks. In terms of policy
optimization, we adopt a deep decentralized multi-agent actor-critic (DDMAC)
reinforcement learning approach, in which the policies are approximated by
actor neural networks guided by a critic network. By including deterioration
dependence in the simulated environment, and by formulating the cost model at
the system level, DDMAC policies intrinsically consider the underlying
system-effects. This is demonstrated through numerical experiments conducted
for both a 9-out-of-10 system and a steel frame under fatigue deterioration.
Results demonstrate that DDMAC policies offer substantial benefits when
compared to state-of-the-art heuristic approaches. The inherent consideration
of system-effects by DDMAC strategies is also interpreted based on the learned
policies.",None,622
14242df4-5dc1-47db-aa71-c73d10b4cf8f,Disentangling Architecture and Training for Optical Flow,0.844879,"How important are training details and datasets to recent optical flow models
like RAFT? And do they generalize? To explore these questions, rather than
develop a new model, we revisit three prominent models, PWC-Net, IRR-PWC and
RAFT, with a common set of modern training techniques and datasets, and observe
significant performance gains, demonstrating the importance and generality of
these training details. Our newly trained PWC-Net and IRR-PWC models show
surprisingly large improvements, up to 30% versus original published results on
Sintel and KITTI 2015 benchmarks. They outperform the more recent Flow1D on
KITTI 2015 while being 3x faster during inference. Our newly trained RAFT
achieves an Fl-all score of 4.31% on KITTI 2015, more accurate than all
published optical flow methods at the time of writing. Our results demonstrate
the benefits of separating the contributions of models, training techniques and
datasets when analyzing performance gains of optical flow methods. Our source
code will be publicly available.",https://autoflow-google.github.io,-1
d42457a6-fac7-402c-8139-41cb857cf41a,OakInk: A Large-scale Knowledge Repository for Understanding Hand-Object Interaction,0.750208,"Learning how humans manipulate objects requires machines to acquire knowledge
from two perspectives: one for understanding object affordances and the other
for learning human's interactions based on the affordances. Even though these
two knowledge bases are crucial, we find that current databases lack a
comprehensive awareness of them. In this work, we propose a multi-modal and
rich-annotated knowledge repository, OakInk, for visual and cognitive
understanding of hand-object interactions. We start to collect 1,800 common
household objects and annotate their affordances to construct the first
knowledge base: Oak. Given the affordance, we record rich human interactions
with 100 selected objects in Oak. Finally, we transfer the interactions on the
100 recorded objects to their virtual counterparts through a novel method:
Tink. The recorded and transferred hand-object interactions constitute the
second knowledge base: Ink. As a result, OakInk contains 50,000 distinct
affordance-aware and intent-oriented hand-object interactions. We benchmark
OakInk on pose estimation and grasp generation tasks. Moreover, we propose two
practical applications of OakInk: intent-based interaction generation and
handover generation. Our datasets and source code are publicly available at
https://github.com/lixiny/OakInk.",https://github.com/lixiny/OakInk,-1
889286c8-9a04-42a4-ba02-bff11bae6b2c,OpenTAL: Towards Open Set Temporal Action Localization,0.842421,"Temporal Action Localization (TAL) has experienced remarkable success under
the supervised learning paradigm. However, existing TAL methods are rooted in
the closed set assumption, which cannot handle the inevitable unknown actions
in open-world scenarios. In this paper, we, for the first time, step toward the
Open Set TAL (OSTAL) problem and propose a general framework OpenTAL based on
Evidential Deep Learning (EDL). Specifically, the OpenTAL consists of
uncertainty-aware action classification, actionness prediction, and temporal
location regression. With the proposed importance-balanced EDL method,
classification uncertainty is learned by collecting categorical evidence
majorly from important samples. To distinguish the unknown actions from
background video frames, the actionness is learned by the positive-unlabeled
learning. The classification uncertainty is further calibrated by leveraging
the guidance from the temporal localization quality. The OpenTAL is general to
enable existing TAL models for open set scenarios, and experimental results on
THUMOS14 and ActivityNet1.3 benchmarks show the effectiveness of our method.
The code and pre-trained models are released at
https://www.rit.edu/actionlab/opental.",https://www.rit.edu/actionlab/opental,-1
6643eaa7-e186-4d49-b71f-add0109eb229,MEAformer: Multi-modal Entity Alignment Transformer for Meta Modality Hybrid,0.77728,"Multi-modal entity alignment (MMEA) aims to discover identical entities
across different knowledge graphs (KGs) whose entities are associated with
relevant images. However, current MMEA algorithms rely on KG-level modality
fusion strategies for multi-modal entity representation, which ignores the
variations of modality preferences of different entities, thus compromising
robustness against noise in modalities such as blurry images and relations.
This paper introduces MEAformer, a multi-modal entity alignment transformer
approach for meta modality hybrid, which dynamically predicts the mutual
correlation coefficients among modalities for more fine-grained entity-level
modality fusion and alignment. Experimental results demonstrate that our model
not only achieves SOTA performance in multiple training scenarios, including
supervised, unsupervised, iterative, and low-resource settings, but also has a
limited number of parameters, efficient runtime, and interpretability. Our code
is available at https://github.com/zjukg/MEAformer.",https://github.com/zjukg/MEAformer,-1
112559cb-9867-44f2-a068-50a26323d793,NCTV: Neural Clamping Toolkit and Visualization for Neural Network Calibration,0.0638794,"With the advancement of deep learning technology, neural networks have
demonstrated their excellent ability to provide accurate predictions in many
tasks. However, a lack of consideration for neural network calibration will not
gain trust from humans, even for high-accuracy models. In this regard, the gap
between the confidence of the model's predictions and the actual correctness
likelihood must be bridged to derive a well-calibrated model. In this paper, we
introduce the Neural Clamping Toolkit, the first open-source framework designed
to help developers employ state-of-the-art model-agnostic calibrated models.
Furthermore, we provide animations and interactive sections in the
demonstration to familiarize researchers with calibration in neural networks. A
Colab tutorial on utilizing our toolkit is also introduced.",None,-1
8d1f236e-a22e-4e05-983f-a5b807fe7320,Improving Health Mentioning Classification of Tweets using Contrastive Adversarial Training,0.0715554,"Health mentioning classification (HMC) classifies an input text as health
mention or not. Figurative and non-health mention of disease words makes the
classification task challenging. Learning the context of the input text is the
key to this problem. The idea is to learn word representation by its
surrounding words and utilize emojis in the text to help improve the
classification results. In this paper, we improve the word representation of
the input text using adversarial training that acts as a regularizer during
fine-tuning of the model. We generate adversarial examples by perturbing the
embeddings of the model and then train the model on a pair of clean and
adversarial examples. Additionally, we utilize contrastive loss that pushes a
pair of clean and perturbed examples close to each other and other examples
away in the representation space. We train and evaluate the method on an
extended version of the publicly available PHM2017 dataset. Experiments show an
improvement of 1.0% over BERT-Large baseline and 0.6% over RoBERTa-Large
baseline, whereas 5.8% over the state-of-the-art in terms of F1 score.
Furthermore, we provide a brief analysis of the results by utilizing the power
of explainable AI.",None,-1
29c7ba75-7e78-45b6-ac08-3605c87f9a0b,Policy Gradient Algorithms with Monte-Carlo Tree Search for Non-Markov Decision Processes,0.0237169,"Policy gradient (PG) is a reinforcement learning (RL) approach that optimizes
a parameterized policy model for an expected return using gradient ascent.
Given a well-parameterized policy model, such as a neural network model, with
appropriate initial parameters, the PG algorithms work well even when
environment does not have the Markov property. Otherwise, they can be trapped
on a plateau or suffer from peakiness effects. As another successful RL
approach, algorithms based on Monte-Carlo Tree Search (MCTS), which include
AlphaZero, have obtained groundbreaking results especially on the board game
playing domain. They are also suitable to be applied to non-Markov decision
processes. However, since the standard MCTS does not have the ability to learn
state representation, the size of the tree-search space can be too large to
search. In this work, we examine a mixture policy of PG and MCTS to complement
each other's difficulties and take advantage of them. We derive conditions for
asymptotic convergence with results of a two-timescale stochastic approximation
and propose an algorithm that satisfies these conditions. The effectivity of
the proposed methods is verified through numerical experiments on non-Markov
decision processes.",None,1194
44fa23dc-227c-4630-8043-a4bc28fcc868,Assessing the Effects of Hyperparameters on Knowledge Graph Embedding Quality,0.107027,"Embedding knowledge graphs into low-dimensional spaces is a popular method
for applying approaches, such as link prediction or node classification, to
these databases. This embedding process is very costly in terms of both
computational time and space. Part of the reason for this is the optimisation
of hyperparameters, which involves repeatedly sampling, by random, guided, or
brute-force selection, from a large hyperparameter space and testing the
resulting embeddings for their quality. However, not all hyperparameters in
this search space will be equally important. In fact, with prior knowledge of
the relative importance of the hyperparameters, some could be eliminated from
the search altogether without significantly impacting the overall quality of
the outputted embeddings. To this end, we ran a Sobol sensitivity analysis to
evaluate the effects of tuning different hyperparameters on the variance of
embedding quality. This was achieved by performing thousands of embedding
trials, each time measuring the quality of embeddings produced by different
hyperparameter configurations. We regressed the embedding quality on those
hyperparameter configurations, using this model to generate Sobol sensitivity
indices for each of the hyperparameters. By evaluating the correlation between
Sobol indices, we find substantial variability in the hyperparameter
sensitivities between knowledge graphs, with differing dataset characteristics
being the probable cause of these inconsistencies. As an additional
contribution of this work we identify several relations in the UMLS knowledge
graph that may cause data leakage via inverse relations, and derive and present
UMLS-43, a leakage-robust variant of that graph.",None,-1
f16dfecb-d145-4f7c-975d-9ec639e918cc,Can language models learn from explanations in context?,0.999953,"Language Models (LMs) can perform new tasks by adapting to a few in-context
examples. For humans, explanations that connect examples to task principles can
improve learning. We therefore investigate whether explanations of few-shot
examples can help LMs. We annotate questions from 40 challenging tasks with
answer explanations, and various matched control explanations. We evaluate how
different types of explanations, instructions, and controls affect zero- and
few-shot performance. We analyze these results using statistical multilevel
modeling techniques that account for the nested dependencies among conditions,
tasks, prompts, and models. We find that explanations can improve performance
-- even without tuning. Furthermore, explanations hand-tuned for performance on
a small validation set offer substantially larger benefits, and building a
prompt by selecting examples and explanations together substantially improves
performance over selecting examples alone. Finally, even untuned explanations
outperform carefully matched controls, suggesting that the benefits are due to
the link between an example and its explanation, rather than lower-level
features. However, only large models benefit. In summary, explanations can
support the in-context learning of large LMs on challenging tasks.",None,-1
997663a8-fc57-4c4e-93a2-0cd493402be5,Impact of Adversarial Training on Robustness and Generalizability of Language Models,0.343122,"Adversarial training is widely acknowledged as the most effective defense
against adversarial attacks. However, it is also well established that
achieving both robustness and generalization in adversarially trained models
involves a trade-off. The goal of this work is to provide an in depth
comparison of different approaches for adversarial training in language models.
Specifically, we study the effect of pre-training data augmentation as well as
training time input perturbations vs. embedding space perturbations on the
robustness and generalization of transformer-based language models. Our
findings suggest that better robustness can be achieved by pre-training data
augmentation or by training with input space perturbation. However, training
with embedding space perturbation significantly improves generalization. A
linguistic correlation analysis of neurons of the learned models reveals that
the improved generalization is due to 'more specialized' neurons. To the best
of our knowledge, this is the first work to carry out a deep qualitative
analysis of different methods of generating adversarial examples in adversarial
training of language models.",None,-1
77bc1e1a-63ba-4411-8aa7-de42e5bf599f,"MAVEN-ERE: A Unified Large-scale Dataset for Event Coreference, Temporal, Causal, and Subevent Relation Extraction",0.979835,"The diverse relationships among real-world events, including coreference,
temporal, causal, and subevent relations, are fundamental to understanding
natural languages. However, two drawbacks of existing datasets limit event
relation extraction (ERE) tasks: (1) Small scale. Due to the annotation
complexity, the data scale of existing datasets is limited, which cannot well
train and evaluate data-hungry models. (2) Absence of unified annotation.
Different types of event relations naturally interact with each other, but
existing datasets only cover limited relation types at once, which prevents
models from taking full advantage of relation interactions. To address these
issues, we construct a unified large-scale human-annotated ERE dataset
MAVEN-ERE with improved annotation schemes. It contains 103,193 event
coreference chains, 1,216,217 temporal relations, 57,992 causal relations, and
15,841 subevent relations, which is larger than existing datasets of all the
ERE tasks by at least an order of magnitude. Experiments show that ERE on
MAVEN-ERE is quite challenging, and considering relation interactions with
joint learning can improve performances. The dataset and source codes can be
obtained from https://github.com/THU-KEG/MAVEN-ERE.",https://github.com/THU-KEG/MAVEN-ERE,-1
52927983-bf2c-4db0-a518-aca265ff4bde,Sentiment-Aware Automatic Speech Recognition pre-training for enhanced Speech Emotion Recognition,0.748558,"We propose a novel multi-task pre-training method for Speech Emotion
Recognition (SER). We pre-train SER model simultaneously on Automatic Speech
Recognition (ASR) and sentiment classification tasks to make the acoustic ASR
model more ``emotion aware''. We generate targets for the sentiment
classification using text-to-sentiment model trained on publicly available
data. Finally, we fine-tune the acoustic ASR on emotion annotated speech data.
We evaluated the proposed approach on the MSP-Podcast dataset, where we
achieved the best reported concordance correlation coefficient (CCC) of 0.41
for valence prediction.",None,-1
3ef7e241-f643-4f84-afcb-5e785fc8969c,Don't Say What You Don't Know: Improving the Consistency of Abstractive Summarization by Constraining Beam Search,0.684194,"Abstractive summarization systems today produce fluent and relevant output,
but often ""hallucinate"" statements not supported by the source text. We analyze
the connection between hallucinations and training data, and find evidence that
models hallucinate because they train on target summaries that are unsupported
by the source. Based on our findings, we present PINOCCHIO, a new decoding
method that improves the consistency of a transformer-based abstractive
summarizer by constraining beam search to avoid hallucinations. Given the model
states and outputs at a given step, PINOCCHIO detects likely model
hallucinations based on various measures of attribution to the source text.
PINOCCHIO backtracks to find more consistent output, and can opt to produce no
summary at all when no consistent generation can be found. In experiments, we
find that PINOCCHIO improves the consistency of generation (in terms of F1) by
an average of~67% on two abstractive summarization datasets.",https://github.com/allenai/pinocchio,14304
9984472b-f856-4587-b12a-5ede15e7ddc2,Lane Detection with Versatile AtrousFormer and Local Semantic Guidance,0.249709,"Lane detection is one of the core functions in autonomous driving and has
aroused widespread attention recently. The networks to segment lane instances,
especially with bad appearance, must be able to explore lane distribution
properties. Most existing methods tend to resort to CNN-based techniques. A few
have a try on incorporating the recent adorable, the seq2seq Transformer
\cite{transformer}. However, their innate drawbacks of weak global information
collection ability and exorbitant computation overhead prohibit a wide range of
the further applications. In this work, we propose Atrous Transformer
(AtrousFormer) to solve the problem. Its variant local AtrousFormer is
interleaved into feature extractor to enhance extraction. Their collecting
information first by rows and then by columns in a dedicated manner finally
equips our network with stronger information gleaning ability and better
computation efficiency. To further improve the performance, we also propose a
local semantic guided decoder to delineate the identities and shapes of lanes
more accurately, in which the predicted Gaussian map of the starting point of
each lane serves to guide the process. Extensive results on three challenging
benchmarks (CULane, TuSimple, and BDD100K) show that our network performs
favorably against the state of the arts.",None,-1
edf47fe2-0baa-451f-905e-9f4f0421c736,A Greek Parliament Proceedings Dataset for Computational Linguistics and Political Analysis,0.229061,"Large, diachronic datasets of political discourse are hard to come across,
especially for resource-lean languages such as Greek. In this paper, we
introduce a curated dataset of the Greek Parliament Proceedings that extends
chronologically from 1989 up to 2020. It consists of more than 1 million
speeches with extensive metadata, extracted from 5,355 parliamentary record
files. We explain how it was constructed and the challenges that we had to
overcome. The dataset can be used for both computational linguistics and
political analysis-ideally, combining the two. We present such an application,
showing (i) how the dataset can be used to study the change of word usage
through time, (ii) between significant historical events and political parties,
(iii) by evaluating and employing algorithms for detecting semantic shifts.",None,-1
8a788169-2014-417d-b5a8-2c965145dfc8,CORE: Consistent Representation Learning for Face Forgery Detection,0.694656,"Face manipulation techniques develop rapidly and arouse widespread public
concerns. Despite that vanilla convolutional neural networks achieve acceptable
performance, they suffer from the overfitting issue. To relieve this issue,
there is a trend to introduce some erasing-based augmentations. We find that
these methods indeed attempt to implicitly induce more consistent
representations for different augmentations via assigning the same label for
different augmented images. However, due to the lack of explicit
regularization, the consistency between different representations is less
satisfactory. Therefore, we constrain the consistency of different
representations explicitly and propose a simple yet effective framework,
COnsistent REpresentation Learning (CORE). Specifically, we first capture the
different representations with different augmentations, then regularize the
cosine distance of the representations to enhance the consistency. Extensive
experiments (in-dataset and cross-dataset) demonstrate that CORE performs
favorably against state-of-the-art face forgery detection methods.",https://github.com/niyunsheng/CORE,-1
f5468bf9-fa8e-4ad7-bb49-6c5db388fe73,Leveraging unsupervised and weakly-supervised data to improve direct speech-to-speech translation,0.795867,"End-to-end speech-to-speech translation (S2ST) without relying on
intermediate text representations is a rapidly emerging frontier of research.
Recent works have demonstrated that the performance of such direct S2ST systems
is approaching that of conventional cascade S2ST when trained on comparable
datasets. However, in practice, the performance of direct S2ST is bounded by
the availability of paired S2ST training data. In this work, we explore
multiple approaches for leveraging much more widely available unsupervised and
weakly-supervised speech and text data to improve the performance of direct
S2ST based on Translatotron 2. With our most effective approaches, the average
translation quality of direct S2ST on 21 language pairs on the CVSS-C corpus is
improved by +13.6 BLEU (or +113% relatively), as compared to the previous
state-of-the-art trained without additional data. The improvements on
low-resource language are even more significant (+398% relatively on average).
Our comparative studies suggest future research directions for S2ST and speech
representation learning.",None,-1
e13d3cfb-ea21-4588-9d9e-727d968f7bc8,Uni-Parser: Unified Semantic Parser for Question Answering on Knowledge Base and Database,0.516673,"Parsing natural language questions into executable logical forms is a useful
and interpretable way to perform question answering on structured data such as
knowledge bases (KB) or databases (DB). However, existing approaches on
semantic parsing cannot adapt to both modalities, as they suffer from the
exponential growth of the logical form candidates and can hardly generalize to
unseen data. In this work, we propose Uni-Parser, a unified semantic parser for
question answering (QA) on both KB and DB. We introduce the primitive (relation
and entity in KB, and table name, column name and cell value in DB) as an
essential element in our framework. The number of primitives grows linearly
with the number of retrieved relations in KB and DB, preventing us from dealing
with exponential logic form candidates. We leverage the generator to predict
final logical forms by altering and composing topranked primitives with
different operations (e.g. select, where, count). With sufficiently pruned
search space by a contrastive primitive ranker, the generator is empowered to
capture the composition of primitives enhancing its generalization ability. We
achieve competitive results on multiple KB and DB QA benchmarks more
efficiently, especially in the compositional and zero-shot settings.",https://github.com/ServiceNow/picard/,-1
05f24f64-2cfc-45e7-acd3-554293d88b56,Global Convergence of Localized Policy Iteration in Networked Multi-Agent Reinforcement Learning,0.847323,"We study a multi-agent reinforcement learning (MARL) problem where the agents
interact over a given network. The goal of the agents is to cooperatively
maximize the average of their entropy-regularized long-term rewards. To
overcome the curse of dimensionality and to reduce communication, we propose a
Localized Policy Iteration (LPI) algorithm that provably learns a
near-globally-optimal policy using only local information. In particular, we
show that, despite restricting each agent's attention to only its $\kappa$-hop
neighborhood, the agents are able to learn a policy with an optimality gap that
decays polynomially in $\kappa$. In addition, we show the finite-sample
convergence of LPI to the global optimal policy, which explicitly captures the
trade-off between optimality and computational complexity in choosing $\kappa$.
Numerical simulations demonstrate the effectiveness of LPI.",None,-1
4d9b346a-8ed5-45e0-90ae-4abd05efb5a9,Parallel Augmentation and Dual Enhancement for Occluded Person Re-identification,0.329595,"Occluded person re-identification (Re-ID), the task of searching for the same
person's images in occluded environments, has attracted lots of attention in
the past decades. Recent approaches concentrate on improving performance on
occluded data by data/feature augmentation or using extra models to predict
occlusions. However, they ignore the imbalance problem in this task and can not
fully utilize the information from the training data. To alleviate these two
issues, we propose a simple yet effective method with Parallel Augmentation and
Dual Enhancement (PADE), which is robust on both occluded and non-occluded data
and does not require any auxiliary clues. First, we design a parallel
augmentation mechanism (PAM) to generate more suitable occluded data to
mitigate the negative effects of unbalanced data. Second, we propose the global
and local dual enhancement strategy (DES) to promote the context information
and details. Experimental results on three widely used occluded datasets and
two non-occluded datasets validate the effectiveness of our method. The code is
available at
https://github.com/littleprince1121/PADE_Parallel_Augmentation_and_Dual_Enhancement_for_Occluded_Person_ReID",None,-1
21a6cf2a-3583-4d39-9fd6-60af3b826126,Pair-Based Joint Encoding with Relational Graph Convolutional Networks for Emotion-Cause Pair Extraction,0.868504,"Emotion-cause pair extraction (ECPE) aims to extract emotion clauses and
corresponding cause clauses, which have recently received growing attention.
Previous methods sequentially encode features with a specified order. They
first encode the emotion and cause features for clause extraction and then
combine them for pair extraction. This lead to an imbalance in inter-task
feature interaction where features extracted later have no direct contact with
the former. To address this issue, we propose a novel Pair-Based Joint Encoding
(PBJE) network, which generates pairs and clauses features simultaneously in a
joint feature encoding manner to model the causal relationship in clauses. PBJE
can balance the information flow among emotion clauses, cause clauses and
pairs. From a multi-relational perspective, we construct a heterogeneous
undirected graph and apply the Relational Graph Convolutional Network (RGCN) to
capture the various relationship between clauses and the relationship between
pairs and clauses. Experimental results show that PBJE achieves
state-of-the-art performance on the Chinese benchmark corpus.",https://github.com/tutuDoki/PBJE-ECPE,-1
1b138b93-2446-4b6d-a060-990cd718d8dd,Multi-Level Modeling Units for End-to-End Mandarin Speech Recognition,0.0769842,"The choice of modeling units is crucial for automatic speech recognition
(ASR) tasks. In mandarin scenarios, the Chinese characters represent meaning
but are not directly related to the pronunciation. Thus only considering the
writing of Chinese characters as modeling units is insufficient to capture
speech features. In this paper, we present a novel method involves with
multi-level modeling units, which integrates multi-level information for
mandarin speech recognition. Specifically, the encoder block considers
syllables as modeling units and the decoder block deals with character-level
modeling units. To facilitate the incremental conversion from syllable features
to character features, we design an auxiliary task that applies cross-entropy
(CE) loss to intermediate decoder layers. During inference, the input feature
sequences are converted into syllable sequences by the encoder block and then
converted into Chinese characters by the decoder block. Experiments on the
widely used AISHELL-1 corpus demonstrate that our method achieves promising
results with CER of 4.1%/4.6% and 4.6%/5.2%, using the Conformer and the
Transformer backbones respectively.",https://github.com/mozillazg/python-pinyin,11
0965388a-a40e-4c3d-ab3f-397a78c6373f,IRISformer: Dense Vision Transformers for Single-Image Inverse Rendering in Indoor Scenes,0.627442,"Indoor scenes exhibit significant appearance variations due to myriad
interactions between arbitrarily diverse object shapes, spatially-changing
materials, and complex lighting. Shadows, highlights, and inter-reflections
caused by visible and invisible light sources require reasoning about
long-range interactions for inverse rendering, which seeks to recover the
components of image formation, namely, shape, material, and lighting. In this
work, our intuition is that the long-range attention learned by transformer
architectures is ideally suited to solve longstanding challenges in
single-image inverse rendering. We demonstrate with a specific instantiation of
a dense vision transformer, IRISformer, that excels at both single-task and
multi-task reasoning required for inverse rendering. Specifically, we propose a
transformer architecture to simultaneously estimate depths, normals,
spatially-varying albedo, roughness and lighting from a single image of an
indoor scene. Our extensive evaluations on benchmark datasets demonstrate
state-of-the-art results on each of the above tasks, enabling applications like
object insertion and material editing in a single unconstrained real image,
with greater photorealism than prior works. Code and data are publicly released
at https://github.com/ViLab-UCSD/IRISformer.",https://github.com/ViLab-UCSD/IRISformer,38190
84dc8454-fbdf-4fac-b2be-d1fb7954c345,Synthetic Dataset Generation for Adversarial Machine Learning Research,0.0555902,"Existing adversarial example research focuses on digitally inserted
perturbations on top of existing natural image datasets. This construction of
adversarial examples is not realistic because it may be difficult, or even
impossible, for an attacker to deploy such an attack in the real-world due to
sensing and environmental effects. To better understand adversarial examples
against cyber-physical systems, we propose approximating the real-world through
simulation. In this paper we describe our synthetic dataset generation tool
that enables scalable collection of such a synthetic dataset with realistic
adversarial examples. We use the CARLA simulator to collect such a dataset and
demonstrate simulated attacks that undergo the same environmental transforms
and processing as real-world images. Our tools have been used to collect
datasets to help evaluate the efficacy of adversarial examples, and can be
found at https://github.com/carla-simulator/carla/pull/4992.",https://github.com/carla-simulator/carla/pull/4992,-1
45abe536-ba12-4cf8-8793-51a74c150ba3,Forming Effective Human-AI Teams: Building Machine Learning Models that Complement the Capabilities of Multiple Experts,0.603157,"Machine learning (ML) models are increasingly being used in application
domains that often involve working together with human experts. In this
context, it can be advantageous to defer certain instances to a single human
expert when they are difficult to predict for the ML model. While previous work
has focused on scenarios with one distinct human expert, in many real-world
situations several human experts with varying capabilities may be available. In
this work, we propose an approach that trains a classification model to
complement the capabilities of multiple human experts. By jointly training the
classifier together with an allocation system, the classifier learns to
accurately predict those instances that are difficult for the human experts,
while the allocation system learns to pass each instance to the most suitable
team member -- either the classifier or one of the human experts. We evaluate
our proposed approach in multiple experiments on public datasets with
""synthetic"" experts and a real-world medical dataset annotated by multiple
radiologists. Our approach outperforms prior work and is more accurate than the
best human expert or a classifier. Furthermore, it is flexibly adaptable to
teams of varying sizes and different levels of expert diversity.",https://github.com/ptrckhmmr/human-ai-teams,-1
93267a5e-59d7-418c-ab85-8f47c464b841,SAT: Improving Semi-Supervised Text Classification with Simple Instance-Adaptive Self-Training,0.331893,"Self-training methods have been explored in recent years and have exhibited
great performance in improving semi-supervised learning. This work presents a
Simple instance-Adaptive self-Training method (SAT) for semi-supervised text
classification. SAT first generates two augmented views for each unlabeled data
and then trains a meta-learner to automatically identify the relative strength
of augmentations based on the similarity between the original view and the
augmented views. The weakly-augmented view is fed to the model to produce a
pseudo-label and the strongly-augmented view is used to train the model to
predict the same pseudo-label. We conducted extensive experiments and analyses
on three text classification datasets and found that with varying sizes of
labeled training data, SAT consistently shows competitive performance compared
to existing semi-supervised learning methods. Our code can be found at
\url{https://github.com/declare-lab/SAT.git}.",https://github.com/declare-lab/SAT.git,-1
10c1eb33-25d5-4fca-8724-14d99da2828b,The Legal Argument Reasoning Task in Civil Procedure,0.573754,"We present a new NLP task and dataset from the domain of the U.S. civil
procedure. Each instance of the dataset consists of a general introduction to
the case, a particular question, and a possible solution argument, accompanied
by a detailed analysis of why the argument applies in that case. Since the
dataset is based on a book aimed at law students, we believe that it represents
a truly complex task for benchmarking modern legal language models. Our
baseline evaluation shows that fine-tuning a legal transformer provides some
advantage over random baseline models, but our analysis reveals that the actual
ability to infer legal arguments remains a challenging open research question.",https://github.com/trusthlt/legal-argument-reasoning-task,-1
9ea7f630-66e4-4387-b3f2-cba04a0f024f,Psychiatric Scale Guided Risky Post Screening for Early Detection of Depression,0.214362,"Depression is a prominent health challenge to the world, and early risk
detection (ERD) of depression from online posts can be a promising technique
for combating the threat. Early depression detection faces the challenge of
efficiently tackling streaming data, balancing the tradeoff between timeliness,
accuracy and explainability. To tackle these challenges, we propose a
psychiatric scale guided risky post screening method that can capture risky
posts related to the dimensions defined in clinical depression scales, and
providing interpretable diagnostic basis. A Hierarchical Attentional Network
equipped with BERT (HAN-BERT) is proposed to further advance explainable
predictions. For ERD, we propose an online algorithm based on an evolving queue
of risky posts that can significantly reduce the number of model inferences to
boost efficiency. Experiments show that our method outperforms the competitive
feature-based and neural models under conventional depression detection
settings, and achieves simultaneous improvement in both efficacy and efficiency
for ERD.",https://github.com/blmoistawinde/scaleearlydepressdetectindicatingwhethertheuserUisuffersfromdepression,-1
acf1d438-6187-4fb3-a33f-d2b9ded560f8,Bi-directional Joint Neural Networks for Intent Classification and Slot Filling,0.6883,"Intent classification and slot filling are two critical tasks for natural
language understanding. Traditionally the two tasks proceeded independently.
However, more recently joint models for intent classification and slot filling
have achieved state-of-the-art performance, and have proved that there exists a
strong relationship between the two tasks. In this paper, we propose a
bi-directional joint model for intent classification and slot filling, which
includes a multi-stage hierarchical process via BERT and bi-directional joint
natural language understanding mechanisms, including intent2slot and
slot2intent, to obtain mutual performance enhancement between intent
classification and slot filling. The evaluations show that our model achieves
state-of-the-art results on intent classification accuracy, slot filling F1,
and significantly improves sentence-level semantic frame accuracy when applied
to publicly available benchmark datasets, ATIS (88.6%) and SNIPS (92.8%).",None,-1
2f0ca11c-0740-4fee-82de-548bf35c7129,Learning to Revise References for Faithful Summarization,0.708969,"In real-world scenarios with naturally occurring datasets, reference
summaries are noisy and may contain information that cannot be inferred from
the source text. On large news corpora, removing low quality samples has been
shown to reduce model hallucinations. Yet, for smaller, and/or noisier corpora,
filtering is detrimental to performance. To improve reference quality while
retaining all data, we propose a new approach: to selectively re-write
unsupported reference sentences to better reflect source data. We automatically
generate a synthetic dataset of positive and negative revisions by corrupting
supported sentences and learn to revise reference sentences with contrastive
learning. The intensity of revisions is treated as a controllable attribute so
that, at inference, diverse candidates can be over-generated-then-rescored to
balance faithfulness and abstraction. To test our methods, we extract noisy
references from publicly available MIMIC-III discharge summaries for the task
of hospital-course summarization, and vary the data on which models are
trained. According to metrics and human evaluation, models trained on revised
clinical references are much more faithful, informative, and fluent than models
trained on original or filtered data.",https://github.com/amazon-research/summary-reference-revision,30354
09a87fe8-afff-4621-9fcb-0031b9cbfd43,End-to-End 3D Hand Pose Estimation from Stereo Cameras,0.692917,"This work proposes an end-to-end approach to estimate full 3D hand pose from
stereo cameras. Most existing methods of estimating hand pose from stereo
cameras apply stereo matching to obtain depth map and use depth-based solution
to estimate hand pose. In contrast, we propose to bypass the stereo matching
and directly estimate the 3D hand pose from the stereo image pairs. The
proposed neural network architecture extends from any keypoint predictor to
estimate the sparse disparity of the hand joints. In order to effectively train
the model, we propose a large scale synthetic dataset that is composed of
stereo image pairs and ground truth 3D hand pose annotations. Experiments show
that the proposed approach outperforms the existing methods based on the stereo
depth.",None,-1
4711b739-d681-48be-bedc-b0f074025b5e,Non-Markovian Reward Modelling from Trajectory Labels via Interpretable Multiple Instance Learning,0.519171,"We generalise the problem of reward modelling (RM) for reinforcement learning
(RL) to handle non-Markovian rewards. Existing work assumes that human
evaluators observe each step in a trajectory independently when providing
feedback on agent behaviour. In this work, we remove this assumption, extending
RM to capture temporal dependencies in human assessment of trajectories. We
show how RM can be approached as a multiple instance learning (MIL) problem,
where trajectories are treated as bags with return labels, and steps within the
trajectories are instances with unseen reward labels. We go on to develop new
MIL models that are able to capture the time dependencies in labelled
trajectories. We demonstrate on a range of RL tasks that our novel MIL models
can reconstruct reward functions to a high level of accuracy, and can be used
to train high-performing agent policies.",https://github.com/JAEarly/MIL-for-Non-Markovian-Reward-Modelling,-1
167014be-c5c2-4c44-8e53-49f65a80f57a,A Secure Clustering Protocol with Fuzzy Trust Evaluation and Outlier Detection for Industrial Wireless Sensor Networks,0.881122,"Security is one of the major concerns in Industrial Wireless Sensor Networks
(IWSNs). To assure the security in clustered IWSNs, this paper presents a
secure clustering protocol with fuzzy trust evaluation and outlier detection
(SCFTO). Firstly, to deal with the transmission uncertainty in an open wireless
medium, an interval type-2 fuzzy logic controller is adopted to estimate the
trusts. And then a density based outlier detection mechanism is introduced to
acquire an adaptive trust threshold used to isolate the malicious nodes from
being cluster heads. Finally, a fuzzy based cluster heads election method is
proposed to achieve a balance between energy saving and security assurance, so
that a normal sensor node with more residual energy or less confidence on other
nodes has higher probability to be the cluster head. Extensive experiments
verify that our secure clustering protocol can effectively defend the network
against attacks from internal malicious or compromised nodes.",None,-1
d6c7b9f8-759a-440f-b558-38ff73458264,A Novel Approach to Fairness in Automated Decision-Making using Affective Normalization,0.0525721,"Any decision, such as one about who to hire, involves two components. First,
a rational component, i.e., they have a good education, they speak clearly.
Second, an affective component, based on observables such as visual features of
race and gender, and possibly biased by stereotypes. Here we propose a method
for measuring the affective, socially biased, component, thus enabling its
removal. That is, given a decision-making process, these affective measurements
remove the affective bias in the decision, rendering it fair across a set of
categories defined by the method itself. We thus propose that this may solve
three key problems in intersectional fairness: (1) the definition of categories
over which fairness is a consideration; (2) an infinite regress into smaller
and smaller groups; and (3) ensuring a fair distribution based on basic human
rights or other prior information. The primary idea in this paper is that
fairness biases can be measured using affective coherence, and that this can be
used to normalize outcome mappings. We aim for this conceptual work to expose a
novel method for handling fairness problems that uses emotional coherence as an
independent measure of bias that goes beyond statistical parity.",None,-1
0f61e374-4734-48d1-8280-d8a30aec25c9,Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs,0.999935,"Social intelligence and Theory of Mind (ToM), i.e., the ability to reason
about the different mental states, intents, and reactions of all people
involved, allow humans to effectively navigate and understand everyday social
interactions. As NLP systems are used in increasingly complex social
situations, their ability to grasp social dynamics becomes crucial. In this
work, we examine the open question of social intelligence and Theory of Mind in
modern NLP systems from an empirical and theory-based perspective. We show that
one of today's largest language models (GPT-3; Brown et al., 2020) lacks this
kind of social intelligence out-of-the box, using two tasks: SocialIQa (Sap et
al., 2019), which measures models' ability to understand intents and reactions
of participants of social interactions, and ToMi (Le et al., 2019), which
measures whether models can infer mental states and realities of participants
of situations. Our results show that models struggle substantially at these
Theory of Mind tasks, with well-below-human accuracies of 55% and 60% on
SocialIQa and ToMi, respectively. To conclude, we draw on theories from
pragmatics to contextualize this shortcoming of large language models, by
examining the limitations stemming from their data, neural architecture, and
training paradigms. Challenging the prevalent narrative that only scale is
needed, we posit that person-centric NLP approaches might be more effective
towards neural Theory of Mind.
  In our updated version, we also analyze newer instruction tuned and RLFH
models for neural ToM. We find that even ChatGPT and GPT-4 do not display
emergent Theory of Mind; strikingly even GPT-4 performs only 60% accuracy on
the ToMi questions related to mental states and realities.",None,-1
28b26f83-ed7d-41a6-b2d9-8efe59bca704,Learning Sparse Latent Representations for Generator Model,0.0468538,"Sparsity is a desirable attribute. It can lead to more efficient and more
effective representations compared to the dense model. Meanwhile, learning
sparse latent representations has been a challenging problem in the field of
computer vision and machine learning due to its complexity. In this paper, we
present a new unsupervised learning method to enforce sparsity on the latent
space for the generator model with a gradually sparsified spike and slab
distribution as our prior. Our model consists of only one top-down generator
network that maps the latent variable to the observed data. Latent variables
can be inferred following generator posterior direction using non-persistent
gradient based method. Spike and Slab regularization in the inference step can
push non-informative latent dimensions towards zero to induce sparsity.
Extensive experiments show the model can preserve majority of the information
from original images with sparse representations while demonstrating improved
results compared to other existing methods. We observe that our model can learn
disentangled semantics and increase explainability of the latent codes while
boosting the robustness in the task of classification and denoising.",None,-1
8f1466b1-cf34-4282-b1dd-a92ba71dc91f,RobustLoc: Robust Camera Pose Regression in Challenging Driving Environments,0.775592,"Camera relocalization has various applications in autonomous driving.
Previous camera pose regression models consider only ideal scenarios where
there is little environmental perturbation. To deal with challenging driving
environments that may have changing seasons, weather, illumination, and the
presence of unstable objects, we propose RobustLoc, which derives its
robustness against perturbations from neural differential equations. Our model
uses a convolutional neural network to extract feature maps from multi-view
images, a robust neural differential equation diffusion block module to diffuse
information interactively, and a branched pose decoder with multi-layer
training to estimate the vehicle poses. Experiments demonstrate that RobustLoc
surpasses current state-of-the-art camera pose regression models and achieves
robust performance in various environments. Our code is released at:
https://github.com/sijieaaa/RobustLoc",https://github.com/sijieaaa/RobustLoc,-1
72fbe0e5-ae26-4e82-9bfd-5e47f070f9c6,Towards Better Chinese-centric Neural Machine Translation for Low-resource Languages,0.818251,"The last decade has witnessed enormous improvements in science and
technology, stimulating the growing demand for economic and cultural exchanges
in various countries. Building a neural machine translation (NMT) system has
become an urgent trend, especially in the low-resource setting. However, recent
work tends to study NMT systems for low-resource languages centered on English,
while few works focus on low-resource NMT systems centered on other languages
such as Chinese. To achieve this, the low-resource multilingual translation
challenge of the 2021 iFLYTEK AI Developer Competition provides the
Chinese-centric multilingual low-resource NMT tasks, where participants are
required to build NMT systems based on the provided low-resource samples. In
this paper, we present the winner competition system that leverages monolingual
word embeddings data enhancement, bilingual curriculum learning, and
contrastive re-ranking. In addition, a new Incomplete-Trust (In-trust) loss
function is proposed to replace the traditional cross-entropy loss when
training. The experimental results demonstrate that the implementation of these
ideas leads better performance than other state-of-the-art methods. All the
experimental codes are released at:
https://github.com/WENGSYX/Low-resource-text-translation.",https://github.com/WENGSYX/Low-resource-text-translation,-1
c56c8a57-36f6-4787-90c9-5cfe22a7596f,Few-Shot Stance Detection via Target-Aware Prompt Distillation,0.20023,"Stance detection aims to identify whether the author of a text is in favor
of, against, or neutral to a given target. The main challenge of this task
comes two-fold: few-shot learning resulting from the varying targets and the
lack of contextual information of the targets. Existing works mainly focus on
solving the second issue by designing attention-based models or introducing
noisy external knowledge, while the first issue remains under-explored. In this
paper, inspired by the potential capability of pre-trained language models
(PLMs) serving as knowledge bases and few-shot learners, we propose to
introduce prompt-based fine-tuning for stance detection. PLMs can provide
essential contextual information for the targets and enable few-shot learning
via prompts. Considering the crucial role of the target in stance detection
task, we design target-aware prompts and propose a novel verbalizer. Instead of
mapping each label to a concrete word, our verbalizer maps each label to a
vector and picks the label that best captures the correlation between the
stance and the target. Moreover, to alleviate the possible defect of dealing
with varying targets with a single hand-crafted prompt, we propose to distill
the information learned from multiple prompts. Experimental results show the
superior performance of our proposed model in both full-data and few-shot
scenarios.",https://github.com/jyjulyseven/TAPD,-1
8a1ba8a4-5fae-4dc8-bfb8-27a2f0f687e3,Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes,0.487329,"We study offline reinforcement learning (RL) in partially observable Markov
decision processes. In particular, we aim to learn an optimal policy from a
dataset collected by a behavior policy which possibly depends on the latent
state. Such a dataset is confounded in the sense that the latent state
simultaneously affects the action and the observation, which is prohibitive for
existing offline RL algorithms. To this end, we propose the \underline{P}roxy
variable \underline{P}essimistic \underline{P}olicy \underline{O}ptimization
(\texttt{P3O}) algorithm, which addresses the confounding bias and the
distributional shift between the optimal and behavior policies in the context
of general function approximation. At the core of \texttt{P3O} is a coupled
sequence of pessimistic confidence regions constructed via proximal causal
inference, which is formulated as minimax estimation. Under a partial coverage
assumption on the confounded dataset, we prove that \texttt{P3O} achieves a
$n^{-1/2}$-suboptimality, where $n$ is the number of trajectories in the
dataset. To our best knowledge, \texttt{P3O} is the first provably efficient
offline RL algorithm for POMDPs with a confounded dataset.",None,-1
8b487b20-730b-4ca2-aa73-98b0c007ce2f,KETOD: Knowledge-Enriched Task-Oriented Dialogue,0.911552,"Existing studies in dialogue system research mostly treat task-oriented
dialogue and chit-chat as separate domains. Towards building a human-like
assistant that can converse naturally and seamlessly with users, it is
important to build a dialogue system that conducts both types of conversations
effectively. In this work, we investigate how task-oriented dialogue and
knowledge-grounded chit-chat can be effectively integrated into a single model.
To this end, we create a new dataset, KETOD (Knowledge-Enriched Task-Oriented
Dialogue), where we naturally enrich task-oriented dialogues with chit-chat
based on relevant entity knowledge. We also propose two new models,
SimpleToDPlus and Combiner, for the proposed task. Experimental results on both
automatic and human evaluations show that the proposed methods can
significantly improve the performance in knowledge-enriched response generation
while maintaining a competitive task-oriented dialog performance. We believe
our new dataset will be a valuable resource for future studies. Our dataset and
code are publicly available at \url{https://github.com/facebookresearch/ketod}.",https://github.com/facebookresearch/ketod,-1
5ef30161-318b-4959-89e0-64d3017b08f4,IRON: Inverse Rendering by Optimizing Neural SDFs and Materials from Photometric Images,0.944665,"We propose a neural inverse rendering pipeline called IRON that operates on
photometric images and outputs high-quality 3D content in the format of
triangle meshes and material textures readily deployable in existing graphics
pipelines. Our method adopts neural representations for geometry as signed
distance fields (SDFs) and materials during optimization to enjoy their
flexibility and compactness, and features a hybrid optimization scheme for
neural SDFs: first, optimize using a volumetric radiance field approach to
recover correct topology, then optimize further using edgeaware physics-based
surface rendering for geometry refinement and disentanglement of materials and
lighting. In the second stage, we also draw inspiration from mesh-based
differentiable rendering, and design a novel edge sampling algorithm for neural
SDFs to further improve performance. We show that our IRON achieves
significantly better inverse rendering quality compared to prior works. Our
project page is here: https://kai-46.github.io/IRON-website/",None,-1
4dcc2878-1fcd-4996-883c-f3b9227c28ee,E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text,0.928236,"Identifying named entities such as a person, location or organization, in
documents can highlight key information to readers. Training Named Entity
Recognition (NER) models requires an annotated data set, which can be a
time-consuming labour-intensive task. Nevertheless, there are publicly
available NER data sets for general English. Recently there has been interest
in developing NER for legal text. However, prior work and experimental results
reported here indicate that there is a significant degradation in performance
when NER methods trained on a general English data set are applied to legal
text. We describe a publicly available legal NER data set, called E-NER, based
on legal company filings available from the US Securities and Exchange
Commission's EDGAR data set. Training a number of different NER algorithms on
the general English CoNLL-2003 corpus but testing on our test collection
confirmed significant degradations in accuracy, as measured by the F1-score, of
between 29.4\% and 60.4\%, compared to training and testing on the E-NER
collection.",https://github.com/terenceau2/E-NER-Dataset,-1
30227273-c426-4736-91e3-333ae91e7d07,Knowledge Graph Induction enabling Recommending and Trend Analysis: A Corporate Research Community Use Case,0.202382,"A research division plays an important role of driving innovation in an
organization. Drawing insights, following trends, keeping abreast of new
research, and formulating strategies are increasingly becoming more challenging
for both researchers and executives as the amount of information grows in both
velocity and volume. In this paper we present a use case of how a corporate
research community, IBM Research, utilizes Semantic Web technologies to induce
a unified Knowledge Graph from both structured and textual data obtained by
integrating various applications used by the community related to research
projects, academic papers, datasets, achievements and recognition. In order to
make the Knowledge Graph more accessible to application developers, we
identified a set of common patterns for exploiting the induced knowledge and
exposed them as APIs. Those patterns were born out of user research which
identified the most valuable use cases or user pain points to be alleviated. We
outline two distinct scenarios: recommendation and analytics for business use.
We will discuss these scenarios in detail and provide an empirical evaluation
on entity recommendation specifically. The methodology used and the lessons
learned from this work can be applied to other organizations facing similar
challenges.",None,3252
38ddde9e-f8e7-4949-8eb9-25c3250cb14e,Text Summarization with Oracle Expectation,0.233691,"Extractive summarization produces summaries by identifying and concatenating
the most important sentences in a document. Since most summarization datasets
do not come with gold labels indicating whether document sentences are
summary-worthy, different labeling algorithms have been proposed to extrapolate
oracle extracts for model training. In this work, we identify two flaws with
the widely used greedy labeling approach: it delivers suboptimal and
deterministic oracles. To alleviate both issues, we propose a simple yet
effective labeling algorithm that creates soft, expectation-based sentence
labels. We define a new learning objective for extractive summarization which
incorporates learning signals from multiple oracle summaries and prove it is
equivalent to estimating the oracle expectation for each document sentence.
Without any architectural modifications, the proposed labeling scheme achieves
superior performance on a variety of summarization benchmarks across domains
and languages, in both supervised and zero-shot settings.",https://github.com/yumoxu/oreo,-1
dab2a3c8-61bb-4c34-a58b-6213a9867ec1,Few-Shot Fine-Grained Entity Typing with Automatic Label Interpretation and Instance Generation,0.655283,"We study the problem of few-shot Fine-grained Entity Typing (FET), where only
a few annotated entity mentions with contexts are given for each entity type.
Recently, prompt-based tuning has demonstrated superior performance to standard
fine-tuning in few-shot scenarios by formulating the entity type classification
task as a ''fill-in-the-blank'' problem. This allows effective utilization of
the strong language modeling capability of Pre-trained Language Models (PLMs).
Despite the success of current prompt-based tuning approaches, two major
challenges remain: (1) the verbalizer in prompts is either manually designed or
constructed from external knowledge bases, without considering the target
corpus and label hierarchy information, and (2) current approaches mainly
utilize the representation power of PLMs, but have not explored their
generation power acquired through extensive general-domain pre-training. In
this work, we propose a novel framework for few-shot FET consisting of two
modules: (1) an entity type label interpretation module automatically learns to
relate type labels to the vocabulary by jointly leveraging few-shot instances
and the label hierarchy, and (2) a type-based contextualized instance generator
produces new instances based on given instances to enlarge the training set for
better generalization. On three benchmark datasets, our model outperforms
existing methods by significant margins. Code can be found at
https://github.com/teapot123/Fine-Grained-Entity-Typing.",https://github.com/teapot123/Fine-Grained-Entity-Typing,-1
0a7562af-86ef-4e84-981d-481f66e0f217,A Scalable Combinatorial Solver for Elastic Geometrically Consistent 3D Shape Matching,0.43958,"We present a scalable combinatorial algorithm for globally optimizing over
the space of geometrically consistent mappings between 3D shapes. We use the
mathematically elegant formalism proposed by Windheuser et al. (ICCV 2011)
where 3D shape matching was formulated as an integer linear program over the
space of orientation-preserving diffeomorphisms. Until now, the resulting
formulation had limited practical applicability due to its complicated
constraint structure and its large size. We propose a novel primal heuristic
coupled with a Lagrange dual problem that is several orders of magnitudes
faster compared to previous solvers. This allows us to handle shapes with
substantially more triangles than previously solvable. We demonstrate
compelling results on diverse datasets, and, even showcase that we can address
the challenging setting of matching two partial shapes without availability of
complete shapes. Our code is publicly available at
http://github.com/paul0noah/sm-comb .",http://github.com/paul0noah/sm-comb,-1
9d84fd9f-05f2-4882-8cae-5aff3ada75b6,Improving Large-scale Paraphrase Acquisition and Generation,0.578161,"This paper addresses the quality issues in existing Twitter-based paraphrase
datasets, and discusses the necessity of using two separate definitions of
paraphrase for identification and generation tasks. We present a new
Multi-Topic Paraphrase in Twitter (MultiPIT) corpus that consists of a total of
130k sentence pairs with crowdsoursing (MultiPIT_crowd) and expert
(MultiPIT_expert) annotations using two different paraphrase definitions for
paraphrase identification, in addition to a multi-reference test set
(MultiPIT_NMR) and a large automatically constructed training set
(MultiPIT_Auto) for paraphrase generation. With improved data annotation
quality and task-specific paraphrase definition, the best pre-trained language
model fine-tuned on our dataset achieves the state-of-the-art performance of
84.2 F1 for automatic paraphrase identification. Furthermore, our empirical
results also demonstrate that the paraphrase generation models trained on
MultiPIT_Auto generate more diverse and high-quality paraphrases compared to
their counterparts fine-tuned on other corpora such as Quora, MSCOCO, and
ParaNMT.",https://www.github.com/Tiiiger/bert_score,-1
dac811d1-d7f4-4838-9a29-02fec254390c,Constants of motion network,0.444285,"The beauty of physics is that there is usually a conserved quantity in an
always-changing system, known as the constant of motion. Finding the constant
of motion is important in understanding the dynamics of the system, but
typically requires mathematical proficiency and manual analytical work. In this
paper, we present a neural network that can simultaneously learn the dynamics
of the system and the constants of motion from data. By exploiting the
discovered constants of motion, it can produce better predictions on dynamics
and can work on a wider range of systems than Hamiltonian-based neural
networks. In addition, the training progresses of our method can be used as an
indication of the number of constants of motion in a system which could be
useful in studying a novel physical system.",https://github.com/machine-discovery/comet/,-1
2bf0c262-bfcf-4dcf-8560-971f9a45f7c0,U-Attention to Textures: Hierarchical Hourglass Vision Transformer for Universal Texture Synthesis,0.0711964,"We present a novel U-Attention vision Transformer for universal texture
synthesis. We exploit the natural long-range dependencies enabled by the
attention mechanism to allow our approach to synthesize diverse textures while
preserving their structures in a single inference. We propose a hierarchical
hourglass backbone that attends to the global structure and performs patch
mapping at varying scales in a coarse-to-fine-to-coarse stream. Completed by
skip connection and convolution designs that propagate and fuse information at
different scales, our hierarchical U-Attention architecture unifies attention
to features from macro structures to micro details, and progressively refines
synthesis results at successive stages. Our method achieves stronger 2$\times$
synthesis than previous work on both stochastic and structured textures while
generalizing to unseen textures without fine-tuning. Ablation studies
demonstrate the effectiveness of each component of our architecture.",None,37852
2aa94fab-c145-48d4-beaf-8dce1d14b64d,Transformers in Action: Weakly Supervised Action Segmentation,0.0747763,"The video action segmentation task is regularly explored under weaker forms
of supervision, such as transcript supervision, where a list of actions is
easier to obtain than dense frame-wise labels. In this formulation, the task
presents various challenges for sequence modeling approaches due to the
emphasis on action transition points, long sequence lengths, and frame
contextualization, making the task well-posed for transformers. Given
developments enabling transformers to scale linearly, we demonstrate through
our architecture how they can be applied to improve action alignment accuracy
over the equivalent RNN-based models with the attention mechanism focusing
around salient action transition regions. Additionally, given the recent focus
on inference-time transcript selection, we propose a supplemental transcript
embedding approach to select transcripts more quickly at inference-time.
Furthermore, we subsequently demonstrate how this approach can also improve the
overall segmentation performance. Finally, we evaluate our proposed methods
across the benchmark datasets to better understand the applicability of
transformers and the importance of transcript selection on this video-driven
weakly-supervised task.",None,78284
b0c58dfa-3881-49d3-b8b8-56d0cd9f3388,NTULM: Enriching Social Media Text Representations with Non-Textual Units,0.408569,"On social media, additional context is often present in the form of
annotations and meta-data such as the post's author, mentions, Hashtags, and
hyperlinks. We refer to these annotations as Non-Textual Units (NTUs). We posit
that NTUs provide social context beyond their textual semantics and leveraging
these units can enrich social media text representations. In this work we
construct an NTU-centric social heterogeneous network to co-embed NTUs. We then
principally integrate these NTU embeddings into a large pretrained language
model by fine-tuning with these additional units. This adds context to noisy
short-text social media. Experiments show that utilizing NTU-augmented text
representations significantly outperforms existing text-only baselines by 2-5\%
relative points on many downstream tasks highlighting the importance of context
to social media NLP. We also highlight that including NTU context into the
initial layers of language model alongside text is better than using it after
the text embedding is generated. Our work leads to the generation of holistic
general purpose social media content embedding.",None,-1
32d8be1a-db0f-4fe1-b1b7-6fa5e15adb3f,SwinNet: Swin Transformer drives edge-aware RGB-D and RGB-T salient object detection,0.940169,"Convolutional neural networks (CNNs) are good at extracting contexture
features within certain receptive fields, while transformers can model the
global long-range dependency features. By absorbing the advantage of
transformer and the merit of CNN, Swin Transformer shows strong feature
representation ability. Based on it, we propose a cross-modality fusion model
SwinNet for RGB-D and RGB-T salient object detection. It is driven by Swin
Transformer to extract the hierarchical features, boosted by attention
mechanism to bridge the gap between two modalities, and guided by edge
information to sharp the contour of salient object. To be specific, two-stream
Swin Transformer encoder first extracts multi-modality features, and then
spatial alignment and channel re-calibration module is presented to optimize
intra-level cross-modality features. To clarify the fuzzy boundary, edge-guided
decoder achieves inter-level cross-modality fusion under the guidance of edge
features. The proposed model outperforms the state-of-the-art models on RGB-D
and RGB-T datasets, showing that it provides more insight into the
cross-modality complementarity task.",https://github.com/liuzywen/SwinNet,5263
eaf23725-3464-42f3-bb6f-806ce87ef3b3,Point3D: tracking actions as moving points with 3D CNNs,0.448851,"Spatio-temporal action recognition has been a challenging task that involves
detecting where and when actions occur. Current state-of-the-art action
detectors are mostly anchor-based, requiring sensitive anchor designs and huge
computations due to calculating large numbers of anchor boxes. Motivated by
nascent anchor-free approaches, we propose Point3D, a flexible and
computationally efficient network with high precision for spatio-temporal
action recognition. Our Point3D consists of a Point Head for action
localization and a 3D Head for action classification. Firstly, Point Head is
used to track center points and knot key points of humans to localize the
bounding box of an action. These location features are then piped into a
time-wise attention to learn long-range dependencies across frames. The 3D Head
is later deployed for the final action classification. Our Point3D achieves
state-of-the-art performance on the JHMDB, UCF101-24, and AVA benchmarks in
terms of frame-mAP and video-mAP. Comprehensive ablation studies also
demonstrate the effectiveness of each module proposed in our Point3D.",None,-1
cb1bd259-ced4-4175-b2cb-ec01e7c0b353,A Pixel-based Encryption Method for Privacy-Preserving Deep Learning Models,0.132686,"In the recent years, pixel-based perceptual algorithms have been successfully
applied for privacy-preserving deep learning (DL) based applications. However,
their security has been broken in subsequent works by demonstrating a
chosen-plaintext attack. In this paper, we propose an efficient pixel-based
perceptual encryption method. The method provides a necessary level of security
while preserving the intrinsic properties of the original image. Thereby, can
enable deep learning (DL) applications in the encryption domain. The method is
substitution based where pixel values are XORed with a sequence (as opposed to
a single value used in the existing methods) generated by a chaotic map. We
have used logistic maps for their low computational requirements. In addition,
to compensate for any inefficiency because of the logistic maps, we use a
second key to shuffle the sequence. We have compared the proposed method in
terms of encryption efficiency and classification accuracy of the DL models on
them. We have validated the proposed method with CIFAR datasets. The analysis
shows that when classification is performed on the cipher images, the model
preserves accuracy of the existing methods while provides better security.",None,-1
251f156a-2106-4b7a-a722-ea0ba61e86ca,Adaptive Local-Component-aware Graph Convolutional Network for One-shot Skeleton-based Action Recognition,0.721547,"Skeleton-based action recognition receives increasing attention because the
skeleton representations reduce the amount of training data by eliminating
visual information irrelevant to actions. To further improve the sample
efficiency, meta-learning-based one-shot learning solutions were developed for
skeleton-based action recognition. These methods find the nearest neighbor
according to the similarity between instance-level global average embedding.
However, such measurement holds unstable representativity due to inadequate
generalized learning on local invariant and noisy features, while intuitively,
more fine-grained recognition usually relies on determining key local body
movements. To address this limitation, we present the Adaptive
Local-Component-aware Graph Convolutional Network, which replaces the
comparison metric with a focused sum of similarity measurements on aligned
local embedding of action-critical spatial/temporal segments. Comprehensive
one-shot experiments on the public benchmark of NTU-RGB+D 120 indicate that our
method provides a stronger representation than the global embedding and helps
our model reach state-of-the-art.",None,-1
25f6634f-86bb-47ea-829c-763e2e39ae37,PIC4rl-gym: a ROS2 modular framework for Robots Autonomous Navigation with Deep Reinforcement Learning,0.80804,"Learning agents can optimize standard autonomous navigation improving
flexibility, efficiency, and computational cost of the system by adopting a
wide variety of approaches. This work introduces the \textit{PIC4rl-gym}, a
fundamental modular framework to enhance navigation and learning research by
mixing ROS2 and Gazebo, the standard tools of the robotics community, with Deep
Reinforcement Learning (DRL). The paper describes the whole structure of the
PIC4rl-gym, which fully integrates DRL agent's training and testing in several
indoor and outdoor navigation scenarios and tasks. A modular approach is
adopted to easily customize the simulation by selecting new platforms, sensors,
or models. We demonstrate the potential of our novel gym by benchmarking the
resulting policies, trained for different navigation tasks, with a complete set
of metrics.",https://github.com/PIC4SeR/PIC4rl_gym,3782
9018e07e-aa42-4fb7-a303-18f854346c4a,Generalizing Multimodal Pre-training into Multilingual via Language Acquisition,0.0754042,"English-based Vision-Language Pre-training (VLP) has achieved great success
in various downstream tasks. Some efforts have been taken to generalize this
success to non-English languages through Multilingual Vision-Language
Pre-training (M-VLP). However, due to the large number of languages, M-VLP
models often require huge computing resources and cannot be flexibly extended
to new languages. In this work, we propose a \textbf{M}ulti\textbf{L}ingual
\textbf{A}cquisition (MLA) framework that can easily generalize a monolingual
Vision-Language Pre-training model into multilingual. Specifically, we design a
lightweight language acquisition encoder based on state-of-the-art monolingual
VLP models. We further propose a two-stage training strategy to optimize the
language acquisition encoder, namely the Native Language Transfer stage and the
Language Exposure stage. With much less multilingual training data and
computing resources, our model achieves state-of-the-art performance on
multilingual image-text and video-text retrieval benchmarks.",https://github.com/FreddeFrallan/Multilingual-CLIP,-1
ffc0e825-d330-4ec0-9db3-6110bfb33c64,On the Impact of Speech Recognition Errors in Passage Retrieval for Spoken Question Answering,0.400384,"Interacting with a speech interface to query a Question Answering (QA) system
is becoming increasingly popular. Typically, QA systems rely on passage
retrieval to select candidate contexts and reading comprehension to extract the
final answer. While there has been some attention to improving the reading
comprehension part of QA systems against errors that automatic speech
recognition (ASR) models introduce, the passage retrieval part remains
unexplored. However, such errors can affect the performance of passage
retrieval, leading to inferior end-to-end performance. To address this gap, we
augment two existing large-scale passage ranking and open domain QA datasets
with synthetic ASR noise and study the robustness of lexical and dense
retrievers against questions with ASR noise. Furthermore, we study the
generalizability of data augmentation techniques across different domains; with
each domain being a different language dialect or accent. Finally, we create a
new dataset with questions voiced by human users and use their transcriptions
to show that the retrieval performance can further degrade when dealing with
natural ASR noise instead of synthetic ASR noise.",None,-1
b761b43e-5e68-48a0-9545-34e097a80b97,Improving Long Tailed Document-Level Relation Extraction via Easy Relation Augmentation and Contrastive Learning,0.382711,"Towards real-world information extraction scenario, research of relation
extraction is advancing to document-level relation extraction(DocRE). Existing
approaches for DocRE aim to extract relation by encoding various information
sources in the long context by novel model architectures. However, the inherent
long-tailed distribution problem of DocRE is overlooked by prior work. We argue
that mitigating the long-tailed distribution problem is crucial for DocRE in
the real-world scenario. Motivated by the long-tailed distribution problem, we
propose an Easy Relation Augmentation(ERA) method for improving DocRE by
enhancing the performance of tailed relations. In addition, we further propose
a novel contrastive learning framework based on our ERA, i.e., ERACL, which can
further improve the model performance on tailed relations and achieve
competitive overall DocRE performance compared to the state-of-arts.",None,-1
47c4467c-7945-4dc3-85a3-43acb5d60413,Engagement Detection with Multi-Task Training in E-Learning Environments,0.0755781,"Recognition of user interaction, in particular engagement detection, became
highly crucial for online working and learning environments, especially during
the COVID-19 outbreak. Such recognition and detection systems significantly
improve the user experience and efficiency by providing valuable feedback. In
this paper, we propose a novel Engagement Detection with Multi-Task Training
(ED-MTT) system which minimizes mean squared error and triplet loss together to
determine the engagement level of students in an e-learning environment. The
performance of this system is evaluated and compared against the
state-of-the-art on a publicly available dataset as well as videos collected
from real-life scenarios. The results show that ED-MTT achieves 6% lower MSE
than the best state-of-the-art performance with highly acceptable training time
and lightweight feature extraction.",https://github.com/CopurOnur/ED-MTT,-1
55a67219-fb1e-412a-8af5-793e599f88fb,Can Demographic Factors Improve Text Classification? Revisiting Demographic Adaptation in the Age of Transformers,0.425663,"Demographic factors (e.g., gender or age) shape our language. Previous work
showed that incorporating demographic factors can consistently improve
performance for various NLP tasks with traditional NLP models. In this work, we
investigate whether these previous findings still hold with state-of-the-art
pretrained Transformer-based language models (PLMs). We use three common
specialization methods proven effective for incorporating external knowledge
into pretrained Transformers (e.g., domain-specific or geographic knowledge).
We adapt the language representations for the demographic dimensions of gender
and age, using continuous language modeling and dynamic multi-task learning for
adaptation, where we couple language modeling objectives with the prediction of
demographic classes. Our results, when employing a multilingual PLM, show
substantial gains in task performance across four languages (English, German,
French, and Danish), which is consistent with the results of previous work.
However, controlling for confounding factors - primarily domain and language
proficiency of Transformer-based PLMs - shows that downstream performance gains
from our demographic adaptation do not actually stem from demographic
knowledge. Our results indicate that demographic specialization of PLMs, while
holding promise for positive societal impact, still represents an unsolved
problem for (modern) NLP.",https://github.com/umanlp/SocioAdapt,-1
b7b9cd66-3ecc-4b96-af3d-8c579b63bb86,Instance-Specific Image Goal Navigation: Training Embodied Agents to Find Object Instances,0.797243,"We consider the problem of embodied visual navigation given an image-goal
(ImageNav) where an agent is initialized in an unfamiliar environment and
tasked with navigating to a location 'described' by an image. Unlike related
navigation tasks, ImageNav does not have a standardized task definition which
makes comparison across methods difficult. Further, existing formulations have
two problematic properties; (1) image-goals are sampled from random locations
which can lead to ambiguity (e.g., looking at walls), and (2) image-goals match
the camera specification and embodiment of the agent; this rigidity is limiting
when considering user-driven downstream applications. We present the
Instance-specific ImageNav task (InstanceImageNav) to address these
limitations. Specifically, the goal image is 'focused' on some particular
object instance in the scene and is taken with camera parameters independent of
the agent. We instantiate InstanceImageNav in the Habitat Simulator using
scenes from the Habitat-Matterport3D dataset (HM3D) and release a standardized
benchmark to measure community progress.",https://github.com/facebookresearch/habitat-lab,-1
2a965375-c4c9-40e7-b2a2-0dfd7548d4fd,Chemotaxis of sea urchin sperm cells through deep reinforcement learning,0.540249,"By imitating biological microswimmers, microrobots can be designed to
accomplish targeted delivery of cargos and biomedical manipulations at
microscale. However, it is still a great challenge to enable microrobots to
maneuver in a complex environment. Machine learning algorithms offer a tool to
boost mobility and flexibility of a synthetic microswimmer, hence could help us
design truly smart microrobots. In this work, we investigate how a model of sea
urchin sperm cell can self-learn chemotactic motion in a chemoattractant
concentration field. We employ an artificial neural network to act as a
decision-making agent and facilitate the sperm cell to discover efficient
maneuver strategies through a deep reinforcement learning (DRL) algorithm. Our
results show that chemotactic behaviours, very similar to the realistic ones,
can be achieved by the DRL utilizing only limited environmental information. In
most cases, the DRL algorithm discovers more efficient strategies than the
human-devised one. Furthermore, the DRL can even utilize an external
disturbance to facilitate the chemotactic motion if the extra flow information
is also taken into account by the artificial neural network. Our results
provide insights to the chemotactic process of sea urchin sperm cells and also
prepare guidance for the intelligent maneuver of microrobots.",None,1256
cfcc793a-4c06-4dc4-a813-131191fbcdfc,SESCORE2: Learning Text Generation Evaluation via Synthesizing Realistic Mistakes,0.124992,"Is it possible to train a general metric for evaluating text generation
quality without human annotated ratings? Existing learned metrics either
perform unsatisfactorily across text generation tasks or require human ratings
for training on specific tasks. In this paper, we propose SESCORE2, a
self-supervised approach for training a model-based metric for text generation
evaluation. The key concept is to synthesize realistic model mistakes by
perturbing sentences retrieved from a corpus. The primary advantage of the
SESCORE2 is its ease of extension to many other languages while providing
reliable severity estimation. We evaluate SESCORE2 and previous methods on four
text generation tasks across three languages. SESCORE2 outperforms unsupervised
metric PRISM on four text generation evaluation benchmarks, with a Kendall
improvement of 0.078. Surprisingly, SESCORE2 even outperforms the supervised
BLEURT and COMET on multiple text generation tasks. The code and data are
available at https://github.com/xu1998hz/SEScore2.",https://github.com/xu1998hz/SEScore21,-1
4aa579b9-5ba3-457b-b0c7-57753fe6dbd7,Multiple View Performers for Shape Completion,0.0474292,"We propose the Multiple View Performer (MVP) - a new architecture for 3D
shape completion from a series of temporally sequential views. MVP accomplishes
this task by using linear-attention Transformers called Performers. Our model
allows the current observation of the scene to attend to the previous ones for
more accurate infilling. The history of past observations is compressed via the
compact associative memory approximating modern continuous Hopfield memory, but
crucially of size independent from the history length. We compare our model
with several baselines for shape completion over time, demonstrating the
generalization gains that MVP provides. To the best of our knowledge, MVP is
the first multiple view voxel reconstruction method that does not require
registration of multiple depth views and the first causal Transformer based
model for 3D shape completion.",None,-1
f1b8d700-4910-451e-ac12-d37d1cfed43c,AAM-Gym: Artificial Intelligence Testbed for Advanced Air Mobility,0.616116,"We introduce AAM-Gym, a research and development testbed for Advanced Air
Mobility (AAM). AAM has the potential to revolutionize travel by reducing
ground traffic and emissions by leveraging new types of aircraft such as
electric vertical take-off and landing (eVTOL) aircraft and new advanced
artificial intelligence (AI) algorithms. Validation of AI algorithms require
representative AAM scenarios, as well as a fast time simulation testbed to
evaluate their performance. Until now, there has been no such testbed available
for AAM to enable a common research platform for individuals in government,
industry, or academia. MIT Lincoln Laboratory has developed AAM-Gym to address
this gap by providing an ecosystem to develop, train, and validate new and
established AI algorithms across a wide variety of AAM use-cases. In this
paper, we use AAM-Gym to study the performance of two reinforcement learning
algorithms on an AAM use-case, separation assurance in AAM corridors. The
performance of the two algorithms is demonstrated based on a series of metrics
provided by AAM-Gym, showing the testbed's utility to AAM research.",None,-1
46e7ff4c-ded8-47d9-9423-8a6a3a5f46c4,Binaural Rendering of Ambisonic Signals by Neural Networks,0.0917893,"Binaural rendering of ambisonic signals is of broad interest to virtual
reality and immersive media. Conventional methods often require manually
measured Head-Related Transfer Functions (HRTFs). To address this issue, we
collect a paired ambisonic-binaural dataset and propose a deep learning
framework in an end-to-end manner. Experimental results show that neural
networks outperform the conventional method in objective metrics and achieve
comparable subjective metrics. To validate the proposed framework, we
experimentally explore different settings of the input features, model
structures, output features, and loss functions. Our proposed system achieves
an SDR of 7.32 and MOSs of 3.83, 3.58, 3.87, 3.58 in quality, timbre,
localization, and immersion dimensions.",None,-1
161d002b-68a2-48f8-a24c-746869efaf47,Matching Tweets With Applicable Fact-Checks Across Languages,0.362923,"An important challenge for news fact-checking is the effective dissemination
of existing fact-checks. This in turn brings the need for reliable methods to
detect previously fact-checked claims. In this paper, we focus on automatically
finding existing fact-checks for claims made in social media posts (tweets). We
conduct both classification and retrieval experiments, in monolingual (English
only), multilingual (Spanish, Portuguese), and cross-lingual (Hindi-English)
settings using multilingual transformer models such as XLM-RoBERTa and
multilingual embeddings such as LaBSE and SBERT. We present promising results
for ""match"" classification (86% average accuracy) in four language pairs. We
also find that a BM25 baseline outperforms or is on par with state-of-the-art
multilingual embedding models for the retrieval task during our monolingual
experiments. We highlight and discuss NLP challenges while addressing this
problem in different languages, and we introduce a novel curated dataset of
fact-checks and corresponding tweets for future research.",None,43162
24fb170d-07b7-4ad4-b215-f16f3b166939,Learning to generate line drawings that convey geometry and semantics,0.999814,"This paper presents an unpaired method for creating line drawings from
photographs. Current methods often rely on high quality paired datasets to
generate line drawings. However, these datasets often have limitations due to
the subjects of the drawings belonging to a specific domain, or in the amount
of data collected. Although recent work in unsupervised image-to-image
translation has shown much progress, the latest methods still struggle to
generate compelling line drawings. We observe that line drawings are encodings
of scene information and seek to convey 3D shape and semantic meaning. We build
these observations into a set of objectives and train an image translation to
map photographs into line drawings. We introduce a geometry loss which predicts
depth information from the image features of a line drawing, and a semantic
loss which matches the CLIP features of a line drawing with its corresponding
photograph. Our approach outperforms state-of-the-art unpaired image
translation and line drawing generation methods on creating line drawings from
arbitrary photographs. For code and demo visit our webpage
carolineec.github.io/informative_drawings",https://github.com/nerdyrodent/VQGAN-CLIP,-1
172a7406-3fdf-4e3b-8d8b-65f329bd472f,On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model,0.810268,"Many recent studies on large-scale language models have reported successful
in-context zero- and few-shot learning ability. However, the in-depth analysis
of when in-context learning occurs is still lacking. For example, it is unknown
how in-context learning performance changes as the training corpus varies.
Here, we investigate the effects of the source and size of the pretraining
corpus on in-context learning in HyperCLOVA, a Korean-centric GPT-3 model. From
our in-depth investigation, we introduce the following observations: (1)
in-context learning performance heavily depends on the corpus domain source,
and the size of the pretraining corpus does not necessarily determine the
emergence of in-context learning, (2) in-context learning ability can emerge
when a language model is trained on a combination of multiple corpora, even
when each corpus does not result in in-context learning on its own, (3)
pretraining with a corpus related to a downstream task does not always
guarantee the competitive in-context learning performance of the downstream
task, especially in the few-shot setting, and (4) the relationship between
language modeling (measured in perplexity) and in-context learning does not
always correlate: e.g., low perplexity does not always imply high in-context
few-shot learning performance.",None,150035
abebe689-a055-49fe-a298-9930f60ba44f,CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge Graph Completion,0.784557,"Knowledge graphs store a large number of factual triples while they are still
incomplete, inevitably. The previous knowledge graph completion (KGC) models
predict missing links between entities merely relying on fact-view data,
ignoring the valuable commonsense knowledge. The previous knowledge graph
embedding (KGE) techniques suffer from invalid negative sampling and the
uncertainty of fact-view link prediction, limiting KGC's performance. To
address the above challenges, we propose a novel and scalable Commonsense-Aware
Knowledge Embedding (CAKE) framework to automatically extract commonsense from
factual triples with entity concepts. The generated commonsense augments
effective self-supervision to facilitate both high-quality negative sampling
(NS) and joint commonsense and fact-view link prediction. Experimental results
on the KGC task demonstrate that assembling our framework could enhance the
performance of the original KGE models, and the proposed commonsense-aware NS
module is superior to other NS techniques. Besides, our proposed framework
could be easily adaptive to various KGE models and explain the predicted
results.",https://github.com/ngl567/CAKE,-1
126fe5e5-ec9f-44e0-aacb-889381273bac,Extractive Summarization of Legal Decisions using Multi-task Learning and Maximal Marginal Relevance,0.854222,"Summarizing legal decisions requires the expertise of law practitioners,
which is both time- and cost-intensive. This paper presents techniques for
extractive summarization of legal decisions in a low-resource setting using
limited expert annotated data. We test a set of models that locate relevant
content using a sequential model and tackle redundancy by leveraging maximal
marginal relevance to compose summaries. We also demonstrate an implicit
approach to help train our proposed models generate more informative summaries.
Our multi-task learning model variant leverages rhetorical role identification
as an auxiliary task to further improve the summarizer. We perform extensive
experiments on datasets containing legal decisions from the US Board of
Veterans' Appeals and conduct quantitative and expert-ranked evaluations of our
models. Our results show that the proposed approaches can achieve ROUGE scores
vis-\`a-vis expert extracted summaries that match those achieved by
inter-annotator comparison.",https://github.com/LLTLab/VetClaims-JSON,-1
59517874-9fe4-495c-9fe8-68ba35d4483c,CP-ViT: Cascade Vision Transformer Pruning via Progressive Sparsity Prediction,0.269478,"Vision transformer (ViT) has achieved competitive accuracy on a variety of
computer vision applications, but its computational cost impedes the deployment
on resource-limited mobile devices.
  We explore the sparsity in ViT and observe that informative patches and heads
are sufficient for accurate image recognition.
  In this paper, we propose a cascade pruning framework named CP-ViT by
predicting sparsity in ViT models progressively and dynamically to reduce
computational redundancy while minimizing the accuracy loss. Specifically, we
define the cumulative score to reserve the informative patches and heads across
the ViT model for better accuracy. We also propose the dynamic pruning ratio
adjustment technique based on layer-aware attention range. CP-ViT has great
general applicability for practical deployment, which can be applied to a wide
range of ViT models and can achieve superior accuracy with or without
fine-tuning.
  Extensive experiments on ImageNet, CIFAR-10, and CIFAR-100 with various
pre-trained models have demonstrated the effectiveness and efficiency of
CP-ViT. By progressively pruning 50\% patches, our CP-ViT method reduces over
40\% FLOPs while maintaining accuracy loss within 1\%.",None,-1
f810fe3a-d5ab-419f-a503-76c9dc7f9582,Self-supervised On-device Federated Learning from Unlabeled Streams,0.322267,"The ubiquity of edge devices has led to a growing amount of unlabeled data
produced at the edge. Deep learning models deployed on edge devices are
required to learn from these unlabeled data to continuously improve accuracy.
Self-supervised representation learning has achieved promising performances
using centralized unlabeled data. However, the increasing awareness of privacy
protection limits centralizing the distributed unlabeled image data on edge
devices. While federated learning has been widely adopted to enable distributed
machine learning with privacy preservation, without a data selection method to
efficiently select streaming data, the traditional federated learning framework
fails to handle these huge amounts of decentralized unlabeled data with limited
storage resources on edge. To address these challenges, we propose a
Self-supervised On-device Federated learning framework with coreset selection,
which we call SOFed, to automatically select a coreset that consists of the
most representative samples into the replay buffer on each device. It preserves
data privacy as each client does not share raw data while learning good visual
representations. Experiments demonstrate the effectiveness and significance of
the proposed method in visual representation learning.",None,-1
4b20e9fe-9962-4174-a838-bd3f17aa85b2,A Multi-turn Machine Reading Comprehension Framework with Rethink Mechanism for Emotion-Cause Pair Extraction,0.646688,"Emotion-cause pair extraction (ECPE) is an emerging task in emotion cause
analysis, which extracts potential emotion-cause pairs from an emotional
document. Most recent studies use end-to-end methods to tackle the ECPE task.
However, these methods either suffer from a label sparsity problem or fail to
model complicated relations between emotions and causes. Furthermore, they all
do not consider explicit semantic information of clauses. To this end, we
transform the ECPE task into a document-level machine reading comprehension
(MRC) task and propose a Multi-turn MRC framework with Rethink mechanism
(MM-R). Our framework can model complicated relations between emotions and
causes while avoiding generating the pairing matrix (the leading cause of the
label sparsity problem). Besides, the multi-turn structure can fuse explicit
semantic information flow between emotions and causes. Extensive experiments on
the benchmark emotion cause corpus demonstrate the effectiveness of our
proposed framework, which outperforms existing state-of-the-art methods.",https://github.com/zhoucz97/ECPE-MM-R,-1
947dc643-071e-4670-965e-ec74f28764fd,Understanding Stereotypes in Language Models: Towards Robust Measurement and Zero-Shot Debiasing,0.78174,"Generated texts from large pretrained language models have been shown to
exhibit a variety of harmful, human-like biases about various demographics.
These findings prompted large efforts aiming to understand and measure such
effects, with the goal of providing benchmarks that can guide the development
of techniques mitigating these stereotypical associations. However, as recent
research has pointed out, the current benchmarks lack a robust experimental
setup, consequently hindering the inference of meaningful conclusions from
their evaluation metrics. In this paper, we extend these arguments and
demonstrate that existing techniques and benchmarks aiming to measure
stereotypes tend to be inaccurate and consist of a high degree of experimental
noise that severely limits the knowledge we can gain from benchmarking language
models based on them. Accordingly, we propose a new framework for robustly
measuring and quantifying biases exhibited by generative language models.
Finally, we use this framework to investigate GPT-3's occupational gender bias
and propose prompting techniques for mitigating these biases without the need
for fine-tuning.",None,-1
3beffa19-61c5-4e35-ba68-8cb97026a57b,Continual Sequence Generation with Adaptive Compositional Modules,0.704817,"Continual learning is essential for real-world deployment when there is a
need to quickly adapt the model to new tasks without forgetting knowledge of
old tasks. Existing work on continual sequence generation either always reuses
existing parameters to learn new tasks, which is vulnerable to catastrophic
forgetting on dissimilar tasks, or blindly adds new parameters for every new
task, which could prevent knowledge sharing between similar tasks. To get the
best of both worlds, in this work, we propose continual sequence generation
with adaptive compositional modules to adaptively add modules in transformer
architectures and compose both old and new modules for new tasks. We also
incorporate pseudo experience replay to facilitate knowledge transfer in those
shared modules. Experiment results on various sequences of generation tasks
show that our framework can adaptively add modules or reuse modules based on
task similarity, outperforming state-of-the-art baselines in terms of both
performance and parameter efficiency. We make our code public at
https://github.com/GT-SALT/Adaptive-Compositional-Modules.",https://github.com/GT-SALT/Adaptive-Compositional-Modules,-1
e780fbdb-c72a-4bf1-a41d-590b488fd1c7,Solving Quantitative Reasoning Problems with Language Models,0.999958,"Language models have achieved remarkable performance on a wide range of tasks
that require natural language understanding. Nevertheless, state-of-the-art
models have generally struggled with tasks that require quantitative reasoning,
such as solving mathematics, science, and engineering problems at the college
level. To help close this gap, we introduce Minerva, a large language model
pretrained on general natural language data and further trained on technical
content. The model achieves state-of-the-art performance on technical
benchmarks without the use of external tools. We also evaluate our model on
over two hundred undergraduate-level problems in physics, biology, chemistry,
economics, and other sciences that require quantitative reasoning, and find
that the model can correctly answer nearly a third of them.",None,-1
5941a0de-54cf-4bda-a292-b344c2b93088,Improving word mover's distance by leveraging self-attention matrix,0.119452,"Measuring the semantic similarity between two sentences is still an important
task. The word mover's distance (WMD) computes the similarity via the optimal
alignment between the sets of word embeddings. However, WMD does not utilize
word order, making it challenging to distinguish sentences with significant
overlaps of similar words, even if they are semantically very different. Here,
we attempt to improve WMD by incorporating the sentence structure represented
by BERT's self-attention matrix (SAM). The proposed method is based on the
Fused Gromov-Wasserstein distance, which simultaneously considers the
similarity of the word embedding and the SAM for calculating the optimal
transport between two sentences. Experiments demonstrate the proposed method
enhances WMD and its variants in paraphrase identification with near-equivalent
performance in semantic textual similarity. Our code is available at
\url{https://github.com/ymgw55/WSMD}.",https://github.com/ymgw55/WSMD,-1
012f0bf5-9666-498d-b95c-10b0379ac8ea,Challenges and Opportunities of Edge AI for Next-Generation Implantable BMIs,0.570493,"Neuroscience and neurotechnology are currently being revolutionized by
artificial intelligence (AI) and machine learning. AI is widely used to study
and interpret neural signals (analytical applications), assist people with
disabilities (prosthetic applications), and treat underlying neurological
symptoms (therapeutic applications). In this brief, we will review the emerging
opportunities of on-chip AI for the next-generation implantable brain-machine
interfaces (BMIs), with a focus on state-of-the-art prosthetic BMIs. Major
technological challenges for the effectiveness of AI models will be discussed.
Finally, we will present algorithmic and IC design solutions to enable a new
generation of AI-enhanced and high-channel-count BMIs.",None,-1
c6c1bb6e-f6c1-4d15-98e2-a4b424ea6131,VarMAE: Pre-training of Variational Masked Autoencoder for Domain-adaptive Language Understanding,0.328646,"Pre-trained language models have achieved promising performance on general
benchmarks, but underperform when migrated to a specific domain. Recent works
perform pre-training from scratch or continual pre-training on domain corpora.
However, in many specific domains, the limited corpus can hardly support
obtaining precise representations. To address this issue, we propose a novel
Transformer-based language model named VarMAE for domain-adaptive language
understanding. Under the masked autoencoding objective, we design a context
uncertainty learning module to encode the token's context into a smooth latent
distribution. The module can produce diverse and well-formed contextual
representations. Experiments on science- and finance-domain NLU tasks
demonstrate that VarMAE can be efficiently adapted to new domains with limited
resources.",None,-1
2f5a297a-e46f-4b88-b60d-c1a5c2f941a3,Universal Domain Adaptive Object Detector,0.539209,"Universal domain adaptive object detection (UniDAOD)is more challenging than
domain adaptive object detection (DAOD) since the label space of the source
domain may not be the same as that of the target and the scale of objects in
the universal scenarios can vary dramatically (i.e, category shift and scale
shift). To this end, we propose US-DAF, namely Universal Scale-Aware Domain
Adaptive Faster RCNN with Multi-Label Learning, to reduce the negative transfer
effect during training while maximizing transferability as well as
discriminability in both domains under a variety of scales. Specifically, our
method is implemented by two modules: 1) We facilitate the feature alignment of
common classes and suppress the interference of private classes by designing a
Filter Mechanism module to overcome the negative transfer caused by category
shift. 2) We fill the blank of scale-aware adaptation in object detection by
introducing a new Multi-Label Scale-Aware Adapter to perform individual
alignment between the corresponding scale for two domains. Experiments show
that US-DAF achieves state-of-the-art results on three scenarios (i.e,
Open-Set, Partial-Set, and Closed-Set) and yields 7.1% and 5.9% relative
improvement on benchmark datasets Clipart1k and Watercolor in particular.",None,-1
ed8dccbc-37a7-45f4-904e-56fefccfa8fc,Domain Generalization Strategy to Train Classifiers Robust to Spatial-Temporal Shift,0.637755,"Deep learning-based weather prediction models have advanced significantly in
recent years. However, data-driven models based on deep learning are difficult
to apply to real-world applications because they are vulnerable to
spatial-temporal shifts. A weather prediction task is especially susceptible to
spatial-temporal shifts when the model is overfitted to locality and
seasonality. In this paper, we propose a training strategy to make the weather
prediction model robust to spatial-temporal shifts. We first analyze the effect
of hyperparameters and augmentations of the existing training strategy on the
spatial-temporal shift robustness of the model. Next, we propose an optimal
combination of hyperparameters and augmentation based on the analysis results
and a test-time augmentation. We performed all experiments on the W4C22
Transfer dataset and achieved the 1st performance.",https://github.com/seominseok0429/W4C22-Simple-Baseline-for-Weather-Forecasting-Using-Spatiotemporal-Context-Aggregation-Network,-1
ce9fc796-c984-463d-9a91-ec358d18e25c,MMFN: Multi-Modal-Fusion-Net for End-to-End Driving,0.708153,"Inspired by the fact that humans use diverse sensory organs to perceive the
world, sensors with different modalities are deployed in end-to-end driving to
obtain the global context of the 3D scene. In previous works, camera and LiDAR
inputs are fused through transformers for better driving performance. These
inputs are normally further interpreted as high-level map information to assist
navigation tasks. Nevertheless, extracting useful information from the complex
map input is challenging, for redundant information may mislead the agent and
negatively affect driving performance. We propose a novel approach to
efficiently extract features from vectorized High-Definition (HD) maps and
utilize them in the end-to-end driving tasks. In addition, we design a new
expert to further enhance the model performance by considering multi-road
rules. Experimental results prove that both of the proposed improvements enable
our agent to achieve superior performance compared with other methods.",https://github.com/Kin-Zhang/mmfn,-1
1548612b-fff8-4d85-aa5c-027fb6415b4d,SimSR: Simple Distance-based State Representation for Deep Reinforcement Learning,0.120017,"This work explores how to learn robust and generalizable state representation
from image-based observations with deep reinforcement learning methods.
Addressing the computational complexity, stringent assumptions and
representation collapse challenges in existing work of bisimulation metric, we
devise Simple State Representation (SimSR) operator. SimSR enables us to design
a stochastic approximation method that can practically learn the mapping
functions (encoders) from observations to latent representation space. In
addition to the theoretical analysis and comparison with the existing work, we
experimented and compared our work with recent state-of-the-art solutions in
visual MuJoCo tasks. The results shows that our model generally achieves better
performance and has better robustness and good generalization.",https://github.com/bit1029public/SimSR,9769
9826c48f-2b75-4f80-8b55-188fccb2a44c,Efficient Adapter Transfer of Self-Supervised Speech Models for Automatic Speech Recognition,0.537487,"Self-supervised learning (SSL) is a powerful tool that allows learning of
underlying representations from unlabeled data. Transformer based models such
as wav2vec 2.0 and HuBERT are leading the field in the speech domain. Generally
these models are fine-tuned on a small amount of labeled data for a downstream
task such as Automatic Speech Recognition (ASR). This involves re-training the
majority of the model for each task. Adapters are small lightweight modules
which are commonly used in Natural Language Processing (NLP) to adapt
pre-trained models to new tasks. In this paper we propose applying adapters to
wav2vec 2.0 to reduce the number of parameters required for downstream ASR
tasks, and increase scalability of the model to multiple tasks or languages.
Using adapters we can perform ASR while training fewer than 10% of parameters
per task compared to full fine-tuning with little degradation of performance.
Ablations show that applying adapters into just the top few layers of the
pre-trained network gives similar performance to full transfer, supporting the
theory that higher pre-trained layers encode more phonemic information, and
further optimizing efficiency.",None,-1
e686c0bf-398e-4b70-9731-f9182c1c3304,Improving Robustness to Out-of-Distribution Data by Frequency-based Augmentation,0.314281,"Although Convolutional Neural Networks (CNNs) have high accuracy in image
recognition, they are vulnerable to adversarial examples and
out-of-distribution data, and the difference from human recognition has been
pointed out. In order to improve the robustness against out-of-distribution
data, we present a frequency-based data augmentation technique that replaces
the frequency components with other images of the same class. When the training
data are CIFAR10 and the out-of-distribution data are SVHN, the Area Under
Receiver Operating Characteristic (AUROC) curve of the model trained with the
proposed method increases from 89.22\% to 98.15\%, and further increased to
98.59\% when combined with another data augmentation method. Furthermore, we
experimentally demonstrate that the robust model for out-of-distribution data
uses a lot of high-frequency components of the image.",None,-1
a0bb662c-7aae-4797-a093-80cfd91e5604,System Network Analytics: Evolution and Stable Rules of a State Series,0.322269,"System Evolution Analytics on a system that evolves is a challenge because it
makes a State Series SS = {S1, S2... SN} (i.e., a set of states ordered by
time) with several inter-connected entities changing over time. We present
stability characteristics of interesting evolution rules occurring in multiple
states. We defined an evolution rule with its stability as the fraction of
states in which the rule is interesting. Extensively, we defined stable rule as
the evolution rule having stability that exceeds a given threshold minimum
stability (minStab). We also defined persistence metric, a quantitative measure
of persistent entity-connections. We explain this with an approach and
algorithm for System Network Analytics (SysNet-Analytics), which uses minStab
to retrieve Network Evolution Rules (NERs) and Stable NERs (SNERs). The
retrieved information is used to calculate a proposed System Network
Persistence (SNP) metric. This work is automated as a SysNet-Analytics Tool to
demonstrate application on real world systems including: software system,
natural-language system, retail market system, and IMDb system. We quantified
stability and persistence of entity-connections in a system state series. This
results in evolution information, which helps in system evolution analytics
based on knowledge discovery and data mining.",None,-1
a78f766e-c9a3-478c-a144-712635198936,Relational Attention: Generalizing Transformers for Graph-Structured Tasks,0.412379,"Transformers flexibly operate over sets of real-valued vectors representing
task-specific entities and their attributes, where each vector might encode one
word-piece token and its position in a sequence, or some piece of information
that carries no position at all. But as set processors, transformers are at a
disadvantage in reasoning over more general graph-structured data where nodes
represent entities and edges represent relations between entities. To address
this shortcoming, we generalize transformer attention to consider and update
edge vectors in each transformer layer. We evaluate this relational transformer
on a diverse array of graph-structured tasks, including the large and
challenging CLRS Algorithmic Reasoning Benchmark. There, it dramatically
outperforms state-of-the-art graph neural networks expressly designed to reason
over graph-structured data. Our analysis demonstrates that these gains are
attributable to relational attention's inherent ability to leverage the greater
expressivity of graphs over sets.",None,-1
aea68549-0aab-420b-a137-d294253adc64,Patterns of near-crash events in a naturalistic driving dataset: applying rules mining,0.741204,"This study aims to explore the associations between near-crash events and
road geometry and trip features by investigating a naturalistic driving dataset
and a corresponding roadway inventory dataset using an association rule mining
method.",None,-1
410ce9cf-9cd9-49b5-8b49-baf764f56707,Better plain ViT baselines for ImageNet-1k,0.668979,"It is commonly accepted that the Vision Transformer model requires
sophisticated regularization techniques to excel at ImageNet-1k scale data.
Surprisingly, we find this is not the case and standard data augmentation is
sufficient. This note presents a few minor modifications to the original Vision
Transformer (ViT) vanilla training setting that dramatically improve the
performance of plain ViT models. Notably, 90 epochs of training surpass 76%
top-1 accuracy in under seven hours on a TPUv3-8, similar to the classic
ResNet50 baseline, and 300 epochs of training reach 80% in less than one day.",https://github.com/google-research/big_vision,-1
76da2cdc-027e-49ce-b344-eb065c0c48ef,MISeval: a Metric Library for Medical Image Segmentation Evaluation,0.474804,"Correct performance assessment is crucial for evaluating modern artificial
intelligence algorithms in medicine like deep-learning based medical image
segmentation models. However, there is no universal metric library in Python
for standardized and reproducible evaluation. Thus, we propose our open-source
publicly available Python package MISeval: a metric library for Medical Image
Segmentation Evaluation. The implemented metrics can be intuitively used and
easily integrated into any performance assessment pipeline. The package
utilizes modern CI/CD strategies to ensure functionality and stability. MISeval
is available from PyPI (miseval) and GitHub:
https://github.com/frankkramer-lab/miseval.",https://github.com/frankkramer-lab/miseval,-1
4f159121-9867-4c1a-b873-046e2a47705d,Internal Language Model Estimation based Adaptive Language Model Fusion for Domain Adaptation,0.131359,"ASR model deployment environment is ever-changing, and the incoming speech
can be switched across different domains during a session. This brings a
challenge for effective domain adaptation when only target domain text data is
available, and our objective is to obtain obviously improved performance on the
target domain while the performance on the general domain is less undermined.
In this paper, we propose an adaptive LM fusion approach called internal
language model estimation based adaptive domain adaptation (ILME-ADA). To
realize such an ILME-ADA, an interpolated log-likelihood score is calculated
based on the maximum of the scores from the internal LM and the external LM
(ELM) respectively. We demonstrate the efficacy of the proposed ILME-ADA method
with both RNN-T and LAS modeling frameworks employing neural network and n-gram
LMs as ELMs respectively on two domain specific (target) test sets. The
proposed method can achieve significantly better performance on the target test
sets while it gets minimal performance degradation on the general test set,
compared with both shallow and ILME-based LM fusion methods.",None,-1
f398e952-23c2-43aa-90d4-4f02b9e88c3d,Learning Disentangled Textual Representations via Statistical Measures of Similarity,0.67503,"When working with textual data, a natural application of disentangled
representations is fair classification where the goal is to make predictions
without being biased (or influenced) by sensitive attributes that may be
present in the data (e.g., age, gender or race). Dominant approaches to
disentangle a sensitive attribute from textual representations rely on learning
simultaneously a penalization term that involves either an adversarial loss
(e.g., a discriminator) or an information measure (e.g., mutual information).
However, these methods require the training of a deep neural network with
several parameter updates for each update of the representation model. As a
matter of fact, the resulting nested optimization loop is both time consuming,
adding complexity to the optimization dynamic, and requires a fine
hyperparameter selection (e.g., learning rates, architecture). In this work, we
introduce a family of regularizers for learning disentangled representations
that do not require training. These regularizers are based on statistical
measures of similarity between the conditional probability distributions with
respect to the sensitive attributes. Our novel regularizers do not require
additional training, are faster and do not involve additional tuning while
achieving better results both when combined with pretrained and randomly
initialized text encoders.",https://github.com/PierreColombo/TORNADO,-1
8b3be452-cf46-41ee-a851-82f8a44438bb,Global Convergence Analysis of Deep Linear Networks with A One-neuron Layer,0.0564881,"In this paper, we follow Eftekhari's work to give a non-local convergence
analysis of deep linear networks. Specifically, we consider optimizing deep
linear networks which have a layer with one neuron under quadratic loss. We
describe the convergent point of trajectories with arbitrary starting point
under gradient flow, including the paths which converge to one of the saddle
points or the original point. We also show specific convergence rates of
trajectories that converge to the global minimizer by stages. To achieve these
results, this paper mainly extends the machinery in Eftekhari's work to
provably identify the rank-stable set and the global minimizer convergent set.
We also give specific examples to show the necessity of our definitions.
Crucially, as far as we know, our results appear to be the first to give a
non-local global analysis of linear neural networks from arbitrary initialized
points, rather than the lazy training regime which has dominated the literature
of neural networks, and restricted benign initialization in Eftekhari's work.
We also note that extending our results to general linear networks without one
hidden neuron assumption remains a challenging open problem.",None,-1
abb66d9b-4952-487d-a01b-36c1f5528140,Relational Message Passing for Fully Inductive Knowledge Graph Completion,0.93954,"In knowledge graph completion (KGC), predicting triples involving emerging
entities and/or relations, which are unseen when the KG embeddings are learned,
has become a critical challenge. Subgraph reasoning with message passing is a
promising and popular solution. Some recent methods have achieved good
performance, but they (i) usually can only predict triples involving unseen
entities alone, failing to address more realistic fully inductive situations
with both unseen entities and unseen relations, and (ii) often conduct message
passing over the entities with the relation patterns not fully utilized. In
this study, we propose a new method named RMPI which uses a novel Relational
Message Passing network for fully Inductive KGC. It passes messages directly
between relations to make full use of the relation patterns for subgraph
reasoning with new techniques on graph transformation, graph pruning,
relation-aware neighborhood attention, addressing empty subgraphs, etc., and
can utilize the relation semantics defined in the ontological schema of KG.
Extensive evaluation on multiple benchmarks has shown the effectiveness of
techniques involved in RMPI and its better performance compared with the
existing methods that support fully inductive KGC. RMPI is also comparable to
the state-of-the-art partially inductive KGC methods with very promising
results achieved. Our codes and data are available at
https://github.com/zjukg/RMPI.",https://github.com/zjukg/RMPI,-1
e1cb0862-3c7b-4e0d-98f2-e327e134b1be,GreenKGC: A Lightweight Knowledge Graph Completion Method,0.529388,"Knowledge graph completion (KGC) aims to discover missing relationships
between entities in knowledge graphs (KGs). Most prior KGC work focuses on
learning embeddings for entities and relations through a simple scoring
function. Yet, a higher-dimensional embedding space is usually required for a
better reasoning capability, which leads to a larger model size and hinders
applicability to real-world problems (e.g., large-scale KGs or mobile/edge
computing). A lightweight modularized KGC solution, called GreenKGC, is
proposed in this work to address this issue. GreenKGC consists of three
modules: representation learning, feature pruning, and decision learning, to
extract discriminant KG features and make accurate predictions on missing
relationships using classifiers and negative sampling. Experimental results
demonstrate that, in low dimensions, GreenKGC can outperform SOTA methods in
most datasets. In addition, low-dimensional GreenKGC can achieve competitive or
even better performance against high-dimensional models with a much smaller
model size.",https://github.com/yunchengwang/GreenKGC,-1
46f066a7-d068-4038-b92a-51d8efce0a8d,Collaborating Domain-shared and Target-specific Feature Clustering for Cross-domain 3D Action Recognition,0.550491,"In this work, we consider the problem of cross-domain 3D action recognition
in the open-set setting, which has been rarely explored before. Specifically,
there is a source domain and a target domain that contain the skeleton
sequences with different styles and categories, and our purpose is to cluster
the target data by utilizing the labeled source data and unlabeled target data.
For such a challenging task, this paper presents a novel approach dubbed CoDT
to collaboratively cluster the domain-shared features and target-specific
features. CoDT consists of two parallel branches. One branch aims to learn
domain-shared features with supervised learning in the source domain, while the
other is to learn target-specific features using contrastive learning in the
target domain. To cluster the features, we propose an online clustering
algorithm that enables simultaneous promotion of robust pseudo label generation
and feature clustering. Furthermore, to leverage the complementarity of
domain-shared features and target-specific features, we propose a novel
collaborative clustering strategy to enforce pair-wise relationship consistency
between the two branches. We conduct extensive experiments on multiple
cross-domain 3D action recognition datasets, and the results demonstrate the
effectiveness of our method.",None,-1
985509d4-2532-4ba5-a568-5c248446f13a,AutoDistil: Few-shot Task-agnostic Neural Architecture Search for Distilling Large Language Models,0.229715,"Knowledge distillation (KD) methods compress large models into smaller
students with manually-designed student architectures given pre-specified
computational cost. This requires several trials to find a viable student, and
further repeating the process for each student or computational budget change.
We use Neural Architecture Search (NAS) to automatically distill several
compressed students with variable cost from a large model. Current works train
a single SuperLM consisting of millions of subnetworks with weight-sharing,
resulting in interference between subnetworks of different sizes. Our framework
AutoDistil addresses above challenges with the following steps: (a)
Incorporates inductive bias and heuristics to partition Transformer search
space into K compact sub-spaces (K=3 for typical student sizes of base, small
and tiny); (b) Trains one SuperLM for each sub-space using task-agnostic
objective (e.g., self-attention distillation) with weight-sharing of students;
(c) Lightweight search for the optimal student without re-training. Fully
task-agnostic training and search allow students to be reused for fine-tuning
on any downstream task. Experiments on GLUE benchmark against state-of-the-art
KD and NAS methods demonstrate AutoDistil to outperform leading compression
techniques with upto 2.7x reduction in computational cost and negligible loss
in task performance.",None,-1
011ab30b-d59d-4eac-b8fe-117d127a4fe8,Data augmentation for efficient learning from parametric experts,0.0731654,"We present a simple, yet powerful data-augmentation technique to enable
data-efficient learning from parametric experts for reinforcement and imitation
learning. We focus on what we call the policy cloning setting, in which we use
online or offline queries of an expert or expert policy to inform the behavior
of a student policy. This setting arises naturally in a number of problems, for
instance as variants of behavior cloning, or as a component of other algorithms
such as DAGGER, policy distillation or KL-regularized RL. Our approach,
augmented policy cloning (APC), uses synthetic states to induce
feedback-sensitivity in a region around sampled trajectories, thus dramatically
reducing the environment interactions required for successful cloning of the
expert. We achieve highly data-efficient transfer of behavior from an expert to
a student policy for high-degrees-of-freedom control problems. We demonstrate
the benefit of our method in the context of several existing and widely used
algorithms that include policy cloning as a constituent part. Moreover, we
highlight the benefits of our approach in two practically relevant settings (a)
expert compression, i.e. transfer to a student with fewer parameters; and (b)
transfer from privileged experts, i.e. where the expert has a different
observation space than the student, usually including access to privileged
information.",None,49708
cd7b4bc7-8ab5-4f64-9255-22c09e18ed7a,Retrieval-based Disentangled Representation Learning with Natural Language Supervision,0.0695313,"Disentangled representation learning remains challenging as the underlying
factors of variation in the data do not naturally exist. The inherent
complexity of real-world data makes it unfeasible to exhaustively enumerate and
encapsulate all its variations within a finite set of factors. However, it is
worth noting that most real-world data have linguistic equivalents, typically
in the form of textual descriptions. These linguistic counterparts can
represent the data and effortlessly decomposed into distinct tokens. In light
of this, we present Vocabulary Disentangled Retrieval (VDR), a retrieval-based
framework that harnesses natural language as proxies of the underlying data
variation to drive disentangled representation learning. Our approach employ a
bi-encoder model to represent both data and natural language in a vocabulary
space, enabling the model to distinguish dimensions that capture intrinsic
characteristics within data through its natural language counterpart, thus
facilitating disentanglement. We extensively assess the performance of VDR
across 15 retrieval benchmark datasets, covering text-to-text and cross-modal
retrieval scenarios, as well as human evaluation. Our experimental results
compellingly demonstrate the superiority of VDR over previous bi-encoder
retrievers with comparable model size and training costs, achieving an
impressive 8.7% improvement in NDCG@10 on the BEIR benchmark, a 5.3% increase
on MS COCO, and a 6.0% increase on Flickr30k in terms of mean recall in the
zero-shot setting. Moreover, The results from human evaluation indicate that
interpretability of our method is on par with SOTA captioning models.",None,-1
abef5d5d-9f00-4569-a289-f38c90ebd205,WeakM3D: Towards Weakly Supervised Monocular 3D Object Detection,0.451848,"Monocular 3D object detection is one of the most challenging tasks in 3D
scene understanding. Due to the ill-posed nature of monocular imagery, existing
monocular 3D detection methods highly rely on training with the manually
annotated 3D box labels on the LiDAR point clouds. This annotation process is
very laborious and expensive. To dispense with the reliance on 3D box labels,
in this paper we explore the weakly supervised monocular 3D detection.
Specifically, we first detect 2D boxes on the image. Then, we adopt the
generated 2D boxes to select corresponding RoI LiDAR points as the weak
supervision. Eventually, we adopt a network to predict 3D boxes which can
tightly align with associated RoI LiDAR points. This network is learned by
minimizing our newly-proposed 3D alignment loss between the 3D box estimates
and the corresponding RoI LiDAR points. We will illustrate the potential
challenges of the above learning problem and resolve these challenges by
introducing several effective designs into our method. Codes will be available
at https://github.com/SPengLiang/WeakM3D.",https://github.com/SPengLiang/WeakM3D,-1
0bafd4b3-d7ed-4637-ac67-8908a8a0ffe6,Effective Transfer Learning for Low-Resource Natural Language Understanding,0.0270159,"Natural language understanding (NLU) is the task of semantic decoding of
human languages by machines. NLU models rely heavily on large training data to
ensure good performance. However, substantial languages and domains have very
few data resources and domain experts. It is necessary to overcome the data
scarcity challenge, when very few or even zero training samples are available.
In this thesis, we focus on developing cross-lingual and cross-domain methods
to tackle the low-resource issues. First, we propose to improve the model's
cross-lingual ability by focusing on the task-related keywords, enhancing the
model's robustness and regularizing the representations. We find that the
representations for low-resource languages can be easily and greatly improved
by focusing on just the keywords. Second, we present Order-Reduced Modeling
methods for the cross-lingual adaptation, and find that modeling partial word
orders instead of the whole sequence can improve the robustness of the model
against word order differences between languages and task knowledge transfer to
low-resource languages. Third, we propose to leverage different levels of
domain-related corpora and additional masking of data in the pre-training for
the cross-domain adaptation, and discover that more challenging pre-training
can better address the domain discrepancy issue in the task knowledge transfer.
Finally, we introduce a coarse-to-fine framework, Coach, and a cross-lingual
and cross-domain parsing framework, X2Parser. Coach decomposes the
representation learning process into a coarse-grained and a fine-grained
feature learning, and X2Parser simplifies the hierarchical task structures into
flattened ones. We observe that simplifying task structures makes the
representation learning more effective for low-resource languages and domains.",None,-1
99ca7e88-14dd-41d6-802b-727c0ff3b69d,Extracting Effective Subnetworks with Gumbel-Softmax,0.104179,"Large and performant neural networks are often overparameterized and can be
drastically reduced in size and complexity thanks to pruning. Pruning is a
group of methods, which seeks to remove redundant or unnecessary weights or
groups of weights in a network. These techniques allow the creation of
lightweight networks, which are particularly critical in embedded or mobile
applications. In this paper, we devise an alternative pruning method that
allows extracting effective subnetworks from larger untrained ones. Our method
is stochastic and extracts subnetworks by exploring different topologies which
are sampled using Gumbel Softmax. The latter is also used to train probability
distributions which measure the relevance of weights in the sampled topologies.
The resulting subnetworks are further enhanced using a highly efficient
rescaling mechanism that reduces training time and improves performance.
Extensive experiments conducted on CIFAR show the outperformance of our
subnetwork extraction method against the related work.",https://github.com/N0ciple/ASLP,-1
6acbe4a0-6ded-4a91-abdb-dc86f4f96bc9,CL2R: Compatible Lifelong Learning Representations,0.0744011,"In this paper, we propose a method to partially mimic natural intelligence
for the problem of lifelong learning representations that are compatible. We
take the perspective of a learning agent that is interested in recognizing
object instances in an open dynamic universe in a way in which any update to
its internal feature representation does not render the features in the gallery
unusable for visual search. We refer to this learning problem as Compatible
Lifelong Learning Representations (CL2R) as it considers compatible
representation learning within the lifelong learning paradigm. We identify
stationarity as the property that the feature representation is required to
hold to achieve compatibility and propose a novel training procedure that
encourages local and global stationarity on the learned representation. Due to
stationarity, the statistical properties of the learned features do not change
over time, making them interoperable with previously learned features.
Extensive experiments on standard benchmark datasets show that our CL2R
training procedure outperforms alternative baselines and state-of-the-art
methods. We also provide novel metrics to specifically evaluate compatible
representation learning under catastrophic forgetting in various sequential
learning tasks. Code at
https://github.com/NiccoBiondi/CompatibleLifelongRepresentation.",https://github.com/NiccoBiondi/CompatibleLifelongRepresentation,-1
0ee3aa76-c5fe-4899-9231-fe5313a20df2,Grounding Answers for Visual Questions Asked by Visually Impaired People,0.503319,"Visual question answering is the task of answering questions about images. We
introduce the VizWiz-VQA-Grounding dataset, the first dataset that visually
grounds answers to visual questions asked by people with visual impairments. We
analyze our dataset and compare it with five VQA-Grounding datasets to
demonstrate what makes it similar and different. We then evaluate the SOTA VQA
and VQA-Grounding models and demonstrate that current SOTA algorithms often
fail to identify the correct visual evidence where the answer is located. These
models regularly struggle when the visual evidence occupies a small fraction of
the image, for images that are higher quality, as well as for visual questions
that require skills in text recognition. The dataset, evaluation server, and
leaderboard all can be found at the following link:
https://vizwiz.org/tasks-and-datasets/answer-grounding-for-vqa/.",https://github.com/CCYChongyanChen/VizWizVQAGroundingCrowdSourcing,-1
ae563b12-3274-42a7-94d8-9421fe100533,GUDN: A novel guide network with label reinforcement strategy for extreme multi-label text classification,0.0945215,"In natural language processing, extreme multi-label text classification is an
emerging but essential task. The problem of extreme multi-label text
classification (XMTC) is to recall some of the most relevant labels for a text
from an extremely large label set. Large-scale pre-trained models have brought
a new trend to this problem. Though the large-scale pre-trained models have
made significant achievements on this problem, the valuable fine-tuned methods
have yet to be studied. Though label semantics have been introduced in XMTC,
the vast semantic gap between texts and labels has yet to gain enough
attention. This paper builds a new guide network (GUDN) to help fine-tune the
pre-trained model to instruct classification later. Furthermore, GUDN uses raw
label semantics combined with a helpful label reinforcement strategy to
effectively explore the latent space between texts and labels, narrowing the
semantic gap, which can further improve predicted accuracy. Experimental
results demonstrate that GUDN outperforms state-of-the-art methods on Eurlex-4k
and has competitive results on other popular datasets. In an additional
experiment, we investigated the input lengths' influence on the
Transformer-based model's accuracy. Our source code is released at
https://t.hk.uy/aFSH.",https://t.hk.uy/aFSH,-1
a7a95b1b-c95e-406c-a7f5-b2a55f9aab90,Evaluating MT Systems: A Theoretical Framework,0.0743525,"This paper outlines a theoretical framework using which different automatic
metrics can be designed for evaluation of Machine Translation systems. It
introduces the concept of {\em cognitive ease} which depends on {\em adequacy}
and {\em lack of fluency}. Thus, cognitive ease becomes the main parameter to
be measured rather than comprehensibility. The framework allows the components
of cognitive ease to be broken up and computed based on different linguistic
levels etc. Independence of dimensions and linearly combining them provides for
a highly modular approach.
  The paper places the existing automatic methods in an overall framework, to
understand them better and to improve upon them in future. It can also be used
to evaluate the newer types of MT systems, such as speech to speech translation
and discourse translation.",None,-1
0ef57b64-2f95-4311-93a5-df553d560f23,CasNet: Investigating Channel Robustness for Speech Separation,0.166911,"Recording channel mismatch between training and testing conditions has been
shown to be a serious problem for speech separation. This situation greatly
reduces the separation performance, and cannot meet the requirement of daily
use. In this study, inheriting the use of our previously constructed TAT-2mix
corpus, we address the channel mismatch problem by proposing a channel-aware
audio separation network (CasNet), a deep learning framework for end-to-end
time-domain speech separation. CasNet is implemented on top of TasNet. Channel
embedding (characterizing channel information in a mixture of multiple
utterances) generated by Channel Encoder is introduced into the separation
module by the FiLM technique. Through two training strategies, we explore two
roles that channel embedding may play: 1) a real-life noise disturbance, making
the model more robust, or 2) a guide, instructing the separation model to
retain the desired channel information. Experimental results on TAT-2mix show
that CasNet trained with both training strategies outperforms the TasNet
baseline, which does not use channel embeddings.",https://github.com/Sinica-SLAM/CasNet,8197
c2c5b205-bcd2-4bb3-8383-3117d746764c,From Explanations to Segmentation: Using Explainable AI for Image Segmentation,0.141413,"The new era of image segmentation leveraging the power of Deep Neural Nets
(DNNs) comes with a price tag: to train a neural network for pixel-wise
segmentation, a large amount of training samples has to be manually labeled on
pixel-precision. In this work, we address this by following an indirect
solution. We build upon the advances of the Explainable AI (XAI) community and
extract a pixel-wise binary segmentation from the output of the Layer-wise
Relevance Propagation (LRP) explaining the decision of a classification
network. We show that we achieve similar results compared to an established
U-Net segmentation architecture, while the generation of the training data is
significantly simplified. The proposed method can be trained in a weakly
supervised fashion, as the training samples must be only labeled on
image-level, at the same time enabling the output of a segmentation mask. This
makes it especially applicable to a wider range of real applications where
tedious pixel-level labelling is often not possible.",None,-1
10b38a65-7fe9-4d93-a358-a67d88b58f8d,Fine-grained Contrastive Learning for Relation Extraction,0.377591,"Recent relation extraction (RE) works have shown encouraging improvements by
conducting contrastive learning on silver labels generated by distant
supervision before fine-tuning on gold labels. Existing methods typically
assume all these silver labels are accurate and treat them equally; however,
distant supervision is inevitably noisy -- some silver labels are more reliable
than others. In this paper, we propose fine-grained contrastive learning
(FineCL) for RE, which leverages fine-grained information about which silver
labels are and are not noisy to improve the quality of learned relationship
representations for RE. We first assess the quality of silver labels via a
simple and automatic approach we call ""learning order denoising,"" where we
train a language model to learn these relations and record the order of learned
training instances. We show that learning order largely corresponds to label
accuracy -- early-learned silver labels have, on average, more accurate labels
than later-learned silver labels. Then, during pre-training, we increase the
weights of accurate labels within a novel contrastive learning objective.
Experiments on several RE benchmarks show that FineCL makes consistent and
significant performance gains over state-of-the-art methods.",https://github.com/wphogan/finecl,4518
3be19415-b8cd-4c99-b1de-6ae46a12eb3b,An Active Contour Model with Local Variance Force Term and Its Efficient Minimization Solver for Multi-phase Image Segmentation,0.0480144,"In this paper, we propose an active contour model with a local variance force
(LVF) term that can be applied to multi-phase image segmentation problems. With
the LVF, the proposed model is very effective in the segmentation of images
with noise. To solve this model efficiently, we represent the regularization
term by characteristic functions and then design a minimization algorithm based
on a modification of the iterative convolution-thresholding method (ICTM),
namely ICTM-LVF. This minimization algorithm enjoys the energy-decaying
property under some conditions and has highly efficient performance in the
segmentation. To overcome the initialization issue of active contour models, we
generalize the inhomogeneous graph Laplacian initialization method (IGLIM) to
the multi-phase case and then apply it to give the initial contour of the
ICTM-LVF solver. Numerical experiments are conducted on synthetic images and
real images to demonstrate the capability of our initialization method, and the
effectiveness of the local variance force for noise robustness in the
multi-phase image segmentation.",None,3116
6e789a10-8001-4b84-9083-a3fb628f0b53,Streamable Neural Fields,0.367445,"Neural fields have emerged as a new data representation paradigm and have
shown remarkable success in various signal representations. Since they preserve
signals in their network parameters, the data transfer by sending and receiving
the entire model parameters prevents this emerging technology from being used
in many practical scenarios. We propose streamable neural fields, a single
model that consists of executable sub-networks of various widths. The proposed
architectural and training techniques enable a single network to be streamable
over time and reconstruct different qualities and parts of signals. For
example, a smaller sub-network produces smooth and low-frequency signals, while
a larger sub-network can represent fine details. Experimental results have
shown the effectiveness of our method in various domains, such as 2D images,
videos, and 3D signed distance functions. Finally, we demonstrate that our
proposed method improves training stability, by exploiting parameter sharing.",https://github.com/jwcho5576/streamable_nf,-1
fc15111a-d762-46d8-a36e-48bbcf117e6a,Context Sensing Attention Network for Video-based Person Re-identification,0.31867,"Video-based person re-identification (ReID) is challenging due to the
presence of various interferences in video frames. Recent approaches handle
this problem using temporal aggregation strategies. In this work, we propose a
novel Context Sensing Attention Network (CSA-Net), which improves both the
frame feature extraction and temporal aggregation steps. First, we introduce
the Context Sensing Channel Attention (CSCA) module, which emphasizes responses
from informative channels for each frame. These informative channels are
identified with reference not only to each individual frame, but also to the
content of the entire sequence. Therefore, CSCA explores both the individuality
of each frame and the global context of the sequence. Second, we propose the
Contrastive Feature Aggregation (CFA) module, which predicts frame weights for
temporal aggregation. Here, the weight for each frame is determined in a
contrastive manner: i.e., not only by the quality of each individual frame, but
also by the average quality of the other frames in a sequence. Therefore, it
effectively promotes the contribution of relatively good frames. Extensive
experimental results on four datasets show that CSA-Net consistently achieves
state-of-the-art performance.",None,-1
17e229c5-a25f-4552-8baf-9c42f9539ed1,Feature transforms for image data augmentation,0.414006,"A problem with Convolutional Neural Networks (CNNs) is that they require
large datasets to obtain adequate robustness; on small datasets, they are prone
to overfitting. Many methods have been proposed to overcome this shortcoming
with CNNs. In cases where additional samples cannot easily be collected, a
common approach is to generate more data points from existing data using an
augmentation technique. In image classification, many augmentation approaches
utilize simple image manipulation algorithms. In this work, we build ensembles
on the data level by adding images generated by combining fourteen augmentation
approaches, three of which are proposed here for the first time. These novel
methods are based on the Fourier Transform (FT), the Radon Transform (RT) and
the Discrete Cosine Transform (DCT). Pretrained ResNet50 networks are finetuned
on training sets that include images derived from each augmentation method.
These networks and several fusions are evaluated and compared across eleven
benchmarks. Results show that building ensembles on the data level by combining
different data augmentation methods produce classifiers that not only compete
competitively against the state-of-the-art but often surpass the best
approaches reported in the literature.",None,-1
05ca3619-1b7a-445e-be50-6fa64ba2a698,"SF-PATE: Scalable, Fair, and Private Aggregation of Teacher Ensembles",0.323759,"A critical concern in data-driven processes is to build models whose outcomes
do not discriminate against some demographic groups, including gender,
ethnicity, or age. To ensure non-discrimination in learning tasks, knowledge of
the group attributes is essential. However, in practice, these attributes may
not be available due to legal and ethical requirements. To address this
challenge, this paper studies a model that protects the privacy of the
individuals' sensitive information while also allowing it to learn
non-discriminatory predictors. A key characteristic of the proposed model is to
enable the adoption of off-the-selves and non-private fair models to create a
privacy-preserving and fair model. The paper analyzes the relation between
accuracy, privacy, and fairness, and the experimental evaluation illustrates
the benefits of the proposed models on several prediction tasks. In particular,
this proposal is the first to allow both scalable and accurate training of
private and fair models for very large neural networks.",None,-1
84dac465-a679-4e5a-a494-17d1f2a6bb41,Limitations of the NTK for Understanding Generalization in Deep Learning,0.632274,"The ``Neural Tangent Kernel'' (NTK) (Jacot et al 2018), and its empirical
variants have been proposed as a proxy to capture certain behaviors of real
neural networks. In this work, we study NTKs through the lens of scaling laws,
and demonstrate that they fall short of explaining important aspects of neural
network generalization. In particular, we demonstrate realistic settings where
finite-width neural networks have significantly better data scaling exponents
as compared to their corresponding empirical and infinite NTKs at
initialization. This reveals a more fundamental difference between the real
networks and NTKs, beyond just a few percentage points of test accuracy.
Further, we show that even if the empirical NTK is allowed to be pre-trained on
a constant number of samples, the kernel scaling does not catch up to the
neural network scaling. Finally, we show that the empirical NTK continues to
evolve throughout most of the training, in contrast with prior work which
suggests that it stabilizes after a few epochs of training. Altogether, our
work establishes concrete limitations of the NTK approach in understanding
generalization of real networks on natural datasets.",None,-1
ae797824-6625-4716-9719-dcb94b68acb0,Simple and Effective Knowledge-Driven Query Expansion for QA-Based Product Attribute Extraction,0.338282,"A key challenge in attribute value extraction (AVE) from e-commerce sites is
how to handle a large number of attributes for diverse products. Although this
challenge is partially addressed by a question answering (QA) approach which
finds a value in product data for a given query (attribute), it does not work
effectively for rare and ambiguous queries. We thus propose simple
knowledge-driven query expansion based on possible answers (values) of a query
(attribute) for QA-based AVE. We retrieve values of a query (attribute) from
the training data to expand the query. We train a model with two tricks,
knowledge dropout and knowledge token mixing, which mimic the imperfection of
the value knowledge in testing. Experimental results on our cleaned version of
AliExpress dataset show that our method improves the performance of AVE (+6.08
macro F1), especially for rare and ambiguous attributes (+7.82 and +6.86 macro
F1, respectively).",https://github.com/lanmanok/ACL19_Scaling_Up_Open_Tagging,-1
602f2078-a607-4503-b0cc-bb514518ee87,Quasi Non-Negative Quaternion Matrix Factorization with Application to Color Face Recognition,0.542539,"To address the non-negativity dropout problem of quaternion models, a novel
quasi non-negative quaternion matrix factorization (QNQMF) model is presented
for color image processing. To implement QNQMF, the quaternion projected
gradient algorithm and the quaternion alternating direction method of
multipliers are proposed via formulating QNQMF as the non-convex constraint
quaternion optimization problems. Some properties of the proposed algorithms
are studied. The numerical experiments on the color image reconstruction show
that these algorithms encoded on the quaternion perform better than these
algorithms encoded on the red, green and blue channels. Furthermore, we apply
the proposed algorithms to the color face recognition. Numerical results
indicate that the accuracy rate of face recognition on the quaternion model is
better than on the red, green and blue channels of color image as well as
single channel of gray level images for the same data, when large facial
expressions and shooting angle variations are presented.",None,-1
0729ed91-f3fd-47a5-a105-5a15e294a761,Interpretation Quality Score for Measuring the Quality of interpretability methods,0.210828,"Machine learning (ML) models have been applied to a wide range of natural
language processing (NLP) tasks in recent years. In addition to making accurate
decisions, the necessity of understanding how models make their decisions has
become apparent in many applications. To that end, many interpretability
methods that help explain the decision processes of ML models have been
developed. Yet, there currently exists no widely-accepted metric to evaluate
the quality of explanations generated by these methods. As a result, there
currently is no standard way of measuring to what degree an interpretability
method achieves an intended objective. Moreover, there is no accepted standard
of performance by which we can compare and rank the current existing
interpretability methods. In this paper, we propose a novel metric for
quantifying the quality of explanations generated by interpretability methods.
We compute the metric on three NLP tasks using six interpretability methods and
present our results.",None,12089
6851a42f-93e1-4717-93f5-e7c524ce0e09,PanoFormer: Panorama Transformer for Indoor 360 Depth Estimation,0.943347,"Existing panoramic depth estimation methods based on convolutional neural
networks (CNNs) focus on removing panoramic distortions, failing to perceive
panoramic structures efficiently due to the fixed receptive field in CNNs. This
paper proposes the panorama transformer (named PanoFormer) to estimate the
depth in panorama images, with tangent patches from spherical domain, learnable
token flows, and panorama specific metrics. In particular, we divide patches on
the spherical tangent domain into tokens to reduce the negative effect of
panoramic distortions. Since the geometric structures are essential for depth
estimation, a self-attention module is redesigned with an additional learnable
token flow. In addition, considering the characteristic of the spherical
domain, we present two panorama-specific metrics to comprehensively evaluate
the panoramic depth estimation models' performance. Extensive experiments
demonstrate that our approach significantly outperforms the state-of-the-art
(SOTA) methods. Furthermore, the proposed method can be effectively extended to
solve semantic panorama segmentation, a similar pixel2pixel task. Code will be
available.",https://github.com/zhijieshen-bjtu/PanoFormer,-1
825fc8e2-8b3d-44ae-9bb0-a366e67f33f2,Robust Trajectory Prediction against Adversarial Attacks,0.790037,"Trajectory prediction using deep neural networks (DNNs) is an essential
component of autonomous driving (AD) systems. However, these methods are
vulnerable to adversarial attacks, leading to serious consequences such as
collisions. In this work, we identify two key ingredients to defend trajectory
prediction models against adversarial attacks including (1) designing effective
adversarial training methods and (2) adding domain-specific data augmentation
to mitigate the performance degradation on clean data. We demonstrate that our
method is able to improve the performance by 46% on adversarial data and at the
cost of only 3% performance degradation on clean data, compared to the model
trained with clean data. Additionally, compared to existing robust methods, our
method can improve performance by 21% on adversarial examples and 9% on clean
data. Our robust model is evaluated with a planner to study its downstream
impacts. We demonstrate that our model can significantly reduce the severe
accident rates (e.g., collisions and off-road driving).",https://robustav.github.io/RobustTraj,-1
47727e5b-441c-4fe2-8d45-2307266b1e00,Multilevel Hierarchical Network with Multiscale Sampling for Video Question Answering,0.655592,"Video question answering (VideoQA) is challenging given its multimodal
combination of visual understanding and natural language processing. While most
existing approaches ignore the visual appearance-motion information at
different temporal scales, it is unknown how to incorporate the multilevel
processing capacity of a deep learning model with such multiscale information.
Targeting these issues, this paper proposes a novel Multilevel Hierarchical
Network (MHN) with multiscale sampling for VideoQA. MHN comprises two modules,
namely Recurrent Multimodal Interaction (RMI) and Parallel Visual Reasoning
(PVR). With a multiscale sampling, RMI iterates the interaction of
appearance-motion information at each scale and the question embeddings to
build the multilevel question-guided visual representations. Thereon, with a
shared transformer encoder, PVR infers the visual cues at each level in
parallel to fit with answering different question types that may rely on the
visual information at relevant levels. Through extensive experiments on three
VideoQA datasets, we demonstrate improved performances than previous
state-of-the-arts and justify the effectiveness of each part of our method.",None,-1
b2720475-5a6b-4f58-8e4b-bcdefc55ec8d,One Agent To Rule Them All: Towards Multi-agent Conversational AI,0.514136,"The increasing volume of commercially available conversational agents (CAs)
on the market has resulted in users being burdened with learning and adopting
multiple agents to accomplish their tasks. Though prior work has explored
supporting a multitude of domains within the design of a single agent, the
interaction experience suffers due to the large action space of desired
capabilities. To address these problems, we introduce a new task BBAI:
Black-Box Agent Integration, focusing on combining the capabilities of multiple
black-box CAs at scale. We explore two techniques: question agent pairing and
question response pairing aimed at resolving this task. Leveraging these
techniques, we design One For All (OFA), a scalable system that provides a
unified interface to interact with multiple CAs. Additionally, we introduce
MARS: Multi-Agent Response Selection, a new encoder model for question response
pairing that jointly encodes user question and agent response pairs. We
demonstrate that OFA is able to automatically and accurately integrate an
ensemble of commercially available CAs spanning disparate domains.
Specifically, using the MARS encoder we achieve the highest accuracy on our
BBAI task, outperforming strong baselines.",https://github.com/ChrisIsKing/black-box-multi-agent-integation,-1
513f756b-3407-4e69-9765-97c28b280c7d,1Cademy @ Causal News Corpus 2022: Enhance Causal Span Detection via Beam-Search-based Position Selector,0.622464,"In this paper, we present our approach and empirical observations for
Cause-Effect Signal Span Detection -- Subtask 2 of Shared task
3~\cite{tan-etal-2022-event} at CASE 2022. The shared task aims to extract the
cause, effect, and signal spans from a given causal sentence. We model the task
as a reading comprehension (RC) problem and apply a token-level RC-based span
prediction paradigm to the task as the baseline. We explore different training
objectives to fine-tune the model, as well as data augmentation (DA) tricks
based on the language model (LM) for performance improvement. Additionally, we
propose an efficient beam-search post-processing strategy to due with the
drawbacks of span detection to obtain a further performance gain. Our approach
achieves an average $F_1$ score of 54.15 and ranks \textbf{$1^{st}$} in the
CASE competition. Our code is available at
\url{https://github.com/Gzhang-umich/1CademyTeamOfCASE}.",https://github.com/Gzhang-umich/1CademyTeamOfCASE,-1
2a0d42b1-6fe7-41fc-be8b-0b352d662c47,CP3: Unifying Point Cloud Completion by Pretrain-Prompt-Predict Paradigm,0.288586,"Point cloud completion aims to predict complete shape from its partial
observation. Current approaches mainly consist of generation and refinement
stages in a coarse-to-fine style. However, the generation stage often lacks
robustness to tackle different incomplete variations, while the refinement
stage blindly recovers point clouds without the semantic awareness. To tackle
these challenges, we unify point cloud Completion by a generic
Pretrain-Prompt-Predict paradigm, namely CP3. Inspired by prompting approaches
from NLP, we creatively reinterpret point cloud generation and refinement as
the prompting and predicting stages, respectively. Then, we introduce a concise
self-supervised pretraining stage before prompting. It can effectively increase
robustness of point cloud generation, by an Incompletion-Of-Incompletion (IOI)
pretext task. Moreover, we develop a novel Semantic Conditional Refinement
(SCR) network at the predicting stage. It can discriminatively modulate
multi-scale refinement with the guidance of semantics. Finally, extensive
experiments demonstrate that our CP3 outperforms the state-of-the-art methods
with a large margin.",None,-1
467f8baa-0bae-4f12-a357-0a3850e73805,Offline Reinforcement Learning for Road Traffic Control,0.0403487,"Traffic signal control is an important problem in urban mobility with a
significant potential of economic and environmental impact. While there is a
growing interest in Reinforcement Learning (RL) for traffic signal control, the
work so far has focussed on learning through simulations which could lead to
inaccuracies due to simplifying assumptions. Instead, real experience data on
traffic is available and could be exploited at minimal costs. Recent progress
in offline or batch RL has enabled just that. Model-based offline RL methods,
in particular, have been shown to generalize from the experience data much
better than others.
  We build a model-based learning framework which infers a Markov Decision
Process (MDP) from a dataset collected using a cyclic traffic signal control
policy that is both commonplace and easy to gather. The MDP is built with
pessimistic costs to manage out-of-distribution scenarios using an adaptive
shaping of rewards which is shown to provide better regularization compared to
the prior related work in addition to being PAC-optimal. Our model is evaluated
on a complex signalized roundabout showing that it is possible to build highly
performant traffic control policies in a data efficient manner.",None,-1
6b52cd8d-bbec-4cd0-a1db-58e80d6b80bb,Dialog Acts for Task-Driven Embodied Agents,0.866018,"Embodied agents need to be able to interact in natural language understanding
task descriptions and asking appropriate follow up questions to obtain
necessary information to be effective at successfully accomplishing tasks for a
wide range of users. In this work, we propose a set of dialog acts for
modelling such dialogs and annotate the TEACh dataset that includes over 3,000
situated, task oriented conversations (consisting of 39.5k utterances in total)
with dialog acts. TEACh-DA is one of the first large scale dataset of dialog
act annotations for embodied task completion. Furthermore, we demonstrate the
use of this annotated dataset in training models for tagging the dialog acts of
a given utterance, predicting the dialog act of the next response given a
dialog history, and use the dialog acts to guide agent's non-dialog behaviour.
In particular, our experiments on the TEACh Execution from Dialog History task
where the model predicts the sequence of low level actions to be executed in
the environment for embodied task completion, demonstrate that dialog acts can
improve end task success rate by up to 2 points compared to the system without
dialog acts.",None,-1
18954a60-40ab-45cd-900a-cf671c82e40d,Study of Encoder-Decoder Architectures for Code-Mix Search Query Translation,0.290758,"With the broad reach of the internet and smartphones, e-commerce platforms
have an increasingly diversified user base. Since native language users are not
conversant in English, their preferred browsing mode is their regional language
or a combination of their regional language and English. From our recent study
on the query data, we noticed that many of the queries we receive are code-mix,
specifically Hinglish i.e. queries with one or more Hindi words written in
English (Latin) script. We propose a transformer-based approach for code-mix
query translation to enable users to search with these queries. We demonstrate
the effectiveness of pre-trained encoder-decoder models trained on a large
corpus of the unlabeled English text for this task. Using generic domain
translation models, we created a pseudo-labelled dataset for training the model
on the search queries and verified the effectiveness of various data
augmentation techniques. Further, to reduce the latency of the model, we use
knowledge distillation and weight quantization. Effectiveness of the proposed
method has been validated through experimental evaluations and A/B testing. The
model is currently live on Flipkart app and website, serving millions of
queries.",None,-1
80c53587-41f2-4d59-af9e-05712ed08504,HeterMPC: A Heterogeneous Graph Neural Network for Response Generation in Multi-Party Conversations,0.847999,"Recently, various response generation models for two-party conversations have
achieved impressive improvements, but less effort has been paid to multi-party
conversations (MPCs) which are more practical and complicated. Compared with a
two-party conversation where a dialogue context is a sequence of utterances,
building a response generation model for MPCs is more challenging, since there
exist complicated context structures and the generated responses heavily rely
on both interlocutors (i.e., speaker and addressee) and history utterances. To
address these challenges, we present HeterMPC, a heterogeneous graph-based
neural network for response generation in MPCs which models the semantics of
utterances and interlocutors simultaneously with two types of nodes in a graph.
Besides, we also design six types of meta relations with
node-edge-type-dependent parameters to characterize the heterogeneous
interactions within the graph. Through multi-hop updating, HeterMPC can
adequately utilize the structural knowledge of conversations for response
generation. Experimental results on the Ubuntu Internet Relay Chat (IRC)
channel benchmark show that HeterMPC outperforms various baseline models for
response generation in MPCs.",https://github.com/lxchtan/HeterMPC,-1
6ba07fcf-611a-4551-bd77-0d092e5aabdf,Mix and Localize: Localizing Sound Sources in Mixtures,0.753976,"We present a method for simultaneously localizing multiple sound sources
within a visual scene. This task requires a model to both group a sound mixture
into individual sources, and to associate them with a visual signal. Our method
jointly solves both tasks at once, using a formulation inspired by the
contrastive random walk of Jabri et al. We create a graph in which images and
separated sounds correspond to nodes, and train a random walker to transition
between nodes from different modalities with high return probability. The
transition probabilities for this walk are determined by an audio-visual
similarity metric that is learned by our model. We show through experiments
with musical instruments and human speech that our model can successfully
localize multiple sounds, outperforming other self-supervised methods. Project
site: https://hxixixh.github.io/mix-and-localize",https://hxixixh.github.io/mix-and-localize,-1
1ca05380-3bec-498a-8d0d-3d849f426ee6,Live Stream Temporally Embedded 3D Human Body Pose and Shape Estimation,0.464593,"3D Human body pose and shape estimation within a temporal sequence can be
quite critical for understanding human behavior. Despite the significant
progress in human pose estimation in the recent years, which are often based on
single images or videos, human motion estimation on live stream videos is still
a rarely-touched area considering its special requirements for real-time output
and temporal consistency. To address this problem, we present a temporally
embedded 3D human body pose and shape estimation (TePose) method to improve the
accuracy and temporal consistency of pose estimation in live stream videos.
TePose uses previous predictions as a bridge to feedback the error for better
estimation in the current frame and to learn the correspondence between data
frames and predictions in the history. A multi-scale spatio-temporal graph
convolutional network is presented as the motion discriminator for adversarial
training using datasets without any 3D labeling. We propose a sequential data
loading strategy to meet the special start-to-end data processing requirement
of live stream. We demonstrate the importance of each proposed module with
extensive experiments. The results show the effectiveness of TePose on
widely-used human pose benchmarks with state-of-the-art performance.",https://github.com/ostadabbas/TePose,2464
bddd40b6-8a0b-483a-8426-f602ad785921,DialoKG: Knowledge-Structure Aware Task-Oriented Dialogue Generation,0.691153,"Task-oriented dialogue generation is challenging since the underlying
knowledge is often dynamic and effectively incorporating knowledge into the
learning process is hard. It is particularly challenging to generate both
human-like and informative responses in this setting. Recent research primarily
focused on various knowledge distillation methods where the underlying
relationship between the facts in a knowledge base is not effectively captured.
In this paper, we go one step further and demonstrate how the structural
information of a knowledge graph can improve the system's inference
capabilities. Specifically, we propose DialoKG, a novel task-oriented dialogue
system that effectively incorporates knowledge into a language model. Our
proposed system views relational knowledge as a knowledge graph and introduces
(1) a structure-aware knowledge embedding technique, and (2) a knowledge
graph-weighted attention masking strategy to facilitate the system selecting
relevant information during the dialogue generation. An empirical evaluation
demonstrates the effectiveness of DialoKG over state-of-the-art methods on
several standard benchmark datasets.",https://github.com/rashad101/DialoKG,-1
0cb4bf0e-726a-4a1d-ba6e-8de05300ea91,DHGE: Dual-View Hyper-Relational Knowledge Graph Embedding for Link Prediction and Entity Typing,0.327003,"In the field of representation learning on knowledge graphs (KGs), a
hyper-relational fact consists of a main triple and several auxiliary
attribute-value descriptions, which is considered more comprehensive and
specific than a triple-based fact. However, currently available
hyper-relational KG embedding methods in a single view are limited in
application because they weaken the hierarchical structure that represents the
affiliation between entities. To overcome this limitation, we propose a
dual-view hyper-relational KG structure (DH-KG) that contains a
hyper-relational instance view for entities and a hyper-relational ontology
view for concepts that are abstracted hierarchically from the entities. This
paper defines link prediction and entity typing tasks on DH-KG for the first
time and constructs two DH-KG datasets, JW44K-6K, extracted from Wikidata, and
HTDM based on medical data. Furthermore, we propose DHGE, a DH-KG embedding
model based on GRAN encoders, HGNNs, and joint learning. DHGE outperforms
baseline models on DH-KG, according to experimental results. Finally, we
provide an example of how this technology can be used to treat hypertension.
Our model and new datasets are publicly available.",https://github.com/LHRLAB/DHGE,1107
8f1bafe6-ac1e-4d9f-ae8d-78e1de139066,Planning Assembly Sequence with Graph Transformer,0.597554,"Assembly sequence planning (ASP) is the essential process for modern
manufacturing, proven to be NP-complete thus its effective and efficient
solution has been a challenge for researchers in the field. In this paper, we
present a graph-transformer based framework for the ASP problem which is
trained and demonstrated on a self-collected ASP database. The ASP database
contains a self-collected set of LEGO models. The LEGO model is abstracted to a
heterogeneous graph structure after a thorough analysis of the original
structure and feature extraction. The ground truth assembly sequence is first
generated by brute-force search and then adjusted manually to in line with
human rational habits. Based on this self-collected ASP dataset, we propose a
heterogeneous graph-transformer framework to learn the latent rules for
assembly planning. We evaluated the proposed framework in a series of
experiment. The results show that the similarity of the predicted and ground
truth sequences can reach 0.44, a medium correlation measured by Kendall's
$\tau$. Meanwhile, we compared the different effects of node features and edge
features and generated a feasible and reasonable assembly sequence as a
benchmark for further research. Our data set and code is available on
https://github.com/AIR-DISCOVER/ICRA\_ASP.",https://github.com/AIR-DISCOVER/ICRA,-1
19dd9f56-ab0e-440a-ad45-34504d108cfb,Atari-5: Distilling the Arcade Learning Environment down to Five Games,0.791756,"The Arcade Learning Environment (ALE) has become an essential benchmark for
assessing the performance of reinforcement learning algorithms. However, the
computational cost of generating results on the entire 57-game dataset limits
ALE's use and makes the reproducibility of many results infeasible. We propose
a novel solution to this problem in the form of a principled methodology for
selecting small but representative subsets of environments within a benchmark
suite. We applied our method to identify a subset of five ALE games, called
Atari-5, which produces 57-game median score estimates within 10% of their true
values. Extending the subset to 10-games recovers 80% of the variance for
log-scores for all games within the 57-game set. We show this level of
compression is possible due to a high degree of correlation between many of the
games in ALE.",https://github.com/maitchison/Atari-5,10193
9af23ada-a457-43e4-8d22-47e4eddb4352,Conformal Prediction is Robust to Dispersive Label Noise,0.0374761,"We study the robustness of conformal prediction, a powerful tool for
uncertainty quantification, to label noise. Our analysis tackles both
regression and classification problems, characterizing when and how it is
possible to construct uncertainty sets that correctly cover the unobserved
noiseless ground truth labels. We further extend our theory and formulate the
requirements for correctly controlling a general loss function, such as the
false negative proportion, with noisy labels. Our theory and experiments
suggest that conformal prediction and risk-controlling techniques with noisy
labels attain conservative risk over the clean ground truth labels except in
adversarial cases. In such cases, we can also correct for noise of bounded size
in the conformal prediction algorithm in order to ensure achieving the correct
risk of the ground truth labels without score or data regularity.",None,-1
4b39b1c5-9b0e-4c9e-a0e5-298ef8218d9d,PairReranker: Pairwise Reranking for Natural Language Generation,0.22867,"Pre-trained language models have been successful in natural language
generation (NLG) tasks. While various decoding methods have been employed, they
often produce suboptimal results. We first present an empirical analysis of
three NLG tasks: summarization, machine translation, and constrained text
generation. We found that selecting the best output from the results of
multiple decoding methods can significantly improve performance. To further
improve reranking for NLG tasks, we proposed a novel method,
\textsc{PairReranker}, which uses a single encoder and a pairwise loss function
to jointly encode a source input and a pair of candidates and compare them.
Experiments on three NLG tasks demonstrated the effectiveness and flexibility
of \textsc{PairReranker}, showing strong results, compared with previous
baselines. In addition, our \textsc{PairReranker} can generalize to
significantly improve GPT-3 (text-davinci-003) results (e.g., 24.55\% on
CommonGen and 11.35\% on WMT18 zh-en), even though our rerankers are not
trained with any GPT-3 candidates.",https://inklab.usc.edu/PairReranker,-1
6cbce68b-8272-4998-817d-1f86be34a1dc,SiRi: A Simple Selective Retraining Mechanism for Transformer-based Visual Grounding,0.311969,"In this paper, we investigate how to achieve better visual grounding with
modern vision-language transformers, and propose a simple yet powerful
Selective Retraining (SiRi) mechanism for this challenging task. Particularly,
SiRi conveys a significant principle to the research of visual grounding, i.e.,
a better initialized vision-language encoder would help the model converge to a
better local minimum, advancing the performance accordingly. In specific, we
continually update the parameters of the encoder as the training goes on, while
periodically re-initialize rest of the parameters to compel the model to be
better optimized based on an enhanced encoder. SiRi can significantly
outperform previous approaches on three popular benchmarks. Specifically, our
method achieves 83.04% Top1 accuracy on RefCOCO+ testA, outperforming the
state-of-the-art approaches (training from scratch) by more than 10.21%.
Additionally, we reveal that SiRi performs surprisingly superior even with
limited training data. We also extend it to transformer-based visual grounding
models and other vision-language tasks to verify the validity.",https://github.com/qumengxue/siri-vg.git,-1
07d35448-f200-4aad-95c8-5159aeb1996f,Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity,0.981761,"Large Language Models (LLMs) have demonstrated impressive capabilities in
generating fluent text, as well as tendencies to reproduce undesirable social
biases. This study investigates whether LLMs reproduce the moral biases
associated with political groups in the United States, an instance of a broader
capability herein termed moral mimicry. This hypothesis is explored in the
GPT-3/3.5 and OPT families of Transformer-based LLMs. Using tools from Moral
Foundations Theory, it is shown that these LLMs are indeed moral mimics. When
prompted with a liberal or conservative political identity, the models generate
text reflecting corresponding moral biases. This study also explores the
relationship between moral mimicry and model size, and similarity between human
and LLM moral word use.",https://github.com/mbforbes/social-chemistry-101,-1
99b79646-253c-4f6a-9d50-5ab11e618a55,Detecting Arbitrary Keypoints on Limbs and Skis with Sparse Partly Correct Segmentation Masks,0.559356,"Analyses based on the body posture are crucial for top-class athletes in many
sports disciplines. If at all, coaches label only the most important keypoints,
since manual annotations are very costly. This paper proposes a method to
detect arbitrary keypoints on the limbs and skis of professional ski jumpers
that requires a few, only partly correct segmentation masks during training.
Our model is based on the Vision Transformer architecture with a special design
for the input tokens to query for the desired keypoints. Since we use
segmentation masks only to generate ground truth labels for the freely
selectable keypoints, partly correct segmentation masks are sufficient for our
training procedure. Hence, there is no need for costly hand-annotated
segmentation masks. We analyze different training techniques for freely
selected and standard keypoints, including pseudo labels, and show in our
experiments that only a few partly correct segmentation masks are sufficient
for learning to detect arbitrary keypoints on limbs and skis.",https://github.com/kaulquappe23/arbitrary-keypoints-skijump,-1
72110980-6ab5-4f00-b623-3d0243523f26,The solution set of fuzzy relation equations with addition-min composition,0.41217,"This paper deals with the resolutions of fuzzy relation equations with
addition-min composition. When the fuzzy relation equations have a solution, we
first propose an algorithm to find all minimal solutions of the fuzzy relation
equations and also supply an algorithm to find all maximal solutions of the
fuzzy relation equations, which will be illustrated, respectively, by numeral
examples. Then we prove that every solution of the fuzzy relation equations is
between a minimal solution and a maximal one, so that we describe the solution
set of the fuzzy relation equations completely.",None,-1
3772b3d3-de32-496a-a930-5159d496217c,CNSNet: A Cleanness-Navigated-Shadow Network for Shadow Removal,0.520938,"The key to shadow removal is recovering the contents of the shadow regions
with the guidance of the non-shadow regions. Due to the inadequate long-range
modeling, the CNN-based approaches cannot thoroughly investigate the
information from the non-shadow regions. To solve this problem, we propose a
novel cleanness-navigated-shadow network (CNSNet), with a shadow-oriented
adaptive normalization (SOAN) module and a shadow-aware aggregation with
transformer (SAAT) module based on the shadow mask. Under the guidance of the
shadow mask, the SOAN module formulates the statistics from the non-shadow
region and adaptively applies them to the shadow region for region-wise
restoration. The SAAT module utilizes the shadow mask to precisely guide the
restoration of each shadowed pixel by considering the highly relevant pixels
from the shadow-free regions for global pixel-wise restoration. Extensive
experiments on three benchmark datasets (ISTD, ISTD+, and SRD) show that our
method achieves superior de-shadowing performance.",None,6653
5356df50-d714-4199-8fbb-22a352d42005,Deep versus Wide: An Analysis of Student Architectures for Task-Agnostic Knowledge Distillation of Self-Supervised Speech Models,0.739619,"Self-supervised learning (SSL) is seen as a very promising approach with high
performance for several speech downstream tasks. Since the parameters of SSL
models are generally so large that training and inference require a lot of
memory and computational cost, it is desirable to produce compact SSL models
without a significant performance degradation by applying compression methods
such as knowledge distillation (KD). Although the KD approach is able to shrink
the depth and/or width of SSL model structures, there has been little research
on how varying the depth and width impacts the internal representation of the
small-footprint model. This paper provides an empirical study that addresses
the question. We investigate the performance on SUPERB while varying the
structure and KD methods so as to keep the number of parameters constant; this
allows us to analyze the contribution of the representation introduced by
varying the model architecture. Experiments demonstrate that a certain depth is
essential for solving content-oriented tasks (e.g. automatic speech
recognition) accurately, whereas a certain width is necessary for achieving
high performance on several speaker-oriented tasks (e.g. speaker
identification). Based on these observations, we identify, for SUPERB, a more
compressed model with better performance than previous studies.",https://github.com/s3prl/s3prl,-1
c5a9f2f2-ba02-48ce-a9da-60d1e9e86952,ORCA: A Challenging Benchmark for Arabic Language Understanding,0.507601,"Due to their crucial role in all NLP, several benchmarks have been proposed
to evaluate pretrained language models. In spite of these efforts, no public
benchmark of diverse nature currently exists for evaluation of Arabic. This
makes it challenging to measure progress for both Arabic and multilingual
language models. This challenge is compounded by the fact that any benchmark
targeting Arabic needs to take into account the fact that Arabic is not a
single language but rather a collection of languages and varieties. In this
work, we introduce ORCA, a publicly available benchmark for Arabic language
understanding evaluation. ORCA is carefully constructed to cover diverse Arabic
varieties and a wide range of challenging Arabic understanding tasks exploiting
60 different datasets across seven NLU task clusters. To measure current
progress in Arabic NLU, we use ORCA to offer a comprehensive comparison between
18 multilingual and Arabic language models. We also provide a public
leaderboard with a unified single-number evaluation metric (ORCA score) to
facilitate future research.",None,-1
446d426b-c428-43ae-ba56-419bb416a933,Guided Unsupervised Learning by Subaperture Decomposition for Ocean SAR Image Retrieval,0.686632,"Spaceborne synthetic aperture radar (SAR) can provide accurate images of the
ocean surface roughness day-or-night in nearly all weather conditions, being an
unique asset for many geophysical applications. Considering the huge amount of
data daily acquired by satellites, automated techniques for physical features
extraction are needed. Even if supervised deep learning methods attain
state-of-the-art results, they require great amount of labeled data, which are
difficult and excessively expensive to acquire for ocean SAR imagery. To this
end, we use the subaperture decomposition (SD) algorithm to enhance the
unsupervised learning retrieval on the ocean surface, empowering ocean
researchers to search into large ocean databases. We empirically prove that SD
improve the retrieval precision with over 20% for an unsupervised transformer
auto-encoder network. Moreover, we show that SD brings important performance
boost when Doppler centroid images are used as input data, leading the way to
new unsupervised physics guided retrieval algorithms.",None,-1
71712c49-4d99-4779-9ec5-1811812d34d6,Tapping the Potential of Coherence and Syntactic Features in Neural Models for Automatic Essay Scoring,0.104578,"In the prompt-specific holistic score prediction task for Automatic Essay
Scoring, the general approaches include pre-trained neural model, coherence
model, and hybrid model that incorporate syntactic features with neural model.
In this paper, we propose a novel approach to extract and represent essay
coherence features with prompt-learning NSP that shows to match the
state-of-the-art AES coherence model, and achieves the best performance for
long essays. We apply syntactic feature dense embedding to augment BERT-based
model and achieve the best performance for hybrid methodology for AES. In
addition, we explore various ideas to combine coherence, syntactic information
and semantic embeddings, which no previous study has done before. Our combined
model also performs better than the SOTA available for combined model, even
though it does not outperform our syntactic enhanced neural model. We further
offer analyses that can be useful for future study.",None,-1
290bedcd-a1b1-4f9f-be83-8f50a9c7e3ff,Visual Context-driven Audio Feature Enhancement for Robust End-to-End Audio-Visual Speech Recognition,0.796594,"This paper focuses on designing a noise-robust end-to-end Audio-Visual Speech
Recognition (AVSR) system. To this end, we propose Visual Context-driven Audio
Feature Enhancement module (V-CAFE) to enhance the input noisy audio speech
with a help of audio-visual correspondence. The proposed V-CAFE is designed to
capture the transition of lip movements, namely visual context and to generate
a noise reduction mask by considering the obtained visual context. Through
context-dependent modeling, the ambiguity in viseme-to-phoneme mapping can be
refined for mask generation. The noisy representations are masked out with the
noise reduction mask resulting in enhanced audio features. The enhanced audio
features are fused with the visual features and taken to an encoder-decoder
model composed of Conformer and Transformer for speech recognition. We show the
proposed end-to-end AVSR with the V-CAFE can further improve the
noise-robustness of AVSR. The effectiveness of the proposed method is evaluated
in noisy speech recognition and overlapped speech recognition experiments using
the two largest audio-visual datasets, LRS2 and LRS3.",None,11033
e0bc21c9-e81c-44f3-8057-efbcc6e3a226,Fine Detailed Texture Learning for 3D Meshes with Generative Models,0.301897,"This paper presents a method to reconstruct high-quality textured 3D models
from both multi-view and single-view images. The reconstruction is posed as an
adaptation problem and is done progressively where in the first stage, we focus
on learning accurate geometry, whereas in the second stage, we focus on
learning the texture with a generative adversarial network. In the generative
learning pipeline, we propose two improvements. First, since the learned
textures should be spatially aligned, we propose an attention mechanism that
relies on the learnable positions of pixels. Secondly, since discriminator
receives aligned texture maps, we augment its input with a learnable embedding
which improves the feedback to the generator. We achieve significant
improvements on multi-view sequences from Tripod dataset as well as on
single-view image datasets, Pascal 3D+ and CUB. We demonstrate that our method
achieves superior 3D textured models compared to the previous works. Please
visit our web-page for 3D visuals.",None,-1
7f1e4a78-e4a7-4932-ab4e-b9b0f3551389,Predicting Future Occupancy Grids in Dynamic Environment with Spatio-Temporal Learning,0.685907,"Reliably predicting future occupancy of highly dynamic urban environments is
an important precursor for safe autonomous navigation. Common challenges in the
prediction include forecasting the relative position of other vehicles,
modelling the dynamics of vehicles subjected to different traffic conditions,
and vanishing surrounding objects. To tackle these challenges, we propose a
spatio-temporal prediction network pipeline that takes the past information
from the environment and semantic labels separately for generating future
occupancy predictions. Compared to the current SOTA, our approach predicts
occupancy for a longer horizon of 3 seconds and in a relatively complex
environment from the nuScenes dataset. Our experimental results demonstrate the
ability of spatio-temporal networks to understand scene dynamics without the
need for HD-Maps and explicit modeling dynamic objects. We publicly release our
occupancy grid dataset based on nuScenes to support further research.",https://github.com/ksm26/SpatioTemporal-Predictions,-1
52b13ba0-4903-4661-aeac-de777c8653bb,FRSUM: Towards Faithful Abstractive Summarization via Enhancing Factual Robustness,0.261763,"Despite being able to generate fluent and grammatical text, current Seq2Seq
summarization models still suffering from the unfaithful generation problem. In
this paper, we study the faithfulness of existing systems from a new
perspective of factual robustness which is the ability to correctly generate
factual information over adversarial unfaithful information. We first measure a
model's factual robustness by its success rate to defend against adversarial
attacks when generating factual information. The factual robustness analysis on
a wide range of current systems shows its good consistency with human judgments
on faithfulness. Inspired by these findings, we propose to improve the
faithfulness of a model by enhancing its factual robustness. Specifically, we
propose a novel training strategy, namely FRSUM, which teaches the model to
defend against both explicit adversarial samples and implicit factual
adversarial perturbations. Extensive automatic and human evaluation results
show that FRSUM consistently improves the faithfulness of various Seq2Seq
models, such as T5, BART.",None,-1
b68be24c-fb3b-4435-b3bc-7a97b350e595,Object-based active inference,0.324714,"The world consists of objects: distinct entities possessing independent
properties and dynamics. For agents to interact with the world intelligently,
they must translate sensory inputs into the bound-together features that
describe each object. These object-based representations form a natural basis
for planning behavior. Active inference (AIF) is an influential unifying
account of perception and action, but existing AIF models have not leveraged
this important inductive bias. To remedy this, we introduce 'object-based
active inference' (OBAI), marrying AIF with recent deep object-based neural
networks. OBAI represents distinct objects with separate variational beliefs,
and uses selective attention to route inputs to their corresponding object
slots. Object representations are endowed with independent action-based
dynamics. The dynamics and generative model are learned from experience with a
simple environment (active multi-dSprites). We show that OBAI learns to
correctly segment the action-perturbed objects from video input, and to
manipulate these objects towards arbitrary goals.",None,-1
0d620c28-6c33-458a-8564-c2dc10ff9eea,Counterfactual Multihop QA: A Cause-Effect Approach for Reducing Disconnected Reasoning,0.160543,"Multi-hop QA requires reasoning over multiple supporting facts to answer the
question. However, the existing QA models always rely on shortcuts, e.g.,
providing the true answer by only one fact, rather than multi-hop reasoning,
which is referred as $\textit{disconnected reasoning}$ problem. To alleviate
this issue, we propose a novel counterfactual multihop QA, a causal-effect
approach that enables to reduce the disconnected reasoning. It builds upon
explicitly modeling of causality: 1) the direct causal effects of disconnected
reasoning and 2) the causal effect of true multi-hop reasoning from the total
causal effect. With the causal graph, a counterfactual inference is proposed to
disentangle the disconnected reasoning from the total causal effect, which
provides us a new perspective and technology to learn a QA model that exploits
the true multi-hop reasoning instead of shortcuts. Extensive experiments have
conducted on the benchmark HotpotQA dataset, which demonstrate that the
proposed method can achieve notable improvement on reducing disconnected
reasoning. For example, our method achieves 5.8% higher points of its Supp$_s$
score on HotpotQA through true multihop reasoning. The code is available at
supplementary material.",None,-1
416e576b-9336-4980-a8da-3910ea347079,Improving Monocular Visual Odometry Using Learned Depth,0.616519,"Monocular visual odometry (VO) is an important task in robotics and computer
vision. Thus far, how to build accurate and robust monocular VO systems that
can work well in diverse scenarios remains largely unsolved. In this paper, we
propose a framework to exploit monocular depth estimation for improving VO. The
core of our framework is a monocular depth estimation module with a strong
generalization capability for diverse scenes. It consists of two separate
working modes to assist the localization and mapping. With a single monocular
image input, the depth estimation module predicts a relative depth to help the
localization module on improving the accuracy. With a sparse depth map and an
RGB image input, the depth estimation module can generate accurate
scale-consistent depth for dense mapping. Compared with current learning-based
VO methods, our method demonstrates a stronger generalization ability to
diverse scenes. More significantly, our framework is able to boost the
performances of existing geometry-based VO methods by a large margin.",None,-1
1b4dffd9-e782-4c21-b418-05c5eb2135ec,The Sound of Bounding-Boxes,0.0958485,"In the task of audio-visual sound source separation, which leverages visual
information for sound source separation, identifying objects in an image is a
crucial step prior to separating the sound source. However, existing methods
that assign sound on detected bounding boxes suffer from a problem that their
approach heavily relies on pre-trained object detectors. Specifically, when
using these existing methods, it is required to predetermine all the possible
categories of objects that can produce sound and use an object detector
applicable to all such categories. To tackle this problem, we propose a fully
unsupervised method that learns to detect objects in an image and separate
sound source simultaneously. As our method does not rely on any pre-trained
detector, our method is applicable to arbitrary categories without any
additional annotation. Furthermore, although being fully unsupervised, we found
that our method performs comparably in separation accuracy.",https://github.com/openimages,-1
974c7588-e707-4069-8ed1-161bf5cd33d4,Revisiting AP Loss for Dense Object Detection: Adaptive Ranking Pair Selection,0.425304,"Average precision (AP) loss has recently shown promising performance on the
dense object detection task. However,a deep understanding of how AP loss
affects the detector from a pairwise ranking perspective has not yet been
developed.In this work, we revisit the average precision (AP)loss and reveal
that the crucial element is that of selecting the ranking pairs between
positive and negative samples.Based on this observation, we propose two
strategies to improve the AP loss. The first of these is a novel Adaptive
Pairwise Error (APE) loss that focusing on ranking pairs in both positive and
negative samples. Moreover,we select more accurate ranking pairs by exploiting
the normalized ranking scores and localization scores with a clustering
algorithm. Experiments conducted on the MSCOCO dataset support our analysis and
demonstrate the superiority of our proposed method compared with current
classification and ranking loss. The code is available at
https://github.com/Xudangliatiger/APE-Loss.",https://github.com/Xudangliatiger/APE-Loss,-1
55ca43f7-d2d5-4150-80ef-4e6ad69b31f3,A Web Application for Experimenting and Validating Remote Measurement of Vital Signs,0.490844,"With a surge in online medical advising remote monitoring of patient vitals
is required. This can be facilitated with the Remote Photoplethysmography
(rPPG) techniques that compute vital signs from facial videos. It involves
processing video frames to obtain skin pixels, extracting the cardiac data from
it and applying signal processing filters to extract the Blood Volume Pulse
(BVP) signal. Different algorithms are applied to the BVP signal to estimate
the various vital signs. We implemented a web application framework to measure
a person's Heart Rate (HR), Heart Rate Variability (HRV), Oxygen Saturation
(SpO2), Respiration Rate (RR), Blood Pressure (BP), and stress from the face
video. The rPPG technique is highly sensitive to illumination and motion
variation. The web application guides the users to reduce the noise due to
these variations and thereby yield a cleaner BVP signal. The accuracy and
robustness of the framework was validated with the help of volunteers.",None,-1
47e2d540-ac4e-404a-b11d-f24f2bcde11e,"EMMT: A simultaneous eye-tracking, 4-electrode EEG and audio corpus for multi-modal reading and translation scenarios",0.353492,"We present the Eyetracked Multi-Modal Translation (EMMT) corpus, a dataset
containing monocular eye movement recordings, audio and 4-electrode
electroencephalogram (EEG) data of 43 participants. The objective was to
collect cognitive signals as responses of participants engaged in a number of
language intensive tasks involving different text-image stimuli settings when
translating from English to Czech.
  Each participant was exposed to 32 text-image stimuli pairs and asked to (1)
read the English sentence, (2) translate it into Czech, (3) consult the image,
(4) translate again, either updating or repeating the previous translation. The
text stimuli consisted of 200 unique sentences with 616 unique words coupled
with 200 unique images as the visual stimuli.
  The recordings were collected over a two week period and all the participants
included in the study were Czech natives with strong English skills. Due to the
nature of the tasks involved in the study and the relatively large number of
participants involved, the corpus is well suited for research in Translation
Process Studies, Cognitive Sciences among other disciplines.",https://github.com/NEUREM3/recording-code-for-eyetracked-multi-modal-translation,-1
a01bb471-a050-444b-b3cc-6ddc2c38c86b,SpanProto: A Two-stage Span-based Prototypical Network for Few-shot Named Entity Recognition,0.722004,"Few-shot Named Entity Recognition (NER) aims to identify named entities with
very little annotated data. Previous methods solve this problem based on
token-wise classification, which ignores the information of entity boundaries,
and inevitably the performance is affected by the massive non-entity tokens. To
this end, we propose a seminal span-based prototypical network (SpanProto) that
tackles few-shot NER via a two-stage approach, including span extraction and
mention classification. In the span extraction stage, we transform the
sequential tags into a global boundary matrix, enabling the model to focus on
the explicit boundary information. For mention classification, we leverage
prototypical learning to capture the semantic representations for each labeled
span and make the model better adapt to novel-class entities. To further
improve the model performance, we split out the false positives generated by
the span extractor but not labeled in the current episode set, and then present
a margin-based loss to separate them from each prototype region. Experiments
over multiple benchmarks demonstrate that our model outperforms strong
baselines by a large margin.",https://github.com/alibaba/EasyNLP,-1
73913274-54d6-49ab-a5fe-ca43247ad24f,Path-Aware Graph Attention for HD Maps in Motion Prediction,0.786419,"The success of motion prediction for autonomous driving relies on integration
of information from the HD maps. As maps are naturally graph-structured,
investigation on graph neural networks (GNNs) for encoding HD maps is
burgeoning in recent years. However, unlike many other applications where GNNs
have been straightforwardly deployed, HD maps are heterogeneous graphs where
vertices (lanes) are connected by edges (lane-lane interaction relationships)
of various nature, and most graph-based models are not designed to understand
the variety of edge types which provide crucial cues for predicting how the
agents would travel the lanes. To overcome this challenge, we propose
Path-Aware Graph Attention, a novel attention architecture that infers the
attention between two vertices by parsing the sequence of edges forming the
paths that connect them. Our analysis illustrates how the proposed attention
mechanism can facilitate learning in a didactic problem where existing graph
networks like GCN struggle. By improving map encoding, the proposed model
surpasses previous state of the art on the Argoverse Motion Forecasting
dataset, and won the first place in the 2021 Argoverse Motion Forecasting
Competition.",None,-1
d468048f-d31a-48c6-b1ab-1b136574a704,Active Learning Framework to Automate NetworkTraffic Classification,0.203338,"Recent network traffic classification methods benefitfrom machine learning
(ML) technology. However, there aremany challenges due to use of ML, such as:
lack of high-qualityannotated datasets, data-drifts and other effects causing
aging ofdatasets and ML models, high volumes of network traffic etc. Thispaper
argues that it is necessary to augment traditional workflowsof ML
training&deployment and adapt Active Learning concepton network traffic
analysis. The paper presents a novel ActiveLearning Framework (ALF) to address
this topic. ALF providesprepared software components that can be used to deploy
an activelearning loop and maintain an ALF instance that continuouslyevolves a
dataset and ML model automatically. The resultingsolution is deployable for IP
flow-based analysis of high-speed(100 Gb/s) networks, and also supports
research experiments ondifferent strategies and methods for annotation,
evaluation, datasetoptimization, etc. Finally, the paper lists some research
challengesthat emerge from the first experiments with ALF in practice.",https://github.com/CESNET/ALF,-1
008f2906-433c-43d7-8d7a-b33041c8cdfd,Learning Classifier Systems for Self-Explaining Socio-Technical-Systems,0.388717,"In socio-technical settings, operators are increasingly assisted by decision
support systems. By employing these, important properties of socio-technical
systems such as self-adaptation and self-optimization are expected to improve
further. To be accepted by and engage efficiently with operators, decision
support systems need to be able to provide explanations regarding the reasoning
behind specific decisions. In this paper, we propose the usage of Learning
Classifier Systems, a family of rule-based machine learning methods, to
facilitate transparent decision making and highlight some techniques to improve
that. We then present a template of seven questions to assess
application-specific explainability needs and demonstrate their usage in an
interview-based case study for a manufacturing scenario. We find that the
answers received did yield useful insights for a well-designed LCS model and
requirements to have stakeholders actively engage with an intelligent agent.",None,-1
77e28296-5960-409d-81ff-862ee5620125,Seeing Like a Toolkit: How Toolkits Envision the Work of AI Ethics,0.946931,"Numerous toolkits have been developed to support ethical AI development.
However, toolkits, like all tools, encode assumptions in their design about
what work should be done and how. In this paper, we conduct a qualitative
analysis of 27 AI ethics toolkits to critically examine how the work of ethics
is imagined and how it is supported by these toolkits. Specifically, we examine
the discourses toolkits rely on when talking about ethical issues, who they
imagine should do the work of ethics, and how they envision the work practices
involved in addressing ethics. Among the toolkits, we identify a mismatch
between the imagined work of ethics and the support the toolkits provide for
doing that work. In particular, we identify a lack of guidance around how to
navigate labor, organizational, and institutional power dynamics as they relate
to performing ethical work. We use these omissions to chart future work for
researchers and designers of AI ethics toolkits.",None,-1
4399ce8c-c6fb-42ca-98a1-19c1979199cb,Incremental Online Learning Algorithms Comparison for Gesture and Visual Smart Sensors,0.352106,"Tiny machine learning (TinyML) in IoT systems exploits MCUs as edge devices
for data processing. However, traditional TinyML methods can only perform
inference, limited to static environments or classes. Real case scenarios
usually work in dynamic environments, thus drifting the context where the
original neural model is no more suitable. For this reason, pre-trained models
reduce accuracy and reliability during their lifetime because the data recorded
slowly becomes obsolete or new patterns appear. Continual learning strategies
maintain the model up to date, with runtime fine-tuning of the parameters. This
paper compares four state-of-the-art algorithms in two real applications: i)
gesture recognition based on accelerometer data and ii) image classification.
Our results confirm these systems' reliability and the feasibility of deploying
them in tiny-memory MCUs, with a drop in the accuracy of a few percentage
points with respect to the original models for unconstrained computing
platforms.",https://gitlab.com/alba11/,-1
983263ed-8a83-4ae4-9d9e-5e73eca3c3f6,Creativity in translation: machine translation as a constraint for literary texts,0.730876,"This article presents the results of a study involving the translation of a
short story by Kurt Vonnegut from English to Catalan and Dutch using three
modalities: machine-translation (MT), post-editing (PE) and translation without
aid (HT). Our aim is to explore creativity, understood to involve novelty and
acceptability, from a quantitative perspective. The results show that HT has
the highest creativity score, followed by PE, and lastly, MT, and this is
unanimous from all reviewers. A neural MT system trained on literary data does
not currently have the necessary capabilities for a creative translation; it
renders literal solutions to translation problems. More importantly, using MT
to post-edit raw output constrains the creativity of translators, resulting in
a poorer translation often not fit for publication, according to experts.",None,-1
8e849333-d3e7-4d2e-9d4d-2ab0c2ffc423,On amortizing convex conjugates for optimal transport,0.967344,"This paper focuses on computing the convex conjugate operation that arises
when solving Euclidean Wasserstein-2 optimal transport problems. This
conjugation, which is also referred to as the Legendre-Fenchel conjugate or
c-transform,is considered difficult to compute and in practice,Wasserstein-2
methods are limited by not being able to exactly conjugate the dual potentials
in continuous space. To overcome this, the computation of the conjugate can be
approximated with amortized optimization, which learns a model to predict the
conjugate. I show that combining amortized approximations to the conjugate with
a solver for fine-tuning significantly improves the quality of transport maps
learned for the Wasserstein-2 benchmark by Korotin et al. (2021a) and is able
to model many 2-dimensional couplings and flows considered in the literature.
All of the baselines, methods, and solvers in this paper are available at
http://github.com/facebookresearch/w2ot.",http://github.com/facebookresearch/w2ot,-1
90c756f1-d1ae-4d49-880f-bebb02905e83,SELC: Self-Ensemble Label Correction Improves Learning with Noisy Labels,0.833861,"Deep neural networks are prone to overfitting noisy labels, resulting in poor
generalization performance. To overcome this problem, we present a simple and
effective method self-ensemble label correction (SELC) to progressively correct
noisy labels and refine the model. We look deeper into the memorization
behavior in training with noisy labels and observe that the network outputs are
reliable in the early stage. To retain this reliable knowledge, SELC uses
ensemble predictions formed by an exponential moving average of network outputs
to update the original noisy labels. We show that training with SELC refines
the model by gradually reducing supervision from noisy labels and increasing
supervision from ensemble predictions. Despite its simplicity, compared with
many state-of-the-art methods, SELC obtains more promising and stable results
in the presence of class-conditional, instance-dependent, and real-world label
noise. The code is available at https://github.com/MacLLL/SELC.",https://github.com/MacLLL/SELC,-1
7fa0b7e0-9241-4d50-8dd5-06fcf59aeaae,Offline Reinforcement Learning with Differential Privacy,0.571326,"The offline reinforcement learning (RL) problem is often motivated by the
need to learn data-driven decision policies in financial, legal and healthcare
applications. However, the learned policy could retain sensitive information of
individuals in the training data (e.g., treatment and outcome of patients),
thus susceptible to various privacy risks. We design offline RL algorithms with
differential privacy guarantees which provably prevent such risks. These
algorithms also enjoy strong instance-dependent learning bounds under both
tabular and linear Markov decision process (MDP) settings. Our theory and
simulation suggest that the privacy guarantee comes at (almost) no drop in
utility comparing to the non-private counterpart for a medium-size dataset.",None,-1
47b869b7-4ff8-4add-8337-030308c21947,VoloGAN: Adversarial Domain Adaptation for Synthetic Depth Data,0.119694,"We present VoloGAN, an adversarial domain adaptation network that translates
synthetic RGB-D images of a high-quality 3D model of a person, into RGB-D
images that could be generated with a consumer depth sensor. This system is
especially useful to generate high amount training data for single-view 3D
reconstruction algorithms replicating the real-world capture conditions, being
able to imitate the style of different sensor types, for the same high-end 3D
model database. The network uses a CycleGAN framework with a U-Net architecture
for the generator and a discriminator inspired by SIV-GAN. We use different
optimizers and learning rate schedules to train the generator and the
discriminator. We further construct a loss function that considers image
channels individually and, among other metrics, evaluates the structural
similarity. We demonstrate that CycleGANs can be used to apply adversarial
domain adaptation of synthetic 3D data to train a volumetric video generator
model having only few training samples.",None,-1
bd76d05a-010d-4ef9-8a99-e96e95ca87f2,The Internet of Senses: Building on Semantic Communications and Edge Intelligence,0.853393,"The Internet of Senses (IoS) holds the promise of flawless telepresence-style
communication for all human `receptors' and therefore blurs the difference of
virtual and real environments. We commence by highlighting the compelling use
cases empowered by the IoS and also the key network requirements. We then
elaborate on how the emerging semantic communications and Artificial
Intelligence (AI)/Machine Learning (ML) paradigms along with 6G technologies
may satisfy the requirements of IoS use cases. On one hand, semantic
communications can be applied for extracting meaningful and significant
information and hence efficiently exploit the resources and for harnessing a
priori information at the receiver to satisfy IoS requirements. On the other
hand, AI/ML facilitates frugal network resource management by making use of the
enormous amount of data generated in IoS edge nodes and devices, as well as by
optimizing the IoS performance via intelligent agents. However, the intelligent
agents deployed at the edge are not completely aware of each others' decisions
and the environments of each other, hence they operate in a partially rather
than fully observable environment. Therefore, we present a case study of
Partially Observable Markov Decision Processes (POMDP) for improving the User
Equipment (UE) throughput and energy consumption, as they are imperative for
IoS use cases, using Reinforcement Learning for astutely activating and
deactivating the component carriers in carrier aggregation. Finally, we outline
the challenges and open issues of IoS implementations and employing semantic
communications, edge intelligence as well as learning under partial
observability in the IoS context.",None,-1
0dfb41f0-003b-4bb8-ba9a-4fa4072f29ee,Objects Matter: Learning Object Relation Graph for Robust Camera Relocalization,0.116451,"Visual relocalization aims to estimate the pose of a camera from one or more
images. In recent years deep learning based pose regression methods have
attracted many attentions. They feature predicting the absolute poses without
relying on any prior built maps or stored images, making the relocalization
very efficient. However, robust relocalization under environments with complex
appearance changes and real dynamics remains very challenging. In this paper,
we propose to enhance the distinctiveness of the image features by extracting
the deep relationship among objects. In particular, we extract objects in the
image and construct a deep object relation graph (ORG) to incorporate the
semantic connections and relative spatial clues of the objects. We integrate
our ORG module into several popular pose regression models. Extensive
experiments on various public indoor and outdoor datasets demonstrate that our
method improves the performance significantly and outperforms the previous
approaches.",None,1155
69640d9f-25c8-49ab-a01b-c88e912e8191,Gaussian Multi-head Attention for Simultaneous Machine Translation,0.607292,"Simultaneous machine translation (SiMT) outputs translation while receiving
the streaming source inputs, and hence needs a policy to determine where to
start translating. The alignment between target and source words often implies
the most informative source word for each target word, and hence provides the
unified control over translation quality and latency, but unfortunately the
existing SiMT methods do not explicitly model the alignment to perform the
control. In this paper, we propose Gaussian Multi-head Attention (GMA) to
develop a new SiMT policy by modeling alignment and translation in a unified
manner. For SiMT policy, GMA models the aligned source position of each target
word, and accordingly waits until its aligned position to start translating. To
integrate the learning of alignment into the translation model, a Gaussian
distribution centered on predicted aligned position is introduced as an
alignment-related prior, which cooperates with translation-related soft
attention to determine the final attention. Experiments on En-Vi and De-En
tasks show that our method outperforms strong baselines on the trade-off
between translation and latency.",https://github.com/ictnlp/GMA,-1
52ecb704-7e02-4d1e-9538-062dca061b9f,End-to-End Image-Based Fashion Recommendation,0.703351,"In fashion-based recommendation settings, incorporating the item image
features is considered a crucial factor, and it has shown significant
improvements to many traditional models, including but not limited to matrix
factorization, auto-encoders, and nearest neighbor models. While there are
numerous image-based recommender approaches that utilize dedicated deep neural
networks, comparisons to attribute-aware models are often disregarded despite
their ability to be easily extended to leverage items' image features. In this
paper, we propose a simple yet effective attribute-aware model that
incorporates image features for better item representation learning in item
recommendation tasks. The proposed model utilizes items' image features
extracted by a calibrated ResNet50 component. We present an ablation study to
compare incorporating the image features using three different techniques into
the recommender system component that can seamlessly leverage any available
items' attributes. Experiments on two image-based real-world recommender
systems datasets show that the proposed model significantly outperforms all
state-of-the-art image-based models.",https://github.com/Shereen-Elsayed/ImgRec,-1
e1768579-fd7b-43dc-b3cb-6c75a5d279e3,Holistic Interaction Transformer Network for Action Detection,0.850023,"Actions are about how we interact with the environment, including other
people, objects, and ourselves. In this paper, we propose a novel multi-modal
Holistic Interaction Transformer Network (HIT) that leverages the largely
ignored, but critical hand and pose information essential to most human
actions. The proposed ""HIT"" network is a comprehensive bi-modal framework that
comprises an RGB stream and a pose stream. Each of them separately models
person, object, and hand interactions. Within each sub-network, an
Intra-Modality Aggregation module (IMA) is introduced that selectively merges
individual interaction units. The resulting features from each modality are
then glued using an Attentive Fusion Mechanism (AFM). Finally, we extract cues
from the temporal context to better classify the occurring actions using cached
memory. Our method significantly outperforms previous approaches on the J-HMDB,
UCF101-24, and MultiSports datasets. We also achieve competitive results on
AVA. The code will be available at https://github.com/joslefaure/HIT.",https://github.com/joslefaure/HIT,-1
634ab71f-07b1-4d26-a622-4a743fa0a591,MOVE: Unsupervised Movable Object Segmentation and Detection,0.560396,"We introduce MOVE, a novel method to segment objects without any form of
supervision. MOVE exploits the fact that foreground objects can be shifted
locally relative to their initial position and result in realistic
(undistorted) new images. This property allows us to train a segmentation model
on a dataset of images without annotation and to achieve state of the art
(SotA) performance on several evaluation datasets for unsupervised salient
object detection and segmentation. In unsupervised single object discovery,
MOVE gives an average CorLoc improvement of 7.2% over the SotA, and in
unsupervised class-agnostic object detection it gives a relative AP improvement
of 53% on average. Our approach is built on top of self-supervised features
(e.g. from DINO or MAE), an inpainting network (based on the Masked
AutoEncoder) and adversarial training.",None,-1
a872af26-07b0-48bd-a675-c9b85f386901,Interactive Grounded Language Understanding in a Collaborative Environment: IGLU 2021,0.794019,"Human intelligence has the remarkable ability to quickly adapt to new tasks
and environments. Starting from a very young age, humans acquire new skills and
learn how to solve new tasks either by imitating the behavior of others or by
following provided natural language instructions. To facilitate research in
this direction, we propose \emph{IGLU: Interactive Grounded Language
Understanding in a Collaborative Environment}.
  The primary goal of the competition is to approach the problem of how to
build interactive agents that learn to solve a task while provided with
grounded natural language instructions in a collaborative environment.
Understanding the complexity of the challenge, we split it into sub-tasks to
make it feasible for participants.",None,-1
7e4cfba2-e1ec-4fbe-b5b8-4381d7861c4e,The Alberta Plan for AI Research,0.747482,"Herein we describe our approach to artificial intelligence research, which we
call the Alberta Plan. The Alberta Plan is pursued within our research groups
in Alberta and by others who are like minded throughout the world. We welcome
all who would join us in this pursuit.",None,-1
20268a05-dcc3-4494-8c80-c681295b553c,AutoAdversary: A Pixel Pruning Method for Sparse Adversarial Attack,0.0603421,"Deep neural networks (DNNs) have been proven to be vulnerable to adversarial
examples. A special branch of adversarial examples, namely sparse adversarial
examples, can fool the target DNNs by perturbing only a few pixels. However,
many existing sparse adversarial attacks use heuristic methods to select the
pixels to be perturbed, and regard the pixel selection and the adversarial
attack as two separate steps. From the perspective of neural network pruning,
we propose a novel end-to-end sparse adversarial attack method, namely
AutoAdversary, which can find the most important pixels automatically by
integrating the pixel selection into the adversarial attack. Specifically, our
method utilizes a trainable neural network to generate a binary mask for the
pixel selection. After jointly optimizing the adversarial perturbation and the
neural network, only the pixels corresponding to the value 1 in the mask are
perturbed. Experiments demonstrate the superiority of our proposed method over
several state-of-the-art methods. Furthermore, since AutoAdversary does not
require a heuristic pixel selection process, it does not slow down excessively
as other methods when the image size increases.",https://github.com/wubaoyuan/Sparse-Adversarial-Attack,-1
bbcd76ea-75c2-491f-8c99-0cc6a214d661,Proper Reuse of Image Classification Features Improves Object Detection,0.391092,"A common practice in transfer learning is to initialize the downstream model
weights by pre-training on a data-abundant upstream task. In object detection
specifically, the feature backbone is typically initialized with Imagenet
classifier weights and fine-tuned on the object detection task. Recent works
show this is not strictly necessary under longer training regimes and provide
recipes for training the backbone from scratch. We investigate the opposite
direction of this end-to-end training trend: we show that an extreme form of
knowledge preservation -- freezing the classifier-initialized backbone --
consistently improves many different detection models, and leads to
considerable resource savings. We hypothesize and corroborate experimentally
that the remaining detector components capacity and structure is a crucial
factor in leveraging the frozen backbone. Immediate applications of our
findings include performance improvements on hard cases like detection of
long-tail object classes and computational and memory resource savings that
contribute to making the field more accessible to researchers with access to
fewer computational resources.",https://github.com/tensorflow/models/blob/master/official/projects/backbone_reuse/README.md,-1
03576811-9cd4-4055-9b10-5f47264461f7,The Causal News Corpus: Annotating Causal Relations in Event Sentences from News,0.875968,"Despite the importance of understanding causality, corpora addressing causal
relations are limited. There is a discrepancy between existing annotation
guidelines of event causality and conventional causality corpora that focus
more on linguistics. Many guidelines restrict themselves to include only
explicit relations or clause-based arguments. Therefore, we propose an
annotation schema for event causality that addresses these concerns. We
annotated 3,559 event sentences from protest event news with labels on whether
it contains causal relations or not. Our corpus is known as the Causal News
Corpus (CNC). A neural network built upon a state-of-the-art pre-trained
language model performed well with 81.20% F1 score on test set, and 83.46% in
5-folds cross-validation. CNC is transferable across two external corpora:
CausalTimeBank (CTB) and Penn Discourse Treebank (PDTB). Leveraging each of
these external datasets for training, we achieved up to approximately 64% F1 on
the CNC test set without additional fine-tuning. CNC also served as an
effective training and pre-training dataset for the two external corpora.
Lastly, we demonstrate the difficulty of our task to the layman in a
crowd-sourced annotation exercise. Our annotated corpus is publicly available,
providing a valuable resource for causal text mining researchers.",https://github.com/tanfiona/,-1
763a7072-d35f-4b46-a855-b8df900b48d6,Massively Digitized Power Grid: Opportunities and Challenges of Use-inspired AI,0.721697,"This article presents a use-inspired perspective of the opportunities and
challenges in a massively digitized power grid. It argues that the intricate
interplay of data availability, computing capability, and artificial
intelligence (AI) algorithm development are the three key factors driving the
adoption of digitized solutions in the power grid. The impact of these three
factors on critical functions of power system operation and planning practices
are reviewed and illustrated with industrial practice case studies. Open
challenges and research opportunities for data, computing, and AI algorithms
are articulated within the context of the power industry's tremendous
decarbonization efforts.",None,-1
d132656b-9ee6-4f89-9c58-ac8fd0b3f2fb,Overview of the Shared Task on Fake News Detection in Urdu at FIRE 2021,0.843807,"Automatic detection of fake news is a highly important task in the
contemporary world. This study reports the 2nd shared task called
UrduFake@FIRE2021 on identifying fake news detection in Urdu. The goal of the
shared task is to motivate the community to come up with efficient methods for
solving this vital problem, particularly for the Urdu language. The task is
posed as a binary classification problem to label a given news article as a
real or a fake news article. The organizers provide a dataset comprising news
in five domains: (i) Health, (ii) Sports, (iii) Showbiz, (iv) Technology, and
(v) Business, split into training and testing sets. The training set contains
1300 annotated news articles -- 750 real news, 550 fake news, while the testing
set contains 300 news articles -- 200 real, 100 fake news. 34 teams from 7
different countries (China, Egypt, Israel, India, Mexico, Pakistan, and UAE)
registered to participate in the UrduFake@FIRE2021 shared task. Out of those,
18 teams submitted their experimental results, and 11 of those submitted their
technical reports, which is substantially higher compared to the UrduFake
shared task in 2020 when only 6 teams submitted their technical reports. The
technical reports submitted by the participants demonstrated different data
representation techniques ranging from count-based BoW features to word vector
embeddings as well as the use of numerous machine learning algorithms ranging
from traditional SVM to various neural network architectures including
Transformers such as BERT and RoBERTa. In this year's competition, the best
performing system obtained an F1-macro score of 0.679, which is lower than the
past year's best result of 0.907 F1-macro. Admittedly, while training sets from
the past and the current years overlap to a large extent, the testing set
provided this year is completely different.",https://github.com/MaazAmjad/Urdu-Fake-news-detection-FIRE2021,-1
8dc74876-ee13-48c0-8175-5e15b77fc3e2,CD$^2$: Fine-grained 3D Mesh Reconstruction With Twice Chamfer Distance,0.0496543,"Monocular 3D reconstruction is to reconstruct the shape of object and its
other information from a single RGB image. In 3D reconstruction, polygon mesh,
with detailed surface information and low computational cost, is the most
prevalent expression form obtained from deep learning models. However, the
state-of-the-art schemes fail to directly generate well-structured meshes, and
we identify that most meshes have severe Vertices Clustering (VC) and Illegal
Twist (IT) problems. By analyzing the mesh deformation process, we pinpoint
that the inappropriate usage of Chamfer Distance (CD) loss is a root cause of
VC and IT problems in deep learning model. In this paper, we initially
demonstrate these two problems induced by CD loss with visual examples and
quantitative analyses. Then, we propose a fine-grained reconstruction method
CD$^2$ by employing Chamfer distance twice to perform a plausible and adaptive
deformation. Extensive experiments on two 3D datasets and comparisons with five
latest schemes demonstrate that our CD$^2$ directly generates a well-structured
mesh and outperforms others in terms of several quantitative metrics.",https://github.com/ThibaultGROUEIX/ChamferDistancePytorch,-1
f61c3979-716e-4174-b914-80e2a642cd19,Apple of Sodom: Hidden Backdoors in Superior Sentence Embeddings via Contrastive Learning,0.0352784,"This paper finds that contrastive learning can produce superior sentence
embeddings for pre-trained models but is also vulnerable to backdoor attacks.
We present the first backdoor attack framework, BadCSE, for state-of-the-art
sentence embeddings under supervised and unsupervised learning settings. The
attack manipulates the construction of positive and negative pairs so that the
backdoored samples have a similar embedding with the target sample (targeted
attack) or the negative embedding of its clean version (non-targeted attack).
By injecting the backdoor in sentence embeddings, BadCSE is resistant against
downstream fine-tuning. We evaluate BadCSE on both STS tasks and other
downstream tasks. The supervised non-targeted attack obtains a performance
degradation of 194.86%, and the targeted attack maps the backdoored samples to
the target embedding with a 97.70% success rate while maintaining the model
utility.",None,-1
75a2bc5d-e545-4a1d-be33-d2426fecd16b,MIRROR: Differentiable Deep Social Projection for Assistive Human-Robot Communication,0.68292,"Communication is a hallmark of intelligence. In this work, we present MIRROR,
an approach to (i) quickly learn human models from human demonstrations, and
(ii) use the models for subsequent communication planning in assistive
shared-control settings. MIRROR is inspired by social projection theory, which
hypothesizes that humans use self-models to understand others. Likewise, MIRROR
leverages self-models learned using reinforcement learning to bootstrap human
modeling. Experiments with simulated humans show that this approach leads to
rapid learning and more robust models compared to existing behavioral cloning
and state-of-the-art imitation learning methods. We also present a
human-subject study using the CARLA simulator which shows that (i) MIRROR is
able to scale to complex domains with high-dimensional observations and
complicated world physics and (ii) provides effective assistive communication
that enabled participants to drive more safely in adverse weather conditions.",https://github.com/clear-nus/mirror,-1
b04fb4d5-1407-46f2-a179-c4269a443702,CL3D: Unsupervised Domain Adaptation for Cross-LiDAR 3D Detection,0.527695,"Domain adaptation for Cross-LiDAR 3D detection is challenging due to the
large gap on the raw data representation with disparate point densities and
point arrangements. By exploring domain-invariant 3D geometric characteristics
and motion patterns, we present an unsupervised domain adaptation method that
overcomes above difficulties. First, we propose the Spatial Geometry Alignment
module to extract similar 3D shape geometric features of the same object class
to align two domains, while eliminating the effect of distinct point
distributions. Second, we present Temporal Motion Alignment module to utilize
motion features in sequential frames of data to match two domains. Prototypes
generated from two modules are incorporated into the pseudo-label reweighting
procedure and contribute to our effective self-training framework for the
target domain. Extensive experiments show that our method achieves
state-of-the-art performance on cross-device datasets, especially for the
datasets with large gaps captured by mechanical scanning LiDARs and solid-state
LiDARs in various scenes. Project homepage is at
https://github.com/4DVLab/CL3D.git",https://github.com/4DVLab/CL3D.git,-1
ec6e56c4-16c6-4bb2-9f85-27bfe947f58c,Self-conditioned Embedding Diffusion for Text Generation,0.65196,"Can continuous diffusion models bring the same performance breakthrough on
natural language they did for image generation? To circumvent the discrete
nature of text data, we can simply project tokens in a continuous space of
embeddings, as is standard in language modeling. We propose Self-conditioned
Embedding Diffusion, a continuous diffusion mechanism that operates on token
embeddings and allows to learn flexible and scalable diffusion models for both
conditional and unconditional text generation. Through qualitative and
quantitative evaluation, we show that our text diffusion models generate
samples comparable with those produced by standard autoregressive language
models - while being in theory more efficient on accelerator hardware at
inference time. Our work paves the way for scaling up diffusion models for
text, similarly to autoregressive models, and for improving performance with
recent refinements to continuous diffusion.",None,-1
9845c274-2798-4382-b70d-493cdda8bc59,MotionDiffuse: Text-Driven Human Motion Generation with Diffusion Model,0.999818,"Human motion modeling is important for many modern graphics applications,
which typically require professional skills. In order to remove the skill
barriers for laymen, recent motion generation methods can directly generate
human motions conditioned on natural languages. However, it remains challenging
to achieve diverse and fine-grained motion generation with various text inputs.
To address this problem, we propose MotionDiffuse, the first diffusion
model-based text-driven motion generation framework, which demonstrates several
desired properties over existing methods. 1) Probabilistic Mapping. Instead of
a deterministic language-motion mapping, MotionDiffuse generates motions
through a series of denoising steps in which variations are injected. 2)
Realistic Synthesis. MotionDiffuse excels at modeling complicated data
distribution and generating vivid motion sequences. 3) Multi-Level
Manipulation. MotionDiffuse responds to fine-grained instructions on body
parts, and arbitrary-length motion synthesis with time-varied text prompts. Our
experiments show MotionDiffuse outperforms existing SoTA methods by convincing
margins on text-driven motion generation and action-conditioned motion
generation. A qualitative analysis further demonstrates MotionDiffuse's
controllability for comprehensive motion generation. Homepage:
https://mingyuan-zhang.github.io/projects/MotionDiffuse.html",https://mingyuan-zhang.github.io/projects/MotionDiffuse.html,-1
1c46b6ca-4c4c-48ed-a8b9-271590eca9a8,AIONER: All-in-one scheme-based biomedical named entity recognition using deep learning,0.806545,"Biomedical named entity recognition (BioNER) seeks to automatically recognize
biomedical entities in natural language text, serving as a necessary foundation
for downstream text mining tasks and applications such as information
extraction and question answering. Manually labeling training data for the
BioNER task is costly, however, due to the significant domain expertise
required for accurate annotation. The resulting data scarcity causes current
BioNER approaches to be prone to overfitting, to suffer from limited
generalizability, and to address a single entity type at a time (e.g., gene or
disease). We therefore propose a novel all-in-one (AIO) scheme that uses
external data from existing annotated resources to enhance the accuracy and
stability of BioNER models. We further present AIONER, a general-purpose BioNER
tool based on cutting-edge deep learning and our AIO schema. We evaluate AIONER
on 14 BioNER benchmark tasks and show that AIONER is effective, robust, and
compares favorably to other state-of-the-art approaches such as multi-task
learning. We further demonstrate the practical utility of AIONER in three
independent tasks to recognize entity types not previously seen in training
data, as well as the advantages of AIONER over existing methods for processing
biomedical text at a large scale (e.g., the entire PubMed data).",None,-1
c9247dc2-a830-4c8a-98a2-28c4a926d610,Parametric Classification for Generalized Category Discovery: A Baseline Study,0.407653,"Generalized Category Discovery (GCD) aims to discover novel categories in
unlabelled datasets using knowledge learned from labelled samples. Previous
studies argued that parametric classifiers are prone to overfitting to seen
categories, and endorsed using a non-parametric classifier formed with
semi-supervised k-means. However, in this study, we investigate the failure of
parametric classifiers, verify the effectiveness of previous design choices
when high-quality supervision is available, and identify unreliable
pseudo-labels as a key problem. We demonstrate that two prediction biases
exist: the classifier tends to predict seen classes more often, and produces an
imbalanced distribution across seen and novel categories. Based on these
findings, we propose a simple yet effective parametric classification method
that benefits from entropy regularisation, achieves state-of-the-art
performance on multiple GCD benchmarks and shows strong robustness to unknown
class numbers. We hope the investigation and proposed simple framework can
serve as a strong baseline to facilitate future studies in this field. Our code
is available at: https://github.com/CVMI-Lab/SimGCD.",https://github.com/CVMI-Lab/SimGCD,-1
07dfdb23-8990-4842-9db0-9c932cd4afbe,Estimating the Uncertainty in Emotion Class Labels with Utterance-Specific Dirichlet Priors,0.398536,"Emotion recognition is a key attribute for artificial intelligence systems
that need to naturally interact with humans. However, the task definition is
still an open problem due to the inherent ambiguity of emotions. In this paper,
a novel Bayesian training loss based on per-utterance Dirichlet prior
distributions is proposed for verbal emotion recognition, which models the
uncertainty in one-hot labels created when human annotators assign the same
utterance to different emotion classes. An additional metric is used to
evaluate the performance by detection test utterances with high labelling
uncertainty. This removes a major limitation that emotion classification
systems only consider utterances with labels where the majority of annotators
agree on the emotion class. Furthermore, a frequentist approach is studied to
leverage the continuous-valued ""soft"" labels obtained by averaging the one-hot
labels. We propose a two-branch model structure for emotion classification on a
per-utterance basis, which achieves state-of-the-art classification results on
the widely used IEMOCAP dataset. Based on this, uncertainty estimation
experiments were performed. The best performance in terms of the area under the
precision-recall curve when detecting utterances with high uncertainty was
achieved by interpolating the Bayesian training loss with the Kullback-Leibler
divergence training loss for the soft labels. The generality of the proposed
approach was verified using the MSP-Podcast dataset which yielded the same
pattern of results.",None,-1
2f3e2ccb-6f53-4f4c-84dc-a7ecdcfd69b3,TurbuGAN: An Adversarial Learning Approach to Spatially-Varying Multiframe Blind Deconvolution with Applications to Imaging Through Turbulence,0.950213,"We present a self-supervised and self-calibrating multi-shot approach to
imaging through atmospheric turbulence, called TurbuGAN. Our approach requires
no paired training data, adapts itself to the distribution of the turbulence,
leverages domain-specific data priors, and can generalize from tens to
thousands of measurements. We achieve such functionality through an adversarial
sensing framework adapted from CryoGAN, which uses a discriminator network to
match the distributions of captured and simulated measurements. Our framework
builds on CryoGAN by (1) generalizing the forward measurement model to
incorporate physically accurate and computationally efficient models for light
propagation through anisoplanatic turbulence, (2) enabling adaptation to
slightly misspecified forward models, and (3) leveraging domain-specific prior
knowledge using pretrained generative networks, when available. We validate
TurbuGAN on both computationally simulated and experimentally captured images
distorted with anisoplanatic turbulence.",None,-1
82b0b244-0c99-4d7c-b0f6-9ab32db2af02,UniMSE: Towards Unified Multimodal Sentiment Analysis and Emotion Recognition,0.955418,"Multimodal sentiment analysis (MSA) and emotion recognition in conversation
(ERC) are key research topics for computers to understand human behaviors. From
a psychological perspective, emotions are the expression of affect or feelings
during a short period, while sentiments are formed and held for a longer
period. However, most existing works study sentiment and emotion separately and
do not fully exploit the complementary knowledge behind the two. In this paper,
we propose a multimodal sentiment knowledge-sharing framework (UniMSE) that
unifies MSA and ERC tasks from features, labels, and models. We perform
modality fusion at the syntactic and semantic levels and introduce contrastive
learning between modalities and samples to better capture the difference and
consistency between sentiments and emotions. Experiments on four public
benchmark datasets, MOSI, MOSEI, MELD, and IEMOCAP, demonstrate the
effectiveness of the proposed method and achieve consistent improvements
compared with state-of-the-art methods.",https://github.com/LeMei/UniMSE,-1
8302c488-3cdd-4653-a2d4-2e63f4cab0bf,PREME: Preference-based Meeting Exploration through an Interactive Questionnaire,0.336197,"The recent increase in the volume of online meetings necessitates automated
tools for managing and organizing the material, especially when an attendee has
missed the discussion and needs assistance in quickly exploring it. In this
work, we propose a novel end-to-end framework for generating interactive
questionnaires for preference-based meeting exploration. As a result, users are
supplied with a list of suggested questions reflecting their preferences. Since
the task is new, we introduce an automatic evaluation strategy. Namely, it
measures how much the generated questions via questionnaire are answerable to
ensure factual correctness and covers the source meeting for the depth of
possible exploration.",https://github.com/microsoft/preme,-1
33690b7a-0b2a-45d2-a9a7-ef85984464a3,Housekeep: Tidying Virtual Households using Commonsense Reasoning,0.719296,"We introduce Housekeep, a benchmark to evaluate commonsense reasoning in the
home for embodied AI. In Housekeep, an embodied agent must tidy a house by
rearranging misplaced objects without explicit instructions specifying which
objects need to be rearranged. Instead, the agent must learn from and is
evaluated against human preferences of which objects belong where in a tidy
house. Specifically, we collect a dataset of where humans typically place
objects in tidy and untidy houses constituting 1799 objects, 268 object
categories, 585 placements, and 105 rooms. Next, we propose a modular baseline
approach for Housekeep that integrates planning, exploration, and navigation.
It leverages a fine-tuned large language model (LLM) trained on an internet
text corpus for effective planning. We show that our baseline agent generalizes
to rearranging unseen objects in unknown environments. See our webpage for more
details: https://yashkant.github.io/housekeep/",None,-1
01be5212-c895-4797-8c0a-0228b1124728,Questions Are All You Need to Train a Dense Passage Retriever,0.87667,"We introduce ART, a new corpus-level autoencoding approach for training dense
retrieval models that does not require any labeled training data. Dense
retrieval is a central challenge for open-domain tasks, such as Open QA, where
state-of-the-art methods typically require large supervised datasets with
custom hard-negative mining and denoising of positive examples. ART, in
contrast, only requires access to unpaired inputs and outputs (e.g. questions
and potential answer documents). It uses a new document-retrieval autoencoding
scheme, where (1) an input question is used to retrieve a set of evidence
documents, and (2) the documents are then used to compute the probability of
reconstructing the original question. Training for retrieval based on question
reconstruction enables effective unsupervised learning of both document and
question encoders, which can be later incorporated into complete Open QA
systems without any further finetuning. Extensive experiments demonstrate that
ART obtains state-of-the-art results on multiple QA retrieval benchmarks with
only generic initialization from a pre-trained language model, removing the
need for labeled data and task-specific losses.",https://github.com/DevSinghSachan/art,104111
d41e9eff-d0e9-4d06-ad0e-69a5b53ed719,Pyramidal Denoising Diffusion Probabilistic Models,0.251969,"Recently, diffusion model have demonstrated impressive image generation
performances, and have been extensively studied in various computer vision
tasks. Unfortunately, training and evaluating diffusion models consume a lot of
time and computational resources. To address this problem, here we present a
novel pyramidal diffusion model that can generate high resolution images
starting from much coarser resolution images using a {\em single} score
function trained with a positional embedding. This enables a neural network to
be much lighter and also enables time-efficient image generation without
compromising its performances. Furthermore, we show that the proposed approach
can be also efficiently used for multi-scale super-resolution problem using a
single score function.",https://github.com/openai/improved-diffusion,-1
dbe5dcc6-7ff3-46a6-9b8b-70d8f1409a4c,MonoJSG: Joint Semantic and Geometric Cost Volume for Monocular 3D Object Detection,0.847963,"Due to the inherent ill-posed nature of 2D-3D projection, monocular 3D object
detection lacks accurate depth recovery ability. Although the deep neural
network (DNN) enables monocular depth-sensing from high-level learned features,
the pixel-level cues are usually omitted due to the deep convolution mechanism.
To benefit from both the powerful feature representation in DNN and pixel-level
geometric constraints, we reformulate the monocular object depth estimation as
a progressive refinement problem and propose a joint semantic and geometric
cost volume to model the depth error. Specifically, we first leverage neural
networks to learn the object position, dimension, and dense normalized 3D
object coordinates. Based on the object depth, the dense coordinates patch
together with the corresponding object features is reprojected to the image
space to build a cost volume in a joint semantic and geometric error manner.
The final depth is obtained by feeding the cost volume to a refinement network,
where the distribution of semantic and geometric error is regularized by direct
depth supervision. Through effectively mitigating depth error by the refinement
framework, we achieve state-of-the-art results on both the KITTI and Waymo
datasets.",https://github.com/lianqing11/MonoJSG,-1
4e4b247f-bffa-43e8-90be-8a520342427e,Efficient Reinforcement Learning for Unsupervised Controlled Text Generation,0.103651,"Controlled text generation tasks such as unsupervised text style transfer
have increasingly adopted the use of Reinforcement Learning (RL). A major
challenge in applying RL to such tasks is the sparse reward, which is available
only after the full text is generated. Sparse rewards, combined with a large
action space make RL training sample-inefficient and difficult to converge.
Recently proposed reward-shaping strategies to address this issue have shown
only negligible gains. In contrast, this work proposes a novel approach that
provides dense rewards to each generated token. We evaluate our approach by its
usage in unsupervised text style transfer. Averaged across datasets, our style
transfer system improves upon current state-of-art systems by 21\% on human
evaluation and 12\% on automatic evaluation. Upon ablated comparison with the
current reward shaping approach (the `roll-out strategy'), using dense rewards
improves the overall style transfer quality by 22\% based on human evaluation.
Further the RL training is 2.5 times as sample efficient, and 7 times faster.",https://github.com/huggingface/transformers,-1
e1d4dedc-7e69-4518-89e5-1a4a95903208,AI agents for facilitating social interactions and wellbeing,0.0362305,"Wellbeing AI has been becoming a new trend in individuals' mental health,
organizational health, and flourishing our societies. Various applications of
wellbeing AI have been introduced to our daily lives. While social
relationships within groups are a critical factor for wellbeing, the
development of wellbeing AI for social interactions remains relatively scarce.
In this paper, we provide an overview of the mediative role of AI-augmented
agents for social interactions. First, we discuss the two-dimensional framework
for classifying wellbeing AI: individual/group and analysis/intervention.
Furthermore, wellbeing AI touches on intervening social relationships between
human-human interactions since positive social relationships are key to human
wellbeing. This intervention may raise technical and ethical challenges. We
discuss opportunities and challenges of the relational approach with wellbeing
AI to promote wellbeing in our societies.",None,-1
40f30f44-0408-4f54-8c05-dc9839251109,Cross-modal Learning for Image-Guided Point Cloud Shape Completion,0.487635,"In this paper we explore the recent topic of point cloud completion, guided
by an auxiliary image. We show how it is possible to effectively combine the
information from the two modalities in a localized latent space, thus avoiding
the need for complex point cloud reconstruction methods from single views used
by the state-of-the-art. We also investigate a novel weakly-supervised setting
where the auxiliary image provides a supervisory signal to the training process
by using a differentiable renderer on the completed point cloud to measure
fidelity in the image space. Experiments show significant improvements over
state-of-the-art supervised methods for both unimodal and multimodal
completion. We also show the effectiveness of the weakly-supervised approach
which outperforms a number of supervised methods and is competitive with the
latest supervised models only exploiting point cloud information.",https://github.com/diegovalsesia/XMFnet,-1
846a5760-31cd-42ea-b69a-5ee6c623931f,Speech Synthesis with Mixed Emotions,0.954974,"Emotional speech synthesis aims to synthesize human voices with various
emotional effects. The current studies are mostly focused on imitating an
averaged style belonging to a specific emotion type. In this paper, we seek to
generate speech with a mixture of emotions at run-time. We propose a novel
formulation that measures the relative difference between the speech samples of
different emotions. We then incorporate our formulation into a
sequence-to-sequence emotional text-to-speech framework. During the training,
the framework does not only explicitly characterize emotion styles, but also
explores the ordinal nature of emotions by quantifying the differences with
other emotions. At run-time, we control the model to produce the desired
emotion mixture by manually defining an emotion attribute vector. The objective
and subjective evaluations have validated the effectiveness of the proposed
framework. To our best knowledge, this research is the first study on
modelling, synthesizing, and evaluating mixed emotions in speech.",https://github.com/chaitanya100100/Relative-Attributes-Zero-Emotions-Demo/,-1
7699ffd0-64ca-4274-9525-20642bd60a76,Offline Supervised Learning V.S. Online Direct Policy Optimization: A Comparative Study and A Unified Training Paradigm for Neural Network-Based Optimal Feedback Control,0.510333,"This work is concerned with solving neural network-based feedback controllers
efficiently for optimal control problems. We first conduct a comparative study
of two prevalent approaches: offline supervised learning and online direct
policy optimization. Albeit the training part of the supervised learning
approach is relatively easy, the success of the method heavily depends on the
optimal control dataset generated by open-loop optimal control solvers. In
contrast, direct policy optimization turns the optimal control problem into an
optimization problem directly without any requirement of pre-computing, but the
dynamics-related objective can be hard to optimize when the problem is
complicated. Our results underscore the superiority of offline supervised
learning in terms of both optimality and training time. To overcome the main
challenges, dataset and optimization, in the two approaches respectively, we
complement them and propose the Pre-train and Fine-tune strategy as a unified
training paradigm for optimal feedback control, which further improves the
performance and robustness significantly. Our code is accessible at
https://github.com/yzhao98/DeepOptimalControl.",https://github.com/yzhao98/DeepOptimalControl,-1
d4020628-cd0a-44bd-b296-146ddd0e3d5e,Punctuation Restoration in Spanish Customer Support Transcripts using Transfer Learning,0.0229185,"Automatic Speech Recognition (ASR) systems typically produce unpunctuated
transcripts that have poor readability. In addition, building a punctuation
restoration system is challenging for low-resource languages, especially for
domain-specific applications. In this paper, we propose a Spanish punctuation
restoration system designed for a real-time customer support transcription
service. To address the data sparsity of Spanish transcripts in the customer
support domain, we introduce two transfer-learning-based strategies: 1) domain
adaptation using out-of-domain Spanish text data; 2) cross-lingual transfer
learning leveraging in-domain English transcript data. Our experiment results
show that these strategies improve the accuracy of the Spanish punctuation
restoration system.",None,-1
6a9b8da3-0b4f-4420-bbea-e6c23a16856d,A Minimal Deductive System for RDFS with Negative Statements,0.182602,"The triple language RDFS is designed to represent and reason with
\emph{positive} statements only (e.g.""antipyretics are drugs"").
  In this paper we show how to extend RDFS to express and reason with various
forms of negative statements under the Open World Assumption (OWA). To do so,
we start from $\rho df$, a minimal, but significant RDFS fragment that covers
all essential features of RDFS, and then extend it to $\rho df_\bot^\neg$,
allowing express also statements such as ""radio therapies are non drug
treatments"", ""Ebola has no treatment"", or ""opioids and antipyretics are
disjoint classes"". The main and, to the best of our knowledge, unique features
of our proposal are: (i) $\rho df_\bot^\neg$ remains syntactically a triple
language by extending $\rho df$ with new symbols with specific semantics and
there is no need to revert to the reification method to represent negative
triples; (ii) the logic is defined in such a way that any RDFS reasoner/store
may handle the new predicates as ordinary terms if it does not want to take
account of the extra capabilities; (iii) despite negated statements, every
$\rho df_\bot^\neg$ knowledge base is satisfiable; (iv) the $\rho df_\bot^\neg$
entailment decision procedure is obtained from $\rho df$ via additional
inference rules favouring a potential implementation; and (v) deciding
entailment in $\rho df_\bot^\neg$ ranges from P to NP.",None,-1
1b33a33e-4f1a-44ef-96d6-21c1c5d9bdb1,A Hierarchical Bayesian Approach to Inverse Reinforcement Learning with Symbolic Reward Machines,0.596133,"A misspecified reward can degrade sample efficiency and induce undesired
behaviors in reinforcement learning (RL) problems. We propose symbolic reward
machines for incorporating high-level task knowledge when specifying the reward
signals. Symbolic reward machines augment existing reward machine formalism by
allowing transitions to carry predicates and symbolic reward outputs. This
formalism lends itself well to inverse reinforcement learning, whereby the key
challenge is determining appropriate assignments to the symbolic values from a
few expert demonstrations. We propose a hierarchical Bayesian approach for
inferring the most likely assignments such that the concretized reward machine
can discriminate expert demonstrated trajectories from other trajectories with
high accuracy. Experimental results show that learned reward machines can
significantly improve training efficiency for complex RL tasks and generalize
well across different task environment configurations.",None,2911
03806996-7c42-4c49-b578-84cea4662282,Exploration via Elliptical Episodic Bonuses,0.770185,"In recent years, a number of reinforcement learning (RL) methods have been
proposed to explore complex environments which differ across episodes. In this
work, we show that the effectiveness of these methods critically relies on a
count-based episodic term in their exploration bonus. As a result, despite
their success in relatively simple, noise-free settings, these methods fall
short in more realistic scenarios where the state space is vast and prone to
noise. To address this limitation, we introduce Exploration via Elliptical
Episodic Bonuses (E3B), a new method which extends count-based episodic bonuses
to continuous state spaces and encourages an agent to explore states that are
diverse under a learned embedding within each episode. The embedding is learned
using an inverse dynamics model in order to capture controllable aspects of the
environment. Our method sets a new state-of-the-art across 16 challenging tasks
from the MiniHack suite, without requiring task-specific inductive biases. E3B
also matches existing methods on sparse reward, pixel-based VizDoom
environments, and outperforms existing methods in reward-free exploration on
Habitat, demonstrating that it can scale to high-dimensional pixel-based
observations and realistic environments.",https://github.com/facebookresearch/e3b,-1
9c92932d-df2f-411f-b21e-105a7cb1f2d1,Contrastive Boundary Learning for Point Cloud Segmentation,0.970563,"Point cloud segmentation is fundamental in understanding 3D environments.
However, current 3D point cloud segmentation methods usually perform poorly on
scene boundaries, which degenerates the overall segmentation performance. In
this paper, we focus on the segmentation of scene boundaries. Accordingly, we
first explore metrics to evaluate the segmentation performance on scene
boundaries. To address the unsatisfactory performance on boundaries, we then
propose a novel contrastive boundary learning (CBL) framework for point cloud
segmentation. Specifically, the proposed CBL enhances feature discrimination
between points across boundaries by contrasting their representations with the
assistance of scene contexts at multiple scales. By applying CBL on three
different baseline methods, we experimentally show that CBL consistently
improves different baselines and assists them to achieve compelling performance
on boundaries, as well as the overall performance, eg in mIoU. The experimental
results demonstrate the effectiveness of our method and the importance of
boundaries for 3D point cloud segmentation. Code and model will be made
publicly available at https://github.com/LiyaoTang/contrastBoundary.",https://github.com/LiyaoTang/contrastBoundary,-1
0efbf51f-a4d6-4127-b365-68b56913211a,Deep Reinforcement Learning for Exact Combinatorial Optimization: Learning to Branch,0.592686,"Branch-and-bound is a systematic enumerative method for combinatorial
optimization, where the performance highly relies on the variable selection
strategy. State-of-the-art handcrafted heuristic strategies suffer from
relatively slow inference time for each selection, while the current machine
learning methods require a significant amount of labeled data. We propose a new
approach for solving the data labeling and inference latency issues in
combinatorial optimization based on the use of the reinforcement learning (RL)
paradigm. We use imitation learning to bootstrap an RL agent and then use
Proximal Policy Optimization (PPO) to further explore global optimal actions.
Then, a value network is used to run Monte-Carlo tree search (MCTS) to enhance
the policy network. We evaluate the performance of our method on four different
categories of combinatorial optimization problems and show that our approach
performs strongly compared to the state-of-the-art machine learning and
heuristics based methods.",None,-1
93c568d7-3681-44e4-b934-e5f0803406e9,Deep object detection for waterbird monitoring using aerial imagery,0.608394,"Monitoring of colonial waterbird nesting islands is essential to tracking
waterbird population trends, which are used for evaluating ecosystem health and
informing conservation management decisions. Recently, unmanned aerial
vehicles, or drones, have emerged as a viable technology to precisely monitor
waterbird colonies. However, manually counting waterbirds from hundreds, or
potentially thousands, of aerial images is both difficult and time-consuming.
In this work, we present a deep learning pipeline that can be used to precisely
detect, count, and monitor waterbirds using aerial imagery collected by a
commercial drone. By utilizing convolutional neural network-based object
detectors, we show that we can detect 16 classes of waterbird species that are
commonly found in colonial nesting islands along the Texas coast. Our
experiments using Faster R-CNN and RetinaNet object detectors give mean
interpolated average precision scores of 67.9% and 63.1% respectively.",https://github.com/RiceD2KLab/Audubon F21,-1
3b65d6f6-4c7b-4d65-9469-6feb71d1592f,Heterformer: Transformer-based Deep Node Representation Learning on Heterogeneous Text-Rich Networks,0.406717,"Representation learning on networks aims to derive a meaningful vector
representation for each node, thereby facilitating downstream tasks such as
link prediction, node classification, and node clustering. In heterogeneous
text-rich networks, this task is more challenging due to (1) presence or
absence of text: Some nodes are associated with rich textual information, while
others are not; (2) diversity of types: Nodes and edges of multiple types form
a heterogeneous network structure. As pretrained language models (PLMs) have
demonstrated their effectiveness in obtaining widely generalizable text
representations, a substantial amount of effort has been made to incorporate
PLMs into representation learning on text-rich networks. However, few of them
can jointly consider heterogeneous structure (network) information as well as
rich textual semantic information of each node effectively. In this paper, we
propose Heterformer, a Heterogeneous Network-Empowered Transformer that
performs contextualized text encoding and heterogeneous structure encoding in a
unified model. Specifically, we inject heterogeneous structure information into
each Transformer layer when encoding node texts. Meanwhile, Heterformer is
capable of characterizing node/edge type heterogeneity and encoding nodes with
or without texts. We conduct comprehensive experiments on three tasks (i.e.,
link prediction, node classification, and node clustering) on three large-scale
datasets from different domains, where Heterformer outperforms competitive
baselines significantly and consistently.",https://github.com/PeterGriﬃnJin/Heterformer,255449
cf112544-35f3-4c5f-b97c-5b5d5a6f2221,Black-Box Tuning for Language-Model-as-a-Service,0.999964,"Extremely large pre-trained language models (PTMs) such as GPT-3 are usually
released as a service. It allows users to design task-specific prompts to query
the PTMs through some black-box APIs. In such a scenario, which we call
Language-Model-as-a-Service (LMaaS), the gradients of PTMs are usually
unavailable. Can we optimize the task prompts by only accessing the model
inference APIs? This paper proposes the black-box tuning framework to optimize
the continuous prompt prepended to the input text via derivative-free
optimization. Instead of optimizing in the original high-dimensional prompt
space, which is intractable for traditional derivative-free optimization, we
perform optimization in a randomly generated subspace due to the low intrinsic
dimensionality of large PTMs. The experimental results show that the black-box
tuning with RoBERTa on a few labeled samples not only significantly outperforms
manual prompt and GPT-3's in-context learning, but also surpasses the
gradient-based counterparts, i.e., prompt tuning and full model tuning.",https://github.com/txsun1997/Black-Box-Tuning,-1
f9a19859-1eb2-4ba6-9663-883d71e9b2b3,Strong Heuristics for Named Entity Linking,0.153178,"Named entity linking (NEL) in news is a challenging endeavour due to the
frequency of unseen and emerging entities, which necessitates the use of
unsupervised or zero-shot methods. However, such methods tend to come with
caveats, such as no integration of suitable knowledge bases (like Wikidata) for
emerging entities, a lack of scalability, and poor interpretability. Here, we
consider person disambiguation in Quotebank, a massive corpus of
speaker-attributed quotations from the news, and investigate the suitability of
intuitive, lightweight, and scalable heuristics for NEL in web-scale corpora.
Our best performing heuristic disambiguates 94% and 63% of the mentions on
Quotebank and the AIDA-CoNLL benchmark, respectively. Additionally, the
proposed heuristics compare favourably to the state-of-the-art unsupervised and
zero-shot methods, Eigenthemes and mGENRE, respectively, thereby serving as
strong baselines for unsupervised and zero-shot entity linking.",https://github.com/epfl-dlab/nelight,-1
7504e7c2-e55c-412a-a882-f5730ad4ebc3,TCE at Qur'an QA 2022: Arabic Language Question Answering Over Holy Qur'an Using a Post-Processed Ensemble of BERT-based Models,0.224954,"In recent years, we witnessed great progress in different tasks of natural
language understanding using machine learning. Question answering is one of
these tasks which is used by search engines and social media platforms for
improved user experience. Arabic is the language of the Holy Qur'an; the sacred
text for 1.8 billion people across the world. Arabic is a challenging language
for Natural Language Processing (NLP) due to its complex structures. In this
article, we describe our attempts at OSACT5 Qur'an QA 2022 Shared Task, which
is a question answering challenge on the Holy Qur'an in Arabic. We propose an
ensemble learning model based on Arabic variants of BERT models. In addition,
we perform post-processing to enhance the model predictions. Our system
achieves a Partial Reciprocal Rank (pRR) score of 56.6% on the official test
set.",https://github.com/mohammed-elkomy/quran-qa,-1
164f2b5a-9952-4991-b19c-853fb5e3a93e,Bridging POMDPs and Bayesian decision making for robust maintenance planning under model uncertainty: An application to railway systems,0.734882,"Structural Health Monitoring (SHM) describes a process for inferring
quantifiable metrics of structural condition, which can serve as input to
support decisions on the operation and maintenance of infrastructure assets.
Given the long lifespan of critical structures, this problem can be cast as a
sequential decision making problem over prescribed horizons. Partially
Observable Markov Decision Processes (POMDPs) offer a formal framework to solve
the underlying optimal planning task. However, two issues can undermine the
POMDP solutions. Firstly, the need for a model that can adequately describe the
evolution of the structural condition under deterioration or corrective actions
and, secondly, the non-trivial task of recovery of the observation process
parameters from available monitoring data. Despite these potential challenges,
the adopted POMDP models do not typically account for uncertainty on model
parameters, leading to solutions which can be unrealistically confident. In
this work, we address both key issues. We present a framework to estimate POMDP
transition and observation model parameters directly from available data, via
Markov Chain Monte Carlo (MCMC) sampling of a Hidden Markov Model (HMM)
conditioned on actions. The MCMC inference estimates distributions of the
involved model parameters. We then form and solve the POMDP problem by
exploiting the inferred distributions, to derive solutions that are robust to
model uncertainty. We successfully apply our approach on maintenance planning
for railway track assets on the basis of a ""fractal value"" indicator, which is
computed from actual railway monitoring data.",http://github.com/google/jax,9608
d5ba15bc-6dc3-4434-a3d9-e2323de3935b,VAST: The Valence-Assessing Semantics Test for Contextualizing Language Models,0.411219,"VAST, the Valence-Assessing Semantics Test, is a novel intrinsic evaluation
task for contextualized word embeddings (CWEs). VAST uses valence, the
association of a word with pleasantness, to measure the correspondence of
word-level LM semantics with widely used human judgments, and examines the
effects of contextualization, tokenization, and LM-specific geometry. Because
prior research has found that CWEs from GPT-2 perform poorly on other intrinsic
evaluations, we select GPT-2 as our primary subject, and include results
showing that VAST is useful for 7 other LMs, and can be used in 7 languages.
GPT-2 results show that the semantics of a word incorporate the semantics of
context in layers closer to model output, such that VAST scores diverge between
our contextual settings, ranging from Pearson's rho of .55 to .77 in layer 11.
We also show that multiply tokenized words are not semantically encoded until
layer 8, where they achieve Pearson's rho of .46, indicating the presence of an
encoding process for multiply tokenized words which differs from that of singly
tokenized words, for which rho is highest in layer 0. We find that a few
neurons with values having greater magnitude than the rest mask word-level
semantics in GPT-2's top layer, but that word-level semantics can be recovered
by nullifying non-semantic principal components: Pearson's rho in the top layer
improves from .32 to .76. After isolating semantics, we show the utility of
VAST for understanding LM semantics via improvements over related work on four
word similarity tasks, with a score of .50 on SimLex-999, better than the
previous best of .45 for GPT-2. Finally, we show that 8 of 10 WEAT bias tests,
which compare differences in word embedding associations between groups of
words, exhibit more stereotype-congruent biases after isolating semantics,
indicating that non-semantic structures in LMs also mask biases.",https://github.com/wolferobert3/vast,-1
b7253f8f-e40c-4fb2-a069-d1e4d6d304ca,Patch-wise Contrastive Style Learning for Instagram Filter Removal,0.811488,"Image-level corruptions and perturbations degrade the performance of CNNs on
different downstream vision tasks. Social media filters are one of the most
common resources of various corruptions and perturbations for real-world visual
analysis applications. The negative effects of these distractive factors can be
alleviated by recovering the original images with their pure style for the
inference of the downstream vision tasks. Assuming these filters substantially
inject a piece of additional style information to the social media images, we
can formulate the problem of recovering the original versions as a reverse
style transfer problem. We introduce Contrastive Instagram Filter Removal
Network (CIFR), which enhances this idea for Instagram filter removal by
employing a novel multi-layer patch-wise contrastive style learning mechanism.
Experiments show our proposed strategy produces better qualitative and
quantitative results than the previous studies. Moreover, we present the
results of our additional experiments for proposed architecture within
different settings. Finally, we present the inference outputs and quantitative
comparison of filtered and recovered images on localization and segmentation
tasks to encourage the main motivation for this problem.",https://github.com/birdortyedi/cifr-pytorch,-1
6c311d3a-0d2c-4ff4-917e-be0c2dea4578,"Frame-level Prediction of Facial Expressions, Valence, Arousal and Action Units for Mobile Devices",0.987559,"In this paper, we consider the problem of real-time video-based facial
emotion analytics, namely, facial expression recognition, prediction of valence
and arousal and detection of action unit points. We propose the novel
frame-level emotion recognition algorithm by extracting facial features with
the single EfficientNet model pre-trained on AffectNet. As a result, our
approach may be implemented even for video analytics on mobile devices.
Experimental results for the large scale Aff-Wild2 database from the third
Affective Behavior Analysis in-the-wild (ABAW) Competition demonstrate that our
simple model is significantly better when compared to the VggFace baseline. In
particular, our method is characterized by 0.15-0.2 higher performance measures
for validation sets in uni-task Expression Classification, Valence-Arousal
Estimation and Expression Classification. Due to simplicity, our approach may
be considered as a new baseline for all four sub-challenges.",None,-1
10e346c8-ff5c-42c0-aeb4-4b94d9eabf2d,SKIPP'D: a SKy Images and Photovoltaic Power Generation Dataset for Short-term Solar Forecasting,0.62498,"Large-scale integration of photovoltaics (PV) into electricity grids is
challenged by the intermittent nature of solar power. Sky-image-based solar
forecasting using deep learning has been recognized as a promising approach to
predicting the short-term fluctuations. However, there are few publicly
available standardized benchmark datasets for image-based solar forecasting,
which limits the comparison of different forecasting models and the exploration
of forecasting methods. To fill these gaps, we introduce SKIPP'D -- a SKy
Images and Photovoltaic Power Generation Dataset. The dataset contains three
years (2017-2019) of quality-controlled down-sampled sky images and PV power
generation data that is ready-to-use for short-term solar forecasting using
deep learning. In addition, to support the flexibility in research, we provide
the high resolution, high frequency sky images and PV power generation data as
well as the concurrent sky video footage. We also include a code base
containing data processing scripts and baseline model implementations for
researchers to reproduce our previous work and accelerate their research in
solar forecasting.",https://github.com/yuhao-nie/Stanford-solar-forecasting-dataset,-1
968db164-9509-407c-8975-d6d8c4a4cd63,DEANet: Decomposition Enhancement and Adjustment Network for Low-Light Image Enhancement,0.418847,"Images obtained under low-light conditions will seriously affect the quality
of the images. Solving the problem of poor low-light image quality can
effectively improve the visual quality of images and better improve the
usability of computer vision. In addition, it has very important applications
in many fields. This paper proposes a DEANet based on Retinex for low-light
image enhancement. It combines the frequency information and content
information of the image into three sub-networks: decomposition network,
enhancement network and adjustment network. These three sub-networks are
respectively used for decomposition, denoising, contrast enhancement and detail
preservation, adjustment, and image generation. Our model has good robust
results for all low-light images. The model is trained on the public data set
LOL, and the experimental results show that our method is better than the
existing state-of-the-art methods in terms of vision and quality.",None,-1
99dfb34d-4e0a-4913-872e-4139d8acbd27,Fusing Convolutional Neural Network and Geometric Constraint for Image-based Indoor Localization,0.82384,"This paper proposes a new image-based localization framework that explicitly
localizes the camera/robot by fusing Convolutional Neural Network (CNN) and
sequential images' geometric constraints. The camera is localized using a
single or few observed images and training images with 6-degree-of-freedom pose
labels. A Siamese network structure is adopted to train an image descriptor
network, and the visually similar candidate image in the training set is
retrieved to localize the testing image geometrically. Meanwhile, a
probabilistic motion model predicts the pose based on a constant velocity
assumption. The two estimated poses are finally fused using their uncertainties
to yield an accurate pose prediction. This method leverages the geometric
uncertainty and is applicable in indoor scenarios predominated by diffuse
illumination. Experiments on simulation and real data sets demonstrate the
efficiency of our proposed method. The results further show that combining the
CNN-based framework with geometric constraint achieves better accuracy when
compared with CNN-only methods, especially when the training data size is
small.",None,-1
4ec7f78f-b375-4a05-a4af-b3ca9a349f47,Instance-wise Prompt Tuning for Pretrained Language Models,0.054641,"Prompt Learning has recently gained great popularity in bridging the gap
between pretraining tasks and various downstream tasks. It freezes Pretrained
Language Models (PLMs) and only tunes a few task-related parameters (prompts)
for downstream tasks, greatly reducing the cost of tuning giant models. The key
enabler of this is the idea of querying PLMs with task-specific knowledge
implicated in prompts. This paper reveals a major limitation of existing
methods that the indiscriminate prompts for all input data in a task ignore the
intrinsic knowledge from input data, resulting in sub-optimal performance. We
introduce Instance-wise Prompt Tuning (IPT), the first prompt learning paradigm
that injects knowledge from the input data instances to the prompts, thereby
providing PLMs with richer and more concrete context information. We devise a
series of strategies to produce instance-wise prompts, addressing various
concerns like model quality and cost-efficiency. Across multiple tasks and
resource settings, IPT significantly outperforms task-based prompt learning
methods, and achieves comparable performance to conventional finetuning with
only 0.5% - 1.5% of tuned parameters.",None,-1
a7f04e3f-d499-4d6b-b4f7-954f6e22ea0c,Benchmarking Long-tail Generalization with Likelihood Splits,0.485634,"In order to reliably process natural language, NLP systems must generalize to
the long tail of rare utterances. We propose a method to create challenging
benchmarks that require generalizing to the tail of the distribution by
re-splitting existing datasets. We create 'Likelihood Splits' where examples
that are assigned lower likelihood by a pre-trained language model (LM) are
placed in the test set, and more likely examples are in the training set. This
simple approach can be customized to construct meaningful train-test splits for
a wide range of tasks. Likelihood Splits surface more challenges than random
splits: relative error rates of state-of-the-art models increase by 59% for
semantic parsing on Spider, 93% for natural language inference on SNLI, and 33%
for yes/no question answering on BoolQ, on our splits compared with the
corresponding random splits. Moreover, Likelihood Splits create fairer
benchmarks than adversarial filtering; when the LM used to create the splits is
also employed as the task model, our splits do not unfairly penalize the LM.",https://github.com/ameyagodbole/long-tail-likelihood-splits,-1
5e83fa2b-4cc2-4174-939f-5bfe4e768fe3,Multi-Vector Retrieval as Sparse Alignment,0.242062,"Multi-vector retrieval models improve over single-vector dual encoders on
many information retrieval tasks. In this paper, we cast the multi-vector
retrieval problem as sparse alignment between query and document tokens. We
propose AligneR, a novel multi-vector retrieval model that learns sparsified
pairwise alignments between query and document tokens (e.g. `dog' vs. `puppy')
and per-token unary saliences reflecting their relative importance for
retrieval. We show that controlling the sparsity of pairwise token alignments
often brings significant performance gains. While most factoid questions
focusing on a specific part of a document require a smaller number of
alignments, others requiring a broader understanding of a document favor a
larger number of alignments. Unary saliences, on the other hand, decide whether
a token ever needs to be aligned with others for retrieval (e.g. `kind' from
`kind of currency is used in new zealand}'). With sparsified unary saliences,
we are able to prune a large number of query and document token vectors and
improve the efficiency of multi-vector retrieval. We learn the sparse unary
saliences with entropy-regularized linear programming, which outperforms other
methods to achieve sparsity. In a zero-shot setting, AligneR scores 51.1 points
nDCG@10, achieving a new retriever-only state-of-the-art on 13 tasks in the
BEIR benchmark. In addition, adapting pairwise alignments with a few examples
(<= 8) further improves the performance up to 15.7 points nDCG@10 for argument
retrieval tasks. The unary saliences of AligneR helps us to keep only 20% of
the document token representations with minimal performance loss. We further
show that our model often produces interpretable alignments and significantly
improves its performance when initialized from larger language models.",None,-1
348304cd-73d0-477f-a6fc-191f22c9d12c,StegaNeRF: Embedding Invisible Information within Neural Radiance Fields,0.581078,"Recent advances in neural rendering imply a future of widespread visual data
distributions through sharing NeRF model weights. However, while common visual
data (images and videos) have standard approaches to embed ownership or
copyright information explicitly or subtly, the problem remains unexplored for
the emerging NeRF format. We present StegaNeRF, a method for steganographic
information embedding in NeRF renderings. We design an optimization framework
allowing accurate hidden information extractions from images rendered by NeRF,
while preserving its original visual quality. We perform experimental
evaluations of our method under several potential deployment scenarios, and we
further discuss the insights discovered through our analysis. StegaNeRF
signifies an initial exploration into the novel problem of instilling
customizable, imperceptible, and recoverable information to NeRF renderings,
with minimal impact to rendered images. Project page:
https://xggnet.github.io/StegaNeRF/.",None,-1
e4ef1efc-4a5b-4f14-baee-b1bec5f0efb5,Filler Word Detection and Classification: A Dataset and Benchmark,0.555862,"Filler words such as `uh' or `um' are sounds or words people use to signal
they are pausing to think. Finding and removing filler words from recordings is
a common and tedious task in media editing. Automatically detecting and
classifying filler words could greatly aid in this task, but few studies have
been published on this problem to date. A key reason is the absence of a
dataset with annotated filler words for model training and evaluation. In this
work, we present a novel speech dataset, PodcastFillers, with 35K annotated
filler words and 50K annotations of other sounds that commonly occur in
podcasts such as breaths, laughter, and word repetitions. We propose a pipeline
that leverages VAD and ASR to detect filler candidates and a classifier to
distinguish between filler word types. We evaluate our proposed pipeline on
PodcastFillers, compare to several baselines, and present a detailed ablation
study. In particular, we evaluate the importance of using ASR and how it
compares to a transcription-free approach resembling keyword spotting. We show
that our pipeline obtains state-of-the-art results, and that leveraging ASR
strongly outperforms a keyword spotting approach. We make PodcastFillers
publicly available, in the hope that our work serves as a benchmark for future
research.",https://github.com/podcastfillers,-1
78185b44-30d2-42ec-bbf4-4425b6c39985,PanGu-Bot: Efficient Generative Dialogue Pre-training from Pre-trained Language Model,0.647594,"In this paper, we introduce PanGu-Bot, a Chinese pre-trained open-domain
dialogue generation model based on a large pre-trained language model (PLM)
PANGU-alpha (Zeng et al.,2021). Different from other pre-trained dialogue
models trained over a massive amount of dialogue data from scratch, we aim to
build a powerful dialogue model with relatively fewer data and computation
costs by inheriting valuable language capabilities and knowledge from PLMs. To
this end, we train PanGu-Bot from the large PLM PANGU-alpha, which has been
proven well-performed on a variety of Chinese natural language tasks. We
investigate different aspects of responses generated by PanGu-Bot, including
response quality, knowledge, and safety. We show that PanGu-Bot outperforms
state-of-the-art Chinese dialogue systems (CDIALGPT (Wang et al., 2020), EVA
(Zhou et al., 2021), EVA2.0 (Gu et al., 2022)) w.r.t. the above three aspects.
We also demonstrate that PanGu-Bot can be easily deployed to generate emotional
responses without further training. Throughout our empirical analysis, we also
point out that the PanGu-Bot response quality, knowledge correctness, and
safety are still far from perfect, and further explorations are indispensable
to building reliable and smart dialogue systems. Our model and code will be
available at
https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/PanGu-Bot
soon.",https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/PanGu-Bot,-1
7331276b-7e1c-440b-9e5f-83da33c9b7b3,Calibrated Interpretation: Confidence Estimation in Semantic Parsing,0.513746,"Sequence generation models are increasingly being used to translate natural
language into programs, i.e. to perform executable semantic parsing. The fact
that semantic parsing aims to predict programs that can lead to executed
actions in the real world motivates developing safe systems. This in turn makes
measuring calibration -- a central component to safety -- particularly
important. We investigate the calibration of popular generation models across
four popular semantic parsing datasets, finding that it varies across models
and datasets. We then analyze factors associated with calibration error and
release new confidence-based challenge splits of two parsing datasets. To
facilitate the inclusion of calibration in semantic parsing evaluations, we
release a library for computing calibration metrics.",https://github.com/esteng/calibration_metric,-1
95849fa0-aa68-4b48-a150-e79c8e061b00,SHINE-Mapping: Large-Scale 3D Mapping Using Sparse Hierarchical Implicit Neural Representations,0.950911,"Accurate mapping of large-scale environments is an essential building block
of most outdoor autonomous systems. Challenges of traditional mapping methods
include the balance between memory consumption and mapping accuracy. This paper
addresses the problem of achieving large-scale 3D reconstruction using implicit
representations built from 3D LiDAR measurements. We learn and store implicit
features through an octree-based, hierarchical structure, which is sparse and
extensible. The implicit features can be turned into signed distance values
through a shallow neural network. We leverage binary cross entropy loss to
optimize the local features with the 3D measurements as supervision. Based on
our implicit representation, we design an incremental mapping system with
regularization to tackle the issue of forgetting in continual learning. Our
experiments show that our 3D reconstructions are more accurate, complete, and
memory-efficient than current state-of-the-art 3D mapping methods.",https://github.com/PRBonn/SHINE_mapping,-1
a8a4886d-a69c-4d8a-9cd8-3528b92b884a,Ask Me Anything: A simple strategy for prompting language models,0.798629,"Large language models (LLMs) transfer well to new tasks out-of-the-box simply
given a natural language prompt that demonstrates how to perform the task and
no additional training. Prompting is a brittle process wherein small
modifications to the prompt can cause large variations in the model
predictions, and therefore significant effort is dedicated towards designing a
painstakingly ""perfect prompt"" for a task. To mitigate the high degree of
effort involved in prompt-design, we instead ask whether producing multiple
effective, yet imperfect, prompts and aggregating them can lead to a high
quality prompting strategy. Our observations motivate our proposed prompting
method, ASK ME ANYTHING (AMA). We first develop an understanding of the
effective prompt formats, finding that question-answering (QA) prompts, which
encourage open-ended generation (""Who went to the park?"") tend to outperform
those that restrict the model outputs (""John went to the park. Output True or
False.""). Our approach recursively uses the LLM itself to transform task inputs
to the effective QA format. We apply the collected prompts to obtain several
noisy votes for the input's true label. We find that the prompts can have very
different accuracies and complex dependencies and thus propose to use weak
supervision, a procedure for combining the noisy predictions, to produce the
final predictions for the inputs. We evaluate AMA across open-source model
families (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B
parameters), demonstrating an average performance lift of 10.2% over the
few-shot baseline. This simple strategy enables the open-source GPT-J-6B model
to match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular
benchmarks. Averaged across these tasks, the GPT-J-6B model outperforms
few-shot GPT3-175B. We release our code here:
https://github.com/HazyResearch/ama_prompting",None,-1
a1b99188-04bb-4940-bcff-6717cbc570bd,Reasoning with fuzzy and uncertain evidence using epistemic random fuzzy sets: general framework and practical models,0.550851,"We introduce a general theory of epistemic random fuzzy sets for reasoning
with fuzzy or crisp evidence. This framework generalizes both the
Dempster-Shafer theory of belief functions, and possibility theory. Independent
epistemic random fuzzy sets are combined by the generalized
product-intersection rule, which extends both Dempster's rule for combining
belief functions, and the product conjunctive combination of possibility
distributions. We introduce Gaussian random fuzzy numbers and their
multi-dimensional extensions, Gaussian random fuzzy vectors, as practical
models for quantifying uncertainty about scalar or vector quantities.
Closed-form expressions for the combination, projection and vacuous extension
of Gaussian random fuzzy numbers and vectors are derived.",None,-1
75af3402-2bd3-41b5-bbd2-e9acd3f9ada0,Generalized Face Anti-Spoofing via Multi-Task Learning and One-Side Meta Triplet Loss,0.270187,"With the increasing variations of face presentation attacks, model
generalization becomes an essential challenge for a practical face
anti-spoofing system. This paper presents a generalized face anti-spoofing
framework that consists of three tasks: depth estimation, face parsing, and
live/spoof classification. With the pixel-wise supervision from the face
parsing and depth estimation tasks, the regularized features can better
distinguish spoof faces. While simulating domain shift with meta-learning
techniques, the proposed one-side triplet loss can further improve the
generalization capability by a large margin. Extensive experiments on four
public datasets demonstrate that the proposed framework and training strategies
are more effective than previous works for model generalization to unseen
domains.",None,-1
851c200c-f738-44e6-99c9-f68dbce71bc0,HyperShot: Few-Shot Learning by Kernel HyperNetworks,0.563876,"Few-shot models aim at making predictions using a minimal number of labeled
examples from a given task. The main challenge in this area is the one-shot
setting where only one element represents each class. We propose HyperShot -
the fusion of kernels and hypernetwork paradigm. Compared to reference
approaches that apply a gradient-based adjustment of the parameters, our model
aims to switch the classification module parameters depending on the task's
embedding. In practice, we utilize a hypernetwork, which takes the aggregated
information from support data and returns the classifier's parameters
handcrafted for the considered problem. Moreover, we introduce the kernel-based
representation of the support examples delivered to hypernetwork to create the
parameters of the classification module. Consequently, we rely on relations
between embeddings of the support examples instead of direct feature values
provided by the backbone models. Thanks to this approach, our model can adapt
to highly different tasks.",None,-1
6d63ee48-d3e1-43cd-84a3-5555eee84f98,"On the Usefulness of Embeddings, Clusters and Strings for Text Generator Evaluation",0.108458,"A good automatic evaluation metric for language generation ideally correlates
highly with human judgements of text quality. Yet, there is a dearth of such
metrics, which inhibits the rapid and efficient progress of language
generators. One exception is the recently proposed Mauve. In theory, Mauve
measures an information-theoretic divergence between two probability
distributions over strings: one representing the language generator under
evaluation; the other representing the true natural language distribution.
Mauve's authors argue that its success comes from the qualitative properties of
their proposed divergence. Yet in practice, as this divergence is uncomputable,
Mauve approximates it by measuring the divergence between multinomial
distributions over clusters instead, where cluster assignments are attained by
grouping strings based on a pre-trained language model's embeddings. As we
show, however, this is not a tight approximation -- in either theory or
practice. This begs the question: why does Mauve work so well? In this work, we
show that Mauve was right for the wrong reasons, and that its newly proposed
divergence is not necessary for its high performance. In fact, classical
divergences paired with its proposed cluster-based approximation may actually
serve as better evaluation metrics. We finish the paper with a probing
analysis; this analysis leads us to conclude that -- by encoding syntactic- and
coherence-level features of text, while ignoring surface-level features -- such
cluster-based substitutes to string distributions may simply be better for
evaluating state-of-the-art language generators.",None,-1
6cd9fd7d-7c51-4c06-9539-36b9d909f027,Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries,0.854259,"Learning under a continuously changing data distribution with incorrect
labels is a desirable real-world problem yet challenging. A large body of
continual learning (CL) methods, however, assumes data streams with clean
labels, and online learning scenarios under noisy data streams are yet
underexplored. We consider a more practical CL task setup of an online learning
from blurry data stream with corrupted labels, where existing CL methods
struggle. To address the task, we first argue the importance of both diversity
and purity of examples in the episodic memory of continual learning models. To
balance diversity and purity in the episodic memory, we propose a novel
strategy to manage and use the memory by a unified approach of label noise
aware diverse sampling and robust learning with semi-supervised learning. Our
empirical validations on four real-world or synthetic noise datasets (CIFAR10
and 100, mini-WebVision, and Food-101N) exhibit that our method significantly
outperforms prior arts in this realistic and challenging continual learning
scenario. Code and data splits are available in
https://github.com/clovaai/puridiver.",https://github.com/clovaai/puridiver,-1
c8b4ee1a-b32f-4f99-ba66-daff217f0161,Monotonic segmental attention for automatic speech recognition,0.463446,"We introduce a novel segmental-attention model for automatic speech
recognition. We restrict the decoder attention to segments to avoid quadratic
runtime of global attention, better generalize to long sequences, and
eventually enable streaming. We directly compare global-attention and different
segmental-attention modeling variants. We develop and compare two separate
time-synchronous decoders, one specifically taking the segmental nature into
account, yielding further improvements. Using time-synchronous decoding for
segmental models is novel and a step towards streaming applications. Our
experiments show the importance of a length model to predict the segment
boundaries. The final best segmental-attention model using segmental decoding
performs better than global-attention, in contrast to other monotonic attention
approaches in the literature. Further, we observe that the segmental model
generalizes much better to long sequences of up to several minutes.",https://github.com/rwth-i6/returnn-experiments/tree/master/,-1
2d619731-4a8b-4b29-8a93-5a573067f0bb,Teacher-student curriculum learning for reinforcement learning,0.032167,"Reinforcement learning (rl) is a popular paradigm for sequential decision
making problems. The past decade's advances in rl have led to breakthroughs in
many challenging domains such as video games, board games, robotics, and chip
design. The sample inefficiency of deep reinforcement learning methods is a
significant obstacle when applying rl to real-world problems. Transfer learning
has been applied to reinforcement learning such that the knowledge gained in
one task can be applied when training in a new task. Curriculum learning is
concerned with sequencing tasks or data samples such that knowledge can be
transferred between those tasks to learn a target task that would otherwise be
too difficult to solve. Designing a curriculum that improves sample efficiency
is a complex problem. In this thesis, we propose a teacher-student curriculum
learning setting where we simultaneously train a teacher that selects tasks for
the student while the student learns how to solve the selected task. Our method
is independent of human domain knowledge and manual curriculum design. We
evaluated our methods on two reinforcement learning benchmarks: grid world and
the challenging Google Football environment. With our method, we can improve
the sample efficiency and generality of the student compared to tabula-rasa
reinforcement learning.",https://github.com/maximecb/gym-minigrid,-1
7c73100c-b2c3-428c-b984-2da644dead6f,TOKEN is a MASK: Few-shot Named Entity Recognition with Pre-trained Language Models,0.28003,"Transferring knowledge from one domain to another is of practical importance
for many tasks in natural language processing, especially when the amount of
available data in the target domain is limited. In this work, we propose a
novel few-shot approach to domain adaptation in the context of Named Entity
Recognition (NER). We propose a two-step approach consisting of a variable base
module and a template module that leverages the knowledge captured in
pre-trained language models with the help of simple descriptive patterns. Our
approach is simple yet versatile and can be applied in few-shot and zero-shot
settings. Evaluating our lightweight approach across a number of different
datasets shows that it can boost the performance of state-of-the-art baselines
by 2-5% F1-score.",None,-1
434bf510-0361-43cc-be3a-e61a696386c4,Towards Stroke Patients' Upper-limb Automatic Motor Assessment Using Smartwatches,0.853605,"Assessing the physical condition in rehabilitation scenarios is a challenging
problem, since it involves Human Activity Recognition (HAR) and kinematic
analysis methods. In addition, the difficulties increase in unconstrained
rehabilitation scenarios, which are much closer to the real use cases. In
particular, our aim is to design an upper-limb assessment pipeline for stroke
patients using smartwatches. We focus on the HAR task, as it is the first part
of the assessing pipeline. Our main target is to automatically detect and
recognize four key movements inspired by the Fugl-Meyer assessment scale, which
are performed in both constrained and unconstrained scenarios. In addition to
the application protocol and dataset, we propose two detection and
classification baseline methods. We believe that the proposed framework,
dataset and baseline results will serve to foster this research field.",None,-1
430f8b7f-a8e7-47fd-8537-0a80d2868fd7,Reinforcement Learning with Large Action Spaces for Neural Machine Translation,0.265416,"Applying Reinforcement learning (RL) following maximum likelihood estimation
(MLE) pre-training is a versatile method for enhancing neural machine
translation (NMT) performance. However, recent work has argued that the gains
produced by RL for NMT are mostly due to promoting tokens that have already
received a fairly high probability in pre-training. We hypothesize that the
large action space is a main obstacle to RL's effectiveness in MT, and conduct
two sets of experiments that lend support to our hypothesis. First, we find
that reducing the size of the vocabulary improves RL's effectiveness. Second,
we find that effectively reducing the dimension of the action space without
changing the vocabulary also yields notable improvement as evaluated by BLEU,
semantic similarity, and human evaluation. Indeed, by initializing the
network's final fully connected layer (that maps the network's internal
dimension to the vocabulary dimension), with a layer that generalizes over
similar actions, we obtain a substantial improvement in RL performance: 1.5
BLEU points on average.",https://github.com/AsafYehudai/Reinforcement-Learning-with-Large-Action-Spaces-for-Neural-Machine-Translation,-1
7434a2ef-2189-4290-b910-baedc3024f2d,A Distributional Lens for Multi-Aspect Controllable Text Generation,0.738625,"Multi-aspect controllable text generation is a more challenging and practical
task than single-aspect control. Existing methods achieve complex multi-aspect
control by fusing multiple controllers learned from single-aspect, but suffer
from attribute degeneration caused by the mutual interference of these
controllers. To address this, we provide observations on attribute fusion from
a distributional perspective and propose to directly search for the
intersection areas of multiple attribute distributions as their combination for
generation. Our method first estimates the attribute space with an autoencoder
structure. Afterward, we iteratively approach the intersections by jointly
minimizing distances to points representing different attributes. Finally, we
map them to attribute-relevant sentences with a prefix-tuning-based decoder.
Experiments on the three-aspect control task, including sentiment, topic, and
detoxification aspects, reveal that our method outperforms several strong
baselines on attribute relevance and text quality and achieves the SOTA.
Further analysis also supplies some explanatory support for the effectiveness
of our approach.",https://github.com/HappyGu0524/MultiControl,-1
34dfd8c2-c760-4ddd-a8a5-70e49370699d,Mapping Husserlian phenomenology onto active inference,0.612881,"Phenomenology is the rigorous descriptive study of conscious experience.
Recent attempts to formalize Husserlian phenomenology provide us with a
mathematical model of perception as a function of prior knowledge and
expectation. In this paper, we re-examine elements of Husserlian phenomenology
through the lens of active inference. In doing so, we aim to advance the
project of computational phenomenology, as recently outlined by proponents of
active inference. We propose that key aspects of Husserl's descriptions of
consciousness can be mapped onto aspects of the generative models associated
with the active inference approach. We first briefly review active inference.
We then discuss Husserl's phenomenology, with a focus on time consciousness.
Finally, we present our mapping from Husserlian phenomenology to active
inference.",None,-1
8fe6ff7e-c59f-4851-9e3b-468a15b15661,Goal-Conditioned Reinforcement Learning: Problems and Solutions,0.994954,"Goal-conditioned reinforcement learning (GCRL), related to a set of complex
RL problems, trains an agent to achieve different goals under particular
scenarios. Compared to the standard RL solutions that learn a policy solely
depending on the states or observations, GCRL additionally requires the agent
to make decisions according to different goals. In this survey, we provide a
comprehensive overview of the challenges and algorithms for GCRL. Firstly, we
answer what the basic problems are studied in this field. Then, we explain how
goals are represented and present how existing solutions are designed from
different points of view. Finally, we make the conclusion and discuss potential
future prospects that recent researches focus on.",https://github.com/apexrl/,-1
8c3c8d4a-c29b-4bb7-a8d6-52b3ffdeb6aa,ASR Error Correction with Constrained Decoding on Operation Prediction,0.510625,"Error correction techniques remain effective to refine outputs from automatic
speech recognition (ASR) models. Existing end-to-end error correction methods
based on an encoder-decoder architecture process all tokens in the decoding
phase, creating undesirable latency. In this paper, we propose an ASR error
correction method utilizing the predictions of correction operations. More
specifically, we construct a predictor between the encoder and the decoder to
learn if a token should be kept (""K""), deleted (""D""), or changed (""C"") to
restrict decoding to only part of the input sequence embeddings (the ""C""
tokens) for fast inference. Experiments on three public datasets demonstrate
the effectiveness of the proposed approach in reducing the latency of the
decoding process in ASR correction. It enhances the inference speed by at least
three times (3.4 and 5.7 times) while maintaining the same level of accuracy
(with WER reductions of 0.53% and 1.69% respectively) for our two proposed
models compared to a solid encoder-decoder baseline. In the meantime, we
produce and release a benchmark dataset contributing to the ASR error
correction community to foster research along this line.",https://github.com/yangjingyuan/ConstDecoder,-1
5a9e06f5-279d-48d1-94ec-39395113051d,LCP-dropout: Compression-based Multiple Subword Segmentation for Neural Machine Translation,0.606678,"In this study, we propose a simple and effective preprocessing method for
subword segmentation based on a data compression algorithm. Compression-based
subword segmentation has recently attracted significant attention as a
preprocessing method for training data in Neural Machine Translation. Among
them, BPE/BPE-dropout is one of the fastest and most effective method compared
to conventional approaches. However, compression-based approach has a drawback
in that generating multiple segmentations is difficult due to the determinism.
To overcome this difficulty, we focus on a probabilistic string algorithm,
called locally-consistent parsing (LCP), that has been applied to achieve
optimum compression. Employing the probabilistic mechanism of LCP, we propose
LCP-dropout for multiple subword segmentation that improves BPE/BPE-dropout,
and show that it outperforms various baselines in learning from especially
small training data.",https://github.com/moses-smt/mosesdecoder,-1
ac14625c-c62a-41f2-83a8-2d7c505779ca,Simultaneous Double Q-learning with Conservative Advantage Learning for Actor-Critic Methods,0.264747,"Actor-critic Reinforcement Learning (RL) algorithms have achieved impressive
performance in continuous control tasks. However, they still suffer two
nontrivial obstacles, i.e., low sample efficiency and overestimation bias. To
this end, we propose Simultaneous Double Q-learning with Conservative Advantage
Learning (SDQ-CAL). Our SDQ-CAL boosts the Double Q-learning for off-policy
actor-critic RL based on a modification of the Bellman optimality operator with
Advantage Learning. Specifically, SDQ-CAL improves sample efficiency by
modifying the reward to facilitate the distinction from experience between the
optimal actions and the others. Besides, it mitigates the overestimation issue
by updating a pair of critics simultaneously upon double estimators. Extensive
experiments reveal that our algorithm realizes less biased value estimation and
achieves state-of-the-art performance in a range of continuous control
benchmark tasks. We release the source code of our method at:
\url{https://github.com/LQNew/SDQ-CAL}.",https://github.com/LQNew/SDQ-CAL,-1
3f64994f-99f0-449a-b078-5e3818534b78,NAN: Noise-Aware NeRFs for Burst-Denoising,0.653369,"Burst denoising is now more relevant than ever, as computational photography
helps overcome sensitivity issues inherent in mobile phones and small cameras.
A major challenge in burst-denoising is in coping with pixel misalignment,
which was so far handled with rather simplistic assumptions of simple motion,
or the ability to align in pre-processing. Such assumptions are not realistic
in the presence of large motion and high levels of noise. We show that Neural
Radiance Fields (NeRFs), originally suggested for physics-based novel-view
rendering, can serve as a powerful framework for burst denoising. NeRFs have an
inherent capability of handling noise as they integrate information from
multiple images, but they are limited in doing so, mainly since they build on
pixel-wise operations which are suitable to ideal imaging conditions. Our
approach, termed NAN, leverages inter-view and spatial information in NeRFs to
better deal with noise. It achieves state-of-the-art results in burst denoising
and is especially successful in coping with large movement and occlusions,
under very high levels of noise. With the rapid advances in accelerating NeRFs,
it could provide a powerful platform for denoising in challenging environments.",None,6308
934ae93c-1eb2-47df-8ec4-114b70c1cc9d,A Framework for Generating Informative Benchmark Instances,0.0235749,"Benchmarking is an important tool for assessing the relative performance of
alternative solving approaches. However, the utility of benchmarking is limited
by the quantity and quality of the available problem instances. Modern
constraint programming languages typically allow the specification of a
class-level model that is parameterised over instance data. This separation
presents an opportunity for automated approaches to generate instance data that
define instances that are graded (solvable at a certain difficulty level for a
solver) or can discriminate between two solving approaches. In this paper, we
introduce a framework that combines these two properties to generate a large
number of benchmark instances, purposely generated for effective and
informative benchmarking. We use five problems that were used in the MiniZinc
competition to demonstrate the usage of our framework. In addition to producing
a ranking among solvers, our framework gives a broader understanding of the
behaviour of each solver for the whole instance space; for example by finding
subsets of instances where the solver performance significantly varies from its
average performance.",https://github.com/stacs-cp/AutoIG,-1
0b7ae3a8-cc36-4813-8e7d-e5a701c73614,longhorns at DADC 2022: How many linguists does it take to fool a Question Answering model? A systematic approach to adversarial attacks,0.457757,"Developing methods to adversarially challenge NLP systems is a promising
avenue for improving both model performance and interpretability. Here, we
describe the approach of the team ""longhorns"" on Task 1 of the The First
Workshop on Dynamic Adversarial Data Collection (DADC), which asked teams to
manually fool a model on an Extractive Question Answering task. Our team
finished first, with a model error rate of 62%. We advocate for a systematic,
linguistically informed approach to formulating adversarial questions, and we
describe the results of our pilot experiments, as well as our official
submission.",None,5637
7fc7e745-a713-4452-8c21-4093e8c7e7fa,Reconciling Security and Communication Efficiency in Federated Learning,0.220262,"Cross-device Federated Learning is an increasingly popular machine learning
setting to train a model by leveraging a large population of client devices
with high privacy and security guarantees. However, communication efficiency
remains a major bottleneck when scaling federated learning to production
environments, particularly due to bandwidth constraints during uplink
communication. In this paper, we formalize and address the problem of
compressing client-to-server model updates under the Secure Aggregation
primitive, a core component of Federated Learning pipelines that allows the
server to aggregate the client updates without accessing them individually. In
particular, we adapt standard scalar quantization and pruning methods to Secure
Aggregation and propose Secure Indexing, a variant of Secure Aggregation that
supports quantization for extreme compression. We establish state-of-the-art
results on LEAF benchmarks in a secure Federated Learning setup with up to
40$\times$ compression in uplink communication with no meaningful loss in
utility compared to uncompressed baselines.",https://github.com/facebookresearch/SecureFLCompression,-1
1210a834-c75c-4b6d-a6c5-0419c9b87300,Zero-shot Aspect-level Sentiment Classification via Explicit Utilization of Aspect-to-Document Sentiment Composition,0.0812469,"As aspect-level sentiment labels are expensive and labor-intensive to
acquire, zero-shot aspect-level sentiment classification is proposed to learn
classifiers applicable to new domains without using any annotated aspect-level
data. In contrast, document-level sentiment data with ratings are more easily
accessible. In this work, we achieve zero-shot aspect-level sentiment
classification by only using document-level reviews. Our key intuition is that
the sentiment representation of a document is composed of the sentiment
representations of all the aspects of that document. Based on this, we propose
the AF-DSC method to explicitly model such sentiment composition in reviews.
AF-DSC first learns sentiment representations for all potential aspects and
then aggregates aspect-level sentiments into a document-level one to perform
document-level sentiment classification. In this way, we obtain the
aspect-level sentiment classifier as the by-product of the document-level
sentiment classifier. Experimental results on aspect-level sentiment
classification benchmarks demonstrate the effectiveness of explicit utilization
of sentiment composition in document-level sentiment classification. Our model
with only 30k training data outperforms previous work utilizing millions of
data.",https://github.com/explosion/,-1
a73e1d7c-48d0-4b39-a7a7-5758cf3d4ac7,Curator: Creating Large-Scale Curated Labelled Datasets using Self-Supervised Learning,0.02449,"Applying Machine learning to domains like Earth Sciences is impeded by the
lack of labeled data, despite a large corpus of raw data available in such
domains. For instance, training a wildfire classifier on satellite imagery
requires curating a massive and diverse dataset, which is an expensive and
time-consuming process that can span from weeks to months. Searching for
relevant examples in over 40 petabytes of unlabelled data requires researchers
to manually hunt for such images, much like finding a needle in a haystack. We
present a no-code end-to-end pipeline, Curator, which dramatically minimizes
the time taken to curate an exhaustive labeled dataset. Curator is able to
search massive amounts of unlabelled data by combining self-supervision,
scalable nearest neighbor search, and active learning to learn and
differentiate image representations. The pipeline can also be readily applied
to solve problems across different domains. Overall, the pipeline makes it
practical for researchers to go from just one reference image to a
comprehensive dataset in a diminutive span of time.",https://www.github.com/spaceml-org,-1
caf63646-54e7-407b-a8f3-c5df257fd7d1,Emergent Communication for Understanding Human Language Evolution: What's Missing?,0.942802,"Emergent communication protocols among humans and artificial neural network
agents do not yet share the same properties and show some critical mismatches
in results. We describe three important phenomena with respect to the emergence
and benefits of compositionality: ease-of-learning, generalization, and group
size effects (i.e., larger groups create more systematic languages). The latter
two are not fully replicated with neural agents, which hinders the use of
neural emergent communication for language evolution research. We argue that
one possible reason for these mismatches is that key cognitive and
communicative constraints of humans are not yet integrated. Specifically, in
humans, memory constraints and the alternation between the roles of speaker and
listener underlie the emergence of linguistic structure, yet these constraints
are typically absent in neural simulations. We suggest that introducing such
communicative and cognitive constraints would promote more linguistically
plausible behaviors with neural agents.",None,-1
5a778814-3d10-457e-8417-77a7f3e24e91,Towards Tracing Factual Knowledge in Language Models Back to the Training Data,0.321927,"Language models (LMs) have been shown to memorize a great deal of factual
knowledge contained in their training data. But when an LM generates an
assertion, it is often difficult to determine where it learned this information
and whether it is true. In this paper, we propose the problem of fact tracing:
identifying which training examples taught an LM to generate a particular
factual assertion. Prior work on training data attribution (TDA) may offer
effective tools for identifying such examples, known as ""proponents"". We
present the first quantitative benchmark to evaluate this. We compare two
popular families of TDA methods -- gradient-based and embedding-based -- and
find that much headroom remains. For example, both methods have lower
proponent-retrieval precision than an information retrieval baseline (BM25)
that does not have access to the LM at all. We identify key challenges that may
be necessary for further improvement such as overcoming the problem of gradient
saturation, and also show how several nuanced implementation details of
existing neural TDA methods can significantly improve overall fact tracing
performance.",https://github.com/ekinakyurek/influence,-1
61717a42-3519-4cc0-a81e-3036af985eec,TaSPM: Targeted Sequential Pattern Mining,0.671764,"Sequential pattern mining (SPM) is an important technique of pattern mining,
which has many applications in reality. Although many efficient sequential
pattern mining algorithms have been proposed, there are few studies can focus
on target sequences. Targeted querying sequential patterns can not only reduce
the number of sequences generated by SPM, but also improve the efficiency of
users in performing pattern analysis. The current algorithms available on
targeted sequence querying are based on specific scenarios and cannot be
generalized to other applications. In this paper, we formulate the problem of
targeted sequential pattern mining and propose a generic framework namely
TaSPM, based on the fast CM-SPAM algorithm. What's more, to improve the
efficiency of TaSPM on large-scale datasets and multiple-items-based sequence
datasets, we propose several pruning strategies to reduce meaningless
operations in mining processes. Totally four pruning strategies are designed in
TaSPM, and hence it can terminate unnecessary pattern extensions quickly and
achieve better performance. Finally, we conduct extensive experiments on
different datasets to compare the existing SPM algorithms with TaSPM.
Experiments show that the novel targeted mining algorithm TaSPM can achieve
faster running time and less memory consumption.",None,-1
a846b18f-1b3c-43a4-9777-06581bd94895,OTPose: Occlusion-Aware Transformer for Pose Estimation in Sparsely-Labeled Videos,0.363362,"Although many approaches for multi-human pose estimation in videos have shown
profound results, they require densely annotated data which entails excessive
man labor. Furthermore, there exists occlusion and motion blur that inevitably
lead to poor estimation performance. To address these problems, we propose a
method that leverages an attention mask for occluded joints and encodes
temporal dependency between frames using transformers. First, our framework
composes different combinations of sparsely annotated frames that denote the
track of the overall joint movement. We propose an occlusion attention mask
from these combinations that enable encoding occlusion-aware heatmaps as a
semi-supervised task. Second, the proposed temporal encoder employs transformer
architecture to effectively aggregate the temporal relationship and
keypoint-wise attention from each time step and accurately refines the target
frame's final pose estimation. We achieve state-of-the-art pose estimation
results for PoseTrack2017 and PoseTrack2018 datasets and demonstrate the
robustness of our approach to occlusion and motion blur in sparsely annotated
video data.",None,-1
4566d250-f8fc-4c84-a5a2-390c876cbdef,World of Bugs: A Platform for Automated Bug Detection in 3D Video Games,0.412464,"We present World of Bugs (WOB), an open platform that aims to support
Automated Bug Detection (ABD) research in video games. We discuss some open
problems in ABD and how they relate to the platform's design, arguing that
learning-based solutions are required if further progress is to be made. The
platform's key feature is a growing collection of common video game bugs that
may be used for training and evaluating ABD approaches.",None,-1
723dd5d4-003c-4e07-bd90-82e5872b7ce1,End-to-End Spoken Language Understanding: Performance analyses of a voice command task in a low resource setting,0.234305,"Spoken Language Understanding (SLU) is a core task in most human-machine
interaction systems. With the emergence of smart homes, smart phones and smart
speakers, SLU has become a key technology for the industry. In a classical SLU
approach, an Automatic Speech Recognition (ASR) module transcribes the speech
signal into a textual representation from which a Natural Language
Understanding (NLU) module extracts semantic information. Recently End-to-End
SLU (E2E SLU) based on Deep Neural Networks has gained momentum since it
benefits from the joint optimization of the ASR and the NLU parts, hence
limiting the cascade of error effect of the pipeline architecture. However,
little is known about the actual linguistic properties used by E2E models to
predict concepts and intents from speech input. In this paper, we present a
study identifying the signal features and other linguistic properties used by
an E2E model to perform the SLU task. The study is carried out in the
application domain of a smart home that has to handle non-English (here French)
voice commands. The results show that a good E2E SLU performance does not
always require a perfect ASR capability. Furthermore, the results show the
superior capabilities of the E2E model in handling background noise and
syntactic variation compared to the pipeline model. Finally, a finer-grained
analysis suggests that the E2E model uses the pitch information of the input
signal to identify voice command concepts. The results and methodology outlined
in this paper provide a springboard for further analyses of E2E models in
speech processing.",None,-1
ecabdc66-f64b-4b1c-ac58-9ce4a0386771,Discovering Transferable Forensic Features for CNN-generated Images Detection,0.727816,"Visual counterfeits are increasingly causing an existential conundrum in
mainstream media with rapid evolution in neural image synthesis methods. Though
detection of such counterfeits has been a taxing problem in the image forensics
community, a recent class of forensic detectors -- universal detectors -- are
able to surprisingly spot counterfeit images regardless of generator
architectures, loss functions, training datasets, and resolutions. This
intriguing property suggests the possible existence of transferable forensic
features (T-FF) in universal detectors. In this work, we conduct the first
analytical study to discover and understand T-FF in universal detectors. Our
contributions are 2-fold: 1) We propose a novel forensic feature relevance
statistic (FF-RS) to quantify and discover T-FF in universal detectors and, 2)
Our qualitative and quantitative investigations uncover an unexpected finding:
color is a critical T-FF in universal detectors. Code and models are available
at https://keshik6.github.io/transferable-forensic-features/",None,-1
241ca2a6-fb0e-40fa-b293-aec986b5684b,SeqOT: A Spatial-Temporal Transformer Network for Place Recognition Using Sequential LiDAR Data,0.997881,"Place recognition is an important component for autonomous vehicles to
achieve loop closing or global localization. In this paper, we tackle the
problem of place recognition based on sequential 3D LiDAR scans obtained by an
onboard LiDAR sensor. We propose a transformer-based network named SeqOT to
exploit the temporal and spatial information provided by sequential range
images generated from the LiDAR data. It uses multi-scale transformers to
generate a global descriptor for each sequence of LiDAR range images in an
end-to-end fashion. During online operation, our SeqOT finds similar places by
matching such descriptors between the current query sequence and those stored
in the map. We evaluate our approach on four datasets collected with different
types of LiDAR sensors in different environments. The experimental results show
that our method outperforms the state-of-the-art LiDAR-based place recognition
methods and generalizes well across different environments. Furthermore, our
method operates online faster than the frame rate of the sensor. The
implementation of our method is released as open source at:
https://github.com/BIT-MJY/SeqOT.",https://github.com/BIT-MJY/SeqOT,108
066b55e4-3d42-4f13-b417-21eb6abfcedb,Training-Free Robust Multimodal Learning via Sample-Wise Jacobian Regularization,0.20687,"Multimodal fusion emerges as an appealing technique to improve model
performances on many tasks. Nevertheless, the robustness of such fusion methods
is rarely involved in the present literature. In this paper, we propose a
training-free robust late-fusion method by exploiting conditional independence
assumption and Jacobian regularization. Our key is to minimize the Frobenius
norm of a Jacobian matrix, where the resulting optimization problem is relaxed
to a tractable Sylvester equation. Furthermore, we provide a theoretical error
bound of our method and some insights about the function of the extra modality.
Several numerical experiments on AV-MNIST, RAVDESS, and VGGsound demonstrate
the efficacy of our method under both adversarial attacks and random
corruptions.",None,18787
24764b26-5158-43fb-a389-d0f7608d3f88,A BERT-based Deep Learning Approach for Reputation Analysis in Social Media,0.333257,"Social media has become an essential part of the modern lifestyle, with its
usage being highly prevalent. This has resulted in unprecedented amounts of
data generated from users in social media, such as users' attitudes, opinions,
interests, purchases, and activities across various aspects of their lives.
Therefore, in a world of social media, where its power has shifted to users,
actions taken by companies and public figures are subject to constantly being
under scrutiny by influential global audiences. As a result, reputation
management in social media has become essential as companies and public figures
need to maintain their reputation to preserve their reputation capital.
However, domain experts still face the challenge of lacking appropriate
solutions to automate reliable online reputation analysis. To tackle this
challenge, we proposed a novel reputation analysis approach based on the
popular language model BERT (Bidirectional Encoder Representations from
Transformers). The proposed approach was evaluated on the reputational polarity
task using RepLab 2013 dataset. Compared to previous works, we achieved 5.8%
improvement in accuracy, 26.9% improvement in balanced accuracy, and 21.8%
improvement in terms of F-score.",None,12055
0265444c-bf9e-4cd8-ac4f-4af206deb5e6,Recognition of Implicit Geographic Movement in Text,0.0448696,"Analyzing the geographic movement of humans, animals, and other phenomena is
a growing field of research. This research has benefited urban planning,
logistics, animal migration understanding, and much more. Typically, the
movement is captured as precise geographic coordinates and time stamps with
Global Positioning Systems (GPS). Although some research uses computational
techniques to take advantage of implicit movement in descriptions of route
directions, hiking paths, and historical exploration routes, innovation would
accelerate with a large and diverse corpus. We created a corpus of sentences
labeled as describing geographic movement or not and including the type of
entity moving. Creating this corpus proved difficult without any comparable
corpora to start with, high human labeling costs, and since movement can at
times be interpreted differently. To overcome these challenges, we developed an
iterative process employing hand labeling, crowd voting for confirmation, and
machine learning to predict more labels. By merging advances in word embeddings
with traditional machine learning models and model ensembling, prediction
accuracy is at an acceptable level to produce a large silver-standard corpus
despite the small gold-standard corpus training set. Our corpus will likely
benefit computational processing of geography in text and spatial cognition, in
addition to detection of movement.",None,1280
f72dc8d8-50f6-4149-a163-0fb5d579839d,A Universal Discriminator for Zero-Shot Generalization,0.377566,"Generative modeling has been the dominant approach for large-scale
pretraining and zero-shot generalization. In this work, we challenge this
convention by showing that discriminative approaches perform substantially
better than generative ones on a large number of NLP tasks. Technically, we
train a single discriminator to predict whether a text sample comes from the
true data distribution, similar to GANs. Since many NLP tasks can be formulated
as selecting from a few options, we use this discriminator to predict the
concatenation of input and which option has the highest probability of coming
from the true data distribution. This simple formulation achieves
state-of-the-art zero-shot results on the T0 benchmark, outperforming T0 by
16.0\%, 7.8\%, and 11.5\% respectively on different scales. In the finetuning
setting, our approach also achieves new state-of-the-art results on a wide
range of NLP tasks, with only 1/4 parameters of previous methods. Meanwhile,
our approach requires minimal prompting efforts, which largely improves
robustness and is essential for real-world applications. Furthermore, we also
jointly train a generalized UD in combination with generative tasks, which
maintains its advantage on discriminative tasks and simultaneously works on
generative tasks.",https://github.com/Rafa-zy/UD,-1
c9090333-146a-410c-bef3-4e2b171b14f6,Sky Computing: Accelerating Geo-distributed Computing in Federated Learning,0.0582988,"Federated learning is proposed by Google to safeguard data privacy through
training models locally on users' devices. However, with deep learning models
growing in size to achieve better results, it becomes increasingly difficult to
accommodate the whole model on one single device. Thus, model parallelism is
then used to divide the model weights among several devices. With this logic,
the approach currently used evenly allocates weights among devices. However, in
reality, a computation bottleneck may occur resulting from variant computing
power of different users' devices. To address this problem, load balancing is
needed to allocate the model weights based on the computational capability of
the device. In this paper, we proposed Sky Computing, a load-balanced model
parallelism framework to adaptively allocate the weights to devices. Sky
Computing outperforms the baseline method by 55% in training time when training
160-layer BERT with 64 nodes. The source code can be found at
https://github.com/hpcaitech/SkyComputing.",https://github.com/hpcaitech/SkyComputing,-1
1f3943b1-a1f2-48ed-a8dd-66034000d1a9,Modeling Label Correlations for Ultra-Fine Entity Typing with Neural Pairwise Conditional Random Field,0.625551,"Ultra-fine entity typing (UFET) aims to predict a wide range of type phrases
that correctly describe the categories of a given entity mention in a sentence.
Most recent works infer each entity type independently, ignoring the
correlations between types, e.g., when an entity is inferred as a president, it
should also be a politician and a leader. To this end, we use an undirected
graphical model called pairwise conditional random field (PCRF) to formulate
the UFET problem, in which the type variables are not only unarily influenced
by the input but also pairwisely relate to all the other type variables. We use
various modern backbones for entity typing to compute unary potentials, and
derive pairwise potentials from type phrase representations that both capture
prior semantic information and facilitate accelerated inference. We use
mean-field variational inference for efficient type inference on very large
type sets and unfold it as a neural network module to enable end-to-end
training. Experiments on UFET show that the Neural-PCRF consistently
outperforms its backbones with little cost and results in a competitive
performance against cross-encoder based SOTA while being thousands of times
faster. We also find Neural- PCRF effective on a widely used fine-grained
entity typing dataset with a smaller type set. We pack Neural-PCRF as a network
module that can be plugged onto multi-label type classifiers with ease and
release it in https://github.com/modelscope/adaseq/tree/master/examples/NPCRF.",https://github.com/modelscope/adaseq/tree/master/examples/NPCRF,-1
71aa4839-ab88-47ad-9b2f-5fa6596a35de,Exploring Wasserstein Distance across Concept Embeddings for Ontology Matching,0.122438,"Measuring the distance between ontological elements is fundamental for
ontology matching. String-based distance metrics are notorious for shallow
syntactic matching. In this exploratory study, we investigate Wasserstein
distance targeting continuous space that can incorporate various types of
information. We use a pre-trained word embeddings system to embed ontology
element labels. We examine the effectiveness of Wasserstein distance for
measuring similarity between ontologies, and discovering and refining matchings
between individual elements. Our experiments with the OAEI conference track and
MSE benchmarks achieved competitive results compared to the leading systems.",https://github.com/EngyNasr/MSE-Benchmark,-1
62816451-a94c-4650-9766-056a03421a59,Learning to Decompose Visual Features with Latent Textual Prompts,0.783576,"Recent advances in pre-training vision-language models like CLIP have shown
great potential in learning transferable visual representations. Nonetheless,
for downstream inference, CLIP-like models suffer from either 1) degraded
accuracy and robustness in the case of inaccurate text descriptions during
retrieval-based inference (the challenge for zero-shot protocol); or 2)
breaking the well-established vision-language alignment (the challenge for
linear probing). To address them, we propose Decomposed Feature Prompting
(DeFo). DeFo leverages a flexible number of learnable embeddings as textual
input while maintaining the vision-language dual-model architecture, which
enables the model to learn decomposed visual features with the help of
feature-level textual prompts. We further use an additional linear layer to
perform classification, allowing a scalable size of language inputs. Our
empirical study shows DeFo's significance in improving the vision-language
models. For example, DeFo obtains 73.2% test accuracy on ImageNet with a
ResNet-50 backbone without tuning any pretrained weights of both the vision and
language encoder, outperforming zero-shot CLIP by a large margin of 15.0%, and
outperforming state-of-the-art vision-language prompt tuning method by 7.6%.",None,-1
fbf96439-4465-4592-828f-3143fdcfcb05,Unpacking Large Language Models with Conceptual Consistency,0.418932,"If a Large Language Model (LLM) answers ""yes"" to the question ""Are mountains
tall?"" then does it know what a mountain is? Can you rely on it responding
correctly or incorrectly to other questions about mountains? The success of
Large Language Models (LLMs) indicates they are increasingly able to answer
queries like these accurately, but that ability does not necessarily imply a
general understanding of concepts relevant to the anchor query. We propose
conceptual consistency to measure a LLM's understanding of relevant concepts.
This novel metric measures how well a model can be characterized by finding out
how consistent its responses to queries about conceptually relevant background
knowledge are. To compute it we extract background knowledge by traversing
paths between concepts in a knowledge base and then try to predict the model's
response to the anchor query from the background knowledge. We investigate the
performance of current LLMs in a commonsense reasoning setting using the CSQA
dataset and the ConceptNet knowledge base. While conceptual consistency, like
other metrics, does increase with the scale of the LLM used, we find that
popular models do not necessarily have high conceptual consistency. Our
analysis also shows significant variation in conceptual consistency across
different kinds of relations, concepts, and prompts. This serves as a step
toward building models that humans can apply a theory of mind to, and thus
interact with intuitively.",None,-1
3d630b70-be44-485d-8e07-689c4245ab51,FedX: Unsupervised Federated Learning with Cross Knowledge Distillation,0.761076,"This paper presents FedX, an unsupervised federated learning framework. Our
model learns unbiased representation from decentralized and heterogeneous local
data. It employs a two-sided knowledge distillation with contrastive learning
as a core component, allowing the federated system to function without
requiring clients to share any data features. Furthermore, its adaptable
architecture can be used as an add-on module for existing unsupervised
algorithms in federated settings. Experiments show that our model improves
performance significantly (1.58--5.52pp) on five unsupervised algorithms.",https://github.com/Sungwon-Han/FEDX,-1
36413736-69c9-4a59-92f1-8be7a700973a,DETR++: Taming Your Multi-Scale Detection Transformer,0.252993,"Convolutional Neural Networks (CNN) have dominated the field of detection
ever since the success of AlexNet in ImageNet classification [12]. With the
sweeping reform of Transformers [27] in natural language processing, Carion et
al. [2] introduce the Transformer-based detection method, i.e., DETR. However,
due to the quadratic complexity in the self-attention mechanism in the
Transformer, DETR is never able to incorporate multi-scale features as
performed in existing CNN-based detectors, leading to inferior results in small
object detection. To mitigate this issue and further improve performance of
DETR, in this work, we investigate different methods to incorporate multi-scale
features and find that a Bi-directional Feature Pyramid (BiFPN) works best with
DETR in further raising the detection precision. With this discovery, we
propose DETR++, a new architecture that improves detection results by 1.9% AP
on MS COCO 2017, 11.5% AP on RICO icon detection, and 9.1% AP on RICO layout
extraction over existing baselines.",None,7581
69ed1fd1-a5a9-467c-a3ff-47ee58a6c62f,Intake Monitoring in Free-Living Conditions: Overview and Lessons we Have Learned,0.0774131,"The progress in artificial intelligence and machine learning algorithms over
the past decade has enabled the development of new methods for the objective
measurement of eating, including both the measurement of eating episodes as
well as the measurement of in-meal eating behavior. These allow the study of
eating behavior outside the laboratory in free-living conditions, without the
need for video recordings and laborious manual annotations. In this paper, we
present a high-level overview of our recent work on intake monitoring using a
smartwatch, as well as methods using an in-ear microphone. We also present
evaluation results of these methods in challenging, real-world datasets.
Furthermore, we discuss use-cases of such intake monitoring tools for advancing
research in eating behavior, for improving dietary monitoring, as well as for
developing evidence-based health policies. Our goal is to inform researchers
and users of intake monitoring methods regarding (i) the development of new
methods based on commercially available devices, (ii) what to expect in terms
of effectiveness, and (iii) how these methods can be used in research as well
as in practical applications.",None,-1
a634f3c1-adaa-4fca-81a2-8b3e309b68ab,Continual Learning Beyond a Single Model,0.183611,"A growing body of research in continual learning focuses on the catastrophic
forgetting problem. While many attempts have been made to alleviate this
problem, the majority of the methods assume a single model in the continual
learning setup. In this work, we question this assumption and show that
employing ensemble models can be a simple yet effective method to improve
continual performance. However, ensembles' training and inference costs can
increase significantly as the number of models grows. Motivated by this
limitation, we study different ensemble models to understand their benefits and
drawbacks in continual learning scenarios. Finally, to overcome the high
compute cost of ensembles, we leverage recent advances in neural network
subspace to propose a computationally cheap algorithm with similar runtime to a
single model yet enjoying the performance benefits of ensembles.",None,-1
072cf838-4966-4bf4-bd20-93c72d63c703,M-VADER: A Model for Diffusion with Multimodal Context,0.142519,"We introduce M-VADER: a diffusion model (DM) for image generation where the
output can be specified using arbitrary combinations of images and text. We
show how M-VADER enables the generation of images specified using combinations
of image and text, and combinations of multiple images. Previously, a number of
successful DM image generation algorithms have been introduced that make it
possible to specify the output image using a text prompt. Inspired by the
success of those models, and led by the notion that language was already
developed to describe the elements of visual contexts that humans find most
important, we introduce an embedding model closely related to a vision-language
model. Specifically, we introduce the embedding model S-MAGMA: a 13 billion
parameter multimodal decoder combining components from an autoregressive
vision-language model MAGMA and biases finetuned for semantic search.",https://github.com/CompVis/stable-diﬀusion,-1
5ff2535e-7c66-4f26-bf1b-fc3d586aa737,A Psychological Theory of Explainability,0.320897,"The goal of explainable Artificial Intelligence (XAI) is to generate
human-interpretable explanations, but there are no computationally precise
theories of how humans interpret AI generated explanations. The lack of theory
means that validation of XAI must be done empirically, on a case-by-case basis,
which prevents systematic theory-building in XAI. We propose a psychological
theory of how humans draw conclusions from saliency maps, the most common form
of XAI explanation, which for the first time allows for precise prediction of
explainee inference conditioned on explanation. Our theory posits that absent
explanation humans expect the AI to make similar decisions to themselves, and
that they interpret an explanation by comparison to the explanations they
themselves would give. Comparison is formalized via Shepard's universal law of
generalization in a similarity space, a classic theory from cognitive science.
A pre-registered user study on AI image classifications with saliency map
explanations demonstrate that our theory quantitatively matches participants'
predictions of the AI.",None,-1
739876d2-43da-4367-8f5c-7aa88777a90d,Revisiting DocRED -- Addressing the False Negative Problem in Relation Extraction,0.74584,"The DocRED dataset is one of the most popular and widely used benchmarks for
document-level relation extraction (RE). It adopts a recommend-revise
annotation scheme so as to have a large-scale annotated dataset. However, we
find that the annotation of DocRED is incomplete, i.e., false negative samples
are prevalent. We analyze the causes and effects of the overwhelming false
negative problem in the DocRED dataset. To address the shortcoming, we
re-annotate 4,053 documents in the DocRED dataset by adding the missed relation
triples back to the original DocRED. We name our revised DocRED dataset
Re-DocRED. We conduct extensive experiments with state-of-the-art neural models
on both datasets, and the experimental results show that the models trained and
evaluated on our Re-DocRED achieve performance improvements of around 13 F1
points. Moreover, we conduct a comprehensive analysis to identify the potential
areas for further improvement. Our dataset is publicly available at
https://github.com/tonytan48/Re-DocRED.",https://github.com/tonytan48/Re-DocRED,-1
80cb945a-e8ed-4876-8cd7-a1b15ca8a072,N-QGN: Navigation Map from a Monocular Camera using Quadtree Generating Networks,0.071735,"Monocular depth estimation has been a popular area of research for several
years, especially since self-supervised networks have shown increasingly good
results in bridging the gap with supervised and stereo methods. However, these
approaches focus their interest on dense 3D reconstruction and sometimes on
tiny details that are superfluous for autonomous navigation. In this paper, we
propose to address this issue by estimating the navigation map under a quadtree
representation. The objective is to create an adaptive depth map prediction
that only extract details that are essential for the obstacle avoidance. Other
3D space which leaves large room for navigation will be provided with
approximate distance. Experiment on KITTI dataset shows that our method can
significantly reduce the number of output information without major loss of
accuracy.",None,-1
aaf77109-161c-4e16-b983-a8bca9f3445a,Sample-Efficient Reinforcement Learning of Partially Observable Markov Games,0.754062,"This paper considers the challenging tasks of Multi-Agent Reinforcement
Learning (MARL) under partial observability, where each agent only sees her own
individual observations and actions that reveal incomplete information about
the underlying state of system. This paper studies these tasks under the
general model of multiplayer general-sum Partially Observable Markov Games
(POMGs), which is significantly larger than the standard model of Imperfect
Information Extensive-Form Games (IIEFGs). We identify a rich subclass of POMGs
-- weakly revealing POMGs -- in which sample-efficient learning is tractable.
In the self-play setting, we prove that a simple algorithm combining optimism
and Maximum Likelihood Estimation (MLE) is sufficient to find approximate Nash
equilibria, correlated equilibria, as well as coarse correlated equilibria of
weakly revealing POMGs, in a polynomial number of samples when the number of
agents is small. In the setting of playing against adversarial opponents, we
show that a variant of our optimistic MLE algorithm is capable of achieving
sublinear regret when being compared against the optimal maximin policies. To
our best knowledge, this work provides the first line of sample-efficient
results for learning POMGs.",None,-1
01cb360b-00a0-483f-b46b-230a1fe746dc,An Attention-based Method for Action Unit Detection at the 3rd ABAW Competition,0.636091,"Facial Action Coding System is an approach for modeling the complexity of
human emotional expression. Automatic action unit (AU) detection is a crucial
research area in human-computer interaction. This paper describes our
submission to the third Affective Behavior Analysis in-the-wild (ABAW)
competition 2022. We proposed a method for detecting facial action units in the
video. At the first stage, a lightweight CNN-based feature extractor is
employed to extract the feature map from each video frame. Then, an attention
module is applied to refine the attention map. The attention encoded vector is
derived using a weighted sum of the feature map and the attention scores later.
Finally, the sigmoid function is used at the output layer to make the
prediction suitable for multi-label AUs detection. We achieved a macro F1 score
of 0.48 on the ABAW challenge validation set compared to 0.39 from the baseline
model.",None,-1
4bba9a04-1ad1-46d2-98e4-2cbd64c20ad0,Interactive Language: Talking to Robots in Real Time,0.994635,"We present a framework for building interactive, real-time, natural
language-instructable robots in the real world, and we open source related
assets (dataset, environment, benchmark, and policies). Trained with behavioral
cloning on a dataset of hundreds of thousands of language-annotated
trajectories, a produced policy can proficiently execute an order of magnitude
more commands than previous works: specifically we estimate a 93.5% success
rate on a set of 87,000 unique natural language strings specifying raw
end-to-end visuo-linguo-motor skills in the real world. We find that the same
policy is capable of being guided by a human via real-time language to address
a wide range of precise long-horizon rearrangement goals, e.g. ""make a smiley
face out of blocks"". The dataset we release comprises nearly 600,000
language-labeled trajectories, an order of magnitude larger than prior
available datasets. We hope the demonstrated results and associated assets
enable further advancement of helpful, capable, natural-language-interactable
robots. See videos at https://interactive-language.github.io.",None,-1
5c69f65e-ace3-4295-9d0c-5bc2392e669d,Robust Structured Declarative Classifiers for 3D Point Clouds: Defending Adversarial Attacks with Implicit Gradients,0.591824,"Deep neural networks for 3D point cloud classification, such as PointNet,
have been demonstrated to be vulnerable to adversarial attacks. Current
adversarial defenders often learn to denoise the (attacked) point clouds by
reconstruction, and then feed them to the classifiers as input. In contrast to
the literature, we propose a family of robust structured declarative
classifiers for point cloud classification, where the internal constrained
optimization mechanism can effectively defend adversarial attacks through
implicit gradients. Such classifiers can be formulated using a bilevel
optimization framework. We further propose an effective and efficient
instantiation of our approach, namely, Lattice Point Classifier (LPC), based on
structured sparse coding in the permutohedral lattice and 2D convolutional
neural networks (CNNs) that is end-to-end trainable. We demonstrate
state-of-the-art robust point cloud classification performance on ModelNet40
and ScanNet under seven different attackers. For instance, we achieve 89.51%
and 83.16% test accuracy on each dataset under the recent JGBA attacker that
outperforms DUP-Net and IF-Defense with PointNet by ~70%. Demo code is
available at https://zhang-vislab.github.io.",https://zhang-vislab.github.io,-1
9d04bd7f-a5ee-4ea4-97cc-58d2c99b4419,Which side are you on? Insider-Outsider classification in conspiracy-theoretic social media,0.454069,"Social media is a breeding ground for threat narratives and related
conspiracy theories. In these, an outside group threatens the integrity of an
inside group, leading to the emergence of sharply defined group identities:
Insiders -- agents with whom the authors identify and Outsiders -- agents who
threaten the insiders. Inferring the members of these groups constitutes a
challenging new NLP task: (i) Information is distributed over many
poorly-constructed posts; (ii) Threats and threat agents are highly contextual,
with the same post potentially having multiple agents assigned to membership in
either group; (iii) An agent's identity is often implicit and transitive; and
(iv) Phrases used to imply Outsider status often do not follow common negative
sentiment patterns. To address these challenges, we define a novel
Insider-Outsider classification task. Because we are not aware of any
appropriate existing datasets or attendant models, we introduce a labeled
dataset (CT5K) and design a model (NP2IO) to address this task. NP2IO leverages
pretrained language modeling to classify Insiders and Outsiders. NP2IO is shown
to be robust, generalizing to noun phrases not seen during training, and
exceeding the performance of non-trivial baseline models by $20\%$.",https://github.com/heartexlabs/label-studio,-1
7eeb36f6-4f16-4a4a-8dd7-a67994973bc4,Evaluating Long-Term Memory in 3D Mazes,0.536736,"Intelligent agents need to remember salient information to reason in
partially-observed environments. For example, agents with a first-person view
should remember the positions of relevant objects even if they go out of view.
Similarly, to effectively navigate through rooms agents need to remember the
floor plan of how rooms are connected. However, most benchmark tasks in
reinforcement learning do not test long-term memory in agents, slowing down
progress in this important research direction. In this paper, we introduce the
Memory Maze, a 3D domain of randomized mazes specifically designed for
evaluating long-term memory in agents. Unlike existing benchmarks, Memory Maze
measures long-term memory separate from confounding agent abilities and
requires the agent to localize itself by integrating information over time.
With Memory Maze, we propose an online reinforcement learning benchmark, a
diverse offline dataset, and an offline probing evaluation. Recording a human
player establishes a strong baseline and verifies the need to build up and
retain memories, which is reflected in their gradually increasing rewards
within each episode. We find that current algorithms benefit from training with
truncated backpropagation through time and succeed on small mazes, but fall
short of human performance on the large mazes, leaving room for future
algorithmic designs to be evaluated on the Memory Maze.",https://github.com/jurgisp/memory-maze,-1
8a59b0ee-a9ff-4a16-bca6-73995dacb41a,Attention-Aware Anime Line Drawing Colorization,0.474212,"Automatic colorization of anime line drawing has attracted much attention in
recent years since it can substantially benefit the animation industry.
User-hint based methods are the mainstream approach for line drawing
colorization, while reference-based methods offer a more intuitive approach.
Nevertheless, although reference-based methods can improve feature aggregation
of the reference image and the line drawing, the colorization results are not
compelling in terms of color consistency or semantic correspondence. In this
paper, we introduce an attention-based model for anime line drawing
colorization, in which a channel-wise and spatial-wise Convolutional Attention
module is used to improve the ability of the encoder for feature extraction and
key area perception, and a Stop-Gradient Attention module with cross-attention
and self-attention is used to tackle the cross-domain long-range dependency
problem. Extensive experiments show that our method outperforms other SOTA
methods, with more accurate line structure and semantic color information.",None,-1
73b30ce8-f8dd-4696-a63c-f5866bddfe9c,PReGAN: Answer Oriented Passage Ranking with Weakly Supervised GAN,0.102496,"Beyond topical relevance, passage ranking for open-domain factoid question
answering also requires a passage to contain an answer (answerability). While a
few recent studies have incorporated some reading capability into a ranker to
account for answerability, the ranker is still hindered by the noisy nature of
the training data typically available in this area, which considers any passage
containing an answer entity as a positive sample. However, the answer entity in
a passage is not necessarily mentioned in relation with the given question. To
address the problem, we propose an approach called \ttt{PReGAN} for Passage
Reranking based on Generative Adversarial Neural networks, which incorporates a
discriminator on answerability, in addition to a discriminator on topical
relevance. The goal is to force the generator to rank higher a passage that is
topically relevant and contains an answer. Experiments on five public datasets
show that \ttt{PReGAN} can better rank appropriate passages, which in turn,
boosts the effectiveness of QA systems, and outperforms the existing approaches
without using external data.",https://github.com/facebookresearch/DPR,-1
4b15d021-67b1-4759-bd85-e4667feb1ff7,A Better Choice: Entire-space Datasets for Aspect Sentiment Triplet Extraction,0.242394,"Aspect sentiment triplet extraction (ASTE) aims to extract aspect term,
sentiment and opinion term triplets from sentences. Since the initial datasets
used to evaluate models on ASTE had flaws, several studies later corrected the
initial datasets and released new versions of the datasets independently. As a
result, different studies select different versions of datasets to evaluate
their methods, which makes ASTE-related works hard to follow. In this paper, we
analyze the relation between different versions of datasets and suggest that
the entire-space version should be used for ASTE. Besides the sentences
containing triplets and the triplets in the sentences, the entire-space version
additionally includes the sentences without triplets and the aspect terms which
do not belong to any triplets. Hence, the entire-space version is consistent
with real-world scenarios and evaluating models on the entire-space version can
better reflect the models' performance in real-world scenarios. In addition,
experimental results show that evaluating models on non-entire-space datasets
inflates the performance of existing models and models trained on the
entire-space version can obtain better performance.",https://github.com/l294265421/entire-space-aste,-1
9d712748-bc94-4f37-9a5b-644a668429c1,NeuMesh: Learning Disentangled Neural Mesh-based Implicit Field for Geometry and Texture Editing,0.99984,"Very recently neural implicit rendering techniques have been rapidly evolved
and shown great advantages in novel view synthesis and 3D scene reconstruction.
However, existing neural rendering methods for editing purposes offer limited
functionality, e.g., rigid transformation, or not applicable for fine-grained
editing for general objects from daily lives. In this paper, we present a novel
mesh-based representation by encoding the neural implicit field with
disentangled geometry and texture codes on mesh vertices, which facilitates a
set of editing functionalities, including mesh-guided geometry editing,
designated texture editing with texture swapping, filling and painting
operations. To this end, we develop several techniques including learnable sign
indicators to magnify spatial distinguishability of mesh-based representation,
distillation and fine-tuning mechanism to make a steady convergence, and the
spatial-aware optimization strategy to realize precise texture editing.
Extensive experiments and editing examples on both real and synthetic data
demonstrate the superiority of our method on representation quality and editing
ability. Code is available on the project webpage:
https://zju3dv.github.io/neumesh/.",https://zju3dv.github.io/neumesh/,-1
5724a834-e937-47f5-a863-3d41776571af,The Royalflush System for VoxCeleb Speaker Recognition Challenge 2022,0.0834846,"In this technical report, we describe the Royalflush submissions for the
VoxCeleb Speaker Recognition Challenge 2022 (VoxSRC-22). Our submissions
contain track 1, which is for supervised speaker verification and track 3,
which is for semi-supervised speaker verification. For track 1, we develop a
powerful U-Net-based speaker embedding extractor with a symmetric architecture.
The proposed system achieves 2.06% in EER and 0.1293 in MinDCF on the
validation set. Compared with the state-of-the-art ECAPA-TDNN, it obtains a
relative improvement of 20.7% in EER and 22.70% in MinDCF. For track 3, we
employ the joint training of source domain supervision and target domain
self-supervision to get a speaker embedding extractor. The subsequent
clustering process can obtain target domain pseudo-speaker labels. We adapt the
speaker embedding extractor using all source and target domain data in a
supervised manner, where it can fully leverage both domain information.
Moreover, clustering and supervised domain adaptation can be repeated until the
performance converges on the validation set. Our final submission is a fusion
of 10 models and achieves 7.75% EER and 0.3517 MinDCF on the validation set.",None,-1
83531106-4d5e-42d8-8a1c-786d04f7c38c,FisheyeHDK: Hyperbolic Deformable Kernel Learning for Ultra-Wide Field-of-View Image Recognition,0.793149,"Conventional convolution neural networks (CNNs) trained on narrow
Field-of-View (FoV) images are the state-of-the-art approaches for object
recognition tasks. Some methods proposed the adaptation of CNNs to ultra-wide
FoV images by learning deformable kernels. However, they are limited by the
Euclidean geometry and their accuracy degrades under strong distortions caused
by fisheye projections. In this work, we demonstrate that learning the shape of
convolution kernels in non-Euclidean spaces is better than existing deformable
kernel methods. In particular, we propose a new approach that learns deformable
kernel parameters (positions) in hyperbolic space. FisheyeHDK is a hybrid CNN
architecture combining hyperbolic and Euclidean convolution layers for
positions and features learning. First, we provide an intuition of hyperbolic
space for wide FoV images. Using synthetic distortion profiles, we demonstrate
the effectiveness of our approach. We select two datasets - Cityscapes and
BDD100K 2020 - of perspective images which we transform to fisheye equivalents
at different scaling factors (analog to focal lengths). Finally, we provide an
experiment on data collected by a real fisheye camera. Validations and
experiments show that our approach improves existing deformable kernel methods
for CNN adaptation on fisheye images.",None,-1
7f38a327-c9af-4731-83bb-151ca83fa92a,SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control,0.451112,"Despite the growing success of diffusion models in continuous-valued domains
(e.g., images), similar efforts for discrete domains such as text have yet to
match the performance of autoregressive language models. In this work, we
present SSD-LM -- a diffusion-based language model with two key design choices.
First, SSD-LM is semi-autoregressive, iteratively generating blocks of text,
allowing for flexible output length at decoding time while enabling local
bidirectional context updates. Second, it is simplex-based, performing
diffusion on the natural vocabulary space rather than a learned latent space,
allowing us to incorporate classifier guidance and modular control using
off-the-shelf classifiers without any adaptation. We evaluate SSD-LM on
unconstrained text generation benchmarks, and show that it matches or
outperforms strong autoregressive GPT-2 models across standard quality and
diversity metrics, while vastly outperforming diffusion-based baselines. On
controlled text generation, SSD-LM also outperforms competitive baselines, with
an extra advantage in modularity.",https://github.com/xhan77/ssd-lm,-1
