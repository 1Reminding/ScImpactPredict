title,TNCSI,abstract
Textual Entailment Recognition with Semantic Features from Empirical Text Representation,0.0,"Textual entailment recognition is one of the basic natural language
understanding(NLU) tasks. Understanding the meaning of sentences is a
prerequisite before applying any natural language processing(NLP) techniques to
automatically recognize the textual entailment. A text entails a hypothesis if
and only if the true value of the hypothesis follows the text. Classical
approaches generally utilize the feature value of each word from word embedding
to represent the sentences. In this paper, we propose a novel approach to
identifying the textual entailment relationship between text and hypothesis,
thereby introducing a new semantic feature focusing on empirical
threshold-based semantic text representation. We employ an element-wise
Manhattan distance vector-based feature that can identify the semantic
entailment relationship between the text-hypothesis pair. We carried out
several experiments on a benchmark entailment classification(SICK-RTE) dataset.
We train several machine learning(ML) algorithms applying both semantic and
lexical features to classify the text-hypothesis pair as entailment, neutral,
or contradiction. Our empirical sentence representation technique enriches the
semantic information of the texts and hypotheses found to be more efficient
than the classical ones. In the end, our approach significantly outperforms
known methods in understanding the meaning of the sentences for the textual
entailment classification task."
Insights on Neural Representations for End-to-End Speech Recognition,0.00654443,"End-to-end automatic speech recognition (ASR) models aim to learn a
generalised speech representation. However, there are limited tools available
to understand the internal functions and the effect of hierarchical
dependencies within the model architecture. It is crucial to understand the
correlations between the layer-wise representations, to derive insights on the
relationship between neural representations and performance.
  Previous investigations of network similarities using correlation analysis
techniques have not been explored for End-to-End ASR models. This paper
analyses and explores the internal dynamics between layers during training with
CNN, LSTM and Transformer based approaches using Canonical correlation analysis
(CCA) and centered kernel alignment (CKA) for the experiments. It was found
that neural representations within CNN layers exhibit hierarchical correlation
dependencies as layer depth increases but this is mostly limited to cases where
neural representation correlates more closely. This behaviour is not observed
in LSTM architecture, however there is a bottom-up pattern observed across the
training process, while Transformer encoder layers exhibit irregular
coefficiency correlation as neural depth increases. Altogether, these results
provide new insights into the role that neural architectures have upon speech
recognition performance. More specifically, these techniques can be used as
indicators to build better performing speech recognition models."
Data augmentation for efficient learning from parametric experts,0.0089734,"We present a simple, yet powerful data-augmentation technique to enable
data-efficient learning from parametric experts for reinforcement and imitation
learning. We focus on what we call the policy cloning setting, in which we use
online or offline queries of an expert or expert policy to inform the behavior
of a student policy. This setting arises naturally in a number of problems, for
instance as variants of behavior cloning, or as a component of other algorithms
such as DAGGER, policy distillation or KL-regularized RL. Our approach,
augmented policy cloning (APC), uses synthetic states to induce
feedback-sensitivity in a region around sampled trajectories, thus dramatically
reducing the environment interactions required for successful cloning of the
expert. We achieve highly data-efficient transfer of behavior from an expert to
a student policy for high-degrees-of-freedom control problems. We demonstrate
the benefit of our method in the context of several existing and widely used
algorithms that include policy cloning as a constituent part. Moreover, we
highlight the benefits of our approach in two practically relevant settings (a)
expert compression, i.e. transfer to a student with fewer parameters; and (b)
transfer from privileged experts, i.e. where the expert has a different
observation space than the student, usually including access to privileged
information."
Generating Explanations from Deep Reinforcement Learning Using Episodic Memory,0.0366845,"Deep Reinforcement Learning (RL) involves the use of Deep Neural Networks
(DNNs) to make sequential decisions in order to maximize reward. For many tasks
the resulting sequence of actions produced by a Deep RL policy can be long and
difficult to understand for humans. A crucial component of human explanations
is selectivity, whereby only key decisions and causes are recounted. Imbuing
Deep RL agents with such an ability would make their resulting policies easier
to understand from a human perspective and generate a concise set of
instructions to aid the learning of future agents. To this end we use a Deep RL
agent with an episodic memory system to identify and recount key decisions
during policy execution. We show that these decisions form a short, human
readable explanation that can also be used to speed up the learning of naive
Deep RL agents in an algorithm-independent manner."
Compressing Pre-trained Transformers via Low-Bit NxM Sparsity for Natural Language Understanding,0.00501456,"In recent years, large pre-trained Transformer networks have demonstrated
dramatic improvements in many natural language understanding tasks. However,
the huge size of these models brings significant challenges to their
fine-tuning and online deployment due to latency and cost constraints. New
hardware supporting both N:M semi-structured sparsity and low-precision integer
computation is a promising solution to boost DNN model serving efficiency.
However, there have been very few studies that systematically investigate to
what extent pre-trained Transformer networks benefit from the combination of
these techniques, as well as how to best compress each component of the
Transformer. We propose a flexible compression framework NxMiFormer that
performs simultaneous sparsification and quantization using ADMM and STE-based
QAT. Furthermore, we present and inexpensive, heuristic-driven search algorithm
that identifies promising heterogeneous compression configurations that meet a
compression ratio constraint. When evaluated across the GLUE suite of NLU
benchmarks, our approach can achieve up to 93% compression of the encoders of a
BERT model while retaining 98.2% of the original model accuracy and taking full
advantage of the hardware's capabilities. Heterogeneous configurations found
the by the search heuristic maintain 99.5% of the baseline accuracy while still
compressing the model by 87.5%."
Dynamic Point Cloud Compression with Cross-Sectional Approach,0.063056,"The recent development of dynamic point clouds has introduced the possibility
of mimicking natural reality, and greatly assisting quality of life. However,
to broadcast successfully, the dynamic point clouds require higher compression
due to their huge volume of data compared to the traditional video. Recently,
MPEG finalized a Video-based Point Cloud Compression standard known as V-PCC.
However, V-PCC requires huge computational time due to expensive normal
calculation and segmentation, sacrifices some points to limit the number of 2D
patches, and cannot occupy all spaces in the 2D frame. The proposed method
addresses these limitations by using a novel cross-sectional approach. This
approach reduces expensive normal estimation and segmentation, retains more
points, and utilizes more spaces for 2D frame generation compared to the VPCC.
The experimental results using standard video sequences show that the proposed
technique can achieve better compression in both geometric and texture data
compared to the V-PCC standard."
P$^3$LM: Probabilistically Permuted Prophet Language Modeling for Generative Pre-Training,0.0108149,"Conventional autoregressive left-to-right (L2R) sequence generation faces two
issues during decoding: limited to unidirectional target sequence modeling, and
constrained on strong local dependencies. To address the aforementioned
problem, we propose P$^3$LM, a probabilistically permuted prophet language
model, which strengthens the modeling of bidirectional information and long
token dependencies for sequence generation. Specifically, P$^3$LM learns to
generate tokens in permuted order upon an order-aware transformer decoder, as
well as to generate the corresponding future $N$ tokens with a multi-stream
attention mechanism. Extensive experiments are conducted on the GLGE benchmark,
which includes four datasets for summarization, two for question generation,
one for conversational question answering, and one for dialog response
generation, where P$^3$LM achieves state-of-the-art results compared with
strong publicly available generative pre-training methods."
Recognition of Implicit Geographic Movement in Text,0.0282515,"Analyzing the geographic movement of humans, animals, and other phenomena is
a growing field of research. This research has benefited urban planning,
logistics, animal migration understanding, and much more. Typically, the
movement is captured as precise geographic coordinates and time stamps with
Global Positioning Systems (GPS). Although some research uses computational
techniques to take advantage of implicit movement in descriptions of route
directions, hiking paths, and historical exploration routes, innovation would
accelerate with a large and diverse corpus. We created a corpus of sentences
labeled as describing geographic movement or not and including the type of
entity moving. Creating this corpus proved difficult without any comparable
corpora to start with, high human labeling costs, and since movement can at
times be interpreted differently. To overcome these challenges, we developed an
iterative process employing hand labeling, crowd voting for confirmation, and
machine learning to predict more labels. By merging advances in word embeddings
with traditional machine learning models and model ensembling, prediction
accuracy is at an acceptable level to produce a large silver-standard corpus
despite the small gold-standard corpus training set. Our corpus will likely
benefit computational processing of geography in text and spatial cognition, in
addition to detection of movement."
Multi-level Latent Space Structuring for Generative Control,0.0072254,"Truncation is widely used in generative models for improving the quality of
the generated samples, at the expense of reducing their diversity. We propose
to leverage the StyleGAN generative architecture to devise a new truncation
technique, based on a decomposition of the latent space into clusters, enabling
customized truncation to be performed at multiple semantic levels. We do so by
learning to re-generate W-space, the extended intermediate latent space of
StyleGAN, using a learnable mixture of Gaussians, while simultaneously training
a classifier to identify, for each latent vector, the cluster that it belongs
to. The resulting truncation scheme is more faithful to the original
untruncated samples and allows a better trade-off between quality and
diversity. We compare our method to other truncation approaches for StyleGAN,
both qualitatively and quantitatively."
"Effectiveness of Text, Acoustic, and Lattice-based representations in Spoken Language Understanding tasks",0.0301609,"In this paper, we perform an exhaustive evaluation of different
representations to address the intent classification problem in a Spoken
Language Understanding (SLU) setup. We benchmark three types of systems to
perform the SLU intent detection task: 1) text-based, 2) lattice-based, and a
novel 3) multimodal approach. Our work provides a comprehensive analysis of
what could be the achievable performance of different state-of-the-art SLU
systems under different circumstances, e.g., automatically- vs.
manually-generated transcripts. We evaluate the systems on the publicly
available SLURP spoken language resource corpus. Our results indicate that
using richer forms of Automatic Speech Recognition (ASR) outputs, namely
word-consensus-networks, allows the SLU system to improve in comparison to the
1-best setup (5.5% relative improvement). However, crossmodal approaches, i.e.,
learning from acoustic and text embeddings, obtains performance similar to the
oracle setup, a relative improvement of 17.8% over the 1-best configuration,
being a recommended alternative to overcome the limitations of working with
automatically generated transcripts."
Continual Contrastive Finetuning Improves Low-Resource Relation Extraction,0.0315331,"Relation extraction (RE), which has relied on structurally annotated corpora
for model training, has been particularly challenging in low-resource scenarios
and domains. Recent literature has tackled low-resource RE by self-supervised
learning, where the solution involves pretraining the entity pair embedding by
RE-based objective and finetuning on labeled data by classification-based
objective. However, a critical challenge to this approach is the gap in
objectives, which prevents the RE model from fully utilizing the knowledge in
pretrained representations. In this paper, we aim at bridging the gap and
propose to pretrain and finetune the RE model using consistent objectives of
contrastive learning. Since in this kind of representation learning paradigm,
one relation may easily form multiple clusters in the representation space, we
further propose a multi-center contrastive loss that allows one relation to
form multiple clusters to better align with pretraining. Experiments on two
document-level RE datasets, BioRED and Re-DocRED, demonstrate the effectiveness
of our method. Particularly, when using 1% end-task training data, our method
outperforms PLM-based RE classifier by 10.5% and 6.1% on the two datasets,
respectively."
Winning the CVPR'2022 AQTC Challenge: A Two-stage Function-centric Approach,0.0251057,"Affordance-centric Question-driven Task Completion for Egocentric
Assistant(AQTC) is a novel task which helps AI assistant learn from
instructional videos and scripts and guide the user step-by-step. In this
paper, we deal with the AQTC via a two-stage Function-centric approach, which
consists of Question2Function Module to ground the question with the related
function and Function2Answer Module to predict the action based on the
historical steps. We evaluated several possible solutions in each module and
obtained significant gains compared to the given baselines. Our code is
available at \url{https://github.com/starsholic/LOVEU-CVPR22-AQTC}."
Visual Information Guided Zero-Shot Paraphrase Generation,0.0211587,"Zero-shot paraphrase generation has drawn much attention as the large-scale
high-quality paraphrase corpus is limited. Back-translation, also known as the
pivot-based method, is typical to this end. Several works leverage different
information as ""pivot"" such as language, semantic representation and so on. In
this paper, we explore using visual information such as image as the ""pivot"" of
back-translation. Different with the pipeline back-translation method, we
propose visual information guided zero-shot paraphrase generation (ViPG) based
only on paired image-caption data. It jointly trains an image captioning model
and a paraphrasing model and leverage the image captioning model to guide the
training of the paraphrasing model. Both automatic evaluation and human
evaluation show our model can generate paraphrase with good relevancy, fluency
and diversity, and image is a promising kind of pivot for zero-shot paraphrase
generation."
Self-directed Learning of Action Models using Exploratory Planning,0.0171364,"Complex, real-world domains may not be fully modeled for an agent, especially
if the agent has never operated in the domain before. The agent's ability to
effectively plan and act in such a domain is influenced by its knowledge of
when it can perform specific actions and the effects of those actions. We
describe a novel exploratory planning agent that is capable of learning action
preconditions and effects without expert traces or a given goal. The agent's
architecture allows it to perform both exploratory actions as well as
goal-directed actions, which opens up important considerations for how
exploratory planning and goal planning should be controlled, as well as how the
agent's behavior should be explained to any teammates it may have. The
contributions of this work include a new representation for contexts called
Lifted Linked Clauses, a novel exploration action selection approach using
these clauses, an exploration planner that uses lifted linked clauses as goals
in order to reach new states, and an empirical evaluation in a scenario from an
exploration-focused video game demonstrating that lifted linked clauses improve
exploration and action model learning against non-planning baseline agents."
Classification Of Fake News Headline Based On Neural Networks,0.0449038,"Over the last few years, Text classification is one of the fundamental tasks
in natural language processing (NLP) in which the objective is to categorize
text documents into one of the predefined classes. The news is full of our
life. Therefore, news headlines classification is a crucial task to connect
users with the right news. The news headline classification is a kind of text
classification, which can be generally divided into three mainly parts: feature
extraction, classifier selection, and evaluations. In this article, we use the
dataset, containing news over a period of eighteen years provided by Kaggle
platform to classify news headlines. We choose TF-IDF to extract features and
neural network as the classifier, while the evaluation metrics is accuracy.
From the experiment result, it is obvious that our NN model has the best
performance among these models in the metrics of accuracy. The higher the
accuracy is, the better performance the model will gain. Our NN model owns the
accuracy 0.8622, which is highest accuracy among these four models. And it is
0.0134, 0.033, 0.080 higher than its of other models."
NaturalAdversaries: Can Naturalistic Adversaries Be as Effective as Artificial Adversaries?,-1.0,"While a substantial body of prior work has explored adversarial example
generation for natural language understanding tasks, these examples are often
unrealistic and diverge from the real-world data distributions. In this work,
we introduce a two-stage adversarial example generation framework
(NaturalAdversaries), for designing adversaries that are effective at fooling a
given classifier and demonstrate natural-looking failure cases that could
plausibly occur during in-the-wild deployment of the models.
  At the first stage a token attribution method is used to summarize a given
classifier's behaviour as a function of the key tokens in the input. In the
second stage a generative model is conditioned on the key tokens from the first
stage. NaturalAdversaries is adaptable to both black-box and white-box
adversarial attacks based on the level of access to the model parameters. Our
results indicate these adversaries generalize across domains, and offer
insights for future research on improving robustness of neural text
classification models."
Task-Adaptive Feature Transformer with Semantic Enrichment for Few-Shot Segmentation,0.0545921,"Few-shot learning allows machines to classify novel classes using only a few
labeled samples. Recently, few-shot segmentation aiming at semantic
segmentation on low sample data has also seen great interest. In this paper, we
propose a learnable module that can be placed on top of existing segmentation
networks for performing few-shot segmentation. This module, called the
task-adaptive feature transformer (TAFT), linearly transforms task-specific
high-level features to a set of task agnostic features well-suited to
conducting few-shot segmentation. The task-conditioned feature transformation
allows an effective utilization of the semantic information in novel classes to
generate tight segmentation masks. We also propose a semantic enrichment (SE)
module that utilizes a pixel-wise attention module for high-level feature and
an auxiliary loss from an auxiliary segmentation network conducting the
semantic segmentation for all training classes. Experiments on PASCAL-$5^i$ and
COCO-$20^i$ datasets confirm that the added modules successfully extend the
capability of existing segmentators to yield highly competitive few-shot
segmentation performances."
Calibration of Derivative Pricing Models: a Multi-Agent Reinforcement Learning Perspective,0.00906834,"One of the most fundamental questions in quantitative finance is the
existence of continuous-time diffusion models that fit market prices of a given
set of options. Traditionally, one employs a mix of intuition, theoretical and
empirical analysis to find models that achieve exact or approximate fits. Our
contribution is to show how a suitable game theoretical formulation of this
problem can help solve this question by leveraging existing developments in
modern deep multi-agent reinforcement learning to search in the space of
stochastic processes. Our experiments show that we are able to learn local
volatility, as well as path-dependence required in the volatility process to
minimize the price of a Bermudan option. Our algorithm can be seen as a
particle method \textit{\`{a} la} Guyon \textit{et} Henry-Labordere where
particles, instead of being designed to ensure $\sigma_{loc}(t,S_t)^2 =
\mathbb{E}[\sigma_t^2|S_t]$, are learning RL-driven agents cooperating towards
more general calibration targets."
LittleBird: Efficient Faster & Longer Transformer for Question Answering,-1.0,"BERT has shown a lot of sucess in a wide variety of NLP tasks. But it has a
limitation dealing with long inputs due to its attention mechanism. Longformer,
ETC and BigBird addressed this issue and effectively solved the quadratic
dependency problem. However we find that these models are not sufficient, and
propose LittleBird, a novel model based on BigBird with improved speed and
memory footprint while maintaining accuracy. In particular, we devise a more
flexible and efficient position representation method based on Attention with
Linear Biases (ALiBi). We also show that replacing the method of global
information represented in the BigBird with pack and unpack attention is more
effective. The proposed model can work on long inputs even after being
pre-trained on short inputs, and can be trained efficiently reusing existing
pre-trained language model for short inputs. This is a significant benefit for
low-resource languages where large amounts of long text data are difficult to
obtain. As a result, our experiments show that LittleBird works very well in a
variety of languages, achieving high performance in question answering tasks,
particularly in KorQuAD2.0, Korean Question Answering Dataset for long
paragraphs."
Who is we? Disambiguating the referents of first person plural pronouns in parliamentary debates,0.0363318,"This paper investigates the use of first person plural pronouns as a
rhetorical device in political speeches. We present an annotation schema for
disambiguating pronoun references and use our schema to create an annotated
corpus of debates from the German Bundestag. We then use our corpus to learn to
automatically resolve pronoun referents in parliamentary debates. We explore
the use of data augmentation with weak supervision to further expand our corpus
and report preliminary results."
Classifiers are Better Experts for Controllable Text Generation,0.00179473,"This paper proposes a simple method for controllable text generation based on
weighting logits with a free-form classifier, namely CAIF sampling. Using an
arbitrary text classifier, we adjust a small part of a language model's logits
and guide text generation towards or away from classifier prediction. We
experimented with toxicity avoidance and sentiment control tasks and showed
that the proposed method significantly outperforms recent PPLM, GeDi, and
DExperts on PPL and task accuracy metrics based on the external classifier of
generated texts. In addition, compared to other approaches, it is easier to
implement and tune and has significantly fewer restrictions and requirements."
Descartes: Generating Short Descriptions of Wikipedia Articles,0.00421647,"Wikipedia is one of the richest knowledge sources on the Web today. In order
to facilitate navigating, searching, and maintaining its content, Wikipedia's
guidelines state that all articles should be annotated with a so-called short
description indicating the article's topic (e.g., the short description of beer
is ""Alcoholic drink made from fermented cereal grains""). Nonetheless, a large
fraction of articles (ranging from 10.2% in Dutch to 99.7% in Kazakh) have no
short description yet, with detrimental effects for millions of Wikipedia
users. Motivated by this problem, we introduce the novel task of automatically
generating short descriptions for Wikipedia articles and propose Descartes, a
multilingual model for tackling it. Descartes integrates three sources of
information to generate an article description in a target language: the text
of the article in all its language versions, the already-existing descriptions
(if any) of the article in other languages, and semantic type information
obtained from a knowledge graph. We evaluate a Descartes model trained for
handling 25 languages simultaneously, showing that it beats baselines
(including a strong translation-based baseline) and performs on par with
monolingual models tailored for specific languages. A human evaluation on three
languages further shows that the quality of Descartes's descriptions is largely
indistinguishable from that of human-written descriptions; e.g., 91.3% of our
English descriptions (vs. 92.1% of human-written descriptions) pass the bar for
inclusion in Wikipedia, suggesting that Descartes is ready for production, with
the potential to support human editors in filling a major gap in today's
Wikipedia across languages."
kpfriends at SemEval-2022 Task 2: NEAMER -- Named Entity Augmented Multi-word Expression Recognizer,0.0952839,"We present NEAMER -- Named Entity Augmented Multi-word Expression Recognizer.
This system is inspired by non-compositionality characteristics shared between
Named Entity and Idiomatic Expressions. We utilize transfer learning and
locality features to enhance idiom classification task. This system is our
submission for SemEval Task 2: Multilingual Idiomaticity Detection and Sentence
Embedding Subtask A OneShot shared task. We achieve SOTA with F1 0.9395 during
post-evaluation phase. We also observe improvement in training stability.
Lastly, we experiment with non-compositionality knowledge transfer,
cross-lingual fine-tuning and locality features, which we also introduce in
this paper."
Far Away in the Deep Space: Dense Nearest-Neighbor-Based Out-of-Distribution Detection,0.0294703,"The key to out-of-distribution detection is density estimation of the
in-distribution data or of its feature representations. This is particularly
challenging for dense anomaly detection in domains where the in-distribution
data has a complex underlying structure. Nearest-Neighbors approaches have been
shown to work well in object-centric data domains, such as industrial
inspection and image classification. In this paper, we show that
nearest-neighbor approaches also yield state-of-the-art results on dense
novelty detection in complex driving scenes when working with an appropriate
feature representation. In particular, we find that transformer-based
architectures produce representations that yield much better similarity metrics
for the task. We identify the multi-head structure of these models as one of
the reasons, and demonstrate a way to transfer some of the improvements to
CNNs. Ultimately, the approach is simple and non-invasive, i.e., it does not
affect the primary segmentation performance, refrains from training on examples
of anomalies, and achieves state-of-the-art results on RoadAnomaly,
StreetHazards, and SegmentMeIfYouCan-Anomaly."
A Comparative Attention Framework for Better Few-Shot Object Detection on Aerial Images,0.0177603,"Few-Shot Object Detection (FSOD) methods are mainly designed and evaluated on
natural image datasets such as Pascal VOC and MS COCO. However, it is not clear
whether the best methods for natural images are also the best for aerial
images. Furthermore, direct comparison of performance between FSOD methods is
difficult due to the wide variety of detection frameworks and training
strategies. Therefore, we propose a benchmarking framework that provides a
flexible environment to implement and compare attention-based FSOD methods. The
proposed framework focuses on attention mechanisms and is divided into three
modules: spatial alignment, global attention, and fusion layer. To remain
competitive with existing methods, which often leverage complex training, we
propose new augmentation techniques designed for object detection. Using this
framework, several FSOD methods are reimplemented and compared. This comparison
highlights two distinct performance regimes on aerial and natural images: FSOD
performs worse on aerial images. Our experiments suggest that small objects,
which are harder to detect in the few-shot setting, account for the poor
performance. Finally, we develop a novel multiscale alignment method,
Cross-Scales Query-Support Alignment (XQSA) for FSOD, to improve the detection
of small objects. XQSA outperforms the state-of-the-art significantly on DOTA
and DIOR."
Learning Explicit Object-Centric Representations with Vision Transformers,0.0137459,"With the recent successful adaptation of transformers to the vision domain,
particularly when trained in a self-supervised fashion, it has been shown that
vision transformers can learn impressive object-reasoning-like behaviour and
features expressive for the task of object segmentation in images. In this
paper, we build on the self-supervision task of masked autoencoding and explore
its effectiveness for explicitly learning object-centric representations with
transformers. To this end, we design an object-centric autoencoder using
transformers only and train it end-to-end to reconstruct full images from
unmasked patches. We show that the model efficiently learns to decompose simple
scenes as measured by segmentation metrics on several multi-object benchmarks."
N-RPN: Hard Example Learning for Region Proposal Networks,0.0134039,"The region proposal task is to generate a set of candidate regions that
contain an object. In this task, it is most important to propose as many
candidates of ground-truth as possible in a fixed number of proposals. In a
typical image, however, there are too few hard negative examples compared to
the vast number of easy negatives, so region proposal networks struggle to
train on hard negatives. Because of this problem, networks tend to propose hard
negatives as candidates, while failing to propose ground-truth candidates,
which leads to poor performance. In this paper, we propose a Negative Region
Proposal Network(nRPN) to improve Region Proposal Network(RPN). The nRPN learns
from the RPN's false positives and provide hard negative examples to the RPN.
Our proposed nRPN leads to a reduction in false positives and better RPN
performance. An RPN trained with an nRPN achieves performance improvements on
the PASCAL VOC 2007 dataset."
"Embodied, Situated, and Grounded Intelligence: Implications for AI",0.0187008,"In April of 2022, the Santa Fe Institute hosted a workshop on embodied,
situated, and grounded intelligence as part of the Institute's Foundations of
Intelligence project. The workshop brought together computer scientists,
psychologists, philosophers, social scientists, and others to discuss the
science of embodiment and related issues in human intelligence, and its
implications for building robust, human-level AI. In this report, we summarize
each of the talks and the subsequent discussions. We also draw out a number of
key themes and identify important frontiers for future research."
Extending Process Discovery with Model Complexity Optimization and Cyclic States Identification: Application to Healthcare Processes,0.0121903,"Within Process mining, discovery techniques had made it possible to construct
business process models automatically from event logs. However, results often
do not achieve the balance between model complexity and its fitting accuracy,
so there is a need for manual model adjusting. The paper presents an approach
to process mining providing semi-automatic support to model optimization based
on the combined assessment of the model complexity and fitness. To balance
between the two ingredients, a model simplification approach is proposed, which
essentially abstracts the raw model at the desired granularity. Additionally,
we introduce a concept of meta-states, a cycle collapsing in the model, which
can potentially simplify the model and interpret it. We aim to demonstrate the
capabilities of the technological solution using three datasets from different
applications in the healthcare domain. They are remote monitoring process for
patients with arterial hypertension and workflows of healthcare workers during
the COVID-19 pandemic. A case study also investigates the use of various
complexity measures and different ways of solution application providing
insights on better practices in improving interpretability and
complexity/fitness balance in process models."
Unsupervised Keyphrase Extraction via Interpretable Neural Networks,0.00976107,"Keyphrase extraction aims at automatically extracting a list of ""important""
phrases representing the key concepts in a document. Prior approaches for
unsupervised keyphrase extraction resorted to heuristic notions of phrase
importance via embedding clustering or graph centrality, requiring extensive
domain expertise. Our work presents a simple alternative approach which defines
keyphrases as document phrases that are salient for predicting the topic of the
document. To this end, we propose INSPECT -- an approach that uses
self-explaining models for identifying influential keyphrases in a document by
measuring the predictive impact of input phrases on the downstream task of the
document topic classification. We show that this novel method not only
alleviates the need for ad-hoc heuristics but also achieves state-of-the-art
results in unsupervised keyphrase extraction in four datasets across two
domains: scientific publications and news articles."
Font Representation Learning via Paired-glyph Matching,0.0062682,"Fonts can convey profound meanings of words in various forms of glyphs.
Without typography knowledge, manually selecting an appropriate font or
designing a new font is a tedious and painful task. To allow users to explore
vast font styles and create new font styles, font retrieval and font style
transfer methods have been proposed. These tasks increase the need for learning
high-quality font representations. Therefore, we propose a novel font
representation learning scheme to embed font styles into the latent space. For
the discriminative representation of a font from others, we propose a
paired-glyph matching-based font representation learning model that attracts
the representations of glyphs in the same font to one another, but pushes away
those of other fonts. Through evaluations on font retrieval with query glyphs
on new fonts, we show our font representation learning scheme achieves better
generalization performance than the existing font representation learning
techniques. Finally on the downstream font style transfer and generation tasks,
we confirm the benefits of transfer learning with the proposed method. The
source code is available at https://github.com/junhocho/paired-glyph-matching."
A Structure-Guided Diffusion Model for Large-Hole Image Completion,0.0152297,"Image completion techniques have made significant progress in filling missing
regions (i.e., holes) in images. However, large-hole completion remains
challenging due to limited structural information. In this paper, we address
this problem by integrating explicit structural guidance into diffusion-based
image completion, forming our structure-guided diffusion model (SGDM). It
consists of two cascaded diffusion probabilistic models: structure and texture
generators. The structure generator generates an edge image representing
plausible structures within the holes, which is then used for guiding the
texture generation process. To train both generators jointly, we devise a novel
strategy that leverages optimal Bayesian denoising, which denoises the output
of the structure generator in a single step and thus allows backpropagation.
Our diffusion-based approach enables a diversity of plausible completions,
while the editable edges allow for editing parts of an image. Our experiments
on natural scene (Places) and face (CelebA-HQ) datasets demonstrate that our
method achieves a superior or comparable visual quality compared to
state-of-the-art approaches. The code is available for research purposes at
https://github.com/UdonDa/Structure_Guided_Diffusion_Model."
Learning Enriched Illuminants for Cross and Single Sensor Color Constancy,0.00132158,"Color constancy aims to restore the constant colors of a scene under
different illuminants. However, due to the existence of camera spectral
sensitivity, the network trained on a certain sensor, cannot work well on
others. Also, since the training datasets are collected in certain
environments, the diversity of illuminants is limited for complex real world
prediction. In this paper, we tackle these problems via two aspects. First, we
propose cross-sensor self-supervised training to train the network. In detail,
we consider both the general sRGB images and the white-balanced RAW images from
current available datasets as the white-balanced agents. Then, we train the
network by randomly sampling the artificial illuminants in a sensor-independent
manner for scene relighting and supervision. Second, we analyze a previous
cascaded framework and present a more compact and accurate model by sharing the
backbone parameters with learning attention specifically. Experiments show that
our cross-sensor model and single-sensor model outperform other
state-of-the-art methods by a large margin on cross and single sensor
evaluations, respectively, with only 16% parameters of the previous best model."
FORCE: A Framework of Rule-Based Conversational Recommender System,0.0295994,"The conversational recommender systems (CRSs) have received extensive
attention in recent years. However, most of the existing works focus on various
deep learning models, which are largely limited by the requirement of
large-scale human-annotated datasets. Such methods are not able to deal with
the cold-start scenarios in industrial products. To alleviate the problem, we
propose FORCE, a Framework Of Rule-based Conversational Recommender system that
helps developers to quickly build CRS bots by simple configuration. We conduct
experiments on two datasets in different languages and domains to verify its
effectiveness and usability."
Data Augmentation by Selecting Mixed Classes Considering Distance Between Classes,0.00598679,"Data augmentation is an essential technique for improving recognition
accuracy in object recognition using deep learning. Methods that generate mixed
data from multiple data sets, such as mixup, can acquire new diversity that is
not included in the training data, and thus contribute significantly to
accuracy improvement. However, since the data selected for mixing are randomly
sampled throughout the training process, there are cases where appropriate
classes or data are not selected. In this study, we propose a data augmentation
method that calculates the distance between classes based on class
probabilities and can select data from suitable classes to be mixed in the
training process. Mixture data is dynamically adjusted according to the
training trend of each class to facilitate training. The proposed method is
applied in combination with conventional methods for generating mixed data.
Evaluation experiments show that the proposed method improves recognition
performance on general and long-tailed image recognition datasets."
Towards Device Efficient Conditional Image Generation,0.0306799,"We present a novel algorithm to reduce tensor compute required by a
conditional image generation autoencoder without sacrificing quality of
photo-realistic image generation. Our method is device agnostic, and can
optimize an autoencoder for a given CPU-only, GPU compute device(s) in about
normal time it takes to train an autoencoder on a generic workstation. We
achieve this via a two-stage novel strategy where, first, we condense the
channel weights, such that, as few as possible channels are used. Then, we
prune the nearly zeroed out weight activations, and fine-tune the autoencoder.
To maintain image quality, fine-tuning is done via student-teacher training,
where we reuse the condensed autoencoder as the teacher. We show performance
gains for various conditional image generation tasks: segmentation mask to face
images, face images to cartoonization, and finally CycleGAN-based model over
multiple compute devices. We perform various ablation studies to justify the
claims and design choices, and achieve real-time versions of various
autoencoders on CPU-only devices while maintaining image quality, thus enabling
at-scale deployment of such autoencoders."
Mental Health Assessment for the Chatbots,0.0246056,"Previous researches on dialogue system assessment usually focus on the
quality evaluation (e.g. fluency, relevance, etc) of responses generated by the
chatbots, which are local and technical metrics. For a chatbot which responds
to millions of online users including minors, we argue that it should have a
healthy mental tendency in order to avoid the negative psychological impact on
them. In this paper, we establish several mental health assessment dimensions
for chatbots (depression, anxiety, alcohol addiction, empathy) and introduce
the questionnaire-based mental health assessment methods. We conduct
assessments on some well-known open-domain chatbots and find that there are
severe mental health issues for all these chatbots. We consider that it is due
to the neglect of the mental health risks during the dataset building and the
model training procedures. We expect to attract researchers' attention to the
serious mental health problems of chatbots and improve the chatbots' ability in
positive emotional interaction."
OCFormer: One-Class Transformer Network for Image Classification,0.0,"We propose a novel deep learning framework based on Vision Transformers (ViT)
for one-class classification. The core idea is to use zero-centered Gaussian
noise as a pseudo-negative class for latent space representation and then train
the network using the optimal loss function. In prior works, there have been
tremendous efforts to learn a good representation using varieties of loss
functions, which ensures both discriminative and compact properties. The
proposed one-class Vision Transformer (OCFormer) is exhaustively experimented
on CIFAR-10, CIFAR-100, Fashion-MNIST and CelebA eyeglasses datasets. Our
method has shown significant improvements over competing CNN based one-class
classifier approaches."
Multi-Task Learning for Visual Scene Understanding,0.00737487,"Despite the recent progress in deep learning, most approaches still go for a
silo-like solution, focusing on learning each task in isolation: training a
separate neural network for each individual task. Many real-world problems,
however, call for a multi-modal approach and, therefore, for multi-tasking
models. Multi-task learning (MTL) aims to leverage useful information across
tasks to improve the generalization capability of a model. This thesis is
concerned with multi-task learning in the context of computer vision. First, we
review existing approaches for MTL. Next, we propose several methods that
tackle important aspects of multi-task learning. The proposed methods are
evaluated on various benchmarks. The results show several advances in the
state-of-the-art of multi-task learning. Finally, we discuss several
possibilities for future work."
ViWOZ: A Multi-Domain Task-Oriented Dialogue Systems Dataset For Low-resource Language,0.0152438,"Most of the current task-oriented dialogue systems (ToD), despite having
interesting results, are designed for a handful of languages like Chinese and
English. Therefore, their performance in low-resource languages is still a
significant problem due to the absence of a standard dataset and evaluation
policy. To address this problem, we proposed ViWOZ, a fully-annotated
Vietnamese task-oriented dialogue dataset. ViWOZ is the first multi-turn,
multi-domain tasked oriented dataset in Vietnamese, a low-resource language.
The dataset consists of a total of 5,000 dialogues, including 60,946 fully
annotated utterances. Furthermore, we provide a comprehensive benchmark of both
modular and end-to-end models in low-resource language scenarios. With those
characteristics, the ViWOZ dataset enables future studies on creating a
multilingual task-oriented dialogue system."
Drawing Causal Inferences About Performance Effects in NLP,0.00458042,"This article emphasizes that NLP as a science seeks to make inferences about
the performance effects that result from applying one method (compared to
another method) in the processing of natural language. Yet NLP research in
practice usually does not achieve this goal: In NLP research articles,
typically only a few models are compared. Each model results from a specific
procedural pipeline (here named processing system) that is composed of a
specific collection of methods that are used in preprocessing, pretraining,
hyperparameter tuning, and training on the target task. To make generalizing
inferences about the performance effect that is caused by applying some method
A vs. another method B, it is not sufficient to compare a few specific models
that are produced by a few specific (probably incomparable) processing systems.
Rather, the following procedure would allow drawing inferences about methods'
performance effects: (1) A population of processing systems that researchers
seek to infer to has to be defined. (2) A random sample of processing systems
from this population is drawn. (The drawn processing systems in the sample will
vary with regard to the methods they apply along their procedural pipelines and
also will vary regarding the compositions of their training and test data sets
used for training and evaluation.) (3) Each processing system is applied once
with method A and once with method B. (4) Based on the sample of applied
processing systems, the expected generalization errors of method A and method B
are approximated. (5) The difference between the expected generalization errors
of method A and method B is the estimated average treatment effect due to
applying method A compared to method B in the population of processing systems."
Can We Find Neurons that Cause Unrealistic Images in Deep Generative Networks?,0.0358988,"Even though Generative Adversarial Networks (GANs) have shown a remarkable
ability to generate high-quality images, GANs do not always guarantee the
generation of photorealistic images. Occasionally, they generate images that
have defective or unnatural objects, which are referred to as 'artifacts'.
Research to investigate why these artifacts emerge and how they can be detected
and removed has yet to be sufficiently carried out. To analyze this, we first
hypothesize that rarely activated neurons and frequently activated neurons have
different purposes and responsibilities for the progress of generating images.
In this study, by analyzing the statistics and the roles for those neurons, we
empirically show that rarely activated neurons are related to the failure
results of making diverse objects and inducing artifacts. In addition, we
suggest a correction method, called 'Sequential Ablation', to repair the
defective part of the generated images without high computational cost and
manual efforts."
Few-Shot Table-to-Text Generation with Prefix-Controlled Generator,0.232355,"Neural table-to-text generation approaches are data-hungry, limiting their
adaptation for low-resource real-world applications. Previous works mostly
resort to Pre-trained Language Models (PLMs) to generate fluent summaries of a
table. However, they often contain hallucinated contents due to the
uncontrolled nature of PLMs. Moreover, the topological differences between
tables and sequences are rarely studied. Last but not least, fine-tuning on
PLMs with a handful of instances may lead to over-fitting and catastrophic
forgetting. To alleviate these problems, we propose a prompt-based approach,
Prefix-Controlled Generator (i.e., PCG), for few-shot table-to-text generation.
We prepend a task-specific prefix for a PLM to make the table structure better
fit the pre-trained input. In addition, we generate an input-specific prefix to
control the factual contents and word order of the generated text. Both
automatic and human evaluations on different domains (humans, books and songs)
of the Wikibio dataset show substantial improvements over baseline approaches."
Automatic Generation of Factual News Headlines in Finnish,0.13934,"We present a novel approach to generating news headlines in Finnish for a
given news story. We model this as a summarization task where a model is given
a news article, and its task is to produce a concise headline describing the
main topic of the article. Because there are no openly available GPT-2 models
for Finnish, we will first build such a model using several corpora. The model
is then fine-tuned for the headline generation task using a massive news
corpus. The system is evaluated by 3 expert journalists working in a Finnish
media house. The results showcase the usability of the presented approach as a
headline suggestion tool to facilitate the news production process."
A multi-domain virtual network embedding algorithm with delay prediction,0.0305758,"Virtual network embedding (VNE) is an crucial part of network virtualization
(NV), which aims to map the virtual networks (VNs) to a shared substrate
network (SN). With the emergence of various delay-sensitive applications, how
to improve the delay performance of the system has become a hot topic in
academic circles. Based on extensive research, we proposed a multi-domain
virtual network embedding algorithm based on delay prediction (DP-VNE).
Firstly, the candidate physical nodes are selected by estimating the delay of
virtual requests, then particle swarm optimization (PSO) algorithm is used to
optimize the mapping process, so as to reduce the delay of the system. The
simulation results show that compared with the other three advanced algorithms,
the proposed algorithm can significantly reduce the system delay while keeping
other indicators unaffected."
Improving Data Driven Inverse Text Normalization using Data Augmentation,0.021946,"Inverse text normalization (ITN) is used to convert the spoken form output of
an automatic speech recognition (ASR) system to a written form. Traditional
handcrafted ITN rules can be complex to transcribe and maintain. Meanwhile
neural modeling approaches require quality large-scale spoken-written pair
examples in the same or similar domain as the ASR system (in-domain data), to
train. Both these approaches require costly and complex annotations. In this
paper, we present a data augmentation technique that effectively generates rich
spoken-written numeric pairs from out-of-domain textual data with minimal human
annotation. We empirically demonstrate that ITN model trained using our data
augmentation technique consistently outperform ITN model trained using only
in-domain data across all numeric surfaces like cardinal, currency, and
fraction, by an overall accuracy of 14.44%."
Quantitative Method for Security Situation of the Power Information Network Based on the Evolutionary Neural Network,0.005721,"Cybersecurity is the security cornerstone of digital transformation of the
power grid and construction of new power systems. The traditional network
security situation quantification method only analyzes from the perspective of
network performance, ignoring the impact of various power application services
on the security situation, so the quantification results cannot fully reflect
the power information network risk state. This study proposes a method for
quantifying security situation of the power information network based on the
evolutionary neural network. First, the security posture system architecture is
designed by analyzing the business characteristics of power information network
applications. Second, combining the importance of power application business,
the spatial element index system of coupled interconnection is established from
three dimensions of network reliability, threat, and vulnerability. Then, the
BP neural network optimized by the genetic evolutionary algorithm is
incorporated into the element index calculation process, and the quantitative
model of security posture of the power information network based on the
evolutionary neural network is constructed. Finally, a simulation experiment
environment is built according to a power sector network topology, and the
effectiveness and robustness of the method proposed in the study are verified."
Transformers as Neural Augmentors: Class Conditional Sentence Generation via Variational Bayes,0.00721154,"Data augmentation methods for Natural Language Processing tasks are explored
in recent years, however they are limited and it is hard to capture the
diversity on sentence level. Besides, it is not always possible to perform data
augmentation on supervised tasks. To address those problems, we propose a
neural data augmentation method, which is a combination of Conditional
Variational Autoencoder and encoder-decoder Transformer model. While encoding
and decoding the input sentence, our model captures the syntactic and semantic
representation of the input language with its class condition. Following the
developments in the past years on pre-trained language models, we train and
evaluate our models on several benchmarks to strengthen the downstream tasks.
We compare our method with 3 different augmentation techniques. The presented
results show that, our model increases the performance of current models
compared to other data augmentation techniques with a small amount of
computation power."
Pop-Out Motion: 3D-Aware Image Deformation via Learning the Shape Laplacian,0.0181975,"We propose a framework that can deform an object in a 2D image as it exists
in 3D space. Most existing methods for 3D-aware image manipulation are limited
to (1) only changing the global scene information or depth, or (2) manipulating
an object of specific categories. In this paper, we present a 3D-aware image
deformation method with minimal restrictions on shape category and deformation
type. While our framework leverages 2D-to-3D reconstruction, we argue that
reconstruction is not sufficient for realistic deformations due to the
vulnerability to topological errors. Thus, we propose to take a supervised
learning-based approach to predict the shape Laplacian of the underlying volume
of a 3D reconstruction represented as a point cloud. Given the deformation
energy calculated using the predicted shape Laplacian and user-defined
deformation handles (e.g., keypoints), we obtain bounded biharmonic weights to
model plausible handle-based image deformation. In the experiments, we present
our results of deforming 2D character and clothed human images. We also
quantitatively show that our approach can produce more accurate deformation
weights compared to alternative methods (i.e., mesh reconstruction and point
cloud Laplacian methods)."
End-to-End Semantic Video Transformer for Zero-Shot Action Recognition,0.0282583,"While video action recognition has been an active area of research for
several years, zero-shot action recognition has only recently started gaining
traction. In this work, we propose a novel end-to-end trained transformer model
which is capable of capturing long range spatiotemporal dependencies
efficiently, contrary to existing approaches which use 3D-CNNs. Moreover, to
address a common ambiguity in the existing works about classes that can be
considered as previously unseen, we propose a new experimentation setup that
satisfies the zero-shot learning premise for action recognition by avoiding
overlap between the training and testing classes. The proposed approach
significantly outperforms the state of the arts in zero-shot action recognition
in terms of the the top-1 accuracy on UCF-101, HMDB-51 and ActivityNet
datasets. The code and proposed experimentation setup are available in GitHub:
https://github.com/Secure-and-Intelligent-Systems-Lab/SemanticVideoTransformer"
A Deep Learning Approach for Automatic Detection of Qualitative Features of Lecturing,0.0,"Artificial Intelligence in higher education opens new possibilities for
improving the lecturing process, such as enriching didactic materials, helping
in assessing students' works or even providing directions to the teachers on
how to enhance the lectures. We follow this research path, and in this work, we
explore how an academic lecture can be assessed automatically by quantitative
features. First, we prepare a set of qualitative features based on teaching
practices and then annotate the dataset of academic lecture videos collected
for this purpose. We then show how these features could be detected
automatically using machine learning and computer vision techniques. Our
results show the potential usefulness of our work."
Seeing a Rose in Five Thousand Ways,0.114308,"What is a rose, visually? A rose comprises its intrinsics, including the
distribution of geometry, texture, and material specific to its object
category. With knowledge of these intrinsic properties, we may render roses of
different sizes and shapes, in different poses, and under different lighting
conditions. In this work, we build a generative model that learns to capture
such object intrinsics from a single image, such as a photo of a bouquet. Such
an image includes multiple instances of an object type. These instances all
share the same intrinsics, but appear different due to a combination of
variance within these intrinsics and differences in extrinsic factors, such as
pose and illumination. Experiments show that our model successfully learns
object intrinsics (distribution of geometry, texture, and material) for a wide
range of objects, each from a single Internet image. Our method achieves
superior results on multiple downstream tasks, including intrinsic image
decomposition, shape and image generation, view synthesis, and relighting."
SexWEs: Domain-Aware Word Embeddings via Cross-lingual Semantic Specialisation for Chinese Sexism Detection in Social Media,0.028007,"The goal of sexism detection is to mitigate negative online content targeting
certain gender groups of people. However, the limited availability of labeled
sexism-related datasets makes it problematic to identify online sexism for
low-resource languages. In this paper, we address the task of automatic sexism
detection in social media for one low-resource language -- Chinese. Rather than
collecting new sexism data or building cross-lingual transfer learning models,
we develop a cross-lingual domain-aware semantic specialisation system in order
to make the most of existing data. Semantic specialisation is a technique for
retrofitting pre-trained distributional word vectors by integrating external
linguistic knowledge (such as lexico-semantic relations) into the specialised
feature space. To do this, we leverage semantic resources for sexism from a
high-resource language (English) to specialise pre-trained word vectors in the
target language (Chinese) to inject domain knowledge. We demonstrate the
benefit of our sexist word embeddings (SexWEs) specialised by our framework via
intrinsic evaluation of word similarity and extrinsic evaluation of sexism
detection. Compared with other specialisation approaches and Chinese baseline
word vectors, our SexWEs shows an average score improvement of 0.033 and 0.064
in both intrinsic and extrinsic evaluations, respectively. The ablative results
and visualisation of SexWEs also prove the effectiveness of our framework on
retrofitting word vectors in low-resource languages."
UnShadowNet: Illumination Critic Guided Contrastive Learning For Shadow Removal,0.0347561,"Shadows are frequently encountered natural phenomena that significantly
hinder the performance of computer vision perception systems in practical
settings, e.g., autonomous driving. A solution to this would be to eliminate
shadow regions from the images before the processing of the perception system.
Yet, training such a solution requires pairs of aligned shadowed and
non-shadowed images which are difficult to obtain. We introduce a novel weakly
supervised shadow removal framework UnShadowNet trained using contrastive
learning. It is composed of a DeShadower network responsible for the removal of
the extracted shadow under the guidance of an Illumination network which is
trained adversarially by the illumination critic and a Refinement network to
further remove artefacts. We show that UnShadowNet can be easily extended to a
fully-supervised set-up to exploit the ground-truth when available. UnShadowNet
outperforms existing state-of-the-art approaches on three publicly available
shadow datasets (ISTD, adjusted ISTD, SRD) in both the weakly and fully
supervised setups."
A Compacted Structure for Cross-domain learning on Monocular Depth and Flow Estimation,0.00718011,"Accurate motion and depth recovery is important for many robot vision tasks
including autonomous driving. Most previous studies have achieved cooperative
multi-task interaction via either pre-defined loss functions or cross-domain
prediction. This paper presents a multi-task scheme that achieves mutual
assistance by means of our Flow to Depth (F2D), Depth to Flow (D2F), and
Exponential Moving Average (EMA). F2D and D2F mechanisms enable multi-scale
information integration between optical flow and depth domain based on
differentiable shallow nets. A dual-head mechanism is used to predict optical
flow for rigid and non-rigid motion based on a divide-and-conquer manner, which
significantly improves the optical flow estimation performance. Furthermore, to
make the prediction more robust and stable, EMA is used for our multi-task
training. Experimental results on KITTI datasets show that our multi-task
scheme outperforms other multi-task schemes and provide marked improvements on
the prediction results."
Improve Ranking Correlation of Super-net through Training Scheme from One-shot NAS to Few-shot NAS,0.00417894,"The algorithms of one-shot neural architecture search(NAS) have been widely
used to reduce computation consumption. However, because of the interference
among the subnets in which weights are shared, the subnets inherited from these
super-net trained by those algorithms have poor consistency in precision
ranking. To address this problem, we propose a step-by-step training super-net
scheme from one-shot NAS to few-shot NAS. In the training scheme, we firstly
train super-net in a one-shot way, and then we disentangle the weights of
super-net by splitting them into multi-subnets and training them gradually.
Finally, our method ranks 4th place in the CVPR2022 3rd Lightweight NAS
Challenge Track1. Our code is available at
https://github.com/liujiawei2333/CVPR2022-NAS-competition-Track-1-4th-solution."
On the Typicality of Musical Sequences,0.0235056,"It has been shown in a recent publication that words in human-produced
English language tend to have an information content close to the conditional
entropy. In this paper, we show that the same is true for events in
human-produced monophonic musical sequences. We also show how ""typical
sampling"" influences the distribution of information around the entropy for
single events and sequences."
Multi-level Distillation of Semantic Knowledge for Pre-training Multilingual Language Model,0.0207227,"Pre-trained multilingual language models play an important role in
cross-lingual natural language understanding tasks. However, existing methods
did not focus on learning the semantic structure of representation, and thus
could not optimize their performance. In this paper, we propose Multi-level
Multilingual Knowledge Distillation (MMKD), a novel method for improving
multilingual language models. Specifically, we employ a teacher-student
framework to adopt rich semantic representation knowledge in English BERT. We
propose token-, word-, sentence-, and structure-level alignment objectives to
encourage multiple levels of consistency between source-target pairs and
correlation similarity between teacher and student models. We conduct
experiments on cross-lingual evaluation benchmarks including XNLI, PAWS-X, and
XQuAD. Experimental results show that MMKD outperforms other baseline models of
similar size on XNLI and XQuAD and obtains comparable performance on PAWS-X.
Especially, MMKD obtains significant performance gains on low-resource
languages."
SaiNet: Stereo aware inpainting behind objects with generative networks,0.0296775,"In this work, we present an end-to-end network for stereo-consistent image
inpainting with the objective of inpainting large missing regions behind
objects. The proposed model consists of an edge-guided UNet-like network using
Partial Convolutions. We enforce multi-view stereo consistency by introducing a
disparity loss. More importantly, we develop a training scheme where the model
is learned from realistic stereo masks representing object occlusions, instead
of the more common random masks. The technique is trained in a supervised way.
Our evaluation shows competitive results compared to previous state-of-the-art
techniques."
Multimodal Image Fusion based on Hybrid CNN-Transformer and Non-local Cross-modal Attention,0.0185176,"The fusion of images taken by heterogeneous sensors helps to enrich the
information and improve the quality of imaging. In this article, we present a
hybrid model consisting of a convolutional encoder and a Transformer-based
decoder to fuse multimodal images. In the encoder, a non-local cross-modal
attention block is proposed to capture both local and global dependencies of
multiple source images. A branch fusion module is designed to adaptively fuse
the features of the two branches. We embed a Transformer module with linear
complexity in the decoder to enhance the reconstruction capability of the
proposed network. Qualitative and quantitative experiments demonstrate the
effectiveness of the proposed method by comparing it with existing
state-of-the-art fusion models. The source code of our work is available at
https://github.com/pandayuanyu/HCFusion."
Finstreder: Simple and fast Spoken Language Understanding with Finite State Transducers using modern Speech-to-Text models,-1.0,"In Spoken Language Understanding (SLU) the task is to extract important
information from audio commands, like the intent of what a user wants the
system to do and special entities like locations or numbers. This paper
presents a simple method for embedding intents and entities into Finite State
Transducers, and, in combination with a pretrained general-purpose
Speech-to-Text model, allows building SLU-models without any additional
training. Building those models is very fast and only takes a few seconds. It
is also completely language independent. With a comparison on different
benchmarks it is shown that this method can outperform multiple other, more
resource demanding SLU approaches."
Semantic Search for Large Scale Clinical Ontologies,0.0196114,"Finding concepts in large clinical ontologies can be challenging when queries
use different vocabularies. A search algorithm that overcomes this problem is
useful in applications such as concept normalisation and ontology matching,
where concepts can be referred to in different ways, using different synonyms.
In this paper, we present a deep learning based approach to build a semantic
search system for large clinical ontologies. We propose a Triplet-BERT model
and a method that generates training data directly from the ontologies. The
model is evaluated using five real benchmark data sets and the results show
that our approach achieves high results on both free text to concept and
concept to concept searching tasks, and outperforms all baseline methods."
Structure and position-aware graph neural network for airway labeling,0.00667309,"We present a novel graph-based approach for labeling the anatomical branches
of a given airway tree segmentation. The proposed method formulates airway
labeling as a branch classification problem in the airway tree graph, where
branch features are extracted using convolutional neural networks (CNN) and
enriched using graph neural networks. Our graph neural network is
structure-aware by having each node aggregate information from its local
neighbors and position-aware by encoding node positions in the graph.
  We evaluated the proposed method on 220 airway trees from subjects with
various severity stages of Chronic Obstructive Pulmonary Disease (COPD). The
results demonstrate that our approach is computationally efficient and
significantly improves branch classification performance than the baseline
method. The overall average accuracy of our method reaches 91.18\% for labeling
all 18 segmental airway branches, compared to 83.83\% obtained by the standard
CNN method. We published our source code at
https://github.com/DIAGNijmegen/spgnn. The proposed algorithm is also publicly
available at
https://grand-challenge.org/algorithms/airway-anatomical-labeling/."
Graph Neural Network Policies and Imitation Learning for Multi-Domain Task-Oriented Dialogues,0.030297,"Task-oriented dialogue systems are designed to achieve specific goals while
conversing with humans. In practice, they may have to handle simultaneously
several domains and tasks. The dialogue manager must therefore be able to take
into account domain changes and plan over different domains/tasks in order to
deal with multidomain dialogues. However, learning with reinforcement in such
context becomes difficult because the state-action dimension is larger while
the reward signal remains scarce. Our experimental results suggest that
structured policies based on graph neural networks combined with different
degrees of imitation learning can effectively handle multi-domain dialogues.
The reported experiments underline the benefit of structured policies over
standard policies."
Go-tuning: Improving Zero-shot Learning Abilities of Smaller Language Models,0.0,"With increasing scale, large language models demonstrate both quantitative
improvement and new qualitative capabilities, especially as zero-shot learners,
like GPT-3. However, these results rely heavily on delicate prompt design and
large computation. In this work, we explore whether the strong zero-shot
ability could be achieved at a smaller model scale without any external
supervised data. To achieve this goal, we revisit masked language modeling and
present a geometry-guided self-supervised learning method (Go-tuningfor short)
by taking a small number of task-aware self-supervised data to update language
models further. Experiments show that Go-tuning can enable T5-small (80M)
competitive zero-shot results compared with large language models, such as
T5-XL (3B). We also apply Go-tuning on multi-task settings and develop a
multi-task model, mgo-T5 (250M). It can reach the average performance of OPT
(175B) on 9 datasets."
Low-rank Meets Sparseness: An Integrated Spatial-Spectral Total Variation Approach to Hyperspectral Denoising,0.0149297,"Spatial-Spectral Total Variation (SSTV) can quantify local smoothness of
image structures, so it is widely used in hyperspectral image (HSI) processing
tasks. Essentially, SSTV assumes a sparse structure of gradient maps calculated
along the spatial and spectral directions. In fact, these gradient tensors are
not only sparse, but also (approximately) low-rank under FFT, which we have
verified by numerical tests and theoretical analysis. Based on this fact, we
propose a novel TV regularization to simultaneously characterize the sparsity
and low-rank priors of the gradient map (LRSTV). The new regularization not
only imposes sparsity on the gradient map itself, but also penalize the rank on
the gradient map after Fourier transform along the spectral dimension. It
naturally encodes the sparsity and lowrank priors of the gradient map, and thus
is expected to reflect the inherent structure of the original image more
faithfully. Further, we use LRSTV to replace conventional SSTV and embed it in
the HSI processing model to improve its performance. Experimental results on
multiple public data-sets with heavy mixed noise show that the proposed model
can get 1.5dB improvement of PSNR."
Reinforcement Learning for Economic Policy: A New Frontier?,0.00286439,"Agent-based computational economics is a field with a rich academic history,
yet one which has struggled to enter mainstream policy design toolboxes,
plagued by the challenges associated with representing a complex and dynamic
reality. The field of Reinforcement Learning (RL), too, has a rich history, and
has recently been at the centre of several exponential developments. Modern RL
implementations have been able to achieve unprecedented levels of
sophistication, handling previously unthinkable degrees of complexity. This
review surveys the historical barriers of classical agent-based techniques in
economic modelling, and contemplates whether recent developments in RL can
overcome any of them."
Rendering Nighttime Image Via Cascaded Color and Brightness Compensation,0.0,"Image signal processing (ISP) is crucial for camera imaging, and neural
networks (NN) solutions are extensively deployed for daytime scenes. The lack
of sufficient nighttime image dataset and insights on nighttime illumination
characteristics poses a great challenge for high-quality rendering using
existing NN ISPs. To tackle it, we first built a high-resolution nighttime
RAW-RGB (NR2R) dataset with white balance and tone mapping annotated by expert
professionals. Meanwhile, to best capture the characteristics of nighttime
illumination light sources, we develop the CBUnet, a two-stage NN ISP to
cascade the compensation of color and brightness attributes. Experiments show
that our method has better visual quality compared to traditional ISP pipeline,
and is ranked at the second place in the NTIRE 2022 Night Photography Rendering
Challenge for two tracks by respective People's and Professional Photographer's
choices. The code and relevant materials are avaiable on our website:
https://njuvision.github.io/CBUnet."
SAVCHOI: Detecting Suspicious Activities using Dense Video Captioning with Human Object Interactions,0.00860225,"Detecting suspicious activities in surveillance videos is a longstanding
problem in real-time surveillance that leads to difficulties in detecting
crimes. Hence, we propose a novel approach for detecting and summarizing
suspicious activities in surveillance videos. We have also created ground truth
summaries for the UCF-Crime video dataset. We modify a pre-existing approach
for this task by leveraging the Human-Object Interaction (HOI) model for the
Visual features in the Bi-Modal Transformer. Further, we validate our approach
against the existing state-of-the-art algorithms for the Dense Video Captioning
task for the ActivityNet Captions dataset. We observe that this formulation for
Dense Captioning performs significantly better than other discussed BMT-based
approaches for BLEU@1, BLEU@2, BLEU@3, BLEU@4, and METEOR. We further perform a
comparative analysis of the dataset and the model to report the findings based
on different NMS thresholds (searched using Genetic Algorithms). Here, our
formulation outperforms all the models for BLEU@1, BLEU@2, BLEU@3, and most
models for BLEU@4 and METEOR falling short of only ADV-INF Global by 25% and
0.5%, respectively."
Physically-admissible polarimetric data augmentation for road-scene analysis,0.00740112,"Polarimetric imaging, along with deep learning, has shown improved
performances on different tasks including scene analysis. However, its
robustness may be questioned because of the small size of the training
datasets. Though the issue could be solved by data augmentation, polarization
modalities are subject to physical feasibility constraints unaddressed by
classical data augmentation techniques. To address this issue, we propose to
use CycleGAN, an image translation technique based on deep generative models
that solely relies on unpaired data, to transfer large labeled road scene
datasets to the polarimetric domain. We design several auxiliary loss terms
that, alongside the CycleGAN losses, deal with the physical constraints of
polarimetric images. The efficiency of this solution is demonstrated on road
scene object detection tasks where generated realistic polarimetric images
allow to improve performances on cars and pedestrian detection up to 9%. The
resulting constrained CycleGAN is publicly released, allowing anyone to
generate their own polarimetric images."
Explaining Causal Models with Argumentation: the Case of Bi-variate Reinforcement,0.0,"Causal models are playing an increasingly important role in machine learning,
particularly in the realm of explainable AI. We introduce a conceptualisation
for generating argumentation frameworks (AFs) from causal models for the
purpose of forging explanations for the models' outputs. The conceptualisation
is based on reinterpreting desirable properties of semantics of AFs as
explanation moulds, which are means for characterising the relations in the
causal model argumentatively. We demonstrate our methodology by reinterpreting
the property of bi-variate reinforcement as an explanation mould to forge
bipolar AFs as explanations for the outputs of causal models. We perform a
theoretical evaluation of these argumentative explanations, examining whether
they satisfy a range of desirable explanatory and argumentative properties."
Towards a Unified Approach to Homography Estimation Using Image Features and Pixel Intensities,0.0367754,"The homography matrix is a key component in various vision-based robotic
tasks. Traditionally, homography estimation algorithms are classified into
feature- or intensity-based. The main advantages of the latter are their
versatility, accuracy, and robustness to arbitrary illumination changes. On the
other hand, they have a smaller domain of convergence than the feature-based
solutions. Their combination is hence promising, but existing techniques only
apply them sequentially. This paper proposes a new hybrid method that unifies
both classes into a single nonlinear optimization procedure, applies the same
minimization method, and uses the same homography parametrization and warping
function. Experimental validation using a classical testing framework shows
that the proposed unified approach has improved convergence properties compared
to each individual class. These are also demonstrated in a visual tracking
application. As a final contribution, our ready-to-use implementation of the
algorithm is made publicly available to the research community."
On Faithfulness and Coherence of Language Explanations for Recommendation Systems,0.0,"Reviews contain rich information about product characteristics and user
interests and thus are commonly used to boost recommender system performance.
Specifically, previous work show that jointly learning to perform review
generation improves rating prediction performance. Meanwhile, these
model-produced reviews serve as recommendation explanations, providing the user
with insights on predicted ratings. However, while existing models could
generate fluent, human-like reviews, it is unclear to what degree the reviews
fully uncover the rationale behind the jointly predicted rating. In this work,
we perform a series of evaluations that probes state-of-the-art models and
their review generation component. We show that the generated explanations are
brittle and need further evaluation before being taken as literal rationales
for the estimated ratings."
RescueNet: A High Resolution UAV Semantic Segmentation Benchmark Dataset for Natural Disaster Damage Assessment,0.063903,"Recent advancements in computer vision and deep learning techniques have
facilitated notable progress in scene understanding, thereby assisting rescue
teams in achieving precise damage assessment. In this paper, we present
RescueNet, a meticulously curated high-resolution post-disaster dataset that
includes detailed classification and semantic segmentation annotations. This
dataset aims to facilitate comprehensive scene understanding in the aftermath
of natural disasters. RescueNet comprises post-disaster images collected after
Hurricane Michael, obtained using Unmanned Aerial Vehicles (UAVs) from multiple
impacted regions. The uniqueness of RescueNet lies in its provision of
high-resolution post-disaster imagery, accompanied by comprehensive annotations
for each image. Unlike existing datasets that offer annotations limited to
specific scene elements such as buildings, RescueNet provides pixel-level
annotations for all classes, including buildings, roads, pools, trees, and
more. Furthermore, we evaluate the utility of the dataset by implementing
state-of-the-art segmentation models on RescueNet, demonstrating its value in
enhancing existing methodologies for natural disaster damage assessment."
Prediction of GPU Failures Under Deep Learning Workloads,0.0136165,"Graphics processing units (GPUs) are the de facto standard for processing
deep learning (DL) tasks. Meanwhile, GPU failures, which are inevitable, cause
severe consequences in DL tasks: they disrupt distributed trainings, crash
inference services, and result in service level agreement violations. To
mitigate the problem caused by GPU failures, we propose to predict failures by
using ML models. This paper is the first to study prediction models of GPU
failures under large-scale production deep learning workloads. As a starting
point, we evaluate classic prediction models and observe that predictions of
these models are both inaccurate and unstable. To improve the precision and
stability of predictions, we propose several techniques, including parallel and
cascade model-ensemble mechanisms and a sliding training method. We evaluate
the performances of our various techniques on a four-month production dataset
including 350 million entries. The results show that our proposed techniques
improve the prediction precision from 46.3\% to 84.0\%."
Auto Machine Learning for Medical Image Analysis by Unifying the Search on Data Augmentation and Neural Architecture,0.00299789,"Automated data augmentation, which aims at engineering augmentation policy
automatically, recently draw a growing research interest. Many previous
auto-augmentation methods utilized a Density Matching strategy by evaluating
policies in terms of the test-time augmentation performance. In this paper, we
theoretically and empirically demonstrated the inconsistency between the train
and validation set of small-scale medical image datasets, referred to as
in-domain sampling bias. Next, we demonstrated that the in-domain sampling bias
might cause the inefficiency of Density Matching. To address the problem, an
improved augmentation search strategy, named Augmented Density Matching, was
proposed by randomly sampling policies from a prior distribution for training.
Moreover, an efficient automatical machine learning(AutoML) algorithm was
proposed by unifying the search on data augmentation and neural architecture.
Experimental results indicated that the proposed methods outperformed
state-of-the-art approaches on MedMNIST, a pioneering benchmark designed for
AutoML in medical image analysis."
Pixel is All You Need: Adversarial Trajectory-Ensemble Active Learning for Salient Object Detection,0.0872335,"Although weakly-supervised techniques can reduce the labeling effort, it is
unclear whether a saliency model trained with weakly-supervised data (e.g.,
point annotation) can achieve the equivalent performance of its
fully-supervised version. This paper attempts to answer this unexplored
question by proving a hypothesis: there is a point-labeled dataset where
saliency models trained on it can achieve equivalent performance when trained
on the densely annotated dataset. To prove this conjecture, we proposed a novel
yet effective adversarial trajectory-ensemble active learning (ATAL). Our
contributions are three-fold: 1) Our proposed adversarial attack triggering
uncertainty can conquer the overconfidence of existing active learning methods
and accurately locate these uncertain pixels. {2)} Our proposed
trajectory-ensemble uncertainty estimation method maintains the advantages of
the ensemble networks while significantly reducing the computational cost. {3)}
Our proposed relationship-aware diversity sampling algorithm can conquer
oversampling while boosting performance. Experimental results show that our
ATAL can find such a point-labeled dataset, where a saliency model trained on
it obtained $97\%$ -- $99\%$ performance of its fully-supervised version with
only ten annotated points per image."
IISERB Brains at SemEval 2022 Task 6: A Deep-learning Framework to Identify Intended Sarcasm in English,0.0272678,"This paper describes the system architectures and the models submitted by our
team ""IISERBBrains"" to SemEval 2022 Task 6 competition. We contested for all
three sub-tasks floated for the English dataset. On the leader-board, wegot19th
rank out of43 teams for sub-taskA, the 8th rank out of22 teams for sub-task
B,and13th rank out of 16 teams for sub-taskC. Apart from the submitted results
and models, we also report the other models and results that we obtained
through our experiments after organizers published the gold labels of their
evaluation data"
Mobile Robot Manipulation using Pure Object Detection,0.0214074,"This paper addresses the problem of mobile robot manipulation using object
detection. Our approach uses detection and control as complimentary functions
that learn from real-world interactions. We develop an end-to-end manipulation
method based solely on detection and introduce Task-focused Few-shot Object
Detection (TFOD) to learn new objects and settings. Our robot collects its own
training data and automatically determines when to retrain detection to improve
performance across various subtasks (e.g., grasping). Notably, detection
training is low-cost, and our robot learns to manipulate new objects using as
few as four clicks of annotation. In physical experiments, our robot learns
visual control from a single click of annotation and a novel update
formulation, manipulates new objects in clutter and other mobile settings, and
achieves state-of-the-art results on an existing visual servo control and depth
estimation benchmark. Finally, we develop a TFOD Benchmark to support future
object detection research for robotics: https://github.com/griffbr/tfod."
TYPIC: A Corpus of Template-Based Diagnostic Comments on Argumentation,0.115804,"Providing feedback on the argumentation of the learner is essential for
developing critical thinking skills, however, it requires a lot of time and
effort. To mitigate the overload on teachers, we aim to automate a process of
providing feedback, especially giving diagnostic comments which point out the
weaknesses inherent in the argumentation. It is recommended to give specific
diagnostic comments so that learners can recognize the diagnosis without
misinterpretation. However, it is not obvious how the task of providing
specific diagnostic comments should be formulated. We present a formulation of
the task as template selection and slot filling to make an automatic evaluation
easier and the behavior of the model more tractable. The key to the formulation
is the possibility of creating a template set that is sufficient for practical
use. In this paper, we define three criteria that a template set should
satisfy: expressiveness, informativeness, and uniqueness, and verify the
feasibility of creating a template set that satisfies these criteria as a first
trial. We will show that it is feasible through an annotation study that
converts diagnostic comments given in a text to a template format. The corpus
used in the annotation study is publicly available."
HYU at SemEval-2022 Task 2: Effective Idiomaticity Detection with Consideration at Different Levels of Contextualization,0.0121256,"We propose a unified framework that enables us to consider various aspects of
contextualization at different levels to better identify the idiomaticity of
multi-word expressions. Through extensive experiments, we demonstrate that our
approach based on the inter- and inner-sentence context of a target MWE is
effective in improving the performance of related models. We also share our
experience in detail on the task of SemEval-2022 Tasks 2 such that future work
on the same task can be benefited from this."
An Adaptive Repeated-Intersection-Reduction Local Search for the Maximum Independent Set Problem,0.0106721,"The maximum independent set (MIS) problem, a classical NP-hard problem with
extensive applications in various areas, aims to find the largest set of
vertices with no edge among them. Due to its computational intractability, it
is difficult to solve the MIS problem effectively, especially on large graphs.
Employing heuristic approaches to obtain a good solution within an acceptable
amount of time has attracted much attention in literature. In this paper, we
propose an efficient local search framework for MIS called ARIR, which
encompasses two main parts: a lightweight adaptive mechanism and a novel
inexact efficient reduction rule to simplify instances. Based on ARIR, three
algorithms -- ARIR-I, ARIR-II, and ARIR-III -- are developed by adopting three
distinct reduction strategies. We conduct experiments on five benchmarks,
encompassing 92 instances. Compared with six state-of-the-art algorithms, our
ARIR-based algorithms offer the best accuracy on the majority of instances,
while obtaining competitive results on the remaining instances."
Memory-Based Label-Text Tuning for Few-Shot Class-Incremental Learning,0.0301272,"Few-shot class-incremental learning(FSCIL) focuses on designing learning
algorithms that can continually learn a sequence of new tasks from a few
samples without forgetting old ones. The difficulties are that training on a
sequence of limited data from new tasks leads to severe overfitting issues and
causes the well-known catastrophic forgetting problem. Existing researches
mainly utilize the image information, such as storing the image knowledge of
previous tasks or limiting classifiers updating. However, they ignore analyzing
the informative and less noisy text information of class labels. In this work,
we propose leveraging the label-text information by adopting the memory prompt.
The memory prompt can learn new data sequentially, and meanwhile store the
previous knowledge. Furthermore, to optimize the memory prompt without
undermining the stored knowledge, we propose a stimulation-based training
strategy. It optimizes the memory prompt depending on the image embedding
stimulation, which is the distribution of the image embedding elements.
Experiments show that our proposed method outperforms all prior
state-of-the-art approaches, significantly mitigating the catastrophic
forgetting and overfitting problems."
Skit-S2I: An Indian Accented Speech to Intent dataset,0.125586,"Conventional conversation assistants extract text transcripts from the speech
signal using automatic speech recognition (ASR) and then predict intent from
the transcriptions. Using end-to-end spoken language understanding (SLU), the
intents of the speaker are predicted directly from the speech signal without
requiring intermediate text transcripts. As a result, the model can optimize
directly for intent classification and avoid cascading errors from ASR. The
end-to-end SLU system also helps in reducing the latency of the intent
prediction model. Although many datasets are available publicly for
text-to-intent tasks, the availability of labeled speech-to-intent datasets is
limited, and there are no datasets available in the Indian accent. In this
paper, we release the Skit-S2I dataset, the first publicly available
Indian-accented SLU dataset in the banking domain in a conversational tonality.
We experiment with multiple baselines, compare different pretrained speech
encoder's representations, and find that SSL pretrained representations perform
slightly better than ASR pretrained representations lacking prosodic features
for speech-to-intent classification. The dataset and baseline code is available
at \url{https://github.com/skit-ai/speech-to-intent-dataset}"
Self-Supervised Speech Representations Preserve Speech Characteristics while Anonymizing Voices,0.0104756,"Collecting speech data is an important step in training speech recognition
systems and other speech-based machine learning models. However, the issue of
privacy protection is an increasing concern that must be addressed. The current
study investigates the use of voice conversion as a method for anonymizing
voices. In particular, we train several voice conversion models using
self-supervised speech representations including Wav2Vec2.0, Hubert and
UniSpeech. Converted voices retain a low word error rate within 1% of the
original voice. Equal error rate increases from 1.52% to 46.24% on the
LibriSpeech test set and from 3.75% to 45.84% on speakers from the VCTK corpus
which signifies degraded performance on speaker verification. Lastly, we
conduct experiments on dysarthric speech data to show that speech features
relevant to articulation, prosody, phonation and phonology can be extracted
from anonymized voices for discriminating between healthy and pathological
speech."
Multi-Level Modeling Units for End-to-End Mandarin Speech Recognition,0.0337623,"The choice of modeling units is crucial for automatic speech recognition
(ASR) tasks. In mandarin scenarios, the Chinese characters represent meaning
but are not directly related to the pronunciation. Thus only considering the
writing of Chinese characters as modeling units is insufficient to capture
speech features. In this paper, we present a novel method involves with
multi-level modeling units, which integrates multi-level information for
mandarin speech recognition. Specifically, the encoder block considers
syllables as modeling units and the decoder block deals with character-level
modeling units. To facilitate the incremental conversion from syllable features
to character features, we design an auxiliary task that applies cross-entropy
(CE) loss to intermediate decoder layers. During inference, the input feature
sequences are converted into syllable sequences by the encoder block and then
converted into Chinese characters by the decoder block. Experiments on the
widely used AISHELL-1 corpus demonstrate that our method achieves promising
results with CER of 4.1%/4.6% and 4.6%/5.2%, using the Conformer and the
Transformer backbones respectively."
Non-Axiomatic Term Logic: A Computational Theory of Cognitive Symbolic Reasoning,0.0435659,"This paper presents Non-Axiomatic Term Logic (NATL) as a theoretical
computational framework of humanlike symbolic reasoning in artificial
intelligence. NATL unites a discrete syntactic system inspired from Aristotle's
term logic and a continuous semantic system based on the modern idea of
distributed representations, or embeddings. This paper positions the proposed
approach in the phylogeny and the literature of logic, and explains the
framework. As it is yet no more than a theory and it requires much further
elaboration to implement it, no quantitative evaluation is presented. Instead,
qualitative analyses of arguments using NATL, some applications to possible
cognitive science/robotics-related research, and remaining issues towards a
machinery implementation are discussed."
Place Recognition under Occlusion and Changing Appearance via Disentangled Representations,0.0,"Place recognition is a critical and challenging task for mobile robots,
aiming to retrieve an image captured at the same place as a query image from a
database. Existing methods tend to fail while robots move autonomously under
occlusion (e.g., car, bus, truck) and changing appearance (e.g., illumination
changes, seasonal variation). Because they encode the image into only one code,
entangling place features with appearance and occlusion features. To overcome
this limitation, we propose PROCA, an unsupervised approach to decompose the
image representation into three codes: a place code used as a descriptor to
retrieve images, an appearance code that captures appearance properties, and an
occlusion code that encodes occlusion content. Extensive experiments show that
our model outperforms the state-of-the-art methods. Our code and data are
available at https://github.com/rover-xingyu/PROCA."
Utilizing unsupervised learning to improve sward content prediction and herbage mass estimation,0.00813804,"Sward species composition estimation is a tedious one. Herbage must be
collected in the field, manually separated into components, dried and weighed
to estimate species composition. Deep learning approaches using neural networks
have been used in previous work to propose faster and more cost efficient
alternatives to this process by estimating the biomass information from a
picture of an area of pasture alone. Deep learning approaches have, however,
struggled to generalize to distant geographical locations and necessitated
further data collection to retrain and perform optimally in different climates.
In this work, we enhance the deep learning solution by reducing the need for
ground-truthed (GT) images when training the neural network. We demonstrate how
unsupervised contrastive learning can be used in the sward composition
prediction problem and compare with the state-of-the-art on the publicly
available GrassClover dataset collected in Denmark as well as a more recent
dataset from Ireland where we tackle herbage mass and height estimation."
LHDR: HDR Reconstruction for Legacy Content using a Lightweight DNN,0.029289,"High dynamic range (HDR) image is widely-used in graphics and photography due
to the rich information it contains. Recently the community has started using
deep neural network (DNN) to reconstruct standard dynamic range (SDR) images
into HDR. Albeit the superiority of current DNN-based methods, their
application scenario is still limited: (1) heavy model impedes real-time
processing, and (2) inapplicable to legacy SDR content with more degradation
types. Therefore, we propose a lightweight DNN-based method trained to tackle
legacy SDR. For better design, we reform the problem modeling and emphasize
degradation model. Experiments show that our method reached appealing
performance with minimal computational cost compared with others."
Toxicity Detection for Indic Multilingual Social Media Content,0.0555733,"Toxic content is one of the most critical issues for social media platforms
today. India alone had 518 million social media users in 2020. In order to
provide a good experience to content creators and their audience, it is crucial
to flag toxic comments and the users who post that. But the big challenge is
identifying toxicity in low resource Indic languages because of the presence of
multiple representations of the same text. Moreover, the posts/comments on
social media do not adhere to a particular format, grammar or sentence
structure; this makes the task of abuse detection even more challenging for
multilingual social media platforms. This paper describes the system proposed
by team 'Moj Masti' using the data provided by ShareChat/Moj in \emph{IIIT-D
Multilingual Abusive Comment Identification} challenge. We focus on how we can
leverage multilingual transformer based pre-trained and fine-tuned models to
approach code-mixed/code-switched classification tasks. Our best performing
system was an ensemble of XLM-RoBERTa and MuRIL which achieved a Mean F-1 score
of 0.9 on the test data/leaderboard. We also observed an increase in the
performance by adding transliterated data. Furthermore, using weak metadata,
ensembling and some post-processing techniques boosted the performance of our
system, thereby placing us 1st on the leaderboard."
Spatio-Temporal Crop Aggregation for Video Representation Learning,0.00665404,"We propose Spatio-temporal Crop Aggregation for video representation LEarning
(SCALE), a novel method that enjoys high scalability at both training and
inference time. Our model builds long-range video features by learning from
sets of video clip-level features extracted with a pre-trained backbone. To
train the model, we propose a self-supervised objective consisting of masked
clip feature prediction. We apply sparsity to both the input, by extracting a
random set of video clips, and to the loss function, by only reconstructing the
sparse inputs. Moreover, we use dimensionality reduction by working in the
latent space of a pre-trained backbone applied to single video clips. These
techniques make our method not only extremely efficient to train but also
highly effective in transfer learning. We demonstrate that our video
representation yields state-of-the-art performance with linear, non-linear, and
KNN probing on common action classification and video understanding datasets."
Multi-domain Unsupervised Image-to-Image Translation with Appearance Adaptive Convolution,0.0206728,"Over the past few years, image-to-image (I2I) translation methods have been
proposed to translate a given image into diverse outputs. Despite the
impressive results, they mainly focus on the I2I translation between two
domains, so the multi-domain I2I translation still remains a challenge. To
address this problem, we propose a novel multi-domain unsupervised
image-to-image translation (MDUIT) framework that leverages the decomposed
content feature and appearance adaptive convolution to translate an image into
a target appearance while preserving the given geometric content. We also
exploit a contrast learning objective, which improves the disentanglement
ability and effectively utilizes multi-domain image data in the training
process by pairing the semantically similar images. This allows our method to
learn the diverse mappings between multiple visual domains with only a single
framework. We show that the proposed method produces visually diverse and
plausible results in multiple domains compared to the state-of-the-art methods."
Visible and Near Infrared Image Fusion Based on Texture Information,0.0163406,"Multi-sensor fusion is widely used in the environment perception system of
the autonomous vehicle. It solves the interference caused by environmental
changes and makes the whole driving system safer and more reliable. In this
paper, a novel visible and near-infrared fusion method based on texture
information is proposed to enhance unstructured environmental images. It aims
at the problems of artifact, information loss and noise in traditional visible
and near infrared image fusion methods. Firstly, the structure information of
the visible image (RGB) and the near infrared image (NIR) after texture removal
is obtained by relative total variation (RTV) calculation as the base layer of
the fused image; secondly, a Bayesian classification model is established to
calculate the noise weight and the noise information and the noise information
in the visible image is adaptively filtered by joint bilateral filter; finally,
the fused image is acquired by color space conversion. The experimental results
demonstrate that the proposed algorithm can preserve the spectral
characteristics and the unique information of visible and near-infrared images
without artifacts and color distortion, and has good robustness as well as
preserving the unique texture."
Applying a Generic Sequence-to-Sequence Model for Simple and Effective Keyphrase Generation,0.203218,"In recent years, a number of keyphrase generation (KPG) approaches were
proposed consisting of complex model architectures, dedicated training
paradigms and decoding strategies. In this work, we opt for simplicity and show
how a commonly used seq2seq language model, BART, can be easily adapted to
generate keyphrases from the text in a single batch computation using a simple
training procedure. Empirical results on five benchmarks show that our approach
is as good as the existing state-of-the-art KPG systems, but using a much
simpler and easy to deploy framework."
Is Face Recognition Safe from Realizable Attacks?,0.0479591,"Face recognition is a popular form of biometric authentication and due to its
widespread use, attacks have become more common as well. Recent studies show
that Face Recognition Systems are vulnerable to attacks and can lead to
erroneous identification of faces. Interestingly, most of these attacks are
white-box, or they are manipulating facial images in ways that are not
physically realizable. In this paper, we propose an attack scheme where the
attacker can generate realistic synthesized face images with subtle
perturbations and physically realize that onto his face to attack black-box
face recognition systems. Comprehensive experiments and analyses show that
subtle perturbations realized on attackers face can create successful attacks
on state-of-the-art face recognition systems in black-box settings. Our study
exposes the underlying vulnerability posed by the Face Recognition Systems
against realizable black-box attacks."
A Benchmark Generator for Combinatorial Testing,0.00787416,"Combinatorial Testing (CT) tools are essential to test properly a wide range
of systems (train systems, Graphical User Interfaces (GUIs), autonomous driving
systems, etc). While there is an active research community working on
developing CT tools, paradoxically little attention has been paid to making
available enough resources to test the CT tools themselves. In particular, the
set of available benchmarks to asses their correctness, effectiveness and
efficiency is rather limited. In this paper, we introduce a new generator of CT
benchmarks that essentially borrows the structure contained in the plethora of
available Combinatorial Problems from other research communities in order to
create meaningful benchmarks. We additionally perform an extensive evaluation
of CT tools with these new benchmarks. Thanks to this study we provide some
insights on under which circumstances a particular CT tool should be used."
Proximal Policy Optimization with Graph Neural Networks for Optimal Power Flow,0.0277721,"Optimal Power Flow (OPF) is a very traditional research area within the power
systems field that seeks for the optimal operation point of electric power
plants, and which needs to be solved every few minutes in real-world scenarios.
However, due to the nonconvexities that arise in power generation systems,
there is not yet a fast, robust solution technique for the full Alternating
Current Optimal Power Flow (ACOPF). In the last decades, power grids have
evolved into a typical dynamic, non-linear and large-scale control system,
known as the power system, so searching for better and faster ACOPF solutions
is becoming crucial. Appearance of Graph Neural Networks (GNN) has allowed the
natural use of Machine Learning (ML) algorithms on graph data, such as power
networks. On the other hand, Deep Reinforcement Learning (DRL) is known for its
powerful capability to solve complex decision-making problems. Although
solutions that use these two methods separately are beginning to appear in the
literature, none has yet combined the advantages of both. We propose a novel
architecture based on the Proximal Policy Optimization algorithm with Graph
Neural Networks to solve the Optimal Power Flow. The objective is to design an
architecture that learns how to solve the optimization problem and that is at
the same time able to generalize to unseen scenarios. We compare our solution
with the DCOPF in terms of cost after having trained our DRL agent on IEEE 30
bus system and then computing the OPF on that base network with topology
changes"
Empirical Bayes approach to Truth Discovery problems,0.00369509,"When aggregating information from conflicting sources, one's goal is to find
the truth. Most real-value \emph{truth discovery} (TD) algorithms try to
achieve this goal by estimating the competence of each source and then
aggregating the conflicting information by weighing each source's answer
proportionally to her competence. However, each of those algorithms requires
more than a single source for such estimation and usually does not consider
different estimation methods other than a weighted mean. Therefore, in this
work we formulate, prove, and empirically test the conditions for an Empirical
Bayes Estimator (EBE) to dominate the weighted mean aggregation. Our main
result demonstrates that EBE, under mild conditions, can be used as a second
step of any TD algorithm in order to reduce the expected error."
Z-BERT-A: a zero-shot Pipeline for Unknown Intent detection,0.0264381,"Intent discovery is a crucial task in natural language processing, and it is
increasingly relevant for various of industrial applications. Identifying
novel, unseen intents from user inputs remains one of the biggest challenges in
this field. Herein, we propose Zero-Shot-BERT-Adapters, a two-stage method for
multilingual intent discovery relying on a Transformer architecture, fine-tuned
with Adapters. We train the model for Natural Language Inference (NLI) and
later perform unknown intent classification in a zero-shot setting for multiple
languages. In our evaluation, we first analyze the quality of the model after
adaptive fine-tuning on known classes. Secondly, we evaluate its performance in
casting intent classification as an NLI task. Lastly, we test the zero-shot
performance of the model on unseen classes, showing how Zero-Shot-BERT-Adapters
can effectively perform intent discovery by generating semantically similar
intents, if not equal, to the ground-truth ones. Our experiments show how
Zero-Shot-BERT-Adapters outperforms various baselines in two zero-shot
settings: known intent classification and unseen intent discovery. The proposed
pipeline holds the potential for broad application in customer care. It enables
automated dynamic triage using a lightweight model that can be easily deployed
and scaled in various business scenarios, unlike large language models.
Zero-Shot-BERT-Adapters represents an innovative multi-language approach for
intent discovery, enabling the online generation of novel intents. A Python
package implementing the pipeline and the new datasets we compiled are
available at the following link:
https://github.com/GT4SD/zero-shot-bert-adapters."
Text normalization for low-resource languages: the case of Ligurian,0.270937,"Text normalization is a crucial technology for low-resource languages which
lack rigid spelling conventions or that have undergone multiple spelling
reforms. Low-resource text normalization has so far relied upon hand-crafted
rules, which are perceived to be more data efficient than neural methods. In
this paper we examine the case of text normalization for Ligurian, an
endangered Romance language. We collect 4,394 Ligurian sentences paired with
their normalized versions, as well as the first open source monolingual corpus
for Ligurian. We show that, in spite of the small amounts of data available, a
compact transformer-based model can be trained to achieve very low error rates
by the use of backtranslation and appropriate tokenization."
Visualizing and Explaining Language Models,0.0,"During the last decade, Natural Language Processing has become, after
Computer Vision, the second field of Artificial Intelligence that was massively
changed by the advent of Deep Learning. Regardless of the architecture, the
language models of the day need to be able to process or generate text, as well
as predict missing words, sentences or relations depending on the task. Due to
their black-box nature, such models are difficult to interpret and explain to
third parties. Visualization is often the bridge that language model designers
use to explain their work, as the coloring of the salient words and phrases,
clustering or neuron activations can be used to quickly understand the
underlying models. This paper showcases the techniques used in some of the most
popular Deep Learning for NLP visualizations, with a special focus on
interpretability and explainability."
Deep Generative Framework for Interactive 3D Terrain Authoring and Manipulation,0.181999,"Automated generation and (user) authoring of the realistic virtual terrain is
most sought for by the multimedia applications like VR models and gaming. The
most common representation adopted for terrain is Digital Elevation Model
(DEM). Existing terrain authoring and modeling techniques have addressed some
of these and can be broadly categorized as: procedural modeling, simulation
method, and example-based methods. In this paper, we propose a novel realistic
terrain authoring framework powered by a combination of VAE and generative
conditional GAN model. Our framework is an example-based method that attempts
to overcome the limitations of existing methods by learning a latent space from
a real-world terrain dataset. This latent space allows us to generate multiple
variants of terrain from a single input as well as interpolate between terrains
while keeping the generated terrains close to real-world data distribution. We
also developed an interactive tool, that lets the user generate diverse
terrains with minimalist inputs. We perform thorough qualitative and
quantitative analysis and provide comparisons with other SOTA methods. We
intend to release our code/tool to the academic community."
Conservative Distributional Reinforcement Learning with Safety Constraints,0.0358157,"Safety exploration can be regarded as a constrained Markov decision problem
where the expected long-term cost is constrained. Previous off-policy
algorithms convert the constrained optimization problem into the corresponding
unconstrained dual problem by introducing the Lagrangian relaxation technique.
However, the cost function of the above algorithms provides inaccurate
estimations and causes the instability of the Lagrange multiplier learning. In
this paper, we present a novel off-policy reinforcement learning algorithm
called Conservative Distributional Maximum a Posteriori Policy Optimization
(CDMPO). At first, to accurately judge whether the current situation satisfies
the constraints, CDMPO adapts distributional reinforcement learning method to
estimate the Q-function and C-function. Then, CDMPO uses a conservative value
function loss to reduce the number of violations of constraints during the
exploration process. In addition, we utilize Weighted Average Proportional
Integral Derivative (WAPID) to update the Lagrange multiplier stably. Empirical
results show that the proposed method has fewer violations of constraints in
the early exploration process. The final test results also illustrate that our
method has better risk control."
Race Bias Analysis of Bona Fide Errors in face anti-spoofing,0.0244182,"The study of bias in Machine Learning is receiving a lot of attention in
recent years, however, few only papers deal explicitly with the problem of race
bias in face anti-spoofing. In this paper, we present a systematic study of
race bias in face anti-spoofing with three key characteristics: the focus is on
analysing potential bias in the bona fide errors, where significant ethical and
legal issues lie; the analysis is not restricted to the final binary outcomes
of the classifier, but also covers the classifier's scalar responses and its
latent space; the threshold determining the operating point of the classifier
is considered a variable. We demonstrate the proposed bias analysis process on
a VQ-VAE based face anti-spoofing algorithm, trained on the Replay Attack and
the Spoof in the Wild (SiW) databases, and analysed for bias on the SiW and
Racial Faces in the Wild (RFW), databases. The results demonstrate that race
bias is not necessarily the result of different mean response values among the
various populations. Instead, it can be better understood as the combined
effect of several possible characteristics of the response distributions:
different means; different variances; bimodal behaviour; existence of outliers."
Which country is this picture from? New data and methods for DNN-based country recognition,0.0236664,"Recognizing the country where a picture has been taken has many potential
applications, such as identification of fake news and prevention of
disinformation campaigns. Previous works focused on the estimation of the
geo-coordinates where a picture has been taken. Yet, recognizing in which
country an image was taken could be more critical, from a semantic and forensic
point of view, than estimating its spatial coordinates. In the above framework,
this paper provides two contributions. First, we introduce the VIPPGeo dataset,
containing 3.8 million geo-tagged images. Secondly, we used the dataset to
train a model casting the country recognition problem as a classification
problem. The experiments show that our model provides better results than the
current state of the art. Notably, we found that asking the network to identify
the country provides better results than estimating the geo-coordinates and
then tracing them back to the country where the picture was taken."
Lightweight Image Codec via Multi-Grid Multi-Block-Size Vector Quantization (MGBVQ),0.0643065,"A multi-grid multi-block-size vector quantization (MGBVQ) method is proposed
for image coding in this work. The fundamental idea of image coding is to
remove correlations among pixels before quantization and entropy coding, e.g.,
the discrete cosine transform (DCT) and intra predictions, adopted by modern
image coding standards. We present a new method to remove pixel correlations.
First, by decomposing correlations into long- and short-range correlations, we
represent long-range correlations in coarser grids due to their smoothness,
thus leading to a multi-grid (MG) coding architecture. Second, we show that
short-range correlations can be effectively coded by a suite of vector
quantizers (VQs). Along this line, we argue the effectiveness of VQs of very
large block sizes and present a convenient way to implement them. It is shown
by experimental results that MGBVQ offers excellent rate-distortion (RD)
performance, which is comparable with existing image coders, at much lower
complexity. Besides, it provides a progressive coded bitstream."
SubER: A Metric for Automatic Evaluation of Subtitle Quality,0.0396593,"This paper addresses the problem of evaluating the quality of automatically
generated subtitles, which includes not only the quality of the
machine-transcribed or translated speech, but also the quality of line
segmentation and subtitle timing. We propose SubER - a single novel metric
based on edit distance with shifts that takes all of these subtitle properties
into account. We compare it to existing metrics for evaluating transcription,
translation, and subtitle quality. A careful human evaluation in a post-editing
scenario shows that the new metric has a high correlation with the post-editing
effort and direct human assessment scores, outperforming baseline metrics
considering only the subtitle text, such as WER and BLEU, and existing methods
to integrate segmentation and timing features."
Utterance Rewriting with Contrastive Learning in Multi-turn Dialogue,0.0105128,"Context modeling plays a significant role in building multi-turn dialogue
systems. In order to make full use of context information, systems can use
Incomplete Utterance Rewriting(IUR) methods to simplify the multi-turn dialogue
into single-turn by merging current utterance and context information into a
self-contained utterance. However, previous approaches ignore the intent
consistency between the original query and rewritten query. The detection of
omitted or coreferred locations in the original query can be further improved.
In this paper, we introduce contrastive learning and multi-task learning to
jointly model the problem. Our method benefits from carefully designed
self-supervised objectives, which act as auxiliary tasks to capture semantics
at both sentence-level and token-level. The experiments show that our proposed
model achieves state-of-the-art performance on several public datasets."
WR-ONE2SET: Towards Well-Calibrated Keyphrase Generation,0.166182,"Keyphrase generation aims to automatically generate short phrases summarizing
an input document. The recently emerged ONE2SET paradigm (Ye et al., 2021)
generates keyphrases as a set and has achieved competitive performance.
Nevertheless, we observe serious calibration errors outputted by ONE2SET,
especially in the over-estimation of $\varnothing$ token (means ""no
corresponding keyphrase""). In this paper, we deeply analyze this limitation and
identify two main reasons behind: 1) the parallel generation has to introduce
excessive $\varnothing$ as padding tokens into training instances; and 2) the
training mechanism assigning target to each slot is unstable and further
aggravates the $\varnothing$ token over-estimation. To make the model
well-calibrated, we propose WR-ONE2SET which extends ONE2SET with an adaptive
instance-level cost Weighting strategy and a target Re-assignment mechanism.
The former dynamically penalizes the over-estimated slots for different
instances thus smoothing the uneven training distribution. The latter refines
the original inappropriate assignment and reduces the supervisory signals of
over-estimated slots. Experimental results on commonly-used datasets
demonstrate the effectiveness and generality of our proposed paradigm."
Join-Chain Network: A Logical Reasoning View of the Multi-head Attention in Transformer,0.0225378,"Developing neural architectures that are capable of logical reasoning has
become increasingly important for a wide range of applications (e.g., natural
language processing). Towards this grand objective, we propose a symbolic
reasoning architecture that chains many join operators together to model output
logical expressions. In particular, we demonstrate that such an ensemble of
join-chains can express a broad subset of ''tree-structured'' first-order
logical expressions, named FOET, which is particularly useful for modeling
natural languages. To endow it with differentiable learning capability, we
closely examine various neural operators for approximating the symbolic
join-chains. Interestingly, we find that the widely used multi-head
self-attention module in transformer can be understood as a special neural
operator that implements the union bound of the join operator in probabilistic
predicate space. Our analysis not only provides a new perspective on the
mechanism of the pretrained models such as BERT for natural language
understanding but also suggests several important future improvement
directions."
Momentum Contrastive Pre-training for Question Answering,0.0166286,"Existing pre-training methods for extractive Question Answering (QA) generate
cloze-like queries different from natural questions in syntax structure, which
could overfit pre-trained models to simple keyword matching. In order to
address this problem, we propose a novel Momentum Contrastive pRe-training fOr
queStion anSwering (MCROSS) method for extractive QA. Specifically, MCROSS
introduces a momentum contrastive learning framework to align the answer
probability between cloze-like and natural query-passage sample pairs. Hence,
the pre-trained models can better transfer the knowledge learned in cloze-like
samples to answering natural questions. Experimental results on three
benchmarking QA datasets show that our method achieves noticeable improvement
compared with all baselines in both supervised and zero-shot scenarios."
OSLAT: Open Set Label Attention Transformer for Medical Entity Retrieval and Span Extraction,0.0224171,"Medical entity span extraction and linking are critical steps for many
healthcare NLP tasks. Most existing entity extraction methods either have a
fixed vocabulary of medical entities or require span annotations. In this
paper, we propose a method for linking an open set of entities that does not
require any span annotations. Our method, Open Set Label Attention Transformer
(OSLAT), uses the label-attention mechanism to learn candidate-entity
contextualized text representations. We find that OSLAT can not only link
entities but is also able to implicitly learn spans associated with entities.
We evaluate OSLAT on two tasks: (1) span extraction trained without explicit
span annotations, and (2) entity linking trained without span-level annotation.
We test the generalizability of our method by training two separate models on
two datasets with low entity overlap and comparing cross-dataset performance."
Towards Proper Contrastive Self-supervised Learning Strategies For Music Audio Representation,0.00872201,"The common research goal of self-supervised learning is to extract a general
representation which an arbitrary downstream task would benefit from. In this
work, we investigate music audio representation learned from different
contrastive self-supervised learning schemes and empirically evaluate the
embedded vectors on various music information retrieval (MIR) tasks where
different levels of the music perception are concerned. We analyze the results
to discuss the proper direction of contrastive learning strategies for
different MIR tasks. We show that these representations convey a comprehensive
information about the auditory characteristics of music in general, although
each of the self-supervision strategies has its own effectiveness in certain
aspect of information."
Regional Negative Bias in Word Embeddings Predicts Racial Animus--but only via Name Frequency,0.0103205,"The word embedding association test (WEAT) is an important method for
measuring linguistic biases against social groups such as ethnic minorities in
large text corpora. It does so by comparing the semantic relatedness of words
prototypical of the groups (e.g., names unique to those groups) and attribute
words (e.g., 'pleasant' and 'unpleasant' words). We show that anti-black WEAT
estimates from geo-tagged social media data at the level of metropolitan
statistical areas strongly correlate with several measures of racial
animus--even when controlling for sociodemographic covariates. However, we also
show that every one of these correlations is explained by a third variable: the
frequency of Black names in the underlying corpora relative to White names.
This occurs because word embeddings tend to group positive (negative) words and
frequent (rare) words together in the estimated semantic space. As the
frequency of Black names on social media is strongly correlated with Black
Americans' prevalence in the population, this results in spurious anti-Black
WEAT estimates wherever few Black Americans live. This suggests that research
using the WEAT to measure bias should consider term frequency, and also
demonstrates the potential consequences of using black-box models like word
embeddings to study human cognition and behavior."
Needs and Artificial Intelligence,0.0,"Throughout their history, homo sapiens have used technologies to better
satisfy their needs. The relation between needs and technology is so
fundamental that the US National Research Council defined the distinguishing
characteristic of technology as its goal ""to make modifications in the world to
meet human needs"". Artificial intelligence (AI) is one of the most promising
emerging technologies of our time. Similar to other technologies, AI is
expected ""to meet [human] needs"". In this article, we reflect on the
relationship between needs and AI, and call for the realisation of needs-aware
AI systems. We argue that re-thinking needs for, through, and by AI can be a
very useful means towards the development of realistic approaches for
Sustainable, Human-centric, Accountable, Lawful, and Ethical (HALE) AI systems.
We discuss some of the most critical gaps, barriers, enablers, and drivers of
co-creating future AI-based socio-technical systems in which [human] needs are
well considered and met. Finally, we provide an overview of potential threats
and HALE considerations that should be carefully taken into account, and call
for joint, immediate, and interdisciplinary efforts and collaborations."
Region-aware Attention for Image Inpainting,0.00770887,"Recent attention-based image inpainting methods have made inspiring progress
by modeling long-range dependencies within a single image. However, they tend
to generate blurry contents since the correlation between each pixel pairs is
always misled by ill-predicted features in holes. To handle this problem, we
propose a novel region-aware attention (RA) module. By avoiding the directly
calculating corralation between each pixel pair in a single samples and
considering the correlation between different samples, the misleading of
invalid information in holes can be avoided. Meanwhile, a learnable region
dictionary (LRD) is introduced to store important information in the entire
dataset, which not only simplifies correlation modeling, but also avoids
information redundancy. By applying RA in our architecture, our methodscan
generate semantically plausible results with realistic details. Extensive
experiments on CelebA, Places2 and Paris StreetView datasets validate the
superiority of our method compared with existing methods."
Efficient Graph-Friendly COCO Metric Computation for Train-Time Model Evaluation,0.0,"Evaluating the COCO mean average precision (MaP) and COCO recall metrics as
part of the static computation graph of modern deep learning frameworks poses a
unique set of challenges. These challenges include the need for maintaining a
dynamic-sized state to compute mean average precision, reliance on global
dataset-level statistics to compute the metrics, and managing differing numbers
of bounding boxes between images in a batch. As a consequence, it is common
practice for researchers and practitioners to evaluate COCO metrics as a post
training evaluation step. With a graph-friendly algorithm to compute COCO Mean
Average Precision and recall, these metrics could be evaluated at training
time, improving visibility into the evolution of the metrics through training
curve plots, and decreasing iteration time when prototyping new model versions.
  Our contributions include an accurate approximation algorithm for Mean
Average Precision, an open source implementation of both COCO mean average
precision and COCO recall, extensive numerical benchmarks to verify the
accuracy of our implementations, and an open-source training loop that include
train-time evaluation of mean average precision and recall."
Decomposing Counterfactual Explanations for Consequential Decision Making,0.0251091,"The goal of algorithmic recourse is to reverse unfavorable decisions (e.g.,
from loan denial to approval) under automated decision making by suggesting
actionable feature changes (e.g., reduce the number of credit cards). To
generate low-cost recourse the majority of methods work under the assumption
that the features are independently manipulable (IMF). To address the feature
dependency issue the recourse problem is usually studied through the causal
recourse paradigm. However, it is well known that strong assumptions, as
encoded in causal models and structural equations, hinder the applicability of
these methods in complex domains where causal dependency structures are
ambiguous. In this work, we develop \texttt{DEAR} (DisEntangling Algorithmic
Recourse), a novel and practical recourse framework that bridges the gap
between the IMF and the strong causal assumptions. \texttt{DEAR} generates
recourses by disentangling the latent representation of co-varying features
from a subset of promising recourse features to capture the main practical
recourse desiderata. Our experiments on real-world data corroborate our
theoretically motivated recourse model and highlight our framework's ability to
provide reliable, low-cost recourse in the presence of feature dependencies."
Revisiting Generative Commonsense Reasoning: A Pre-Ordering Approach,0.0359492,"Pre-trained models (PTMs) have lead to great improvements in natural language
generation (NLG). However, it is still unclear how much commonsense knowledge
they possess. With the goal of evaluating commonsense knowledge of NLG models,
recent work has proposed the problem of generative commonsense reasoning, e.g.,
to compose a logical sentence given a set of unordered concepts. Existing
approaches to this problem hypothesize that PTMs lack sufficient parametric
knowledge for this task, which can be overcome by introducing external
knowledge or task-specific pre-training objectives. Different from this trend,
we argue that PTM's inherent ability for generative commonsense reasoning is
underestimated due to the order-agnostic property of its input. In particular,
we hypothesize that the order of the input concepts can affect the PTM's
ability to utilize its commonsense knowledge. To this end, we propose a
pre-ordering approach to elaborately manipulate the order of the given concepts
before generation. Experiments show that our approach can outperform the more
sophisticated models that have access to a lot of external data and resources."
Towards Soft Fairness in Restless Multi-Armed Bandits,0.0417937,"Restless multi-armed bandits (RMAB) is a framework for allocating limited
resources under uncertainty. It is an extremely useful model for monitoring
beneficiaries and executing timely interventions to ensure maximum benefit in
public health settings (e.g., ensuring patients take medicines in tuberculosis
settings, ensuring pregnant mothers listen to automated calls about good
pregnancy practices). Due to the limited resources, typically certain
communities or regions are starved of interventions that can have follow-on
effects. To avoid starvation in the executed interventions across
individuals/regions/communities, we first provide a soft fairness constraint
and then provide an approach to enforce the soft fairness constraint in RMABs.
The soft fairness constraint requires that an algorithm never probabilistically
favor one arm over another if the long-term cumulative reward of choosing the
latter arm is higher. Our approach incorporates softmax based value iteration
method in the RMAB setting to design selection algorithms that manage to
satisfy the proposed fairness constraint. Our method, referred to as SoftFair,
also provides theoretical performance guarantees and is asymptotically optimal.
Finally, we demonstrate the utility of our approaches on simulated benchmarks
and show that the soft fairness constraint can be handled without a significant
sacrifice on value."
Language-Based Audio Retrieval with Converging Tied Layers and Contrastive Loss,0.0274361,"In this paper, we tackle the new Language-Based Audio Retrieval task proposed
in DCASE 2022. Firstly, we introduce a simple, scalable architecture which ties
both the audio and text encoder together. Secondly, we show that using this
architecture along with contrastive loss allows the model to significantly beat
the performance of the baseline model. Finally, in addition to having an
extremely low training memory requirement, we are able to use pretrained models
as it is without needing to finetune them. We test our methods and show that
using a combination of our methods beats the baseline scores significantly."
DEXTER: An end-to-end system to extract table contents from electronic medical health documents,0.0364185,"In this paper, we propose DEXTER, an end to end system to extract information
from tables present in medical health documents, such as electronic health
records (EHR) and explanation of benefits (EOB). DEXTER consists of four
sub-system stages: i) table detection ii) table type classification iii) cell
detection; and iv) cell content extraction. We propose a two-stage transfer
learning-based approach using CDeC-Net architecture along with Non-Maximal
suppression for table detection. We design a conventional computer vision-based
approach for table type classification and cell detection using parameterized
kernels based on image size for detecting rows and columns. Finally, we extract
the text from the detected cells using pre-existing OCR engine Tessaract. To
evaluate our system, we manually annotated a sample of the real-world medical
dataset (referred to as Meddata) consisting of wide variations of documents (in
terms of appearance) covering different table structures, such as bordered,
partially bordered, borderless, or coloured tables. We experimentally show that
DEXTER outperforms the commercially available Amazon Textract and Microsoft
Azure Form Recognizer systems on the annotated real-world medical dataset"
Super-Resolution and Image Re-projection for Iris Recognition,0.0215979,"Several recent works have addressed the ability of deep learning to disclose
rich, hierarchical and discriminative models for the most diverse purposes.
Specifically in the super-resolution field, Convolutional Neural Networks
(CNNs) using different deep learning approaches attempt to recover realistic
texture and fine grained details from low resolution images. In this work we
explore the viability of these approaches for iris Super-Resolution (SR) in an
iris recognition environment. For this, we test different architectures with
and without a so called image re-projection to reduce artifacts applying it to
different iris databases to verify the viability of the different CNNs for iris
super-resolution. Results show that CNNs and image re-projection can improve
the results specially for the accuracy of recognition systems using a complete
different training database performing the transfer learning successfully."
Exploiting Feature Diversity for Make-up Temporal Video Grounding,0.0186548,"This technical report presents the 3rd winning solution for MTVG, a new task
introduced in the 4-th Person in Context (PIC) Challenge at ACM MM 2022. MTVG
aims at localizing the temporal boundary of the step in an untrimmed video
based on a textual description. The biggest challenge of this task is the fi
ne-grained video-text semantics of make-up steps. However, current methods
mainly extract video features using action-based pre-trained models. As actions
are more coarse-grained than make-up steps, action-based features are not
sufficient to provide fi ne-grained cues. To address this issue,we propose to
achieve fi ne-grained representation via exploiting feature diversities.
Specifically, we proposed a series of methods from feature extraction, network
optimization, to model ensemble. As a result, we achieved 3rd place in the MTVG
competition."
Beyond Value: CHECKLIST for Testing Inferences in Planning-Based RL,0.0,"Reinforcement learning (RL) agents are commonly evaluated via their expected
value over a distribution of test scenarios. Unfortunately, this evaluation
approach provides limited evidence for post-deployment generalization beyond
the test distribution. In this paper, we address this limitation by extending
the recent CheckList testing methodology from natural language processing to
planning-based RL. Specifically, we consider testing RL agents that make
decisions via online tree search using a learned transition model and value
function. The key idea is to improve the assessment of future performance via a
CheckList approach for exploring and assessing the agent's inferences during
tree search. The approach provides the user with an interface and general
query-rule mechanism for identifying potential inference flaws and validating
expected inference invariances. We present a user study involving knowledgeable
AI researchers using the approach to evaluate an agent trained to play a
complex real-time strategy game. The results show the approach is effective in
allowing users to identify previously-unknown flaws in the agent's reasoning.
In addition, our analysis provides insight into how AI experts use this type of
testing approach, which may help improve future instantiations."
Class Interference of Deep Neural Networks,0.00960967,"Recognizing and telling similar objects apart is even hard for human beings.
In this paper, we show that there is a phenomenon of class interference with
all deep neural networks. Class interference represents the learning difficulty
in data, and it constitutes the largest percentage of generalization errors by
deep networks. To understand class interference, we propose cross-class tests,
class ego directions and interference models. We show how to use these
definitions to study minima flatness and class interference of a trained model.
We also show how to detect class interference during training through label
dancing pattern and class dancing notes."
ConceptNet infused DialoGPT for Underlying Commonsense Understanding and Reasoning in Dialogue Response Generation,0.0158676,"The pre-trained conversational models still fail to capture the implicit
commonsense (CS) knowledge hidden in the dialogue interaction, even though they
were pre-trained with an enormous dataset. In order to build a dialogue agent
with CS capability, we firstly inject external knowledge into a pre-trained
conversational model to establish basic commonsense through efficient Adapter
tuning (Section 4). Secondly, we propose the ``two-way learning'' method to
enable the bidirectional relationship between CS knowledge and sentence pairs
so that the model can generate a sentence given the CS triplets, also generate
the underlying CS knowledge given a sentence (Section 5). Finally, we leverage
this integrated CS capability to improve open-domain dialogue response
generation so that the dialogue agent is capable of understanding the CS
knowledge hidden in dialogue history on top of inferring related other
knowledge to further guide response generation (Section 6). The experiment
results demonstrate that CS\_Adapter fusion helps DialoGPT to be able to
generate series of CS knowledge. And the DialoGPT+CS\_Adapter response model
adapted from CommonGen training can generate underlying CS triplets that fits
better to dialogue context."
Assembly Planning from Observations under Physical Constraints,0.031224,"This paper addresses the problem of copying an unknown assembly of primitives
with known shape and appearance using information extracted from a single
photograph by an off-the-shelf procedure for object detection and pose
estimation. The proposed algorithm uses a simple combination of physical
stability constraints, convex optimization and Monte Carlo tree search to plan
assemblies as sequences of pick-and-place operations represented by STRIPS
operators. It is efficient and, most importantly, robust to the errors in
object detection and pose estimation unavoidable in any real robotic system.
The proposed approach is demonstrated with thorough experiments on a UR5
manipulator."
DeepVoxNet2: Yet another CNN framework,-1.0,"We know that both the CNN mapping function and the sampling scheme are of
paramount importance for CNN-based image analysis. It is clear that both
functions operate in the same space, with an image axis $\mathcal{I}$ and a
feature axis $\mathcal{F}$. Remarkably, we found that no frameworks existed
that unified the two and kept track of the spatial origin of the data
automatically. Based on our own practical experience, we found the latter to
often result in complex coding and pipelines that are difficult to exchange.
This article introduces our framework for 1, 2 or 3D image classification or
segmentation: DeepVoxNet2 (DVN2). This article serves as an interactive
tutorial, and a pre-compiled version, including the outputs of the code blocks,
can be found online in the public DVN2 repository. This tutorial uses data from
the multimodal Brain Tumor Image Segmentation Benchmark (BRATS) of 2018 to show
an example of a 3D segmentation pipeline."
Machine Learning Challenges of Biological Factors in Insect Image Data,0.00373415,"The BIOSCAN project, led by the International Barcode of Life Consortium,
seeks to study changes in biodiversity on a global scale. One component of the
project is focused on studying the species interaction and dynamics of all
insects. In addition to genetically barcoding insects, over 1.5 million images
per year will be collected, each needing taxonomic classification. With the
immense volume of incoming images, relying solely on expert taxonomists to
label the images would be impossible; however, artificial intelligence and
computer vision technology may offer a viable high-throughput solution.
Additional tasks including manually weighing individual insects to determine
biomass, remain tedious and costly. Here again, computer vision may offer an
efficient and compelling alternative. While the use of computer vision methods
is appealing for addressing these problems, significant challenges resulting
from biological factors present themselves. These challenges are formulated in
the context of machine learning in this paper."
MACC: Cross-Layer Multi-Agent Congestion Control with Deep Reinforcement Learning,0.00480452,"Congestion Control (CC), as the core networking task to efficiently utilize
network capacity, received great attention and widely used in various Internet
communication applications such as 5G, Internet-of-Things, UAN, and more.
Various CC algorithms have been proposed both on network and transport layers
such as Active Queue Management (AQM) algorithm and Transmission Control
Protocol (TCP) congestion control mechanism. But it is hard to model dynamic
AQM/TCP system and cooperate two algorithms to obtain excellent performance
under different communication scenarios. In this paper, we explore the
performance of multi-agent reinforcement learning-based cross-layer congestion
control algorithms and present cooperation performance of two agents, known as
MACC (Multi-agent Congestion Control). We implement MACC in NS3. The simulation
results show that our scheme outperforms other congestion control combination
in terms of throughput and delay, etc. Not only does it proves that networking
protocols based on multi-agent deep reinforcement learning is efficient for
communication managing, but also verifies that networking area can be used as
new playground for machine learning algorithms."
Attention Mechanism with Energy-Friendly Operations,0.0361375,"Attention mechanism has become the dominant module in natural language
processing models. It is computationally intensive and depends on massive
power-hungry multiplications. In this paper, we rethink variants of attention
mechanism from the energy consumption aspects. After reaching the conclusion
that the energy costs of several energy-friendly operations are far less than
their multiplication counterparts, we build a novel attention model by
replacing multiplications with either selective operations or additions.
Empirical results on three machine translation tasks demonstrate that the
proposed model, against the vanilla one, achieves competitable accuracy while
saving 99\% and 66\% energy during alignment calculation and the whole
attention procedure. Code is available at: https://github.com/NLP2CT/E-Att."
Self-distilled Knowledge Delegator for Exemplar-free Class Incremental Learning,0.0461469,"Exemplar-free incremental learning is extremely challenging due to
inaccessibility of data from old tasks. In this paper, we attempt to exploit
the knowledge encoded in a previously trained classification model to handle
the catastrophic forgetting problem in continual learning. Specifically, we
introduce a so-called knowledge delegator, which is capable of transferring
knowledge from the trained model to a randomly re-initialized new model by
generating informative samples. Given the previous model only, the delegator is
effectively learned using a self-distillation mechanism in a data-free manner.
The knowledge extracted by the delegator is then utilized to maintain the
performance of the model on old tasks in incremental learning. This simple
incremental learning framework surpasses existing exemplar-free methods by a
large margin on four widely used class incremental benchmarks, namely
CIFAR-100, ImageNet-Subset, Caltech-101 and Flowers-102. Notably, we achieve
comparable performance to some exemplar-based methods without accessing any
exemplars."
Mathematically Modeling the Lexicon Entropy of Emergent Language,0.0162712,"We formulate a stochastic process, FiLex, as a mathematical model of lexicon
entropy in deep learning-based emergent language systems. Defining a model
mathematically allows it to generate clear predictions which can be directly
and decisively tested. We empirically verify across four different environments
that FiLex predicts the correct correlation between hyperparameters (training
steps, lexicon size, learning rate, rollout buffer size, and Gumbel-Softmax
temperature) and the emergent language's entropy in 20 out of 20
environment-hyperparameter combinations. Furthermore, our experiments reveal
that different environments show diverse relationships between their
hyperparameters and entropy which demonstrates the need for a model which can
make well-defined predictions at a precise level of granularity."
Towards Using Promises for Multi-Agent Cooperation in Goal Reasoning,0.0210063,"Reasoning and planning for mobile robots is a challenging problem, as the
world evolves over time and thus the robot's goals may change. One technique to
tackle this problem is goal reasoning, where the agent not only reasons about
its actions, but also about which goals to pursue. While goal reasoning for
single agents has been researched extensively, distributed, multi-agent goal
reasoning comes with additional challenges, especially in a distributed
setting. In such a context, some form of coordination is necessary to allow for
cooperative behavior. Previous goal reasoning approaches share the agent's
world model with the other agents, which already enables basic cooperation.
However, the agent's goals, and thus its intentions, are typically not shared.
  In this paper, we present a method to tackle this limitation. Extending an
existing goal reasoning framework, we propose enabling cooperative behavior
between multiple agents through promises, where an agent may promise that
certain facts will be true at some point in the future. Sharing these promises
allows other agents to not only consider the current state of the world, but
also the intentions of other agents when deciding on which goal to pursue next.
We describe how promises can be incorporated into the goal life cycle, a
commonly used goal refinement mechanism. We then show how promises can be used
when planning for a particular goal by connecting them to timed initial
literals (TILs) from PDDL planning. Finally, we evaluate our prototypical
implementation in a simplified logistics scenario."
Interpretable Distribution Shift Detection using Optimal Transport,0.00358784,"We propose a method to identify and characterize distribution shifts in
classification datasets based on optimal transport. It allows the user to
identify the extent to which each class is affected by the shift, and retrieves
corresponding pairs of samples to provide insights on its nature. We illustrate
its use on synthetic and natural shift examples. While the results we present
are preliminary, we hope that this inspires future work on interpretable
methods for analyzing distribution shifts."
Parameter-Efficient Tuning by Manipulating Hidden States of Pretrained Language Models For Classification Tasks,0.00341851,"Parameter-efficient tuning aims to distill knowledge for downstream tasks by
optimizing a few introduced parameters while freezing the pretrained language
models (PLMs). Continuous prompt tuning which prepends a few trainable vectors
to the embeddings of input is one of these methods and has drawn much attention
due to its effectiveness and efficiency. This family of methods can be
illustrated as exerting nonlinear transformations of hidden states inside PLMs.
However, a natural question is ignored: can the hidden states be directly used
for classification without changing them? In this paper, we aim to answer this
question by proposing a simple tuning method which only introduces three
trainable vectors. Firstly, we integrate all layers hidden states using the
introduced vectors. And then, we input the integrated hidden state(s) to a
task-specific linear classifier to predict categories. This scheme is similar
to the way ELMo utilises hidden states except that they feed the hidden states
to LSTM-based models. Although our proposed tuning scheme is simple, it
achieves comparable performance with prompt tuning methods like P-tuning and
P-tuning v2, verifying that original hidden states do contain useful
information for classification tasks. Moreover, our method has an advantage
over prompt tuning in terms of time and the number of parameters."
Leveraging Deepfakes to Close the Domain Gap between Real and Synthetic Images in Facial Capture Pipelines,0.0181622,"We propose an end-to-end pipeline for both building and tracking 3D facial
models from personalized in-the-wild (cellphone, webcam, youtube clips, etc.)
video data. First, we present a method for automatic data curation and
retrieval based on a hierarchical clustering framework typical of collision
detection algorithms in traditional computer graphics pipelines. Subsequently,
we utilize synthetic turntables and leverage deepfake technology in order to
build a synthetic multi-view stereo pipeline for appearance capture that is
robust to imperfect synthetic geometry and image misalignment. The resulting
model is fit with an animation rig, which is then used to track facial
performances. Notably, our novel use of deepfake technology enables us to
perform robust tracking of in-the-wild data using differentiable renderers
despite a significant synthetic-to-real domain gap. Finally, we outline how we
train a motion capture regressor, leveraging the aforementioned techniques to
avoid the need for real-world ground truth data and/or a high-end calibrated
camera capture setup."
StyLandGAN: A StyleGAN based Landscape Image Synthesis using Depth-map,0.0146625,"Despite recent success in conditional image synthesis, prevalent input
conditions such as semantics and edges are not clear enough to express `Linear
(Ridges)' and `Planar (Scale)' representations. To address this problem, we
propose a novel framework StyLandGAN, which synthesizes desired landscape
images using a depth map which has higher expressive power. Our StyleLandGAN is
extended from the unconditional generation model to accept input conditions. We
also propose a '2-phase inference' pipeline which generates diverse depth maps
and shifts local parts so that it can easily reflect user's intend. As a
comparison, we modified the existing semantic image synthesis models to accept
a depth map as well. Experimental results show that our method is superior to
existing methods in quality, diversity, and depth-accuracy."
Policy Gradient Algorithms with Monte-Carlo Tree Search for Non-Markov Decision Processes,0.0186003,"Policy gradient (PG) is a reinforcement learning (RL) approach that optimizes
a parameterized policy model for an expected return using gradient ascent.
Given a well-parameterized policy model, such as a neural network model, with
appropriate initial parameters, the PG algorithms work well even when
environment does not have the Markov property. Otherwise, they can be trapped
on a plateau or suffer from peakiness effects. As another successful RL
approach, algorithms based on Monte-Carlo Tree Search (MCTS), which include
AlphaZero, have obtained groundbreaking results especially on the board game
playing domain. They are also suitable to be applied to non-Markov decision
processes. However, since the standard MCTS does not have the ability to learn
state representation, the size of the tree-search space can be too large to
search. In this work, we examine a mixture policy of PG and MCTS to complement
each other's difficulties and take advantage of them. We derive conditions for
asymptotic convergence with results of a two-timescale stochastic approximation
and propose an algorithm that satisfies these conditions. The effectivity of
the proposed methods is verified through numerical experiments on non-Markov
decision processes."
Multi-fidelity Gaussian Process for Biomanufacturing Process Modeling with Small Data,0.0323653,"In biomanufacturing, developing an accurate model to simulate the complex
dynamics of bioprocesses is an important yet challenging task. This is
partially due to the uncertainty associated with bioprocesses, high data
acquisition cost, and lack of data availability to learn complex relations in
bioprocesses. To deal with these challenges, we propose to use a statistical
machine learning approach, multi-fidelity Gaussian process, for process
modelling in biomanufacturing. Gaussian process regression is a
well-established technique based on probability theory which can naturally
consider uncertainty in a dataset via Gaussian noise, and multi-fidelity
techniques can make use of multiple sources of information with different
levels of fidelity, thus suitable for bioprocess modeling with small data. We
apply the multi-fidelity Gaussian process to solve two significant problems in
biomanufacturing, bioreactor scale-up and knowledge transfer across cell lines,
and demonstrate its efficacy on real-world datasets."
Explainability as statistical inference,0.00298812,"A wide variety of model explanation approaches have been proposed in recent
years, all guided by very different rationales and heuristics. In this paper,
we take a new route and cast interpretability as a statistical inference
problem. We propose a general deep probabilistic model designed to produce
interpretable predictions. The model parameters can be learned via maximum
likelihood, and the method can be adapted to any predictor network architecture
and any type of prediction problem. Our method is a case of amortized
interpretability models, where a neural network is used as a selector to allow
for fast interpretation at inference time. Several popular interpretability
methods are shown to be particular cases of regularised maximum likelihood for
our general model. We propose new datasets with ground truth selection which
allow for the evaluation of the features importance map. Using these datasets,
we show experimentally that using multiple imputation provides more reasonable
interpretations."
A Hierarchical Deep Neural Network for Detecting Lines of Codes with Vulnerabilities,0.00734378,"Software vulnerabilities, caused by unintentional flaws in source codes, are
the main root cause of cyberattacks. Source code static analysis has been used
extensively to detect the unintentional defects, i.e. vulnerabilities,
introduced into the source codes by software developers. In this paper, we
propose a deep learning approach to detect vulnerabilities from their LLVM IR
representations based on the techniques that have been used in natural language
processing. The proposed approach uses a hierarchical process to first identify
source codes with vulnerabilities, and then it identifies the lines of codes
that contribute to the vulnerability within the detected source codes. This
proposed two-step approach reduces the false alarm of detecting vulnerable
lines. Our extensive experiment on real-world and synthetic codes collected in
NVD and SARD shows high accuracy (about 98\%) in detecting source code
vulnerabilities."
Solving Disjunctive Temporal Networks with Uncertainty under Restricted Time-Based Controllability using Tree Search and Graph Neural Networks,0.0192598,"Planning under uncertainty is an area of interest in artificial intelligence.
We present a novel approach based on tree search and graph machine learning for
the scheduling problem known as Disjunctive Temporal Networks with Uncertainty
(DTNU). Dynamic Controllability (DC) of DTNUs seeks a reactive scheduling
strategy to satisfy temporal constraints in response to uncontrollable action
durations. We introduce new semantics for reactive scheduling: Time-based
Dynamic Controllability (TDC) and a restricted subset of TDC, R-TDC. We design
a tree search algorithm to determine whether or not a DTNU is R-TDC. Moreover,
we leverage a graph neural network as a heuristic for tree search guidance.
Finally, we conduct experiments on a known benchmark on which we show R-TDC to
retain significant completeness with regard to DC, while being faster to prove.
This results in the tree search processing fifty percent more DTNU problems in
R-TDC than the state-of-the-art DC solver does in DC with the same time budget.
We also observe that graph neural network search guidance leads to substantial
performance gains on benchmarks of more complex DTNUs, with up to eleven times
more problems solved than the baseline tree search."
Transformers in Action: Weakly Supervised Action Segmentation,0.0503694,"The video action segmentation task is regularly explored under weaker forms
of supervision, such as transcript supervision, where a list of actions is
easier to obtain than dense frame-wise labels. In this formulation, the task
presents various challenges for sequence modeling approaches due to the
emphasis on action transition points, long sequence lengths, and frame
contextualization, making the task well-posed for transformers. Given
developments enabling transformers to scale linearly, we demonstrate through
our architecture how they can be applied to improve action alignment accuracy
over the equivalent RNN-based models with the attention mechanism focusing
around salient action transition regions. Additionally, given the recent focus
on inference-time transcript selection, we propose a supplemental transcript
embedding approach to select transcripts more quickly at inference-time.
Furthermore, we subsequently demonstrate how this approach can also improve the
overall segmentation performance. Finally, we evaluate our proposed methods
across the benchmark datasets to better understand the applicability of
transformers and the importance of transcript selection on this video-driven
weakly-supervised task."
From Pedestrian Detection to Crosswalk Estimation: An EM Algorithm and Analysis on Diverse Datasets,0.00413915,"In this work, we contribute an EM algorithm for estimation of corner points
and linear crossing segments for both marked and unmarked pedestrian crosswalks
using the detections of pedestrians from processed LiDAR point clouds or camera
images. We demonstrate the algorithmic performance by analyzing three
real-world datasets containing multiple periods of data collection for
four-corner and two-corner intersections with marked and unmarked crosswalks.
Additionally, we include a Python video tool to visualize the crossing
parameter estimation, pedestrian trajectories, and phase intervals in our
public source code."
Classification of Misinformation in New Articles using Natural Language Processing and a Recurrent Neural Network,0.0262376,"This paper seeks to address the classification of misinformation in news
articles using a Long Short Term Memory Recurrent Neural Network. Articles were
taken from 2018; a year that was filled with reporters writing about President
Donald Trump, Special Counsel Robert Mueller, the Fifa World Cup, and Russia.
The model presented successfully classifies these articles with an accuracy
score of 0.779944. We consider this to be successful because the model was
trained on articles that included languages other than English as well as
incomplete, or fragmented, articles."
U-Attention to Textures: Hierarchical Hourglass Vision Transformer for Universal Texture Synthesis,0.0380449,"We present a novel U-Attention vision Transformer for universal texture
synthesis. We exploit the natural long-range dependencies enabled by the
attention mechanism to allow our approach to synthesize diverse textures while
preserving their structures in a single inference. We propose a hierarchical
hourglass backbone that attends to the global structure and performs patch
mapping at varying scales in a coarse-to-fine-to-coarse stream. Completed by
skip connection and convolution designs that propagate and fuse information at
different scales, our hierarchical U-Attention architecture unifies attention
to features from macro structures to micro details, and progressively refines
synthesis results at successive stages. Our method achieves stronger 2$\times$
synthesis than previous work on both stochastic and structured textures while
generalizing to unseen textures without fine-tuning. Ablation studies
demonstrate the effectiveness of each component of our architecture."
Pre-Avatar: An Automatic Presentation Generation Framework Leveraging Talking Avatar,0.164914,"Since the beginning of the COVID-19 pandemic, remote conferencing and
school-teaching have become important tools. The previous applications aim to
save the commuting cost with real-time interactions. However, our application
is going to lower the production and reproduction costs when preparing the
communication materials. This paper proposes a system called Pre-Avatar,
generating a presentation video with a talking face of a target speaker with 1
front-face photo and a 3-minute voice recording. Technically, the system
consists of three main modules, user experience interface (UEI), talking face
module and few-shot text-to-speech (TTS) module. The system firstly clones the
target speaker's voice, and then generates the speech, and finally generate an
avatar with appropriate lip and head movements. Under any scenario, users only
need to replace slides with different notes to generate another new video. The
demo has been released here and will be published as free software for use."
Data-Free Quantization with Accurate Activation Clipping and Adaptive Batch Normalization,0.0,"Data-free quantization is a task that compresses the neural network to low
bit-width without access to original training data. Most existing data-free
quantization methods cause severe performance degradation due to inaccurate
activation clipping range and quantization error, especially for low bit-width.
In this paper, we present a simple yet effective data-free quantization method
with accurate activation clipping and adaptive batch normalization. Accurate
activation clipping (AAC) improves the model accuracy by exploiting accurate
activation information from the full-precision model. Adaptive batch
normalization firstly proposes to address the quantization error from
distribution changes by updating the batch normalization layer adaptively.
Extensive experiments demonstrate that the proposed data-free quantization
method can yield surprisingly performance, achieving 64.33% top-1 accuracy of
ResNet18 on ImageNet dataset, with 3.7% absolute improvement outperforming the
existing state-of-the-art methods."
Facilitating Global Team Meetings Between Language-Based Subgroups: When and How Can Machine Translation Help?,0.00173796,"Global teams frequently consist of language-based subgroups who put together
complementary information to achieve common goals. Previous research outlines a
two-step work communication flow in these teams. There are team meetings using
a required common language (i.e., English); in preparation for those meetings,
people have subgroup conversations in their native languages. Work
communication at team meetings is often less effective than in subgroup
conversations. In the current study, we investigate the idea of leveraging
machine translation (MT) to facilitate global team meetings. We hypothesize
that exchanging subgroup conversation logs before a team meeting offers
contextual information that benefits teamwork at the meeting. MT can translate
these logs, which enables comprehension at a low cost. To test our hypothesis,
we conducted a between-subjects experiment where twenty quartets of
participants performed a personnel selection task. Each quartet included two
English native speakers (NS) and two non-native speakers (NNS) whose native
language was Mandarin. All participants began the task with subgroup
conversations in their native languages, then proceeded to team meetings in
English. We manipulated the exchange of subgroup conversation logs prior to
team meetings: with MT-mediated exchanges versus without. Analysis of
participants' subjective experience, task performance, and depth of discussions
as reflected through their conversational moves jointly indicates that team
meeting quality improved when there were MT-mediated exchanges of subgroup
conversation logs as opposed to no exchanges. We conclude with reflections on
when and how MT could be applied to enhance global teamwork across a language
barrier."
A Comprehensive Gold Standard and Benchmark for Comics Text Detection and Recognition,0.0122093,"This study focuses on improving the optical character recognition (OCR) data
for panels in the COMICS dataset, the largest dataset containing text and
images from comic books. To do this, we developed a pipeline for OCR processing
and labeling of comic books and created the first text detection and
recognition datasets for western comics, called ""COMICS Text+: Detection"" and
""COMICS Text+: Recognition"". We evaluated the performance of state-of-the-art
text detection and recognition models on these datasets and found significant
improvement in word accuracy and normalized edit distance compared to the text
in COMICS. We also created a new dataset called ""COMICS Text+"", which contains
the extracted text from the textboxes in the COMICS dataset. Using the improved
text data of COMICS Text+ in the comics processing model from resulted in
state-of-the-art performance on cloze-style tasks without changing the model
architecture. The COMICS Text+ dataset can be a valuable resource for
researchers working on tasks including text detection, recognition, and
high-level processing of comics, such as narrative understanding, character
relations, and story generation. All the data and inference instructions can be
accessed in https://github.com/gsoykan/comics_text_plus."
CS-Insights: A System for Analyzing Computer Science Research,0.0491988,"This paper presents CS-Insights, an interactive web application to analyze
computer science publications from DBLP through multiple perspectives. The
dedicated interfaces allow its users to identify trends in research activity,
productivity, accessibility, author's productivity, venues' statistics, topics
of interest, and the impact of computer science research on other fields.
CS-Insightsis publicly available, and its modular architecture can be easily
adapted to domains other than computer science."
A Multimodal Approach for Dementia Detection from Spontaneous Speech with Tensor Fusion Layer,0.0603767,"Alzheimer's disease (AD) is a progressive neurological disorder, meaning that
the symptoms develop gradually throughout the years. It is also the main cause
of dementia, which affects memory, thinking skills, and mental abilities.
Nowadays, researchers have moved their interest towards AD detection from
spontaneous speech, since it constitutes a time-effective procedure. However,
existing state-of-the-art works proposing multimodal approaches do not take
into consideration the inter- and intra-modal interactions and propose early
and late fusion approaches. To tackle these limitations, we propose deep neural
networks, which can be trained in an end-to-end trainable way and capture the
inter- and intra-modal interactions. Firstly, each audio file is converted to
an image consisting of three channels, i.e., log-Mel spectrogram, delta, and
delta-delta. Next, each transcript is passed through a BERT model followed by a
gated self-attention layer. Similarly, each image is passed through a Swin
Transformer followed by an independent gated self-attention layer. Acoustic
features are extracted also from each audio file. Finally, the representation
vectors from the different modalities are fed to a tensor fusion layer for
capturing the inter-modal interactions. Extensive experiments conducted on the
ADReSS Challenge dataset indicate that our introduced approaches obtain
valuable advantages over existing research initiatives reaching Accuracy and
F1-score up to 86.25% and 85.48% respectively."
Identifying epidemic related Tweets using noisy learning,0.00172357,"Supervised learning algorithms are heavily reliant on annotated datasets to
train machine learning models. However, the curation of the annotated datasets
is laborious and time consuming due to the manual effort involved and has
become a huge bottleneck in supervised learning. In this work, we apply the
theory of noisy learning to generate weak supervision signals instead of manual
annotation. We curate a noisy labeled dataset using a labeling heuristic to
identify epidemic related tweets. We evaluated the performance using a large
epidemic corpus and our results demonstrate that models trained with noisy data
in a class imbalanced and multi-classification weak supervision setting
achieved performance greater than 90%."
Diversity Over Size: On the Effect of Sample and Topic Sizes for Argument Mining Datasets,0.0163633,"The task of Argument Mining, that is extracting argumentative sentences for a
specific topic from large document sources, is an inherently difficult task for
machine learning models and humans alike, as large Argument Mining datasets are
rare and recognition of argumentative sentences requires expert knowledge. The
task becomes even more difficult if it also involves stance detection of
retrieved arguments. Given the cost and complexity of creating suitably large
Argument Mining datasets, we ask whether it is necessary for acceptable
performance to have datasets growing in size. Our findings show that, when
using carefully composed training samples and a model pretrained on related
tasks, we can reach 95% of the maximum performance while reducing the training
sample size by at least 85%. This gain is consistent across three Argument
Mining tasks on three different datasets. We also publish a new dataset for
future benchmarking."
Introspective Deep Metric Learning for Image Retrieval,0.0101796,"This paper proposes an introspective deep metric learning (IDML) framework
for uncertainty-aware comparisons of images. Conventional deep metric learning
methods produce confident semantic distances between images regardless of the
uncertainty level. However, we argue that a good similarity model should
consider the semantic discrepancies with caution to better deal with ambiguous
images for more robust training. To achieve this, we propose to represent an
image using not only a semantic embedding but also an accompanying uncertainty
embedding, which describes the semantic characteristics and ambiguity of an
image, respectively. We further propose an introspective similarity metric to
make similarity judgments between images considering both their semantic
differences and ambiguities. The proposed IDML framework improves the
performance of deep metric learning through uncertainty modeling and attains
state-of-the-art results on the widely used CUB-200-2011, Cars196, and Stanford
Online Products datasets for image retrieval and clustering. We further provide
an in-depth analysis of our framework to demonstrate the effectiveness and
reliability of IDML. Code is available at: https://github.com/wzzheng/IDML."
CoDo: Contrastive Learning with Downstream Background Invariance for Detection,0.00437056,"The prior self-supervised learning researches mainly select image-level
instance discrimination as pretext task. It achieves a fantastic classification
performance that is comparable to supervised learning methods. However, with
degraded transfer performance on downstream tasks such as object detection. To
bridge the performance gap, we propose a novel object-level self-supervised
learning method, called Contrastive learning with Downstream background
invariance (CoDo). The pretext task is converted to focus on instance location
modeling for various backgrounds, especially for downstream datasets. The
ability of background invariance is considered vital for object detection.
Firstly, a data augmentation strategy is proposed to paste the instances onto
background images, and then jitter the bounding box to involve background
information. Secondly, we implement architecture alignment between our
pretraining network and the mainstream detection pipelines. Thirdly,
hierarchical and multi views contrastive learning is designed to improve
performance of visual representation learning. Experiments on MSCOCO
demonstrate that the proposed CoDo with common backbones, ResNet50-FPN, yields
strong transfer learning results for object detection."
Quantifying Robustness to Adversarial Word Substitutions,0.00425598,"Deep-learning-based NLP models are found to be vulnerable to word
substitution perturbations. Before they are widely adopted, the fundamental
issues of robustness need to be addressed. Along this line, we propose a formal
framework to evaluate word-level robustness. First, to study safe regions for a
model, we introduce robustness radius which is the boundary where the model can
resist any perturbation. As calculating the maximum robustness radius is
computationally hard, we estimate its upper and lower bound. We repurpose
attack methods as ways of seeking upper bound and design a pseudo-dynamic
programming algorithm for a tighter upper bound. Then verification method is
utilized for a lower bound. Further, for evaluating the robustness of regions
outside a safe radius, we reexamine robustness from another view:
quantification. A robustness metric with a rigorous statistical guarantee is
introduced to measure the quantification of adversarial examples, which
indicates the model's susceptibility to perturbations outside the safe radius.
The metric helps us figure out why state-of-the-art models like BERT can be
easily fooled by a few word substitutions, but generalize well in the presence
of real-world noises."
"Paraphrasing, textual entailment, and semantic similarity above word level",0.0130521,"This dissertation explores the linguistic and computational aspects of the
meaning relations that can hold between two or more complex linguistic
expressions (phrases, clauses, sentences, paragraphs). In particular, it
focuses on Paraphrasing, Textual Entailment, Contradiction, and Semantic
Similarity.
  In Part I: ""Similarity at the Level of Words and Phrases"", I study the
Distributional Hypothesis (DH) and explore several different methodologies for
quantifying semantic similarity at the levels of words and short phrases.
  In Part II: ""Paraphrase Typology and Paraphrase Identification"", I focus on
the meaning relation of paraphrasing and the empirical task of automated
Paraphrase Identification (PI).
  In Part III: ""Paraphrasing, Textual Entailment, and Semantic Similarity"", I
present a novel direction in the research on textual meaning relations,
resulting from joint research carried out on on paraphrasing, textual
entailment, contradiction, and semantic similarity."
Unsupervised Opinion Summarisation in the Wasserstein Space,0.0336793,"Opinion summarisation synthesises opinions expressed in a group of documents
discussing the same topic to produce a single summary. Recent work has looked
at opinion summarisation of clusters of social media posts. Such posts are
noisy and have unpredictable structure, posing additional challenges for the
construction of the summary distribution and the preservation of meaning
compared to online reviews, which has been so far the focus of opinion
summarisation. To address these challenges we present \textit{WassOS}, an
unsupervised abstractive summarization model which makes use of the Wasserstein
distance. A Variational Autoencoder is used to get the distribution of
documents/posts, and the distributions are disentangled into separate semantic
and syntactic spaces. The summary distribution is obtained using the
Wasserstein barycenter of the semantic and syntactic distributions. A latent
variable sampled from the summary distribution is fed into a GRU decoder with a
transformer layer to produce the final summary. Our experiments on multiple
datasets including Twitter clusters, Reddit threads, and reviews show that
WassOS almost always outperforms the state-of-the-art on ROUGE metrics and
consistently produces the best summaries with respect to meaning preservation
according to human evaluations."
Addressing the Challenges of Cross-Lingual Hate Speech Detection,0.212605,"The goal of hate speech detection is to filter negative online content aiming
at certain groups of people. Due to the easy accessibility of social media
platforms it is crucial to protect everyone which requires building hate speech
detection systems for a wide range of languages. However, the available labeled
hate speech datasets are limited making it problematic to build systems for
many languages. In this paper we focus on cross-lingual transfer learning to
support hate speech detection in low-resource languages. We leverage
cross-lingual word embeddings to train our neural network systems on the source
language and apply it to the target language, which lacks labeled examples, and
show that good performance can be achieved. We then incorporate unlabeled
target language data for further model improvements by bootstrapping labels
using an ensemble of different model architectures. Furthermore, we investigate
the issue of label imbalance of hate speech datasets, since the high ratio of
non-hate examples compared to hate examples often leads to low model
performance. We test simple data undersampling and oversampling techniques and
show their effectiveness."
Medical Dataset Classification for Kurdish Short Text over Social Media,0.603448,"The Facebook application is used as a resource for collecting the comments of
this dataset, The dataset consists of 6756 comments to create a Medical Kurdish
Dataset (MKD). The samples are comments of users, which are gathered from
different posts of pages (Medical, News, Economy, Education, and Sport). Six
steps as a preprocessing technique are performed on the raw dataset to clean
and remove noise in the comments by replacing characters. The comments (short
text) are labeled for positive class (medical comment) and negative class
(non-medical comment) as text classification. The percentage ratio of the
negative class is 55% while the positive class is 45%."
What do Models Learn From Training on More Than Text? Measuring Visual Commonsense Knowledge,0.0438929,"There are limitations in learning language from text alone. Therefore, recent
focus has been on developing multimodal models. However, few benchmarks exist
that can measure what language models learn about language from multimodal
training. We hypothesize that training on a visual modality should improve on
the visual commonsense knowledge in language models. Therefore, we introduce
two evaluation tasks for measuring visual commonsense knowledge in language
models and use them to evaluate different multimodal models and unimodal
baselines. Primarily, we find that the visual commonsense knowledge is not
significantly different between the multimodal models and unimodal baseline
models trained on visual text data."
Position Paper: Online Modeling for Offline Planning,0.00456251,"The definition and representation of planning problems is at the heart of AI
planning research. A key part is the representation of action models. Decades
of advances improving declarative action model representations resulted in
numerous theoretical advances, and capable, working, domain-independent
planners. However, despite the maturity of the field, AI planning technology is
still rarely used outside the research community, suggesting that current
representations fail to capture real-world requirements, such as utilizing
complex mathematical functions and models learned from data. We argue that this
is because the modeling process is assumed to have taken place and completed
prior to the planning process, i.e., offline modeling for offline planning.
There are several challenges inherent to this approach, including: limited
expressiveness of declarative modeling languages; early commitment to modeling
choices and computation, that preclude using the most appropriate resolution
for each action model -- which can only be known during planning; and
difficulty in reliably using non-declarative, learned, models.
  We therefore suggest to change the AI planning process, such that is carries
out online modeling in offline planning, i.e., the use of action models that
are computed or even generated as part of the planning process, as they are
accessed. This generalizes the existing approach (offline modeling). The
proposed definition admits novel planning processes, and we suggest one
concrete implementation, demonstrating the approach. We sketch initial results
that were obtained as part of a first attempt to follow this approach by
planning with action cost estimators. We conclude by discussing open
challenges."
Bridging the Gap between Local Semantic Concepts and Bag of Visual Words for Natural Scene Image Retrieval,0.0220956,"This paper addresses the problem of semantic-based image retrieval of natural
scenes. A typical content-based image retrieval system deals with the query
image and images in the dataset as a collection of low-level features and
retrieves a ranked list of images based on the similarities between features of
the query image and features of images in the image dataset. However, top
ranked images in the retrieved list, which have high similarities to the query
image, may be different from the query image in terms of the semantic
interpretation of the user which is known as the semantic gap. In order to
reduce the semantic gap, this paper investigates how natural scene retrieval
can be performed using the bag of visual word model and the distribution of
local semantic concepts. The paper studies the efficiency of using different
approaches for representing the semantic information, depicted in natural scene
images, for image retrieval. An extensive experimental work has been conducted
to study the efficiency of using semantic information as well as the bag of
visual words model for natural and urban scene image retrieval."
Learning Reduced Nonlinear State-Space Models: an Output-Error Based Canonical Approach,0.0153557,"The identification of a nonlinear dynamic model is an open topic in control
theory, especially from sparse input-output measurements. A fundamental
challenge of this problem is that very few to zero prior knowledge is available
on both the state and the nonlinear system model. To cope with this challenge,
we investigate the effectiveness of deep learning in the modeling of dynamic
systems with nonlinear behavior by advocating an approach which relies on three
main ingredients: (i) we show that under some structural conditions on the
to-be-identified model, the state can be expressed in function of a sequence of
the past inputs and outputs; (ii) this relation which we call the state map can
be modelled by resorting to the well-documented approximation power of deep
neural networks; (iii) taking then advantage of existing learning schemes, a
state-space model can be finally identified. After the formulation and analysis
of the approach, we show its ability to identify three different nonlinear
systems. The performances are evaluated in terms of open-loop prediction on
test data generated in simulation as well as a real world data-set of unmanned
aerial vehicle flight measurements."
Unsupervised Explanation Generation via Correct Instantiations,0.0369707,"While large pre-trained language models (PLM) have shown their great skills
at solving discriminative tasks, a significant gap remains when compared with
humans for explanation-related tasks. Among them, explaining the reason why a
statement is wrong (e.g., against commonsense) is incredibly challenging. The
major difficulty is finding the conflict point, where the statement contradicts
our real world. This paper proposes Neon, a two-phrase, unsupervised
explanation generation framework. Neon first generates corrected instantiations
of the statement (phase I), then uses them to prompt large PLMs to find the
conflict point and complete the explanation (phase II). We conduct extensive
experiments on two standard explanation benchmarks, i.e., ComVE and e-SNLI.
According to both automatic and human evaluations, Neon outperforms baselines,
even for those with human-annotated instantiations. In addition to explaining a
negative prediction, we further demonstrate that Neon remains effective when
generalizing to different scenarios."
"Markov categories, causal theories, and the do-calculus",0.0355463,"We give a category-theoretic treatment of causal models that formalizes the
syntax for causal reasoning over a directed acyclic graph (DAG) by associating
a free Markov category with the DAG in a canonical way. This framework enables
us to define and study important concepts in causal reasoning from an abstract
and ""purely causal"" point of view, such as causal independence/separation,
causal conditionals, and decomposition of intervention effects. Our results
regarding these concepts abstract away from the details of the commonly adopted
causal models such as (recursive) structural equation models or causal Bayesian
networks. They are therefore more widely applicable and in a way conceptually
clearer. Our results are also intimately related to Judea Pearl's celebrated
do-calculus, and yield a syntactic version of a core part of the calculus that
is inherited in all causal models. In particular, it induces a simpler and
specialized version of Pearl's do-calculus in the context of causal Bayesian
networks, which we show is as strong as the full version."
Collaborative Image Understanding,0.0350558,"Automatically understanding the contents of an image is a highly relevant
problem in practice. In e-commerce and social media settings, for example, a
common problem is to automatically categorize user-provided pictures. Nowadays,
a standard approach is to fine-tune pre-trained image models with
application-specific data. Besides images, organizations however often also
collect collaborative signals in the context of their application, in
particular how users interacted with the provided online content, e.g., in
forms of viewing, rating, or tagging. Such signals are commonly used for item
recommendation, typically by deriving latent user and item representations from
the data. In this work, we show that such collaborative information can be
leveraged to improve the classification process of new images. Specifically, we
propose a multitask learning framework, where the auxiliary task is to
reconstruct collaborative latent item representations. A series of experiments
on datasets from e-commerce and social media demonstrates that considering
collaborative signals helps to significantly improve the performance of the
main task of image classification by up to 9.1%."
Exploring and Exploiting Hubness Priors for High-Quality GAN Latent Sampling,0.013813,"Despite the extensive studies on Generative Adversarial Networks (GANs), how
to reliably sample high-quality images from their latent spaces remains an
under-explored topic. In this paper, we propose a novel GAN latent sampling
method by exploring and exploiting the hubness priors of GAN latent
distributions. Our key insight is that the high dimensionality of the GAN
latent space will inevitably lead to the emergence of hub latents that usually
have much larger sampling densities than other latents in the latent space. As
a result, these hub latents are better trained and thus contribute more to the
synthesis of high-quality images. Unlike the a posterior ""cherry-picking"", our
method is highly efficient as it is an a priori method that identifies
high-quality latents before the synthesis of images. Furthermore, we show that
the well-known but purely empirical truncation trick is a naive approximation
to the central clustering effect of hub latents, which not only uncovers the
rationale of the truncation trick, but also indicates the superiority and
fundamentality of our method. Extensive experimental results demonstrate the
effectiveness of the proposed method."
Convolutional Neural Network Modelling for MODIS Land Surface Temperature Super-Resolution,0.0313179,"Nowadays, thermal infrared satellite remote sensors enable to extract very
interesting information at large scale, in particular Land Surface Temperature
(LST). However such data are limited in spatial and/or temporal resolutions
which prevents from an analysis at fine scales. For example, MODIS satellite
provides daily acquisitions with 1Km spatial resolutions which is not
sufficient to deal with highly heterogeneous environments as agricultural
parcels. Therefore, image super-resolution is a crucial task to better exploit
MODIS LSTs. This issue is tackled in this paper. We introduce a deep
learning-based algorithm, named Multi-residual U-Net, for super-resolution of
MODIS LST single-images. Our proposed network is a modified version of U-Net
architecture, which aims at super-resolving the input LST image from 1Km to
250m per pixel. The results show that our Multi-residual U-Net outperforms
other state-of-the-art methods."
Caption supervision enables robust learners,0.0116782,"Vision language (VL) models like CLIP are robust to natural distribution
shifts, in part because CLIP learns on unstructured data using a technique
called caption supervision; the model inteprets image-linked texts as
ground-truth labels. In a carefully controlled comparison study, we show that
caption-supervised CNNs trained on a standard cross-entropy loss (with image
labels assigned by scanning captions for class names) can exhibit greater
distributional robustness than VL models trained on the same data. To
facilitate future experiments with high-accuracy caption-supervised models, we
introduce CaptionNet (https://github.com/penfever/CaptionNet/), which includes
a class-balanced, fully supervised dataset with over 50,000 new human-labeled
ImageNet-compliant samples which includes web-scraped captions. In a series of
experiments on CaptionNet, we show how the choice of loss function, data
filtration and supervision strategy enable robust computer vision. We also
provide the codebase necessary to reproduce our experiments at VL Hub
(https://github.com/penfever/vlhub/)."
Iterative collaborative routing among equivariant capsules for transformation-robust capsule networks,0.0255114,"Transformation-robustness is an important feature for machine learning models
that perform image classification. Many methods aim to bestow this property to
models by the use of data augmentation strategies, while more formal guarantees
are obtained via the use of equivariant models. We recognise that
compositional, or part-whole structure is also an important aspect of images
that has to be considered for building transformation-robust models. Thus, we
propose a capsule network model that is, at once, equivariant and
compositionality-aware. Equivariance of our capsule network model comes from
the use of equivariant convolutions in a carefully-chosen novel architecture.
The awareness of compositionality comes from the use of our proposed novel,
iterative, graph-based routing algorithm, termed Iterative collaborative
routing (ICR). ICR, the core of our contribution, weights the predictions made
for capsules based on an iteratively averaged score of the degree-centralities
of its nearest neighbours. Experiments on transformed image classification on
FashionMNIST, CIFAR-10, and CIFAR-100 show that our model that uses ICR
outperforms convolutional and capsule baselines to achieve state-of-the-art
performance."
Towards Two-view 6D Object Pose Estimation: A Comparative Study on Fusion Strategy,0.0190405,"Current RGB-based 6D object pose estimation methods have achieved noticeable
performance on datasets and real world applications. However, predicting 6D
pose from single 2D image features is susceptible to disturbance from changing
of environment and textureless or resemblant object surfaces. Hence, RGB-based
methods generally achieve less competitive results than RGBD-based methods,
which deploy both image features and 3D structure features. To narrow down this
performance gap, this paper proposes a framework for 6D object pose estimation
that learns implicit 3D information from 2 RGB images. Combining the learned 3D
information and 2D image features, we establish more stable correspondence
between the scene and the object models. To seek for the methods best utilizing
3D information from RGB inputs, we conduct an investigation on three different
approaches, including Early- Fusion, Mid-Fusion, and Late-Fusion. We ascertain
the Mid- Fusion approach is the best approach to restore the most precise 3D
keypoints useful for object pose estimation. The experiments show that our
method outperforms state-of-the-art RGB-based methods, and achieves comparable
results with RGBD-based methods."
Probabilistic Implicit Scene Completion,0.0206978,"We propose a probabilistic shape completion method extended to the continuous
geometry of large-scale 3D scenes. Real-world scans of 3D scenes suffer from a
considerable amount of missing data cluttered with unsegmented objects. The
problem of shape completion is inherently ill-posed, and high-quality result
requires scalable solutions that consider multiple possible outcomes. We employ
the Generative Cellular Automata that learns the multi-modal distribution and
transform the formulation to process large-scale continuous geometry. The local
continuous shape is incrementally generated as a sparse voxel embedding, which
contains the latent code for each occupied cell. We formally derive that our
training objective for the sparse voxel embedding maximizes the variational
lower bound of the complete shape distribution and therefore our progressive
generation constitutes a valid generative model. Experiments show that our
model successfully generates diverse plausible scenes faithful to the input,
especially when the input suffers from a significant amount of missing data. We
also demonstrate that our approach outperforms deterministic models even in
less ambiguous cases with a small amount of missing data, which infers that
probabilistic formulation is crucial for high-quality geometry completion on
input scans exhibiting any levels of completeness."
Decanus to Legatus: Synthetic training for 2D-3D human pose lifting,0.0112251,"3D human pose estimation is a challenging task because of the difficulty to
acquire ground-truth data outside of controlled environments. A number of
further issues have been hindering progress in building a universal and robust
model for this task, including domain gaps between different datasets, unseen
actions between train and test datasets, various hardware settings and high
cost of annotation, etc. In this paper, we propose an algorithm to generate
infinite 3D synthetic human poses (Legatus) from a 3D pose distribution based
on 10 initial handcrafted 3D poses (Decanus) during the training of a 2D to 3D
human pose lifter neural network. Our results show that we can achieve 3D pose
estimation performance comparable to methods using real data from specialized
datasets but in a zero-shot setup, showing the generalization potential of our
framework."
Improving the Cross-Lingual Generalisation in Visual Question Answering,0.043198,"While several benefits were realized for multilingual vision-language
pretrained models, recent benchmarks across various tasks and languages showed
poor cross-lingual generalisation when multilingually pre-trained
vision-language models are applied to non-English data, with a large gap
between (supervised) English performance and (zero-shot) cross-lingual
transfer. In this work, we explore the poor performance of these models on a
zero-shot cross-lingual visual question answering (VQA) task, where models are
fine-tuned on English visual-question data and evaluated on 7 typologically
diverse languages. We improve cross-lingual transfer with three strategies: (1)
we introduce a linguistic prior objective to augment the cross-entropy loss
with a similarity-based loss to guide the model during training, (2) we learn a
task-specific subnetwork that improves cross-lingual generalisation and reduces
variance without model modification, (3) we augment training examples using
synthetic code-mixing to promote alignment of embeddings between source and
target languages. Our experiments on xGQA using the pretrained multilingual
multimodal transformers UC2 and M3P demonstrate the consistent effectiveness of
the proposed fine-tuning strategy for 7 languages, outperforming existing
transfer methods with sparse models. Code and data to reproduce our findings
are publicly available."
CSS: Combining Self-training and Self-supervised Learning for Few-shot Dialogue State Tracking,0.0246275,"Few-shot dialogue state tracking (DST) is a realistic problem that trains the
DST model with limited labeled data. Existing few-shot methods mainly transfer
knowledge learned from external labeled dialogue data (e.g., from question
answering, dialogue summarization, machine reading comprehension tasks, etc.)
into DST, whereas collecting a large amount of external labeled data is
laborious, and the external data may not effectively contribute to the
DST-specific task. In this paper, we propose a few-shot DST framework called
CSS, which Combines Self-training and Self-supervised learning methods. The
unlabeled data of the DST task is incorporated into the self-training
iterations, where the pseudo labels are predicted by a DST model trained on
limited labeled data in advance. Besides, a contrastive self-supervised method
is used to learn better representations, where the data is augmented by the
dropout operation to train the model. Experimental results on the MultiWOZ
dataset show that our proposed CSS achieves competitive performance in several
few-shot scenarios."
Sequence-to-Sequence Models for Extracting Information from Registration and Legal Documents,0.00143522,"A typical information extraction pipeline consists of token- or span-level
classification models coupled with a series of pre- and post-processing
scripts. In a production pipeline, requirements often change, with classes
being added and removed, which leads to nontrivial modifications to the source
code and the possible introduction of bugs. In this work, we evaluate
sequence-to-sequence models as an alternative to token-level classification
methods for information extraction of legal and registration documents. We
finetune models that jointly extract the information and generate the output
already in a structured format. Post-processing steps are learned during
training, thus eliminating the need for rule-based methods and simplifying the
pipeline. Furthermore, we propose a novel method to align the output with the
input text, thus facilitating system inspection and auditing. Our experiments
on four real-world datasets show that the proposed method is an alternative to
classical pipelines."
Zoom Text Detector,0.0134942,"To pursue comprehensive performance, recent text detectors improve detection
speed at the expense of accuracy. They adopt shrink-mask based text
representation strategies, which leads to a high dependency of detection
accuracy on shrink-masks. Unfortunately, three disadvantages cause unreliable
shrink-masks. Specifically, these methods try to strengthen the discrimination
of shrink-masks from the background by semantic information. However, the
feature defocusing phenomenon that coarse layers are optimized by fine-grained
objectives limits the extraction of semantic features. Meanwhile, since both
shrink-masks and the margins belong to texts, the detail loss phenomenon that
the margins are ignored hinders the distinguishment of shrink-masks from the
margins, which causes ambiguous shrink-mask edges. Moreover, false-positive
samples enjoy similar visual features with shrink-masks. They aggravate the
decline of shrink-masks recognition. To avoid the above problems, we propose a
Zoom Text Detector (ZTD) inspired by the zoom process of the camera.
Specifically, Zoom Out Module (ZOM) is introduced to provide coarse-grained
optimization objectives for coarse layers to avoid feature defocusing.
Meanwhile, Zoom In Module (ZIM) is presented to enhance the margins recognition
to prevent detail loss. Furthermore, Sequential-Visual Discriminator (SVD) is
designed to suppress false-positive samples by sequential and visual features.
Experiments verify the superior comprehensive performance of ZTD."
Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations,0.0117474,"Due to the huge amount of parameters, fine-tuning of pretrained language
models (PLMs) is prone to overfitting in the low resource scenarios. In this
work, we present a novel method that operates on the hidden representations of
a PLM to reduce overfitting. During fine-tuning, our method inserts random
autoencoders between the hidden layers of a PLM, which transform activations
from the previous layers into multi-view compressed representations before
feeding them into the upper layers. The autoencoders are plugged out after
fine-tuning, so our method does not add extra parameters or increase
computation cost during inference. Our method demonstrates promising
performance improvement across a wide range of sequence- and token-level
low-resource NLP tasks."
A Comparative Study of Graph Neural Networks for Shape Classification in Neuroimaging,0.0042152,"Graph neural networks have emerged as a promising approach for the analysis
of non-Euclidean data such as meshes. In medical imaging, mesh-like data plays
an important role for modelling anatomical structures, and shape classification
can be used in computer aided diagnosis and disease detection. However, with a
plethora of options, the best architectural choices for medical shape analysis
using GNNs remain unclear. We conduct a comparative analysis to provide
practitioners with an overview of the current state-of-the-art in geometric
deep learning for shape classification in neuroimaging. Using biological sex
classification as a proof-of-concept task, we find that using FPFH as node
features substantially improves GNN performance and generalisation to
out-of-distribution data; we compare the performance of three alternative
convolutional layers; and we reinforce the importance of data augmentation for
graph based learning. We then confirm these results hold for a clinically
relevant task, using the classification of Alzheimer's disease."
Learning Efficient Representations for Enhanced Object Detection on Large-scene SAR Images,0.0122216,"It is a challenging problem to detect and recognize targets on complex
large-scene Synthetic Aperture Radar (SAR) images. Recently developed deep
learning algorithms can automatically learn the intrinsic features of SAR
images, but still have much room for improvement on large-scene SAR images with
limited data. In this paper, based on learning representations and multi-scale
features of SAR images, we propose an efficient and robust deep learning based
target detection method. Especially, by leveraging the effectiveness of
adversarial autoencoder (AAE) which influences the distribution of the
investigated data explicitly, the raw SAR dataset is augmented into an enhanced
version with a large quantity and diversity. Besides, an auto-labeling scheme
is proposed to improve labeling efficiency. Finally, with jointly training
small target chips and large-scene images, an integrated YOLO network combining
non-maximum suppression on sub-images is used to realize multiple targets
detection of high resolution images. The numerical experimental results on the
MSTAR dataset show that our method can realize target detection and recognition
on large-scene images accurately and efficiently. The superior anti-noise
performance is also confirmed by experiments."
A Flexible Diffusion Model,0.0148977,"Diffusion (score-based) generative models have been widely used for modeling
various types of complex data, including images, audios, and point clouds.
Recently, the deep connection between forward-backward stochastic differential
equations (SDEs) and diffusion-based models has been revealed, and several new
variants of SDEs are proposed (e.g., sub-VP, critically-damped Langevin) along
this line. Despite the empirical success of the hand-crafted fixed forward
SDEs, a great quantity of proper forward SDEs remain unexplored. In this work,
we propose a general framework for parameterizing the diffusion model,
especially the spatial part of the forward SDE. An abstract formalism is
introduced with theoretical guarantees, and its connection with previous
diffusion models is leveraged. We demonstrate the theoretical advantage of our
method from an optimization perspective. Numerical experiments on synthetic
datasets, MINIST and CIFAR10 are also presented to validate the effectiveness
of our framework."
Self-Supervised Pre-training of Vision Transformers for Dense Prediction Tasks,0.00936174,"We present a new self-supervised pre-training of Vision Transformers for
dense prediction tasks. It is based on a contrastive loss across views that
compares pixel-level representations to global image representations. This
strategy produces better local features suitable for dense prediction tasks as
opposed to contrastive pre-training based on global image representation only.
Furthermore, our approach does not suffer from a reduced batch size since the
number of negative examples needed in the contrastive loss is in the order of
the number of local features. We demonstrate the effectiveness of our
pre-training strategy on two dense prediction tasks: semantic segmentation and
monocular depth estimation."
Text Simplification of College Admissions Instructions: A Professionally Simplified and Verified Corpus,0.0,"Access to higher education is critical for minority populations and emergent
bilingual students. However, the language used by higher education institutions
to communicate with prospective students is often too complex; concretely, many
institutions in the US publish admissions application instructions far above
the average reading level of a typical high school graduate, often near the
13th or 14th grade level. This leads to an unnecessary barrier between students
and access to higher education. This work aims to tackle this challenge via
text simplification. We present PSAT (Professionally Simplified Admissions
Texts), a dataset with 112 admissions instructions randomly selected from
higher education institutions across the US. These texts are then
professionally simplified, and verified and accepted by subject-matter experts
who are full-time employees in admissions offices at various institutions.
Additionally, PSAT comes with manual alignments of 1,883 original-simplified
sentence pairs. The result is a first-of-its-kind corpus for the evaluation and
fine-tuning of text simplification systems in a high-stakes genre distinct from
existing simplification resources."
DeepTechnome: Mitigating Unknown Bias in Deep Learning Based Assessment of CT Images,0.0121462,"Reliably detecting diseases using relevant biological information is crucial
for real-world applicability of deep learning techniques in medical imaging. We
debias deep learning models during training against unknown bias - without
preprocessing/filtering the input beforehand or assuming specific knowledge
about its distribution or precise nature in the dataset. We use control regions
as surrogates that carry information regarding the bias, employ the classifier
model to extract features, and suppress biased intermediate features with our
custom, modular DecorreLayer. We evaluate our method on a dataset of 952 lung
computed tomography scans by introducing simulated biases w.r.t. reconstruction
kernel and noise level and propose including an adversarial test set in
evaluations of bias reduction techniques. In a moderately sized model
architecture, applying the proposed method to learn from data exhibiting a
strong bias, it near-perfectly recovers the classification performance observed
when training with corresponding unbiased data."
"Understanding, Detecting, and Separating Out-of-Distribution Samples and Adversarial Samples in Text Classification",0.00767297,"In this paper, we study the differences and commonalities between
statistically out-of-distribution (OOD) samples and adversarial (Adv) samples,
both of which hurting a text classification model's performance. We conduct
analyses to compare the two types of anomalies (OOD and Adv samples) with the
in-distribution (ID) ones from three aspects: the input features, the hidden
representations in each layer of the model, and the output probability
distributions of the classifier. We find that OOD samples expose their
aberration starting from the first layer, while the abnormalities of Adv
samples do not emerge until the deeper layers of the model. We also illustrate
that the models' output probabilities for Adv samples tend to be more
unconfident. Based on our observations, we propose a simple method to separate
ID, OOD, and Adv samples using the hidden representations and output
probabilities of the model. On multiple combinations of ID, OOD datasets, and
Adv attacks, our proposed method shows exceptional results on distinguishing
ID, OOD, and Adv samples."
Too much information: why CDCL solvers need to forget learned clauses,0.0349126,"Conflict-driven clause learning (CDCL) is a remarkably successful paradigm
for solving the satisfiability problem of propositional logic. Instead of a
simple depth-first backtracking approach, this kind of solver learns the reason
behind occurring conflicts in the form of additional clauses. However, despite
the enormous success of CDCL solvers, there is still only a limited
understanding of what influences the performance of these solvers in what way.
  Considering different measures, this paper demonstrates, quite surprisingly,
that clause learning (without being able to get rid of some clauses) can not
only help the solver but can oftentimes deteriorate the solution process
dramatically. By conducting extensive empirical analysis, we furthermore find
that the runtime distributions of CDCL solvers are multimodal. This
multimodality can be seen as a reason for the deterioration phenomenon
described above. Simultaneously, it also gives an indication of why clause
learning in combination with clause deletion is virtually the de facto standard
of SAT solving, in spite of this phenomenon. As a final contribution, we show
that Weibull mixture distributions can accurately describe the multimodal
distributions. Thus, adding new clauses to a base instance has an inherent
effect of making runtimes long-tailed. This insight provides an explanation as
to why the technique of forgetting clauses is useful in CDCL solvers apart from
the optimization of unit propagation speed."
An Active Contour Model with Local Variance Force Term and Its Efficient Minimization Solver for Multi-phase Image Segmentation,0.00776508,"In this paper, we propose an active contour model with a local variance force
(LVF) term that can be applied to multi-phase image segmentation problems. With
the LVF, the proposed model is very effective in the segmentation of images
with noise. To solve this model efficiently, we represent the regularization
term by characteristic functions and then design a minimization algorithm based
on a modification of the iterative convolution-thresholding method (ICTM),
namely ICTM-LVF. This minimization algorithm enjoys the energy-decaying
property under some conditions and has highly efficient performance in the
segmentation. To overcome the initialization issue of active contour models, we
generalize the inhomogeneous graph Laplacian initialization method (IGLIM) to
the multi-phase case and then apply it to give the initial contour of the
ICTM-LVF solver. Numerical experiments are conducted on synthetic images and
real images to demonstrate the capability of our initialization method, and the
effectiveness of the local variance force for noise robustness in the
multi-phase image segmentation."
An Unsupervised Masking Objective for Abstractive Multi-Document News Summarization,0.0102418,"We show that a simple unsupervised masking objective can approach near
supervised performance on abstractive multi-document news summarization. Our
method trains a state-of-the-art neural summarization model to predict the
masked out source document with highest lexical centrality relative to the
multi-document group. In experiments on the Multi-News dataset, our masked
training objective yields a system that outperforms past unsupervised methods
and, in human evaluation, surpasses the best supervised method without
requiring access to any ground-truth summaries. Further, we evaluate how
different measures of lexical centrality, inspired by past work on extractive
summarization, affect final performance."
Generative Pre-Trained Transformers for Biologically Inspired Design,0.0336583,"Biological systems in nature have evolved for millions of years to adapt and
survive the environment. Many features they developed can be inspirational and
beneficial for solving technical problems in modern industries. This leads to a
novel form of design-by-analogy called bio-inspired design (BID). Although BID
as a design method has been proven beneficial, the gap between biology and
engineering continuously hinders designers from effectively applying the
method. Therefore, we explore the recent advance of artificial intelligence
(AI) for a computational approach to bridge the gap. This paper proposes a
generative design approach based on the pre-trained language model (PLM) to
automatically retrieve and map biological analogy and generate BID in the form
of natural language. The latest generative pre-trained transformer, namely
GPT-3, is used as the base PLM. Three types of design concept generators are
identified and fine-tuned from the PLM according to the looseness of the
problem space representation. Machine evaluators are also fine-tuned to assess
the correlation between the domains within the generated BID concepts. The
approach is then tested via a case study in which the fine-tuned models are
applied to generate and evaluate light-weighted flying car concepts inspired by
nature. The results show our approach can generate BID concepts with good
performance."
Policy Regularization for Legible Behavior,0.0337435,"In Reinforcement Learning interpretability generally means to provide insight
into the agent's mechanisms such that its decisions are understandable by an
expert upon inspection. This definition, with the resulting methods from the
literature, may however fall short for online settings where the fluency of
interactions prohibits deep inspections of the decision-making algorithm. To
support interpretability in online settings it is useful to borrow from the
Explainable Planning literature methods that focus on the legibility of the
agent, by making its intention easily discernable in an observer model. As we
propose in this paper, injecting legible behavior inside an agent's policy
doesn't require modify components of its learning algorithm. Rather, the
agent's optimal policy can be regularized for legibility by evaluating how the
policy may produce observations that would make an observer infer an incorrect
policy. In our formulation, the decision boundary introduced by legibility
impacts the states in which the agent's policy returns an action that has high
likelihood also in other policies. In these cases, a trade-off between such
action, and legible/sub-optimal action is made."
Reducing the Amount of Real World Data for Object Detector Training with Synthetic Data,0.00439231,"A number of studies have investigated the training of neural networks with
synthetic data for applications in the real world. The aim of this study is to
quantify how much real world data can be saved when using a mixed dataset of
synthetic and real world data. By modeling the relationship between the number
of training examples and detection performance by a simple power law, we find
that the need for real world data can be reduced by up to 70% without
sacrificing detection performance. The training of object detection networks is
especially enhanced by enriching the mixed dataset with classes
underrepresented in the real world dataset. The results indicate that mixed
datasets with real world data ratios between 5% and 20% reduce the need for
real world data the most without reducing the detection performance."
A Human-Centric Perspective on Fairness and Transparency in Algorithmic Decision-Making,0.0,"Automated decision systems (ADS) are increasingly used for consequential
decision-making. These systems often rely on sophisticated yet opaque machine
learning models, which do not allow for understanding how a given decision was
arrived at. This is not only problematic from a legal perspective, but
non-transparent systems are also prone to yield unfair outcomes because their
sanity is challenging to assess and calibrate in the first place -- which is
particularly worrisome for human decision-subjects. Based on this observation
and building upon existing work, I aim to make the following three main
contributions through my doctoral thesis: (a) understand how (potential)
decision-subjects perceive algorithmic decisions (with varying degrees of
transparency of the underlying ADS), as compared to similar decisions made by
humans; (b) evaluate different tools for transparent decision-making with
respect to their effectiveness in enabling people to appropriately assess the
quality and fairness of ADS; and (c) develop human-understandable technical
artifacts for fair automated decision-making. Over the course of the first half
of my PhD program, I have already addressed substantial pieces of (a) and (c),
whereas (b) will be the major focus of the second half."
Multi-Curve Translator for High-Resolution Photorealistic Image Translation,0.0150073,"The dominant image-to-image translation methods are based on fully
convolutional networks, which extract and translate an image's features and
then reconstruct the image. However, they have unacceptable computational costs
when working with high-resolution images. To this end, we present the
Multi-Curve Translator (MCT), which not only predicts the translated pixels for
the corresponding input pixels but also for their neighboring pixels. And if a
high-resolution image is downsampled to its low-resolution version, the lost
pixels are the remaining pixels' neighboring pixels. So MCT makes it possible
to feed the network only the downsampled image to perform the mapping for the
full-resolution image, which can dramatically lower the computational cost.
Besides, MCT is a plug-in approach that utilizes existing base models and
requires only replacing their output layers. Experiments demonstrate that the
MCT variants can process 4K images in real-time and achieve comparable or even
better performance than the base models on various photorealistic
image-to-image translation tasks."
Bayesian Learning to Discover Mathematical Operations in Governing Equations of Dynamic Systems,0.243772,"Discovering governing equations from data is critical for diverse scientific
disciplines as they can provide insights into the underlying phenomenon of
dynamic systems. This work presents a new representation for governing
equations by designing the Mathematical Operation Network (MathONet) with a
deep neural network-like hierarchical structure. Specifically, the MathONet is
stacked by several layers of unary operations (e.g., sin, cos, log) and binary
operations (e.g., +,-), respectively. An initialized MathONet is typically
regarded as a super-graph with a redundant structure, a sub-graph of which can
yield the governing equation. We develop a sparse group Bayesian learning
algorithm to extract the sub-graph by employing structurally constructed priors
over the redundant mathematical operations. By demonstrating the chaotic Lorenz
system, Lotka-Volterra system, and Kolmogorov-Petrovsky-Piskunov system, the
proposed method can discover the ordinary differential equations (ODEs) and
partial differential equations (PDEs) from the observations given limited
mathematical operations, without any prior knowledge on possible expressions of
the ODEs and PDEs."
Overlapping Word Removal is All You Need: Revisiting Data Imbalance in Hope Speech Detection,0.0107542,"Hope Speech Detection, a task of recognizing positive expressions, has made
significant strides recently. However, much of the current works focus on model
development without considering the issue of inherent imbalance in the data.
Our work revisits this issue in hope-speech detection by introducing focal
loss, data augmentation, and pre-processing strategies. Accordingly, we find
that introducing focal loss as part of Multilingual-BERT's (M-BERT) training
process mitigates the effect of class imbalance and improves overall F1-Macro
by 0.11. At the same time, contextual and back-translation-based word
augmentation with M-BERT improves results by 0.10 over baseline despite
imbalance. Finally, we show that overlapping word removal based on
pre-processing, though simple, improves F1-Macro by 0.28. In due process, we
present detailed studies depicting various behaviors of each of these
strategies and summarize key findings from our empirical results for those
interested in getting the most out of M-BERT for hope speech detection under
real-world conditions of data imbalance."
Active Evaluation: Efficient NLG Evaluation with Few Pairwise Comparisons,0.0117894,"Recent studies have shown the advantages of evaluating NLG systems using
pairwise comparisons as opposed to direct assessment. Given $k$ systems, a
naive approach for identifying the top-ranked system would be to uniformly
obtain pairwise comparisons from all ${k \choose 2}$ pairs of systems. However,
this can be very expensive as the number of human annotations required would
grow quadratically with $k$. In this work, we introduce Active Evaluation, a
framework to efficiently identify the top-ranked system by actively choosing
system pairs for comparison using dueling bandit algorithms. We perform
extensive experiments with 13 dueling bandits algorithms on 13 NLG evaluation
datasets spanning 5 tasks and show that the number of human annotations can be
reduced by 80%. To further reduce the number of human annotations, we propose
model-based dueling bandit algorithms which combine automatic evaluation
metrics with human evaluations. Specifically, we eliminate sub-optimal systems
even before the human annotation process and perform human evaluations only on
test examples where the automatic metric is highly uncertain. This reduces the
number of human annotations required further by 89%. In effect, we show that
identifying the top-ranked system requires only a few hundred human
annotations, which grow linearly with $k$. Lastly, we provide practical
recommendations and best practices to identify the top-ranked system
efficiently. Our code has been made publicly available at
https://github.com/akashkm99/duelnlg"
Mirror modular cloning and fast quantum associative retrieval,0.0124166,"We show that a quantum state can be perfectly cloned up to global mirroring
with a unitary transformation that depends on one single parameter. We then
show that this is equivalent to ""perfect"" cloning for quantum associative
memories which, as a consequence efficiently hold exponentially more
information than their classical counterparts. Finally, we present a quantum
associative retrieval algorithm which can correct corrupted inputs and is
exponentially faster than the Grover algorithm."
Deceptive Planning for Resource Allocation,0.0134552,"We consider a team of autonomous agents that navigate in an adversarial
environment and aim to achieve a task by allocating their resources over a set
of target locations. An adversary in the environment observes the autonomous
team's behavior to infer their objective and responds against the team. In this
setting, we propose strategies for controlling the density of the autonomous
team so that they can deceive the adversary regarding their objective while
achieving the desired final resource allocation. We first develop a prediction
algorithm based on the principle of maximum entropy to express the team's
behavior expected by the adversary. Then, by measuring the deceptiveness via
Kullback-Leibler divergence, we devise convex optimization-based planning
algorithms that deceive the adversary by either exaggerating the behavior
towards a decoy allocation strategy or creating ambiguity regarding the final
allocation strategy. A user study with $320$ participants demonstrates that the
proposed algorithms are effective for deception and reveal the inherent biases
of participants towards proximate goals."
MiQA: A Benchmark for Inference on Metaphorical Questions,0.625114,"We propose a benchmark to assess the capability of large language models to
reason with conventional metaphors. Our benchmark combines the previously
isolated topics of metaphor detection and commonsense reasoning into a single
task that requires a model to make inferences by accurately selecting between
the literal and metaphorical register. We examine the performance of
state-of-the-art pre-trained models on binary-choice tasks and find a large
discrepancy between the performance of small and very large models, going from
chance to near-human level. We also analyse the largest model in a generative
setting and find that although human performance is approached, careful
multiple-shot prompting is required."
Mixed-effects transformers for hierarchical adaptation,0.00532336,"Language use differs dramatically from context to context. To some degree,
modern language models like GPT-3 are able to account for such variance by
conditioning on a string of previous input text, or prompt. Yet prompting is
ineffective when contexts are sparse, out-of-sample, or extra-textual; for
instance, accounting for when and where the text was produced or who produced
it. In this paper, we introduce the mixed-effects transformer (MET), a novel
approach for learning hierarchically-structured prefixes -- lightweight modules
prepended to the input -- to account for structured variation. Specifically, we
show how the popular class of mixed-effects models may be extended to
transformer-based architectures using a regularized prefix-tuning procedure
with dropout. We evaluate this approach on several domain-adaptation
benchmarks, finding that it efficiently adapts to novel contexts with minimal
data while still effectively generalizing to unseen contexts."
Why Adversarial Training of ReLU Networks Is Difficult?,0.00430038,"This paper mathematically derives an analytic solution of the adversarial
perturbation on a ReLU network, and theoretically explains the difficulty of
adversarial training. Specifically, we formulate the dynamics of the
adversarial perturbation generated by the multi-step attack, which shows that
the adversarial perturbation tends to strengthen eigenvectors corresponding to
a few top-ranked eigenvalues of the Hessian matrix of the loss w.r.t. the
input. We also prove that adversarial training tends to strengthen the
influence of unconfident input samples with large gradient norms in an
exponential manner. Besides, we find that adversarial training strengthens the
influence of the Hessian matrix of the loss w.r.t. network parameters, which
makes the adversarial training more likely to oscillate along directions of a
few samples, and boosts the difficulty of adversarial training. Crucially, our
proofs provide a unified explanation for previous findings in understanding
adversarial training."
Computational Complexity of Segmentation,0.0,"Computational feasibility is a widespread concern that guides the framing and
modeling of biological and artificial intelligence. The specification of
cognitive system capacities is often shaped by unexamined intuitive assumptions
about the search space and complexity of a subcomputation. However, a mistaken
intuition might make such initial conceptualizations misleading for what
empirical questions appear relevant later on. We undertake here
computational-level modeling and complexity analyses of segmentation - a widely
hypothesized subcomputation that plays a requisite role in explanations of
capacities across domains - as a case study to show how crucial it is to
formally assess these assumptions. We mathematically prove two sets of results
regarding hardness and search space size that may run counter to intuition, and
position their implications with respect to existing views on the subcapacity."
MultiEarth 2022 Deforestation Challenge -- ForestGump,0.0047734,"The estimation of deforestation in the Amazon Forest is challenge task
because of the vast size of the area and the difficulty of direct human access.
However, it is a crucial problem in that deforestation results in serious
environmental problems such as global climate change, reduced biodiversity,
etc. In order to effectively solve the problems, satellite imagery would be a
good alternative to estimate the deforestation of the Amazon. With a
combination of optical images and Synthetic aperture radar (SAR) images,
observation of such a massive area regardless of weather conditions become
possible. In this paper, we present an accurate deforestation estimation method
with conventional UNet and comprehensive data processing. The diverse channels
of Sentinel-1, Sentinel-2 and Landsat 8 are carefully selected and utilized to
train deep neural networks. With the proposed method, deforestation status for
novel queries are successfully estimated with high accuracy."
GANzzle: Reframing jigsaw puzzle solving as a retrieval task using a generative mental image,0.0497539,"Puzzle solving is a combinatorial challenge due to the difficulty of matching
adjacent pieces. Instead, we infer a mental image from all pieces, which a
given piece can then be matched against avoiding the combinatorial explosion.
Exploiting advancements in Generative Adversarial methods, we learn how to
reconstruct the image given a set of unordered pieces, allowing the model to
learn a joint embedding space to match an encoding of each piece to the cropped
layer of the generator. Therefore we frame the problem as a R@1 retrieval task,
and then solve the linear assignment using differentiable Hungarian attention,
making the process end-to-end. In doing so our model is puzzle size agnostic,
in contrast to prior deep learning methods which are single size. We evaluate
on two new large-scale datasets, where our model is on par with deep learning
methods, while generalizing to multiple puzzle sizes."
Online Motion Style Transfer for Interactive Character Control,0.0225261,"Motion style transfer is highly desired for motion generation systems for
gaming. Compared to its offline counterpart, the research on online motion
style transfer under interactive control is limited. In this work, we propose
an end-to-end neural network that can generate motions with different styles
and transfer motion styles in real-time under user control. Our approach
eliminates the use of handcrafted phase features, and could be easily trained
and directly deployed in game systems. In the experiment part, we evaluate our
approach from three aspects that are essential for industrial game design:
accuracy, flexibility, and variety, and our model performs a satisfying result."
Spoken Term Detection and Relevance Score Estimation using Dot-Product of Pronunciation Embeddings,0.0704162,"The paper describes a novel approach to Spoken Term Detection (STD) in large
spoken archives using deep LSTM networks. The work is based on the previous
approach of using Siamese neural networks for STD and naturally extends it to
directly localize a spoken term and estimate its relevance score. The phoneme
confusion network generated by a phoneme recognizer is processed by the deep
LSTM network which projects each segment of the confusion network into an
embedding space. The searched term is projected into the same embedding space
using another deep LSTM network. The relevance score is then computed using a
simple dot-product in the embedding space and calibrated using a sigmoid
function to predict the probability of occurrence. The location of the searched
term is then estimated from the sequence of output probabilities. The deep LSTM
networks are trained in a self-supervised manner from paired recognition
hypotheses on word and phoneme levels. The method is experimentally evaluated
on MALACH data in English and Czech languages."
Counterfactually Evaluating Explanations in Recommender Systems,0.0927823,"Modern recommender systems face an increasing need to explain their
recommendations. Despite considerable progress in this area, evaluating the
quality of explanations remains a significant challenge for researchers and
practitioners. Prior work mainly conducts human study to evaluate explanation
quality, which is usually expensive, time-consuming, and prone to human bias.
In this paper, we propose an offline evaluation method that can be computed
without human involvement. To evaluate an explanation, our method quantifies
its counterfactual impact on the recommendation. To validate the effectiveness
of our method, we carry out an online user study. We show that, compared to
conventional methods, our method can produce evaluation scores more correlated
with the real human judgments, and therefore can serve as a better proxy for
human evaluation. In addition, we show that explanations with high evaluation
scores are considered better by humans. Our findings highlight the promising
direction of using the counterfactual approach as one possible way to evaluate
recommendation explanations."
Characterizing the Action-Generalization Gap in Deep Q-Learning,0.00913586,"We study the action generalization ability of deep Q-learning in discrete
action spaces. Generalization is crucial for efficient reinforcement learning
(RL) because it allows agents to use knowledge learned from past experiences on
new tasks. But while function approximation provides deep RL agents with a
natural way to generalize over state inputs, the same generalization mechanism
does not apply to discrete action outputs. And yet, surprisingly, our
experiments indicate that Deep Q-Networks (DQN), which use exactly this type of
function approximator, are still able to achieve modest action generalization.
Our main contribution is twofold: first, we propose a method of evaluating
action generalization using expert knowledge of action similarity, and
empirically confirm that action generalization leads to faster learning;
second, we characterize the action-generalization gap (the difference in
learning performance between DQN and the expert) in different domains. We find
that DQN can indeed generalize over actions in several simple domains, but that
its ability to do so decreases as the action space grows larger."
Predicting Long-Term Citations from Short-Term Linguistic Influence,0.0313709,"A standard measure of the influence of a research paper is the number of
times it is cited. However, papers may be cited for many reasons, and citation
count offers limited information about the extent to which a paper affected the
content of subsequent publications. We therefore propose a novel method to
quantify linguistic influence in timestamped document collections. There are
two main steps: first, identify lexical and semantic changes using contextual
embeddings and word frequencies; second, aggregate information about these
changes into per-document influence scores by estimating a high-dimensional
Hawkes process with a low-rank parameter matrix. We show that this measure of
linguistic influence is predictive of $\textit{future}$ citations: the estimate
of linguistic influence from the two years after a paper's publication is
correlated with and predictive of its citation count in the following three
years. This is demonstrated using an online evaluation with incremental
temporal training/test splits, in comparison with a strong baseline that
includes predictors for initial citation counts, topics, and lexical features."
Learning Point Processes using Recurrent Graph Network,0.00213332,"We present a novel Recurrent Graph Network (RGN) approach for predicting
discrete marked event sequences by learning the underlying complex stochastic
process. Using the framework of Point Processes, we interpret a marked discrete
event sequence as the superposition of different sequences each of a unique
type. The nodes of the Graph Network use LSTM to incorporate past information
whereas a Graph Attention Network (GAT Network) introduces strong inductive
biases to capture the interaction between these different types of events. By
changing the self-attention mechanism from attending over past events to
attending over event types, we obtain a reduction in time and space complexity
from $\mathcal{O}(N^2)$ (total number of events) to
$\mathcal{O}(|\mathcal{Y}|^2)$ (number of event types). Experiments show that
the proposed approach improves performance in log-likelihood, prediction and
goodness-of-fit tasks with lower time and space complexity compared to
state-of-the art Transformer based architectures."
Can GAN-induced Attribute Manipulations Impact Face Recognition?,0.0201071,"Impact due to demographic factors such as age, sex, race, etc., has been
studied extensively in automated face recognition systems. However, the impact
of \textit{digitally modified} demographic and facial attributes on face
recognition is relatively under-explored. In this work, we study the effect of
attribute manipulations induced via generative adversarial networks (GANs) on
face recognition performance. We conduct experiments on the CelebA dataset by
intentionally modifying thirteen attributes using AttGAN and STGAN and
evaluating their impact on two deep learning-based face verification methods,
ArcFace and VGGFace. Our findings indicate that some attribute manipulations
involving eyeglasses and digital alteration of sex cues can significantly
impair face recognition by up to 73% and need further analysis."
Assessing the Effects of Hyperparameters on Knowledge Graph Embedding Quality,0.0098751,"Embedding knowledge graphs into low-dimensional spaces is a popular method
for applying approaches, such as link prediction or node classification, to
these databases. This embedding process is very costly in terms of both
computational time and space. Part of the reason for this is the optimisation
of hyperparameters, which involves repeatedly sampling, by random, guided, or
brute-force selection, from a large hyperparameter space and testing the
resulting embeddings for their quality. However, not all hyperparameters in
this search space will be equally important. In fact, with prior knowledge of
the relative importance of the hyperparameters, some could be eliminated from
the search altogether without significantly impacting the overall quality of
the outputted embeddings. To this end, we ran a Sobol sensitivity analysis to
evaluate the effects of tuning different hyperparameters on the variance of
embedding quality. This was achieved by performing thousands of embedding
trials, each time measuring the quality of embeddings produced by different
hyperparameter configurations. We regressed the embedding quality on those
hyperparameter configurations, using this model to generate Sobol sensitivity
indices for each of the hyperparameters. By evaluating the correlation between
Sobol indices, we find substantial variability in the hyperparameter
sensitivities between knowledge graphs, with differing dataset characteristics
being the probable cause of these inconsistencies. As an additional
contribution of this work we identify several relations in the UMLS knowledge
graph that may cause data leakage via inverse relations, and derive and present
UMLS-43, a leakage-robust variant of that graph."
Improving Shape Awareness and Interpretability in Deep Networks Using Geometric Moments,0.0460958,"Deep networks for image classification often rely more on texture information
than object shape. While efforts have been made to make deep-models
shape-aware, it is often difficult to make such models simple, interpretable,
or rooted in known mathematical definitions of shape. This paper presents a
deep-learning model inspired by geometric moments, a classically well
understood approach to measure shape-related properties. The proposed method
consists of a trainable network for generating coordinate bases and affine
parameters for making the features geometrically invariant yet in a
task-specific manner. The proposed model improves the final feature's
interpretation. We demonstrate the effectiveness of our method on standard
image classification datasets. The proposed model achieves higher
classification performance compared to the baseline and standard ResNet models
while substantially improving interpretability."
Stacking Ensemble Learning in Deep Domain Adaptation for Ophthalmic Image Classification,0.00616899,"Domain adaptation is an attractive approach given the availability of a large
amount of labeled data with similar properties but different domains. It is
effective in image classification tasks where obtaining sufficient label data
is challenging. We propose a novel method, named SELDA, for stacking ensemble
learning via extending three domain adaptation methods for effectively solving
real-world problems. The major assumption is that when base domain adaptation
models are combined, we can obtain a more accurate and robust model by
exploiting the ability of each of the base models. We extend Maximum Mean
Discrepancy (MMD), Low-rank coding, and Correlation Alignment (CORAL) to
compute the adaptation loss in three base models. Also, we utilize a two-fully
connected layer network as a meta-model to stack the output predictions of
these three well-performing domain adaptation models to obtain high accuracy in
ophthalmic image classification tasks. The experimental results using
Age-Related Eye Disease Study (AREDS) benchmark ophthalmic dataset demonstrate
the effectiveness of the proposed model."
Resolving Semantic Confusions for Improved Zero-Shot Detection,0.0529035,"Zero-shot detection (ZSD) is a challenging task where we aim to recognize and
localize objects simultaneously, even when our model has not been trained with
visual samples of a few target (""unseen"") classes. Recently, methods employing
generative models like GANs have shown some of the best results, where
unseen-class samples are generated based on their semantics by a GAN trained on
seen-class data, enabling vanilla object detectors to recognize unseen objects.
However, the problem of semantic confusion still remains, where the model is
sometimes unable to distinguish between semantically-similar classes. In this
work, we propose to train a generative model incorporating a triplet loss that
acknowledges the degree of dissimilarity between classes and reflects them in
the generated samples. Moreover, a cyclic-consistency loss is also enforced to
ensure that generated visual samples of a class highly correspond to their own
semantics. Extensive experiments on two benchmark ZSD datasets - MSCOCO and
PASCAL-VOC - demonstrate significant gains over the current ZSD methods,
reducing semantic confusion and improving detection for the unseen classes."
Offline Reinforcement Learning for Road Traffic Control,0.0403487,"Traffic signal control is an important problem in urban mobility with a
significant potential of economic and environmental impact. While there is a
growing interest in Reinforcement Learning (RL) for traffic signal control, the
work so far has focussed on learning through simulations which could lead to
inaccuracies due to simplifying assumptions. Instead, real experience data on
traffic is available and could be exploited at minimal costs. Recent progress
in offline or batch RL has enabled just that. Model-based offline RL methods,
in particular, have been shown to generalize from the experience data much
better than others.
  We build a model-based learning framework which infers a Markov Decision
Process (MDP) from a dataset collected using a cyclic traffic signal control
policy that is both commonplace and easy to gather. The MDP is built with
pessimistic costs to manage out-of-distribution scenarios using an adaptive
shaping of rewards which is shown to provide better regularization compared to
the prior related work in addition to being PAC-optimal. Our model is evaluated
on a complex signalized roundabout showing that it is possible to build highly
performant traffic control policies in a data efficient manner."
"What's Different between Visual Question Answering for Machine ""Understanding"" Versus for Accessibility?",0.0,"In visual question answering (VQA), a machine must answer a question given an
associated image. Recently, accessibility researchers have explored whether VQA
can be deployed in a real-world setting where users with visual impairments
learn about their environment by capturing their visual surroundings and asking
questions. However, most of the existing benchmarking datasets for VQA focus on
machine ""understanding"" and it remains unclear how progress on those datasets
corresponds to improvements in this real-world use case. We aim to answer this
question by evaluating discrepancies between machine ""understanding"" datasets
(VQA-v2) and accessibility datasets (VizWiz) by evaluating a variety of VQA
models. Based on our findings, we discuss opportunities and challenges in VQA
for accessibility and suggest directions for future work."
Unsupervised Fish Trajectory Tracking and Segmentation,0.0252777,"DNN for fish tracking and segmentation based on high-quality labels is
expensive. Alternative unsupervised approaches rely on spatial and temporal
variations that naturally occur in video data to generate noisy
pseudo-ground-truth labels. These pseudo-labels are used to train a multi-task
deep neural network. In this paper, we propose a three-stage framework for
robust fish tracking and segmentation, where the first stage is an optical flow
model, which generates the pseudo labels using spatial and temporal consistency
between frames. In the second stage, a self-supervised model refines the
pseudo-labels incrementally. In the third stage, the refined labels are used to
train a segmentation network. No human annotations are used during the training
or inference. Extensive experiments are performed to validate our method on
three public underwater video datasets and to demonstrate that it is highly
effective for video annotation and segmentation. We also evaluate the
robustness of our framework to different imaging conditions and discuss the
limitations of our current implementation."
Sensor Data Fusion in Top-View Grid Maps using Evidential Reasoning with Advanced Conflict Resolution,0.0215914,"We present a new method to combine evidential top-view grid maps estimated
based on heterogeneous sensor sources. Dempster's combination rule that is
usually applied in this context provides undesired results with highly
conflicting inputs. Therefore, we use more advanced evidential reasoning
techniques and improve the conflict resolution by modeling the reliability of
the evidence sources. We propose a data-driven reliability estimation to
optimize the fusion quality using the Kitti-360 dataset. We apply the proposed
method to the fusion of LiDAR and stereo camera data and evaluate the results
qualitatively and quantitatively. The results demonstrate that our proposed
method robustly combines measurements from heterogeneous sensors and
successfully resolves sensor conflicts."
Multimodal and Explainable Internet Meme Classification,0.0443941,"In the current context where online platforms have been effectively
weaponized in a variety of geo-political events and social issues, Internet
memes make fair content moderation at scale even more difficult. Existing work
on meme classification and tracking has focused on black-box methods that do
not explicitly consider the semantics of the memes or the context of their
creation. In this paper, we pursue a modular and explainable architecture for
Internet meme understanding. We design and implement multimodal classification
methods that perform example- and prototype-based reasoning over training
cases, while leveraging both textual and visual SOTA models to represent the
individual cases. We study the relevance of our modular and explainable models
in detecting harmful memes on two existing tasks: Hate Speech Detection and
Misogyny Classification. We compare the performance between example- and
prototype-based methods, and between text, vision, and multimodal models,
across different categories of harmfulness (e.g., stereotype and
objectification). We devise a user-friendly interface that facilitates the
comparative analysis of examples retrieved by all of our models for any given
meme, informing the community about the strengths and limitations of these
explainable methods."
Efficient Hybrid Network: Inducting Scattering Features,0.0405541,"Recent work showed that hybrid networks, which combine predefined and learnt
filters within a single architecture, are more amenable to theoretical analysis
and less prone to overfitting in data-limited scenarios. However, their
performance has yet to prove competitive against the conventional counterparts
when sufficient amounts of training data are available. In an attempt to
address this core limitation of current hybrid networks, we introduce an
Efficient Hybrid Network (E-HybridNet). We show that it is the first scattering
based approach that consistently outperforms its conventional counterparts on a
diverse range of datasets. It is achieved with a novel inductive architecture
that embeds scattering features into the network flow using Hybrid Fusion
Blocks. We also demonstrate that the proposed design inherits the key property
of prior hybrid networks -- an effective generalisation in data-limited
scenarios. Our approach successfully combines the best of the two worlds:
flexibility and power of learnt features and stability and predictability of
scattering representations."
PSA-Det3D: Pillar Set Abstraction for 3D object Detection,0.00699342,"Small object detection for 3D point cloud is a challenging problem because of
two limitations: (1) Perceiving small objects is much more diffcult than normal
objects due to the lack of valid points. (2) Small objects are easily blocked
which breaks the shape of their meshes in 3D point cloud. In this paper, we
propose a pillar set abstraction (PSA) and foreground point compensation (FPC)
and design a point-based detection network, PSA-Det3D, to improve the detection
performance for small object. The PSA embeds a pillar query operation on the
basis of set abstraction (SA) to expand its receptive field of the network,
which can aggregate point-wise features effectively. To locate more occluded
objects, we persent a proposal generation layer consisting of a foreground
point segmentation and a FPC module. Both the foreground points and the
estimated centers are finally fused together to generate the detection result.
The experiments on the KITTI 3D detection benchmark show that our proposed
PSA-Det3D outperforms other algorithms with high accuracy for small object
detection."
Understanding the Domain Gap in LiDAR Object Detection Networks,0.0348202,"In order to make autonomous driving a reality, artificial neural networks
have to work reliably in the open-world. However, the open-world is vast and
continuously changing, so it is not technically feasible to collect and
annotate training datasets which accurately represent this domain. Therefore,
there are always domain gaps between training datasets and the open-world which
must be understood. In this work, we investigate the domain gaps between
high-resolution and low-resolution LiDAR sensors in object detection networks.
Using a unique dataset, which enables us to study sensor resolution domain gaps
independent of other effects, we show two distinct domain gaps - an inference
domain gap and a training domain gap. The inference domain gap is characterised
by a strong dependence on the number of LiDAR points per object, while the
training gap shows no such dependence. These fndings show that different
approaches are required to close these inference and training domain gaps."
VidConv: A modernized 2D ConvNet for Efficient Video Recognition,-1.0,"Since being introduced in 2020, Vision Transformers (ViT) has been steadily
breaking the record for many vision tasks and are often described as
``all-you-need"" to replace ConvNet. Despite that, ViTs are generally
computational, memory-consuming, and unfriendly for embedded devices. In
addition, recent research shows that standard ConvNet if redesigned and trained
appropriately can compete favorably with ViT in terms of accuracy and
scalability. In this paper, we adopt the modernized structure of ConvNet to
design a new backbone for action recognition. Particularly, our main target is
to serve for industrial product deployment, such as FPGA boards in which only
standard operations are supported. Therefore, our network simply consists of 2D
convolutions, without using any 3D convolution, long-range attention plugin, or
Transformer blocks. While being trained with much fewer epochs (5x-10x), our
backbone surpasses the methods using (2+1)D and 3D convolution, and achieve
comparable results with ViT on two benchmark datasets."
Low-resource Accent Classification in Geographically-proximate Settings: A Forensic and Sociophonetics Perspective,0.205297,"Accented speech recognition and accent classification are relatively
under-explored research areas in speech technology. Recently, deep
learning-based methods and Transformer-based pretrained models have achieved
superb performances in both areas. However, most accent classification tasks
focused on classifying different kinds of English accents and little attention
was paid to geographically-proximate accent classification, especially under a
low-resource setting where forensic speech science tasks usually encounter. In
this paper, we explored three main accent modelling methods combined with two
different classifiers based on 105 speaker recordings retrieved from five urban
varieties in Northern England. Although speech representations generated from
pretrained models generally have better performances in downstream
classification, traditional methods like Mel Frequency Cepstral Coefficients
(MFCCs) and formant measurements are equipped with specific strengths. These
results suggest that in forensic phonetics scenario where data are relatively
scarce, a simple modelling method and classifier could be competitive with
state-of-the-art pretrained speech models as feature extractors, which could
enhance a sooner estimation for the accent information in practices. Besides,
our findings also cross-validated a new methodology in quantifying
sociophonetic changes."
Data Generation for Satellite Image Classification Using Self-Supervised Representation Learning,0.0080474,"Supervised deep neural networks are the-state-of-the-art for many tasks in
the remote sensing domain, against the fact that such techniques require the
dataset consisting of pairs of input and label, which are rare and expensive to
collect in term of both manpower and resources. On the other hand, there are
abundance of raw satellite images available both for commercial and academic
purposes. Hence, in this work, we tackle the insufficient labeled data problem
in satellite image classification task by introducing the process based on the
self-supervised learning technique to create the synthetic labels for satellite
image patches. These synthetic labels can be used as the training dataset for
the existing supervised learning techniques. In our experiments, we show that
the models trained on the synthetic labels give similar performance to the
models trained on the real labels. And in the process of creating the synthetic
labels, we also obtain the visual representation vectors that are versatile and
knowledge transferable."
Few-Max: Few-Shot Domain Adaptation for Unsupervised Contrastive Representation Learning,0.0153355,"Contrastive self-supervised learning methods learn to map data points such as
images into non-parametric representation space without requiring labels. While
highly successful, current methods require a large amount of data in the
training phase. In situations where the target training set is limited in size,
generalization is known to be poor. Pretraining on a large source data set and
fine-tuning on the target samples is prone to overfitting in the few-shot
regime, where only a small number of target samples are available. Motivated by
this, we propose a domain adaption method for self-supervised contrastive
learning, termed Few-Max, to address the issue of adaptation to a target
distribution under few-shot learning. To quantify the representation quality,
we evaluate Few-Max on a range of source and target datasets, including
ImageNet, VisDA, and fastMRI, on which Few-Max consistently outperforms other
approaches."
MEAT: Maneuver Extraction from Agent Trajectories,0.0242818,"Advances in learning-based trajectory prediction are enabled by large-scale
datasets. However, in-depth analysis of such datasets is limited. Moreover, the
evaluation of prediction models is limited to metrics averaged over all samples
in the dataset. We propose an automated methodology that allows to extract
maneuvers (e.g., left turn, lane change) from agent trajectories in such
datasets. The methodology considers information about the agent dynamics and
information about the lane segments the agent traveled along. Although it is
possible to use the resulting maneuvers for training classification networks,
we exemplary use them for extensive trajectory dataset analysis and
maneuver-specific evaluation of multiple state-of-the-art trajectory prediction
models. Additionally, an analysis of the datasets and an evaluation of the
prediction models based on the agent dynamics is provided."
Advanced Conditional Variational Autoencoders (A-CVAE): Towards interpreting open-domain conversation generation via disentangling latent feature representation,0.0108221,"Currently end-to-end deep learning based open-domain dialogue systems remain
black box models, making it easy to generate irrelevant contents with
data-driven models. Specifically, latent variables are highly entangled with
different semantics in the latent space due to the lack of priori knowledge to
guide the training. To address this problem, this paper proposes to harness the
generative model with a priori knowledge through a cognitive approach involving
mesoscopic scale feature disentanglement. Particularly, the model integrates
the macro-level guided-category knowledge and micro-level open-domain dialogue
data for the training, leveraging the priori knowledge into the latent space,
which enables the model to disentangle the latent variables within the
mesoscopic scale. Besides, we propose a new metric for open-domain dialogues,
which can objectively evaluate the interpretability of the latent space
distribution. Finally, we validate our model on different datasets and
experimentally demonstrate that our model is able to generate higher quality
and more interpretable dialogues than other models."
"Attacking Face Recognition with T-shirts: Database, Vulnerability Assessment and Detection",0.0360243,"Face recognition systems are widely deployed for biometric authentication.
Despite this, it is well-known that, without any safeguards, face recognition
systems are highly vulnerable to presentation attacks. In response to this
security issue, several promising methods for detecting presentation attacks
have been proposed which show high performance on existing benchmarks. However,
an ongoing challenge is the generalization of presentation attack detection
methods to unseen and new attack types. To this end, we propose a new T-shirt
Face Presentation Attack (TFPA) database of 1,608 T-shirt attacks using 100
unique presentation attack instruments. In an extensive evaluation, we show
that this type of attack can compromise the security of face recognition
systems and that some state-of-the-art attack detection mechanisms trained on
popular benchmarks fail to robustly generalize to the new attacks. Further, we
propose three new methods for detecting T-shirt attack images, one which relies
on the statistical differences between depth maps of bona fide images and
T-shirt attacks, an anomaly detection approach trained on features only
extracted from bona fide RGB images, and a fusion approach which achieves
competitive detection performance."
Korean-Specific Dataset for Table Question Answering,0.140139,"Existing question answering systems mainly focus on dealing with text data.
However, much of the data produced daily is stored in the form of tables that
can be found in documents and relational databases, or on the web. To solve the
task of question answering over tables, there exist many datasets for table
question answering written in English, but few Korean datasets. In this paper,
we demonstrate how we construct Korean-specific datasets for table question
answering: Korean tabular dataset is a collection of 1.4M tables with
corresponding descriptions for unsupervised pre-training language models.
Korean table question answering corpus consists of 70k pairs of questions and
answers created by crowd-sourced workers. Subsequently, we then build a
pre-trained language model based on Transformer and fine-tune the model for
table question answering with these datasets. We then report the evaluation
results of our model. We make our datasets publicly available via our GitHub
repository and hope that those datasets will help further studies for question
answering over tables, and for the transformation of table formats."
Multiple View Performers for Shape Completion,0.00556605,"We propose the Multiple View Performer (MVP) - a new architecture for 3D
shape completion from a series of temporally sequential views. MVP accomplishes
this task by using linear-attention Transformers called Performers. Our model
allows the current observation of the scene to attend to the previous ones for
more accurate infilling. The history of past observations is compressed via the
compact associative memory approximating modern continuous Hopfield memory, but
crucially of size independent from the history length. We compare our model
with several baselines for shape completion over time, demonstrating the
generalization gains that MVP provides. To the best of our knowledge, MVP is
the first multiple view voxel reconstruction method that does not require
registration of multiple depth views and the first causal Transformer based
model for 3D shape completion."
SAD: A Large-scale Dataset towards Airport Detection in Synthetic Aperture Radar Images,0.0409459,"Airports have an important role in both military and civilian domains. The
synthetic aperture radar (SAR) based airport detection has received increasing
attention in recent years. However, due to the high cost of SAR imaging and
annotation process, there is no publicly available SAR dataset for airport
detection. As a result, deep learning methods have not been fully used in
airport detection tasks. To provide a benchmark for airport detection research
in SAR images, this paper introduces a large-scale SAR Airport Dataset (SAD).
In order to adequately reflect the demands of real world applications, it
contains 624 SAR images from Sentinel 1B and covers 104 airfield instances with
different scales, orientations and shapes. The experiments of multiple deep
learning approach on this dataset proves its effectiveness. It developing
state-of-the-art airport area detection algorithms or other relevant tasks."
Synonym Detection Using Syntactic Dependency And Neural Embeddings,0.00992617,"Recent advances on the Vector Space Model have significantly improved some
NLP applications such as neural machine translation and natural language
generation. Although word co-occurrences in context have been widely used in
counting-/predicting-based distributional models, the role of syntactic
dependencies in deriving distributional semantics has not yet been thoroughly
investigated. By comparing various Vector Space Models in detecting synonyms in
TOEFL, we systematically study the salience of syntactic dependencies in
accounting for distributional similarity. We separate syntactic dependencies
into different groups according to their various grammatical roles and then use
context-counting to construct their corresponding raw and SVD-compressed
matrices. Moreover, using the same training hyperparameters and corpora, we
study typical neural embeddings in the evaluation. We further study the
effectiveness of injecting human-compiled semantic knowledge into neural
embeddings on computing distributional similarity. Our results show that the
syntactically conditioned contexts can interpret lexical semantics better than
the unconditioned ones, whereas retrofitting neural embeddings with semantic
knowledge can significantly improve synonym detection."
Improving Topic Segmentation by Injecting Discourse Dependencies,0.0786669,"Recent neural supervised topic segmentation models achieve distinguished
superior effectiveness over unsupervised methods, with the availability of
large-scale training corpora sampled from Wikipedia. These models may, however,
suffer from limited robustness and transferability caused by exploiting simple
linguistic cues for prediction, but overlooking more important inter-sentential
topical consistency. To address this issue, we present a discourse-aware neural
topic segmentation model with the injection of above-sentence discourse
dependency structures to encourage the model make topic boundary prediction
based more on the topical consistency between sentences. Our empirical study on
English evaluation datasets shows that injecting above-sentence discourse
structures to a neural topic segmenter with our proposed strategy can
substantially improve its performances on intra-domain and out-of-domain data,
with little increase of model's complexity."
A Machine With Human-Like Memory Systems,0.00518037,"Inspired by the cognitive science theory, we explicitly model an agent with
both semantic and episodic memory systems, and show that it is better than
having just one of the two memory systems. In order to show this, we have
designed and released our own challenging environment, ""the Room"", compatible
with OpenAI Gym, where an agent has to properly learn how to encode, store, and
retrieve memories to maximize its rewards. The Room environment allows for a
hybrid intelligence setup where machines and humans can collaborate. We show
that two agents collaborating with each other results in better performance
than one agent acting alone. We have open-sourced our code and models at
https://github.com/tae898/explicit-memory."
AUTOLEX: An Automatic Framework for Linguistic Exploration,0.798104,"Each language has its own complex systems of word, phrase, and sentence
construction, the guiding principles of which are often summarized in grammar
descriptions for the consumption of linguists or language learners. However,
manual creation of such descriptions is a fraught process, as creating
descriptions which describe the language in ""its own terms"" without bias or
error requires both a deep understanding of the language at hand and
linguistics as a whole. We propose an automatic framework AutoLEX that aims to
ease linguists' discovery and extraction of concise descriptions of linguistic
phenomena. Specifically, we apply this framework to extract descriptions for
three phenomena: morphological agreement, case marking, and word order, across
several languages. We evaluate the descriptions with the help of language
experts and propose a method for automated evaluation when human evaluation is
infeasible."
Unleashing the Power of Transformer for Graphs,0.0391515,"Despite recent successes in natural language processing and computer vision,
Transformer suffers from the scalability problem when dealing with graphs. The
computational complexity is unacceptable for large-scale graphs, e.g.,
knowledge graphs. One solution is to consider only the near neighbors, which,
however, will lose the key merit of Transformer to attend to the elements at
any distance. In this paper, we propose a new Transformer architecture, named
dual-encoding Transformer (DET). DET has a structural encoder to aggregate
information from connected neighbors and a semantic encoder to focus on
semantically useful distant nodes. In comparison with resorting to multi-hop
neighbors, DET seeks the desired distant neighbors via self-supervised
training. We further find these two encoders can be incorporated to boost each
others' performance. Our experiments demonstrate DET has achieved superior
performance compared to the respective state-of-the-art methods in dealing with
molecules, networks and knowledge graphs with various sizes."
drsphelps at SemEval-2022 Task 2: Learning idiom representations using BERTRAM,0.0505911,"This paper describes our system for SemEval-2022 Task 2 Multilingual
Idiomaticity Detection and Sentence Embedding sub-task B. We modify a standard
BERT sentence transformer by adding embeddings for each idioms, which are
created using BERTRAM and a small number of contexts. We show that this
technique increases the quality of idiom representations and leads to better
performance on the task. We also perform analysis on our final results and show
that the quality of the produced idiom embeddings is highly sensitive to the
quality of the input contexts."
Optimization of Directional Landmark Deployment for Visual Observer on SE(3),0.0140613,"An optimization method is proposed in this paper for novel deployment of
given number of directional landmarks (location and pose) within a given region
in the 3-D task space. This new deployment technique is built on the geometric
models of both landmarks and the monocular camera. In particular, a new concept
of Multiple Coverage Probability (MCP) is defined to characterize the
probability of at least n landmarks being covered simultaneously by a camera at
a fixed position. The optimization is conducted with respect to the position
and pose of the given number of landmarks to maximize MCP through globally
exploration of the given 3-D space. By adopting the elimination genetic
algorithm, the global optimal solutions can be obtained, which are then applied
to improve the convergent performance of the visual observer on SE(3) as a
demonstration example. Both simulation and experimental results are presented
to validate the effectiveness of the proposed landmark deployment optimization
method."
Contrastive Learning for Object Detection,0.00218767,"Contrastive learning is commonly used as a method of self-supervised learning
with the ""anchor"" and ""positive"" being two random augmentations of a given
input image, and the ""negative"" is the set of all other images. However, the
requirement of large batch sizes and memory banks has made it difficult and
slow to train. This has motivated the rise of Supervised Contrasative
approaches that overcome these problems by using annotated data. We look to
further improve supervised contrastive learning by ranking classes based on
their similarity, and observe the impact of human bias (in the form of ranking)
on the learned representations. We feel this is an important question to
address, as learning good feature embeddings has been a long sought after
problem in computer vision."
Automatic Evaluation and Analysis of Idioms in Neural Machine Translation,0.213743,"A major open problem in neural machine translation (NMT) is the translation
of idiomatic expressions, such as ""under the weather"". The meaning of these
expressions is not composed by the meaning of their constituent words, and NMT
models tend to translate them literally (i.e., word-by-word), which leads to
confusing and nonsensical translations. Research on idioms in NMT is limited
and obstructed by the absence of automatic methods for quantifying these
errors. In this work, first, we propose a novel metric for automatically
measuring the frequency of literal translation errors without human
involvement. Equipped with this metric, we present controlled translation
experiments with models trained in different conditions (with/without the
test-set idioms) and across a wide range of (global and targeted) metrics and
test sets. We explore the role of monolingual pretraining and find that it
yields substantial targeted improvements, even without observing any
translation examples of the test-set idioms. In our analysis, we probe the role
of idiom context. We find that the randomly initialized models are more local
or ""myopic"" as they are relatively unaffected by variations of the idiom
context, unlike the pretrained ones."
A Simple Strategy to Provable Invariance via Orbit Mapping,0.0,"Many applications require robustness, or ideally invariance, of neural
networks to certain transformations of input data. Most commonly, this
requirement is addressed by training data augmentation, using adversarial
training, or defining network architectures that include the desired invariance
by design. In this work, we propose a method to make network architectures
provably invariant with respect to group actions by choosing one element from a
(possibly continuous) orbit based on a fixed criterion. In a nutshell, we
intend to 'undo' any possible transformation before feeding the data into the
actual network. Further, we empirically analyze the properties of different
approaches which incorporate invariance via training or architecture, and
demonstrate the advantages of our method in terms of robustness and
computational efficiency. In particular, we investigate the robustness with
respect to rotations of images (which can hold up to discretization artifacts)
as well as the provable orientation and scaling invariance of 3D point cloud
classification."
Linearizing Transformer with Key-Value Memory,0.2387,"Efficient transformer variants with linear time complexity have been
developed to mitigate the quadratic computational overhead of the vanilla
transformer. Among them are low-rank projection methods such as Linformer and
kernel-based Transformers. Despite their unique merits, they usually suffer
from a performance drop comparing with the vanilla transformer on many sequence
generation tasks, and often fail to obtain computation gain when the generation
is short. We propose MemSizer, an approach towards closing the performance gap
while improving the efficiency even with short generation. It projects the
source sequences into lower dimension representations like Linformer, while
enjoying efficient recurrent-style incremental computation similar to
kernel-based transformers. This yields linear computation time and constant
memory complexity at inference time. MemSizer also employs a lightweight
multi-head mechanism which renders the computation as light as a single-head
model. We demonstrate that MemSizer provides an improved balance between
efficiency and accuracy over the vanilla transformer and other efficient
transformer variants in three typical sequence generation tasks, including
machine translation, abstractive text summarization, and language modeling."
Automated Audio Captioning with Epochal Difficult Captions for Curriculum Learning,0.0431766,"In this paper, we propose an algorithm, Epochal Difficult Captions, to
supplement the training of any model for the Automated Audio Captioning task.
Epochal Difficult Captions is an elegant evolution to the keyword estimation
task that previous work have used to train the encoder of the AAC model.
Epochal Difficult Captions modifies the target captions based on a curriculum
and a difficulty level determined as a function of current epoch. Epochal
Difficult Captions can be used with any model architecture and is a lightweight
function that does not increase training time. We test our results on three
systems and show that using Epochal Difficult Captions consistently improves
performance"
Deep Vehicle Detection in Satellite Video,0.129491,"This work presents a deep learning approach for vehicle detection in
satellite video. Vehicle detection is perhaps impossible in single EO satellite
images due to the tininess of vehicles (4-10 pixel) and their similarity to the
background. Instead, we consider satellite video which overcomes the lack of
spatial information by temporal consistency of vehicle movement. A new
spatiotemporal model of a compact $3 \times 3$ convolutional, neural network is
proposed which neglects pooling layers and uses leaky ReLUs. Then we use a
reformulation of the output heatmap including Non-Maximum-Suppression (NMS) for
the final segmentation. Empirical results on two new annotated satellite videos
reconfirm the applicability of this approach for vehicle detection. They more
importantly indicate that pre-training on WAMI data and then fine-tuning on few
annotated video frames for a new video is sufficient. In our experiment only
five annotated images yield a $F_1$ score of 0.81 on a new video showing more
complex traffic patterns than the Las Vegas video. Our best result on Las Vegas
is a $F_1$ score of 0.87 which makes the proposed approach a leading method for
this benchmark."
Autoregressive GAN for Semantic Unconditional Head Motion Generation,0.00525344,"In this work, we address the task of unconditional head motion generation to
animate still human faces in a low-dimensional semantic space from a single
reference pose. Different from traditional audio-conditioned talking head
generation that seldom puts emphasis on realistic head motions, we devise a
GAN-based architecture that learns to synthesize rich head motion sequences
over long duration while maintaining low error accumulation levels.In
particular, the autoregressive generation of incremental outputs ensures smooth
trajectories, while a multi-scale discriminator on input pairs drives
generation toward better handling of high- and low-frequency signals and less
mode collapse.We experimentally demonstrate the relevance of the proposed
method and show its superiority compared to models that attained
state-of-the-art performances on similar tasks."
A New Amharic Speech Emotion Dataset and Classification Benchmark,0.167651,"In this paper we present the Amharic Speech Emotion Dataset (ASED), which
covers four dialects (Gojjam, Wollo, Shewa and Gonder) and five different
emotions (neutral, fearful, happy, sad and angry). We believe it is the first
Speech Emotion Recognition (SER) dataset for the Amharic language. 65 volunteer
participants, all native speakers, recorded 2,474 sound samples, two to four
seconds in length. Eight judges assigned emotions to the samples with high
agreement level (Fleiss kappa = 0.8). The resulting dataset is freely available
for download. Next, we developed a four-layer variant of the well-known VGG
model which we call VGGb. Three experiments were then carried out using VGGb
for SER, using ASED. First, we investigated whether Mel-spectrogram features or
Mel-frequency Cepstral coefficient (MFCC) features work best for Amharic. This
was done by training two VGGb SER models on ASED, one using Mel-spectrograms
and the other using MFCC. Four forms of training were tried, standard
cross-validation, and three variants based on sentences, dialects and speaker
groups. Thus, a sentence used for training would not be used for testing, and
the same for a dialect and speaker group. The conclusion was that MFCC features
are superior under all four training schemes. MFCC was therefore adopted for
Experiment 2, where VGGb and three other existing models were compared on ASED:
RESNet50, Alex-Net and LSTM. VGGb was found to have very good accuracy (90.73%)
as well as the fastest training time. In Experiment 3, the performance of VGGb
was compared when trained on two existing SER datasets, RAVDESS (English) and
EMO-DB (German) as well as on ASED (Amharic). Results are comparable across
these languages, with ASED being the highest. This suggests that VGGb can be
successfully applied to other languages. We hope that ASED will encourage
researchers to experiment with other models for Amharic SER."
Multi-Viewpoint and Multi-Evaluation with Felicitous Inductive Bias Boost Machine Abstract Reasoning Ability,0.0415954,"Great endeavors have been made to study AI's ability in abstract reasoning,
along with which different versions of RAVEN's progressive matrices (RPM) are
proposed as benchmarks. Previous works give inkling that without sophisticated
design or extra meta-data containing semantic information, neural networks may
still be indecisive in making decisions regarding RPM problems, after
relentless training. Evidenced by thorough experiments and ablation studies, we
showcase that end-to-end neural networks embodied with felicitous inductive
bias, intentionally design or serendipitously match, can solve RPM problems
elegantly, without the augment of any extra meta-data or preferences of any
specific backbone. Our work also reveals that multi-viewpoint with
multi-evaluation is a key learning strategy for successful reasoning. Finally,
potential explanations for the failure of connectionist models in
generalization are provided. We hope that these results will serve as
inspections of AI's ability beyond perception and toward abstract reasoning.
Source code can be found in https://github.com/QinglaiWeiCASIA/RavenSolver."
Bias-Scalable Near-Memory CMOS Analog Processor for Machine Learning,0.0356846,"Bias-scalable analog computing is attractive for implementing machine
learning (ML) processors with distinct power-performance specifications. For
instance, ML implementations for server workloads are focused on higher
computational throughput for faster training, whereas ML implementations for
edge devices are focused on energy-efficient inference. In this paper, we
demonstrate the implementation of bias-scalable approximate analog computing
circuits using the generalization of the margin-propagation principle called
shape-based analog computing (S-AC). The resulting S-AC core integrates several
near-memory compute elements, which include: (a) non-linear activation
functions; (b) inner-product compute circuits; and (c) a mixed-signal
compressive memory, all of which can be scaled for performance or power while
preserving its functionality. Using measured results from prototypes fabricated
in a 180nm CMOS process, we demonstrate that the performance of computing
modules remains robust to transistor biasing and variations in temperature. In
this paper, we also demonstrate the effect of bias-scalability and
computational accuracy on a simple ML regression task."
Mismatching-Aware Unsupervised Translation Quality Estimation For Low-Resource Languages,0.0553044,"Translation Quality Estimation (QE) is the task of predicting the quality of
machine translation (MT) output without any reference. This task has gained
increasing attention as an important component in the practical applications of
MT. In this paper, we first propose XLMRScore, which is a cross-lingual
counterpart of BERTScore computed via the XLM-RoBERTa (XLMR) model. This metric
can be used as a simple unsupervised QE method, nevertheless facing two issues:
firstly, the untranslated tokens leading to unexpectedly high translation
scores, and secondly, the issue of mismatching errors between source and
hypothesis tokens when applying the greedy matching in XLMRScore. To mitigate
these issues, we suggest replacing untranslated words with the unknown token
and the cross-lingual alignment of the pre-trained model to represent aligned
words closer to each other, respectively. We evaluate the proposed method on
four low-resource language pairs of the WMT21 QE shared task, as well as a new
English$\rightarrow$Persian (En-Fa) test dataset introduced in this paper.
Experiments show that our method could get comparable results with the
supervised baseline for two zero-shot scenarios, i.e., with less than 0.01
difference in Pearson correlation, while outperforming unsupervised rivals in
all the low-resource language pairs for above 8%, on average."
Analytical Solutions for the Inverse Problem within Gradual Semantics,0.0492012,"Gradual semantics within abstract argumentation associate a numeric score
with every argument in a system, which represents the level of acceptability of
this argument, and from which a preference ordering over arguments can be
derived. While some semantics operate over standard argumentation frameworks,
many utilise a weighted framework, where a numeric initial weight is associated
with each argument. Recent work has examined the inverse problem within gradual
semantics. Rather than determining a preference ordering given an argumentation
framework and a semantics, the inverse problem takes an argumentation
framework, a gradual semantics, and a preference ordering as inputs, and
identifies what weights are needed to over arguments in the framework to obtain
the desired preference ordering. Existing work has attacked the inverse problem
numerically, using a root finding algorithm (the bisection method) to identify
appropriate initial weights. In this paper we demonstrate that for a class of
gradual semantics, an analytical approach can be used to solve the inverse
problem. Unlike the current state-of-the-art, such an analytic approach can
rapidly find a solution, and is guaranteed to do so. In obtaining this result,
we are able to prove several important properties which previous work had posed
as conjectures."
What Makes Data-to-Text Generation Hard for Pretrained Language Models?,0.044083,"Expressing natural language descriptions of structured facts or relations --
data-to-text generation (D2T) -- increases the accessibility of structured
knowledge repositories. Previous work shows that pre-trained language
models(PLMs) perform remarkably well on this task after fine-tuning on a
significant amount of task-specific training data. On the other hand, while
auto-regressive PLMs can generalize from a few task examples, their efficacy at
D2T is largely unexplored. Furthermore, we have an incomplete understanding of
the limits of PLMs on D2T.
  In this work, we conduct an empirical study of both fine-tuned and
auto-regressive PLMs on the DART multi-domain D2T dataset. We consider their
performance as a function of the amount of task-specific data and how these
data are incorporated into the models: zero and few-shot learning, and
fine-tuning of model weights. In addition, we probe the limits of PLMs by
measuring performance on subsets of the evaluation data: novel predicates and
abstractive test examples. To improve the performance on these subsets, we
investigate two techniques: providing predicate descriptions in the context and
re-ranking generated candidates by information reflected in the source.
Finally, we conduct a human evaluation of model errors and show that D2T
generation tasks would benefit from datasets with more careful manual curation."
Multi-Spectral Image Classification with Ultra-Lean Complex-Valued Models,0.0410324,"Multi-spectral imagery is invaluable for remote sensing due to different
spectral signatures exhibited by materials that often appear identical in
greyscale and RGB imagery. Paired with modern deep learning methods, this
modality has great potential utility in a variety of remote sensing
applications, such as humanitarian assistance and disaster recovery efforts.
State-of-the-art deep learning methods have greatly benefited from large-scale
annotations like in ImageNet, but existing MSI image datasets lack annotations
at a similar scale. As an alternative to transfer learning on such data with
few annotations, we apply complex-valued co-domain symmetric models to classify
real-valued MSI images. Our experiments on 8-band xView data show that our
ultra-lean model trained on xView from scratch without data augmentations can
outperform ResNet with data augmentation and modified transfer learning on
xView. Our work is the first to demonstrate the value of complex-valued deep
learning on real-valued MSI data."
First do not fall: learning to exploit a wall with a damaged humanoid robot,0.0219169,"Humanoid robots could replace humans in hazardous situations but most of such
situations are equally dangerous for them, which means that they have a high
chance of being damaged and falling. We hypothesize that humanoid robots would
be mostly used in buildings, which makes them likely to be close to a wall. To
avoid a fall, they can therefore lean on the closest wall, as a human would do,
provided that they find in a few milliseconds where to put the hand(s). This
article introduces a method, called D-Reflex, that learns a neural network that
chooses this contact position given the wall orientation, the wall distance,
and the posture of the robot. This contact position is then used by a
whole-body controller to reach a stable posture. We show that D-Reflex allows a
simulated TALOS robot (1.75m, 100kg, 30 degrees of freedom) to avoid more than
75% of the avoidable falls and can work on the real robot."
BBA-net: A bi-branch attention network for crowd counting,0.161621,"In the field of crowd counting, the current mainstream CNN-based regression
methods simply extract the density information of pedestrians without finding
the position of each person. This makes the output of the network often found
to contain incorrect responses, which may erroneously estimate the total number
and not conducive to the interpretation of the algorithm. To this end, we
propose a Bi-Branch Attention Network (BBA-NET) for crowd counting, which has
three innovation points. i) A two-branch architecture is used to estimate the
density information and location information separately. ii) Attention
mechanism is used to facilitate feature extraction, which can reduce false
responses. iii) A new density map generation method combining geometric
adaptation and Voronoi split is introduced. Our method can integrate the
pedestrian's head and body information to enhance the feature expression
ability of the density map. Extensive experiments performed on two public
datasets show that our method achieves a lower crowd counting error compared to
other state-of-the-art methods."
Bipartite-play Dialogue Collection for Practical Automatic Evaluation of Dialogue Systems,0.0232073,"Automation of dialogue system evaluation is a driving force for the efficient
development of dialogue systems. This paper introduces the bipartite-play
method, a dialogue collection method for automating dialogue system evaluation.
It addresses the limitations of existing dialogue collection methods: (i)
inability to compare with systems that are not publicly available, and (ii)
vulnerability to cheating by intentionally selecting systems to be compared.
Experimental results show that the automatic evaluation using the
bipartite-play method mitigates these two drawbacks and correlates as strongly
with human subjectivity as existing methods."
Mean Field Games on Weighted and Directed Graphs via Colored Digraphons,-1.0,"The field of multi-agent reinforcement learning (MARL) has made considerable
progress towards controlling challenging multi-agent systems by employing
various learning methods. Numerous of these approaches focus on empirical and
algorithmic aspects of the MARL problems and lack a rigorous theoretical
foundation. Graphon mean field games (GMFGs) on the other hand provide a
scalable and mathematically well-founded approach to learning problems that
involve a large number of connected agents. In standard GMFGs, the connections
between agents are undirected, unweighted and invariant over time. Our paper
introduces colored digraphon mean field games (CDMFGs) which allow for weighted
and directed links between agents that are also adaptive over time. Thus,
CDMFGs are able to model more complex connections than standard GMFGs. Besides
a rigorous theoretical analysis including both existence and convergence
guarantees, we provide a learning scheme and illustrate our findings with an
epidemics model and a model of the systemic risk in financial markets."
Moving Other Way: Exploring Word Mover Distance Extensions,0.00991219,"The word mover's distance (WMD) is a popular semantic similarity metric for
two texts. This position paper studies several possible extensions of WMD. We
experiment with the frequency of words in the corpus as a weighting factor and
the geometry of the word vector space. We validate possible extensions of WMD
on six document classification datasets. Some proposed extensions show better
results in terms of the k-nearest neighbor classification error than WMD."
Training-Free Robust Multimodal Learning via Sample-Wise Jacobian Regularization,0.00838028,"Multimodal fusion emerges as an appealing technique to improve model
performances on many tasks. Nevertheless, the robustness of such fusion methods
is rarely involved in the present literature. In this paper, we propose a
training-free robust late-fusion method by exploiting conditional independence
assumption and Jacobian regularization. Our key is to minimize the Frobenius
norm of a Jacobian matrix, where the resulting optimization problem is relaxed
to a tractable Sylvester equation. Furthermore, we provide a theoretical error
bound of our method and some insights about the function of the extra modality.
Several numerical experiments on AV-MNIST, RAVDESS, and VGGsound demonstrate
the efficacy of our method under both adversarial attacks and random
corruptions."
AI Autonomy : Self-Initiated Open-World Continual Learning and Adaptation,0.0600174,"As more and more AI agents are used in practice, it is time to think about
how to make these agents fully autonomous so that they can (1) learn by
themselves continually in a self-motivated and self-initiated manner rather
than being retrained offline periodically on the initiation of human engineers
and (2) accommodate or adapt to unexpected or novel circumstances. As the
real-world is an open environment that is full of unknowns or novelties, the
capabilities of detecting novelties, characterizing them,
accommodating/adapting to them, gathering ground-truth training data and
incrementally learning the unknowns/novelties become critical in making the AI
agent more and more knowledgeable, powerful and self-sustainable over time. The
key challenge here is how to automate the process so that it is carried out
continually on the agent's own initiative and through its own interactions with
humans, other agents and the environment just like human on-the-job learning.
This paper proposes a framework (called SOLA) for this learning paradigm to
promote the research of building autonomous and continual learning enabled AI
agents. To show feasibility, an implemented agent is also described."
Interpretation Quality Score for Measuring the Quality of interpretability methods,0.0398972,"Machine learning (ML) models have been applied to a wide range of natural
language processing (NLP) tasks in recent years. In addition to making accurate
decisions, the necessity of understanding how models make their decisions has
become apparent in many applications. To that end, many interpretability
methods that help explain the decision processes of ML models have been
developed. Yet, there currently exists no widely-accepted metric to evaluate
the quality of explanations generated by these methods. As a result, there
currently is no standard way of measuring to what degree an interpretability
method achieves an intended objective. Moreover, there is no accepted standard
of performance by which we can compare and rank the current existing
interpretability methods. In this paper, we propose a novel metric for
quantifying the quality of explanations generated by interpretability methods.
We compute the metric on three NLP tasks using six interpretability methods and
present our results."
PAMI-AD: An Activity Detector Exploiting Part-attention and Motion Information in Surveillance Videos,0.0132488,"Activity detection in surveillance videos is a challenging task caused by
small objects, complex activity categories, its untrimmed nature, etc. Existing
methods are generally limited in performance due to inaccurate proposals, poor
classifiers or inadequate post-processing method. In this work, we propose a
comprehensive and effective activity detection system in untrimmed surveillance
videos for person-centered and vehicle-centered activities. It consists of four
modules, i.e., object localizer, proposal filter, activity classifier and
activity refiner. For person-centered activities, a novel part-attention
mechanism is proposed to explore detailed features in different body parts. As
for vehicle-centered activities, we propose a localization masking method to
jointly encode motion and foreground attention features. We conduct experiments
on the large-scale activity detection datasets VIRAT, and achieve the best
results for both groups of activities. Furthermore, our team won the 1st place
in the TRECVID 2021 ActEV challenge."
HSADML: Hyper-Sphere Angular Deep Metric based Learning for Brain Tumor Classification,-1.0,"Brain Tumors are abnormal mass of clustered cells penetrating regions of
brain. Their timely identification and classification help doctors to provide
appropriate treatment. However, Classifi-cation of Brain Tumors is quite
intricate because of high-intra class similarity and low-inter class
variability. Due to morphological similarity amongst various MRI-Slices of
different classes the challenge deepens more. This all leads to hampering
generalizability of classification models. To this end, this paper proposes
HSADML, a novel framework which enables deep metric learning (DML) using
SphereFace Loss. SphereFace loss embeds the features into a
hyperspheric-manifold and then imposes margin on the embeddings to enhance
differentiability between the classes. With utilization of SphereFace loss
based deep metric learning it is ensured that samples from class clustered
together while the different ones are pushed apart. Results reflects the
promi-nence in the approach, the proposed framework achieved state-of-the-art
98.69% validation accu-racy using k-NN (k=1) and this is significantly higher
than normal SoftMax Loss training which though obtains 98.47% validation
accuracy but that too with limited inter-class separability and intra-class
closeness. Experimental analysis done over various classifiers and loss
function set-tings suggests potential in the approach."
The Shared Task on Gender Rewriting,0.0203204,"In this paper, we present the results and findings of the Shared Task on
Gender Rewriting, which was organized as part of the Seventh Arabic Natural
Language Processing Workshop. The task of gender rewriting refers to generating
alternatives of a given sentence to match different target user gender contexts
(e.g., female speaker with a male listener, a male speaker with a male
listener, etc.). This requires changing the grammatical gender (masculine or
feminine) of certain words referring to the users. In this task, we focus on
Arabic, a gender-marking morphologically rich language. A total of five teams
from four countries participated in the shared task."
A Vocabulary-Free Multilingual Neural Tokenizer for End-to-End Task Learning,0.0352569,"Subword tokenization is a commonly used input pre-processing step in most
recent NLP models. However, it limits the models' ability to leverage
end-to-end task learning. Its frequency-based vocabulary creation compromises
tokenization in low-resource languages, leading models to produce suboptimal
representations. Additionally, the dependency on a fixed vocabulary limits the
subword models' adaptability across languages and domains. In this work, we
propose a vocabulary-free neural tokenizer by distilling segmentation
information from heuristic-based subword tokenization. We pre-train our
character-based tokenizer by processing unique words from multilingual corpus,
thereby extensively increasing word diversity across languages. Unlike the
predefined and fixed vocabularies in subword methods, our tokenizer allows
end-to-end task learning, resulting in optimal task-specific tokenization. The
experimental results show that replacing the subword tokenizer with our neural
tokenizer consistently improves performance on multilingual (NLI) and
code-switching (sentiment analysis) tasks, with larger gains in low-resource
languages. Additionally, our neural tokenizer exhibits a robust performance on
downstream tasks when adversarial noise is present (typos and misspelling),
further increasing the initial improvements over statistical subword
tokenizers."
EDU-level Extractive Summarization with Varying Summary Lengths,0.0112355,"Extractive models usually formulate text summarization as extracting fixed
top-$k$ salient sentences from the document as a summary. Few works exploited
extracting finer-grained Elementary Discourse Unit (EDU) with little analysis
and justification for the extractive unit selection. Further, the selection
strategy of the fixed top-$k$ salient sentences fits the summarization need
poorly, as the number of salient sentences in different documents varies and
therefore a common or best $k$ does not exist in reality. To fill these gaps,
this paper first conducts the comparison analysis of oracle summaries based on
EDUs and sentences, which provides evidence from both theoretical and
experimental perspectives to justify and quantify that EDUs make summaries with
higher automatic evaluation scores than sentences. Then, considering this merit
of EDUs, this paper further proposes an EDU-level extractive model with Varying
summary Lengths and develops the corresponding learning algorithm. EDU-VL
learns to encode and predict probabilities of EDUs in the document, generate
multiple candidate summaries with varying lengths based on various $k$ values,
and encode and score candidate summaries, in an end-to-end training manner.
Finally, EDU-VL is experimented on single and multi-document benchmark datasets
and shows improved performances on ROUGE scores in comparison with
state-of-the-art extractive models, and further human evaluation suggests that
EDU-constituent summaries maintain good grammaticality and readability."
Deep Leaning-Based Ultra-Fast Stair Detection,0.234668,"Staircases are some of the most common building structures in urban
environments. Stair detection is an important task for various applications,
including the environmental perception of exoskeleton robots, humanoid robots,
and rescue robots and the navigation of visually impaired people. Most existing
stair detection algorithms have difficulty dealing with the diversity of stair
structure materials, extreme light and serious occlusion. Inspired by human
perception, we propose an end-to-end method based on deep learning.
Specifically, we treat the process of stair line detection as a multitask
involving coarse-grained semantic segmentation and object detection. The input
images are divided into cells, and a simple neural network is used to judge
whether each cell contains stair lines. For cells containing stair lines, the
locations of the stair lines relative to each cell are regressed. Extensive
experiments on our dataset show that our method can achieve high performance in
terms of both speed and accuracy. A lightweight version can even achieve 300+
frames per second with the same resolution. Our code and dataset will be soon
available at GitHub."
Evolution of a Web-Scale Near Duplicate Image Detection System,0.0207109,"Detecting near duplicate images is fundamental to the content ecosystem of
photo sharing web applications. However, such a task is challenging when
involving a web-scale image corpus containing billions of images. In this
paper, we present an efficient system for detecting near duplicate images
across 8 billion images. Our system consists of three stages: candidate
generation, candidate selection, and clustering. We also demonstrate that this
system can be used to greatly improve the quality of recommendations and search
results across a number of real-world applications.
  In addition, we include the evolution of the system over the course of six
years, bringing out experiences and lessons on how new systems are designed to
accommodate organic content growth as well as the latest technology. Finally,
we are releasing a human-labeled dataset of ~53,000 pairs of images introduced
in this paper."
Planning Landscape Analysis for Self-Adaptive Systems,0.0877092,"To assure performance on the fly, planning is arguably one of the most
important steps for self-adaptive systems (SASs), especially when they are
highly configurable with a daunting number of adaptation options. However,
there has been little understanding of the planning landscape or ways by which
it can be analyzed. This inevitably creates barriers to the design of better
and tailored planners for SASs. In this paper, we showcase how the planning
landscapes of SASs can be quantified and reasoned, particularly with respect to
the different environments. By studying four diverse real-world SASs and 14
environments, we found that (1) the SAS planning landscapes often provide
strong guidance to the planner, but their ruggedness and multi-modality can be
the major obstacle; (2) the extents of guidance and number of global/local
optima are sensitive to the changing environment, but not the ruggedness of the
surface; (3) the local optima are often closer to the global optimum than other
random points; and (4) there are considerable (and useful) overlaps on the
global/local optima between landscapes under different environments. We then
discuss the potential implications to the future work of planner designs for
SASs."
Mono-surrogate vs Multi-surrogate in Multi-objective Bayesian Optimisation,0.0741982,"Bayesian optimisation (BO) has been widely used to solve problems with
expensive function evaluations. In multi-objective optimisation problems, BO
aims to find a set of approximated Pareto optimal solutions. There are
typically two ways to build surrogates in multi-objective BO: One surrogate by
aggregating objective functions (by using a scalarising function, also called
mono-surrogate approach) and multiple surrogates (for each objective function,
also called multi-surrogate approach). In both approaches, an acquisition
function (AF) is used to guide the search process. Mono-surrogate has the
advantage that only one model is used, however, the approach has two major
limitations. Firstly, the fitness landscape of the scalarising function and the
objective functions may not be similar. Secondly, the approach assumes that the
scalarising function distribution is Gaussian, and thus a closed-form
expression of the AF can be used. In this work, we overcome these limitations
by building a surrogate model for each objective function and show that the
scalarising function distribution is not Gaussian. We approximate the
distribution using Generalised extreme value distribution. The results and
comparison with existing approaches on standard benchmark and real-world
optimisation problems show the potential of the multi-surrogate approach."
CREATER: CTR-driven Advertising Text Generation with Controlled Pre-Training and Contrastive Fine-Tuning,0.0621283,"This paper focuses on automatically generating the text of an ad, and the
goal is that the generated text can capture user interest for achieving higher
click-through rate (CTR). We propose CREATER, a CTR-driven advertising text
generation approach, to generate ad texts based on high-quality user reviews.
To incorporate CTR objective, our model learns from online A/B test data with
contrastive learning, which encourages the model to generate ad texts that
obtain higher CTR. To alleviate the low-resource issue, we design a customized
self-supervised objective reducing the gap between pre-training and
fine-tuning. Experiments on industrial datasets show that CREATER significantly
outperforms current approaches. It has been deployed online in a leading
advertising platform and brings uplift on core online metrics."
Explain My Surprise: Learning Efficient Long-Term Memory by Predicting Uncertain Outcomes,0.0120638,"In many sequential tasks, a model needs to remember relevant events from the
distant past to make correct predictions. Unfortunately, a straightforward
application of gradient based training requires intermediate computations to be
stored for every element of a sequence. This requires to store prohibitively
large intermediate data if a sequence consists of thousands or even millions
elements, and as a result, makes learning of very long-term dependencies
infeasible. However, the majority of sequence elements can usually be predicted
by taking into account only temporally local information. On the other hand,
predictions affected by long-term dependencies are sparse and characterized by
high uncertainty given only local information. We propose MemUP, a new training
method that allows to learn long-term dependencies without backpropagating
gradients through the whole sequence at a time. This method can potentially be
applied to any recurrent architecture. LSTM network trained with MemUP performs
better or comparable to baselines while requiring to store less intermediate
data."
Chunk-aware Alignment and Lexical Constraint for Visual Entailment with Natural Language Explanations,0.0676316,"Visual Entailment with natural language explanations aims to infer the
relationship between a text-image pair and generate a sentence to explain the
decision-making process. Previous methods rely mainly on a pre-trained
vision-language model to perform the relation inference and a language model to
generate the corresponding explanation. However, the pre-trained
vision-language models mainly build token-level alignment between text and
image yet ignore the high-level semantic alignment between the phrases (chunks)
and visual contents, which is critical for vision-language reasoning. Moreover,
the explanation generator based only on the encoded joint representation does
not explicitly consider the critical decision-making points of relation
inference. Thus the generated explanations are less faithful to visual-language
reasoning. To mitigate these problems, we propose a unified Chunk-aware
Alignment and Lexical Constraint based method, dubbed as CALeC. It contains a
Chunk-aware Semantic Interactor (arr. CSI), a relation inferrer, and a Lexical
Constraint-aware Generator (arr. LeCG). Specifically, CSI exploits the sentence
structure inherent in language and various image regions to build chunk-aware
semantic alignment. Relation inferrer uses an attention-based reasoning network
to incorporate the token-level and chunk-level vision-language representations.
LeCG utilizes lexical constraints to expressly incorporate the words or chunks
focused by the relation inferrer into explanation generation, improving the
faithfulness and informativeness of the explanations. We conduct extensive
experiments on three datasets, and experimental results indicate that CALeC
significantly outperforms other competitor models on inference accuracy and
quality of generated explanations."
Controlling the Focus of Pretrained Language Generation Models,0.00477097,"The finetuning of pretrained transformer-based language generation models are
typically conducted in an end-to-end manner, where the model learns to attend
to relevant parts of the input by itself. However, there does not exist a
mechanism to directly control the model's focus. This work aims to develop a
control mechanism by which a user can select spans of context as ""highlights""
for the model to focus on, and generate relevant output. To achieve this goal,
we augment a pretrained model with trainable ""focus vectors"" that are directly
applied to the model's embeddings, while the model itself is kept fixed. These
vectors, trained on automatic annotations derived from attribution methods, act
as indicators for context importance. We test our approach on two core
generation tasks: dialogue response generation and abstractive summarization.
We also collect evaluation data where the highlight-generation pairs are
annotated by humans. Our experiments show that the trained focus vectors are
effective in steering the model to generate outputs that are relevant to
user-selected highlights."
A Comprehensive Study on Occlusion Invariant Face Recognition under Face Mask Occlusion,0.028006,"The face mask is an essential sanitaryware in daily lives growing during the
pandemic period and is a big threat to current face recognition systems. The
masks destroy a lot of details in a large area of face, and it makes it
difficult to recognize them even for humans. The evaluation report shows the
difficulty well when recognizing masked faces. Rapid development and
breakthrough of deep learning in the recent past have witnessed most promising
results from face recognition algorithms. But they fail to perform far from
satisfactory levels in the unconstrained environment during the challenges such
as varying lighting conditions, low resolution, facial expressions, pose
variation and occlusions. Facial occlusions are considered one of the most
intractable problems. Especially when the occlusion occupies a large region of
the face because it destroys lots of official features."
Shapley value-based approaches to explain the robustness of classifiers in machine learning,0.0305259,"The use of algorithm-agnostic approaches is an emerging area of research for
explaining the contribution of individual features towards the predicted
outcome. Whilst there is a focus on explaining the prediction itself, a little
has been done on explaining the robustness of these models, that is, how each
feature contributes towards achieving that robustness. In this paper, we
propose the use of Shapley values to explain the contribution of each feature
towards the model's robustness, measured in terms of Receiver-operating
Characteristics (ROC) curve and the Area under the ROC curve (AUC). With the
help of an illustrative example, we demonstrate the proposed idea of explaining
the ROC curve, and visualising the uncertainties in these curves. For
imbalanced datasets, the use of Precision-Recall Curve (PRC) is considered more
appropriate, therefore we also demonstrate how to explain the PRCs with the
help of Shapley values. The explanation of robustness can help analysts in a
number of ways, for example, it can help in feature selection by identifying
the irrelevant features that can be removed to reduce the computational
complexity. It can also help in identifying the features having critical
contributions or negative contributions towards robustness."
LiDAR-MIMO: Efficient Uncertainty Estimation for LiDAR-based 3D Object Detection,0.00550928,"The estimation of uncertainty in robotic vision, such as 3D object detection,
is an essential component in developing safe autonomous systems aware of their
own performance. However, the deployment of current uncertainty estimation
methods in 3D object detection remains challenging due to timing and
computational constraints. To tackle this issue, we propose LiDAR-MIMO, an
adaptation of the multi-input multi-output (MIMO) uncertainty estimation method
to the LiDAR-based 3D object detection task. Our method modifies the original
MIMO by performing multi-input at the feature level to ensure the detection,
uncertainty estimation, and runtime performance benefits are retained despite
the limited capacity of the underlying detector and the large computational
costs of point cloud processing. We compare LiDAR-MIMO with MC dropout and
ensembles as baselines and show comparable uncertainty estimation results with
only a small number of output heads. Further, LiDAR-MIMO can be configured to
be twice as fast as MC dropout and ensembles, while achieving higher mAP than
MC dropout and approaching that of ensembles."
Neural Label Search for Zero-Shot Multi-Lingual Extractive Summarization,0.0226756,"In zero-shot multilingual extractive text summarization, a model is typically
trained on English summarization dataset and then applied on summarization
datasets of other languages. Given English gold summaries and documents,
sentence-level labels for extractive summarization are usually generated using
heuristics. However, these monolingual labels created on English datasets may
not be optimal on datasets of other languages, for that there is the syntactic
or semantic discrepancy between different languages. In this way, it is
possible to translate the English dataset to other languages and obtain
different sets of labels again using heuristics. To fully leverage the
information of these different sets of labels, we propose NLSSum (Neural Label
Search for Summarization), which jointly learns hierarchical weights for these
different sets of labels together with our summarization model. We conduct
multilingual zero-shot summarization experiments on MLSUM and WikiLingua
datasets, and we achieve state-of-the-art results using both human and
automatic evaluations across these two datasets."
The Frost Hollow Experiments: Pavlovian Signalling as a Path to Coordination and Communication Between Agents,0.0021119,"Learned communication between agents is a powerful tool when approaching
decision-making problems that are hard to overcome by any single agent in
isolation. However, continual coordination and communication learning between
machine agents or human-machine partnerships remains a challenging open
problem. As a stepping stone toward solving the continual communication
learning problem, in this paper we contribute a multi-faceted study into what
we term Pavlovian signalling -- a process by which learned, temporally extended
predictions made by one agent inform decision-making by another agent with
different perceptual access to their shared environment. We seek to establish
how different temporal processes and representational choices impact Pavlovian
signalling between learning agents. To do so, we introduce a partially
observable decision-making domain we call the Frost Hollow. In this domain a
prediction learning agent and a reinforcement learning agent are coupled into a
two-part decision-making system that seeks to acquire sparse reward while
avoiding time-conditional hazards. We evaluate two domain variations: 1)
machine prediction and control learning in a linear walk, and 2) a prediction
learning machine interacting with a human participant in a virtual reality
environment. Our results showcase the speed of learning for Pavlovian
signalling, the impact that different temporal representations do (and do not)
have on agent-agent coordination, and how temporal aliasing impacts agent-agent
and human-agent interactions differently. As a main contribution, we establish
Pavlovian signalling as a natural bridge between fixed signalling paradigms and
fully adaptive communication learning. Our results therefore point to an
actionable, constructivist path towards continual communication learning
between reinforcement learning agents, with potential impact in a range of
real-world settings."
Non-iterative optimization of pseudo-labeling thresholds for training object detection models from multiple datasets,0.0144285,"We propose a non-iterative method to optimize pseudo-labeling thresholds for
learning object detection from a collection of low-cost datasets, each of which
is annotated for only a subset of all the object classes. A popular approach to
this problem is first to train teacher models and then to use their confident
predictions as pseudo ground-truth labels when training a student model. To
obtain the best result, however, thresholds for prediction confidence must be
adjusted. This process typically involves iterative search and repeated
training of student models and is time-consuming. Therefore, we develop a
method to optimize the thresholds without iterative optimization by maximizing
the $F_\beta$-score on a validation dataset, which measures the quality of
pseudo labels and can be measured without training a student model. We
experimentally demonstrate that our proposed method achieves an mAP comparable
to that of grid search on the COCO and VOC datasets."
Learning Program Synthesis for Integer Sequences from Scratch,0.0230053,"We present a self-learning approach for synthesizing programs from integer
sequences. Our method relies on a tree search guided by a learned policy. Our
system is tested on the On-Line Encyclopedia of Integer Sequences. There, it
discovers, on its own, solutions for 27987 sequences starting from basic
operators and without human-written training examples."
Objects Matter: Learning Object Relation Graph for Robust Camera Relocalization,0.0748047,"Visual relocalization aims to estimate the pose of a camera from one or more
images. In recent years deep learning based pose regression methods have
attracted many attentions. They feature predicting the absolute poses without
relying on any prior built maps or stored images, making the relocalization
very efficient. However, robust relocalization under environments with complex
appearance changes and real dynamics remains very challenging. In this paper,
we propose to enhance the distinctiveness of the image features by extracting
the deep relationship among objects. In particular, we extract objects in the
image and construct a deep object relation graph (ORG) to incorporate the
semantic connections and relative spatial clues of the objects. We integrate
our ORG module into several popular pose regression models. Extensive
experiments on various public indoor and outdoor datasets demonstrate that our
method improves the performance significantly and outperforms the previous
approaches."
An anomaly detection approach for backdoored neural networks: face recognition as a case study,0.00525965,"Backdoor attacks allow an attacker to embed functionality jeopardizing proper
behavior of any algorithm, machine learning or not. This hidden functionality
can remain inactive for normal use of the algorithm until activated by the
attacker. Given how stealthy backdoor attacks are, consequences of these
backdoors could be disastrous if such networks were to be deployed for
applications as critical as border or access control. In this paper, we propose
a novel backdoored network detection method based on the principle of anomaly
detection, involving access to the clean part of the training data and the
trained network. We highlight its promising potential when considering various
triggers, locations and identity pairs, without the need to make any
assumptions on the nature of the backdoor and its setup. We test our method on
a novel dataset of backdoored networks and report detectability results with
perfect scores."
"V3GAN: Decomposing Background, Foreground and Motion for Video Generation",0.018876,"Video generation is a challenging task that requires modeling plausible
spatial and temporal dynamics in a video. Inspired by how humans perceive a
video by grouping a scene into moving and stationary components, we propose a
method that decomposes the task of video generation into the synthesis of
foreground, background and motion. Foreground and background together describe
the appearance, whereas motion specifies how the foreground moves in a video
over time. We propose V3GAN, a novel three-branch generative adversarial
network where two branches model foreground and background information, while
the third branch models the temporal information without any supervision. The
foreground branch is augmented with our novel feature-level masking layer that
aids in learning an accurate mask for foreground and background separation. To
encourage motion consistency, we further propose a shuffling loss for the video
discriminator. Extensive quantitative and qualitative analysis on synthetic as
well as real-world benchmark datasets demonstrates that V3GAN outperforms the
state-of-the-art methods by a significant margin."
Feature Engineering vs BERT on Twitter Data,0.00430844,"In this paper, we compare the performances of traditional machine learning
models using feature engineering and word vectors and the state-of-the-art
language model BERT using word embeddings on three datasets. We also consider
the time and cost efficiency of feature engineering compared to BERT. From our
results we conclude that the use of the BERT model was only worth the time and
cost trade-off for one of the three datasets we used for comparison, where the
BERT model significantly outperformed any kind of traditional classifier that
uses feature vectors, instead of embeddings. Using the BERT model for the other
datasets only achieved an increase of 0.03 and 0.05 of accuracy and F1 score
respectively, which could be argued makes its use not worth the time and cost
of GPU."
Label-Efficient Online Continual Object Detection in Streaming Video,0.0507915,"Humans can watch a continuous video stream and effortlessly perform continual
acquisition and transfer of new knowledge with minimal supervision yet
retaining previously learnt experiences. In contrast, existing continual
learning (CL) methods require fully annotated labels to effectively learn from
individual frames in a video stream. Here, we examine a more realistic and
challenging problem$\unicode{x2014}$Label-Efficient Online Continual Object
Detection (LEOCOD) in streaming video. We propose a plug-and-play module,
Efficient-CLS, that can be easily inserted into and improve existing continual
learners for object detection in video streams with reduced data annotation
costs and model retraining time. We show that our method has achieved
significant improvement with minimal forgetting across all supervision levels
on two challenging CL benchmarks for streaming real-world videos. Remarkably,
with only 25% annotated video frames, our method still outperforms the base CL
learners, which are trained with 100% annotations on all video frames. The data
and source code will be publicly available at
https://github.com/showlab/Efficient-CLS."
SPBERTQA: A Two-Stage Question Answering System Based on Sentence Transformers for Medical Texts,-1.0,"Question answering (QA) systems have gained explosive attention in recent
years. However, QA tasks in Vietnamese do not have many datasets.
Significantly, there is mostly no dataset in the medical domain. Therefore, we
built a Vietnamese Healthcare Question Answering dataset (ViHealthQA),
including 10,015 question-answer passage pairs for this task, in which
questions from health-interested users were asked on prestigious health
websites and answers from highly qualified experts. This paper proposes a
two-stage QA system based on Sentence-BERT (SBERT) using multiple negatives
ranking (MNR) loss combined with BM25. Then, we conduct diverse experiments
with many bag-of-words models to assess our system's performance. With the
obtained results, this system achieves better performance than traditional
methods."
CasNet: Investigating Channel Robustness for Speech Separation,0.0101415,"Recording channel mismatch between training and testing conditions has been
shown to be a serious problem for speech separation. This situation greatly
reduces the separation performance, and cannot meet the requirement of daily
use. In this study, inheriting the use of our previously constructed TAT-2mix
corpus, we address the channel mismatch problem by proposing a channel-aware
audio separation network (CasNet), a deep learning framework for end-to-end
time-domain speech separation. CasNet is implemented on top of TasNet. Channel
embedding (characterizing channel information in a mixture of multiple
utterances) generated by Channel Encoder is introduced into the separation
module by the FiLM technique. Through two training strategies, we explore two
roles that channel embedding may play: 1) a real-life noise disturbance, making
the model more robust, or 2) a guide, instructing the separation model to
retain the desired channel information. Experimental results on TAT-2mix show
that CasNet trained with both training strategies outperforms the TasNet
baseline, which does not use channel embeddings."
Distribution-based Emotion Recognition in Conversation,0.00105675,"Automatic emotion recognition in conversation (ERC) is crucial for
emotion-aware conversational artificial intelligence. This paper proposes a
distribution-based framework that formulates ERC as a sequence-to-sequence
problem for emotion distribution estimation. The inherent ambiguity of emotions
and the subjectivity of human perception lead to disagreements in emotion
labels, which is handled naturally in our framework from the perspective of
uncertainty estimation in emotion distributions. A Bayesian training loss is
introduced to improve the uncertainty estimation by conditioning each emotional
state on an utterance-specific Dirichlet prior distribution. Experimental
results on the IEMOCAP dataset show that ERC outperformed the
single-utterance-based system, and the proposed distribution-based ERC methods
have not only better classification accuracy, but also show improved
uncertainty estimation."
Towards Realistic Underwater Dataset Generation and Color Restoration,0.0102387,"Recovery of true color from underwater images is an ill-posed problem. This
is because the wide-band attenuation coefficients for the RGB color channels
depend on object range, reflectance, etc. which are difficult to model. Also,
there is backscattering due to suspended particles in water. Thus, most
existing deep-learning based color restoration methods, which are trained on
synthetic underwater datasets, do not perform well on real underwater data.
This can be attributed to the fact that synthetic data cannot accurately
represent real conditions. To address this issue, we use an image to image
translation network to bridge the gap between the synthetic and real domains by
translating images from synthetic underwater domain to real underwater domain.
Using this multimodal domain adaptation technique, we create a dataset that can
capture a diverse array of underwater conditions. We then train a simple but
effective CNN based network on our domain adapted dataset to perform color
restoration. Code and pre-trained models can be accessed at
https://github.com/nehamjain10/TRUDGCR"
Cross-Camera View-Overlap Recognition,0.00687131,"We propose a decentralised view-overlap recognition framework that operates
across freely moving cameras without the need of a reference 3D map. Each
camera independently extracts, aggregates into a hierarchical structure, and
shares feature-point descriptors over time. A view overlap is recognised by
view-matching and geometric validation to discard wrongly matched views. The
proposed framework is generic and can be used with different descriptors. We
conduct the experiments on publicly available sequences as well as new
sequences we collected with hand-held cameras. We show that Oriented FAST and
Rotated BRIEF (ORB) features with Bags of Binary Words within the proposed
framework lead to higher precision and a higher or similar accuracy compared to
NetVLAD, RootSIFT, and SuperGlue."
MMINR: Multi-frame-to-Multi-frame Inference with Noise Resistance for Precipitation Nowcasting with Radar,0.0198096,"Precipitation nowcasting based on radar echo maps is essential in
meteorological research. Recently, Convolutional RNNs based methods dominate
this field, but they cannot be solved by parallel computation resulting in
longer inference time. FCN based methods adopt a multi-frame-to-single-frame
inference (MSI) strategy to avoid this problem. They feedback into the model
again to predict the next time step to get multi-frame nowcasting results in
the prediction phase, which will lead to the accumulation of prediction errors.
In addition, precipitation noise is a crucial factor contributing to high
prediction errors because of its unpredictability. To address this problem, we
propose a novel Multi-frame-to-Multi-frame Inference (MMI) model with Noise
Resistance (NR) named MMINR. It avoids error accumulation and resists
precipitation noise\'s negative effect in parallel computation. NR contains a
Noise Dropout Module (NDM) and a Semantic Restore Module (SRM). NDM
deliberately dropout noise simple yet efficient, and SRM supplements semantic
information of features to alleviate the problem of semantic information
mistakenly lost by NDM. Experimental results demonstrate that MMINR can attain
competitive scores compared with other SOTAs. The ablation experiments show
that the proposed NDM and SRM can solve the aforementioned problems."
Explaining Image Classifiers Using Contrastive Counterfactuals in Generative Latent Spaces,0.0263522,"Despite their high accuracies, modern complex image classifiers cannot be
trusted for sensitive tasks due to their unknown decision-making process and
potential biases. Counterfactual explanations are very effective in providing
transparency for these black-box algorithms. Nevertheless, generating
counterfactuals that can have a consistent impact on classifier outputs and yet
expose interpretable feature changes is a very challenging task. We introduce a
novel method to generate causal and yet interpretable counterfactual
explanations for image classifiers using pretrained generative models without
any re-training or conditioning. The generative models in this technique are
not bound to be trained on the same data as the target classifier. We use this
framework to obtain contrastive and causal sufficiency and necessity scores as
global explanations for black-box classifiers. On the task of face attribute
classification, we show how different attributes influence the classifier
output by providing both causal and contrastive feature attributions, and the
corresponding counterfactual images."
SpikiLi: A Spiking Simulation of LiDAR based Real-time Object Detection for Autonomous Driving,-1.0,"Spiking Neural Networks are a recent and new neural network design approach
that promises tremendous improvements in power efficiency, computation
efficiency, and processing latency. They do so by using asynchronous
spike-based data flow, event-based signal generation, processing, and modifying
the neuron model to resemble biological neurons closely. While some initial
works have shown significant initial evidence of applicability to common deep
learning tasks, their applications in complex real-world tasks has been
relatively low. In this work, we first illustrate the applicability of spiking
neural networks to a complex deep learning task namely Lidar based 3D object
detection for automated driving. Secondly, we make a step-by-step demonstration
of simulating spiking behavior using a pre-trained convolutional neural
network. We closely model essential aspects of spiking neural networks in
simulation and achieve equivalent run-time and accuracy on a GPU. When the
model is realized on a neuromorphic hardware, we expect to have significantly
improved power efficiency."
Unsupervised multi-branch Capsule for Hyperspectral and LiDAR classification,0.0129823,"With the convenient availability of remote sensing data, how to make models
to interpret complex remote sensing data attracts wide attention. In remote
sensing data, hyperspectral images contain spectral information and LiDAR
contains elevation information. Hence, more explorations are warranted to
better fuse the features of different source data. In this paper, we introduce
semantic understanding to dynamically fuse data from two different sources,
extract features of HSI and LiDAR through different capsule network branches
and improve self-supervised loss and random rigid rotation in Canonical Capsule
to a high-dimensional situation. Canonical Capsule computes the capsule
decomposition of objects by permutation-equivariant attention and the process
is self-supervised by training pairs of randomly rotated objects. After fusing
the features of HSI and LiDAR with semantic understanding, the unsupervised
extraction of spectral-spatial-elevation fusion features is achieved. With two
real-world examples of HSI and LiDAR fused, the experimental results show that
the proposed multi-branch high-dimensional canonical capsule algorithm can be
effective for semantic understanding of HSI and LiDAR. It indicates that the
model can extract HSI and LiDAR data features effectively as opposed to
existing models for unsupervised extraction of multi-source RS data."
"Computational analyses of the topics, sentiments, literariness, creativity and beauty of texts in a large Corpus of English Literature",0.0575012,"The Gutenberg Literary English Corpus (GLEC, Jacobs, 2018a) provides a rich
source of textual data for research in digital humanities, computational
linguistics or neurocognitive poetics. In this study we address differences
among the different literature categories in GLEC, as well as differences
between authors. We report the results of three studies providing i) topic and
sentiment analyses for six text categories of GLEC (i.e., children and youth,
essays, novels, plays, poems, stories) and its >100 authors, ii) novel measures
of semantic complexity as indices of the literariness, creativity and book
beauty of the works in GLEC (e.g., Jane Austen's six novels), and iii) two
experiments on text classification and authorship recognition using novel
features of semantic complexity. The data on two novel measures estimating a
text's literariness, intratextual variance and stepwise distance (van
Cranenburgh et al., 2019) revealed that plays are the most literary texts in
GLEC, followed by poems and novels. Computation of a novel index of text
creativity (Gray et al., 2016) revealed poems and plays as the most creative
categories with the most creative authors all being poets (Milton, Pope, Keats,
Byron, or Wordsworth). We also computed a novel index of perceived beauty of
verbal art (Kintsch, 2012) for the works in GLEC and predict that Emma is the
theoretically most beautiful of Austen's novels. Finally, we demonstrate that
these novel measures of semantic complexity are important features for text
classification and authorship recognition with overall predictive accuracies in
the range of .75 to .97. Our data pave the way for future computational and
empirical studies of literature or experiments in reading psychology and offer
multiple baselines and benchmarks for analysing and validating other book
corpora."
Sort by Structure: Language Model Ranking as Dependency Probing,0.0178449,"Making an informed choice of pre-trained language model (LM) is critical for
performance, yet environmentally costly, and as such widely underexplored. The
field of Computer Vision has begun to tackle encoder ranking, with promising
forays into Natural Language Processing, however they lack coverage of
linguistic tasks such as structured prediction. We propose probing to rank LMs,
specifically for parsing dependencies in a given language, by measuring the
degree to which labeled trees are recoverable from an LM's contextualized
embeddings. Across 46 typologically and architecturally diverse LM-language
pairs, our probing approach predicts the best LM choice 79% of the time using
orders of magnitude less compute than training a full parser. Within this
study, we identify and analyze one recently proposed decoupled LM - RemBERT -
and find it strikingly contains less inherent dependency information, but often
yields the best parser after full fine-tuning. Without this outlier our
approach identifies the best LM in 89% of cases."
Quantifying Harm,0.0156861,"In a companion paper (Beckers et al. 2022), we defined a qualitative notion
of harm: either harm is caused, or it is not. For practical applications, we
often need to quantify harm; for example, we may want to choose the lest
harmful of a set of possible interventions. We first present a quantitative
definition of harm in a deterministic context involving a single individual,
then we consider the issues involved in dealing with uncertainty regarding the
context and going from a notion of harm for a single individual to a notion of
""societal harm"", which involves aggregating the harm to individuals. We show
that the ""obvious"" way of doing this (just taking the expected harm for an
individual and then summing the expected harm over all individuals can lead to
counterintuitive or inappropriate answers, and discuss alternatives, drawing on
work from the decision-theory literature."
SparseFormer: Attention-based Depth Completion Network,0.076309,"Most pipelines for Augmented and Virtual Reality estimate the ego-motion of
the camera by creating a map of sparse 3D landmarks. In this paper, we tackle
the problem of depth completion, that is, densifying this sparse 3D map using
RGB images as guidance. This remains a challenging problem due to the low
density, non-uniform and outlier-prone 3D landmarks produced by SfM and SLAM
pipelines. We introduce a transformer block, SparseFormer, that fuses 3D
landmarks with deep visual features to produce dense depth. The SparseFormer
has a global receptive field, making the module especially effective for depth
completion with low-density and non-uniform landmarks. To address the issue of
depth outliers among the 3D landmarks, we introduce a trainable refinement
module that filters outliers through attention between the sparse landmarks."
Gradient Obfuscation Checklist Test Gives a False Sense of Security,0.0152661,"One popular group of defense techniques against adversarial attacks is based
on injecting stochastic noise into the network. The main source of robustness
of such stochastic defenses however is often due to the obfuscation of the
gradients, offering a false sense of security. Since most of the popular
adversarial attacks are optimization-based, obfuscated gradients reduce their
attacking ability, while the model is still susceptible to stronger or
specifically tailored adversarial attacks. Recently, five characteristics have
been identified, which are commonly observed when the improvement in robustness
is mainly caused by gradient obfuscation. It has since become a trend to use
these five characteristics as a sufficient test, to determine whether or not
gradient obfuscation is the main source of robustness. However, these
characteristics do not perfectly characterize all existing cases of gradient
obfuscation, and therefore can not serve as a basis for a conclusive test. In
this work, we present a counterexample, showing this test is not sufficient for
concluding that gradient obfuscation is not the main cause of improvements in
robustness."
Zero-Shot Video Captioning with Evolving Pseudo-Tokens,0.281674,"We introduce a zero-shot video captioning method that employs two frozen
networks: the GPT-2 language model and the CLIP image-text matching model. The
matching score is used to steer the language model toward generating a sentence
that has a high average matching score to a subset of the video frames. Unlike
zero-shot image captioning methods, our work considers the entire sentence at
once. This is achieved by optimizing, during the generation process, part of
the prompt from scratch, by modifying the representation of all other tokens in
the prompt, and by repeating the process iteratively, gradually improving the
specificity and comprehensiveness of the generated sentence. Our experiments
show that the generated captions are coherent and display a broad range of
real-world knowledge. Our code is available at:
https://github.com/YoadTew/zero-shot-video-to-text"
Pretraining a Neural Network before Knowing Its Architecture,0.0118744,"Training large neural networks is possible by training a smaller hypernetwork
that predicts parameters for the large ones. A recently released Graph
HyperNetwork (GHN) trained this way on one million smaller ImageNet
architectures is able to predict parameters for large unseen networks such as
ResNet-50. While networks with predicted parameters lose performance on the
source task, the predicted parameters have been found useful for fine-tuning on
other tasks. We study if fine-tuning based on the same GHN is still useful on
novel strong architectures that were published after the GHN had been trained.
We found that for recent architectures such as ConvNeXt, GHN initialization
becomes less useful than for ResNet-50. One potential reason is the increased
distribution shift of novel architectures from those used to train the GHN. We
also found that the predicted parameters lack the diversity necessary to
successfully fine-tune parameters with gradient descent. We alleviate this
limitation by applying simple post-processing techniques to predicted
parameters before fine-tuning them on a target task and improve fine-tuning of
ResNet-50 and ConvNeXt."
SimSR: Simple Distance-based State Representation for Deep Reinforcement Learning,0.973652,"This work explores how to learn robust and generalizable state representation
from image-based observations with deep reinforcement learning methods.
Addressing the computational complexity, stringent assumptions and
representation collapse challenges in existing work of bisimulation metric, we
devise Simple State Representation (SimSR) operator. SimSR enables us to design
a stochastic approximation method that can practically learn the mapping
functions (encoders) from observations to latent representation space. In
addition to the theoretical analysis and comparison with the existing work, we
experimented and compared our work with recent state-of-the-art solutions in
visual MuJoCo tasks. The results shows that our model generally achieves better
performance and has better robustness and good generalization."
"""The Pedestrian next to the Lamppost"" Adaptive Object Graphs for Better Instantaneous Mapping",0.103607,"Estimating a semantically segmented bird's-eye-view (BEV) map from a single
image has become a popular technique for autonomous control and navigation.
However, they show an increase in localization error with distance from the
camera. While such an increase in error is entirely expected - localization is
harder at distance - much of the drop in performance can be attributed to the
cues used by current texture-based models, in particular, they make heavy use
of object-ground intersections (such as shadows), which become increasingly
sparse and uncertain for distant objects. In this work, we address these
shortcomings in BEV-mapping by learning the spatial relationship between
objects in a scene. We propose a graph neural network which predicts BEV
objects from a monocular image by spatially reasoning about an object within
the context of other objects. Our approach sets a new state-of-the-art in BEV
estimation from monocular images across three large-scale datasets, including a
50% relative improvement for objects on nuScenes."
On the Convergence of Semi-Relaxed Sinkhorn with Marginal Constraint and OT Distance Gaps,0.0304123,"This paper presents consideration of the Semi-Relaxed Sinkhorn (SR-Sinkhorn)
algorithm for the semi-relaxed optimal transport (SROT) problem, which relaxes
one marginal constraint of the standard OT problem. For evaluation of how the
constraint relaxation affects the algorithm behavior and solution, it is
vitally necessary to present the theoretical convergence analysis in terms not
only of the functional value gap, but also of the marginal constraint gap as
well as the OT distance gap. However, no existing work has addressed all
analyses simultaneously. To this end, this paper presents a comprehensive
convergence analysis for SR-Sinkhorn. After presenting the
$\epsilon$-approximation of the functional value gap based on a new proof
strategy and exploiting this proof strategy, we give the upper bound of the
marginal constraint gap. We also provide its convergence to the
$\epsilon$-approximation when two distributions are in the probability simplex.
Furthermore, the convergence analysis of the OT distance gap to the
$\epsilon$-approximation is given as assisted by the obtained marginal
constraint gap. The latter two theoretical results are the first results
presented in the literature related to the SROT problem."
Duality-Induced Regularizer for Semantic Matching Knowledge Graph Embeddings,0.0367605,"Semantic matching models -- which assume that entities with similar semantics
have similar embeddings -- have shown great power in knowledge graph embeddings
(KGE). Many existing semantic matching models use inner products in embedding
spaces to measure the plausibility of triples and quadruples in static and
temporal knowledge graphs. However, vectors that have the same inner products
with another vector can still be orthogonal to each other, which implies that
entities with similar semantics may have dissimilar embeddings. This property
of inner products significantly limits the performance of semantic matching
models. To address this challenge, we propose a novel regularizer -- namely,
DUality-induced RegulArizer (DURA) -- which effectively encourages the entities
with similar semantics to have similar embeddings. The major novelty of DURA is
based on the observation that, for an existing semantic matching KGE model
(primal), there is often another distance based KGE model (dual) closely
associated with it, which can be used as effective constraints for entity
embeddings. Experiments demonstrate that DURA consistently and significantly
improves the performance of state-of-the-art semantic matching models on both
static and temporal knowledge graph benchmarks."
Language Model Classifier Aligns Better with Physician Word Sensitivity than XGBoost on Readmission Prediction,0.0147813,"Traditional evaluation metrics for classification in natural language
processing such as accuracy and area under the curve fail to differentiate
between models with different predictive behaviors despite their similar
performance metrics. We introduce sensitivity score, a metric that scrutinizes
models' behaviors at the vocabulary level to provide insights into disparities
in their decision-making logic. We assess the sensitivity score on a set of
representative words in the test set using two classifiers trained for hospital
readmission classification with similar performance statistics. Our experiments
compare the decision-making logic of clinicians and classifiers based on rank
correlations of sensitivity scores. The results indicate that the language
model's sensitivity score aligns better with the professionals than the xgboost
classifier on tf-idf embeddings, which suggests that xgboost uses some spurious
features. Overall, this metric offers a novel perspective on assessing models'
robustness by quantifying their discrepancy with professional opinions. Our
code is available on GitHub (https://github.com/nyuolab/Model_Sensitivity)."
Approximating Constraint Manifolds Using Generative Models for Sampling-Based Constrained Motion Planning,0.0645846,"Sampling-based motion planning under task constraints is challenging because
the null-measure constraint manifold in the configuration space makes rejection
sampling extremely inefficient, if not impossible. This paper presents a
learning-based sampling strategy for constrained motion planning problems. We
investigate the use of two well-known deep generative models, the Conditional
Variational Autoencoder (CVAE) and the Conditional Generative Adversarial Net
(CGAN), to generate constraint-satisfying sample configurations. Instead of
precomputed graphs, we use generative models conditioned on constraint
parameters for approximating the constraint manifold. This approach allows for
the efficient drawing of constraint-satisfying samples online without any need
for modification of available sampling-based motion planning algorithms. We
evaluate the efficiency of these two generative models in terms of their
sampling accuracy and coverage of sampling distribution. Simulations and
experiments are also conducted for different constraint tasks on two robotic
platforms."
Joint covariate-alignment and concept-alignment: a framework for domain generalization,0.0133565,"In this paper, we propose a novel domain generalization (DG) framework based
on a new upper bound to the risk on the unseen domain. Particularly, our
framework proposes to jointly minimize both the covariate-shift as well as the
concept-shift between the seen domains for a better performance on the unseen
domain. While the proposed approach can be implemented via an arbitrary
combination of covariate-alignment and concept-alignment modules, in this work
we use well-established approaches for distributional alignment namely, Maximum
Mean Discrepancy (MMD) and covariance Alignment (CORAL), and use an Invariant
Risk Minimization (IRM)-based approach for concept alignment. Our numerical
results show that the proposed methods perform as well as or better than the
state-of-the-art for domain generalization on several data sets."
PINCH: An Adversarial Extraction Attack Framework for Deep Learning Models,0.0151029,"Adversarial extraction attacks constitute an insidious threat against Deep
Learning (DL) models in-which an adversary aims to steal the architecture,
parameters, and hyper-parameters of a targeted DL model. Existing extraction
attack literature have observed varying levels of attack success for different
DL models and datasets, yet the underlying cause(s) behind their susceptibility
often remain unclear, and would help facilitate creating secure DL systems. In
this paper we present PINCH: an efficient and automated extraction attack
framework capable of designing, deploying, and analyzing extraction attack
scenarios across heterogeneous hardware platforms. Using PINCH, we perform
extensive experimental evaluation of extraction attacks against 21 model
architectures to explore new extraction attack scenarios and further attack
staging. Our findings show (1) key extraction characteristics whereby
particular model configurations exhibit strong resilience against specific
attacks, (2) even partial extraction success enables further staging for other
adversarial attacks, and (3) equivalent stolen models uncover differences in
expressive power, yet exhibit similar captured knowledge."
RedApt: An Adaptor for wav2vec 2 Encoding \\ Faster and Smaller Speech Translation without Quality Compromise,0.0112745,"Pre-trained speech Transformers in speech translation (ST) have facilitated
state-of-the-art (SotA) results; yet, using such encoders is computationally
expensive. To improve this, we present a novel Reducer Adaptor block, RedApt,
that could be seamlessly integrated within any Transformer-based speech
encoding architecture. Integrating the pretrained wav2vec 2 speech encoder with
RedAptbrings 41% speedup, 33% memory reduction with 24% fewer FLOPs at
inference. To our positive surprise, our ST model with RedApt outperforms the
SotA architecture by an average of 0.68 BLEU score on 8 language pairs from
Must-C."
"Modeling Intention, Emotion and External World in Dialogue Systems",0.0430846,"Intention, emotion and action are important elements in human activities.
Modeling the interaction process between individuals by analyzing the
relationships between these elements is a challenging task. However, previous
work mainly focused on modeling intention and emotion independently, and
neglected of exploring the mutual relationships between intention and emotion.
In this paper, we propose a RelAtion Interaction Network (RAIN), consisting of
Intention Relation Module and Emotion Relation Module, to jointly model mutual
relationships and explicitly integrate historical intention information. The
experiments on the dataset show that our model can take full advantage of the
intention, emotion and action between individuals and achieve a remarkable
improvement over BERT-style baselines. Qualitative analysis verifies the
importance of the mutual interaction between the intention and emotion."
Arbitrary Point Cloud Upsampling with Spherical Mixture of Gaussians,0.12227,"Generating dense point clouds from sparse raw data benefits downstream 3D
understanding tasks, but existing models are limited to a fixed upsampling
ratio or to a short range of integer values. In this paper, we present
APU-SMOG, a Transformer-based model for Arbitrary Point cloud Upsampling (APU).
The sparse input is firstly mapped to a Spherical Mixture of Gaussians (SMOG)
distribution, from which an arbitrary number of points can be sampled. Then,
these samples are fed as queries to the Transformer decoder, which maps them
back to the target surface. Extensive qualitative and quantitative evaluations
show that APU-SMOG outperforms state-of-the-art fixed-ratio methods, while
effectively enabling upsampling with any scaling factor, including non-integer
values, with a single trained model. The code is available at
https://github.com/apusmog/apusmog/"
Semantic Segmentation in Learned Compressed Domain,0.0400202,"Most machine vision tasks (e.g., semantic segmentation) are based on images
encoded and decoded by image compression algorithms (e.g., JPEG). However,
these decoded images in the pixel domain introduce distortion, and they are
optimized for human perception, making the performance of machine vision tasks
suboptimal. In this paper, we propose a method based on the compressed domain
to improve segmentation tasks. i) A dynamic and a static channel selection
method are proposed to reduce the redundancy of compressed representations that
are obtained by encoding. ii) Two different transform modules are explored and
analyzed to help the compressed representation be transformed as the features
in the segmentation network. The experimental results show that we can save up
to 15.8\% bitrates compared with a state-of-the-art compressed domain-based
work while saving up to about 83.6\% bitrates and 44.8\% inference time
compared with the pixel domain-based method."
Task-Induced Representation Learning,0.0282793,"In this work, we evaluate the effectiveness of representation learning
approaches for decision making in visually complex environments. Representation
learning is essential for effective reinforcement learning (RL) from
high-dimensional inputs. Unsupervised representation learning approaches based
on reconstruction, prediction or contrastive learning have shown substantial
learning efficiency gains. Yet, they have mostly been evaluated in clean
laboratory or simulated settings. In contrast, real environments are visually
complex and contain substantial amounts of clutter and distractors.
Unsupervised representations will learn to model such distractors, potentially
impairing the agent's learning efficiency. In contrast, an alternative class of
approaches, which we call task-induced representation learning, leverages task
information such as rewards or demonstrations from prior tasks to focus on
task-relevant parts of the scene and ignore distractors. We investigate the
effectiveness of unsupervised and task-induced representation learning
approaches on four visually complex environments, from Distracting DMControl to
the CARLA driving simulator. For both, RL and imitation learning, we find that
representation learning generally improves sample efficiency on unseen tasks
even in visually complex scenes and that task-induced representations can
double learning efficiency compared to unsupervised alternatives. Code is
available at https://clvrai.com/tarp."
Style Matters! Investigating Linguistic Style in Online Communities,0.276514,"Content has historically been the primary lens used to study language in
online communities. This paper instead focuses on the linguistic style of
communities. While we know that individuals have distinguishable styles, here
we ask whether communities have distinguishable styles. Additionally, while
prior work has relied on a narrow definition of style, we employ a broad
definition involving 262 features to analyze the linguistic style of 9 online
communities from 3 social media platforms discussing politics, television and
travel. We find that communities indeed have distinct styles. Also, style is an
excellent predictor of group membership (F-score 0.952 and Accuracy 96.09%).
While on average it is statistically equivalent to predictions using content
alone, it is more resilient to reductions in training data."
Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control Approach,0.00998951,"In this paper we address the solution of the popular Wordle puzzle, using new
reinforcement learning methods, which apply more generally to adaptive control
of dynamic systems and to classes of Partially Observable Markov Decision
Process (POMDP) problems. These methods are based on approximation in value
space and the rollout approach, admit a straightforward implementation, and
provide improved performance over various heuristic approaches. For the Wordle
puzzle, they yield on-line solution strategies that are very close to optimal
at relatively modest computational cost. Our methods are viable for more
complex versions of Wordle and related search problems, for which an optimal
strategy would be impossible to compute. They are also applicable to a wide
range of adaptive sequential decision problems that involve an unknown or
frequently changing environment whose parameters are estimated on-line."
Human Response to an AI-Based Decision Support System: A User Study on the Effects of Accuracy and Bias,0.00279971,"Artificial Intelligence (AI) is increasingly used to build Decision Support
Systems (DSS) across many domains. This paper describes a series of experiments
designed to observe human response to different characteristics of a DSS such
as accuracy and bias, particularly the extent to which participants rely on the
DSS, and the performance they achieve. In our experiments, participants play a
simple online game inspired by so-called ""wildcat"" (i.e., exploratory) drilling
for oil. The landscape has two layers: a visible layer describing the costs
(terrain), and a hidden layer describing the reward (oil yield). Participants
in the control group play the game without receiving any assistance, while in
treatment groups they are assisted by a DSS suggesting places to drill. For
certain treatments, the DSS does not consider costs, but only rewards, which
introduces a bias that is observable by users. Between subjects, we vary the
accuracy and bias of the DSS, and observe the participants' total score, time
to completion, the extent to which they follow or ignore suggestions. We also
measure the acceptability of the DSS in an exit survey. Our results show that
participants tend to score better with the DSS, that the score increase is due
to users following the DSS advice, and related to the difficulty of the game
and the accuracy of the DSS. We observe that this setting elicits mostly
rational behavior from participants, who place a moderate amount of trust in
the DSS and show neither algorithmic aversion (under-reliance) nor automation
bias (over-reliance).However, their stated willingness to accept the DSS in the
exit survey seems less sensitive to the accuracy of the DSS than their
behavior, suggesting that users are only partially aware of the (lack of)
accuracy of the DSS."
Misspelling Semantics In Thai,0.135371,"User-generated content is full of misspellings. Rather than being just random
noise, we hypothesise that many misspellings contain hidden semantics that can
be leveraged for language understanding tasks. This paper presents a
fine-grained annotated corpus of misspelling in Thai, together with an analysis
of misspelling intention and its possible semantics to get a better
understanding of the misspelling patterns observed in the corpus. In addition,
we introduce two approaches to incorporate the semantics of misspelling:
Misspelling Average Embedding (MAE) and Misspelling Semantic Tokens (MST).
Experiments on a sentiment analysis task confirm our overall hypothesis:
additional semantics from misspelling can boost the micro F1 score up to
0.4-2%, while blindly normalising misspelling is harmful and suboptimal."
SSformer: A Lightweight Transformer for Semantic Segmentation,0.0138457,"It is well believed that Transformer performs better in semantic segmentation
compared to convolutional neural networks. Nevertheless, the original Vision
Transformer may lack of inductive biases of local neighborhoods and possess a
high time complexity. Recently, Swin Transformer sets a new record in various
vision tasks by using hierarchical architecture and shifted windows while being
more efficient. However, as Swin Transformer is specifically designed for image
classification, it may achieve suboptimal performance on dense prediction-based
segmentation task. Further, simply combing Swin Transformer with existing
methods would lead to the boost of model size and parameters for the final
segmentation model. In this paper, we rethink the Swin Transformer for semantic
segmentation, and design a lightweight yet effective transformer model, called
SSformer. In this model, considering the inherent hierarchical design of Swin
Transformer, we propose a decoder to aggregate information from different
layers, thus obtaining both local and global attentions. Experimental results
show the proposed SSformer yields comparable mIoU performance with
state-of-the-art models, while maintaining a smaller model size and lower
compute."
Multi-modal Video Chapter Generation,0.0444212,"Chapter generation becomes practical technique for online videos nowadays.
The chapter breakpoints enable users to quickly find the parts they want and
get the summative annotations. However, there is no public method and dataset
for this task. To facilitate the research along this direction, we introduce a
new dataset called Chapter-Gen, which consists of approximately 10k
user-generated videos with annotated chapter information. Our data collection
procedure is fast, scalable and does not require any additional manual
annotation. On top of this dataset, we design an effective baseline specificlly
for video chapters generation task. which captures two aspects of a
video,including visual dynamics and narration text. It disentangles local and
global video features for localization and title generation respectively. To
parse the long video efficiently, a skip sliding window mechanism is designed
to localize potential chapters. And a cross attention multi-modal fusion module
is developed to aggregate local features for title generation. Our experiments
demonstrate that the proposed framework achieves superior results over existing
methods which illustrate that the method design for similar task cannot be
transfered directly even after fine-tuning. Code and dataset are available at
https://github.com/czt117/MVCG."
Leveraging Trajectory Prediction for Pedestrian Video Anomaly Detection,0.0449405,"Video anomaly detection is a core problem in vision. Correctly detecting and
identifying anomalous behaviors in pedestrians from video data will enable
safety-critical applications such as surveillance, activity monitoring, and
human-robot interaction. In this paper, we propose to leverage trajectory
localization and prediction for unsupervised pedestrian anomaly event
detection. Different than previous reconstruction-based approaches, our
proposed framework rely on the prediction errors of normal and abnormal
pedestrian trajectories to detect anomalies spatially and temporally. We
present experimental results on real-world benchmark datasets on varying
timescales and show that our proposed trajectory-predictor-based anomaly
detection pipeline is effective and efficient at identifying anomalous
activities of pedestrians in videos. Code will be made available at
https://github.com/akanuasiegbu/Leveraging-Trajectory-Prediction-for-Pedestrian-Video-Anomaly-Detection."
Using Multiple Instance Learning to Build Multimodal Representations,0.0479948,"Image-text multimodal representation learning aligns data across modalities
and enables important medical applications, e.g., image classification, visual
grounding, and cross-modal retrieval. In this work, we establish a connection
between multimodal representation learning and multiple instance learning.
Based on this connection, we propose a generic framework for constructing
permutation-invariant score functions with many existing multimodal
representation learning approaches as special cases. Furthermore, we use the
framework to derive a novel contrastive learning approach and demonstrate that
our method achieves state-of-the-art results in several downstream tasks."
Booster-SHOT: Boosting Stacked Homography Transformations for Multiview Pedestrian Detection with Attention,0.00810099,"Improving multi-view aggregation is integral for multi-view pedestrian
detection, which aims to obtain a bird's-eye-view pedestrian occupancy map from
images captured through a set of calibrated cameras. Inspired by the success of
attention modules for deep neural networks, we first propose a Homography
Attention Module (HAM) which is shown to boost the performance of existing
end-to-end multiview detection approaches by utilizing a novel channel gate and
spatial gate. Additionally, we propose Booster-SHOT, an end-to-end
convolutional approach to multiview pedestrian detection incorporating our
proposed HAM as well as elements from previous approaches such as view-coherent
augmentation or stacked homography transformations. Booster-SHOT achieves 92.9%
and 94.2% for MODA on Wildtrack and MultiviewX respectively, outperforming the
state-of-the-art by 1.4% on Wildtrack and 0.5% on MultiviewX, achieving
state-of-the-art performance overall for standard evaluation metrics used in
multi-view pedestrian detection."
Online Dynamic Reliability Evaluation of Wind Turbines based on Drone-assisted Monitoring,0.0286378,"The offshore wind energy is increasingly becoming an attractive source of
energy due to having lower environmental impact. Effective operation and
maintenance that ensures the maximum availability of the energy generation
process using offshore facilities and minimal production cost are two key
factors to improve the competitiveness of this energy source over other
traditional sources of energy. Condition monitoring systems are widely used for
health management of offshore wind farms to have improved operation and
maintenance. Reliability of the wind farms are increasingly being evaluated to
aid in the maintenance process and thereby to improve the availability of the
farms. However, much of the reliability analysis is performed offline based on
statistical data. In this article, we propose a drone-assisted monitoring based
method for online reliability evaluation of wind turbines. A blade system of a
wind turbine is used as an illustrative example to demonstrate the proposed
approach."
Scan2Part: Fine-grained and Hierarchical Part-level Understanding of Real-World 3D Scans,0.0207504,"We propose Scan2Part, a method to segment individual parts of objects in
real-world, noisy indoor RGB-D scans. To this end, we vary the part hierarchies
of objects in indoor scenes and explore their effect on scene understanding
models. Specifically, we use a sparse U-Net-based architecture that captures
the fine-scale detail of the underlying 3D scan geometry by leveraging a
multi-scale feature hierarchy. In order to train our method, we introduce the
Scan2Part dataset, which is the first large-scale collection providing detailed
semantic labels at the part level in the real-world setting. In total, we
provide 242,081 correspondences between 53,618 PartNet parts of 2,477 ShapeNet
objects and 1,506 ScanNet scenes, at two spatial resolutions of 2 cm$^3$ and 5
cm$^3$. As output, we are able to predict fine-grained per-object part labels,
even when the geometry is coarse or partially missing."
A gentle introduction to Quantum Natural Language Processing,0.0261484,"The main goal of this master's thesis is to introduce Quantum Natural
Language Processing (QNLP) in a way understandable by both the NLP engineer and
the quantum computing practitioner. QNLP is a recent application of quantum
computing that aims at representing sentences' meaning as vectors encoded into
quantum computers. To achieve this, the distributional meaning of words is
extended by the compositional meaning of sentences (DisCoCat model) : the
vectors representing words' meanings are composed through the syntactic
structure of the sentence. This is done using an algorithm based on tensor
products. We see that this algorithm is inefficient on classical computers but
scales well using quantum circuits. After exposing the practical details of its
implementation, we go through three use-cases."
Feature Refinement to Improve High Resolution Image Inpainting,0.0709817,"In this paper, we address the problem of degradation in inpainting quality of
neural networks operating at high resolutions. Inpainting networks are often
unable to generate globally coherent structures at resolutions higher than
their training set. This is partially attributed to the receptive field
remaining static, despite an increase in image resolution. Although downscaling
the image prior to inpainting produces coherent structure, it inherently lacks
detail present at higher resolutions. To get the best of both worlds, we
optimize the intermediate featuremaps of a network by minimizing a multiscale
consistency loss at inference. This runtime optimization improves the
inpainting results and establishes a new state-of-the-art for high resolution
inpainting. Code is available at:
https://github.com/geomagical/lama-with-refiner/tree/refinement."
A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges,0.0207768,"Data-enabled cities are recently accelerated and enhanced with automated
learning for improved Smart Cities applications. In the context of an Internet
of Things (IoT) ecosystem, the data communication is frequently costly,
inefficient, not scalable and lacks security. Federated Learning (FL) plays a
pivotal role in providing privacy-preserving and communication efficient
Machine Learning (ML) frameworks. In this paper we evaluate the feasibility of
FL in the context of a Smart Cities Street Light Monitoring application. FL is
evaluated against benchmarks of centralised and (fully) personalised machine
learning techniques for the classification task of the lampposts operation.
Incorporating FL in such a scenario shows minimal performance reduction in
terms of the classification task, but huge improvements in the communication
cost and the privacy preserving. These outcomes strengthen FL's viability and
potential for IoT applications."
SimCURL: Simple Contrastive User Representation Learning from Command Sequences,-1.0,"User modeling is crucial to understanding user behavior and essential for
improving user experience and personalized recommendations. When users interact
with software, vast amounts of command sequences are generated through logging
and analytics systems. These command sequences contain clues to the users'
goals and intents. However, these data modalities are highly unstructured and
unlabeled, making it difficult for standard predictive systems to learn from.
We propose SimCURL, a simple yet effective contrastive self-supervised deep
learning framework that learns user representation from unlabeled command
sequences. Our method introduces a user-session network architecture, as well
as session dropout as a novel way of data augmentation. We train and evaluate
our method on a real-world command sequence dataset of more than half a billion
commands. Our method shows significant improvement over existing methods when
the learned representation is transferred to downstream tasks such as
experience and expertise classification."
A Contrastive Objective for Learning Disentangled Representations,0.102877,"Learning representations of images that are invariant to sensitive or
unwanted attributes is important for many tasks including bias removal and
cross domain retrieval. Here, our objective is to learn representations that
are invariant to the domain (sensitive attribute) for which labels are
provided, while being informative over all other image attributes, which are
unlabeled. We present a new approach, proposing a new domain-wise contrastive
objective for ensuring invariant representations. This objective crucially
restricts negative image pairs to be drawn from the same domain, which enforces
domain invariance whereas the standard contrastive objective does not. This
domain-wise objective is insufficient on its own as it suffers from shortcut
solutions resulting in feature suppression. We overcome this issue by a
combination of a reconstruction constraint, image augmentations and
initialization with pre-trained weights. Our analysis shows that the choice of
augmentations is important, and that a misguided choice of augmentations can
harm the invariance and informativeness objectives. In an extensive evaluation,
our method convincingly outperforms the state-of-the-art in terms of
representation invariance, representation informativeness, and training speed.
Furthermore, we find that in some cases our method can achieve excellent
results even without the reconstruction constraint, leading to a much faster
and resource efficient training."
"Please, Don't Forget the Difference and the Confidence Interval when Seeking for the State-of-the-Art Status",0.00352352,"This paper argues for the widest possible use of bootstrap confidence
intervals for comparing NLP system performances instead of the state-of-the-art
status (SOTA) and statistical significance testing. Their main benefits are to
draw attention to the difference in performance between two systems and to help
assessing the degree of superiority of one system over another. Two cases
studies, one comparing several systems and the other based on a K-fold
cross-validation procedure, illustrate these benefits. A python module for
obtaining these confidence intervals as well as a second function implementing
the Fisher-Pitman test for paired samples are freely available on PyPi."
WeatherFusionNet: Predicting Precipitation from Satellite Data,-1.0,"The short-term prediction of precipitation is critical in many areas of life.
Recently, a large body of work was devoted to forecasting radar reflectivity
images. The radar images are available only in areas with ground weather
radars. Thus, we aim to predict high-resolution precipitation from
lower-resolution satellite radiance images. A neural network called
WeatherFusionNet is employed to predict severe rain up to eight hours in
advance. WeatherFusionNet is a U-Net architecture that fuses three different
ways to process the satellite data; predicting future satellite frames,
extracting rain information from the current frames, and using the input
sequence directly. Using the presented method, we achieved 1st place in the
NeurIPS 2022 Weather4Cast Core challenge. The code and trained parameters are
available at \url{https://github.com/Datalab-FIT-CTU/weather4cast-2022}."
Explicit Occlusion Reasoning for Multi-person 3D Human Pose Estimation,0.106007,"Occlusion poses a great threat to monocular multi-person 3D human pose
estimation due to large variability in terms of the shape, appearance, and
position of occluders. While existing methods try to handle occlusion with pose
priors/constraints, data augmentation, or implicit reasoning, they still fail
to generalize to unseen poses or occlusion cases and may make large mistakes
when multiple people are present. Inspired by the remarkable ability of humans
to infer occluded joints from visible cues, we develop a method to explicitly
model this process that significantly improves bottom-up multi-person human
pose estimation with or without occlusions. First, we split the task into two
subtasks: visible keypoints detection and occluded keypoints reasoning, and
propose a Deeply Supervised Encoder Distillation (DSED) network to solve the
second one. To train our model, we propose a Skeleton-guided human Shape
Fitting (SSF) approach to generate pseudo occlusion labels on the existing
datasets, enabling explicit occlusion reasoning. Experiments show that
explicitly learning from occlusions improves human pose estimation. In
addition, exploiting feature-level information of visible joints allows us to
reason about occluded joints more accurately. Our method outperforms both the
state-of-the-art top-down and bottom-up methods on several benchmarks."
Crowdsourcing Relative Rankings of Multi-Word Expressions: Experts versus Non-Experts,0.0509888,"In this study we investigate to which degree experts and non-experts agree on
questions of difficulty in a crowdsourcing experiment. We ask non-experts
(second language learners of Swedish) and two groups of experts (teachers of
Swedish as a second/foreign language and CEFR experts) to rank multi-word
expressions in a crowdsourcing experiment. We find that the resulting rankings
by all the three tested groups correlate to a very high degree, which suggests
that judgments produced in a comparative setting are not influenced by
professional insights into Swedish as a second language."
Team VI-I2R Technical Report on EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2021,0.0154179,"In this report, we present the technical details of our approach to the
EPIC-KITCHENS-100 Unsupervised Domain Adaptation (UDA) Challenge for Action
Recognition. The EPIC-KITCHENS-100 dataset consists of daily kitchen activities
focusing on the interaction between human hands and their surrounding objects.
It is very challenging to accurately recognize these fine-grained activities,
due to the presence of distracting objects and visually similar action classes,
especially in the unlabelled target domain. Based on an existing method for
video domain adaptation, i.e., TA3N, we propose to learn hand-centric features
by leveraging the hand bounding box information for UDA on fine-grained action
recognition. This helps reduce the distraction from background as well as
facilitate the learning of domain-invariant features. To achieve high quality
hand localization, we adopt an uncertainty-aware domain adaptation network,
i.e., MEAA, to train a domain-adaptive hand detector, which only uses very
limited hand bounding box annotations in the source domain but can generalize
well to the unlabelled target domain. Our submission achieved the 1st place in
terms of top-1 action recognition accuracy, using only RGB and optical flow
modalities as input."
Searching for fingerspelled content in American Sign Language,0.0117905,"Natural language processing for sign language video - including tasks like
recognition, translation, and search - is crucial for making artificial
intelligence technologies accessible to deaf individuals, and is gaining
research interest in recent years. In this paper, we address the problem of
searching for fingerspelled key-words or key phrases in raw sign language
videos. This is an important task since significant content in sign language is
often conveyed via fingerspelling, and to our knowledge the task has not been
studied before. We propose an end-to-end model for this task, FSS-Net, that
jointly detects fingerspelling and matches it to a text sequence. Our
experiments, done on a large public dataset of ASL fingerspelling in the wild,
show the importance of fingerspelling detection as a component of a search and
retrieval model. Our model significantly outperforms baseline methods adapted
from prior work on related tasks"
A dataset of ant colonies motion trajectories in indoor and outdoor scenes for social cluster behavior study,0.0265708,"Motion and interaction of social insects (such as ants) have been studied by
many researchers to understand the clustering mechanism. Most studies in the
field of ant behavior have only focused on indoor environments, while outdoor
environments are still underexplored. In this paper, we collect 10 videos of
ant colonies from different indoor and outdoor scenes. And we develop an image
sequence marking software named VisualMarkData, which enables us to provide
annotations of ants in the video. In all 5354 frames, the location information
and the identification number of each ant are recorded for a total of 712 ants
and 114112 annotations. Moreover, we provide visual analysis tools to assess
and validate the technical quality and reproducibility of our data. It is hoped
that this dataset will contribute to a deeper exploration on the behavior of
the ant colony."
Few-Shot Cross-lingual Transfer for Coarse-grained De-identification of Code-Mixed Clinical Texts,0.0893511,"Despite the advances in digital healthcare systems offering curated
structured knowledge, much of the critical information still lies in large
volumes of unlabeled and unstructured clinical texts. These texts, which often
contain protected health information (PHI), are exposed to information
extraction tools for downstream applications, risking patient identification.
Existing works in de-identification rely on using large-scale annotated corpora
in English, which often are not suitable in real-world multilingual settings.
Pre-trained language models (LM) have shown great potential for cross-lingual
transfer in low-resource settings. In this work, we empirically show the
few-shot cross-lingual transfer property of LMs for named entity recognition
(NER) and apply it to solve a low-resource and real-world challenge of
code-mixed (Spanish-Catalan) clinical notes de-identification in the stroke
domain. We annotate a gold evaluation dataset to assess few-shot setting
performance where we only use a few hundred labeled examples for training. Our
model improves the zero-shot F1-score from 73.7% to 91.2% on the gold
evaluation set when adapting Multilingual BERT (mBERT) (Devlin et al., 2019)
from the MEDDOCAN (Marimon et al., 2019) corpus with our few-shot cross-lingual
target corpus. When generalized to an out-of-sample test set, the best model
achieves a human-evaluation F1-score of 97.2%."
Ethics for Digital Medicine: A Path for Ethical Emerging Medical IoT Design,0.0910585,"The dawn of the digital medicine era, ushered in by increasingly powerful
embedded systems and Internet of Things (IoT) computing devices, is creating
new therapies and biomedical solutions that promise to positively transform our
quality of life. However, the digital medicine revolution also creates
unforeseen and complex ethical, regulatory, and societal issues. In this
article, we reflect on the ethical challenges facing digital medicine. We
discuss the perils of ethical oversights in medical devices, and the role of
professional codes and regulatory oversight towards the ethical design,
deployment, and operation of digital medicine devices that safely and
effectively meet the needs of patients. We advocate for an ensemble approach of
intensive education, programmable ethical behaviors, and ethical analysis
frameworks, to prevent mishaps and sustain ethical innovation, design, and
lifecycle management of emerging digital medicine devices."
Mitigating Both Covariate and Conditional Shift for Domain Generalization,0.00892425,"Domain generalization (DG) aims to learn a model on several source domains,
hoping that the model can generalize well to unseen target domains. The
distribution shift between domains contains the covariate shift and conditional
shift, both of which the model must be able to handle for better
generalizability. In this paper, a novel DG method is proposed to deal with the
distribution shift via Visual Alignment and Uncertainty-guided belief Ensemble
(VAUE). Specifically, for the covariate shift, a visual alignment module is
designed to align the distribution of image style to a common empirical
Gaussian distribution so that the covariate shift can be eliminated in the
visual space. For the conditional shift, we adopt an uncertainty-guided belief
ensemble strategy based on the subjective logic and Dempster-Shafer theory. The
conditional distribution given a test sample is estimated by the dynamic
combination of that of source domains. Comprehensive experiments are conducted
to demonstrate the superior performance of the proposed method on four widely
used datasets, i.e., Office-Home, VLCS, TerraIncognita, and PACS."
Design and Development of Rule-based open-domain Question-Answering System on SQuAD v2.0 Dataset,0.0651143,"Human mind is the palace of curious questions that seek answers.
Computational resolution of this challenge is possible through Natural Language
Processing techniques. Statistical techniques like machine learning and deep
learning require a lot of data to train and despite that they fail to tap into
the nuances of language. Such systems usually perform best on close-domain
datasets. We have proposed development of a rule-based open-domain
question-answering system which is capable of answering questions of any domain
from a corresponding context passage. We have used 1000 questions from SQuAD
2.0 dataset for testing the developed system and it gives satisfactory results.
In this paper, we have described the structure of the developed system and have
analyzed the performance."
The Inverse Problem for Argumentation Gradual Semantics,0.0249415,"Gradual semantics with abstract argumentation provide each argument with a
score reflecting its acceptability, i.e. how ""much"" it is attacked by other
arguments. Many different gradual semantics have been proposed in the
literature, each following different principles and producing different
argument rankings. A sub-class of such semantics, the so-called weighted
semantics, takes, in addition to the graph structure, an initial set of weights
over the arguments as input, with these weights affecting the resultant
argument ranking. In this work, we consider the inverse problem over such
weighted semantics. That is, given an argumentation framework and a desired
argument ranking, we ask whether there exist initial weights such that a
particular semantics produces the given ranking. The contribution of this paper
are: (1) an algorithm to answer this problem, (2) a characterisation of the
properties that a gradual semantics must satisfy for the algorithm to operate,
and (3) an empirical evaluation of the proposed algorithm."
What do Toothbrushes do in the Kitchen? How Transformers Think our World is Structured,0.0311228,"Transformer-based models are now predominant in NLP. They outperform
approaches based on static models in many respects. This success has in turn
prompted research that reveals a number of biases in the language models
generated by transformers. In this paper we utilize this research on biases to
investigate to what extent transformer-based language models allow for
extracting knowledge about object relations (X occurs in Y; X consists of Z;
action A involves using X). To this end, we compare contextualized models with
their static counterparts. We make this comparison dependent on the application
of a number of similarity measures and classifiers. Our results are threefold:
Firstly, we show that the models combined with the different similarity
measures differ greatly in terms of the amount of knowledge they allow for
extracting. Secondly, our results suggest that similarity measures perform much
worse than classifier-based approaches. Thirdly, we show that, surprisingly,
static models perform almost as well as contextualized models -- in some cases
even better."
Neural Space-filling Curves,0.0327947,"We present Neural Space-filling Curves (SFCs), a data-driven approach to
infer a context-based scan order for a set of images. Linear ordering of pixels
forms the basis for many applications such as video scrambling, compression,
and auto-regressive models that are used in generative modeling for images.
Existing algorithms resort to a fixed scanning algorithm such as Raster scan or
Hilbert scan. Instead, our work learns a spatially coherent linear ordering of
pixels from the dataset of images using a graph-based neural network. The
resulting Neural SFC is optimized for an objective suitable for the downstream
task when the image is traversed along with the scan line order. We show the
advantage of using Neural SFCs in downstream applications such as image
compression. Code and additional results will be made available at
https://hywang66.github.io/publication/neuralsfc."
Multi-Phase Multi-Objective Dexterous Manipulation with Adaptive Hierarchical Curriculum,0.0,"Dexterous manipulation tasks usually have multiple objectives, and the
priorities of these objectives may vary at different phases of a manipulation
task. Varying priority makes a robot hardly or even failed to learn an optimal
policy with a deep reinforcement learning (DRL) method. To solve this problem,
we develop a novel Adaptive Hierarchical Reward Mechanism (AHRM) to guide the
DRL agent to learn manipulation tasks with multiple prioritized objectives. The
AHRM can determine the objective priorities during the learning process and
update the reward hierarchy to adapt to the changing objective priorities at
different phases. The proposed method is validated in a multi-objective
manipulation task with a JACO robot arm in which the robot needs to manipulate
a target with obstacles surrounded. The simulation and physical experiment
results show that the proposed method improved robot learning in task
performance and learning efficiency."
Box Supervised Video Segmentation Proposal Network,0.0135715,"Video Object Segmentation (VOS) has been targeted by various fully-supervised
and self-supervised approaches. While fully-supervised methods demonstrate
excellent results, self-supervised ones, which do not use pixel-level ground
truth, attract much attention. However, self-supervised approaches pose a
significant performance gap. Box-level annotations provide a balanced
compromise between labeling effort and result quality for image segmentation
but have not been exploited for the video domain. In this work, we propose a
box-supervised video object segmentation proposal network, which takes
advantage of intrinsic video properties. Our method incorporates object motion
in the following way: first, motion is computed using a bidirectional temporal
difference and a novel bounding box-guided motion compensation. Second, we
introduce a novel motion-aware affinity loss that encourages the network to
predict positive pixel pairs if they share similar motion and color. The
proposed method outperforms the state-of-the-art self-supervised benchmark by
16.4% and 6.9% $\mathcal{J}$ &$\mathcal{F}$ score and the majority of fully
supervised methods on the DAVIS and Youtube-VOS dataset without imposing
network architectural specifications. We provide extensive tests and ablations
on the datasets, demonstrating the robustness of our method."
Revisiting Grammatical Error Correction Evaluation and Beyond,0.289992,"Pretraining-based (PT-based) automatic evaluation metrics (e.g., BERTScore
and BARTScore) have been widely used in several sentence generation tasks
(e.g., machine translation and text summarization) due to their better
correlation with human judgments over traditional overlap-based methods.
Although PT-based methods have become the de facto standard for training
grammatical error correction (GEC) systems, GEC evaluation still does not
benefit from pretrained knowledge. This paper takes the first step towards
understanding and improving GEC evaluation with pretraining. We first find that
arbitrarily applying PT-based metrics to GEC evaluation brings unsatisfactory
correlation results because of the excessive attention to inessential systems
outputs (e.g., unchanged parts). To alleviate the limitation, we propose a
novel GEC evaluation metric to achieve the best of both worlds, namely PT-M2
which only uses PT-based metrics to score those corrected parts. Experimental
results on the CoNLL14 evaluation task show that PT-M2 significantly
outperforms existing methods, achieving a new state-of-the-art result of 0.949
Pearson correlation. Further analysis reveals that PT-M2 is robust to evaluate
competitive GEC systems. Source code and scripts are freely available at
https://github.com/pygongnlp/PT-M2."
Detecting Shortcuts in Medical Images -- A Case Study in Chest X-rays,0.199263,"The availability of large public datasets and the increased amount of
computing power have shifted the interest of the medical community to
high-performance algorithms. However, little attention is paid to the quality
of the data and their annotations. High performance on benchmark datasets may
be reported without considering possible shortcuts or artifacts in the data,
besides, models are not tested on subpopulation groups. With this work, we aim
to raise awareness about shortcuts problems. We validate previous findings, and
present a case study on chest X-rays using two publicly available datasets. We
share annotations for a subset of pneumothorax images with drains. We conclude
with general recommendations for medical image classification."
FormLM: Recommending Creation Ideas for Online Forms by Modelling Semantic and Structural Information,0.060499,"Online forms are widely used to collect data from human and have a
multi-billion market. Many software products provide online services for
creating semi-structured forms where questions and descriptions are organized
by pre-defined structures. However, the design and creation process of forms is
still tedious and requires expert knowledge. To assist form designers, in this
work we present FormLM to model online forms (by enhancing pre-trained language
model with form structural information) and recommend form creation ideas
(including question / options recommendations and block type suggestion). For
model training and evaluation, we collect the first public online form dataset
with 62K online forms. Experiment results show that FormLM significantly
outperforms general-purpose language models on all tasks, with an improvement
by 4.71 on Question Recommendation and 10.6 on Block Type Suggestion in terms
of ROUGE-1 and Macro-F1, respectively."
Split-U-Net: Preventing Data Leakage in Split Learning for Collaborative Multi-Modal Brain Tumor Segmentation,0.049545,"Split learning (SL) has been proposed to train deep learning models in a
decentralized manner. For decentralized healthcare applications with vertical
data partitioning, SL can be beneficial as it allows institutes with
complementary features or images for a shared set of patients to jointly
develop more robust and generalizable models. In this work, we propose
""Split-U-Net"" and successfully apply SL for collaborative biomedical image
segmentation. Nonetheless, SL requires the exchanging of intermediate
activation maps and gradients to allow training models across different feature
spaces, which might leak data and raise privacy concerns. Therefore, we also
quantify the amount of data leakage in common SL scenarios for biomedical image
segmentation and provide ways to counteract such leakage by applying
appropriate defense strategies."
Multi-task Safe Reinforcement Learning for Navigating Intersections in Dense Traffic,0.0684253,"Multi-task intersection navigation including the unprotected turning left,
turning right, and going straight in dense traffic is still a challenging task
for autonomous driving. For the human driver, the negotiation skill with other
interactive vehicles is the key to guarantee safety and efficiency. However, it
is hard to balance the safety and efficiency of the autonomous vehicle for
multi-task intersection navigation. In this paper, we formulate a multi-task
safe reinforcement learning with social attention to improve the safety and
efficiency when interacting with other traffic participants. Specifically, the
social attention module is used to focus on the states of negotiation vehicles.
In addition, a safety layer is added to the multi-task reinforcement learning
framework to guarantee safe negotiation. We compare the experiments in the
simulator SUMO with abundant traffic flows and CARLA with high-fidelity vehicle
models, which both show that the proposed algorithm can improve safety with
consistent traffic efficiency for multi-task intersection navigation."
Multimodality Multi-Lead ECG Arrhythmia Classification using Self-Supervised Learning,0.0273177,"Electrocardiogram (ECG) signal is one of the most effective sources of
information mainly employed for the diagnosis and prediction of cardiovascular
diseases (CVDs) connected with the abnormalities in heart rhythm. Clearly,
single modality ECG (i.e. time series) cannot convey its complete
characteristics, thus, exploiting both time and time-frequency modalities in
the form of time-series data and spectrogram is needed. Leveraging the
cutting-edge self-supervised learning (SSL) technique on unlabeled data, we
propose SSL-based multimodality ECG classification. Our proposed network
follows SSL learning paradigm and consists of two modules corresponding to
pre-stream task, and down-stream task, respectively. In the SSL-pre-stream
task, we utilize self-knowledge distillation (KD) techniques with no labeled
data, on various transformations and in both time and frequency domains. In the
down-stream task, which is trained on labeled data, we propose a gate fusion
mechanism to fuse information from multimodality.To evaluate the effectiveness
of our approach, ten-fold cross validation on the 12-lead PhysioNet 2020
dataset has been conducted."
Pessimistic Off-Policy Optimization for Learning to Rank,0.00926374,"Off-policy learning is a framework for optimizing policies without deploying
them, using data collected by another policy. In recommender systems, this is
especially challenging due to the imbalance in logged data: some items are
recommended and thus logged more frequently than others. This is further
perpetuated when recommending a list of items, as the action space is
combinatorial. To address this challenge, we study pessimistic off-policy
optimization for learning to rank. The key idea is to compute lower confidence
bounds on parameters of click models and then return the list with the highest
pessimistic estimate of its value. This approach is computationally efficient
and we analyze it. We study its Bayesian and frequentist variants, and overcome
the limitation of unknown prior by incorporating empirical Bayes. To show the
empirical effectiveness of our approach, we compare it to off-policy optimizers
that use inverse propensity scores or neglect uncertainty. Our approach
outperforms all baselines, is robust, and is also general."
Consistency driven Sequential Transformers Attention Model for Partially Observable Scenes,0.0450168,"Most hard attention models initially observe a complete scene to locate and
sense informative glimpses, and predict class-label of a scene based on
glimpses. However, in many applications (e.g., aerial imaging), observing an
entire scene is not always feasible due to the limited time and resources
available for acquisition. In this paper, we develop a Sequential Transformers
Attention Model (STAM) that only partially observes a complete image and
predicts informative glimpse locations solely based on past glimpses. We design
our agent using DeiT-distilled and train it with a one-step actor-critic
algorithm. Furthermore, to improve classification performance, we introduce a
novel training objective, which enforces consistency between the class
distribution predicted by a teacher model from a complete image and the class
distribution predicted by our agent using glimpses. When the agent senses only
4% of the total image area, the inclusion of the proposed consistency loss in
our training objective yields 3% and 8% higher accuracy on ImageNet and fMoW
datasets, respectively. Moreover, our agent outperforms previous
state-of-the-art by observing nearly 27% and 42% fewer pixels in glimpses on
ImageNet and fMoW."
Enhanced Vehicle Re-identification for ITS: A Feature Fusion approach using Deep Learning,0.0163673,"In recent years, the development of robust Intelligent transportation systems
(ITS) is tackled across the globe to provide better traffic efficiency by
reducing frequent traffic problems. As an application of ITS, vehicle
re-identification has gained ample interest in the domain of computer vision
and robotics. Convolutional neural network (CNN) based methods are developed to
perform vehicle re-identification to address key challenges such as occlusion,
illumination change, scale, etc. The advancement of transformers in computer
vision has opened an opportunity to explore the re-identification process
further to enhance performance. In this paper, a framework is developed to
perform the re-identification of vehicles across CCTV cameras. To perform
re-identification, the proposed framework fuses the vehicle representation
learned using a CNN and a transformer model. The framework is tested on a
dataset that contains 81 unique vehicle identities observed across 20 CCTV
cameras. From the experiments, the fused vehicle re-identification framework
yields an mAP of 61.73% which is significantly better when compared with the
standalone CNN or transformer model."
ANAct: Adaptive Normalization for Activation Functions,0.0122596,"In this paper, we investigate the negative effect of activation functions on
forward and backward propagation and how to counteract this effect. First, We
examine how activation functions affect the forward and backward propagation of
neural networks and derive a general form for gradient variance that extends
the previous work in this area. We try to use mini-batch statistics to
dynamically update the normalization factor to ensure the normalization
property throughout the training process, rather than only accounting for the
state of the neural network after weight initialization. Second, we propose
ANAct, a method that normalizes activation functions to maintain consistent
gradient variance across layers and demonstrate its effectiveness through
experiments. We observe that the convergence rate is roughly related to the
normalization property. We compare ANAct with several common activation
functions on CNNs and residual networks and show that ANAct consistently
improves their performance. For instance, normalized Swish achieves 1.4\%
higher top-1 accuracy than vanilla Swish on ResNet50 with the Tiny ImageNet
dataset and more than 1.2\% higher with CIFAR-100."
Variable Functioning and Its Application to Large Scale Steel Frame Design Optimization,0.0,"To solve complex real-world problems, heuristics and concept-based approaches
can be used in order to incorporate information into the problem. In this
study, a concept-based approach called variable functioning Fx is introduced to
reduce the optimization variables and narrow down the search space. In this
method, the relationships among one or more subset of variables are defined
with functions using information prior to optimization; thus, instead of
modifying the variables in the search process, the function variables are
optimized. By using problem structure analysis technique and engineering expert
knowledge, the $Fx$ method is used to enhance the steel frame design
optimization process as a complex real-world problem. The proposed approach is
coupled with particle swarm optimization and differential evolution algorithms
and used for three case studies. The algorithms are applied to optimize the
case studies by considering the relationships among column cross-section areas.
The results show that $Fx$ can significantly improve both the convergence rate
and the final design of a frame structure, even if it is only used for seeding."
Compositional Generalization Requires Compositional Parsers,0.045046,"A rapidly growing body of research on compositional generalization
investigates the ability of a semantic parser to dynamically recombine
linguistic elements seen in training into unseen sequences. We present a
systematic comparison of sequence-to-sequence models and models guided by
compositional principles on the recent COGS corpus (Kim and Linzen, 2020).
Though seq2seq models can perform well on lexical tasks, they perform with
near-zero accuracy on structural generalization tasks that require novel
syntactic structures; this holds true even when they are trained to predict
syntax instead of semantics. In contrast, compositional models achieve
near-perfect accuracy on structural generalization; we present new results
confirming this from the AM parser (Groschwitz et al., 2021). Our findings show
structural generalization is a key measure of compositional generalization and
requires models that are aware of complex structure."
Debugging using Orthogonal Gradient Descent,0.00334628,"In this report we consider the following problem: Given a trained model that
is partially faulty, can we correct its behaviour without having to train the
model from scratch? In other words, can we ``debug"" neural networks similar to
how we address bugs in our mathematical models and standard computer code. We
base our approach on the hypothesis that debugging can be treated as a two-task
continual learning problem. In particular, we employ a modified version of a
continual learning algorithm called Orthogonal Gradient Descent (OGD) to
demonstrate, via two simple experiments on the MNIST dataset, that we can
in-fact \textit{unlearn} the undesirable behaviour while retaining the general
performance of the model, and we can additionally \textit{relearn} the
appropriate behaviour, both without having to train the model from scratch."
Improving Low-Resource Question Answering using Active Learning in Multiple Stages,0.00479158,"Neural approaches have become very popular in the domain of Question
Answering, however they require a large amount of annotated data. Furthermore,
they often yield very good performance but only in the domain they were trained
on. In this work we propose a novel approach that combines data augmentation
via question-answer generation with Active Learning to improve performance in
low resource settings, where the target domains are diverse in terms of
difficulty and similarity to the source domain. We also investigate Active
Learning for question answering in different stages, overall reducing the
annotation effort of humans. For this purpose, we consider target domains in
realistic settings, with an extremely low amount of annotated samples but with
many unlabeled documents, which we assume can be obtained with little effort.
Additionally, we assume sufficient amount of labeled data from the source
domain is available. We perform extensive experiments to find the best setup
for incorporating domain experts. Our findings show that our novel approach,
where humans are incorporated as early as possible in the process, boosts
performance in the low-resource, domain-specific setting, allowing for
low-labeling-effort question answering systems in new, specialized domains.
They further demonstrate how human annotation affects the performance of QA
depending on the stage it is performed."
Knowledge-Grounded Conversational Data Augmentation with Generative Conversational Networks,0.0147488,"While rich, open-domain textual data are generally available and may include
interesting phenomena (humor, sarcasm, empathy, etc.) most are designed for
language processing tasks, and are usually in a non-conversational format. In
this work, we take a step towards automatically generating conversational data
using Generative Conversational Networks, aiming to benefit from the breadth of
available language and knowledge data, and train open domain social
conversational agents. We evaluate our approach on conversations with and
without knowledge on the Topical Chat dataset using automatic metrics and human
evaluators. Our results show that for conversations without knowledge
grounding, GCN can generalize from the seed data, producing novel conversations
that are less relevant but more engaging and for knowledge-grounded
conversations, it can produce more knowledge-focused, fluent, and engaging
conversations. Specifically, we show that for open-domain conversations with
10\% of seed data, our approach performs close to the baseline that uses 100%
of the data, while for knowledge-grounded conversations, it achieves the same
using only 1% of the data, on human ratings of engagingness, fluency, and
relevance."
Seq2Seq Surrogates of Epidemic Models to Facilitate Bayesian Inference,0.0154675,"Epidemic models are powerful tools in understanding infectious disease.
However, as they increase in size and complexity, they can quickly become
computationally intractable. Recent progress in modelling methodology has shown
that surrogate models can be used to emulate complex epidemic models with a
high-dimensional parameter space. We show that deep sequence-to-sequence
(seq2seq) models can serve as accurate surrogates for complex epidemic models
with sequence based model parameters, effectively replicating seasonal and
long-term transmission dynamics. Once trained, our surrogate can predict
scenarios a several thousand times faster than the original model, making them
ideal for policy exploration. We demonstrate that replacing a traditional
epidemic model with a learned simulator facilitates robust Bayesian inference."
"Can counterfactual explanations of AI systems' predictions skew lay users' causal intuitions about the world? If so, can we correct for that?",0.135174,"Counterfactual (CF) explanations have been employed as one of the modes of
explainability in explainable AI-both to increase the transparency of AI
systems and to provide recourse. Cognitive science and psychology, however,
have pointed out that people regularly use CFs to express causal relationships.
Most AI systems are only able to capture associations or correlations in data
so interpreting them as casual would not be justified. In this paper, we
present two experiment (total N = 364) exploring the effects of CF explanations
of AI system's predictions on lay people's causal beliefs about the real world.
In Experiment 1 we found that providing CF explanations of an AI system's
predictions does indeed (unjustifiably) affect people's causal beliefs
regarding factors/features the AI uses and that people are more likely to view
them as causal factors in the real world. Inspired by the literature on
misinformation and health warning messaging, Experiment 2 tested whether we can
correct for the unjustified change in causal beliefs. We found that pointing
out that AI systems capture correlations and not necessarily causal
relationships can attenuate the effects of CF explanations on people's causal
beliefs."
Hyperplane bounds for neural feature mappings,0.0104288,"Deep learning methods minimise the empirical risk using loss functions such
as the cross entropy loss. When minimising the empirical risk, the
generalisation of the learnt function still depends on the performance on the
training data, the Vapnik-Chervonenkis(VC)-dimension of the function and the
number of training examples. Neural networks have a large number of parameters,
which correlates with their VC-dimension that is typically large but not
infinite, and typically a large number of training instances are needed to
effectively train them.
  In this work, we explore how to optimize feature mappings using neural
network with the intention to reduce the effective VC-dimension of the
hyperplane found in the space generated by the mapping. An interpretation of
the results of this study is that it is possible to define a loss that controls
the VC-dimension of the separating hyperplane. We evaluate this approach and
observe that the performance when using this method improves when the size of
the training set is small."
Which Student is Best? A Comprehensive Knowledge Distillation Exam for Task-Specific BERT Models,0.0215853,"We perform knowledge distillation (KD) benchmark from task-specific BERT-base
teacher models to various student models: BiLSTM, CNN, BERT-Tiny, BERT-Mini,
and BERT-Small. Our experiment involves 12 datasets grouped in two tasks: text
classification and sequence labeling in the Indonesian language. We also
compare various aspects of distillations including the usage of word embeddings
and unlabeled data augmentation. Our experiments show that, despite the rising
popularity of Transformer-based models, using BiLSTM and CNN student models
provide the best trade-off between performance and computational resource (CPU,
RAM, and storage) compared to pruned BERT models. We further propose some quick
wins on performing KD to produce small NLP models via efficient KD training
mechanisms involving simple choices of loss functions, word embeddings, and
unlabeled data preparation."
Strong Instance Segmentation Pipeline for MMSports Challenge,0.0106876,"The goal of ACM MMSports2022 DeepSportRadar Instance Segmentation Challenge
is to tackle the segmentation of individual humans including players, coaches
and referees on a basketball court. And the main characteristics of this
challenge are there is a high level of occlusions between players and the
amount of data is quite limited. In order to address these problems, we
designed a strong instance segmentation pipeline. Firstly, we employed a proper
data augmentation strategy for this task mainly including photometric
distortion transform and copy-paste strategy, which can generate more image
instances with a wider distribution. Secondly, we employed a strong
segmentation model, Hybrid Task Cascade based detector on the Swin-Base based
CBNetV2 backbone, and we add MaskIoU head to HTCMaskHead that can simply and
effectively improve the performance of instance segmentation. Finally, the SWA
training strategy was applied to improve the performance further. Experimental
results demonstrate the proposed pipeline can achieve a competitive result on
the DeepSportRadar challenge, with 0.768AP@0.50:0.95 on the challenge set.
Source code is available at
https://github.com/YJingyu/Instanc_Segmentation_Pro."
Near-Term Advances in Quantum Natural Language Processing,0.023988,"This paper describes experiments showing that some tasks in natural language
processing (NLP) can already be performed using quantum computers, though so
far only with small datasets.
  We demonstrate various approaches to topic classification. The first uses an
explicit word-based approach, in which word-topic scoring weights are
implemented as fractional rotations of individual qubit, and a new phrase is
classified based on the accumulation of these weights in a scoring qubit using
entangling controlled-NOT gates. This is compared with more scalable quantum
encodings of word embedding vectors, which are used in the computation of
kernel values in a quantum support vector machine: this approach achieved an
average of 62% accuracy on classification tasks involving over 10000 words,
which is the largest such quantum computing experiment to date.
  We describe a quantum probability approach to bigram modeling that can be
applied to sequences of words and formal concepts, investigating a generative
approximation to these distributions using a quantum circuit Born machine, and
an approach to ambiguity resolution in verb-noun composition using single-qubit
rotations for simple nouns and 2-qubit controlled-NOT gates for simple verbs.
  The smaller systems described have been run successfully on physical quantum
computers, and the larger ones have been simulated. We show that statistically
meaningful results can be obtained using real datasets, but this is much more
difficult to predict than with easier artificial language examples used
previously in developing quantum NLP systems.
  Other approaches to quantum NLP are compared, partly with respect to
contemporary issues including informal language, fluency, and truthfulness."
Pavementscapes: a large-scale hierarchical image dataset for asphalt pavement damage segmentation,0.0,"Pavement damage segmentation has benefited enormously from deep learning. %
and large-scale datasets. However, few current public datasets limit the
potential exploration of deep learning in the application of pavement damage
segmentation. To address this problem, this study has proposed Pavementscapes,
a large-scale dataset to develop and evaluate methods for pavement damage
segmentation. Pavementscapes is comprised of 4,000 images with a resolution of
$1024 \times 2048$, which have been recorded in the real-world pavement
inspection projects with 15 different pavements. A total of 8,680 damage
instances are manually labeled with six damage classes at the pixel level. The
statistical study gives a thorough investigation and analysis of the proposed
dataset. The numeral experiments propose the top-performing deep neural
networks capable of segmenting pavement damages, which provides the baselines
of the open challenge for pavement inspection. The experiment results also
indicate the existing problems for damage segmentation using deep learning, and
this study provides potential solutions."
Computable Artificial General Intelligence,0.0443995,"Artificial general intelligence (AGI) may herald our extinction, according to
AI safety research. Yet claims regarding AGI must rely upon mathematical
formalisms -- theoretical agents we may analyse or attempt to build. AIXI
appears to be the only such formalism supported by proof that its behaviour is
optimal, a consequence of its use of compression as a proxy for intelligence.
Unfortunately, AIXI is incomputable and claims regarding its behaviour highly
subjective. We argue that this is because AIXI formalises cognition as taking
place in isolation from the environment in which goals are pursued (Cartesian
dualism). We propose an alternative, supported by proof and experiment, which
overcomes these problems. Integrating research from cognitive science with AI,
we formalise an enactive model of learning and reasoning to address the problem
of subjectivity. This allows us to formulate a different proxy for
intelligence, called weakness, which addresses the problem of incomputability.
We prove optimal behaviour is attained when weakness is maximised. This proof
is supplemented by experimental results comparing weakness and description
length (the closest analogue to compression possible without reintroducing
subjectivity). Weakness outperforms description length, suggesting it is a
better proxy. Furthermore we show that, if cognition is enactive, then
minimisation of description length is neither necessary nor sufficient to
attain optimal performance, undermining the notion that compression is closely
related to intelligence. However, there remain open questions regarding the
implementation of scale-able AGI. In the short term, these results may be best
utilised to improve the performance of existing systems. For example, our
results explain why Deepmind's Apperception Engine is able to generalise
effectively, and how to replicate that performance by maximising weakness."
PersDet: Monocular 3D Detection in Perspective Bird's-Eye-View,0.041286,"Currently, detecting 3D objects in Bird's-Eye-View (BEV) is superior to other
3D detectors for autonomous driving and robotics. However, transforming image
features into BEV necessitates special operators to conduct feature sampling.
These operators are not supported on many edge devices, bringing extra
obstacles when deploying detectors. To address this problem, we revisit the
generation of BEV representation and propose detecting objects in perspective
BEV -- a new BEV representation that does not require feature sampling. We
demonstrate that perspective BEV features can likewise enjoy the benefits of
the BEV paradigm. Moreover, the perspective BEV improves detection performance
by addressing issues caused by feature sampling. We propose PersDet for
high-performance object detection in perspective BEV space based on this
discovery. While implementing a simple and memory-efficient structure, PersDet
outperforms existing state-of-the-art monocular methods on the nuScenes
benchmark, reaching 34.6% mAP and 40.8% NDS when using ResNet-50 as the
backbone."
Logic-based Reward Shaping for Multi-Agent Reinforcement Learning,0.027276,"Reinforcement learning (RL) relies heavily on exploration to learn from its
environment and maximize observed rewards. Therefore, it is essential to design
a reward function that guarantees optimal learning from the received
experience. Previous work has combined automata and logic based reward shaping
with environment assumptions to provide an automatic mechanism to synthesize
the reward function based on the task. However, there is limited work on how to
expand logic-based reward shaping to Multi-Agent Reinforcement Learning (MARL).
The environment will need to consider the joint state in order to keep track of
other agents if the task requires cooperation, thus suffering from the curse of
dimensionality with respect to the number of agents. This project explores how
logic-based reward shaping for MARL can be designed for different scenarios and
tasks. We present a novel method for semi-centralized logic-based MARL reward
shaping that is scalable in the number of agents and evaluate it in multiple
scenarios."
Knowledge Graph Induction enabling Recommending and Trend Analysis: A Corporate Research Community Use Case,0.0506885,"A research division plays an important role of driving innovation in an
organization. Drawing insights, following trends, keeping abreast of new
research, and formulating strategies are increasingly becoming more challenging
for both researchers and executives as the amount of information grows in both
velocity and volume. In this paper we present a use case of how a corporate
research community, IBM Research, utilizes Semantic Web technologies to induce
a unified Knowledge Graph from both structured and textual data obtained by
integrating various applications used by the community related to research
projects, academic papers, datasets, achievements and recognition. In order to
make the Knowledge Graph more accessible to application developers, we
identified a set of common patterns for exploiting the induced knowledge and
exposed them as APIs. Those patterns were born out of user research which
identified the most valuable use cases or user pain points to be alleviated. We
outline two distinct scenarios: recommendation and analytics for business use.
We will discuss these scenarios in detail and provide an empirical evaluation
on entity recommendation specifically. The methodology used and the lessons
learned from this work can be applied to other organizations facing similar
challenges."
Vulnerability Prioritization: An Offensive Security Approach,0.0806939,"Organizations struggle to handle sheer number of vulnerabilities in their
cloud environments. The de facto methodology used for prioritizing
vulnerabilities is to use Common Vulnerability Scoring System (CVSS). However,
CVSS has inherent limitations that makes it not ideal for prioritization. In
this work, we propose a new way of prioritizing vulnerabilities. Our approach
is inspired by how offensive security practitioners perform penetration
testing. We evaluate our approach with a real world case study for a large
client, and the accuracy of machine learning to automate the process end to
end."
Fix Bugs with Transformer through a Neural-Symbolic Edit Grammar,0.134609,"We introduce NSEdit (neural-symbolic edit), a novel Transformer-based code
repair method. Given only the source code that contains bugs, NSEdit predicts
an editing sequence that can fix the bugs. The edit grammar is formulated as a
regular language, and the Transformer uses it as a neural-symbolic scripting
interface to generate editing programs. We modify the Transformer and add a
pointer network to select the edit locations. An ensemble of rerankers are
trained to re-rank the editing sequences generated by beam search. We fine-tune
the rerankers on the validation set to reduce over-fitting. NSEdit is evaluated
on various code repair datasets and achieved a new state-of-the-art accuracy
($24.04\%$) on the Tufano small dataset of the CodeXGLUE benchmark. NSEdit
performs robustly when programs vary from packages to packages and when buggy
programs are concrete. We conduct detailed analysis on our methods and
demonstrate the effectiveness of each component."
"""Even if ..."" -- Diverse Semifactual Explanations of Reject",0.025127,"Machine learning based decision making systems applied in safety critical
areas require reliable high certainty predictions. For this purpose, the system
can be extended by an reject option which allows the system to reject inputs
where only a prediction with an unacceptably low certainty would be possible.
While being able to reject uncertain samples is important, it is also of
importance to be able to explain why a particular sample was rejected. With the
ongoing rise of eXplainable AI (XAI), a lot of explanation methodologies for
machine learning based systems have been developed -- explaining reject
options, however, is still a novel field where only very little prior work
exists.
  In this work, we propose to explain rejects by semifactual explanations, an
instance of example-based explanation methods, which them self have not been
widely considered in the XAI community yet. We propose a conceptual modeling of
semifactual explanations for arbitrary reject options and empirically evaluate
a specific implementation on a conformal prediction based reject option."
AIREPAIR: A Repair Platform for Neural Networks,-1.0,"We present AIREPAIR, a platform for repairing neural networks. It features
the integration of existing network repair tools. Based on AIREPAIR, one can
run different repair methods on the same model, thus enabling the fair
comparison of different repair techniques. We evaluate AIREPAIR with three
state-of-the-art repair tools on popular deep-learning datasets and models. Our
evaluation confirms the utility of AIREPAIR, by comparing and analyzing the
results from different repair techniques. A demonstration is available at
https://youtu.be/UkKw5neeWhw."
Stability of Syntactic Dialect Classification Over Space and Time,0.0808759,"This paper analyses the degree to which dialect classifiers based on
syntactic representations remain stable over space and time. While previous
work has shown that the combination of grammar induction and geospatial text
classification produces robust dialect models, we do not know what influence
both changing grammars and changing populations have on dialect models. This
paper constructs a test set for 12 dialects of English that spans three years
at monthly intervals with a fixed spatial distribution across 1,120 cities.
Syntactic representations are formulated within the usage-based Construction
Grammar paradigm (CxG). The decay rate of classification performance for each
dialect over time allows us to identify regions undergoing syntactic change.
And the distribution of classification accuracy within dialect regions allows
us to identify the degree to which the grammar of a dialect is internally
heterogeneous. The main contribution of this paper is to show that a rigorous
evaluation of dialect classification models can be used to find both variation
over space and change over time."
Retrieval augmentation of large language models for lay language generation,0.0726202,"Recent lay language generation systems have used Transformer models trained
on a parallel corpus to increase health information accessibility. However, the
applicability of these models is constrained by the limited size and topical
breadth of available corpora. We introduce CELLS, the largest (63k pairs) and
broadest-ranging (12 journals) parallel corpus for lay language generation. The
abstract and the corresponding lay language summary are written by domain
experts, assuring the quality of our dataset. Furthermore, qualitative
evaluation of expert-authored plain language summaries has revealed background
explanation as a key strategy to increase accessibility. Such explanation is
challenging for neural models to generate because it goes beyond simplification
by adding content absent from the source. We derive two specialized paired
corpora from CELLS to address key challenges in lay language generation:
generating background explanations and simplifying the original abstract. We
adopt retrieval-augmented models as an intuitive fit for the task of background
explanation generation, and show improvements in summary quality and simplicity
while maintaining factual correctness. Taken together, this work presents the
first comprehensive study of background explanation for lay language
generation, paving the path for disseminating scientific knowledge to a broader
audience. CELLS is publicly available at:
https://github.com/LinguisticAnomalies/pls_retrieval."
Nested Named Entity Recognition from Medical Texts: An Adaptive Shared Network Architecture with Attentive CRF,0.0103454,"Recognizing useful named entities plays a vital role in medical information
processing, which helps drive the development of medical area research. Deep
learning methods have achieved good results in medical named entity recognition
(NER). However, we find that existing methods face great challenges when
dealing with the nested named entities. In this work, we propose a novel
method, referred to as ASAC, to solve the dilemma caused by the nested
phenomenon, in which the core idea is to model the dependency between different
categories of entity recognition. The proposed method contains two key modules:
the adaptive shared (AS) part and the attentive conditional random field (ACRF)
module. The former part automatically assigns adaptive weights across each task
to achieve optimal recognition accuracy in the multi-layer network. The latter
module employs the attention operation to model the dependency between
different entities. In this way, our model could learn better entity
representations by capturing the implicit distinctions and relationships
between different categories of entities. Extensive experiments on public
datasets verify the effectiveness of our method. Besides, we also perform
ablation analyses to deeply understand our methods."
Sequence-aware multimodal page classification of Brazilian legal documents,0.0294521,"The Brazilian Supreme Court receives tens of thousands of cases each
semester. Court employees spend thousands of hours to execute the initial
analysis and classification of those cases -- which takes effort away from
posterior, more complex stages of the case management workflow. In this paper,
we explore multimodal classification of documents from Brazil's Supreme Court.
We train and evaluate our methods on a novel multimodal dataset of 6,510
lawsuits (339,478 pages) with manual annotation assigning each page to one of
six classes. Each lawsuit is an ordered sequence of pages, which are stored
both as an image and as a corresponding text extracted through optical
character recognition. We first train two unimodal classifiers: a ResNet
pre-trained on ImageNet is fine-tuned on the images, and a convolutional
network with filters of multiple kernel sizes is trained from scratch on
document texts. We use them as extractors of visual and textual features, which
are then combined through our proposed Fusion Module. Our Fusion Module can
handle missing textual or visual input by using learned embeddings for missing
data. Moreover, we experiment with bi-directional Long Short-Term Memory
(biLSTM) networks and linear-chain conditional random fields to model the
sequential nature of the pages. The multimodal approaches outperform both
textual and visual classifiers, especially when leveraging the sequential
nature of the pages."
Feature Selection for Fault Detection and Prediction based on Event Log Analysis,0.00466555,"Event logs are widely used for anomaly detection and prediction in complex
systems. Existing log-based anomaly detection methods usually consist of four
main steps: log collection, log parsing, feature extraction, and anomaly
detection, wherein the feature extraction step extracts useful features for
anomaly detection by counting log events. For a complex system, such as a
lithography machine consisting of a large number of subsystems, its log may
contain thousands of different events, resulting in abounding extracted
features. However, when anomaly detection is performed at the subsystem level,
analyzing all features becomes expensive and unnecessary. To mitigate this
problem, we develop a feature selection method for log-based anomaly detection
and prediction, largely improving the effectiveness and efficiency."
Addressing Client Drift in Federated Continual Learning with Adaptive Optimization,0.026414,"Federated learning has been extensively studied and is the prevalent method
for privacy-preserving distributed learning in edge devices. Correspondingly,
continual learning is an emerging field targeted towards learning multiple
tasks sequentially. However, there is little attention towards additional
challenges emerging when federated aggregation is performed in a continual
learning system. We identify \textit{client drift} as one of the key weaknesses
that arise when vanilla federated averaging is applied in such a system,
especially since each client can independently have different order of tasks.
We outline a framework for performing Federated Continual Learning (FCL) by
using NetTailor as a candidate continual learning approach and show the extent
of the problem of client drift. We show that adaptive federated optimization
can reduce the adverse impact of client drift and showcase its effectiveness on
CIFAR100, MiniImagenet, and Decathlon benchmarks. Further, we provide an
empirical analysis highlighting the interplay between different hyperparameters
such as client and server learning rates, the number of local training
iterations, and communication rounds. Finally, we evaluate our framework on
useful characteristics of federated learning systems such as scalability,
robustness to the skewness in clients' data distribution, and stragglers."
Non-Deterministic Face Mask Removal Based On 3D Priors,0.0200246,"This paper presents a novel image inpainting framework for face mask removal.
Although current methods have demonstrated their impressive ability in
recovering damaged face images, they suffer from two main problems: the
dependence on manually labeled missing regions and the deterministic result
corresponding to each input. The proposed approach tackles these problems by
integrating a multi-task 3D face reconstruction module with a face inpainting
module. Given a masked face image, the former predicts a 3DMM-based
reconstructed face together with a binary occlusion map, providing dense
geometrical and textural priors that greatly facilitate the inpainting task of
the latter. By gradually controlling the 3D shape parameters, our method
generates high-quality dynamic inpainting results with different expressions
and mouth movements. Qualitative and quantitative experiments verify the
effectiveness of the proposed method."
A Study of Syntactic Multi-Modality in Non-Autoregressive Machine Translation,0.047262,"It is difficult for non-autoregressive translation (NAT) models to capture
the multi-modal distribution of target translations due to their conditional
independence assumption, which is known as the ""multi-modality problem"",
including the lexical multi-modality and the syntactic multi-modality. While
the first one has been well studied, the syntactic multi-modality brings severe
challenge to the standard cross entropy (XE) loss in NAT and is under studied.
In this paper, we conduct a systematic study on the syntactic multi-modality
problem. Specifically, we decompose it into short- and long-range syntactic
multi-modalities and evaluate several recent NAT algorithms with advanced loss
functions on both carefully designed synthesized datasets and real datasets. We
find that the Connectionist Temporal Classification (CTC) loss and the
Order-Agnostic Cross Entropy (OAXE) loss can better handle short- and
long-range syntactic multi-modalities respectively. Furthermore, we take the
best of both and design a new loss function to better handle the complicated
syntactic multi-modality in real-world datasets. To facilitate practical usage,
we provide a guide to use different loss functions for different kinds of
syntactic multi-modality."
Label Anchored Contrastive Learning for Language Understanding,0.0765328,"Contrastive learning (CL) has achieved astonishing progress in computer
vision, speech, and natural language processing fields recently with
self-supervised learning. However, CL approach to the supervised setting is not
fully explored, especially for the natural language understanding
classification task. Intuitively, the class label itself has the intrinsic
ability to perform hard positive/negative mining, which is crucial for CL.
Motivated by this, we propose a novel label anchored contrastive learning
approach (denoted as LaCon) for language understanding. Specifically, three
contrastive objectives are devised, including a multi-head instance-centered
contrastive loss (ICL), a label-centered contrastive loss (LCL), and a label
embedding regularizer (LER). Our approach does not require any specialized
network architecture or any extra data augmentation, thus it can be easily
plugged into existing powerful pre-trained language models. Compared to the
state-of-the-art baselines, LaCon obtains up to 4.1% improvement on the popular
datasets of GLUE and CLUE benchmarks. Besides, LaCon also demonstrates
significant advantages under the few-shot and data imbalance settings, which
obtains up to 9.4% improvement on the FewGLUE and FewCLUE benchmarking tasks."
Ensemble Transformer for Efficient and Accurate Ranking Tasks: an Application to Question Answering Systems,0.0467871,"Large transformer models can highly improve Answer Sentence Selection (AS2)
tasks, but their high computational costs prevent their use in many real-world
applications. In this paper, we explore the following research question: How
can we make the AS2 models more accurate without significantly increasing their
model complexity? To address the question, we propose a Multiple Heads Student
architecture (named CERBERUS), an efficient neural network designed to distill
an ensemble of large transformers into a single smaller model. CERBERUS
consists of two components: a stack of transformer layers that is used to
encode inputs, and a set of ranking heads; unlike traditional distillation
technique, each of them is trained by distilling a different large transformer
architecture in a way that preserves the diversity of the ensemble members. The
resulting model captures the knowledge of heterogeneous transformer models by
using just a few extra parameters. We show the effectiveness of CERBERUS on
three English datasets for AS2; our proposed approach outperforms all
single-model distillations we consider, rivaling the state-of-the-art large AS2
models that have 2.7x more parameters and run 2.5x slower. Code for our model
is available at https://github.com/amazon-research/wqa-cerberus"
Synthesizing Programs with Continuous Optimization,0.00434682,"Automatic software generation based on some specification is known as program
synthesis. Most existing approaches formulate program synthesis as a search
problem with discrete parameters. In this paper, we present a novel formulation
of program synthesis as a continuous optimization problem and use a
state-of-the-art evolutionary approach, known as Covariance Matrix Adaptation
Evolution Strategy to solve the problem. We then propose a mapping scheme to
convert the continuous formulation into actual programs. We compare our system,
called GENESYS, with several recent program synthesis techniques (in both
discrete and continuous domains) and show that GENESYS synthesizes more
programs within a fixed time budget than those existing schemes. For example,
for programs of length 10, GENESYS synthesizes 28% more programs than those
existing schemes within the same time budget."
Prompt-based Text Entailment for Low-Resource Named Entity Recognition,0.0944513,"Pre-trained Language Models (PLMs) have been applied in NLP tasks and achieve
promising results. Nevertheless, the fine-tuning procedure needs labeled data
of the target domain, making it difficult to learn in low-resource and
non-trivial labeled scenarios. To address these challenges, we propose
Prompt-based Text Entailment (PTE) for low-resource named entity recognition,
which better leverages knowledge in the PLMs. We first reformulate named entity
recognition as the text entailment task. The original sentence with entity
type-specific prompts is fed into PLMs to get entailment scores for each
candidate. The entity type with the top score is then selected as final label.
Then, we inject tagging labels into prompts and treat words as basic units
instead of n-gram spans to reduce time complexity in generating candidates by
n-grams enumeration. Experimental results demonstrate that the proposed method
PTE achieves competitive performance on the CoNLL03 dataset, and better than
fine-tuned counterparts on the MIT Movie and Few-NERD dataset in low-resource
settings."
Bias-Eliminated Semantic Refinement for Any-Shot Learning,0.134599,"When training samples are scarce, the semantic embedding technique, ie,
describing class labels with attributes, provides a condition to generate
visual features for unseen objects by transferring the knowledge from seen
objects. However, semantic descriptions are usually obtained in an external
paradigm, such as manual annotation, resulting in weak consistency between
descriptions and visual features. In this paper, we refine the coarse-grained
semantic description for any-shot learning tasks, ie, zero-shot learning (ZSL),
generalized zero-shot learning (GZSL), and few-shot learning (FSL). A new
model, namely, the semantic refinement Wasserstein generative adversarial
network (SRWGAN) model, is designed with the proposed multihead representation
and hierarchical alignment techniques. Unlike conventional methods, semantic
refinement is performed with the aim of identifying a bias-eliminated condition
for disjoint-class feature generation and is applicable in both inductive and
transductive settings. We extensively evaluate model performance on six
benchmark datasets and observe state-of-the-art results for any-shot learning;
eg, we obtain 70.2% harmonic accuracy for the Caltech UCSD Birds (CUB) dataset
and 82.2% harmonic accuracy for the Oxford Flowers (FLO) dataset in the
standard GZSL setting. Various visualizations are also provided to show the
bias-eliminated generation of SRWGAN. Our code is available."
CoSe-Co: Text Conditioned Generative CommonSense Contextualizer,0.0667924,"Pre-trained Language Models (PTLMs) have been shown to perform well on
natural language tasks. Many prior works have leveraged structured commonsense
present in the form of entities linked through labeled relations in Knowledge
Graphs (KGs) to assist PTLMs. Retrieval approaches use KG as a separate static
module which limits coverage since KGs contain finite knowledge. Generative
methods train PTLMs on KG triples to improve the scale at which knowledge can
be obtained. However, training on symbolic KG entities limits their
applicability in tasks involving natural language text where they ignore
overall context. To mitigate this, we propose a CommonSense Contextualizer
(CoSe-Co) conditioned on sentences as input to make it generically usable in
tasks for generating knowledge relevant to the overall context of input text.
To train CoSe-Co, we propose a novel dataset comprising of sentence and
commonsense knowledge pairs. The knowledge inferred by CoSe-Co is diverse and
contain novel entities not present in the underlying KG. We augment generated
knowledge in Multi-Choice QA and Open-ended CommonSense Reasoning tasks leading
to improvements over current best methods on CSQA, ARC, QASC and OBQA datasets.
We also demonstrate its applicability in improving performance of a baseline
model for paraphrase generation task."
Learning Parameters for a Generalized Vidale-Wolfe Response Model with Flexible Ad Elasticity and Word-of-Mouth,0.219286,"In this research, we investigate a generalized form of Vidale-Wolfe (GVW)
model. One key element of our modeling work is that the GVW model contains two
useful indexes representing advertiser's elasticity and the word-of-mouth (WoM)
effect, respectively. Moreover, we discuss some desirable properties of the GVW
model, and present a deep neural network (DNN)-based estimation method to learn
its parameters. Furthermore, based on three realworld datasets, we conduct
computational experiments to validate the GVW model and identified properties.
In addition, we also discuss potential advantages of the GVW model over
econometric models. The research outcome shows that both the ad elasticity
index and the WoM index have significant influences on advertising responses,
and the GVW model has potential advantages over econometric models of
advertising, in terms of several interesting phenomena drawn from practical
advertising situations. The GVW model and its deep learning-based estimation
method provide a basis to support big data-driven advertising analytics and
decision makings; in the meanwhile, identified properties and experimental
findings of this research illuminate critical managerial insights for
advertisers in various advertising forms."
An IoT Cloud and Big Data Architecture for the Maintenance of Home Appliances,0.0281699,"Billions of interconnected Internet of Things (IoT) sensors and devices
collect tremendous amounts of data from real-world scenarios. Big data is
generating increasing interest in a wide range of industries. Once data is
analyzed through compute-intensive Machine Learning (ML) methods, it can derive
critical business value for organizations. Powerfulplatforms are essential to
handle and process such massive collections of information cost-effectively and
conveniently. This work introduces a distributed and scalable platform
architecture that can be deployed for efficient real-world big data collection
and analytics. The proposed system was tested with a case study for Predictive
Maintenance of Home Appliances, where current and vibration sensors with high
acquisition frequency were connected to washing machines and refrigerators. The
introduced platform was used to collect, store, and analyze the data. The
experimental results demonstrated that the presented system could be
advantageous for tackling real-world IoT scenarios in a cost-effective and
local approach."
ContraCLM: Contrastive Learning For Causal Language Model,-1.0,"Despite exciting progress in causal language models, the expressiveness of
the representations is largely limited due to poor discrimination ability. To
remedy this issue, we present ContraCLM, a novel contrastive learning framework
at both token-level and sequence-level. We assess ContraCLM on a variety of
downstream tasks. We show that ContraCLM enhances discrimination of the
representations and bridges the gap with the encoder-only models, which makes
causal language models better suited for tasks beyond language generation.
Specifically, we attain $44\%$ relative improvement on the Semantic Textual
Similarity tasks and $34\%$ on Code-to-Code Search tasks. Furthermore, by
improving the expressiveness of the representations, ContraCLM also boosts the
source code generation capability with $9\%$ relative improvement on execution
accuracy on the HumanEval benchmark."
SummScore: A Comprehensive Evaluation Metric for Summary Quality Based on Cross-Encoder,-1.0,"Text summarization models are often trained to produce summaries that meet
human quality requirements. However, the existing evaluation metrics for
summary text are only rough proxies for summary quality, suffering from low
correlation with human scoring and inhibition of summary diversity. To solve
these problems, we propose SummScore, a comprehensive metric for summary
quality evaluation based on CrossEncoder. Firstly, by adopting the
original-summary measurement mode and comparing the semantics of the original
text, SummScore gets rid of the inhibition of summary diversity. With the help
of the text-matching pre-training Cross-Encoder, SummScore can effectively
capture the subtle differences between the semantics of summaries. Secondly, to
improve the comprehensiveness and interpretability, SummScore consists of four
fine-grained submodels, which measure Coherence, Consistency, Fluency, and
Relevance separately. We use semi-supervised multi-rounds of training to
improve the performance of our model on extremely limited annotated data.
Extensive experiments show that SummScore significantly outperforms existing
evaluation metrics in the above four dimensions in correlation with human
scoring. We also provide the quality evaluation results of SummScore on 16
mainstream summarization models for later research."
Spectral Probing,0.0782761,"Linguistic information is encoded at varying timescales (subwords, phrases,
etc.) and communicative levels, such as syntax and semantics. Contextualized
embeddings have analogously been found to capture these phenomena at
distinctive layers and frequencies. Leveraging these findings, we develop a
fully learnable frequency filter to identify spectral profiles for any given
task. It enables vastly more granular analyses than prior handcrafted filters,
and improves on efficiency. After demonstrating the informativeness of spectral
probing over manual filters in a monolingual setting, we investigate its
multilingual characteristics across seven diverse NLP tasks in six languages.
Our analyses identify distinctive spectral profiles which quantify cross-task
similarity in a linguistically intuitive manner, while remaining consistent
across languages-highlighting their potential as robust, lightweight task
descriptors."
Eliciting and Understanding Cross-Task Skills with Task-Level Mixture-of-Experts,0.0420878,"Recent works suggest that transformer models are capable of multi-tasking on
diverse NLP tasks and adapting to new tasks efficiently. However, the potential
of these multi-task models may be limited as they use the same set of
parameters for all tasks. In contrast, humans tackle tasks in a more flexible
way, by making proper presumptions on what skills and knowledge are relevant
and executing only the necessary computations. Inspired by this, we propose to
use task-level mixture-of-expert models, which has a collection of transformer
layers (i.e., experts) and a router component that chooses from these experts
dynamically and flexibly. We find that these models help improve the average
performance gain (ARG) metric by 2.6% when adapting to unseen tasks in the
few-shot setting and by 5.6% in the zero-shot generalization setting. Further,
we show that the learned routing decisions partly rediscover human
categorization of NLP tasks -- certain experts are strongly associated with
extractive tasks, some with classification tasks, and some with tasks requiring
world knowledge."
Reinforced Imitative Graph Learning for Mobile User Profiling,0.0310722,"Mobile user profiling refers to the efforts of extracting users'
characteristics from mobile activities. In order to capture the dynamic varying
of user characteristics for generating effective user profiling, we propose an
imitation-based mobile user profiling framework. Considering the objective of
teaching an autonomous agent to imitate user mobility based on the user's
profile, the user profile is the most accurate when the agent can perfectly
mimic the user behavior patterns. The profiling framework is formulated into a
reinforcement learning task, where an agent is a next-visit planner, an action
is a POI that a user will visit next, and the state of the environment is a
fused representation of a user and spatial entities. An event in which a user
visits a POI will construct a new state, which helps the agent predict users'
mobility more accurately. In the framework, we introduce a spatial Knowledge
Graph (KG) to characterize the semantics of user visits over connected spatial
entities. Additionally, we develop a mutual-updating strategy to quantify the
state that evolves over time. Along these lines, we develop a reinforcement
imitative graph learning framework for mobile user profiling. Finally, we
conduct extensive experiments to demonstrate the superiority of our approach."
Multi-Frames Temporal Abnormal Clues Learning Method for Face Anti-Spoofing,0.0193995,"Face anti-spoofing researches are widely used in face recognition and has
received more attention from industry and academics. In this paper, we propose
the EulerNet, a new temporal feature fusion network in which the differential
filter and residual pyramid are used to extract and amplify abnormal clues from
continuous frames, respectively. A lightweight sample labeling method based on
face landmarks is designed to label large-scale samples at a lower cost and has
better results than other methods such as 3D camera. Finally, we collect 30,000
live and spoofing samples using various mobile ends to create a dataset that
replicates various forms of attacks in a real-world setting. Extensive
experiments on public OULU-NPU show that our algorithm is superior to the state
of art and our solution has already been deployed in real-world systems
servicing millions of users."
FAKD: Feature Augmented Knowledge Distillation for Semantic Segmentation,0.0779711,"In this work, we explore data augmentations for knowledge distillation on
semantic segmentation. To avoid over-fitting to the noise in the teacher
network, a large number of training examples is essential for knowledge
distillation. Imagelevel argumentation techniques like flipping, translation or
rotation are widely used in previous knowledge distillation framework. Inspired
by the recent progress on semantic directions on feature-space, we propose to
include augmentations in feature space for efficient distillation.
Specifically, given a semantic direction, an infinite number of augmentations
can be obtained for the student in the feature space. Furthermore, the analysis
shows that those augmentations can be optimized simultaneously by minimizing an
upper bound for the losses defined by augmentations. Based on the observation,
a new algorithm is developed for knowledge distillation in semantic
segmentation. Extensive experiments on four semantic segmentation benchmarks
demonstrate that the proposed method can boost the performance of current
knowledge distillation methods without any significant overhead. Code is
available at: https://github.com/jianlong-yuan/FAKD."
Deep Learning Reproducibility and Explainable AI (XAI),0.0,"The nondeterminism of Deep Learning (DL) training algorithms and its
influence on the explainability of neural network (NN) models are investigated
in this work with the help of image classification examples. To discuss the
issue, two convolutional neural networks (CNN) have been trained and their
results compared. The comparison serves the exploration of the feasibility of
creating deterministic, robust DL models and deterministic explainable
artificial intelligence (XAI) in practice. Successes and limitation of all here
carried out efforts are described in detail. The source code of the attained
deterministic models has been listed in this work. Reproducibility is indexed
as a development-phase-component of the Model Governance Framework, proposed by
the EU within their excellence in AI approach. Furthermore, reproducibility is
a requirement for establishing causality for the interpretation of model
results and building of trust towards the overwhelming expansion of AI systems
applications. Problems that have to be solved on the way to reproducibility and
ways to deal with some of them, are examined in this work."
Unsupervised Domain Adaptation for One-stage Object Detector using Offsets to Bounding Box,0.0230374,"Most existing domain adaptive object detection methods exploit adversarial
feature alignment to adapt the model to a new domain. Recent advances in
adversarial feature alignment strives to reduce the negative effect of
alignment, or negative transfer, that occurs because the distribution of
features varies depending on the category of objects. However, by analyzing the
features of the anchor-free one-stage detector, in this paper, we find that
negative transfer may occur because the feature distribution varies depending
on the regression value for the offset to the bounding box as well as the
category. To obtain domain invariance by addressing this issue, we align the
feature conditioned on the offset value, considering the modality of the
feature distribution. With a very simple and effective conditioning method, we
propose OADA (Offset-Aware Domain Adaptive object detector) that achieves
state-of-the-art performances in various experimental settings. In addition, by
analyzing through singular value decomposition, we find that our model enhances
both discriminability and transferability."
Identifying Electrocardiogram Abnormalities Using a Handcrafted-Rule-Enhanced Neural Network,0.139359,"A large number of people suffer from life-threatening cardiac abnormalities,
and electrocardiogram (ECG) analysis is beneficial to determining whether an
individual is at risk of such abnormalities. Automatic ECG classification
methods, especially the deep learning based ones, have been proposed to detect
cardiac abnormalities using ECG records, showing good potential to improve
clinical diagnosis and help early prevention of cardiovascular diseases.
However, the predictions of the known neural networks still do not
satisfactorily meet the needs of clinicians, and this phenomenon suggests that
some information used in clinical diagnosis may not be well captured and
utilized by these methods. In this paper, we introduce some rules into
convolutional neural networks, which help present clinical knowledge to deep
learning based ECG analysis, in order to improve automated ECG diagnosis
performance. Specifically, we propose a Handcrafted-Rule-enhanced Neural
Network (called HRNN) for ECG classification with standard 12-lead ECG input,
which consists of a rule inference module and a deep learning module.
Experiments on two large-scale public ECG datasets show that our new approach
considerably outperforms existing state-of-the-art methods. Further, our
proposed approach not only can improve the diagnosis performance, but also can
assist in detecting mislabelled ECG samples. Our codes are available at
https://github.com/alwaysbyx/ecg_processing."
Video Frame Interpolation with Transformer,0.0576022,"Video frame interpolation (VFI), which aims to synthesize intermediate frames
of a video, has made remarkable progress with development of deep convolutional
networks over past years. Existing methods built upon convolutional networks
generally face challenges of handling large motion due to the locality of
convolution operations. To overcome this limitation, we introduce a novel
framework, which takes advantage of Transformer to model long-range pixel
correlation among video frames. Further, our network is equipped with a novel
cross-scale window-based attention mechanism, where cross-scale windows
interact with each other. This design effectively enlarges the receptive field
and aggregates multi-scale information. Extensive quantitative and qualitative
experiments demonstrate that our method achieves new state-of-the-art results
on various benchmarks."
PInKS: Preconditioned Commonsense Inference with Minimal Supervision,0.0798573,"Reasoning with preconditions such as ""glass can be used for drinking water
unless the glass is shattered"" remains an open problem for language models. The
main challenge lies in the scarcity of preconditions data and the model's lack
of support for such reasoning. We present PInKS, Preconditioned Commonsense
Inference with WeaK Supervision, an improved model for reasoning with
preconditions through minimum supervision. We show, both empirically and
theoretically, that PInKS improves the results on benchmarks focused on
reasoning with the preconditions of commonsense knowledge (up to 40% Macro-F1
scores). We further investigate PInKS through PAC-Bayesian informativeness
analysis, precision measures, and ablation study."
R2D2: Robust Data-to-Text with Replacement Detection,0.187147,"Unfaithful text generation is a common problem for text generation systems.
In the case of Data-to-Text (D2T) systems, the factuality of the generated text
is particularly crucial for any real-world applications. We introduce R2D2, a
training framework that addresses unfaithful Data-to-Text generation by
training a system both as a generator and a faithfulness discriminator with
additional replacement detection and unlikelihood learning tasks. To facilitate
such training, we propose two methods for sampling unfaithful sentences. We
argue that the poor entity retrieval capability of D2T systems is one of the
primary sources of unfaithfulness, so in addition to the existing metrics, we
further propose NER-based metrics to evaluate the fidelity of D2T generations.
Our experimental results show that R2D2 systems could effectively mitigate the
unfaithful text generation, and they achieve new state-of-the-art results on
FeTaQA, LogicNLG, and ToTTo, all with significant improvements."
TourBERT: A pretrained language model for the tourism industry,0.527633,"The Bidirectional Encoder Representations from Transformers (BERT) is
currently one of the most important and state-of-the-art models for natural
language. However, it has also been shown that for domain-specific tasks it is
helpful to pretrain BERT on a domain-specific corpus. In this paper, we present
TourBERT, a pretrained language model for tourism. We describe how TourBERT was
developed and evaluated. The evaluations show that TourBERT is outperforming
BERT in all tourism-specific tasks."
Infrared and visible image fusion based on Multi-State Contextual Hidden Markov Model,0.0324339,"The traditional two-state hidden Markov model divides the high frequency
coefficients only into two states (large and small states). Such scheme is
prone to produce an inaccurate statistical model for the high frequency subband
and reduces the quality of fusion result. In this paper, a fine-grained
multi-state contextual hidden Markov model (MCHMM) is proposed for infrared and
visible image fusion in the non-subsampled Shearlet domain, which takes full
consideration of the strong correlations and level of details of NSST
coefficients. To this end, an accurate soft context variable is designed
correspondingly from the perspective of context correlation. Then, the
statistical features provided by MCHMM are utilized for the fusion of high
frequency subbands. To ensure the visual quality, a fusion strategy based on
the difference in regional energy is proposed as well for lowfrequency
subbands. Experimental results demonstrate that the proposed method can achieve
a superior performance compared with other fusion methods in both subjective
and objective aspects."
SentBS: Sentence-level Beam Search for Controllable Summarization,0.037171,"A wide range of control perspectives have been explored in controllable text
generation. Structure-controlled summarization is recently proposed as a useful
and interesting research direction. However, current structure-controlling
methods have limited effectiveness in enforcing the desired structure. To
address this limitation, we propose a sentence-level beam search generation
method (SentBS), where evaluation is conducted throughout the generation
process to select suitable sentences for subsequent generations. We experiment
with different combinations of decoding methods to be used as subcomponents by
SentBS and evaluate results on the structure-controlled dataset MReD.
Experiments show that all explored combinations for SentBS can improve the
agreement between the generated text and the desired structure, with the best
method significantly reducing the structural discrepancies suffered by the
existing model, by approximately 68%."
Graph-based Extractive Explainer for Recommendations,0.161265,"Explanations in a recommender system assist users in making informed
decisions among a set of recommended items. Great research attention has been
devoted to generating natural language explanations to depict how the
recommendations are generated and why the users should pay attention to them.
However, due to different limitations of those solutions, e.g., template-based
or generation-based, it is hard to make the explanations easily perceivable,
reliable and personalized at the same time.
  In this work, we develop a graph attentive neural network model that
seamlessly integrates user, item, attributes, and sentences for
extraction-based explanation. The attributes of items are selected as the
intermediary to facilitate message passing for user-item specific evaluation of
sentence relevance. And to balance individual sentence relevance, overall
attribute coverage, and content redundancy, we solve an integer linear
programming problem to make the final selection of sentences. Extensive
empirical evaluations against a set of state-of-the-art baseline methods on two
benchmark review datasets demonstrated the generation quality of the proposed
solution."
3D Moments from Near-Duplicate Photos,0.220065,"We introduce 3D Moments, a new computational photography effect. As input we
take a pair of near-duplicate photos, i.e., photos of moving subjects from
similar viewpoints, common in people's photo collections. As output, we produce
a video that smoothly interpolates the scene motion from the first photo to the
second, while also producing camera motion with parallax that gives a
heightened sense of 3D. To achieve this effect, we represent the scene as a
pair of feature-based layered depth images augmented with scene flow. This
representation enables motion interpolation along with independent control of
the camera viewpoint. Our system produces photorealistic space-time videos with
motion parallax and scene dynamics, while plausibly recovering regions occluded
in the original views. We conduct extensive experiments demonstrating superior
performance over baselines on public datasets and in-the-wild photos. Project
page: https://3d-moments.github.io/"
Orders Are Unwanted: Dynamic Deep Graph Convolutional Network for Personality Detection,0.182825,"Predicting personality traits based on online posts has emerged as an
important task in many fields such as social network analysis. One of the
challenges of this task is assembling information from various posts into an
overall profile for each user. While many previous solutions simply concatenate
the posts into a long document and then encode the document by sequential or
hierarchical models, they introduce unwarranted orders for the posts, which may
mislead the models. In this paper, we propose a dynamic deep graph
convolutional network (D-DGCN) to overcome the above limitation. Specifically,
we design a learn-to-connect approach that adopts a dynamic multi-hop structure
instead of a deterministic structure, and combine it with a DGCN module to
automatically learn the connections between posts. The modules of post encoder,
learn-to-connect, and DGCN are jointly trained in an end-to-end manner.
Experimental results on the Kaggle and Pandora datasets show the superior
performance of D-DGCN to state-of-the-art baselines. Our code is available at
https://github.com/djz233/D-DGCN."
Adversarial Learning to Reason in an Arbitrary Logic,0.00234891,"Existing approaches to learning to prove theorems focus on particular logics
and datasets. In this work, we propose Monte-Carlo simulations guided by
reinforcement learning that can work in an arbitrarily specified logic, without
any human knowledge or set of problems. Since the algorithm does not need any
training dataset, it is able to learn to work with any logical foundation, even
when there is no body of proofs or even conjectures available. We practically
demonstrate the feasibility of the approach in multiple logical systems. The
approach is stronger than training on randomly generated data but weaker than
the approaches trained on tailored axiom and conjecture sets. It however allows
us to apply machine learning to automated theorem proving for many logics,
where no such attempts have been tried to date, such as intuitionistic logic or
linear logic."
A deep scalable neural architecture for soil properties estimation from spectral information,0.00866028,"In this paper we propose an adaptive deep neural architecture for the
prediction of multiple soil characteristics from the analysis of hyperspectral
signatures. The proposed method overcomes the limitations of previous methods
in the state of art: (i) it allows to predict multiple soil variables at once;
(ii) it permits to backtrace the spectral bands that most contribute to the
estimation of a given variable; (iii) it is based on a flexible neural
architecture capable of automatically adapting to the spectral library under
analysis. The proposed architecture is experimented on LUCAS, a large
laboratory dataset and on a dataset achieved by simulating PRISMA hyperspectral
sensor. 'Results, compared with other state-of-the-art methods confirm the
effectiveness of the proposed solution."
An Effective Approach for Multi-label Classification with Missing Labels,0.023667,"Compared with multi-class classification, multi-label classification that
contains more than one class is more suitable in real life scenarios. Obtaining
fully labeled high-quality datasets for multi-label classification problems,
however, is extremely expensive, and sometimes even infeasible, with respect to
annotation efforts, especially when the label spaces are too large. This
motivates the research on partial-label classification, where only a limited
number of labels are annotated and the others are missing. To address this
problem, we first propose a pseudo-label based approach to reduce the cost of
annotation without bringing additional complexity to the existing
classification networks. Then we quantitatively study the impact of missing
labels on the performance of classifier. Furthermore, by designing a novel loss
function, we are able to relax the requirement that each instance must contain
at least one positive label, which is commonly used in most existing
approaches. Through comprehensive experiments on three large-scale multi-label
image datasets, i.e. MS-COCO, NUS-WIDE, and Pascal VOC12, we show that our
method can handle the imbalance between positive labels and negative labels,
while still outperforming existing missing-label learning approaches in most
cases, and in some cases even approaches with fully labeled datasets."
Data-Driven Online Interactive Bidding Strategy for Demand Response,0.02367,"Demand response (DR), as one of the important energy resources in the
future's grid, provides the services of peak shaving, enhancing the efficiency
of renewable energy utilization with a short response period, and low cost.
Various categories of DR are established, e.g. automated DR, incentive DR,
emergency DR, and demand bidding. However, with the practical issue of the
unawareness of residential and commercial consumers' utility models, the
researches about demand bidding aggregator involved in the electricity market
are just at the beginning stage. For this issue, the bidding price and bidding
quantity are two required decision variables while considering the
uncertainties due to the market and participants. In this paper, we determine
the bidding and purchasing strategy simultaneously employing the smart meter
data and functions. A two-agent deep deterministic policy gradient method is
developed to optimize the decisions through learning historical bidding
experiences. The online learning further utilizes the daily newest bidding
experience attained to ensure trend tracing and self-adaptation. Two
environment simulators are adopted for testifying the robustness of the model.
The results prove that when facing diverse situations the proposed model can
earn the optimal profit via off/online learning the bidding rules and robustly
making the proper bid."
Continual Learning Approaches for Anomaly Detection,0.0113121,"Anomaly Detection is a relevant problem that arises in numerous real-world
applications, especially when dealing with images. However, there has been
little research for this task in the Continual Learning setting. In this work,
we introduce a novel approach called SCALE (SCALing is Enough) to perform
Compressed Replay in a framework for Anomaly Detection in Continual Learning
setting. The proposed technique scales and compresses the original images using
a Super Resolution model which, to the best of our knowledge, is studied for
the first time in the Continual Learning setting. SCALE can achieve a high
level of compression while maintaining a high level of image reconstruction
quality. In conjunction with other Anomaly Detection approaches, it can achieve
optimal results. To validate the proposed approach, we use a real-world dataset
of images with pixel-based anomalies, with the scope to provide a reliable
benchmark for Anomaly Detection in the context of Continual Learning, serving
as a foundation for further advancements in the field."
FedUKD: Federated UNet Model with Knowledge Distillation for Land Use Classification from Satellite and Street Views,0.0105325,"Federated Deep Learning frameworks can be used strategically to monitor Land
Use locally and infer environmental impacts globally. Distributed data from
across the world would be needed to build a global model for Land Use
classification. The need for a Federated approach in this application domain
would be to avoid transfer of data from distributed locations and save network
bandwidth to reduce communication cost. We use a Federated UNet model for
Semantic Segmentation of satellite and street view images. The novelty of the
proposed architecture is the integration of Knowledge Distillation to reduce
communication cost and response time. The accuracy obtained was above 95% and
we also brought in a significant model compression to over 17 times and 62
times for street View and satellite images respectively. Our proposed framework
has the potential to be a game-changer in real-time tracking of climate change
across the planet."
Paddy Leaf diseases identification on Infrared Images based on Convolutional Neural Networks,0.0475261,"Agriculture is the mainstay of human society because it is an essential need
for every organism. Paddy cultivation is very significant so far as humans are
concerned, largely in the Asian continent, and it is one of the staple foods.
However, plant diseases in agriculture lead to depletion in productivity. Plant
diseases are generally caused by pests, insects, and pathogens that decrease
productivity to a large scale if not controlled within a particular time.
Eventually, one cannot see an increase in paddy yield. Accurate and timely
identification of plant diseases can help farmers mitigate losses due to pests
and diseases. Recently, deep learning techniques have been used to identify
paddy diseases and overcome these problems. This paper implements a
convolutional neural network (CNN) based on a model and tests a public dataset
consisting of 636 infrared image samples with five paddy disease classes and
one healthy class. The proposed model proficiently identified and classified
paddy diseases of five different types and achieved an accuracy of 88.28%"
Event Tables for Efficient Experience Replay,0.0241444,"Experience replay (ER) is a crucial component of many deep reinforcement
learning (RL) systems. However, uniform sampling from an ER buffer can lead to
slow convergence and unstable asymptotic behaviors. This paper introduces
Stratified Sampling from Event Tables (SSET), which partitions an ER buffer
into Event Tables, each capturing important subsequences of optimal behavior.
We prove a theoretical advantage over the traditional monolithic buffer
approach and combine SSET with an existing prioritized sampling strategy to
further improve learning speed and stability. Empirical results in challenging
MiniGrid domains, benchmark RL environments, and a high-fidelity car racing
simulator demonstrate the advantages and versatility of SSET over existing ER
buffer sampling approaches."
OptG: Optimizing Gradient-driven Criteria in Network Sparsity,0.32968,"Network sparsity receives popularity mostly due to its capability to reduce
the network complexity. Extensive studies excavate gradient-driven sparsity.
Typically, these methods are constructed upon premise of weight independence,
which however, is contrary to the fact that weights are mutually influenced.
Thus, their performance remains to be improved. In this paper, we propose to
optimize gradient-driven sparsity (OptG) by solving this independence paradox.
Our motive comes from the recent advances in supermask training which shows
that high-performing sparse subnetworks can be located by simply updating mask
values without modifying any weight. We prove that supermask training is to
accumulate the criteria of gradient-driven sparsity for both removed and
preserved weights, and it can partly solve the independence paradox.
Consequently, OptG integrates supermask training into gradient-driven sparsity,
and a novel supermask optimizer is further proposed to comprehensively mitigate
the independence paradox. Experiments show that OptG can well surpass many
existing state-of-the-art competitors, especially at ultra-high sparsity
levels. Our code is available at \url{https://github.com/zyxxmu/OptG}."
Learning Disentangled Representations of Negation and Uncertainty,0.15684,"Negation and uncertainty modeling are long-standing tasks in natural language
processing. Linguistic theory postulates that expressions of negation and
uncertainty are semantically independent from each other and the content they
modify. However, previous works on representation learning do not explicitly
model this independence. We therefore attempt to disentangle the
representations of negation, uncertainty, and content using a Variational
Autoencoder. We find that simply supervising the latent representations results
in good disentanglement, but auxiliary objectives based on adversarial learning
and mutual information minimization can provide additional disentanglement
gains."
Implicit Regularization with Polynomial Growth in Deep Tensor Factorization,0.0138873,"We study the implicit regularization effects of deep learning in tensor
factorization. While implicit regularization in deep matrix and 'shallow'
tensor factorization via linear and certain type of non-linear neural networks
promotes low-rank solutions with at most quadratic growth, we show that its
effect in deep tensor factorization grows polynomially with the depth of the
network. This provides a remarkably faithful description of the observed
experimental behaviour. Using numerical experiments, we demonstrate the
benefits of this implicit regularization in yielding a more accurate estimation
and better convergence properties."
DIGAT: Modeling News Recommendation with Dual-Graph Interaction,0.047045,"News recommendation (NR) is essential for online news services. Existing NR
methods typically adopt a news-user representation learning framework, facing
two potential limitations. First, in news encoder, single candidate news
encoding suffers from an insufficient semantic information problem. Second,
existing graph-based NR methods are promising but lack effective news-user
feature interaction, rendering the graph-based recommendation suboptimal. To
overcome these limitations, we propose dual-interactive graph attention
networks (DIGAT) consisting of news- and user-graph channels. In the news-graph
channel, we enrich the semantics of single candidate news by incorporating the
semantically relevant news information with a semantic-augmented graph (SAG).
In the user-graph channel, multi-level user interests are represented with a
news-topic graph. Most notably, we design a dual-graph interaction process to
perform effective feature interaction between the news and user graphs, which
facilitates accurate news-user representation matching. Experiment results on
the benchmark dataset MIND show that DIGAT outperforms existing news
recommendation methods. Further ablation studies and analyses validate the
effectiveness of (1) semantic-augmented news graph modeling and (2) dual-graph
interaction."
"Strategy Complexity of Point Payoff, Mean Payoff and Total Payoff Objectives in Countable MDPs",0.0,"We study countably infinite Markov decision processes (MDPs) with real-valued
transition rewards. Every infinite run induces the following sequences of
payoffs: 1. Point payoff (the sequence of directly seen transition rewards), 2.
Mean payoff (the sequence of the sums of all rewards so far, divided by the
number of steps), and 3. Total payoff (the sequence of the sums of all rewards
so far). For each payoff type, the objective is to maximize the probability
that the $\liminf$ is non-negative. We establish the complete picture of the
strategy complexity of these objectives, i.e., how much memory is necessary and
sufficient for $\varepsilon$-optimal (resp. optimal) strategies. Some cases can
be won with memoryless deterministic strategies, while others require a step
counter, a reward counter, or both."
M-Adapter: Modality Adaptation for End-to-End Speech-to-Text Translation,0.173782,"End-to-end speech-to-text translation models are often initialized with
pre-trained speech encoder and pre-trained text decoder. This leads to a
significant training gap between pre-training and fine-tuning, largely due to
the modality differences between speech outputs from the encoder and text
inputs to the decoder. In this work, we aim to bridge the modality gap between
speech and text to improve translation quality. We propose M-Adapter, a novel
Transformer-based module, to adapt speech representations to text. While
shrinking the speech sequence, M-Adapter produces features desired for
speech-to-text translation via modelling global and local dependencies of a
speech sequence. Our experimental results show that our model outperforms a
strong baseline by up to 1 BLEU score on the Must-C En$\rightarrow$DE
dataset.\footnote{Our code is available at
https://github.com/mingzi151/w2v2-st.}"
An Efficient FPGA-based Accelerator for Deep Forest,0.022816,"Deep Forest is a prominent machine learning algorithm known for its high
accuracy in forecasting. Compared with deep neural networks, Deep Forest has
almost no multiplication operations and has better performance on small
datasets. However, due to the deep structure and large forest quantity, it
suffers from large amounts of calculation and memory consumption. In this
paper, an efficient hardware accelerator is proposed for deep forest models,
which is also the first work to implement Deep Forest on FPGA. Firstly, a
delicate node computing unit (NCU) is designed to improve inference speed.
Secondly, based on NCU, an efficient architecture and an adaptive dataflow are
proposed, in order to alleviate the problem of node computing imbalance in the
classification process. Moreover, an optimized storage scheme in this design
also improves hardware utilization and power efficiency. The proposed design is
implemented on an FPGA board, Intel Stratix V, and it is evaluated by two
typical datasets, ADULT and Face Mask Detection. The experimental results show
that the proposed design can achieve around 40x speedup compared to that on a
40 cores high performance x86 CPU."
Monte Carlo Planning in Hybrid Belief POMDPs,0.00816115,"Real-world problems often require reasoning about hybrid beliefs, over both
discrete and continuous random variables. Yet, such a setting has hardly been
investigated in the context of planning. Moreover, existing online Partially
Observable Markov Decision Processes (POMDPs) solvers do not support hybrid
beliefs directly. In particular, these solvers do not address the added
computational burden due to an increasing number of hypotheses with the
planning horizon, which can grow exponentially. As part of this work, we
present a novel algorithm, Hybrid Belief Monte Carlo Planning (HB-MCP) that
utilizes the Monte Carlo Tree Search (MCTS) algorithm to solve a POMDP while
maintaining a hybrid belief. We illustrate how the upper confidence bound (UCB)
exploration bonus can be leveraged to guide the growth of hypotheses trees
alongside the belief trees. We then evaluate our approach in highly aliased
simulated environments where unresolved data association leads to multi-modal
belief hypotheses."
Find a Way Forward: a Language-Guided Semantic Map Navigator,0.0759383,"In this paper, we introduce the map-language navigation task where an agent
executes natural language instructions and moves to the target position based
only on a given 3D semantic map. To tackle the task, we design the
instruction-aware Path Proposal and Discrimination model (iPPD). Our approach
leverages map information to provide instruction-aware path proposals, i.e., it
selects all potential instruction-aligned candidate paths to reduce the
solution space. Next, to represent the map observations along a path for a
better modality alignment, a novel Path Feature Encoding scheme tailored for
semantic maps is proposed. An attention-based Language Driven Discriminator is
designed to evaluate path candidates and determine the best path as the final
result. Our method can naturally avoid error accumulation compared with
single-step greedy decision methods. Comparing to a single-step imitation
learning approach, iPPD has performance gains above 17% on navigation success
and 0.18 on path matching measurement nDTW in challenging unseen environments."
Cross-Align: Modeling Deep Cross-lingual Interactions for Word Alignment,0.0211242,"Word alignment which aims to extract lexicon translation equivalents between
source and target sentences, serves as a fundamental tool for natural language
processing. Recent studies in this area have yielded substantial improvements
by generating alignments from contextualized embeddings of the pre-trained
multilingual language models. However, we find that the existing approaches
capture few interactions between the input sentence pairs, which degrades the
word alignment quality severely, especially for the ambiguous words in the
monolingual context. To remedy this problem, we propose Cross-Align to model
deep interactions between the input sentence pairs, in which the source and
target sentences are encoded separately with the shared self-attention modules
in the shallow layers, while cross-lingual interactions are explicitly
constructed by the cross-attention modules in the upper layers. Besides, to
train our model effectively, we propose a two-stage training framework, where
the model is trained with a simple Translation Language Modeling (TLM)
objective in the first stage and then finetuned with a self-supervised
alignment objective in the second stage. Experiments show that the proposed
Cross-Align achieves the state-of-the-art (SOTA) performance on four out of
five language pairs."
PointInverter: Point Cloud Reconstruction and Editing via a Generative Model with Shape Priors,0.0352937,"In this paper, we propose a new method for mapping a 3D point cloud to the
latent space of a 3D generative adversarial network. Our generative model for
3D point clouds is based on SP-GAN, a state-of-the-art sphere-guided 3D point
cloud generator. We derive an efficient way to encode an input 3D point cloud
to the latent space of the SP-GAN. Our point cloud encoder can resolve the
point ordering issue during inversion, and thus can determine the
correspondences between points in the generated 3D point cloud and those in the
canonical sphere used by the generator. We show that our method outperforms
previous GAN inversion methods for 3D point clouds, achieving state-of-the-art
results both quantitatively and qualitatively. Our code is available at
https://github.com/hkust-vgd/point_inverter."
Argumentative Reward Learning: Reasoning About Human Preferences,0.0157905,"We define a novel neuro-symbolic framework, argumentative reward learning,
which combines preference-based argumentation with existing approaches to
reinforcement learning from human feedback. Our method improves prior work by
generalising human preferences, reducing the burden on the user and increasing
the robustness of the reward model. We demonstrate this with a number of
experiments."
Representing Spatial Trajectories as Distributions,0.0,"We introduce a representation learning framework for spatial trajectories. We
represent partial observations of trajectories as probability distributions in
a learned latent space, which characterize the uncertainty about unobserved
parts of the trajectory. Our framework allows us to obtain samples from a
trajectory for any continuous point in time, both interpolating and
extrapolating. Our flexible approach supports directly modifying specific
attributes of a trajectory, such as its pace, as well as combining different
partial observations into single representations. Experiments show our method's
advantage over baselines in prediction tasks."
A Baseline for Detecting Out-of-Distribution Examples in Image Captioning,0.0101605,"Image captioning research achieved breakthroughs in recent years by
developing neural models that can generate diverse and high-quality
descriptions for images drawn from the same distribution as training images.
However, when facing out-of-distribution (OOD) images, such as corrupted
images, or images containing unknown objects, the models fail in generating
relevant captions.
  In this paper, we consider the problem of OOD detection in image captioning.
We formulate the problem and suggest an evaluation setup for assessing the
model's performance on the task. Then, we analyze and show the effectiveness of
the caption's likelihood score at detecting and rejecting OOD images, which
implies that the relatedness between the input image and the generated caption
is encapsulated within the score."
CLEAR: Causal Explanations from Attention in Neural Recommenders,0.0450677,"We present CLEAR, a method for learning session-specific causal graphs, in
the possible presence of latent confounders, from attention in pre-trained
attention-based recommenders. These causal graphs describe user behavior,
within the context captured by attention, and can provide a counterfactual
explanation for a recommendation. In essence, these causal graphs allow
answering ""why"" questions uniquely for any specific session. Using empirical
evaluations we show that, compared to naively using attention weights to
explain input-output relations, counterfactual explanations found by CLEAR are
shorter and an alternative recommendation is ranked higher in the original
top-k recommendations."
Stop Filtering: Multi-View Attribute-Enhanced Dialogue Learning,0.0227809,"There is a growing interest in improving the conversational ability of models
by filtering the raw dialogue corpora. Previous filtering strategies usually
rely on a scoring method to assess and discard samples from one perspective,
enabling the model to enhance the corresponding dialogue attributes (e.g.,
consistency) more easily. However, the discarded samples may obtain high scores
in other perspectives and can provide regularization effects on the model
learning, which causes the performance improvement to be sensitive to the
filtering ratio. In this work, we propose a multi-view attribute-enhanced
dialogue learning framework that strengthens the attribute-related features
more robustly and comprehensively. Instead of filtering the raw dataset to
train the model, our framework first pre-trains the model on the raw dataset
and then fine-tunes it through adapters on the selected sub-sets, which also
enhances certain attributes of responses but without suffering from the
problems mentioned above. Considering the variety of the dialogue attribute, we
further design a multi-view enhancement mechanism, including multi-view
selection and inter-view fusion. It groups the high-quality samples from
multiple perspectives, respectively, and enhances different attributes of
responses with the corresponding sample sets and adapters, keeping knowledge
independent and allowing flexible integration. Empirical results and analysis
show that our framework can improve the performance significantly in terms of
enhancing dialogue attributes and fusing view-specific knowledge."
Estimating Social Influence from Observational Data,0.00737052,"We consider the problem of estimating social influence, the effect that a
person's behavior has on the future behavior of their peers. The key challenge
is that shared behavior between friends could be equally explained by influence
or by two other confounding factors: 1) latent traits that caused people to
both become friends and engage in the behavior, and 2) latent preferences for
the behavior. This paper addresses the challenges of estimating social
influence with three contributions. First, we formalize social influence as a
causal effect, one which requires inferences about hypothetical interventions.
Second, we develop Poisson Influence Factorization (PIF), a method for
estimating social influence from observational data. PIF fits probabilistic
factor models to networks and behavior data to infer variables that serve as
substitutes for the confounding latent traits. Third, we develop assumptions
under which PIF recovers estimates of social influence. We empirically study
PIF with semi-synthetic and real data from Last.fm, and conduct a sensitivity
analysis. We find that PIF estimates social influence most accurately compared
to related methods and remains robust under some violations of its assumptions."
DimonGen: Diversified Generative Commonsense Reasoning for Explaining Concept Relationships,0.0436572,"In this paper, we propose DimonGen, which aims to generate diverse sentences
describing concept relationships in various everyday scenarios. To support
this, we first create a benchmark dataset for this task by adapting the
existing CommonGen dataset. We then propose a two-stage model called MoREE to
generate the target sentences. MoREE consists of a mixture of retrievers model
that retrieves diverse context sentences related to the given concepts, and a
mixture of generators model that generates diverse sentences based on the
retrieved contexts. We conduct experiments on the DimonGen task and show that
MoREE outperforms strong baselines in terms of both the quality and diversity
of the generated sentences. Our results demonstrate that MoREE is able to
generate diverse sentences that reflect different relationships between
concepts, leading to a comprehensive understanding of concept relationships."
System Resilience through Health Monitoring and Reconfiguration,0.0653568,"We demonstrate an end-to-end framework to improve the resilience of man-made
systems to unforeseen events. The framework is based on a physics-based digital
twin model and three modules tasked with real-time fault diagnosis, prognostics
and reconfiguration. The fault diagnosis module uses model-based diagnosis
algorithms to detect and isolate faults and generates interventions in the
system to disambiguate uncertain diagnosis solutions. We scale up the fault
diagnosis algorithm to the required real-time performance through the use of
parallelization and surrogate models of the physics-based digital twin. The
prognostics module tracks the fault progressions and trains the online
degradation models to compute remaining useful life of system components. In
addition, we use the degradation models to assess the impact of the fault
progression on the operational requirements. The reconfiguration module uses
PDDL-based planning endowed with semantic attachments to adjust the system
controls so that the fault impact on the system operation is minimized. We
define a resilience metric and use the example of a fuel system model to
demonstrate how the metric improves with our framework."
Urban Scene Semantic Segmentation with Low-Cost Coarse Annotation,0.0622467,"For best performance, today's semantic segmentation methods use large and
carefully labeled datasets, requiring expensive annotation budgets. In this
work, we show that coarse annotation is a low-cost but highly effective
alternative for training semantic segmentation models. Considering the urban
scene segmentation scenario, we leverage cheap coarse annotations for
real-world captured data, as well as synthetic data to train our model and show
competitive performance compared with finely annotated real-world data.
Specifically, we propose a coarse-to-fine self-training framework that
generates pseudo labels for unlabeled regions of the coarsely annotated data,
using synthetic data to improve predictions around the boundaries between
semantic classes, and using cross-domain data augmentation to increase
diversity. Our extensive experimental results on Cityscapes and BDD100k
datasets demonstrate that our method achieves a significantly better
performance vs annotation cost tradeoff, yielding a comparable performance to
fully annotated data with only a small fraction of the annotation budget. Also,
when used as pretraining, our framework performs better compared to the
standard fully supervised setting."
Contrastive Learning for Joint Normal Estimation and Point Cloud Filtering,0.00437056,"Point cloud filtering and normal estimation are two fundamental research
problems in the 3D field. Existing methods usually perform normal estimation
and filtering separately and often show sensitivity to noise and/or inability
to preserve sharp geometric features such as corners and edges. In this paper,
we propose a novel deep learning method to jointly estimate normals and filter
point clouds. We first introduce a 3D patch based contrastive learning
framework, with noise corruption as an augmentation, to train a feature encoder
capable of generating faithful representations of point cloud patches while
remaining robust to noise. These representations are consumed by a simple
regression network and supervised by a novel joint loss, simultaneously
estimating point normals and displacements that are used to filter the patch
centers. Experimental results show that our method well supports the two tasks
simultaneously and preserves sharp features and fine details. It generally
outperforms state-of-the-art techniques on both tasks. Our source code is
available at https://github.com/ddsediri/CLJNEPCF."
Local Feature Swapping for Generalization in Reinforcement Learning,0.0422064,"Over the past few years, the acceleration of computing resources and research
in deep learning has led to significant practical successes in a range of
tasks, including in particular in computer vision. Building on these advances,
reinforcement learning has also seen a leap forward with the emergence of
agents capable of making decisions directly from visual observations. Despite
these successes, the over-parametrization of neural architectures leads to
memorization of the data used during training and thus to a lack of
generalization. Reinforcement learning agents based on visual inputs also
suffer from this phenomenon by erroneously correlating rewards with unrelated
visual features such as background elements. To alleviate this problem, we
introduce a new regularization technique consisting of channel-consistent local
permutations (CLOP) of the feature maps. The proposed permutations induce
robustness to spatial correlations and help prevent overfitting behaviors in
RL. We demonstrate, on the OpenAI Procgen Benchmark, that RL agents trained
with the CLOP method exhibit robustness to visual changes and better
generalization properties than agents trained using other state-of-the-art
regularization techniques. We also demonstrate the effectiveness of CLOP as a
general regularization technique in supervised learning."
PIZZA: A Powerful Image-only Zero-Shot Zero-CAD Approach to 6 DoF Tracking,0.0586418,"Estimating the relative pose of a new object without prior knowledge is a
hard problem, while it is an ability very much needed in robotics and Augmented
Reality. We present a method for tracking the 6D motion of objects in RGB video
sequences when neither the training images nor the 3D geometry of the objects
are available. In contrast to previous works, our method can therefore consider
unknown objects in open world instantly, without requiring any prior
information or a specific training phase. We consider two architectures, one
based on two frames, and the other relying on a Transformer Encoder, which can
exploit an arbitrary number of past frames. We train our architectures using
only synthetic renderings with domain randomization. Our results on challenging
datasets are on par with previous works that require much more information
(training images of the target objects, 3D models, and/or depth data). Our
source code is available at https://github.com/nv-nguyen/pizza"
Real3D-Aug: Point Cloud Augmentation by Placing Real Objects with Occlusion Handling for 3D Detection and Segmentation,0.079046,"Object detection and semantic segmentation with the 3D lidar point cloud data
require expensive annotation. We propose a data augmentation method that takes
advantage of already annotated data multiple times. We propose an augmentation
framework that reuses real data, automatically finds suitable placements in the
scene to be augmented, and handles occlusions explicitly. Due to the usage of
the real data, the scan points of newly inserted objects in augmentation
sustain the physical characteristics of the lidar, such as intensity and
raydrop. The pipeline proves competitive in training top-performing models for
3D object detection and semantic segmentation. The new augmentation provides a
significant performance gain in rare and essential classes, notably 6.65%
average precision gain for ""Hard"" pedestrian class in KITTI object detection or
2.14 mean IoU gain in the SemanticKITTI segmentation challenge over the state
of the art."
Featurized Query R-CNN,0.0817561,"The query mechanism introduced in the DETR method is changing the paradigm of
object detection and recently there are many query-based methods have obtained
strong object detection performance. However, the current query-based detection
pipelines suffer from the following two issues. Firstly, multi-stage decoders
are required to optimize the randomly initialized object queries, incurring a
large computation burden. Secondly, the queries are fixed after training,
leading to unsatisfying generalization capability. To remedy the above issues,
we present featurized object queries predicted by a query generation network in
the well-established Faster R-CNN framework and develop a Featurized Query
R-CNN. Extensive experiments on the COCO dataset show that our Featurized Query
R-CNN obtains the best speed-accuracy trade-off among all R-CNN detectors,
including the recent state-of-the-art Sparse R-CNN detector. The code is
available at {https://github.com/hustvl/Featurized-QueryRCNN."
Performance of different machine learning methods on activity recognition and pose estimation datasets,0.0031964,"With advancements in computer vision taking place day by day, recently a lot
of light is being shed on activity recognition. With the range for real-world
applications utilizing this field of study increasing across a multitude of
industries such as security and healthcare, it becomes crucial for businesses
to distinguish which machine learning methods perform better than others in the
area. This paper strives to aid in this predicament i.e. building upon previous
related work, it employs both classical and ensemble approaches on rich pose
estimation (OpenPose) and HAR datasets. Making use of appropriate metrics to
evaluate the performance for each model, the results show that overall, random
forest yields the highest accuracy in classifying ADLs. Relatively all the
models have excellent performance across both datasets, except for logistic
regression and AdaBoost perform poorly in the HAR one. With the limitations of
this paper also discussed in the end, the scope for further research is vast,
which can use this paper as a base in aims of producing better results."
Data-driven Parsing Evaluation for Child-Parent Interactions,0.006907,"We present a syntactic dependency treebank for naturalistic child and
child-directed speech in English (MacWhinney, 2000). Our annotations largely
followed the guidelines of the Universal Dependencies project (UD (Zeman et
al., 2022)), with detailed extensions to lexical/syntactic structures unique to
conversational speech (in opposition to written texts). Compared to existing
UD-style spoken treebanks as well as other dependency corpora of child-parent
interactions specifically, our dataset is of (much) larger size (N of
utterances = 44,744; N of words = 233, 907) and contains speech from a total of
10 children covering a wide age range (18-66 months). With this dataset, we
ask: (1) How well would state-of-the-art dependency parsers, tailored for the
written domain, perform for speech of different interlocutors in spontaneous
conversations? (2) What is the relationship between parser performance and the
developmental stage of the child? To address these questions, in ongoing work,
we are conducting thorough dependency parser evaluations using both graph-based
and transition-based parsers with different hyperparameterization, trained from
three different types of out-of-domain written texts: news, tweets, and learner
data."
Can NMT Understand Me? Towards Perturbation-based Evaluation of NMT Models for Code Generation,0.0350812,"Neural Machine Translation (NMT) has reached a level of maturity to be
recognized as the premier method for the translation between different
languages and aroused interest in different research areas, including software
engineering. A key step to validate the robustness of the NMT models consists
in evaluating the performance of the models on adversarial inputs, i.e., inputs
obtained from the original ones by adding small amounts of perturbation.
However, when dealing with the specific task of the code generation (i.e., the
generation of code starting from a description in natural language), it has not
yet been defined an approach to validate the robustness of the NMT models. In
this work, we address the problem by identifying a set of perturbations and
metrics tailored for the robustness assessment of such models. We present a
preliminary experimental evaluation, showing what type of perturbations affect
the model the most and deriving useful insights for future directions."
Language Agnostic Code-Mixing Data Augmentation by Predicting Linguistic Patterns,0.0188526,"In this work, we focus on intrasentential code-mixing and propose several
different Synthetic Code-Mixing (SCM) data augmentation methods that outperform
the baseline on downstream sentiment analysis tasks across various amounts of
labeled gold data. Most importantly, our proposed methods demonstrate that
strategically replacing parts of sentences in the matrix language with a
constant mask significantly improves classification accuracy, motivating
further linguistic insights into the phenomenon of code-mixing. We test our
data augmentation method in a variety of low-resource and cross-lingual
settings, reaching up to a relative improvement of 7.73% on the extremely
scarce English-Malayalam dataset. We conclude that the code-switch pattern in
code-mixing sentences is also important for the model to learn. Finally, we
propose a language-agnostic SCM algorithm that is cheap yet extremely helpful
for low-resource languages."
Proceedings of the 2022 XCSP3 Competition,0.00677865,"This document represents the proceedings of the 2022 XCSP3 Competition. The
results of this competition of constraint solvers were presented at FLOC
(Federated Logic Conference) 2022 Olympic Games, held in Haifa, Israel from
31th July 2022 to 7th August, 2022."
HieNet: Bidirectional Hierarchy Framework for Automated ICD Coding,0.295195,"International Classification of Diseases (ICD) is a set of classification
codes for medical records. Automated ICD coding, which assigns unique
International Classification of Diseases codes with each medical record, is
widely used recently for its efficiency and error-prone avoidance. However,
there are challenges that remain such as heterogeneity, label unbalance, and
complex relationships between ICD codes. In this work, we proposed a novel
Bidirectional Hierarchy Framework(HieNet) to address the challenges.
Specifically, a personalized PageRank routine is developed to capture the
co-relation of codes, a bidirectional hierarchy passage encoder to capture the
codes' hierarchical representations, and a progressive predicting method is
then proposed to narrow down the semantic searching space of prediction. We
validate our method on two widely used datasets. Experimental results on two
authoritative public datasets demonstrate that our proposed method boosts
state-of-the-art performance by a large margin."
Learn to Adapt for Monocular Depth Estimation,0.0092392,"Monocular depth estimation is one of the fundamental tasks in environmental
perception and has achieved tremendous progress in virtue of deep learning.
However, the performance of trained models tends to degrade or deteriorate when
employed on other new datasets due to the gap between different datasets.
Though some methods utilize domain adaptation technologies to jointly train
different domains and narrow the gap between them, the trained models cannot
generalize to new domains that are not involved in training. To boost the
transferability of depth estimation models, we propose an adversarial depth
estimation task and train the model in the pipeline of meta-learning. Our
proposed adversarial task mitigates the issue of meta-overfitting, since the
network is trained in an adversarial manner and aims to extract domain
invariant representations. In addition, we propose a constraint to impose upon
cross-task depth consistency to compel the depth estimation to be identical in
different adversarial tasks, which improves the performance of our method and
smoothens the training process. Experiments demonstrate that our method adapts
well to new datasets after few training steps during the test procedure."
Abstract Interpretation on E-Graphs,0.00738385,"Recent e-graph applications have typically considered concrete semantics of
expressions, where the notion of equivalence stems from concrete interpretation
of expressions. However, equivalences that hold over one interpretation may not
hold in an alternative interpretation. Such an observation can be exploited. We
consider the application of abstract interpretation to e-graphs, and show that
within an e-graph, the lattice meet operation associated with the abstract
domain has a natural interpretation for an e-class, leading to improved
precision in over-approximation. In this extended abstract, we use Interval
Arithmetic (IA) to illustrate this point."
An Application of Pseudo-Log-Likelihoods to Natural Language Scoring,0.0114502,"Language models built using semi-supervised machine learning on large corpora
of natural language have very quickly enveloped the fields of natural language
generation and understanding. In this paper we apply a zero-shot approach
independently developed by a number of researchers now gaining recognition as a
significant alternative to fine-tuning for evaluation on common sense tasks. A
language model with relatively few parameters and training steps compared to a
more recent language model (T5) can outperform it on a recent large data set
(TimeDial), while displaying robustness in its performance across a similar
class of language tasks. Surprisingly, this result is achieved by using a
hyperparameter-free zero-shot method with the smaller model, compared to
fine-tuning to the larger model. We argue that robustness of the smaller model
ought to be understood in terms of compositionality, in a sense that we draw
from recent literature on a class of similar models. We identify a practical
cost for our method and model: high GPU-time for natural language evaluation.
The zero-shot measurement technique that produces remarkable stability, both
for ALBERT and other BERT variants, is an application of pseudo-log-likelihoods
to masked language models for the relative measurement of probability for
substitution alternatives in forced choice language tasks such as the Winograd
Schema Challenge, Winogrande, and others. One contribution of this paper is to
bring together a number of similar, but independent strands of research. We
produce some absolute state-of-the-art results for common sense reasoning in
binary choice tasks, performing better than any published result in the
literature, including fine-tuned efforts. We show a remarkable consistency of
the model's performance under adversarial settings, which we argue is best
explained by the model's compositionality of representations."
Computationally efficient joint coordination of multiple electric vehicle charging points using reinforcement learning,0.0180575,"A major challenge in todays power grid is to manage the increasing load from
electric vehicle (EV) charging. Demand response (DR) solutions aim to exploit
flexibility therein, i.e., the ability to shift EV charging in time and thus
avoid excessive peaks or achieve better balancing. Whereas the majority of
existing research works either focus on control strategies for a single EV
charger, or use a multi-step approach (e.g., a first high level aggregate
control decision step, followed by individual EV control decisions), we rather
propose a single-step solution that jointly coordinates multiple charging
points at once. In this paper, we further refine an initial proposal using
reinforcement learning (RL), specifically addressing computational challenges
that would limit its deployment in practice. More precisely, we design a new
Markov decision process (MDP) formulation of the EV charging coordination
process, exhibiting only linear space and time complexity (as opposed to the
earlier quadratic space complexity). We thus improve upon earlier
state-of-the-art, demonstrating 30% reduction of training time in our case
study using real-world EV charging session data. Yet, we do not sacrifice the
resulting performance in meeting the DR objectives: our new RL solutions still
improve the performance of charging demand coordination by 40-50% compared to a
business-as-usual policy (that charges EV fully upon arrival) and 20-30%
compared to a heuristic policy (that uniformly spreads individual EV charging
over time)."
"""Dummy Grandpa, do you know anything?"": Identifying and Characterizing Ad hominem Fallacy Usage in the Wild",0.0429732,"Today, participating in discussions on online forums is extremely commonplace
and these discussions have started rendering a strong influence on the overall
opinion of online users. Naturally, twisting the flow of the argument can have
a strong impact on the minds of naive users, which in the long run might have
socio-political ramifications, for example, winning an election or spreading
targeted misinformation. Thus, these platforms are potentially highly
vulnerable to malicious players who might act individually or as a cohort to
breed fallacious arguments with a motive to sway public opinion. Ad hominem
arguments are one of the most effective forms of such fallacies. Although a
simple fallacy, it is effective enough to sway public debates in offline world
and can be used as a precursor to shutting down the voice of opposition by
slander.
  In this work, we take a first step in shedding light on the usage of ad
hominem fallacies in the wild. First, we build a powerful ad hominem detector
with high accuracy (F1 more than 83%, showing a significant improvement over
prior work), even for datasets for which annotated instances constitute a very
small fraction. We then used our detector on 265k arguments collected from the
online debate forum - CreateDebate. Our crowdsourced surveys validate our
in-the-wild predictions on CreateDebate data (94% match with manual
annotation). Our analysis revealed that a surprising 31.23% of CreateDebate
content contains ad hominem fallacy, and a cohort of highly active users post
significantly more ad hominem to suppress opposing views. Then, our temporal
analysis revealed that ad hominem argument usage increased significantly since
the 2016 US Presidential election, not only for topics like Politics, but also
for Science and Law. We conclude by discussing important implications of our
work to detect and defend against ad hominem fallacies."
Anytime-Lidar: Deadline-aware 3D Object Detection,0.0414184,"In this work, we present a novel scheduling framework enabling anytime
perception for deep neural network (DNN) based 3D object detection pipelines.
We focus on computationally expensive region proposal network (RPN) and
per-category multi-head detector components, which are common in 3D object
detection pipelines, and make them deadline-aware. We propose a scheduling
algorithm, which intelligently selects the subset of the components to make
effective time and accuracy trade-off on the fly. We minimize accuracy loss of
skipping some of the neural network sub-components by projecting previously
detected objects onto the current scene through estimations. We apply our
approach to a state-of-art 3D object detection network, PointPillars, and
evaluate its performance on Jetson Xavier AGX using nuScenes dataset. Compared
to the baselines, our approach significantly improve the network's accuracy
under various deadline constraints."
Learning functional sections in medical conversations: iterative pseudo-labeling and human-in-the-loop approach,0.0131034,"Medical conversations between patients and medical professionals have
implicit functional sections, such as ""history taking"", ""summarization"",
""education"", and ""care plan."" In this work, we are interested in learning to
automatically extract these sections. A direct approach would require
collecting large amounts of expert annotations for this task, which is
inherently costly due to the contextual inter-and-intra variability between
these sections. This paper presents an approach that tackles the problem of
learning to classify medical dialogue into functional sections without
requiring a large number of annotations. Our approach combines pseudo-labeling
and human-in-the-loop. First, we bootstrap using weak supervision with
pseudo-labeling to generate dialogue turn-level pseudo-labels and train a
transformer-based model, which is then applied to individual sentences to
create noisy sentence-level labels. Second, we iteratively refine
sentence-level labels using a cluster-based human-in-the-loop approach. Each
iteration requires only a few dozen annotator decisions. We evaluate the
results on an expert-annotated dataset of 100 dialogues and find that while our
models start with 69.5% accuracy, we can iteratively improve it to 82.5%. The
code used to perform all experiments described in this paper can be found here:
https://github.com/curai/curai-research/tree/main/functional-sections."
Prompt-based Generative Approach towards Multi-Hierarchical Medical Dialogue State Tracking,0.0861141,"The medical dialogue system is a promising application that can provide great
convenience for patients. The dialogue state tracking (DST) module in the
medical dialogue system which interprets utterances into the machine-readable
structure for downstream tasks is particularly challenging. Firstly, the states
need to be able to represent compound entities such as symptoms with their body
part or diseases with degrees of severity to provide enough information for
decision support. Secondly, these named entities in the utterance might be
discontinuous and scattered across sentences and speakers. These also make it
difficult to annotate a large corpus which is essential for most methods.
Therefore, we first define a multi-hierarchical state structure. We annotate
and publish a medical dialogue dataset in Chinese. To the best of our
knowledge, there are no publicly available ones before. Then we propose a
Prompt-based Generative Approach which can generate slot values with
multi-hierarchies incrementally using a top-down approach. A dialogue style
prompt is also supplemented to utilize the large unlabeled dialogue corpus to
alleviate the data scarcity problem. The experiments show that our approach
outperforms other DST methods and is rather effective in the scenario with
little data."
Attentive Dual Stream Siamese U-net for Flood Detection on Multi-temporal Sentinel-1 Data,0.331598,"Due to climate and land-use change, natural disasters such as flooding have
been increasing in recent years. Timely and reliable flood detection and
mapping can help emergency response and disaster management. In this work, we
propose a flood detection network using bi-temporal SAR acquisitions. The
proposed segmentation network has an encoder-decoder architecture with two
Siamese encoders for pre and post-flood images. The network's feature maps are
fused and enhanced using attention blocks to achieve more accurate detection of
the flooded areas. Our proposed network is evaluated on publicly available
Sen1Flood11 benchmark dataset. The network outperformed the existing
state-of-the-art (uni-temporal) flood detection method by 6\% IOU. The
experiments highlight that the combination of bi-temporal SAR data with an
effective network architecture achieves more accurate flood detection than
uni-temporal methods."
Rethinking Round-Trip Translation for Machine Translation Evaluation,0.00968215,"Automatic evaluation on low-resource language translation suffers from a
deficiency of parallel corpora. Round-trip translation could be served as a
clever and straightforward technique to alleviate the requirement of the
parallel evaluation corpus. However, there was an observation of obscure
correlations between the evaluation scores by forward and round-trip
translations in the era of statistical machine translation (SMT). In this
paper, we report the surprising finding that round-trip translation can be used
for automatic evaluation without the references. Firstly, our revisit on the
round-trip translation in SMT evaluation unveils that its long-standing
misunderstanding is essentially caused by copying mechanism. After removing
copying mechanism in SMT, round-trip translation scores can appropriately
reflect the forward translation performance. Then, we demonstrate the
rectification is overdue as round-trip translation could benefit multiple
machine translation evaluation tasks. To be more specific, round-trip
translation could be used i) to predict corresponding forward translation
scores; ii) to improve the performance of the recently advanced quality
estimation model; and iii) to identify adversarial competitors in shared tasks
via cross-system verification."
VizInspect Pro -- Automated Optical Inspection (AOI) solution,0.0604405,"Traditional vision based Automated Optical Inspection (referred to as AOI in
paper) systems present multiple challenges in factory settings including
inability to scale across multiple product lines, requirement of vendor
programming expertise, little tolerance to variations and lack of cloud
connectivity for aggregated insights. The lack of flexibility in these systems
presents a unique opportunity for a deep learning based AOI system specifically
for factory automation. The proposed solution, VizInspect pro is a generic
computer vision based AOI solution built on top of Leo - An edge AI platform.
Innovative features that overcome challenges of traditional vision systems
include deep learning based image analysis which combines the power of
self-learning with high speed and accuracy, an intuitive user interface to
configure inspection profiles in minutes without ML or vision expertise and the
ability to solve complex inspection challenges while being tolerant to
deviations and unpredictable defects. This solution has been validated by
multiple external enterprise customers with confirmed value propositions. In
this paper we show you how this solution and platform solved problems around
model development, deployment, scaling multiple inferences and visualizations."
WikiMulti: a Corpus for Cross-Lingual Summarization,0.0260199,"Cross-lingual summarization (CLS) is the task to produce a summary in one
particular language for a source document in a different language. We introduce
WikiMulti - a new dataset for cross-lingual summarization based on Wikipedia
articles in 15 languages. As a set of baselines for further studies, we
evaluate the performance of existing cross-lingual abstractive summarization
methods on our dataset. We make our dataset publicly available here:
https://github.com/tikhonovpavel/wikimulti"
VRKitchen2.0-IndoorKit: A Tutorial for Augmented Indoor Scene Building in Omniverse,0.0250651,"With the recent progress of simulations by 3D modeling software and game
engines, many researchers have focused on Embodied AI tasks in the virtual
environment. However, the research community lacks a platform that can easily
serve both indoor scene synthesis and model benchmarking with various
algorithms. Meanwhile, computer graphics-related tasks need a toolkit for
implementing advanced synthesizing techniques. To facilitate the study of
indoor scene building methods and their potential robotics applications, we
introduce INDOORKIT: a built-in toolkit for NVIDIA OMNIVERSE that provides
flexible pipelines for indoor scene building, scene randomizing, and animation
controls. Besides, combining Python coding in the animation software INDOORKIT
assists researchers in creating real-time training and controlling avatars and
robotics. The source code for this toolkit is available at
https://github.com/realvcla/VRKitchen2.0-Tutorial, and the tutorial along with
the toolkit is available at https://vrkitchen20-tutorial.readthedocs.io/en/"
Solving Bilevel Knapsack Problem using Graph Neural Networks,0.0258778,"The Bilevel Optimization Problem is a hierarchical optimization problem with
two agents, a leader and a follower. The leader make their own decisions first,
and the followers make the best choices accordingly. The leader knows the
information of the followers, and the goal of the problem is to find the
optimal solution by considering the reactions of the followers from the
leader's point of view. For the Bilevel Optimization Problem, there are no
general and efficient algorithms or commercial solvers to get an optimal
solution, and it is very difficult to get a good solution even for a simple
problem. In this paper, we propose a deep learning approach using Graph Neural
Networks to solve the bilevel knapsack problem. We train the model to predict
the leader's solution and use it to transform the hierarchical optimization
problem into a single-level optimization problem to get the solution. Our model
found the feasible solution that was about 500 times faster than the exact
algorithm with $1.7\%$ optimal gap. Also, our model performed well on problems
of different size from the size it was trained on."
Enriching Abusive Language Detection with Community Context,0.00926749,"Uses of pejorative expressions can be benign or actively empowering. When
models for abuse detection misclassify these expressions as derogatory, they
inadvertently censor productive conversations held by marginalized groups. One
way to engage with non-dominant perspectives is to add context around
conversations. Previous research has leveraged user- and thread-level features,
but it often neglects the spaces within which productive conversations take
place. Our paper highlights how community context can improve classification
outcomes in abusive language detection. We make two main contributions to this
end. First, we demonstrate that online communities cluster by the nature of
their support towards victims of abuse. Second, we establish how community
context improves accuracy and reduces the false positive rates of
state-of-the-art abusive language classifiers. These findings suggest a
promising direction for context-aware models in abusive language research."
A Unified Image Preprocessing Framework For Image Compression,0.0145753,"With the development of streaming media technology, increasing communication
relies on sound and visual information, which puts a massive burden on online
media. Data compression becomes increasingly important to reduce the volume of
data transmission and storage. To further improve the efficiency of image
compression, researchers utilize various image processing methods to compensate
for the limitations of conventional codecs and advanced learning-based
compression methods. Instead of modifying the image compression oriented
approaches, we propose a unified image compression preprocessing framework,
called Kuchen, which aims to further improve the performance of existing
codecs. The framework consists of a hybrid data labeling system along with a
learning-based backbone to simulate personalized preprocessing. As far as we
know, this is the first exploration of setting a unified preprocessing
benchmark in image compression tasks. Results demonstrate that the modern
codecs optimized by our unified preprocessing framework constantly improve the
efficiency of the state-of-the-art compression."
Hierarchical Graph Structures for Congestion and ETA Prediction,0.00631613,"Traffic4cast is an annual competition to predict spatio temporal traffic
based on real world data. We propose an approach using Graph Neural Networks
that directly works on the road graph topology which was extracted from
OpenStreetMap data. Our architecture can incorporate a hierarchical graph
representation to improve the information flow between key intersections of the
graph and the shortest paths connecting them. Furthermore, we investigate how
the road graph can be compacted to ease the flow of information and make use of
a multi-task approach to predict congestion classes and ETA simultaneously. Our
code and models are released here:
https://github.com/floriangroetschla/NeurIPS2022-traffic4cast"
An Overview of Distant Supervision for Relation Extraction with a Focus on Denoising and Pre-training Methods,0.0537049,"Relation Extraction (RE) is a foundational task of natural language
processing. RE seeks to transform raw, unstructured text into structured
knowledge by identifying relational information between entity pairs found in
text. RE has numerous uses, such as knowledge graph completion, text
summarization, question-answering, and search querying. The history of RE
methods can be roughly organized into four phases: pattern-based RE,
statistical-based RE, neural-based RE, and large language model-based RE. This
survey begins with an overview of a few exemplary works in the earlier phases
of RE, highlighting limitations and shortcomings to contextualize progress.
Next, we review popular benchmarks and critically examine metrics used to
assess RE performance. We then discuss distant supervision, a paradigm that has
shaped the development of modern RE methods. Lastly, we review recent RE works
focusing on denoising and pre-training methods."
Efficient Speech Translation with Pre-trained Models,0.0114363,"When building state-of-the-art speech translation models, the need for large
computational resources is a significant obstacle due to the large training
data size and complex models. The availability of pre-trained models is a
promising opportunity to build strong speech translation systems efficiently.
In a first step, we investigate efficient strategies to build cascaded and
end-to-end speech translation systems based on pre-trained models. Using this
strategy, we can train and apply the models on a single GPU. While the
end-to-end models show superior translation performance to cascaded ones, the
application of this technology has a limitation on the need for additional
end-to-end training data. In a second step, we proposed an additional
similarity loss to encourage the model to generate similar hidden
representations for speech and transcript. Using this technique, we can
increase the data efficiency and improve the translation quality by 6 BLEU
points in scenarios with limited end-to-end training data."
New wrapper method based on normalized mutual information for dimension reduction and classification of hyperspectral images,0.045995,"Feature selection is one of the most important problems in hyperspectral
images classification. It consists to choose the most informative bands from
the entire set of input datasets and discard the noisy, redundant and
irrelevant ones. In this context, we propose a new wrapper method based on
normalized mutual information (NMI) and error probability (PE) using support
vector machine (SVM) to reduce the dimensionality of the used hyperspectral
images and increase the classification efficiency. The experiments have been
performed on two challenging hyperspectral benchmarks datasets captured by the
NASA's Airborne Visible/Infrared Imaging Spectrometer Sensor (AVIRIS). Several
metrics had been calculated to evaluate the performance of the proposed
algorithm. The obtained results prove that our method can increase the
classification performance and provide an accurate thematic map in comparison
with other reproduced algorithms. This method may be improved for more
classification efficiency. Keywords-Feature selection, hyperspectral images,
classification, wrapper, normalized mutual information, support vector machine."
Domain Mismatch Doesn't Always Prevent Cross-Lingual Transfer Learning,0.0231278,"Cross-lingual transfer learning without labeled target language data or
parallel text has been surprisingly effective in zero-shot cross-lingual
classification, question answering, unsupervised machine translation, etc.
However, some recent publications have claimed that domain mismatch prevents
cross-lingual transfer, and their results show that unsupervised bilingual
lexicon induction (UBLI) and unsupervised neural machine translation (UNMT) do
not work well when the underlying monolingual corpora come from different
domains (e.g., French text from Wikipedia but English text from UN
proceedings). In this work, we show that a simple initialization regimen can
overcome much of the effect of domain mismatch in cross-lingual transfer. We
pre-train word and contextual embeddings on the concatenated domain-mismatched
corpora, and use these as initializations for three tasks: MUSE UBLI, UN
Parallel UNMT, and the SemEval 2017 cross-lingual word similarity task. In all
cases, our results challenge the conclusions of prior work by showing that
proper initialization can recover a large portion of the losses incurred by
domain mismatch."
Using EBGAN for Anomaly Intrusion Detection,0.0142173,"As an active network security protection scheme, intrusion detection system
(IDS) undertakes the important responsibility of detecting network attacks in
the form of malicious network traffic. Intrusion detection technology is an
important part of IDS. At present, many scholars have carried out extensive
research on intrusion detection technology. However, developing an efficient
intrusion detection method for massive network traffic data is still difficult.
Since Generative Adversarial Networks (GANs) have powerful modeling
capabilities for complex high-dimensional data, they provide new ideas for
addressing this problem. In this paper, we put forward an EBGAN-based intrusion
detection method, IDS-EBGAN, that classifies network records as normal traffic
or malicious traffic. The generator in IDS-EBGAN is responsible for converting
the original malicious network traffic in the training set into adversarial
malicious examples. This is because we want to use adversarial learning to
improve the ability of discriminator to detect malicious traffic. At the same
time, the discriminator adopts Autoencoder model. During testing, IDS-EBGAN
uses reconstruction error of discriminator to classify traffic records."
A Means-End Account of Explainable Artificial Intelligence,0.040278,"Explainable artificial intelligence (XAI) seeks to produce explanations for
those machine learning methods which are deemed opaque. However, there is
considerable disagreement about what this means and how to achieve it. Authors
disagree on what should be explained (topic), to whom something should be
explained (stakeholder), how something should be explained (instrument), and
why something should be explained (goal). In this paper, I employ insights from
means-end epistemology to structure the field. According to means-end
epistemology, different means ought to be rationally adopted to achieve
different epistemic ends. Applied to XAI, different topics, stakeholders, and
goals thus require different instruments. I call this the means-end account of
XAI. The means-end account has a descriptive and a normative component: on the
one hand, I show how the specific means-end relations give rise to a taxonomy
of existing contributions to the field of XAI; on the other hand, I argue that
the suitability of XAI methods can be assessed by analyzing whether they are
prescribed by a given topic, stakeholder, and goal."
Context-Dependent Anomaly Detection with Knowledge Graph Embedding Models,0.0098751,"Increasing the semantic understanding and contextual awareness of machine
learning models is important for improving robustness and reducing
susceptibility to data shifts. In this work, we leverage contextual awareness
for the anomaly detection problem. Although graphed-based anomaly detection has
been widely studied, context-dependent anomaly detection is an open problem and
without much current research. We develop a general framework for converting a
context-dependent anomaly detection problem to a link prediction problem,
allowing well-established techniques from this domain to be applied. We
implement a system based on our framework that utilizes knowledge graph
embedding models and demonstrates the ability to detect outliers using context
provided by a semantic knowledge base. We show that our method can detect
context-dependent anomalies with a high degree of accuracy and show that
current object detectors can detect enough classes to provide the needed
context for good performance within our example domain."
Improving Generalization of Deep Neural Network Acoustic Models with Length Perturbation and N-best Based Label Smoothing,0.228815,"We introduce two techniques, length perturbation and n-best based label
smoothing, to improve generalization of deep neural network (DNN) acoustic
models for automatic speech recognition (ASR). Length perturbation is a data
augmentation algorithm that randomly drops and inserts frames of an utterance
to alter the length of the speech feature sequence. N-best based label
smoothing randomly injects noise to ground truth labels during training in
order to avoid overfitting, where the noisy labels are generated from n-best
hypotheses. We evaluate these two techniques extensively on the 300-hour
Switchboard (SWB300) dataset and an in-house 500-hour Japanese (JPN500) dataset
using recurrent neural network transducer (RNNT) acoustic models for ASR. We
show that both techniques improve the generalization of RNNT models
individually and they can also be complementary. In particular, they yield good
improvements over a strong SWB300 baseline and give state-of-art performance on
SWB300 using RNNT models."
Transformer-based Cross-Modal Recipe Embeddings with Large Batch Training,0.0369329,"In this paper, we present a cross-modal recipe retrieval framework,
Transformer-based Network for Large Batch Training (TNLBT), which is inspired
by ACME~(Adversarial Cross-Modal Embedding) and H-T~(Hierarchical Transformer).
TNLBT aims to accomplish retrieval tasks while generating images from recipe
embeddings. We apply the Hierarchical Transformer-based recipe text encoder,
the Vision Transformer~(ViT)-based recipe image encoder, and an adversarial
network architecture to enable better cross-modal embedding learning for recipe
texts and images. In addition, we use self-supervised learning to exploit the
rich information in the recipe texts having no corresponding images. Since
contrastive learning could benefit from a larger batch size according to the
recent literature on self-supervised learning, we adopt a large batch size
during training and have validated its effectiveness. In the experiments, the
proposed framework significantly outperformed the current state-of-the-art
frameworks in both cross-modal recipe retrieval and image generation tasks on
the benchmark Recipe1M. This is the first work which confirmed the
effectiveness of large batch training on cross-modal recipe embeddings."
Ultra-high-resolution unpaired stain transformation via Kernelized Instance Normalization,0.0193312,"While hematoxylin and eosin (H&E) is a standard staining procedure,
immunohistochemistry (IHC) staining further serves as a diagnostic and
prognostic method. However, acquiring special staining results requires
substantial costs.
  Hence, we proposed a strategy for ultra-high-resolution unpaired
image-to-image translation: Kernelized Instance Normalization (KIN), which
preserves local information and successfully achieves seamless stain
transformation with constant GPU memory usage. Given a patch, corresponding
position, and a kernel, KIN computes local statistics using convolution
operation. In addition, KIN can be easily plugged into most currently developed
frameworks without re-training.
  We demonstrate that KIN achieves state-of-the-art stain transformation by
replacing instance normalization (IN) layers with KIN layers in three popular
frameworks and testing on two histopathological datasets. Furthermore, we
manifest the generalizability of KIN with high-resolution natural images.
Finally, human evaluation and several objective metrics are used to compare the
performance of different approaches.
  Overall, this is the first successful study for the ultra-high-resolution
unpaired image-to-image translation with constant space complexity. Code is
available at: https://github.com/Kaminyou/URUST"
Dog nose print matching with dual global descriptor based on Contrastive Learning,0.0193363,"Recent studies in biometric-based identification tasks have shown that deep
learning methods can achieve better performance. These methods generally
extract the global features as descriptor to represent the original image.
Nonetheless, it does not perform well for biometric identification under
fine-grained tasks. The main reason is that the single image descriptor
contains insufficient information to represent image. In this paper, we present
a dual global descriptor model, which combines multiple global descriptors to
exploit multi level image features. Moreover, we utilize a contrastive loss to
enlarge the distance between image representations of confusing classes. The
proposed framework achieves the top2 on the CVPR2022 Biometrics Workshop Pet
Biometric Challenge. The source code and trained models are publicly available
at: https://github.com/flyingsheepbin/pet-biometrics"
A Mixed Integer Programming Approach for Verifying Properties of Binarized Neural Networks,0.0370519,"Many approaches for verifying input-output properties of neural networks have
been proposed recently. However, existing algorithms do not scale well to large
networks. Recent work in the field of model compression studied binarized
neural networks (BNNs), whose parameters and activations are binary. BNNs tend
to exhibit a slight decrease in performance compared to their full-precision
counterparts, but they can be easier to verify. This paper proposes a simple
mixed integer programming formulation for BNN verification that leverages
network structure. We demonstrate our approach by verifying properties of BNNs
trained on the MNIST dataset and an aircraft collision avoidance controller. We
compare the runtime of our approach against state-of-the-art verification
algorithms for full-precision neural networks. The results suggest that the
difficulty of training BNNs might be worth the reduction in runtime achieved by
our verification algorithm."
DeViT: Deformed Vision Transformers in Video Inpainting,0.0402173,"This paper proposes a novel video inpainting method. We make three main
contributions: First, we extended previous Transformers with patch alignment by
introducing Deformed Patch-based Homography (DePtH), which improves patch-level
feature alignments without additional supervision and benefits challenging
scenes with various deformation. Second, we introduce Mask Pruning-based Patch
Attention (MPPA) to improve patch-wised feature matching by pruning out less
essential features and using saliency map. MPPA enhances matching accuracy
between warped tokens with invalid pixels. Third, we introduce a
Spatial-Temporal weighting Adaptor (STA) module to obtain accurate attention to
spatial-temporal tokens under the guidance of the Deformation Factor learned
from DePtH, especially for videos with agile motions. Experimental results
demonstrate that our method outperforms recent methods qualitatively and
quantitatively and achieves a new state-of-the-art."
Sampling Strategies for Static Powergrid Models,0.00173599,"Machine learning and computational intelligence technologies gain more and
more popularity as possible solution for issues related to the power grid. One
of these issues, the power flow calculation, is an iterative method to compute
the voltage magnitudes of the power grid's buses from power values. Machine
learning and, especially, artificial neural networks were successfully used as
surrogates for the power flow calculation. Artificial neural networks highly
rely on the quality and size of the training data, but this aspect of the
process is apparently often neglected in the works we found. However, since the
availability of high quality historical data for power grids is limited, we
propose the Correlation Sampling algorithm. We show that this approach is able
to cover a larger area of the sampling space compared to different random
sampling algorithms from the literature and a copula-based approach, while at
the same time inter-dependencies of the inputs are taken into account, which,
from the other algorithms, only the copula-based approach does."
AutoMap: Automatic Medical Code Mapping for Clinical Prediction Model Deployment,0.0450244,"Given a deep learning model trained on data from a source site, how to deploy
the model to a target hospital automatically? How to accommodate heterogeneous
medical coding systems across different hospitals? Standard approaches rely on
existing medical code mapping tools, which have significant practical
limitations.
  To tackle this problem, we propose AutoMap to automatically map the medical
codes across different EHR systems in a coarse-to-fine manner: (1)
Ontology-level Alignment: We leverage the ontology structure to learn a coarse
alignment between the source and target medical coding systems; (2) Code-level
Refinement: We refine the alignment at a fine-grained code level for the
downstream tasks using a teacher-student framework.
  We evaluate AutoMap using several deep learning models with two real-world
EHR datasets: eICU and MIMIC-III. Results show that AutoMap achieves relative
improvements up to 3.9% (AUC-ROC) and 8.7% (AUC-PR) for mortality prediction,
and up to 4.7% (AUC-ROC) and 3.7% (F1) for length-of-stay estimation. Further,
we show that AutoMap can provide accurate mapping across coding systems.
Lastly, we demonstrate that AutoMap can adapt to the two challenging scenarios:
(1) mapping between completely different coding systems and (2) between
completely different hospitals."
"""Diversity and Uncertainty in Moderation"" are the Key to Data Selection for Multilingual Few-shot Transfer",0.0444903,"Few-shot transfer often shows substantial gain over zero-shot
transfer~\cite{lauscher2020zero}, which is a practically useful trade-off
between fully supervised and unsupervised learning approaches for multilingual
pretrained model-based systems. This paper explores various strategies for
selecting data for annotation that can result in a better few-shot transfer.
The proposed approaches rely on multiple measures such as data entropy using
$n$-gram language model, predictive entropy, and gradient embedding. We propose
a loss embedding method for sequence labeling tasks, which induces diversity
and uncertainty sampling similar to gradient embedding. The proposed data
selection strategies are evaluated and compared for POS tagging, NER, and NLI
tasks for up to 20 languages. Our experiments show that the gradient and loss
embedding-based strategies consistently outperform random data selection
baselines, with gains varying with the initial performance of the zero-shot
transfer. Furthermore, the proposed method shows similar trends in improvement
even when the model is fine-tuned using a lower proportion of the original
task-specific labeled training data for zero-shot transfer."
Interactive Visual Reasoning under Uncertainty,0.0216128,"One of the fundamental cognitive abilities of humans is to quickly resolve
uncertainty by generating hypotheses and testing them via active trials.
Encountering a novel phenomenon accompanied by ambiguous cause-effect
relationships, humans make hypotheses against data, conduct inferences from
observation, test their theory via experimentation, and correct the proposition
if inconsistency arises. These iterative processes persist until the underlying
mechanism becomes clear. In this work, we devise the IVRE (pronounced as
""ivory"") environment for evaluating artificial agents' reasoning ability under
uncertainty. IVRE is an interactive environment featuring rich scenarios
centered around Blicket detection. Agents in IVRE are placed into environments
with various ambiguous action-effect pairs and asked to determine each object's
role. They are encouraged to propose effective and efficient experiments to
validate their hypotheses based on observations and actively gather new
information. The game ends when all uncertainties are resolved or the maximum
number of trials is consumed. By evaluating modern artificial agents in IVRE,
we notice a clear failure of today's learning methods compared to humans. Such
inefficacy in interactive reasoning ability under uncertainty calls for future
research in building human-like intelligence."
Statistical Foundation Behind Machine Learning and Its Impact on Computer Vision,0.0118975,"This paper revisits the principle of uniform convergence in statistical
learning, discusses how it acts as the foundation behind machine learning, and
attempts to gain a better understanding of the essential problem that current
deep learning algorithms are solving. Using computer vision as an example
domain in machine learning, the discussion shows that recent research trends in
leveraging increasingly large-scale data to perform pre-training for
representation learning are largely to reduce the discrepancy between a
practically tractable empirical loss and its ultimately desired but intractable
expected loss. Furthermore, this paper suggests a few future research
directions, predicts the continued increase of data, and argues that more
fundamental research is needed on robustness, interpretability, and reasoning
capabilities of machine learning by incorporating structure and knowledge."
TwistSLAM++: Fusing multiple modalities for accurate dynamic semantic SLAM,0.0446313,"Most classical SLAM systems rely on the static scene assumption, which limits
their applicability in real world scenarios. Recent SLAM frameworks have been
proposed to simultaneously track the camera and moving objects. However they
are often unable to estimate the canonical pose of the objects and exhibit a
low object tracking accuracy. To solve this problem we propose TwistSLAM++, a
semantic, dynamic, SLAM system that fuses stereo images and LiDAR information.
Using semantic information, we track potentially moving objects and associate
them to 3D object detections in LiDAR scans to obtain their pose and size.
Then, we perform registration on consecutive object scans to refine object pose
estimation. Finally, object scans are used to estimate the shape of the object
and constrain map points to lie on the estimated surface within the BA. We show
on classical benchmarks that this fusion approach based on multimodal
information improves the accuracy of object tracking."
Atypical lexical abbreviations identification in Russian medical texts,0.00780499,"Abbreviation is a method of word formation that aims to construct the
shortened term from the first letters of the initial phrase. Implicit
abbreviations frequently cause the comprehension difficulties for unprepared
readers. In this paper, we propose an efficient ML-based algorithm which allows
to identify the abbreviations in Russian texts. The method achieves ROC AUC
score 0.926 and F1 score 0.706 which are confirmed as competitive in comparison
with the baselines. Along with the pipeline, we also establish first to our
knowledge Russian dataset that is relevant for the desired task."
BERT4Loc: BERT for Location -- POI Recommender System,0.0520889,"Recommending points of interest (POIs) is a challenging task that requires
extracting comprehensive location data from location-based social media
platforms. To provide effective location-based recommendations, it's important
to analyze users' historical behavior and preferences. In this study, we
present a sophisticated location-aware recommendation system that uses
Bidirectional Encoder Representations from Transformers (BERT) to offer
personalized location-based suggestions. Our model combines location
information and user preferences to provide more relevant recommendations
compared to models that predict the next POI in a sequence. Our experiments on
two benchmark dataset show that our BERT-based model outperforms various
state-of-the-art sequential models. Moreover, we see the effectiveness of the
proposed model for quality through additional experiments."
Leaf: Multiple-Choice Question Generation,0.0700979,"Testing with quiz questions has proven to be an effective way to assess and
improve the educational process. However, manually creating quizzes is tedious
and time-consuming. To address this challenge, we present Leaf, a system for
generating multiple-choice questions from factual text. In addition to being
very well suited for the classroom, Leaf could also be used in an industrial
setting, e.g., to facilitate onboarding and knowledge sharing, or as a
component of chatbots, question answering systems, or Massive Open Online
Courses (MOOCs). The code and the demo are available on
https://github.com/KristiyanVachev/Leaf-Question-Generation."
Incorporating Multi-armed Bandit with Local Search for MaxSAT,0.0120932,"Partial MaxSAT (PMS) and Weighted PMS (WPMS) are two practical
generalizations of the MaxSAT problem. In this paper, we propose a local search
algorithm for these problems, called BandHS, which applies two multi-armed
bandits to guide the search directions when escaping local optima. One bandit
is combined with all the soft clauses to help the algorithm select to satisfy
appropriate soft clauses, and the other bandit with all the literals in hard
clauses to help the algorithm select appropriate literals to satisfy the hard
clauses. These two bandits can improve the algorithm's search ability in both
feasible and infeasible solution spaces. We further propose an initialization
method for (W)PMS that prioritizes both unit and binary clauses when producing
the initial solutions. Extensive experiments demonstrate the excellent
performance and generalization capability of our proposed methods, that greatly
boost the state-of-the-art local search algorithm, SATLike3.0, and the
state-of-the-art SAT-based incomplete solver, NuWLS-c."
"""Covid vaccine is against Covid but Oxford vaccine is made at Oxford!"" Semantic Interpretation of Proper Noun Compounds",0.0241587,"Proper noun compounds, e.g., ""Covid vaccine"", convey information in a
succinct manner (a ""Covid vaccine"" is a ""vaccine that immunizes against the
Covid disease""). These are commonly used in short-form domains, such as news
headlines, but are largely ignored in information-seeking applications. To
address this limitation, we release a new manually annotated dataset, ProNCI,
consisting of 22.5K proper noun compounds along with their free-form semantic
interpretations. ProNCI is 60 times larger than prior noun compound datasets
and also includes non-compositional examples, which have not been previously
explored. We experiment with various neural models for automatically generating
the semantic interpretations from proper noun compounds, ranging from few-shot
prompting to supervised learning, with varying degrees of knowledge about the
constituent nouns. We find that adding targeted knowledge, particularly about
the common noun, results in performance gains of upto 2.8%. Finally, we
integrate our model generated interpretations with an existing Open IE system
and observe an 7.5% increase in yield at a precision of 85%. The dataset and
code are available at https://github.com/dair-iitd/pronci."
Socially Intelligent Genetic Agents for the Emergence of Explicit Norms,0.0441994,"Norms help regulate a society. Norms may be explicit (represented in
structured form) or implicit. We address the emergence of explicit norms by
developing agents who provide and reason about explanations for norm violations
in deciding sanctions and identifying alternative norms. These agents use a
genetic algorithm to produce norms and reinforcement learning to learn the
values of these norms. We find that applying explanations leads to norms that
provide better cohesion and goal satisfaction for the agents. Our results are
stable for societies with differing attitudes of generosity."
Paying More Attention to Self-attention: Improving Pre-trained Language Models via Attention Guiding,0.0328939,"Pre-trained language models (PLM) have demonstrated their effectiveness for a
broad range of information retrieval and natural language processing tasks. As
the core part of PLM, multi-head self-attention is appealing for its ability to
jointly attend to information from different positions. However, researchers
have found that PLM always exhibits fixed attention patterns regardless of the
input (e.g., excessively paying attention to [CLS] or [SEP]), which we argue
might neglect important information in the other positions. In this work, we
propose a simple yet effective attention guiding mechanism to improve the
performance of PLM by encouraging attention towards the established goals.
Specifically, we propose two kinds of attention guiding methods, i.e., map
discrimination guiding (MDG) and attention pattern decorrelation guiding (PDG).
The former definitely encourages the diversity among multiple self-attention
heads to jointly attend to information from different representation subspaces,
while the latter encourages self-attention to attend to as many different
positions of the input as possible. We conduct experiments with multiple
general pre-trained models (i.e., BERT, ALBERT, and Roberta) and
domain-specific pre-trained models (i.e., BioBERT, ClinicalBERT, BlueBert, and
SciBERT) on three benchmark datasets (i.e., MultiNLI, MedNLI, and
Cross-genre-IR). Extensive experimental results demonstrate that our proposed
MDG and PDG bring stable performance improvements on all datasets with high
efficiency and low cost."
Exploiting Global and Local Hierarchies for Hierarchical Text Classification,0.128213,"Hierarchical text classification aims to leverage label hierarchy in
multi-label text classification. Existing methods encode label hierarchy in a
global view, where label hierarchy is treated as the static hierarchical
structure containing all labels. Since global hierarchy is static and
irrelevant to text samples, it makes these methods hard to exploit hierarchical
information. Contrary to global hierarchy, local hierarchy as a structured
labels hierarchy corresponding to each text sample. It is dynamic and relevant
to text samples, which is ignored in previous methods. To exploit global and
local hierarchies,we propose Hierarchy-guided BERT with Global and Local
hierarchies (HBGL), which utilizes the large-scale parameters and prior
language knowledge of BERT to model both global and local
hierarchies.Moreover,HBGL avoids the intentional fusion of semantic and
hierarchical modules by directly modeling semantic and hierarchical information
with BERT.Compared with the state-of-the-art method HGCLR,our method achieves
significant improvement on three benchmark datasets."
WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named Entity Recognition,0.00437056,"Named Entity Recognition task is one of the core tasks of information
extraction. Word ambiguity and word abbreviation are important reasons for the
low recognition rate of named entities. In this paper, we propose a novel named
entity recognition model WCL-BBCD (Word Contrastive Learning with
BERT-BiLSTM-CRF-DBpedia), which incorporates the idea of contrastive learning.
The model first trains the sentence pairs in the text, calculate similarity
between sentence pairs, and fine-tunes BERT used for the named entity
recognition task according to the similarity, so as to alleviate word
ambiguity. Then, the fine-tuned BERT is combined with BiLSTM-CRF to perform the
named entity recognition task. Finally, the recognition results are corrected
in combination with prior knowledge such as knowledge graphs, so as to
alleviate the low-recognition-rate problem caused by word abbreviations. The
results of experimentals conducted on the CoNLL-2003 English dataset and
OntoNotes V5 English dataset show that our model outperforms other similar
models on."
Label-Driven Denoising Framework for Multi-Label Few-Shot Aspect Category Detection,0.139308,"Multi-Label Few-Shot Aspect Category Detection (FS-ACD) is a new sub-task of
aspect-based sentiment analysis, which aims to detect aspect categories
accurately with limited training instances. Recently, dominant works use the
prototypical network to accomplish this task, and employ the attention
mechanism to extract keywords of aspect category from the sentences to produce
the prototype for each aspect. However, they still suffer from serious noise
problems: (1) due to lack of sufficient supervised data, the previous methods
easily catch noisy words irrelevant to the current aspect category, which
largely affects the quality of the generated prototype; (2) the
semantically-close aspect categories usually generate similar prototypes, which
are mutually noisy and confuse the classifier seriously. In this paper, we
resort to the label information of each aspect to tackle the above problems,
along with proposing a novel Label-Driven Denoising Framework (LDF). Extensive
experimental results show that our framework achieves better performance than
other state-of-the-art methods."
Ad Hoc Teamwork in the Presence of Adversaries,0.0384489,"Advances in ad hoc teamwork have the potential to create agents that
collaborate robustly in real-world applications. Agents deployed in the real
world, however, are vulnerable to adversaries with the intent to subvert them.
There has been little research in ad hoc teamwork that assumes the presence of
adversaries. We explain the importance of extending ad hoc teamwork to include
the presence of adversaries and clarify why this problem is difficult. We then
propose some directions for new research opportunities in ad hoc teamwork that
leads to more robust multi-agent cyber-physical infrastructure systems."
State Dropout-Based Curriculum Reinforcement Learning for Self-Driving at Unsignalized Intersections,0.0253503,"Traversing intersections is a challenging problem for autonomous vehicles,
especially when the intersections do not have traffic control. Recently deep
reinforcement learning has received massive attention due to its success in
dealing with autonomous driving tasks. In this work, we address the problem of
traversing unsignalized intersections using a novel curriculum for deep
reinforcement learning. The proposed curriculum leads to: 1) A faster training
process for the reinforcement learning agent, and 2) Better performance
compared to an agent trained without curriculum. Our main contribution is
two-fold: 1) Presenting a unique curriculum for training deep reinforcement
learning agents, and 2) showing the application of the proposed curriculum for
the unsignalized intersection traversal task. The framework expects processed
observations of the surroundings from the perception system of the autonomous
vehicle. We test our method in the CommonRoad motion planning simulator on
T-intersections and four-way intersections."
Contrastive Learning with Prompt-derived Virtual Semantic Prototypes for Unsupervised Sentence Embedding,0.731829,"Contrastive learning has become a new paradigm for unsupervised sentence
embeddings. Previous studies focus on instance-wise contrastive learning,
attempting to construct positive pairs with textual data augmentation. In this
paper, we propose a novel Contrastive learning method with Prompt-derived
Virtual semantic Prototypes (ConPVP). Specifically, with the help of prompts,
we construct virtual semantic prototypes to each instance, and derive negative
prototypes by using the negative form of the prompts. Using a prototypical
contrastive loss, we enforce the anchor sentence embedding to be close to its
corresponding semantic prototypes, and far apart from the negative prototypes
as well as the prototypes of other sentences. Extensive experimental results on
semantic textual similarity, transfer, and clustering tasks demonstrate the
effectiveness of our proposed model compared to strong baselines. Code is
available at https://github.com/lemon0830/promptCSE."
Task-specific Compression for Multi-task Language Models using Attribution-based Pruning,0.022262,"Multi-task language models show outstanding performance for various natural
language understanding tasks with only a single model. However, these language
models utilize an unnecessarily large number of model parameters, even when
used only for a specific task. This paper proposes a novel training-free
compression method for multi-task language models using a pruning method.
Specifically, we use an attribution method to determine which neurons are
essential for performing a specific task. We task-specifically prune
unimportant neurons and leave only task-specific parameters. Furthermore, we
extend our method to be applicable in low-resource and unsupervised settings.
Since our compression method is training-free, it uses few computing resources
and does not destroy the pre-trained knowledge of language models. Experimental
results on the six widely-used datasets show that our proposed pruning method
significantly outperforms baseline pruning methods. In addition, we demonstrate
that our method preserves performance even in an unseen domain setting."
Multi-View Dreaming: Multi-View World Model with Contrastive Learning,0.041571,"In this paper, we propose Multi-View Dreaming, a novel reinforcement learning
agent for integrated recognition and control from multi-view observations by
extending Dreaming. Most current reinforcement learning method assumes a
single-view observation space, and this imposes limitations on the observed
data, such as lack of spatial information and occlusions. This makes obtaining
ideal observational information from the environment difficult and is a
bottleneck for real-world robotics applications. In this paper, we use
contrastive learning to train a shared latent space between different
viewpoints, and show how the Products of Experts approach can be used to
integrate and control the probability distributions of latent states for
multiple viewpoints. We also propose Multi-View DreamingV2, a variant of
Multi-View Dreaming that uses a categorical distribution to model the latent
state instead of the Gaussian distribution. Experiments show that the proposed
method outperforms simple extensions of existing methods in a realistic robot
control task."
Dual Progressive Transformations for Weakly Supervised Semantic Segmentation,0.0930372,"Weakly supervised semantic segmentation (WSSS), which aims to mine the object
regions by merely using class-level labels, is a challenging task in computer
vision. The current state-of-the-art CNN-based methods usually adopt
Class-Activation-Maps (CAMs) to highlight the potential areas of the object,
however, they may suffer from the part-activated issues. To this end, we try an
early attempt to explore the global feature attention mechanism of vision
transformer in WSSS task. However, since the transformer lacks the inductive
bias as in CNN models, it can not boost the performance directly and may yield
the over-activated problems. To tackle these drawbacks, we propose a
Convolutional Neural Networks Refined Transformer (CRT) to mine a globally
complete and locally accurate class activation maps in this paper. To validate
the effectiveness of our proposed method, extensive experiments are conducted
on PASCAL VOC 2012 and CUB-200-2011 datasets. Experimental evaluations show
that our proposed CRT achieves the new state-of-the-art performance on both the
weakly supervised semantic segmentation task the weakly supervised object
localization task, which outperform others by a large margin."
Standing on the Shoulders of Giant Frozen Language Models,0.177088,"Huge pretrained language models (LMs) have demonstrated surprisingly good
zero-shot capabilities on a wide variety of tasks. This gives rise to the
appealing vision of a single, versatile model with a wide range of
functionalities across disparate applications. However, current leading
techniques for leveraging a ""frozen"" LM -- i.e., leaving its weights untouched
-- still often underperform fine-tuning approaches which modify these weights
in a task-dependent way. Those, in turn, suffer forgetfulness and compromise
versatility, suggesting a tradeoff between performance and versatility. The
main message of this paper is that current frozen-model techniques such as
prompt tuning are only the tip of the iceberg, and more powerful methods for
leveraging frozen LMs can do just as well as fine tuning in challenging domains
without sacrificing the underlying model's versatility. To demonstrate this, we
introduce three novel methods for leveraging frozen models: input-dependent
prompt tuning, frozen readers, and recursive LMs, each of which vastly improves
on current frozen-model approaches. Indeed, some of our methods even outperform
fine-tuning approaches in domains currently dominated by the latter. The
computational cost of each method is higher than that of existing frozen model
methods, but still negligible relative to a single pass through a huge frozen
LM. Each of these methods constitutes a meaningful contribution in its own
right, but by presenting these contributions together we aim to convince the
reader of a broader message that goes beyond the details of any given method:
that frozen models have untapped potential and that fine-tuning is often
unnecessary."
Towards customizable reinforcement learning agents: Enabling preference specification through online vocabulary expansion,0.138389,"There is a growing interest in developing automated agents that can work
alongside humans. In addition to completing the assigned task, such an agent
will undoubtedly be expected to behave in a manner that is preferred by the
human. This requires the human to communicate their preferences to the agent.
To achieve this, the current approaches either require the users to specify the
reward function or the preference is interactively learned from queries that
ask the user to compare behavior. The former approach can be challenging if the
internal representation used by the agent is inscrutable to the human while the
latter is unnecessarily cumbersome for the user if their preference can be
specified more easily in symbolic terms. In this work, we propose PRESCA
(PREference Specification through Concept Acquisition), a system that allows
users to specify their preferences in terms of concepts that they understand.
PRESCA maintains a set of such concepts in a shared vocabulary. If the relevant
concept is not in the shared vocabulary, then it is learned. To make learning a
new concept more feedback efficient, PRESCA leverages causal associations
between the target concept and concepts that are already known. In addition, we
use a novel data augmentation approach to further reduce required feedback. We
evaluate PRESCA by using it on a Minecraft environment and show that it can
effectively align the agent with the user's preference."
Defending From Physically-Realizable Adversarial Attacks Through Internal Over-Activation Analysis,0.0831078,"This work presents Z-Mask, a robust and effective strategy to improve the
adversarial robustness of convolutional networks against physically-realizable
adversarial attacks. The presented defense relies on specific Z-score analysis
performed on the internal network features to detect and mask the pixels
corresponding to adversarial objects in the input image. To this end, spatially
contiguous activations are examined in shallow and deep layers to suggest
potential adversarial regions. Such proposals are then aggregated through a
multi-thresholding mechanism. The effectiveness of Z-Mask is evaluated with an
extensive set of experiments carried out on models for both semantic
segmentation and object detection. The evaluation is performed with both
digital patches added to the input images and printed patches positioned in the
real world. The obtained results confirm that Z-Mask outperforms the
state-of-the-art methods in terms of both detection accuracy and overall
performance of the networks under attack. Additional experiments showed that
Z-Mask is also robust against possible defense-aware attacks."
YORO -- Lightweight End to End Visual Grounding,0.207477,"We present YORO - a multi-modal transformer encoder-only architecture for the
Visual Grounding (VG) task. This task involves localizing, in an image, an
object referred via natural language. Unlike the recent trend in the literature
of using multi-stage approaches that sacrifice speed for accuracy, YORO seeks a
better trade-off between speed an accuracy by embracing a single-stage design,
without CNN backbone. YORO consumes natural language queries, image patches,
and learnable detection tokens and predicts coordinates of the referred object,
using a single transformer encoder. To assist the alignment between text and
visual objects, a novel patch-text alignment loss is proposed. Extensive
experiments are conducted on 5 different datasets with ablations on
architecture design choices. YORO is shown to support real-time inference and
outperform all approaches in this class (single-stage methods) by large
margins. It is also the fastest VG model and achieves the best speed/accuracy
trade-off in the literature."
Will Large-scale Generative Models Corrupt Future Datasets?,0.194836,"Recently proposed large-scale text-to-image generative models such as
DALL$\cdot$E 2, Midjourney, and StableDiffusion can generate high-quality and
realistic images from users' prompts. Not limited to the research community,
ordinary Internet users enjoy these generative models, and consequently, a
tremendous amount of generated images have been shared on the Internet.
Meanwhile, today's success of deep learning in the computer vision field owes a
lot to images collected from the Internet. These trends lead us to a research
question: ""\textbf{will such generated images impact the quality of future
datasets and the performance of computer vision models positively or
negatively?}"" This paper empirically answers this question by simulating
contamination. Namely, we generate ImageNet-scale and COCO-scale datasets using
a state-of-the-art generative model and evaluate models trained with
""contaminated"" datasets on various tasks, including image classification and
image generation. Throughout experiments, we conclude that generated images
negatively affect downstream performance, while the significance depends on
tasks and the amount of generated images. The generated datasets and the codes
for experiments will be publicly released for future research. Generated
datasets and source codes are available from
\url{https://github.com/moskomule/dataset-contamination}."
Mere Contrastive Learning for Cross-Domain Sentiment Analysis,0.0216626,"Cross-domain sentiment analysis aims to predict the sentiment of texts in the
target domain using the model trained on the source domain to cope with the
scarcity of labeled data. Previous studies are mostly cross-entropy-based
methods for the task, which suffer from instability and poor generalization. In
this paper, we explore contrastive learning on the cross-domain sentiment
analysis task. We propose a modified contrastive objective with in-batch
negative samples so that the sentence representations from the same class will
be pushed close while those from the different classes become further apart in
the latent space. Experiments on two widely used datasets show that our model
can achieve state-of-the-art performance in both cross-domain and multi-domain
sentiment analysis tasks. Meanwhile, visualizations demonstrate the
effectiveness of transferring knowledge learned in the source domain to the
target domain and the adversarial test verifies the robustness of our model."
Implicit Two-Tower Policies,0.106533,"We present a new class of structured reinforcement learning
policy-architectures, Implicit Two-Tower (ITT) policies, where the actions are
chosen based on the attention scores of their learnable latent representations
with those of the input states. By explicitly disentangling action from state
processing in the policy stack, we achieve two main goals: substantial
computational gains and better performance. Our architectures are compatible
with both: discrete and continuous action spaces. By conducting tests on 15
environments from OpenAI Gym and DeepMind Control Suite, we show that
ITT-architectures are particularly suited for blackbox/evolutionary
optimization and the corresponding policy training algorithms outperform their
vanilla unstructured implicit counterparts as well as commonly used explicit
policies. We complement our analysis by showing how techniques such as hashing
and lazy tower updates, critically relying on the two-tower structure of ITTs,
can be applied to obtain additional computational improvements."
Goal Recognition as a Deep Learning Task: the GRNet Approach,0.0224485,"In automated planning, recognising the goal of an agent from a trace of
observations is an important task with many applications. The state-of-the-art
approaches to goal recognition rely on the application of planning techniques,
which requires a model of the domain actions and of the initial domain state
(written, e.g., in PDDL). We study an alternative approach where goal
recognition is formulated as a classification task addressed by machine
learning. Our approach, called GRNet, is primarily aimed at making goal
recognition more accurate as well as faster by learning how to solve it in a
given domain. Given a planning domain specified by a set of propositions and a
set of action names, the goal classification instances in the domain are solved
by a Recurrent Neural Network (RNN). A run of the RNN processes a trace of
observed actions to compute how likely it is that each domain proposition is
part of the agent's goal, for the problem instance under considerations. These
predictions are then aggregated to choose one of the candidate goals. The only
information required as input of the trained RNN is a trace of action labels,
each one indicating just the name of an observed action. An experimental
analysis confirms that \our achieves good performance in terms of both goal
classification accuracy and runtime, obtaining better performance w.r.t. a
state-of-the-art goal recognition system over the considered benchmarks."
Is GPT-3 all you need for Visual Question Answering in Cultural Heritage?,0.0734519,"The use of Deep Learning and Computer Vision in the Cultural Heritage domain
is becoming highly relevant in the last few years with lots of applications
about audio smart guides, interactive museums and augmented reality. All these
technologies require lots of data to work effectively and be useful for the
user. In the context of artworks, such data is annotated by experts in an
expensive and time consuming process. In particular, for each artwork, an image
of the artwork and a description sheet have to be collected in order to perform
common tasks like Visual Question Answering. In this paper we propose a method
for Visual Question Answering that allows to generate at runtime a description
sheet that can be used for answering both visual and contextual questions about
the artwork, avoiding completely the image and the annotation process. For this
purpose, we investigate on the use of GPT-3 for generating descriptions for
artworks analyzing the quality of generated descriptions through captioning
metrics. Finally we evaluate the performance for Visual Question Answering and
captioning tasks."
STVGFormer: Spatio-Temporal Video Grounding with Static-Dynamic Cross-Modal Understanding,0.0226383,"In this technical report, we introduce our solution to human-centric
spatio-temporal video grounding task. We propose a concise and effective
framework named STVGFormer, which models spatiotemporal visual-linguistic
dependencies with a static branch and a dynamic branch. The static branch
performs cross-modal understanding in a single frame and learns to localize the
target object spatially according to intra-frame visual cues like object
appearances. The dynamic branch performs cross-modal understanding across
multiple frames. It learns to predict the starting and ending time of the
target moment according to dynamic visual cues like motions. Both the static
and dynamic branches are designed as cross-modal transformers. We further
design a novel static-dynamic interaction block to enable the static and
dynamic branches to transfer useful and complementary information from each
other, which is shown to be effective to improve the prediction on hard cases.
Our proposed method achieved 39.6% vIoU and won the first place in the HC-STVG
track of the 4th Person in Context Challenge."
DHGE: Dual-View Hyper-Relational Knowledge Graph Embedding for Link Prediction and Entity Typing,0.0917354,"In the field of representation learning on knowledge graphs (KGs), a
hyper-relational fact consists of a main triple and several auxiliary
attribute-value descriptions, which is considered more comprehensive and
specific than a triple-based fact. However, currently available
hyper-relational KG embedding methods in a single view are limited in
application because they weaken the hierarchical structure that represents the
affiliation between entities. To overcome this limitation, we propose a
dual-view hyper-relational KG structure (DH-KG) that contains a
hyper-relational instance view for entities and a hyper-relational ontology
view for concepts that are abstracted hierarchically from the entities. This
paper defines link prediction and entity typing tasks on DH-KG for the first
time and constructs two DH-KG datasets, JW44K-6K, extracted from Wikidata, and
HTDM based on medical data. Furthermore, we propose DHGE, a DH-KG embedding
model based on GRAN encoders, HGNNs, and joint learning. DHGE outperforms
baseline models on DH-KG, according to experimental results. Finally, we
provide an example of how this technology can be used to treat hypertension.
Our model and new datasets are publicly available."
CLAM: Selective Clarification for Ambiguous Questions with Generative Language Models,0.0816835,"Users often ask dialogue systems ambiguous questions that require
clarification. We show that current language models rarely ask users to clarify
ambiguous questions and instead provide incorrect answers. To address this, we
introduce CLAM: a framework for getting language models to selectively ask for
clarification about ambiguous user questions. In particular, we show that we
can prompt language models to detect whether a given question is ambiguous,
generate an appropriate clarifying question to ask the user, and give a final
answer after receiving clarification. We also show that we can simulate users
by providing language models with privileged information. This lets us
automatically evaluate multi-turn clarification dialogues. Finally, CLAM
significantly improves language models' accuracy on mixed ambiguous and
unambiguous questions relative to SotA."
3D-CSL: self-supervised 3D context similarity learning for Near-Duplicate Video Retrieval,0.00666453,"In this paper, we introduce 3D-CSL, a compact pipeline for Near-Duplicate
Video Retrieval (NDVR), and explore a novel self-supervised learning strategy
for video similarity learning. Most previous methods only extract video spatial
features from frames separately and then design kinds of complex mechanisms to
learn the temporal correlations among frame features. However, parts of
spatiotemporal dependencies have already been lost. To address this, our 3D-CSL
extracts global spatiotemporal dependencies in videos end-to-end with a 3D
transformer and find a good balance between efficiency and effectiveness by
matching on clip-level. Furthermore, we propose a two-stage self-supervised
similarity learning strategy to optimize the entire network. Firstly, we
propose PredMAE to pretrain the 3D transformer with video prediction task;
Secondly, ShotMix, a novel video-specific augmentation, and FCS loss, a novel
triplet loss, are proposed further promote the similarity learning results. The
experiments on FIVR-200K and CC_WEB_VIDEO demonstrate the superiority and
reliability of our method, which achieves the state-of-the-art performance on
clip-level NDVR."
Recovering Patient Journeys: A Corpus of Biomedical Entities and Relations on Twitter (BEAR),0.157228,"Text mining and information extraction for the medical domain has focused on
scientific text generated by researchers. However, their direct access to
individual patient experiences or patient-doctor interactions can be limited.
Information provided on social media, e.g., by patients and their relatives,
complements the knowledge in scientific text. It reflects the patient's journey
and their subjective perspective on the process of developing symptoms, being
diagnosed and offered a treatment, being cured or learning to live with a
medical condition. The value of this type of data is therefore twofold:
Firstly, it offers direct access to people's perspectives. Secondly, it might
cover information that is not available elsewhere, including self-treatment or
self-diagnoses. Named entity recognition and relation extraction are methods to
structure information that is available in unstructured text. However, existing
medical social media corpora focused on a comparably small set of entities and
relations and particular domains, rather than putting the patient into the
center of analyses. With this paper we contribute a corpus with a rich set of
annotation layers following the motivation to uncover and model patients'
journeys and experiences in more detail. We label 14 entity classes (incl.
environmental factors, diagnostics, biochemical processes, patients'
quality-of-life descriptions, pathogens, medical conditions, and treatments)
and 20 relation classes (e.g., prevents, influences, interactions, causes) most
of which have not been considered before for social media data. The publicly
available dataset consists of 2,100 tweets with approx. 6,000 entity and 3,000
relation annotations. In a corpus analysis we find that over 80 % of documents
contain relevant entities. Over 50 % of tweets express relations which we
consider essential for uncovering patients' narratives about their journeys."
WeDef: Weakly Supervised Backdoor Defense for Text Classification,0.05434,"Existing backdoor defense methods are only effective for limited trigger
types. To defend different trigger types at once, we start from the
class-irrelevant nature of the poisoning process and propose a novel weakly
supervised backdoor defense framework WeDef. Recent advances in weak
supervision make it possible to train a reasonably accurate text classifier
using only a small number of user-provided, class-indicative seed words. Such
seed words shall be considered independent of the triggers. Therefore, a weakly
supervised text classifier trained by only the poisoned documents without their
labels will likely have no backdoor. Inspired by this observation, in WeDef, we
define the reliability of samples based on whether the predictions of the weak
classifier agree with their labels in the poisoned training set. We further
improve the results through a two-phase sanitization: (1) iteratively refine
the weak classifier based on the reliable samples and (2) train a binary poison
classifier by distinguishing the most unreliable samples from the most reliable
samples. Finally, we train the sanitized model on the samples that the poison
classifier predicts as benign. Extensive experiments show that WeDefis
effective against popular trigger-based attacks (e.g., words, sentences, and
paraphrases), outperforming existing defense methods."
NEEDED: Introducing Hierarchical Transformer to Eye Diseases Diagnosis,0.0667801,"With the development of natural language processing techniques(NLP),
automatic diagnosis of eye diseases using ophthalmology electronic medical
records (OEMR) has become possible. It aims to evaluate the condition of both
eyes of a patient respectively, and we formulate it as a particular multi-label
classification task in this paper. Although there are a few related studies in
other diseases, automatic diagnosis of eye diseases exhibits unique
characteristics. First, descriptions of both eyes are mixed up in OEMR
documents, with both free text and templated asymptomatic descriptions,
resulting in sparsity and clutter of information. Second, OEMR documents
contain multiple parts of descriptions and have long document lengths. Third,
it is critical to provide explainability to the disease diagnosis model. To
overcome those challenges, we present an effective automatic eye disease
diagnosis framework, NEEDED. In this framework, a preprocessing module is
integrated to improve the density and quality of information. Then, we design a
hierarchical transformer structure for learning the contextualized
representations of each sentence in the OEMR document. For the diagnosis part,
we propose an attention-based predictor that enables traceable diagnosis by
obtaining disease-specific information. Experiments on the real dataset and
comparison with several baseline models show the advantage and explainability
of our framework."
DATE: Dual Assignment for End-to-End Fully Convolutional Object Detection,0.0443286,"Fully convolutional detectors discard the one-to-many assignment and adopt a
one-to-one assigning strategy to achieve end-to-end detection but suffer from
the slow convergence issue. In this paper, we revisit these two assignment
methods and find that bringing one-to-many assignment back to end-to-end fully
convolutional detectors helps with model convergence. Based on this
observation, we propose {\em \textbf{D}ual \textbf{A}ssignment} for end-to-end
fully convolutional de\textbf{TE}ction (DATE). Our method constructs two
branches with one-to-many and one-to-one assignment during training and speeds
up the convergence of the one-to-one assignment branch by providing more
supervision signals. DATE only uses the branch with the one-to-one matching
strategy for model inference, which doesn't bring inference overhead.
Experimental results show that Dual Assignment gives nontrivial improvements
and speeds up model convergence upon OneNet and DeFCN. Code:
https://github.com/YiqunChen1999/date."
METRO: Efficient Denoising Pretraining of Large Scale Autoencoding Language Models with Model Generated Signals,0.0651485,"We present an efficient method of pretraining large-scale autoencoding
language models using training signals generated by an auxiliary model.
Originated in ELECTRA, this training strategy has demonstrated
sample-efficiency to pretrain models at the scale of hundreds of millions of
parameters. In this work, we conduct a comprehensive empirical study, and
propose a recipe, namely ""Model generated dEnoising TRaining Objective""
(METRO), which incorporates some of the best modeling techniques developed
recently to speed up, stabilize, and enhance pretrained language models without
compromising model effectiveness. The resultant models, METRO-LM, consisting of
up to 5.4 billion parameters, achieve new state-of-the-art on the GLUE,
SuperGLUE, and SQuAD benchmarks. More importantly, METRO-LM are efficient in
that they often outperform previous large models with significantly smaller
model sizes and lower pretraining cost."
Hierarchical Compositional Representations for Few-shot Action Recognition,0.0200738,"Recently action recognition has received more and more attention for its
comprehensive and practical applications in intelligent surveillance and
human-computer interaction. However, few-shot action recognition has not been
well explored and remains challenging because of data scarcity. In this paper,
we propose a novel hierarchical compositional representations (HCR) learning
approach for few-shot action recognition. Specifically, we divide a complicated
action into several sub-actions by carefully designed hierarchical clustering
and further decompose the sub-actions into more fine-grained spatially
attentional sub-actions (SAS-actions). Although there exist large differences
between base classes and novel classes, they can share similar patterns in
sub-actions or SAS-actions. Furthermore, we adopt the Earth Mover's Distance in
the transportation problem to measure the similarity between video samples in
terms of sub-action representations. It computes the optimal matching flows
between sub-actions as distance metric, which is favorable for comparing
fine-grained patterns. Extensive experiments show our method achieves the
state-of-the-art results on HMDB51, UCF101 and Kinetics datasets."
"A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks",0.0169225,"Predictive coding networks are neuroscience-inspired models with roots in
both Bayesian statistics and neuroscience. Training such models, however, is
quite inefficient and unstable. In this work, we show how by simply changing
the temporal scheduling of the update rule for the synaptic weights leads to an
algorithm that is much more efficient and stable than the original one, and has
theoretical guarantees in terms of convergence. The proposed algorithm, that we
call incremental predictive coding (iPC) is also more biologically plausible
than the original one, as it it fully automatic. In an extensive set of
experiments, we show that iPC constantly performs better than the original
formulation on a large number of benchmarks for image classification, as well
as for the training of both conditional and masked language models, in terms of
test accuracy, efficiency, and convergence with respect to a large set of
hyperparameters."
A.I. Robustness: a Human-Centered Perspective on Technological Challenges and Opportunities,0.0213387,"Despite the impressive performance of Artificial Intelligence (AI) systems,
their robustness remains elusive and constitutes a key issue that impedes
large-scale adoption. Robustness has been studied in many domains of AI, yet
with different interpretations across domains and contexts. In this work, we
systematically survey the recent progress to provide a reconciled terminology
of concepts around AI robustness. We introduce three taxonomies to organize and
describe the literature both from a fundamental and applied point of view: 1)
robustness by methods and approaches in different phases of the machine
learning pipeline; 2) robustness for specific model architectures, tasks, and
systems; and in addition, 3) robustness assessment methodologies and insights,
particularly the trade-offs with other trustworthiness properties. Finally, we
identify and discuss research gaps and opportunities and give an outlook on the
field. We highlight the central role of humans in evaluating and enhancing AI
robustness, considering the necessary knowledge humans can provide, and discuss
the need for better understanding practices and developing supportive tools in
the future."
Traffic Sign Classification Using Deep and Quantum Neural Networks,0.025663,"Quantum Neural Networks (QNNs) are an emerging technology that can be used in
many applications including computer vision. In this paper, we presented a
traffic sign classification system implemented using a hybrid quantum-classical
convolutional neural network. Experiments on the German Traffic Sign
Recognition Benchmark dataset indicate that currently QNN do not outperform
classical DCNN (Deep Convolutuional Neural Networks), yet still provide an
accuracy of over 90% and are a definitely promising solution for advanced
computer vision."
Geometric Features Informed Multi-person Human-object Interaction Recognition in Videos,0.0613587,"Human-Object Interaction (HOI) recognition in videos is important for
analyzing human activity. Most existing work focusing on visual features
usually suffer from occlusion in the real-world scenarios. Such a problem will
be further complicated when multiple people and objects are involved in HOIs.
Consider that geometric features such as human pose and object position provide
meaningful information to understand HOIs, we argue to combine the benefits of
both visual and geometric features in HOI recognition, and propose a novel
Two-level Geometric feature-informed Graph Convolutional Network (2G-GCN). The
geometric-level graph models the interdependency between geometric features of
humans and objects, while the fusion-level graph further fuses them with visual
features of humans and objects. To demonstrate the novelty and effectiveness of
our method in challenging scenarios, we propose a new multi-person HOI dataset
(MPHOI-72). Extensive experiments on MPHOI-72 (multi-person HOI), CAD-120
(single-human HOI) and Bimanual Actions (two-hand HOI) datasets demonstrate our
superior performance compared to state-of-the-arts."
Unsupervised Syntactically Controlled Paraphrase Generation with Abstract Meaning Representations,0.13895,"Syntactically controlled paraphrase generation has become an emerging
research direction in recent years. Most existing approaches require annotated
paraphrase pairs for training and are thus costly to extend to new domains.
Unsupervised approaches, on the other hand, do not need paraphrase pairs but
suffer from relatively poor performance in terms of syntactic control and
quality of generated paraphrases. In this paper, we demonstrate that leveraging
Abstract Meaning Representations (AMR) can greatly improve the performance of
unsupervised syntactically controlled paraphrase generation. Our proposed
model, AMR-enhanced Paraphrase Generator (AMRPG), separately encodes the AMR
graph and the constituency parse of the input sentence into two disentangled
semantic and syntactic embeddings. A decoder is then learned to reconstruct the
input sentence from the semantic and syntactic embeddings. Our experiments show
that AMRPG generates more accurate syntactically controlled paraphrases, both
quantitatively and qualitatively, compared to the existing unsupervised
approaches. We also demonstrate that the paraphrases generated by AMRPG can be
used for data augmentation to improve the robustness of NLP models."
Rethinking Implicit Neural Representations for Vision Learners,0.0219789,"Implicit Neural Representations (INRs) are powerful to parameterize
continuous signals in computer vision. However, almost all INRs methods are
limited to low-level tasks, e.g., image/video compression, super-resolution,
and image generation. The questions on how to explore INRs to high-level tasks
and deep networks are still under-explored. Existing INRs methods suffer from
two problems: 1) narrow theoretical definitions of INRs are inapplicable to
high-level tasks; 2) lack of representation capabilities to deep networks.
Motivated by the above facts, we reformulate the definitions of INRs from a
novel perspective and propose an innovative Implicit Neural Representation
Network (INRN), which is the first study of INRs to tackle both low-level and
high-level tasks. Specifically, we present three key designs for basic blocks
in INRN along with two different stacking ways and corresponding loss
functions. Extensive experiments with analysis on both low-level tasks (image
fitting) and high-level vision tasks (image classification, object detection,
instance segmentation) demonstrate the effectiveness of the proposed method."
JAMES: Normalizing Job Titles with Multi-Aspect Graph Embeddings and Reasoning,0.0356519,"In online job marketplaces, it is important to establish a well-defined job
title taxonomy for various downstream tasks (e.g., job recommendation, users'
career analysis, and turnover prediction). Job Title Normalization (JTN) is
such a cleaning step to classify user-created non-standard job titles into
normalized ones. However, solving the JTN problem is non-trivial with
challenges: (1) semantic similarity of different job titles, (2) non-normalized
user-created job titles, and (3) large-scale and long-tailed job titles in
real-world applications. To this end, we propose a novel solution, named JAMES,
that constructs three unique embeddings (i.e., graph, contextual, and
syntactic) of a target job title to effectively capture its various traits. We
further propose a multi-aspect co-attention mechanism to attentively combine
these embeddings, and employ neural logical reasoning representations to
collaboratively estimate similarities between messy job titles and normalized
job titles in a reasoning space. To evaluate JAMES, we conduct comprehensive
experiments against ten competing models on a large-scale real-world dataset
with over 350,000 job titles. Our experimental results show that JAMES
significantly outperforms the best baseline by 10.06% in Precision@10 and by
17.52% in NDCG@10, respectively."
Lightweight Monocular Depth Estimation with an Edge Guided Network,0.0743767,"Monocular depth estimation is an important task that can be applied to many
robotic applications. Existing methods focus on improving depth estimation
accuracy via training increasingly deeper and wider networks, however these
suffer from large computational complexity. Recent studies found that edge
information are important cues for convolutional neural networks (CNNs) to
estimate depth. Inspired by the above observations, we present a novel
lightweight Edge Guided Depth Estimation Network (EGD-Net) in this study. In
particular, we start out with a lightweight encoder-decoder architecture and
embed an edge guidance branch which takes as input image gradients and
multi-scale feature maps from the backbone to learn the edge attention
features. In order to aggregate the context information and edge attention
features, we design a transformer-based feature aggregation module (TRFA). TRFA
captures the long-range dependencies between the context information and edge
attention features through cross-attention mechanism. We perform extensive
experiments on the NYU depth v2 dataset. Experimental results show that the
proposed method runs about 96 fps on a Nvidia GTX 1080 GPU whilst achieving the
state-of-the-art performance in terms of accuracy."
Retrieval Based Time Series Forecasting,0.0313139,"Time series data appears in a variety of applications such as smart
transportation and environmental monitoring. One of the fundamental problems
for time series analysis is time series forecasting. Despite the success of
recent deep time series forecasting methods, they require sufficient
observation of historical values to make accurate forecasting. In other words,
the ratio of the output length (or forecasting horizon) to the sum of the input
and output lengths should be low enough (e.g., 0.3). As the ratio increases
(e.g., to 0.8), the uncertainty for the forecasting accuracy increases
significantly. In this paper, we show both theoretically and empirically that
the uncertainty could be effectively reduced by retrieving relevant time series
as references. In the theoretical analysis, we first quantify the uncertainty
and show its connections to the Mean Squared Error (MSE). Then we prove that
models with references are easier to learn than models without references since
the retrieved references could reduce the uncertainty. To empirically
demonstrate the effectiveness of the retrieval based time series forecasting
models, we introduce a simple yet effective two-stage method, called ReTime
consisting of a relational retrieval and a content synthesis. We also show that
ReTime can be easily adapted to the spatial-temporal time series and time
series imputation settings. Finally, we evaluate ReTime on real-world datasets
to demonstrate its effectiveness."
Features Fusion Framework for Multimodal Irregular Time-series Events,0.132188,"Some data from multiple sources can be modeled as multimodal time-series
events which have different sampling frequencies, data compositions, temporal
relations and characteristics. Different types of events have complex nonlinear
relationships, and the time of each event is irregular. Neither the classical
Recurrent Neural Network (RNN) model nor the current state-of-the-art
Transformer model can deal with these features well. In this paper, a features
fusion framework for multimodal irregular time-series events is proposed based
on the Long Short-Term Memory networks (LSTM). Firstly, the complex features
are extracted according to the irregular patterns of different events.
Secondly, the nonlinear correlation and complex temporal dependencies
relationship between complex features are captured and fused into a tensor.
Finally, a feature gate are used to control the access frequency of different
tensors. Extensive experiments on MIMIC-III dataset demonstrate that the
proposed framework significantly outperforms to the existing methods in terms
of AUC (the area under Receiver Operating Characteristic curve) and AP (Average
Precision)."
Long Short-Term Memory for Spatial Encoding in Multi-Agent Path Planning,0.0927892,"Reinforcement learning-based path planning for multi-agent systems of varying
size constitutes a research topic with increasing significance as progress in
domains such as urban air mobility and autonomous aerial vehicles continues.
Reinforcement learning with continuous state and action spaces is used to train
a policy network that accommodates desirable path planning behaviors and can be
used for time-critical applications. A Long Short-Term Memory module is
proposed to encode an unspecified number of states for a varying, indefinite
number of agents. The described training strategies and policy architecture
lead to a guidance that scales to an infinite number of agents and unlimited
physical dimensions, although training takes place at a smaller scale. The
guidance is implemented on a low-cost, off-the-shelf onboard computer. The
feasibility of the proposed approach is validated by presenting flight test
results of up to four drones, autonomously navigating collision-free in a
real-world environment."
Batch-efficient EigenDecomposition for Small and Medium Matrices,0.05519,"EigenDecomposition (ED) is at the heart of many computer vision algorithms
and applications. One crucial bottleneck limiting its usage is the expensive
computation cost, particularly for a mini-batch of matrices in the deep neural
networks. In this paper, we propose a QR-based ED method dedicated to the
application scenarios of computer vision. Our proposed method performs the ED
entirely by batched matrix/vector multiplication, which processes all the
matrices simultaneously and thus fully utilizes the power of GPUs. Our
technique is based on the explicit QR iterations by Givens rotation with double
Wilkinson shifts. With several acceleration techniques, the time complexity of
QR iterations is reduced from $O{(}n^5{)}$ to $O{(}n^3{)}$. The numerical test
shows that for small and medium batched matrices (\emph{e.g.,} $dim{<}32$) our
method can be much faster than the Pytorch SVD function. Experimental results
on visual recognition and image generation demonstrate that our methods also
achieve competitive performances."
Probabilistic and Non-Deterministic Event Data in Process Mining: Embedding Uncertainty in Process Analysis Techniques,0.0919136,"Process mining is a subfield of process science that analyzes event data
collected in databases called event logs. Recently, novel types of event data
have become of interest due to the wide industrial application of process
mining analyses. In this paper, we examine uncertain event data. Such data
contain meta-attributes describing the amount of imprecision tied with
attributes recorded in an event log. We provide examples of uncertain event
data, present the state of the art in regard of uncertainty in process mining,
and illustrate open challenges related to this research direction."
Multilinguals at SemEval-2022 Task 11: Complex NER in Semantically Ambiguous Settings for Low Resource Languages,0.0449765,"We leverage pre-trained language models to solve the task of complex NER for
two low-resource languages: Chinese and Spanish. We use the technique of Whole
Word Masking(WWM) to boost the performance of masked language modeling
objective on large and unsupervised corpora. We experiment with multiple neural
network architectures, incorporating CRF, BiLSTMs, and Linear Classifiers on
top of a fine-tuned BERT layer. All our models outperform the baseline by a
significant margin and our best performing model obtains a competitive position
on the evaluation leaderboard for the blind test set."
Fine-grained Czech News Article Dataset: An Interdisciplinary Approach to Trustworthiness Analysis,0.0156727,"We present the Verifee Dataset: a novel dataset of news articles with
fine-grained trustworthiness annotations. We develop a detailed methodology
that assesses the texts based on their parameters encompassing editorial
transparency, journalist conventions, and objective reporting while penalizing
manipulative techniques. We bring aboard a diverse set of researchers from
social, media, and computer sciences to overcome barriers and limited framing
of this interdisciplinary problem. We collect over $10,000$ unique articles
from almost $60$ Czech online news sources. These are categorized into one of
the $4$ classes across the credibility spectrum we propose, raging from
entirely trustworthy articles all the way to the manipulative ones. We produce
detailed statistics and study trends emerging throughout the set. Lastly, we
fine-tune multiple popular sequence-to-sequence language models using our
dataset on the trustworthiness classification task and report the best testing
F-1 score of $0.52$. We open-source the dataset, annotation methodology, and
annotators' instructions in full length at https://verifee.ai/research to
enable easy build-up work. We believe similar methods can help prevent
disinformation and educate in the realm of media literacy."
Practical Network Acceleration with Tiny Sets,0.0290576,"Due to data privacy issues, accelerating networks with tiny training sets has
become a critical need in practice. Previous methods mainly adopt filter-level
pruning to accelerate networks with scarce training samples. In this paper, we
reveal that dropping blocks is a fundamentally superior approach in this
scenario. It enjoys a higher acceleration ratio and results in a better
latency-accuracy performance under the few-shot setting. To choose which blocks
to drop, we propose a new concept namely recoverability to measure the
difficulty of recovering the compressed network. Our recoverability is
efficient and effective for choosing which blocks to drop. Finally, we propose
an algorithm named PRACTISE to accelerate networks using only tiny sets of
training images. PRACTISE outperforms previous methods by a significant margin.
For 22% latency reduction, PRACTISE surpasses previous methods by on average 7%
on ImageNet-1k. It also enjoys high generalization ability, working well under
data-free or out-of-domain data settings, too. Our code is at
https://github.com/DoctorKey/Practise."
Breaking the Spurious Causality of Conditional Generation via Fairness Intervention with Corrective Sampling,0.116834,"To capture the relationship between samples and labels, conditional
generative models often inherit spurious correlations from the training
dataset. This can result in label-conditional distributions that are imbalanced
with respect to another latent attribute. To mitigate this issue, which we call
spurious causality of conditional generation, we propose a general two-step
strategy. (a) Fairness Intervention (FI): emphasize the minority samples that
are hard to generate due to the spurious correlation in the training dataset.
(b) Corrective Sampling (CS): explicitly filter the generated samples and
ensure that they follow the desired latent attribute distribution. We have
designed the fairness intervention to work for various degrees of supervision
on the spurious attribute, including unsupervised, weakly-supervised, and
semi-supervised scenarios. Our experimental results demonstrate that FICS can
effectively resolve spurious causality of conditional generation across various
datasets."
Accurate and Reliable Methods for 5G UAV Jamming Identification With Calibrated Uncertainty,0.0376915,"Only increasing accuracy without considering uncertainty may negatively
impact Deep Neural Network (DNN) decision-making and decrease its reliability.
This paper proposes five combined preprocessing and post-processing methods for
time-series binary classification problems that simultaneously increase the
accuracy and reliability of DNN outputs applied in a 5G UAV security dataset.
These techniques use DNN outputs as input parameters and process them in
different ways. Two methods use a well-known Machine Learning (ML) algorithm as
a complement, and the other three use only confidence values that the DNN
estimates. We compare seven different metrics, such as the Expected Calibration
Error (ECE), Maximum Calibration Error (MCE), Mean Confidence (MC), Mean
Accuracy (MA), Normalized Negative Log Likelihood (NLL), Brier Score Loss
(BSL), and Reliability Score (RS) and the tradeoffs between them to evaluate
the proposed hybrid algorithms. First, we show that the eXtreme Gradient
Boosting (XGB) classifier might not be reliable for binary classification under
the conditions this work presents. Second, we demonstrate that at least one of
the potential methods can achieve better results than the classification in the
DNN softmax layer. Finally, we show that the prospective methods may improve
accuracy and reliability with better uncertainty calibration based on the
assumption that the RS determines the difference between MC and MA metrics, and
this difference should be zero to increase reliability. For example, Method 3
presents the best RS of 0.65 even when compared to the XGB classifier, which
achieves RS of 7.22."
An Emotion-guided Approach to Domain Adaptive Fake News Detection using Adversarial Learning,0.0368886,"Recent works on fake news detection have shown the efficacy of using emotions
as a feature for improved performance. However, the cross-domain impact of
emotion-guided features for fake news detection still remains an open problem.
In this work, we propose an emotion-guided, domain-adaptive, multi-task
approach for cross-domain fake news detection, proving the efficacy of
emotion-guided models in cross-domain settings for various datasets."
Entity-Conditioned Question Generation for Robust Attention Distribution in Neural Information Retrieval,0.0329518,"We show that supervised neural information retrieval (IR) models are prone to
learning sparse attention patterns over passage tokens, which can result in key
phrases including named entities receiving low attention weights, eventually
leading to model under-performance. Using a novel targeted synthetic data
generation method that identifies poorly attended entities and conditions the
generation episodes on those, we teach neural IR to attend more uniformly and
robustly to all entities in a given passage. On two public IR benchmarks, we
empirically show that the proposed method helps improve both the model's
attention patterns and retrieval performance, including in zero-shot settings."
Ethical Design of Computers: From Semiconductors to IoT and Artificial Intelligence,0.0,"Computing systems are tightly integrated today into our professional, social,
and private lives. An important consequence of this growing ubiquity of
computing is that it can have significant ethical implications of which
computing professionals should take account. In most real-world scenarios, it
is not immediately obvious how particular technical choices during the design
and use of computing systems could be viewed from an ethical perspective. This
article provides a perspective on the ethical challenges within semiconductor
chip design, IoT applications, and the increasing use of artificial
intelligence in the design processes, tools, and hardware-software stacks of
these systems."
Applied monocular reconstruction of parametric faces with domain engineering,0.0138874,"Many modern online 3D applications and videogames rely on parametric models
of human faces for creating believable avatars. However, manual reproduction of
someone's facial likeness with a parametric model is difficult and
time-consuming. Machine Learning solution for that task is highly desirable but
is also challenging. The paper proposes a novel approach to the so-called
Face-to-Parameters problem (F2P for short), aiming to reconstruct a parametric
face from a single image. The proposed method utilizes synthetic data, domain
decomposition, and domain adaptation for addressing multifaceted challenges in
solving the F2P. The open-sourced codebase illustrates our key observations and
provides means for quantitative evaluation. The presented approach proves
practical in an industrial application; it improves accuracy and allows for
more efficient models training. The techniques have the potential to extend to
other types of parametric models."
Hypergraph Convolutional Networks for Weakly-Supervised Semantic Segmentation,0.0,"Semantic segmentation is a fundamental topic in computer vision. Several deep
learning methods have been proposed for semantic segmentation with outstanding
results. However, these models require a lot of densely annotated images. To
address this problem, we propose a new algorithm that uses HyperGraph
Convolutional Networks for Weakly-supervised Semantic Segmentation
(HyperGCN-WSS). Our algorithm constructs spatial and k-Nearest Neighbor (k-NN)
graphs from the images in the dataset to generate the hypergraphs. Then, we
train a specialized HyperGraph Convolutional Network (HyperGCN) architecture
using some weak signals. The outputs of the HyperGCN are denominated
pseudo-labels, which are later used to train a DeepLab model for semantic
segmentation. HyperGCN-WSS is evaluated on the PASCAL VOC 2012 dataset for
semantic segmentation, using scribbles or clicks as weak signals. Our algorithm
shows competitive performance against previous methods."
Unified Line and Paragraph Detection by Graph Convolutional Networks,0.0147867,"We formulate the task of detecting lines and paragraphs in a document into a
unified two-level clustering problem. Given a set of text detection boxes that
roughly correspond to words, a text line is a cluster of boxes and a paragraph
is a cluster of lines. These clusters form a two-level tree that represents a
major part of the layout of a document. We use a graph convolutional network to
predict the relations between text detection boxes and then build both levels
of clusters from these predictions. Experimentally, we demonstrate that the
unified approach can be highly efficient while still achieving state-of-the-art
quality for detecting paragraphs in public benchmarks and real-world images."
Efficient Data-Plane Memory Scheduling for In-Network Aggregation,0.0285274,"As the scale of distributed training grows, communication becomes a
bottleneck. To accelerate the communication, recent works introduce In-Network
Aggregation (INA), which moves the gradients summation into network
middle-boxes, e.g., programmable switches to reduce the traffic volume.
However, switch memory is scarce compared to the volume of gradients
transmitted in distributed training. Although literature applies methods like
pool-based streaming or dynamic sharing to tackle the mismatch, switch memory
is still a potential performance bottleneck. Furthermore, we observe the
under-utilization of switch memory due to the synchronization requirement for
aggregator deallocation in recent works. To improve the switch memory
utilization, we propose ESA, an $\underline{E}$fficient Switch Memory
$\underline{S}$cheduler for In-Network $\underline{A}$ggregation. At its cores,
ESA enforces the preemptive aggregator allocation primitive and introduces
priority scheduling at the data-plane, which improves the switch memory
utilization and average job completion time (JCT). Experiments show that ESA
can improve the average JCT by up to $1.35\times$."
ClarifyDelphi: Reinforced Clarification Questions with Defeasibility Rewards for Social and Moral Situations,0.446489,"Context is everything, even in commonsense moral reasoning. Changing contexts
can flip the moral judgment of an action; ""Lying to a friend"" is wrong in
general, but may be morally acceptable if it is intended to protect their life.
  We present ClarifyDelphi, an interactive system that learns to ask
clarification questions (e.g., why did you lie to your friend?) in order to
elicit additional salient contexts of a social or moral situation. We posit
that questions whose potential answers lead to diverging moral judgments are
the most informative. Thus, we propose a reinforcement learning framework with
a defeasibility reward that aims to maximize the divergence between moral
judgments of hypothetical answers to a question. Human evaluation demonstrates
that our system generates more relevant, informative and defeasible questions
compared to competitive baselines. Our work is ultimately inspired by studies
in cognitive science that have investigated the flexibility in moral cognition
(i.e., the diverse contexts in which moral rules can be bent), and we hope that
research in this direction can assist both cognitive and computational
investigations of moral judgments."
Prompting Large Pre-trained Vision-Language Models For Compositional Concept Learning,0.0346826,"This work explores the zero-shot compositional learning ability of large
pre-trained vision-language models(VLMs) within the prompt-based learning
framework and propose a model (\textit{PromptCompVL}) to solve the compositonal
zero-shot learning (CZSL) problem. \textit{PromptCompVL} makes two design
choices: first, it uses a soft-prompting instead of hard-prompting to inject
learnable parameters to reprogram VLMs for compositional learning. Second, to
address the compositional challenge, it uses the soft-embedding layer to learn
primitive concepts in different combinations. By combining both soft-embedding
and soft-prompting, \textit{PromptCompVL} achieves state-of-the-art performance
on the MIT-States dataset. Furthermore, our proposed model achieves consistent
improvement compared to other CLIP-based methods which shows the effectiveness
of the proposed prompting strategies for CZSL."
Self-Knowledge Distillation via Dropout,0.0586329,"To boost the performance, deep neural networks require deeper or wider
network structures that involve massive computational and memory costs. To
alleviate this issue, the self-knowledge distillation method regularizes the
model by distilling the internal knowledge of the model itself. Conventional
self-knowledge distillation methods require additional trainable parameters or
are dependent on the data. In this paper, we propose a simple and effective
self-knowledge distillation method using a dropout (SD-Dropout). SD-Dropout
distills the posterior distributions of multiple models through a dropout
sampling. Our method does not require any additional trainable modules, does
not rely on data, and requires only simple operations. Furthermore, this simple
method can be easily combined with various self-knowledge distillation
approaches. We provide a theoretical and experimental analysis of the effect of
forward and reverse KL-divergences in our work. Extensive experiments on
various vision tasks, i.e., image classification, object detection, and
distribution shift, demonstrate that the proposed method can effectively
improve the generalization of a single network. Further experiments show that
the proposed method also improves calibration performance, adversarial
robustness, and out-of-distribution detection ability."
Counterfactual Data Augmentation improves Factuality of Abstractive Summarization,0.0502801,"Abstractive summarization systems based on pretrained language models often
generate coherent but factually inconsistent sentences. In this paper, we
present a counterfactual data augmentation approach where we augment data with
perturbed summaries that increase the training data diversity. Specifically, we
present three augmentation approaches based on replacing (i) entities from
other and the same category and (ii) nouns with their corresponding WordNet
hypernyms. We show that augmenting the training data with our approach improves
the factual correctness of summaries without significantly affecting the ROUGE
score. We show that in two commonly used summarization datasets (CNN/Dailymail
and XSum), we improve the factual correctness by about 2.5 points on average"
SATformer: Transformer-Based UNSAT Core Learning,0.0904707,"This paper introduces SATformer, a novel Transformer-based approach for the
Boolean Satisfiability (SAT) problem. Rather than solving the problem directly,
SATformer approaches the problem from the opposite direction by focusing on
unsatisfiability. Specifically, it models clause interactions to identify any
unsatisfiable sub-problems. Using a graph neural network, we convert clauses
into clause embeddings and employ a hierarchical Transformer-based model to
understand clause correlation. SATformer is trained through a multi-task
learning approach, using the single-bit satisfiability result and the minimal
unsatisfiable core (MUC) for UNSAT problems as clause supervision. As an
end-to-end learning-based satisfiability classifier, the performance of
SATformer surpasses that of NeuroSAT significantly. Furthermore, we integrate
the clause predictions made by SATformer into modern heuristic-based SAT
solvers and validate our approach with a logic equivalence checking task.
Experimental results show that our SATformer can decrease the runtime of
existing solvers by an average of 21.33%."
Towards Realistic Low-resource Relation Extraction: A Benchmark with Empirical Baseline Study,0.147878,"This paper presents an empirical study to build relation extraction systems
in low-resource settings. Based upon recent pre-trained language models, we
comprehensively investigate three schemes to evaluate the performance in
low-resource settings: (i) different types of prompt-based methods with
few-shot labeled data; (ii) diverse balancing methods to address the
long-tailed distribution issue; (iii) data augmentation technologies and
self-training to generate more labeled in-domain data. We create a benchmark
with 8 relation extraction (RE) datasets covering different languages, domains
and contexts and perform extensive comparisons over the proposed schemes with
combinations. Our experiments illustrate: (i) Though prompt-based tuning is
beneficial in low-resource RE, there is still much potential for improvement,
especially in extracting relations from cross-sentence contexts with multiple
relational triples; (ii) Balancing methods are not always helpful for RE with
long-tailed distribution; (iii) Data augmentation complements existing
baselines and can bring much performance gain, while self-training may not
consistently achieve advancement to low-resource RE. Code and datasets are in
https://github.com/zjunlp/LREBench."
Sim-2-Sim Transfer for Vision-and-Language Navigation in Continuous Environments,0.223418,"Recent work in Vision-and-Language Navigation (VLN) has presented two
environmental paradigms with differing realism -- the standard VLN setting
built on topological environments where navigation is abstracted away, and the
VLN-CE setting where agents must navigate continuous 3D environments using
low-level actions. Despite sharing the high-level task and even the underlying
instruction-path data, performance on VLN-CE lags behind VLN significantly. In
this work, we explore this gap by transferring an agent from the abstract
environment of VLN to the continuous environment of VLN-CE. We find that this
sim-2-sim transfer is highly effective, improving over the prior state of the
art in VLN-CE by +12% success rate. While this demonstrates the potential for
this direction, the transfer does not fully retain the original performance of
the agent in the abstract setting. We present a sequence of experiments to
identify what differences result in performance degradation, providing clear
directions for further improvement."
MACSum: Controllable Summarization with Mixed Attributes,0.141442,"Controllable summarization allows users to generate customized summaries with
specified attributes. However, due to the lack of designated annotations of
controlled summaries, existing works have to craft pseudo datasets by adapting
generic summarization benchmarks. Furthermore, most research focuses on
controlling single attributes individually (e.g., a short summary or a highly
abstractive summary) rather than controlling a mix of attributes together
(e.g., a short and highly abstractive summary). In this paper, we propose
MACSum, the first human-annotated summarization dataset for controlling mixed
attributes. It contains source texts from two domains, news articles and
dialogues, with human-annotated summaries controlled by five designed
attributes (Length, Extractiveness, Specificity, Topic, and Speaker). We
propose two simple and effective parameter-efficient approaches for the new
task of mixed controllable summarization based on hard prompt tuning and soft
prefix tuning. Results and analysis demonstrate that hard prompt models yield
the best performance on all metrics and human evaluations. However,
mixed-attribute control is still challenging for summarization tasks. Our
dataset and code are available at https://github.com/psunlpgroup/MACSum."
Measuring Harmful Representations in Scandinavian Language Models,0.0143979,"Scandinavian countries are perceived as role-models when it comes to gender
equality. With the advent of pre-trained language models and their widespread
usage, we investigate to what extent gender-based harmful and toxic content
exist in selected Scandinavian language models. We examine nine models,
covering Danish, Swedish, and Norwegian, by manually creating template-based
sentences and probing the models for completion. We evaluate the completions
using two methods for measuring harmful and toxic completions and provide a
thorough analysis of the results. We show that Scandinavian pre-trained
language models contain harmful and gender-based stereotypes with similar
values across all languages. This finding goes against the general expectations
related to gender equality in Scandinavian countries and shows the possible
problematic outcomes of using such models in real-world settings."
A BERT-based Deep Learning Approach for Reputation Analysis in Social Media,0.0283484,"Social media has become an essential part of the modern lifestyle, with its
usage being highly prevalent. This has resulted in unprecedented amounts of
data generated from users in social media, such as users' attitudes, opinions,
interests, purchases, and activities across various aspects of their lives.
Therefore, in a world of social media, where its power has shifted to users,
actions taken by companies and public figures are subject to constantly being
under scrutiny by influential global audiences. As a result, reputation
management in social media has become essential as companies and public figures
need to maintain their reputation to preserve their reputation capital.
However, domain experts still face the challenge of lacking appropriate
solutions to automate reliable online reputation analysis. To tackle this
challenge, we proposed a novel reputation analysis approach based on the
popular language model BERT (Bidirectional Encoder Representations from
Transformers). The proposed approach was evaluated on the reputational polarity
task using RepLab 2013 dataset. Compared to previous works, we achieved 5.8%
improvement in accuracy, 26.9% improvement in balanced accuracy, and 21.8%
improvement in terms of F-score."
ILSGAN: Independent Layer Synthesis for Unsupervised Foreground-Background Segmentation,0.0338453,"Unsupervised foreground-background segmentation aims at extracting salient
objects from cluttered backgrounds, where Generative Adversarial Network (GAN)
approaches, especially layered GANs, show great promise. However, without human
annotations, they are typically prone to produce foreground and background
layers with non-negligible semantic and visual confusion, dubbed ""information
leakage"", resulting in notable degeneration of the generated segmentation mask.
To alleviate this issue, we propose a simple-yet-effective explicit layer
independence modeling approach, termed Independent Layer Synthesis GAN
(ILSGAN), pursuing independent foreground-background layer generation by
encouraging their discrepancy. Specifically, it targets minimizing the mutual
information between visible and invisible regions of the foreground and
background to spur interlayer independence. Through in-depth theoretical and
experimental analyses, we justify that explicit layer independence modeling is
critical to suppressing information leakage and contributes to impressive
segmentation performance gains. Also, our ILSGAN achieves strong
state-of-the-art generation quality and segmentation performance on complex
real-world data. Code is available at: https://github.com/qrzou/ILSGAN"
Detection of Fights in Videos: A Comparison Study of Anomaly Detection and Action Recognition,0.0265739,"Detection of fights is an important surveillance application in videos. Most
existing methods use supervised binary action recognition. Since frame-level
annotations are very hard to get for anomaly detection, weakly supervised
learning using multiple instance learning is widely used. This paper explores
the detection of fights in videos as one special type of anomaly detection and
as binary action recognition. We use the UBI-Fight and NTU-CCTV-Fight datasets
for most of the study since they have frame-level annotations. We find that the
anomaly detection has similar or even better performance than the action
recognition. Furthermore, we study to use anomaly detection as a toolbox to
generate training datasets for action recognition in an iterative way
conditioned on the performance of the anomaly detection. Experiment results
should show that we achieve state-of-the-art performance on three fight
detection datasets."
Discrete Tree Flows via Tree-Structured Permutations,0.00841392,"While normalizing flows for continuous data have been extensively researched,
flows for discrete data have only recently been explored. These prior models,
however, suffer from limitations that are distinct from those of continuous
flows. Most notably, discrete flow-based models cannot be straightforwardly
optimized with conventional deep learning methods because gradients of discrete
functions are undefined or zero. Previous works approximate pseudo-gradients of
the discrete functions but do not solve the problem on a fundamental level. In
addition to that, backpropagation can be computationally burdensome compared to
alternative discrete algorithms such as decision tree algorithms. Our approach
seeks to reduce computational burden and remove the need for pseudo-gradients
by developing a discrete flow based on decision trees -- building upon the
success of efficient tree-based methods for classification and regression for
discrete data. We first define a tree-structured permutation (TSP) that
compactly encodes a permutation of discrete data where the inverse is easy to
compute; thus, we can efficiently compute the density value and sample new
data. We then propose a decision tree algorithm to build TSPs that learns the
tree structure and permutations at each node via novel criteria. We empirically
demonstrate the feasibility of our method on multiple datasets."
Robust and Accurate -- Compositional Architectures for Randomized Smoothing,0.0385201,"Randomized Smoothing (RS) is considered the state-of-the-art approach to
obtain certifiably robust models for challenging tasks. However, current RS
approaches drastically decrease standard accuracy on unperturbed data, severely
limiting their real-world utility. To address this limitation, we propose a
compositional architecture, ACES, which certifiably decides on a per-sample
basis whether to use a smoothed model yielding predictions with guarantees or a
more accurate standard model without guarantees. This, in contrast to prior
approaches, enables both high standard accuracies and significant provable
robustness. On challenging tasks such as ImageNet, we obtain, e.g., $80.0\%$
natural accuracy and $28.2\%$ certifiable accuracy against $\ell_2$
perturbations with $r=1.0$. We release our code and models at
https://github.com/eth-sri/aces."
Traceable and Authenticable Image Tagging for Fake News Detection,0.00741567,"To prevent fake news images from misleading the public, it is desirable not
only to verify the authenticity of news images but also to trace the source of
fake news, so as to provide a complete forensic chain for reliable fake news
detection. To simultaneously achieve the goals of authenticity verification and
source tracing, we propose a traceable and authenticable image tagging approach
that is based on a design of Decoupled Invertible Neural Network (DINN). The
designed DINN can simultaneously embed the dual-tags, \textit{i.e.},
authenticable tag and traceable tag, into each news image before publishing,
and then separately extract them for authenticity verification and source
tracing. Moreover, to improve the accuracy of dual-tags extraction, we design a
parallel Feature Aware Projection Model (FAPM) to help the DINN preserve
essential tag information. In addition, we define a Distance Metric-Guided
Module (DMGM) that learns asymmetric one-class representations to enable the
dual-tags to achieve different robustness performances under malicious
manipulations. Extensive experiments, on diverse datasets and unseen
manipulations, demonstrate that the proposed tagging approach achieves
excellent performance in the aspects of both authenticity verification and
source tracing for reliable fake news detection and outperforms the prior
works."
Generalized Probabilistic U-Net for medical image segementation,0.0268776,"We propose the Generalized Probabilistic U-Net, which extends the
Probabilistic U-Net by allowing more general forms of the Gaussian distribution
as the latent space distribution that can better approximate the uncertainty in
the reference segmentations. We study the effect the choice of latent space
distribution has on capturing the uncertainty in the reference segmentations
using the LIDC-IDRI dataset. We show that the choice of distribution affects
the sample diversity of the predictions and their overlap with respect to the
reference segmentations. For the LIDC-IDRI dataset, we show that using a
mixture of Gaussians results in a statistically significant improvement in the
generalized energy distance (GED) metric with respect to the standard
Probabilistic U-Net. We have made our implementation available at
https://github.com/ishaanb92/GeneralizedProbabilisticUNet"
Knowledge Transfer from Answer Ranking to Answer Generation,0.0367087,"Recent studies show that Question Answering (QA) based on Answer Sentence
Selection (AS2) can be improved by generating an improved answer from the top-k
ranked answer sentences (termed GenQA). This allows for synthesizing the
information from multiple candidates into a concise, natural-sounding answer.
However, creating large-scale supervised training data for GenQA models is very
challenging. In this paper, we propose to train a GenQA model by transferring
knowledge from a trained AS2 model, to overcome the aforementioned issue.
First, we use an AS2 model to produce a ranking over answer candidates for a
set of questions. Then, we use the top ranked candidate as the generation
target, and the next k top ranked candidates as context for training a GenQA
model. We also propose to use the AS2 model prediction scores for loss
weighting and score-conditioned input/output shaping, to aid the knowledge
transfer. Our evaluation on three public and one large industrial datasets
demonstrates the superiority of our approach over the AS2 baseline, and GenQA
trained using supervised data."
On the Usefulness of the Fit-on-the-Test View on Evaluating Calibration of Classifiers,0.0,"Every uncalibrated classifier has a corresponding true calibration map that
calibrates its confidence. Deviations of this idealistic map from the identity
map reveal miscalibration. Such calibration errors can be reduced with many
post-hoc calibration methods which fit some family of calibration maps on a
validation dataset. In contrast, evaluation of calibration with the expected
calibration error (ECE) on the test set does not explicitly involve fitting.
However, as we demonstrate, ECE can still be viewed as if fitting a family of
functions on the test data. This motivates the fit-on-the-test view on
evaluation: first, approximate a calibration map on the test data, and second,
quantify its distance from the identity. Exploiting this view allows us to
unlock missed opportunities: (1) use the plethora of post-hoc calibration
methods for evaluating calibration; (2) tune the number of bins in ECE with
cross-validation. Furthermore, we introduce: (3) benchmarking on pseudo-real
data where the true calibration map can be estimated very precisely; and (4)
novel calibration and evaluation methods using new calibration map families PL
and PL3."
Common Knowledge of Abstract Groups,0.0418996,"Epistemic logics typically talk about knowledge of individual agents or
groups of explicitly listed agents. Often, however, one wishes to express
knowledge of groups of agents specified by a given property, as in `it is
common knowledge among economists'. We introduce such a logic of common
knowledge, which we term abstract-group epistemic logic (AGEL). That is, AGEL
features a common knowledge operator for groups of agents given by concepts in
a separate agent logic that we keep generic, with one possible agent logic
being ALC. We show that AGEL is EXPTIME-complete, with the lower bound
established by reduction from standard group epistemic logic, and the upper
bound by a satisfiability-preserving embedding into the full $\mu$-calculus.
Further main results include a finite model property (not enjoyed by the full
$\mu$-calculus) and a complete axiomatization."
Task Grouping for Multilingual Text Recognition,0.0627957,"Most existing OCR methods focus on alphanumeric characters due to the
popularity of English and numbers, as well as their corresponding datasets. On
extending the characters to more languages, recent methods have shown that
training different scripts with different recognition heads can greatly improve
the end-to-end recognition accuracy compared to combining characters from all
languages in the same recognition head. However, we postulate that similarities
between some languages could allow sharing of model parameters and benefit from
joint training. Determining language groupings, however, is not immediately
obvious. To this end, we propose an automatic method for multilingual text
recognition with a task grouping and assignment module using Gumbel-Softmax,
introducing a task grouping loss and weighted recognition loss to allow for
simultaneous training of the models and grouping modules. Experiments on MLT19
lend evidence to our hypothesis that there is a middle ground between combining
every task together and separating every task that achieves a better
configuration of task grouping/separation."
License Plate Privacy in Collaborative Visual Analysis of Traffic Scenes,0.0731315,"Traffic scene analysis is important for emerging technologies such as smart
traffic management and autonomous vehicles. However, such analysis also poses
potential privacy threats. For example, a system that can recognize license
plates may construct patterns of behavior of the corresponding vehicles' owners
and use that for various illegal purposes. In this paper we present a system
that enables traffic scene analysis while at the same time preserving license
plate privacy. The system is based on a multi-task model whose latent space is
selectively compressed depending on the amount of information the specific
features carry about analysis tasks and private information. Effectiveness of
the proposed method is illustrated by experiments on the Cityscapes dataset,
for which we also provide license plate annotations."
Scale-free and Task-agnostic Attack: Generating Photo-realistic Adversarial Patterns with Patch Quilting Generator,0.134751,"\noindent Traditional L_p norm-restricted image attack algorithms suffer from
poor transferability to black box scenarios and poor robustness to defense
algorithms. Recent CNN generator-based attack approaches can synthesize
unrestricted and semantically meaningful entities to the image, which is shown
to be transferable and robust. However, such methods attack images by either
synthesizing local adversarial entities, which are only suitable for attacking
specific contents or performing global attacks, which are only applicable to a
specific image scale. In this paper, we propose a novel Patch Quilting
Generative Adversarial Networks (PQ-GAN) to learn the first scale-free CNN
generator that can be applied to attack images with arbitrary scales for
various computer vision tasks. The principal investigation on transferability
of the generated adversarial examples, robustness to defense frameworks, and
visual quality assessment show that the proposed PQG-based attack framework
outperforms the other nine state-of-the-art adversarial attack approaches when
attacking the neural networks trained on two standard evaluation datasets
(i.e., ImageNet and CityScapes)."
Adaptive Meta-learner via Gradient Similarity for Few-shot Text Classification,0.05937,"Few-shot text classification aims to classify the text under the few-shot
scenario. Most of the previous methods adopt optimization-based meta learning
to obtain task distribution. However, due to the neglect of matching between
the few amount of samples and complicated models, as well as the distinction
between useful and useless task features, these methods suffer from the
overfitting issue. To address this issue, we propose a novel Adaptive
Meta-learner via Gradient Similarity (AMGS) method to improve the model
generalization ability to a new task. Specifically, the proposed AMGS
alleviates the overfitting based on two aspects: (i) acquiring the potential
semantic representation of samples and improving model generalization through
the self-supervised auxiliary task in the inner loop, (ii) leveraging the
adaptive meta-learner via gradient similarity to add constraints on the
gradient obtained by base-learner in the outer loop. Moreover, we make a
systematic analysis of the influence of regularization on the entire framework.
Experimental results on several benchmarks demonstrate that the proposed AMGS
consistently improves few-shot text classification performance compared with
the state-of-the-art optimization-based meta-learning approaches."
Instance Segmentation of Unlabeled Modalities via Cyclic Segmentation GAN,0.115086,"Instance segmentation for unlabeled imaging modalities is a challenging but
essential task as collecting expert annotation can be expensive and
time-consuming. Existing works segment a new modality by either deploying a
pre-trained model optimized on diverse training data or conducting domain
translation and image segmentation as two independent steps. In this work, we
propose a novel Cyclic Segmentation Generative Adversarial Network (CySGAN)
that conducts image translation and instance segmentation jointly using a
unified framework. Besides the CycleGAN losses for image translation and
supervised losses for the annotated source domain, we introduce additional
self-supervised and segmentation-based adversarial objectives to improve the
model performance by leveraging unlabeled target domain images. We benchmark
our approach on the task of 3D neuronal nuclei segmentation with annotated
electron microscopy (EM) images and unlabeled expansion microscopy (ExM) data.
Our CySGAN outperforms both pretrained generalist models and the baselines that
sequentially conduct image translation and segmentation. Our implementation and
the newly collected, densely annotated ExM nuclei dataset, named NucExM, are
available at https://connectomics-bazaar.github.io/proj/CySGAN/index.html."
Development of Automatic Endotracheal Tube and Carina Detection on Portable Supine Chest Radiographs using Artificial Intelligence,0.0868051,"The image quality of portable supine chest radiographs is inherently poor due
to low contrast and high noise. The endotracheal intubation detection requires
the locations of the endotracheal tube (ETT) tip and carina. The goal is to
find the distance between the ETT tip and the carina in chest radiography. To
overcome such a problem, we propose a feature extraction method with Mask
R-CNN. The Mask R-CNN predicts a tube and a tracheal bifurcation in an image.
Then, the feature extraction method is used to find the feature point of the
ETT tip and that of the carina. Therefore, the ETT-carina distance can be
obtained. In our experiments, our results can exceed 96\% in terms of recall
and precision. Moreover, the object error is less than $4.7751\pm 5.3420$ mm,
and the ETT-carina distance errors are less than $5.5432\pm 6.3100$ mm. The
external validation shows that the proposed method is a high-robustness system.
According to the Pearson correlation coefficient, we have a strong correlation
between the board-certified intensivists and our result in terms of ETT-carina
distance."
ACORT: A Compact Object Relation Transformer for Parameter Efficient Image Captioning,0.0724399,"Recent research that applies Transformer-based architectures to image
captioning has resulted in state-of-the-art image captioning performance,
capitalising on the success of Transformers on natural language tasks.
Unfortunately, though these models work well, one major flaw is their large
model sizes. To this end, we present three parameter reduction methods for
image captioning Transformers: Radix Encoding, cross-layer parameter sharing,
and attention parameter sharing. By combining these methods, our proposed ACORT
models have 3.7x to 21.6x fewer parameters than the baseline model without
compromising test performance. Results on the MS-COCO dataset demonstrate that
our ACORT models are competitive against baselines and SOTA approaches, with
CIDEr score >=126. Finally, we present qualitative results and ablation studies
to demonstrate the efficacy of the proposed changes further. Code and
pre-trained models are publicly available at
https://github.com/jiahuei/sparse-image-captioning."
Self-Supervised Domain Calibration and Uncertainty Estimation for Place Recognition,0.0113976,"Visual place recognition techniques based on deep learning, which have
imposed themselves as the state-of-the-art in recent years, do not generalize
well to environments visually different from the training set. Thus, to achieve
top performance, it is sometimes necessary to fine-tune the networks to the
target environment. To this end, we propose a self-supervised domain
calibration procedure based on robust pose graph optimization from Simultaneous
Localization and Mapping (SLAM) as the supervision signal without requiring GPS
or manual labeling. Moreover, we leverage the procedure to improve uncertainty
estimation for place recognition matches which is important in safety critical
applications. We show that our approach can improve the performance of a
state-of-the-art technique on a target environment dissimilar from its training
set and that we can obtain uncertainty estimates. We believe that this approach
will help practitioners to deploy robust place recognition solutions in
real-world applications. Our code is available publicly:
https://github.com/MISTLab/vpr-calibration-and-uncertainty"
Natural Language Processing for Cognitive Analysis of Emotions,0.00597033,"Emotion analysis in texts suffers from two major limitations: annotated
gold-standard corpora are mostly small and homogeneous, and emotion
identification is often simplified as a sentence-level classification problem.
To address these issues, we introduce a new annotation scheme for exploring
emotions and their causes, along with a new French dataset composed of
autobiographical accounts of an emotional scene. The texts were collected by
applying the Cognitive Analysis of Emotions developed by A. Finkel to help
people improve on their emotion management. The method requires the manual
analysis of an emotional event by a coach trained in Cognitive Analysis. We
present a rule-based approach to automatically annotate emotions and their
semantic roles (e.g. emotion causes) to facilitate the identification of
relevant aspects by the coach. We investigate future directions for emotion
analysis using graph structures."
Leveraging Natural Language Processing to Augment Structured Social Determinants of Health Data in the Electronic Health Record,0.0148141,"Objective: Social determinants of health (SDOH) impact health outcomes and
are documented in the electronic health record (EHR) through structured data
and unstructured clinical notes. However, clinical notes often contain more
comprehensive SDOH information, detailing aspects such as status, severity, and
temporality. This work has two primary objectives: i) develop a natural
language processing (NLP) information extraction model to capture detailed SDOH
information and ii) evaluate the information gain achieved by applying the SDOH
extractor to clinical narratives and combining the extracted representations
with existing structured data.
  Materials and Methods: We developed a novel SDOH extractor using a deep
learning entity and relation extraction architecture to characterize SDOH
across various dimensions. In an EHR case study, we applied the SDOH extractor
to a large clinical data set with 225,089 patients and 430,406 notes with
social history sections and compared the extracted SDOH information with
existing structured data.
  Results: The SDOH extractor achieved 0.86 F1 on a withheld test set. In the
EHR case study, we found extracted SDOH information complements existing
structured data with 32% of homeless patients, 19% of current tobacco users,
and 10% of drug users only having these health risk factors documented in the
clinical narrative.
  Conclusions: Utilizing EHR data to identify SDOH health risk factors and
social needs may improve patient care and outcomes. Semantic representations of
text-encoded SDOH information can augment existing structured data, and this
more comprehensive SDOH representation can assist health systems in identifying
and addressing these social needs."
Easing Automatic Neurorehabilitation via Classification and Smoothness Analysis,0.0640635,"Assessing the quality of movements for post-stroke patients during the
rehabilitation phase is vital given that there is no standard stroke
rehabilitation plan for all the patients. In fact, it depends basically on the
patient's functional independence and its progress along the rehabilitation
sessions. To tackle this challenge and make neurorehabilitation more agile, we
propose an automatic assessment pipeline that starts by recognizing patients'
movements by means of a shallow deep learning architecture, then measuring the
movement quality using jerk measure and related measures. A particularity of
this work is that the dataset used is clinically relevant, since it represents
movements inspired from Fugl-Meyer a well common upper-limb clinical stroke
assessment scale for stroke patients. We show that it is possible to detect the
contrast between healthy and patients movements in terms of smoothness, besides
achieving conclusions about the patients' progress during the rehabilitation
sessions that correspond to the clinicians' findings about each case."
MVP: Robust Multi-View Practice for Driving Action Localization,0.0458675,"Distracted driving causes thousands of deaths per year, and how to apply
deep-learning methods to prevent these tragedies has become a crucial problem.
In Track3 of the 6th AI City Challenge, researchers provide a high-quality
video dataset with densely action annotations. Due to the small data scale and
unclear action boundary, the dataset presents a unique challenge to precisely
localize all the different actions and classify their categories. In this
paper, we make good use of the multi-view synchronization among videos, and
conduct robust Multi-View Practice (MVP) for driving action localization. To
avoid overfitting, we fine-tune SlowFast with Kinetics-700 pre-training as the
feature extractor. Then the features of different views are passed to
ActionFormer to generate candidate action proposals. For precisely localizing
all the actions, we design elaborate post-processing, including model voting,
threshold filtering and duplication removal. The results show that our MVP is
robust for driving action localization, which achieves 28.49% F1-score in the
Track3 test set."
Harnessing Artificial Intelligence to Infer Novel Spatial Biomarkers for the Diagnosis of Eosinophilic Esophagitis,0.168528,"Eosinophilic esophagitis (EoE) is a chronic allergic inflammatory condition
of the esophagus associated with elevated esophageal eosinophils. Second only
to gastroesophageal reflux disease, EoE is one of the leading causes of chronic
refractory dysphagia in adults and children. EoE diagnosis requires enumerating
the density of esophageal eosinophils in esophageal biopsies, a somewhat
subjective task that is time-consuming, thus reducing the ability to process
the complex tissue structure. Previous artificial intelligence (AI) approaches
that aimed to improve histology-based diagnosis focused on recapitulating
identification and quantification of the area of maximal eosinophil density.
However, this metric does not account for the distribution of eosinophils or
other histological features, over the whole slide image. Here, we developed an
artificial intelligence platform that infers local and spatial biomarkers based
on semantic segmentation of intact eosinophils and basal zone distributions.
Besides the maximal density of eosinophils (referred to as Peak Eosinophil
Count [PEC]) and a maximal basal zone fraction, we identify two additional
metrics that reflect the distribution of eosinophils and basal zone fractions.
This approach enables a decision support system that predicts EoE activity and
classifies the histological severity of EoE patients. We utilized a cohort that
includes 1066 biopsy slides from 400 subjects to validate the system's
performance and achieved a histological severity classification accuracy of
86.70%, sensitivity of 84.50%, and specificity of 90.09%. Our approach
highlights the importance of systematically analyzing the distribution of
biopsy features over the entire slide and paves the way towards a personalized
decision support system that will assist not only in counting cells but can
also potentially improve diagnosis and provide treatment prediction."
Graph Neural Networks and Representation Embedding for Table Extraction in PDF Documents,0.105325,"Tables are widely used in several types of documents since they can bring
important information in a structured way. In scientific papers, tables can sum
up novel discoveries and summarize experimental results, making the research
comparable and easily understandable by scholars. Several methods perform table
analysis working on document images, losing useful information during the
conversion from the PDF files since OCR tools can be prone to recognition
errors, in particular for text inside tables. The main contribution of this
work is to tackle the problem of table extraction, exploiting Graph Neural
Networks. Node features are enriched with suitably designed representation
embeddings. These representations help to better distinguish not only tables
from the other parts of the paper, but also table cells from table headers. We
experimentally evaluated the proposed approach on a new dataset obtained by
merging the information provided in the PubLayNet and PubTables-1M datasets."
Device-friendly Guava fruit and leaf disease detection using deep learning,0.0351877,"This work presents a deep learning-based plant disease diagnostic system
using images of fruits and leaves. Five state-of-the-art convolutional neural
networks (CNN) have been employed for implementing the system. Hitherto model
accuracy has been the focus for such applications and model optimization has
not been accounted for the model to be applicable to end-user devices. Two
model quantization techniques such as float16 and dynamic range quantization
have been applied to the five state-of-the-art CNN architectures. The study
shows that the quantized GoogleNet model achieved the size of 0.143 MB with an
accuracy of 97%, which is the best candidate model considering the size
criterion. The EfficientNet model achieved the size of 4.2MB with an accuracy
of 99%, which is the best model considering the performance criterion. The
source codes are available at
https://github.com/CompostieAI/Guava-disease-detection."
Copiloting Autonomous Multi-Robot Missions: A Game-inspired Supervisory Control Interface,0.0927735,"Real-world deployment of new technology and capabilities can be daunting. The
recent DARPA Subterranean (SubT) Challenge, for instance, aimed at the
advancement of robotic platforms and autonomy capabilities in three one-year
development pushes. While multi-agent systems are traditionally deployed in
controlled and structured environments that allow for controlled testing (e.g.,
warehouses), the SubT challenge targeted various types of unknown underground
environments that imposed the risk of robot loss in the case of failure. In
this work, we introduce a video game-inspired interface, an autonomous mission
assistant, and test and deploy these using a heterogeneous multi-agent system
in challenging environments. This work leads to improved human-supervisory
control for a multi-agent system reducing overhead from application switching,
task planning, execution, and verification while increasing available
exploration time with this human-autonomy teaming platform."
Personalized Game Difficulty Prediction Using Factorization Machines,0.0224337,"The accurate and personalized estimation of task difficulty provides many
opportunities for optimizing user experience. However, user diversity makes
such difficulty estimation hard, in that empirical measurements from some user
sample do not necessarily generalize to others. In this paper, we contribute a
new approach for personalized difficulty estimation of game levels, borrowing
methods from content recommendation. Using factorization machines (FM) on a
large dataset from a commercial puzzle game, we are able to predict difficulty
as the number of attempts a player requires to pass future game levels, based
on observed attempt counts from earlier levels and levels played by others. In
addition to performance and scalability, FMs offer the benefit that the learned
latent variable model can be used to study the characteristics of both players
and game levels that contribute to difficulty. We compare the approach to a
simple non-personalized baseline and a personalized prediction using Random
Forests. Our results suggest that FMs are a promising tool enabling game
designers to both optimize player experience and learn more about their players
and the game."
ProspectNet: Weighted Conditional Attention for Future Interaction Modeling in Behavior Prediction,0.0158765,"Behavior prediction plays an important role in integrated autonomous driving
software solutions. In behavior prediction research, interactive behavior
prediction is a less-explored area, compared to single-agent behavior
prediction. Predicting the motion of interactive agents requires initiating
novel mechanisms to capture the joint behaviors of the interactive pairs. In
this work, we formulate the end-to-end joint prediction problem as a sequential
learning process of marginal learning and joint learning of vehicle behaviors.
We propose ProspectNet, a joint learning block that adopts the weighted
attention score to model the mutual influence between interactive agent pairs.
The joint learning block first weighs the multi-modal predicted candidate
trajectories, then updates the ego-agent's embedding via cross attention.
Furthermore, we broadcast the individual future predictions for each
interactive agent into a pair-wise scoring module to select the top $K$
prediction pairs. We show that ProspectNet outperforms the Cartesian product of
two marginal predictions, and achieves comparable performance on the Waymo
Interactive Motion Prediction benchmarks."
CATrans: Context and Affinity Transformer for Few-Shot Segmentation,0.0,"Few-shot segmentation (FSS) aims to segment novel categories given scarce
annotated support images. The crux of FSS is how to aggregate dense
correlations between support and query images for query segmentation while
being robust to the large variations in appearance and context. To this end,
previous Transformer-based methods explore global consensus either on context
similarity or affinity map between support-query pairs. In this work, we
effectively integrate the context and affinity information via the proposed
novel Context and Affinity Transformer (CATrans) in a hierarchical
architecture. Specifically, the Relation-guided Context Transformer (RCT)
propagates context information from support to query images conditioned on more
informative support features. Based on the observation that a huge feature
distinction between support and query pairs brings barriers for context
knowledge transfer, the Relation-guided Affinity Transformer (RAT) measures
attention-aware affinity as auxiliary information for FSS, in which the
self-affinity is responsible for more reliable cross-affinity. We conduct
experiments to demonstrate the effectiveness of the proposed model,
outperforming the state-of-the-art methods."
Diversity Enhanced Table-to-Text Generation via Type Control,0.271898,"Generating natural language statements to convey logical inferences from
tabular data (i.e., Logical NLG) is a process with one input and a variety of
valid outputs. This characteristic underscores the need for a method to produce
a diverse set of valid outputs, presenting different perspectives of the input
data. We propose a simple yet effective diversity-enhancing scheme that builds
upon an inherent property of the statements, their logic-types, by using a
type-controlled table-to-text generation model. We demonstrate, through
extensive automatic and human evaluations over the two publicly available
Logical NLG datasets, that our proposed method both facilitates the ability to
effectively control the generated statement type, and produces results superior
to the strongest baselines in terms of quality and factuality-diversity
trade-off."
A Unified Neural Network Model for Readability Assessment with Feature Projection and Length-Balanced Loss,0.11342,"For readability assessment, traditional methods mainly employ machine
learning classifiers with hundreds of linguistic features. Although the deep
learning model has become the prominent approach for almost all NLP tasks, it
is less explored for readability assessment. In this paper, we propose a
BERT-based model with feature projection and length-balanced loss (BERT-FP-LBL)
for readability assessment. Specially, we present a new difficulty knowledge
guided semi-supervised method to extract topic features to complement the
traditional linguistic features. From the linguistic features, we employ
projection filtering to extract orthogonal features to supplement BERT
representations. Furthermore, we design a new length-balanced loss to handle
the greatly varying length distribution of data. Our model achieves
state-of-the-art performances on two English benchmark datasets and one dataset
of Chinese textbooks, and also achieves the near-perfect accuracy of 99\% on
one English dataset. Moreover, our proposed model obtains comparable results
with human experts in consistency test."
Individual Topology Structure of Eye Movement Trajectories,0.0157208,"Traditionally, extracting patterns from eye movement data relies on
statistics of different macro-events such as fixations and saccades. This
requires an additional preprocessing step to separate the eye movement
subtypes, often with a number of parameters on which the classification results
depend. Besides that, definitions of such macro events are formulated in
different ways by different researchers.
  We propose an application of a new class of features to the quantitative
analysis of personal eye movement trajectories structure. This new class of
features based on algebraic topology allows extracting patterns from different
modalities of gaze such as time series of coordinates and amplitudes, heatmaps,
and point clouds in a unified way at all scales from micro to macro. We
experimentally demonstrate the competitiveness of the new class of features
with the traditional ones and their significant synergy while being used
together for the person authentication task on the recently published eye
movement trajectories dataset."
State Space Closure: Revisiting Endless Online Level Generation via Reinforcement Learning,0.0188439,"In this paper, we revisit endless online level generation with the recently
proposed experience-driven procedural content generation via reinforcement
learning (EDRL) framework. Inspired by an observation that EDRL tends to
generate recurrent patterns, we formulate a notion of state space closure which
makes any stochastic state appeared possibly in an infinite-horizon online
generation process can be found within a finite-horizon. Through theoretical
analysis, we find that even though state space closure arises a concern about
diversity, it generalises EDRL trained with a finite-horizon to the
infinite-horizon scenario without deterioration of content quality. Moreover,
we verify the quality and the diversity of contents generated by EDRL via
empirical studies, on the widely used Super Mario Bros. benchmark. Experimental
results reveal that the diversity of levels generated by EDRL is limited due to
the state space closure, whereas their quality does not deteriorate in a
horizon which is longer than the one specified in the training. Concluding our
outcomes and analysis, future work on endless online level generation via
reinforcement learning should address the issue of diversity while assuring the
occurrence of state space closure and quality."
Do Large Language Models know what humans know?,0.0373026,"Humans can attribute beliefs to others. However, it is unknown to what extent
this ability results from an innate biological endowment or from experience
accrued through child development, particularly exposure to language describing
others' mental states. We test the viability of the language exposure
hypothesis by assessing whether models exposed to large quantities of human
language display sensitivity to the implied knowledge states of characters in
written passages. In pre-registered analyses, we present a linguistic version
of the False Belief Task to both human participants and a Large Language Model,
GPT-3. Both are sensitive to others' beliefs, but while the language model
significantly exceeds chance behavior, it does not perform as well as the
humans, nor does it explain the full extent of their behavior -- despite being
exposed to more language than a human would in a lifetime. This suggests that
while statistical learning from language exposure may in part explain how
humans develop the ability to reason about the mental states of others, other
mechanisms are also responsible."
Learning Options via Compression,0.0132363,"Identifying statistical regularities in solutions to some tasks in multi-task
reinforcement learning can accelerate the learning of new tasks. Skill learning
offers one way of identifying these regularities by decomposing pre-collected
experiences into a sequence of skills. A popular approach to skill learning is
maximizing the likelihood of the pre-collected experience with latent variable
models, where the latent variables represent the skills. However, there are
often many solutions that maximize the likelihood equally well, including
degenerate solutions. To address this underspecification, we propose a new
objective that combines the maximum likelihood objective with a penalty on the
description length of the skills. This penalty incentivizes the skills to
maximally extract common structures from the experiences. Empirically, our
objective learns skills that solve downstream tasks in fewer samples compared
to skills learned from only maximizing likelihood. Further, while most prior
works in the offline multi-task setting focus on tasks with low-dimensional
observations, our objective can scale to challenging tasks with
high-dimensional image observations."
Anomaly Attribution with Likelihood Compensation,0.0525261,"This paper addresses the task of explaining anomalous predictions of a
black-box regression model. When using a black-box model, such as one to
predict building energy consumption from many sensor measurements, we often
have a situation where some observed samples may significantly deviate from
their prediction. It may be due to a sub-optimal black-box model, or simply
because those samples are outliers. In either case, one would ideally want to
compute a ``responsibility score'' indicative of the extent to which an input
variable is responsible for the anomalous output. In this work, we formalize
this task as a statistical inverse problem: Given model deviation from the
expected value, infer the responsibility score of each of the input variables.
We propose a new method called likelihood compensation (LC), which is founded
on the likelihood principle and computes a correction to each input variable.
To the best of our knowledge, this is the first principled framework that
computes a responsibility score for real valued anomalous model deviations. We
apply our approach to a real-world building energy prediction task and confirm
its utility based on expert feedback."
CCC-wav2vec 2.0: Clustering aided Cross Contrastive Self-supervised learning of speech representations,0.119469,"While Self-Supervised Learning has helped reap the benefit of the scale from
the available unlabeled data, the learning paradigms are continuously being
bettered. We present a new pre-training strategy named ccc-wav2vec 2.0, which
uses clustering and an augmentation-based cross-contrastive loss as its
self-supervised objective. Through the clustering module, we scale down the
influence of those negative examples that are highly similar to the positive.
The Cross-Contrastive loss is computed between the encoder output of the
original sample and the quantizer output of its augmentation and vice-versa,
bringing robustness to the pre-training strategy. ccc-wav2vec 2.0 achieves up
to 15.6% and 12.7% relative WER improvement over the baseline wav2vec 2.0 on
the test-clean and test-other sets, respectively, of LibriSpeech, without the
use of any language model. The proposed method also achieves up to 14.9%
relative WER improvement over the baseline wav2vec 2.0 when fine-tuned on
Switchboard data. We make all our codes publicly available on GitHub."
A Real-Time Fusion Framework for Long-term Visual Localization,0.0902252,"Visual localization is a fundamental task that regresses the 6 Degree Of
Freedom (6DoF) poses with image features in order to serve the high precision
localization requests in many robotics applications. Degenerate conditions like
motion blur, illumination changes and environment variations place great
challenges in this task. Fusion with additional information, such as sequential
information and Inertial Measurement Unit (IMU) inputs, would greatly assist
such problems. In this paper, we present an efficient client-server visual
localization architecture that fuses global and local pose estimations to
realize promising precision and efficiency. We include additional geometry
hints in mapping and global pose regressing modules to improve the measurement
quality. A loosely coupled fusion policy is adopted to leverage the computation
complexity and accuracy. We conduct the evaluations on two typical open-source
benchmarks, 4Seasons and OpenLORIS. Quantitative results prove that our
framework has competitive performance with respect to other state-of-the-art
visual localization solutions."
Planes vs. Chairs: Category-guided 3D shape learning without any 3D cues,0.0234267,"We present a novel 3D shape reconstruction method which learns to predict an
implicit 3D shape representation from a single RGB image. Our approach uses a
set of single-view images of multiple object categories without viewpoint
annotation, forcing the model to learn across multiple object categories
without 3D supervision. To facilitate learning with such minimal supervision,
we use category labels to guide shape learning with a novel categorical metric
learning approach. We also utilize adversarial and viewpoint regularization
techniques to further disentangle the effects of viewpoint and shape. We obtain
the first results for large-scale (more than 50 categories) single-viewpoint
shape prediction using a single model without any 3D cues. We are also the
first to examine and quantify the benefit of class information in single-view
supervised 3D shape reconstruction. Our method achieves superior performance
over state-of-the-art methods on ShapeNet-13, ShapeNet-55 and Pascal3D+."
StereoKG: Data-Driven Knowledge Graph Construction for Cultural Knowledge and Stereotypes,0.017786,"Analyzing ethnic or religious bias is important for improving fairness,
accountability, and transparency of natural language processing models.
However, many techniques rely on human-compiled lists of bias terms, which are
expensive to create and are limited in coverage. In this study, we present a
fully data-driven pipeline for generating a knowledge graph (KG) of cultural
knowledge and stereotypes. Our resulting KG covers 5 religious groups and 5
nationalities and can easily be extended to include more entities. Our human
evaluation shows that the majority (59.2%) of non-singleton entries are
coherent and complete stereotypes. We further show that performing intermediate
masked language model training on the verbalized KG leads to a higher level of
cultural awareness in the model and has the potential to increase
classification performance on knowledge-crucial samples on a related task,
i.e., hate speech detection."
Maknuune: A Large Open Palestinian Arabic Lexicon,-1.0,"We present Maknuune, a large open lexicon for the Palestinian Arabic dialect.
Maknuune has over 36K entries from 17K lemmas, and 3.7K roots. All entries
include diacritized Arabic orthography, phonological transcription and English
glosses. Some entries are enriched with additional information such as broken
plurals and templatic feminine forms, associated phrases and collocations,
Standard Arabic glosses, and examples or notes on grammar, usage, or location
of collected entry."
Check-worthy Claim Detection across Topics for Automated Fact-checking,0.0226938,"An important component of an automated fact-checking system is the claim
check-worthiness detection system, which ranks sentences by prioritising them
based on their need to be checked. Despite a body of research tackling the
task, previous research has overlooked the challenging nature of identifying
check-worthy claims across different topics. In this paper, we assess and
quantify the challenge of detecting check-worthy claims for new, unseen topics.
After highlighting the problem, we propose the AraCWA model to mitigate the
performance deterioration when detecting check-worthy claims across topics. The
AraCWA model enables boosting the performance for new topics by incorporating
two components for few-shot learning and data augmentation. Using a publicly
available dataset of Arabic tweets consisting of 14 different topics, we
demonstrate that our proposed data augmentation strategy achieves substantial
improvements across topics overall, where the extent of the improvement varies
across topics. Further, we analyse the semantic similarities between topics,
suggesting that the similarity metric could be used as a proxy to determine the
difficulty level of an unseen topic prior to undertaking the task of labelling
the underlying sentences."
MelHuBERT: A simplified HuBERT on Mel spectrograms,-1.0,"Self-supervised models have had great success in learning speech
representations that can generalize to various downstream tasks. However, most
self-supervised models require a large amount of compute and multiple GPUs to
train, significantly hampering the development of self-supervised learning. In
an attempt to reduce the computation of training, we revisit the training of
HuBERT, a highly successful self-supervised model. We improve and simplify
several key components, including the loss function, input representation, and
training in multiple stages. Our model, MelHuBERT, is able to achieve favorable
performance on phone recognition, speaker identification, and automatic speech
recognition against HuBERT, while saving 31.2% of the pre-training time, or
equivalently 33.5% MACs per one second speech. The code and pre-trained models
are available in https://github.com/nervjack2/MelHuBERT."
DETR++: Taming Your Multi-Scale Detection Transformer,0.136939,"Convolutional Neural Networks (CNN) have dominated the field of detection
ever since the success of AlexNet in ImageNet classification [12]. With the
sweeping reform of Transformers [27] in natural language processing, Carion et
al. [2] introduce the Transformer-based detection method, i.e., DETR. However,
due to the quadratic complexity in the self-attention mechanism in the
Transformer, DETR is never able to incorporate multi-scale features as
performed in existing CNN-based detectors, leading to inferior results in small
object detection. To mitigate this issue and further improve performance of
DETR, in this work, we investigate different methods to incorporate multi-scale
features and find that a Bi-directional Feature Pyramid (BiFPN) works best with
DETR in further raising the detection precision. With this discovery, we
propose DETR++, a new architecture that improves detection results by 1.9% AP
on MS COCO 2017, 11.5% AP on RICO icon detection, and 9.1% AP on RICO layout
extraction over existing baselines."
Generation-Augmented Query Expansion For Code Retrieval,0.225686,"Pre-trained language models have achieved promising success in code retrieval
tasks, where a natural language documentation query is given to find the most
relevant existing code snippet. However, existing models focus only on
optimizing the documentation code pairs by embedding them into latent space,
without the association of external knowledge. In this paper, we propose a
generation-augmented query expansion framework. Inspired by the human retrieval
process - sketching an answer before searching, in this work, we utilize the
powerful code generation model to benefit the code retrieval task.
Specifically, we demonstrate that rather than merely retrieving the target code
snippet according to the documentation query, it would be helpful to augment
the documentation query with its generation counterpart - generated code
snippets from the code generation model. To the best of our knowledge, this is
the first attempt that leverages the code generation model to enhance the code
retrieval task. We achieve new state-of-the-art results on the CodeSearchNet
benchmark and surpass the baselines significantly."
Towards 3D Object Detection with 2D Supervision,0.0402705,"The great progress of 3D object detectors relies on large-scale data and 3D
annotations. The annotation cost for 3D bounding boxes is extremely expensive
while the 2D ones are easier and cheaper to collect. In this paper, we
introduce a hybrid training framework, enabling us to learn a visual 3D object
detector with massive 2D (pseudo) labels, even without 3D annotations. To break
through the information bottleneck of 2D clues, we explore a new perspective:
Temporal 2D Supervision. We propose a temporal 2D transformation to bridge the
3D predictions with temporal 2D labels. Two steps, including homography wraping
and 2D box deduction, are taken to transform the 3D predictions into 2D ones
for supervision. Experiments conducted on the nuScenes dataset show strong
results (nearly 90% of its fully-supervised performance) with only 25% 3D
annotations. We hope our findings can provide new insights for using a large
number of 2D annotations for 3D perception."
Predictive Crypto-Asset Automated Market Making Architecture for Decentralized Finance using Deep Reinforcement Learning,0.0465139,"The study proposes a quote-driven predictive automated market maker (AMM)
platform with on-chain custody and settlement functions, alongside off-chain
predictive reinforcement learning capabilities to improve liquidity provision
of real-world AMMs. The proposed AMM architecture is an augmentation to the
Uniswap V3, a cryptocurrency AMM protocol, by utilizing a novel market
equilibrium pricing for reduced divergence and slippage loss. Further, the
proposed architecture involves a predictive AMM capability, utilizing a deep
hybrid Long Short-Term Memory (LSTM) and Q-learning reinforcement learning
framework that looks to improve market efficiency through better forecasts of
liquidity concentration ranges, so liquidity starts moving to expected
concentration ranges, prior to asset price movement, so that liquidity
utilization is improved. The augmented protocol framework is expected have
practical real-world implications, by (i) reducing divergence loss for
liquidity providers, (ii) reducing slippage for crypto-asset traders, while
(iii) improving capital efficiency for liquidity provision for the AMM
protocol. To our best knowledge, there are no known protocol or literature that
are proposing similar deep learning-augmented AMM that achieves similar capital
efficiency and loss minimization objectives for practical real-world
applications."
Fuzzy granular approximation classifier,0.0279899,"In this article, a new Fuzzy Granular Approximation Classifier (FGAC) is
introduced. The classifier is based on the previously introduced concept of the
granular approximation and its multi-class classification case. The classifier
is instance-based and its biggest advantage is its local transparency i.e., the
ability to explain every individual prediction it makes. We first develop the
FGAC for the binary classification case and the multi-class classification case
and we discuss its variation that includes the Ordered Weighted Average (OWA)
operators. Those variations of the FGAC are then empirically compared with
other locally transparent ML methods. At the end, we discuss the transparency
of the FGAC and its advantage over other locally transparent methods. We
conclude that while the FGAC has similar predictive performance to other
locally transparent ML models, its transparency can be superior in certain
cases."
Hierarchical Attention Network for Few-Shot Object Detection via Meta-Contrastive Learning,0.0326231,"Few-shot object detection (FSOD) aims to classify and detect few images of
novel categories. Existing meta-learning methods insufficiently exploit
features between support and query images owing to structural limitations. We
propose a hierarchical attention network with sequentially large receptive
fields to fully exploit the query and support images. In addition,
meta-learning does not distinguish the categories well because it determines
whether the support and query images match. In other words, metric-based
learning for classification is ineffective because it does not work directly.
Thus, we propose a contrastive learning method called meta-contrastive
learning, which directly helps achieve the purpose of the meta-learning
strategy. Finally, we establish a new state-of-the-art network, by realizing
significant margins. Our method brings 2.3, 1.0, 1.3, 3.4 and 2.4% AP
improvements for 1-30 shots object detection on COCO dataset. Our code is
available at: https://github.com/infinity7428/hANMCL"
Continual Predictive Learning from Videos,0.0168061,"Predictive learning ideally builds the world model of physical processes in
one or more given environments. Typical setups assume that we can collect data
from all environments at all times. In practice, however, different prediction
tasks may arrive sequentially so that the environments may change persistently
throughout the training procedure. Can we develop predictive learning
algorithms that can deal with more realistic, non-stationary physical
environments? In this paper, we study a new continual learning problem in the
context of video prediction, and observe that most existing methods suffer from
severe catastrophic forgetting in this setup. To tackle this problem, we
propose the continual predictive learning (CPL) approach, which learns a
mixture world model via predictive experience replay and performs test-time
adaptation with non-parametric task inference. We construct two new benchmarks
based on RoboNet and KTH, in which different tasks correspond to different
physical robotic environments or human actions. Our approach is shown to
effectively mitigate forgetting and remarkably outperform the na\""ive
combinations of previous art in video prediction and continual learning."
Morphological Processing of Low-Resource Languages: Where We Are and What's Next,0.0477708,"Automatic morphological processing can aid downstream natural language
processing applications, especially for low-resource languages, and assist
language documentation efforts for endangered languages. Having long been
multilingual, the field of computational morphology is increasingly moving
towards approaches suitable for languages with minimal or no annotated
resources. First, we survey recent developments in computational morphology
with a focus on low-resource languages. Second, we argue that the field is
ready to tackle the logical next challenge: understanding a language's
morphology from raw text alone. We perform an empirical study on a truly
unsupervised version of the paradigm completion task and show that, while
existing state-of-the-art models bridged by two newly proposed models we devise
perform reasonably, there is still much room for improvement. The stakes are
high: solving this task will increase the language coverage of morphological
resources by a number of magnitudes."
AltUB: Alternating Training Method to Update Base Distribution of Normalizing Flow for Anomaly Detection,-1.0,"Unsupervised anomaly detection is coming into the spotlight these days in
various practical domains due to the limited amount of anomaly data. One of the
major approaches for it is a normalizing flow which pursues the invertible
transformation of a complex distribution as images into an easy distribution as
N(0, I). In fact, algorithms based on normalizing flow like FastFlow and
CFLOW-AD establish state-of-the-art performance on unsupervised anomaly
detection tasks. Nevertheless, we investigate these algorithms convert normal
images into not N(0, I) as their destination, but an arbitrary normal
distribution. Moreover, their performances are often unstable, which is highly
critical for unsupervised tasks because data for validation are not provided.
To break through these observations, we propose a simple solution AltUB which
introduces alternating training to update the base distribution of normalizing
flow for anomaly detection. AltUB effectively improves the stability of
performance of normalizing flow. Furthermore, our method achieves the new
state-of-the-art performance of the anomaly segmentation task on the MVTec AD
dataset with 98.8% AUROC."
Evaluation of Pre-Trained CNN Models for Geographic Fake Image Detection,0.0424933,"Thanks to the remarkable advances in generative adversarial networks (GANs),
it is becoming increasingly easy to generate/manipulate images. The existing
works have mainly focused on deepfake in face images and videos. However, we
are currently witnessing the emergence of fake satellite images, which can be
misleading or even threatening to national security. Consequently, there is an
urgent need to develop detection methods capable of distinguishing between real
and fake satellite images. To advance the field, in this paper, we explore the
suitability of several convolutional neural network (CNN) architectures for
fake satellite image detection. Specifically, we benchmark four CNN models by
conducting extensive experiments to evaluate their performance and robustness
against various image distortions. This work allows the establishment of new
baselines and may be useful for the development of CNN-based methods for fake
satellite image detection."
Safe and Robust Experience Sharing for Deterministic Policy Gradient Algorithms,0.0460301,"Learning in high dimensional continuous tasks is challenging, mainly when the
experience replay memory is very limited. We introduce a simple yet effective
experience sharing mechanism for deterministic policies in continuous action
domains for the future off-policy deep reinforcement learning applications in
which the allocated memory for the experience replay buffer is limited. To
overcome the extrapolation error induced by learning from other agents'
experiences, we facilitate our algorithm with a novel off-policy correction
technique without any action probability estimates. We test the effectiveness
of our method in challenging OpenAI Gym continuous control tasks and conclude
that it can achieve a safe experience sharing across multiple agents and
exhibits a robust performance when the replay memory is strictly limited."
Of Human Criteria and Automatic Metrics: A Benchmark of the Evaluation of Story Generation,0.517173,"Research on Automatic Story Generation (ASG) relies heavily on human and
automatic evaluation. However, there is no consensus on which human evaluation
criteria to use, and no analysis of how well automatic criteria correlate with
them. In this paper, we propose to re-evaluate ASG evaluation. We introduce a
set of 6 orthogonal and comprehensive human criteria, carefully motivated by
the social sciences literature. We also present HANNA, an annotated dataset of
1,056 stories produced by 10 different ASG systems. HANNA allows us to
quantitatively evaluate the correlations of 72 automatic metrics with human
criteria. Our analysis highlights the weaknesses of current metrics for ASG and
allows us to formulate practical recommendations for ASG evaluation."
EnDex: Evaluation of Dialogue Engagingness at Scale,0.0140826,"We propose EnDex, the first human-reaction based model to evaluate dialogue
engagingness. EnDex is trained on 80k Reddit-based Engagement Dataset (RED)
curated using a novel distant-supervision framework. Engagingness is a key
measure that captures high-level quality of AI dialogue systems and closely
reflects actual user experience. However, data shortage, plus the abstract and
extensive definition of engagingness makes it challenging to develop an
automatic metric. Our work departs from mainstream approaches that use
synthetic negative examples to train binary classifiers, and instead, proposes
a solution using distant-supervision from human-reaction feedback. To support
the soundness of our EnDex metric, we offer a theoretical foundation for
engagement, an extensive ablation study, and empirical evidence of high
correlation on five engagingness related datasets. We will release code,
off-the-shelf EnDex model, and a large-scale dataset upon paper publication to
facilitate future research."
Unsupervised Lifelong Person Re-identification via Contrastive Rehearsal,0.0194788,"Existing unsupervised person re-identification (ReID) methods focus on
adapting a model trained on a source domain to a fixed target domain. However,
an adapted ReID model usually only works well on a certain target domain, but
can hardly memorize the source domain knowledge and generalize to upcoming
unseen data. In this paper, we propose unsupervised lifelong person ReID, which
focuses on continuously conducting unsupervised domain adaptation on new
domains without forgetting the knowledge learnt from old domains. To tackle
unsupervised lifelong ReID, we conduct a contrastive rehearsal on a small
number of stored old samples while sequentially adapting to new domains. We
further set an image-to-image similarity constraint between old and new models
to regularize the model updates in a way that suits old knowledge. We
sequentially train our model on several large-scale datasets in an unsupervised
manner and test it on all seen domains as well as several unseen domains to
validate the generalizability of our method. Our proposed unsupervised lifelong
method achieves strong generalizability, which significantly outperforms
previous lifelong methods on both seen and unseen domains. Code will be made
available at https://github.com/chenhao2345/UCR."
Low-resource Neural Machine Translation with Cross-modal Alignment,0.181888,"How to achieve neural machine translation with limited parallel data?
Existing techniques often rely on large-scale monolingual corpora, which is
impractical for some low-resource languages. In this paper, we turn to connect
several low-resource languages to a particular high-resource one by additional
visual modality. Specifically, we propose a cross-modal contrastive learning
method to learn a shared space for all languages, where both a coarse-grained
sentence-level objective and a fine-grained token-level one are introduced.
Experimental results and further analysis show that our method can effectively
learn the cross-modal and cross-lingual alignment with a small amount of
image-text pairs and achieves significant improvements over the text-only
baseline under both zero-shot and few-shot scenarios."
Fault-Tolerant Offline Multi-Agent Path Planning,0.0927892,"We study a novel graph path planning problem for multiple agents that may
crash at runtime, and block part of the workspace. In our setting, agents can
detect neighboring crashed agents, and change followed paths at runtime. The
objective is then to prepare a set of paths and switching rules for each agent,
ensuring that all correct agents reach their destinations without collisions or
deadlocks, despite unforeseen crashes of other agents. Such planning is
attractive to build reliable multi-robot systems. We present problem
formalization, theoretical analysis such as computational complexities, and how
to solve this offline planning problem."
Image-based Automatic Dial Meter Reading in Unconstrained Scenarios,0.320399,"The replacement of analog meters with smart meters is costly, laborious, and
far from complete in developing countries. The Energy Company of Parana (Copel)
(Brazil) performs more than 4 million meter readings (almost entirely of
non-smart devices) per month, and we estimate that 850 thousand of them are
from dial meters. Therefore, an image-based automatic reading system can reduce
human errors, create a proof of reading, and enable the customers to perform
the reading themselves through a mobile application. We propose novel
approaches for Automatic Dial Meter Reading (ADMR) and introduce a new dataset
for ADMR in unconstrained scenarios, called UFPR-ADMR-v2. Our best-performing
method combines YOLOv4 with a novel regression approach (AngReg), and explores
several postprocessing techniques. Compared to previous works, it decreased the
Mean Absolute Error (MAE) from 1,343 to 129 and achieved a meter recognition
rate (MRR) of 98.90% -- with an error tolerance of 1 Kilowatt-hour (kWh)."
Combining State-of-the-Art Models with Maximal Marginal Relevance for Few-Shot and Zero-Shot Multi-Document Summarization,0.0413975,"In Natural Language Processing, multi-document summarization (MDS) poses many
challenges to researchers above those posed by single-document summarization
(SDS). These challenges include the increased search space and greater
potential for the inclusion of redundant information. While advancements in
deep learning approaches have led to the development of several advanced
language models capable of summarization, the variety of training data specific
to the problem of MDS remains relatively limited. Therefore, MDS approaches
which require little to no pretraining, known as few-shot or zero-shot
applications, respectively, could be beneficial additions to the current set of
tools available in summarization. To explore one possible approach, we devise a
strategy for combining state-of-the-art models' outputs using maximal marginal
relevance (MMR) with a focus on query relevance rather than document diversity.
Our MMR-based approach shows improvement over some aspects of the current
state-of-the-art results in both few-shot and zero-shot MDS applications while
maintaining a state-of-the-art standard of output by all available metrics."
Universal Deep GNNs: Rethinking Residual Connection in GNNs from a Path Decomposition Perspective for Preventing the Over-smoothing,0.0222211,"The performance of GNNs degrades as they become deeper due to the
over-smoothing. Among all the attempts to prevent over-smoothing, residual
connection is one of the promising methods due to its simplicity. However,
recent studies have shown that GNNs with residual connections only slightly
slow down the degeneration. The reason why residual connections fail in GNNs is
still unknown. In this paper, we investigate the forward and backward behavior
of GNNs with residual connections from a novel path decomposition perspective.
We find that the recursive aggregation of the median length paths from the
binomial distribution of residual connection paths dominates output
representation, resulting in over-smoothing as GNNs go deeper. Entangled
propagation and weight matrices cause gradient smoothing and prevent GNNs with
residual connections from optimizing to the identity mapping. Based on these
findings, we present a Universal Deep GNNs (UDGNN) framework with cold-start
adaptive residual connections (DRIVE) and feedforward modules. Extensive
experiments demonstrate the effectiveness of our method, which achieves
state-of-the-art results over non-smooth heterophily datasets by simply
stacking standard GNNs."
ArcAid: Analysis of Archaeological Artifacts using Drawings,0.0562783,"Archaeology is an intriguing domain for computer vision. It suffers not only
from shortage in (labeled) data, but also from highly-challenging data, which
is often extremely abraded and damaged. This paper proposes a novel
semi-supervised model for classification and retrieval of images of
archaeological artifacts. This model utilizes unique data that exists in the
domain -- manual drawings made by special artists. These are used during
training to implicitly transfer the domain knowledge from the drawings to their
corresponding images, improving their classification results. We show that
while learning how to classify, our model also learns how to generate drawings
of the artifacts, an important documentation task, which is currently performed
manually. Last but not least, we collected a new dataset of stamp-seals of the
Southern Levant. Our code and dataset are publicly available."
Smart Multi-tenant Federated Learning,0.0616644,"Federated learning (FL) is an emerging distributed machine learning method
that empowers in-situ model training on decentralized edge devices. However,
multiple simultaneous training activities could overload resource-constrained
devices. In this work, we propose a smart multi-tenant FL system, MuFL, to
effectively coordinate and execute simultaneous training activities. We first
formalize the problem of multi-tenant FL, define multi-tenant FL scenarios, and
introduce a vanilla multi-tenant FL system that trains activities sequentially
to form baselines. Then, we propose two approaches to optimize multi-tenant FL:
1) activity consolidation merges training activities into one activity with a
multi-task architecture; 2) after training it for rounds, activity splitting
divides it into groups by employing affinities among activities such that
activities within a group have better synergy. Extensive experiments
demonstrate that MuFL outperforms other methods while consuming 40% less
energy. We hope this work will inspire the community to further study and
optimize multi-tenant FL."
Multi-sensor large-scale dataset for multi-view 3D reconstruction,0.119322,"We present a new multi-sensor dataset for multi-view 3D surface
reconstruction. It includes registered RGB and depth data from sensors of
different resolutions and modalities: smartphones, Intel RealSense, Microsoft
Kinect, industrial cameras, and structured-light scanner. The scenes are
selected to emphasize a diverse set of material properties challenging for
existing algorithms. We provide around 1.4 million images of 107 different
scenes acquired from 100 viewing directions under 14 lighting conditions. We
expect our dataset will be useful for evaluation and training of 3D
reconstruction algorithms and for related tasks. The dataset is available at
skoltech3d.appliedai.tech."
Online Auction-Based Incentive Mechanism Design for Horizontal Federated Learning with Budget Constraint,0.0409351,"Federated learning makes it possible for all parties with data isolation to
train the model collaboratively and efficiently while satisfying privacy
protection. To obtain a high-quality model, an incentive mechanism is necessary
to motivate more high-quality workers with data and computing power. The
existing incentive mechanisms are applied in offline scenarios, where the task
publisher collects all bids and selects workers before the task. However, it is
practical that different workers arrive online in different orders before or
during the task. Therefore, we propose a reverse auction-based online incentive
mechanism for horizontal federated learning with budget constraint. Workers
submit bids when they arrive online. The task publisher with a limited budget
leverages the information of the arrived workers to decide on whether to select
the new worker. Theoretical analysis proves that our mechanism satisfies budget
feasibility, computational efficiency, individual rationality, consumer
sovereignty, time truthfulness, and cost truthfulness with a sufficient budget.
The experimental results show that our online mechanism is efficient and can
obtain high-quality models."
Computing Abductive Explanations for Boosted Trees,0.125846,"Boosted trees is a dominant ML model, exhibiting high accuracy. However,
boosted trees are hardly intelligible, and this is a problem whenever they are
used in safety-critical applications. Indeed, in such a context, rigorous
explanations of the predictions made are expected. Recent work have shown how
subset-minimal abductive explanations can be derived for boosted trees, using
automated reasoning techniques. However, the generation of such well-founded
explanations is intractable in the general case. To improve the scalability of
their generation, we introduce the notion of tree-specific explanation for a
boosted tree. We show that tree-specific explanations are abductive
explanations that can be computed in polynomial time. We also explain how to
derive a subset-minimal abductive explanation from a tree-specific explanation.
Experiments on various datasets show the computational benefits of leveraging
tree-specific explanations for deriving subset-minimal abductive explanations."
Semi-supervised Object Detection via Virtual Category Learning,0.0807466,"Due to the costliness of labelled data in real-world applications,
semi-supervised object detectors, underpinned by pseudo labelling, are
appealing. However, handling confusing samples is nontrivial: discarding
valuable confusing samples would compromise the model generalisation while
using them for training would exacerbate the confirmation bias issue caused by
inevitable mislabelling. To solve this problem, this paper proposes to use
confusing samples proactively without label correction. Specifically, a virtual
category (VC) is assigned to each confusing sample such that they can safely
contribute to the model optimisation even without a concrete label. It is
attributed to specifying the embedding distance between the training sample and
the virtual category as the lower bound of the inter-class distance. Moreover,
we also modify the localisation loss to allow high-quality boundaries for
location regression. Extensive experiments demonstrate that the proposed VC
learning significantly surpasses the state-of-the-art, especially with small
amounts of available labels."
Socio-cognitive Optimization of Time-delay Control Problems using Evolutionary Metaheuristics,0.079563,"Metaheuristics are universal optimization algorithms which should be used for
solving difficult problems, unsolvable by classic approaches. In this paper we
aim at constructing novel socio-cognitive metaheuristic based on castes, and
apply several versions of this algorithm to optimization of time-delay system
model. Besides giving the background and the details of the proposed algorithms
we apply them to optimization of selected variants of the problem and discuss
the results."
Revisiting initial sets in abstract argumentation,0.00997978,"We revisit the notion of initial sets by Xu and Cayrol, i.e., non-empty
minimal admissible sets in abstract argumentation frameworks. Initial sets are
a simple concept for analysing conflicts in an abstract argumentation framework
and to explain why certain arguments can be accepted. We contribute with new
insights on the structure of initial sets and devise a simple non-deterministic
construction principle for any admissible set, based on iterative selection of
initial sets of the original framework and its induced reducts. In particular,
we characterise many existing admissibility-based semantics via this
construction principle, thus providing a constructive explanation on the
structure of extensions. We also investigate certain problems related to
initial sets with respect to their computational complexity."
Explainable Reinforcement Learning via Model Transforms,0.00736046,"Understanding emerging behaviors of reinforcement learning (RL) agents may be
difficult since such agents are often trained in complex environments using
highly complex decision making procedures. This has given rise to a variety of
approaches to explainability in RL that aim to reconcile discrepancies that may
arise between the behavior of an agent and the behavior that is anticipated by
an observer. Most recent approaches have relied either on domain knowledge that
may not always be available, on an analysis of the agent's policy, or on an
analysis of specific elements of the underlying environment, typically modeled
as a Markov Decision Process (MDP). Our key claim is that even if the
underlying model is not fully known (e.g., the transition probabilities have
not been accurately learned) or is not maintained by the agent (i.e., when
using model-free methods), the model can nevertheless be exploited to
automatically generate explanations. For this purpose, we suggest using formal
MDP abstractions and transforms, previously used in the literature for
expediting the search for optimal policies, to automatically produce
explanations. Since such transforms are typically based on a symbolic
representation of the environment, they can provide meaningful explanations for
gaps between the anticipated and actual agent behavior. We formally define the
explainability problem, suggest a class of transforms that can be used for
explaining emergent behaviors, and suggest methods that enable efficient search
for an explanation. We demonstrate the approach on a set of standard
benchmarks."
Beyond Prompting: Making Pre-trained Language Models Better Zero-shot Learners by Clustering Representations,0.053644,"Recent work has demonstrated that pre-trained language models (PLMs) are
zero-shot learners. However, most existing zero-shot methods involve heavy
human engineering or complicated self-training pipelines, hindering their
application to new situations. In this work, we show that zero-shot text
classification can be improved simply by clustering texts in the embedding
spaces of PLMs. Specifically, we fit the unlabeled texts with a Bayesian
Gaussian Mixture Model after initializing cluster positions and shapes using
class names. Despite its simplicity, this approach achieves superior or
comparable performance on both topic and sentiment classification datasets and
outperforms prior works significantly on unbalanced datasets. We further
explore the applicability of our clustering approach by evaluating it on 14
datasets with more diverse topics, text lengths, and numbers of classes. Our
approach achieves an average of 20% absolute improvement over prompt-based
zero-shot learning. Finally, we compare different PLM embedding spaces and find
that texts are well-clustered by topics even if the PLM is not explicitly
pre-trained to generate meaningful sentence embeddings. This work indicates
that PLM embeddings can categorize texts without task-specific fine-tuning,
thus providing a new way to analyze and utilize their knowledge and zero-shot
learning ability."
Score-Guided Intermediate Layer Optimization: Fast Langevin Mixing for Inverse Problems,0.247393,"We prove fast mixing and characterize the stationary distribution of the
Langevin Algorithm for inverting random weighted DNN generators. This result
extends the work of Hand and Voroninski from efficient inversion to efficient
posterior sampling. In practice, to allow for increased expressivity, we
propose to do posterior sampling in the latent space of a pre-trained
generative model. To achieve that, we train a score-based model in the latent
space of a StyleGAN-2 and we use it to solve inverse problems. Our framework,
Score-Guided Intermediate Layer Optimization (SGILO), extends prior work by
replacing the sparsity regularization with a generative prior in the
intermediate layer. Experimentally, we obtain significant improvements over the
previous state-of-the-art, especially in the low measurement regime."
TorchMD-NET: Equivariant Transformers for Neural Network based Molecular Potentials,0.206391,"The prediction of quantum mechanical properties is historically plagued by a
trade-off between accuracy and speed. Machine learning potentials have
previously shown great success in this domain, reaching increasingly better
accuracy while maintaining computational efficiency comparable with classical
force fields. In this work we propose TorchMD-NET, a novel equivariant
transformer (ET) architecture, outperforming state-of-the-art on MD17, ANI-1,
and many QM9 targets in both accuracy and computational efficiency. Through an
extensive attention weight analysis, we gain valuable insights into the black
box predictor and show differences in the learned representation of conformers
versus conformations sampled from molecular dynamics or normal modes.
Furthermore, we highlight the importance of datasets including off-equilibrium
conformations for the evaluation of molecular potentials."
CC-Riddle: A Question Answering Dataset of Chinese Character Riddles,0.0104335,"The Chinese character riddle is a unique form of cultural entertainment
specific to the Chinese language. It typically comprises two parts: the riddle
description and the solution. The solution to the riddle is a single character,
while the riddle description primarily describes the glyph of the solution,
occasionally supplemented with its explanation and pronunciation. Solving
Chinese character riddles is a challenging task that demands understanding of
character glyph, general knowledge, and a grasp of figurative language. In this
paper, we construct a \textbf{C}hinese \textbf{C}haracter riddle dataset named
CC-Riddle, which covers the majority of common simplified Chinese characters.
The construction process is a combination of web crawling, language model
generation and manual filtering. In generation stage, we input the Chinese
phonetic alphabet, glyph and meaning of the solution character into the
generation model, which then produces multiple riddle descriptions. The
generated riddles are then manually filtered and the final CC-Riddle dataset is
composed of both human-written riddles and these filtered, generated riddles.
In order to assess the performance of language models on the task of solving
character riddles, we use retrieval-based, generative and multiple-choice QA
strategies to test three language models: BERT, ChatGPT and ChatGLM. The test
results reveal that current language models still struggle to solve Chinese
character riddles. CC-Riddle is publicly available at
\url{https://github.com/pku0xff/CC-Riddle}."
A Twitter-Driven Deep Learning Mechanism for the Determination of Vehicle Hijacking Spots in Cities,0.0357973,"Vehicle hijacking is one of the leading crimes in many cities. For instance,
in South Africa, drivers must constantly remain vigilant on the road in order
to ensure that they do not become hijacking victims. This work is aimed at
developing a map depicting hijacking spots in a city by using Twitter data.
Tweets, which include the keyword ""hijacking"", are obtained in a designated
city of Cape Town, in this work. In order to extract relevant tweets, these
tweets are analyzed by using the following machine learning techniques: 1) a
Multi-layer Feed-forward Neural Network (MLFNN); 2) Convolutional Neural
Network; and Bidirectional Encoder Representations from Transformers (BERT).
Through training and testing, CNN achieved an accuracy of 99.66%, while MLFNN
and BERT achieve accuracies of 98.99% and 73.99% respectively. In terms of
Recall, Precision and F1-score, CNN also achieved the best results. Therefore,
CNN was used for the identification of relevant tweets. The relevant reports
that it generates are visually presented on a points map of the City of Cape
Town. This work used a small dataset of 426 tweets. In future, the use of
evolutionary computation will be explored for purposes of optimizing the deep
learning models. A mobile application is under development to make this
information usable by the general public."
Self-Supervised Losses for One-Class Textual Anomaly Detection,0.140809,"Current deep learning methods for anomaly detection in text rely on
supervisory signals in inliers that may be unobtainable or bespoke
architectures that are difficult to tune. We study a simpler alternative:
fine-tuning Transformers on the inlier data with self-supervised objectives and
using the losses as an anomaly score. Overall, the self-supervision approach
outperforms other methods under various anomaly detection scenarios, improving
the AUROC score on semantic anomalies by 11.6% and on syntactic anomalies by
22.8% on average. Additionally, the optimal objective and resultant learnt
representation depend on the type of downstream anomaly. The separability of
anomalies and inliers signals that a representation is more effective for
detecting semantic anomalies, whilst the presence of narrow feature directions
signals a representation that is effective for detecting syntactic anomalies."
CLINICAL: Targeted Active Learning for Imbalanced Medical Image Classification,0.0562619,"Training deep learning models on medical datasets that perform well for all
classes is a challenging task. It is often the case that a suboptimal
performance is obtained on some classes due to the natural class imbalance
issue that comes with medical data. An effective way to tackle this problem is
by using targeted active learning, where we iteratively add data points to the
training data that belong to the rare classes. However, existing active
learning methods are ineffective in targeting rare classes in medical datasets.
In this work, we propose Clinical (targeted aCtive Learning for ImbalaNced
medICal imAge cLassification) a framework that uses submodular mutual
information functions as acquisition functions to mine critical data points
from rare classes. We apply our framework to a wide-array of medical imaging
datasets on a variety of real-world class imbalance scenarios - namely, binary
imbalance and long-tail imbalance. We show that Clinical outperforms the
state-of-the-art active learning methods by acquiring a diverse set of data
points that belong to the rare classes."
Multilingual Multimodal Learning with Machine Translated Text,0.073169,"Most vision-and-language pretraining research focuses on English tasks.
However, the creation of multilingual multimodal evaluation datasets (e.g.
Multi30K, xGQA, XVNLI, and MaRVL) poses a new challenge in finding high-quality
training data that is both multilingual and multimodal. In this paper, we
investigate whether machine translating English multimodal data can be an
effective proxy for the lack of readily available multilingual data. We call
this framework TD-MML: Translated Data for Multilingual Multimodal Learning,
and it can be applied to any multimodal dataset and model. We apply it to both
pretraining and fine-tuning data with a state-of-the-art model. In order to
prevent models from learning from low-quality translated text, we propose two
metrics for automatically removing such translations from the resulting
datasets. In experiments on five tasks across 20 languages in the IGLUE
benchmark, we show that translated data can provide a useful signal for
multilingual multimodal learning, both at pretraining and fine-tuning."
UM6P-CS at SemEval-2022 Task 11: Enhancing Multilingual and Code-Mixed Complex Named Entity Recognition via Pseudo Labels using Multilingual Transformer,0.0198676,"Building real-world complex Named Entity Recognition (NER) systems is a
challenging task. This is due to the complexity and ambiguity of named entities
that appear in various contexts such as short input sentences, emerging
entities, and complex entities. Besides, real-world queries are mostly
malformed, as they can be code-mixed or multilingual, among other scenarios. In
this paper, we introduce our submitted system to the Multilingual Complex Named
Entity Recognition (MultiCoNER) shared task. We approach the complex NER for
multilingual and code-mixed queries, by relying on the contextualized
representation provided by the multilingual Transformer XLM-RoBERTa. In
addition to the CRF-based token classification layer, we incorporate a span
classification loss to recognize named entities spans. Furthermore, we use a
self-training mechanism to generate weakly-annotated data from a large
unlabeled dataset. Our proposed system is ranked 6th and 8th in the
multilingual and code-mixed MultiCoNER's tracks respectively."
Online Detection Of Supply Chain Network Disruptions Using Sequential Change-Point Detection for Hawkes Processes,0.0466921,"In this paper, we attempt to detect an inflection or change-point resulting
from the Covid-19 pandemic on supply chain data received from a large furniture
company. To accomplish this, we utilize a modified CUSUM (Cumulative Sum)
procedure on the company's spatial-temporal order data as well as a GLR
(Generalized Likelihood Ratio) based method. We model the order data using the
Hawkes Process Network, a multi-dimensional self and mutually exciting point
process, by discretizing the spatial data and treating each order as an event
that has a corresponding node and time. We apply the methodologies on the
company's most ordered item on a national scale and perform a deep dive into a
single state. Because the item was ordered infrequently in the state compared
to the nation, this approach allows us to show efficacy upon different degrees
of data sparsity. Furthermore, it showcases use potential across differing
levels of spatial detail."
The distribution of syntactic dependency distances,0.0112027,"The syntactic structure of a sentence can be represented as a graph where
vertices are words and edges indicate syntactic dependencies between them. In
this setting, the distance between two syntactically linked words can be
defined as the difference between their positions. Here we want to contribute
to the characterization of the actual distribution of syntactic dependency
distances, and unveil its relationship with short-term memory limitations. We
propose a new double-exponential model in which decay in probability is allowed
to change after a break-point. This transition could mirror the transition from
the processing of words chunks to higher-level structures. We find that a
two-regime model -- where the first regime follows either an exponential or a
power-law decay -- is the most likely one in all 20 languages we considered,
independently of sentence length and annotation style. Moreover, the
break-point is fairly stable across languages and averages values of 4-5 words,
suggesting that the amount of words that can be simultaneously processed
abstracts from the specific language to a high degree. Finally, we give an
account of the relation between the best estimated model and the closeness of
syntactic dependencies, as measured by a recently introduced optimality score."
Keyword Extraction from Short Texts with a Text-To-Text Transfer Transformer,0.093237,"The paper explores the relevance of the Text-To-Text Transfer Transformer
language model (T5) for Polish (plT5) to the task of intrinsic and extrinsic
keyword extraction from short text passages. The evaluation is carried out on
the new Polish Open Science Metadata Corpus (POSMAC), which is released with
this paper: a collection of 216,214 abstracts of scientific publications
compiled in the CURLICAT project. We compare the results obtained by four
different methods, i.e. plT5kw, extremeText, TermoPL, KeyBERT and conclude that
the plT5kw model yields particularly promising results for both frequent and
sparsely represented keywords. Furthermore, a plT5kw keyword generation model
trained on the POSMAC also seems to produce highly useful results in
cross-domain text labelling scenarios. We discuss the performance of the model
on news stories and phone-based dialog transcripts which represent text genres
and domains extrinsic to the dataset of scientific abstracts. Finally, we also
attempt to characterize the challenges of evaluating a text-to-text model on
both intrinsic and extrinsic keyword extraction."
A Better Choice: Entire-space Datasets for Aspect Sentiment Triplet Extraction,0.0191404,"Aspect sentiment triplet extraction (ASTE) aims to extract aspect term,
sentiment and opinion term triplets from sentences. Since the initial datasets
used to evaluate models on ASTE had flaws, several studies later corrected the
initial datasets and released new versions of the datasets independently. As a
result, different studies select different versions of datasets to evaluate
their methods, which makes ASTE-related works hard to follow. In this paper, we
analyze the relation between different versions of datasets and suggest that
the entire-space version should be used for ASTE. Besides the sentences
containing triplets and the triplets in the sentences, the entire-space version
additionally includes the sentences without triplets and the aspect terms which
do not belong to any triplets. Hence, the entire-space version is consistent
with real-world scenarios and evaluating models on the entire-space version can
better reflect the models' performance in real-world scenarios. In addition,
experimental results show that evaluating models on non-entire-space datasets
inflates the performance of existing models and models trained on the
entire-space version can obtain better performance."
PairReranker: Pairwise Reranking for Natural Language Generation,0.00779766,"Pre-trained language models have been successful in natural language
generation (NLG) tasks. While various decoding methods have been employed, they
often produce suboptimal results. We first present an empirical analysis of
three NLG tasks: summarization, machine translation, and constrained text
generation. We found that selecting the best output from the results of
multiple decoding methods can significantly improve performance. To further
improve reranking for NLG tasks, we proposed a novel method,
\textsc{PairReranker}, which uses a single encoder and a pairwise loss function
to jointly encode a source input and a pair of candidates and compare them.
Experiments on three NLG tasks demonstrated the effectiveness and flexibility
of \textsc{PairReranker}, showing strong results, compared with previous
baselines. In addition, our \textsc{PairReranker} can generalize to
significantly improve GPT-3 (text-davinci-003) results (e.g., 24.55\% on
CommonGen and 11.35\% on WMT18 zh-en), even though our rerankers are not
trained with any GPT-3 candidates."
Connecting Neural Response measurements & Computational Models of language: a non-comprehensive guide,0.103494,"Understanding the neural basis of language comprehension in the brain has
been a long-standing goal of various scientific research programs. Recent
advances in language modelling and in neuroimaging methodology promise
potential improvements in both the investigation of language's neurobiology and
in the building of better and more human-like language models. This survey
traces a line from early research linking Event Related Potentials and
complexity measures derived from simple language models to contemporary studies
employing Artificial Neural Network models trained on large corpora in
combination with neural response recordings from multiple modalities using
naturalistic stimuli."
A generative grammar of cooking,0.0,"Cooking is a uniquely human endeavor for transforming raw ingredients into
delicious dishes. Over centuries, cultures worldwide have evolved diverse
cooking practices ingrained in their culinary traditions. Recipes, thus, are
cultural capsules that capture culinary knowledge in elaborate cooking
protocols. While simple quantitative models have probed the patterns in recipe
composition and the process of cuisine evolution, unlike other cultural quirks
such as language, the principles of cooking remain hitherto unexplored. The
fundamental rules that drive the act of cooking, shaping recipe composition and
cuisine architecture, are unclear. Here we present a generative grammar of
cooking that captures the underlying culinary logic. By studying an extensive
repository of structured recipes, we identify core concepts and rules that
together forge a combinatorial system for culinary synthesis. Building on the
body of work done in the context of language, the demonstration of a logically
consistent generative framework offers profound insights into the act of
cooking. Given the central role of food in nutrition and lifestyle disorders,
culinary grammar provides leverage to improve public health through dietary
interventions beyond applications for creative pursuits such as novel recipe
generation."
Is it all a cluster game? -- Exploring Out-of-Distribution Detection based on Clustering in the Embedding Space,0.0438781,"It is essential for safety-critical applications of deep neural networks to
determine when new inputs are significantly different from the training
distribution. In this paper, we explore this out-of-distribution (OOD)
detection problem for image classification using clusters of semantically
similar embeddings of the training data and exploit the differences in distance
relationships to these clusters between in- and out-of-distribution data. We
study the structure and separation of clusters in the embedding space and find
that supervised contrastive learning leads to well-separated clusters while its
self-supervised counterpart fails to do so. In our extensive analysis of
different training methods, clustering strategies, distance metrics, and
thresholding approaches, we observe that there is no clear winner. The optimal
approach depends on the model architecture and selected datasets for in- and
out-of-distribution. While we could reproduce the outstanding results for
contrastive training on CIFAR-10 as in-distribution data, we find standard
cross-entropy paired with cosine similarity outperforms all contrastive
training methods when training on CIFAR-100 instead. Cross-entropy provides
competitive results as compared to expensive contrastive training methods."
TALCS: An Open-Source Mandarin-English Code-Switching Corpus and a Speech Recognition Baseline,0.0802702,"This paper introduces a new corpus of Mandarin-English code-switching speech
recognition--TALCS corpus, suitable for training and evaluating code-switching
speech recognition systems. TALCS corpus is derived from real online one-to-one
English teaching scenes in TAL education group, which contains roughly 587
hours of speech sampled at 16 kHz. To our best knowledge, TALCS corpus is the
largest well labeled Mandarin-English code-switching open source automatic
speech recognition (ASR) dataset in the world. In this paper, we will introduce
the recording procedure in detail, including audio capturing devices and corpus
environments. And the TALCS corpus is freely available for download under the
permissive license1. Using TALCS corpus, we conduct ASR experiments in two
popular speech recognition toolkits to make a baseline system, including ESPnet
and Wenet. The Mixture Error Rate (MER) performance in the two speech
recognition toolkits is compared in TALCS corpus. The experimental results
implies that the quality of audio recordings and transcriptions are promising
and the baseline system is workable."
A Context-Aware Feature Fusion Framework for Punctuation Restoration,0.0225962,"To accomplish the punctuation restoration task, most existing approaches
focused on leveraging extra information (e.g., part-of-speech tags) or
addressing the class imbalance problem. Recent works have widely applied the
transformer-based language models and significantly improved their
effectiveness. To the best of our knowledge, an inherent issue has remained
neglected: the attention of individual heads in the transformer will be diluted
or powerless while feeding the long non-punctuation utterances. Since those
previous contexts, not the followings, are comparatively more valuable to the
current position, it's hard to achieve a good balance by independent attention.
In this paper, we propose a novel Feature Fusion framework based on two-type
Attentions (FFA) to alleviate the shortage. It introduces a two-stream
architecture. One module involves interaction between attention heads to
encourage the communication, and another masked attention module captures the
dependent feature representation. Then, it aggregates two feature embeddings to
fuse information and enhances context-awareness. The experiments on the popular
benchmark dataset IWSLT demonstrate that our approach is effective. Without
additional data, it obtains comparable performance to the current
state-of-the-art models."
Consistency-based Self-supervised Learning for Temporal Anomaly Localization,0.0765198,"This work tackles Weakly Supervised Anomaly detection, in which a predictor
is allowed to learn not only from normal examples but also from a few labeled
anomalies made available during training. In particular, we deal with the
localization of anomalous activities within the video stream: this is a very
challenging scenario, as training examples come only with video-level
annotations (and not frame-level). Several recent works have proposed various
regularization terms to address it i.e. by enforcing sparsity and smoothness
constraints over the weakly-learned frame-level anomaly scores. In this work,
we get inspired by recent advances within the field of self-supervised learning
and ask the model to yield the same scores for different augmentations of the
same video sequence. We show that enforcing such an alignment improves the
performance of the model on XD-Violence."
Learning Discriminative Representations and Decision Boundaries for Open Intent Detection,0.100167,"Open intent detection is a significant problem in natural language
understanding, which aims to identify the unseen open intent while ensuring
known intent identification performance. However, current methods face two
major challenges. Firstly, they struggle to learn friendly representations to
detect the open intent with prior knowledge of only known intents. Secondly,
there is a lack of an effective approach to obtaining specific and compact
decision boundaries for known intents. To address these issues, this paper
presents an original framework called DA-ADB, which successively learns
distance-aware intent representations and adaptive decision boundaries for open
intent detection. Specifically, we first leverage distance information to
enhance the distinguishing capability of the intent representations. Then, we
design a novel loss function to obtain appropriate decision boundaries by
balancing both empirical and open space risks. Extensive experiments
demonstrate the effectiveness of the proposed distance-aware and boundary
learning strategies. Compared to state-of-the-art methods, our framework
achieves substantial improvements on three benchmark datasets. Furthermore, it
yields robust performance with varying proportions of labeled data and known
categories."
Evaluating Distributional Distortion in Neural Language Modeling,0.0826041,"A fundamental characteristic of natural language is the high rate at which
speakers produce novel expressions. Because of this novelty, a heavy-tail of
rare events accounts for a significant amount of the total probability mass of
distributions in language (Baayen, 2001). Standard language modeling metrics
such as perplexity quantify the performance of language models (LM) in
aggregate. As a result, we have relatively little understanding of whether
neural LMs accurately estimate the probability of sequences in this heavy-tail
of rare events. To address this gap, we develop a controlled evaluation scheme
which uses generative models trained on natural data as artificial languages
from which we can exactly compute sequence probabilities. Training LMs on
generations from these artificial languages, we compare the sequence-level
probability estimates given by LMs to the true probabilities in the target
language. Our experiments reveal that LSTM and Transformer language models (i)
systematically underestimate the probability of sequences drawn from the target
language, and (ii) do so more severely for less-probable sequences.
Investigating where this probability mass went, (iii) we find that LMs tend to
overestimate the probability of ill formed (perturbed) sequences. In addition,
we find that this underestimation behaviour (iv) is weakened, but not
eliminated by greater amounts of training data, and (v) is exacerbated for
target distributions with lower entropy."
Parallel Augmentation and Dual Enhancement for Occluded Person Re-identification,0.014145,"Occluded person re-identification (Re-ID), the task of searching for the same
person's images in occluded environments, has attracted lots of attention in
the past decades. Recent approaches concentrate on improving performance on
occluded data by data/feature augmentation or using extra models to predict
occlusions. However, they ignore the imbalance problem in this task and can not
fully utilize the information from the training data. To alleviate these two
issues, we propose a simple yet effective method with Parallel Augmentation and
Dual Enhancement (PADE), which is robust on both occluded and non-occluded data
and does not require any auxiliary clues. First, we design a parallel
augmentation mechanism (PAM) to generate more suitable occluded data to
mitigate the negative effects of unbalanced data. Second, we propose the global
and local dual enhancement strategy (DES) to promote the context information
and details. Experimental results on three widely used occluded datasets and
two non-occluded datasets validate the effectiveness of our method. The code is
available at
https://github.com/littleprince1121/PADE_Parallel_Augmentation_and_Dual_Enhancement_for_Occluded_Person_ReID"
PriorLane: A Prior Knowledge Enhanced Lane Detection Approach Based on Transformer,-1.0,"Lane detection is one of the fundamental modules in self-driving. In this
paper we employ a transformer-only method for lane detection, thus it could
benefit from the blooming development of fully vision transformer and achieve
the state-of-the-art (SOTA) performance on both CULane and TuSimple benchmarks,
by fine-tuning the weight fully pre-trained on large datasets. More
importantly, this paper proposes a novel and general framework called
PriorLane, which is used to enhance the segmentation performance of the fully
vision transformer by introducing the low-cost local prior knowledge.
Specifically, PriorLane utilizes an encoder-only transformer to fuse the
feature extracted by a pre-trained segmentation model with prior knowledge
embeddings. Note that a Knowledge Embedding Alignment (KEA) module is adapted
to enhance the fusion performance by aligning the knowledge embedding.
Extensive experiments on our Zjlab dataset show that PriorLane outperforms SOTA
lane detection methods by a 2.82% mIoU when prior knowledge is employed, and
the code will be released at: https://github.com/vincentqqb/PriorLane."
A new perspective on Digital Twins: Imparting intelligence and agency to entities,0.0418856,"Despite the Digital Twin (DT) concept being in the industry for a long time,
it remains ambiguous, unable to differentiate itself from information models,
general computing, and simulation technologies. Part of this confusion stems
from previous studies overlooking the DT's bidirectional nature, that enables
the shift of agency (delegating control) from humans to physical elements,
something that was not possible with earlier technologies. Thus, we present DTs
in a new light by viewing them as a means of imparting intelligence and agency
to entities, emphasizing that DTs are not just expert-centric tools but are
active systems that extend the capabilities of the entities being twinned. This
new perspective on DTs can help reduce confusion and humanize the concept by
starting discussions about how intelligent a DT should be, and its roles and
responsibilities, as well as setting a long-term direction for DTs."
RITA: Boost Driving Simulators with Realistic Interactive Traffic Flow,0.0401843,"High-quality traffic flow generation is the core module in building
simulators for autonomous driving. However, the majority of available
simulators are incapable of replicating traffic patterns that accurately
reflect the various features of real-world data while also simulating
human-like reactive responses to the tested autopilot driving strategies.
Taking one step forward to addressing such a problem, we propose Realistic
Interactive TrAffic flow (RITA) as an integrated component of existing driving
simulators to provide high-quality traffic flow for the evaluation and
optimization of the tested driving strategies. RITA is developed with
consideration of three key features, i.e., fidelity, diversity, and
controllability, and consists of two core modules called RITABackend and
RITAKit. RITABackend is built to support vehicle-wise control and provide
traffic generation models from real-world datasets, while RITAKit is developed
with easy-to-use interfaces for controllable traffic generation via
RITABackend. We demonstrate RITA's capacity to create diversified and
high-fidelity traffic simulations in several highly interactive highway
scenarios. The experimental findings demonstrate that our produced RITA traffic
flows exhibit all three key features, hence enhancing the completeness of
driving strategy evaluation. Moreover, we showcase the possibility for further
improvement of baseline strategies through online fine-tuning with RITA traffic
flows."
CINO: A Chinese Minority Pre-trained Language Model,0.7092,"Multilingual pre-trained language models have shown impressive performance on
cross-lingual tasks. It greatly facilitates the applications of natural
language processing on low-resource languages. However, there are still some
languages that the current multilingual models do not perform well on. In this
paper, we propose CINO (Chinese Minority Pre-trained Language Model), a
multilingual pre-trained language model for Chinese minority languages. It
covers Standard Chinese, Yue Chinese, and six other ethnic minority languages.
To evaluate the cross-lingual ability of the multilingual model on ethnic
minority languages, we collect documents from Wikipedia and news websites, and
construct two text classification datasets, WCM (Wiki-Chinese-Minority) and
CMNews (Chinese-Minority-News). We show that CINO notably outperforms the
baselines on various classification tasks. The CINO model and the datasets are
publicly available at http://cino.hfl-rc.com."
Bridging the Gap between Reality and Ideality of Entity Matching: A Revisiting and Benchmark Re-Construction,0.0683571,"Entity matching (EM) is the most critical step for entity resolution (ER).
While current deep learningbased methods achieve very impressive performance on
standard EM benchmarks, their realworld application performance is much
frustrating. In this paper, we highlight that such the gap between reality and
ideality stems from the unreasonable benchmark construction process, which is
inconsistent with the nature of entity matching and therefore leads to biased
evaluations of current EM approaches. To this end, we build a new EM corpus and
re-construct EM benchmarks to challenge critical assumptions implicit in the
previous benchmark construction process by step-wisely changing the restricted
entities, balanced labels, and single-modal records in previous benchmarks into
open entities, imbalanced labels, and multimodal records in an open
environment. Experimental results demonstrate that the assumptions made in the
previous benchmark construction process are not coincidental with the open
environment, which conceal the main challenges of the task and therefore
significantly overestimate the current progress of entity matching. The
constructed benchmarks and code are publicly released"
Controllable Text Generation with Neurally-Decomposed Oracle,0.138016,"We propose a general and efficient framework to control auto-regressive
generation models with NeurAlly-Decomposed Oracle (NADO). Given a pre-trained
base language model and a sequence-level boolean oracle function, we propose to
decompose the oracle function into token-level guidance to steer the base model
in text generation. Specifically, the token-level guidance is approximated by a
neural model trained with examples sampled from the base model, demanding no
additional auxiliary labeled data. Based on posterior regularization, we
present the closed-form optimal solution to incorporate the token-level
guidance into the base model for controllable generation. We further provide a
theoretical analysis of how the approximation quality of NADO affects the
controllable generation results. Experiments conducted on two applications: (1)
text generation with lexical constraints and (2) machine translation with
formality control demonstrate that our framework efficiently guides the base
model towards the given oracle while maintaining high generation quality."
Domain-Specific Text Generation for Machine Translation,0.171238,"Preservation of domain knowledge from the source to target is crucial in any
translation workflow. It is common in the translation industry to receive
highly specialized projects, where there is hardly any parallel in-domain data.
In such scenarios where there is insufficient in-domain data to fine-tune
Machine Translation (MT) models, producing translations that are consistent
with the relevant context is challenging. In this work, we propose a novel
approach to domain adaptation leveraging state-of-the-art pretrained language
models (LMs) for domain-specific data augmentation for MT, simulating the
domain characteristics of either (a) a small bilingual dataset, or (b) the
monolingual source text to be translated. Combining this idea with
back-translation, we can generate huge amounts of synthetic bilingual in-domain
data for both use cases. For our investigation, we use the state-of-the-art
Transformer architecture. We employ mixed fine-tuning to train models that
significantly improve translation of in-domain texts. More specifically, in
both scenarios, our proposed methods achieve improvements of approximately 5-6
BLEU and 2-3 BLEU, respectively, on the Arabic-to-English and English-to-Arabic
language pairs. Furthermore, the outcome of human evaluation corroborates the
automatic evaluation results."
A Feasibility Study on Image Inpainting for Non-cleft Lip Generation from Patients with Cleft Lip,0.036521,"A Cleft lip is a congenital abnormality requiring surgical repair by a
specialist. The surgeon must have extensive experience and theoretical
knowledge to perform surgery, and Artificial Intelligence (AI) method has been
proposed to guide surgeons in improving surgical outcomes. If AI can be used to
predict what a repaired cleft lip would look like, surgeons could use it as an
adjunct to adjust their surgical technique and improve results. To explore the
feasibility of this idea while protecting patient privacy, we propose a deep
learning-based image inpainting method that is capable of covering a cleft lip
and generating a lip and nose without a cleft. Our experiments are conducted on
two real-world cleft lip datasets and are assessed by expert cleft lip surgeons
to demonstrate the feasibility of the proposed method."
OTExtSum: Extractive Text Summarisation with Optimal Transport,0.864665,"Extractive text summarisation aims to select salient sentences from a
document to form a short yet informative summary. While learning-based methods
have achieved promising results, they have several limitations, such as
dependence on expensive training and lack of interpretability. Therefore, in
this paper, we propose a novel non-learning-based method by for the first time
formulating text summarisation as an Optimal Transport (OT) problem, namely
Optimal Transport Extractive Summariser (OTExtSum). Optimal sentence extraction
is conceptualised as obtaining an optimal summary that minimises the
transportation cost to a given document regarding their semantic distributions.
Such a cost is defined by the Wasserstein distance and used to measure the
summary's semantic coverage of the original document. Comprehensive experiments
on four challenging and widely used datasets - MultiNews, PubMed, BillSum, and
CNN/DM demonstrate that our proposed method outperforms the state-of-the-art
non-learning-based methods and several recent learning-based methods in terms
of the ROUGE metric."
Calibrate and Refine! A Novel and Agile Framework for ASR-error Robust Intent Detection,0.0487527,"The past ten years have witnessed the rapid development of text-based intent
detection, whose benchmark performances have already been taken to a remarkable
level by deep learning techniques. However, automatic speech recognition (ASR)
errors are inevitable in real-world applications due to the environment noise,
unique speech patterns and etc, leading to sharp performance drop in
state-of-the-art text-based intent detection models. Essentially, this
phenomenon is caused by the semantic drift brought by ASR errors and most
existing works tend to focus on designing new model structures to reduce its
impact, which is at the expense of versatility and flexibility. Different from
previous one-piece model, in this paper, we propose a novel and agile framework
called CR-ID for ASR error robust intent detection with two plug-and-play
modules, namely semantic drift calibration module (SDCM) and phonemic
refinement module (PRM), which are both model-agnostic and thus could be easily
integrated to any existing intent detection models without modifying their
structures. Experimental results on SNIPS dataset show that, our proposed CR-ID
framework achieves competitive performance and outperform all the baseline
methods on ASR outputs, which verifies that CR-ID can effectively alleviate the
semantic drift caused by ASR errors."
BEV-Locator: An End-to-end Visual Semantic Localization Network Using Multi-View Images,0.0979126,"Accurate localization ability is fundamental in autonomous driving.
Traditional visual localization frameworks approach the semantic map-matching
problem with geometric models, which rely on complex parameter tuning and thus
hinder large-scale deployment. In this paper, we propose BEV-Locator: an
end-to-end visual semantic localization neural network using multi-view camera
images. Specifically, a visual BEV (Birds-Eye-View) encoder extracts and
flattens the multi-view images into BEV space. While the semantic map features
are structurally embedded as map queries sequence. Then a cross-model
transformer associates the BEV features and semantic map queries. The
localization information of ego-car is recursively queried out by
cross-attention modules. Finally, the ego pose can be inferred by decoding the
transformer outputs. We evaluate the proposed method in large-scale nuScenes
and Qcraft datasets. The experimental results show that the BEV-locator is
capable to estimate the vehicle poses under versatile scenarios, which
effectively associates the cross-model information from multi-view images and
global semantic maps. The experiments report satisfactory accuracy with mean
absolute errors of 0.052m, 0.135m and 0.251$^\circ$ in lateral, longitudinal
translation and heading angle degree."
FRSUM: Towards Faithful Abstractive Summarization via Enhancing Factual Robustness,0.0250855,"Despite being able to generate fluent and grammatical text, current Seq2Seq
summarization models still suffering from the unfaithful generation problem. In
this paper, we study the faithfulness of existing systems from a new
perspective of factual robustness which is the ability to correctly generate
factual information over adversarial unfaithful information. We first measure a
model's factual robustness by its success rate to defend against adversarial
attacks when generating factual information. The factual robustness analysis on
a wide range of current systems shows its good consistency with human judgments
on faithfulness. Inspired by these findings, we propose to improve the
faithfulness of a model by enhancing its factual robustness. Specifically, we
propose a novel training strategy, namely FRSUM, which teaches the model to
defend against both explicit adversarial samples and implicit factual
adversarial perturbations. Extensive automatic and human evaluation results
show that FRSUM consistently improves the faithfulness of various Seq2Seq
models, such as T5, BART."
A Socially Assistive Robot using Automated Planning in a Paediatric Clinical Setting,0.0507477,"We present an ongoing project that aims to develop a social robot to help
children cope with painful and distressing medical procedures in a clinical
setting. Our approach uses automated planning as a core component for action
selection in order to generate plans that include physical, sensory, and social
actions for the robot to use when interacting with humans. A key capability of
our system is that the robot's behaviour adapts based on the affective state of
the child patient. The robot must operate in a challenging physical and social
environment where appropriate and safe interaction with children,
parents/caregivers, and healthcare professionals is crucial. In this paper, we
present our system, examine some of the key challenges of the scenario, and
describe how they are addressed by our system."
A hybrid quantum image edge detector for the NISQ era,0.0445732,"Edges are image locations where the gray value intensity changes suddenly.
They are among the most important features to understand and segment an image.
Edge detection is a standard task in digital image processing, solved for
example using filtering techniques. However, the amount of data to be processed
grows rapidly and pushes even supercomputers to their limits. Quantum computing
promises exponentially lower memory usage in terms of the number of qubits
compared to the number of classical bits. In this paper, we propose a hybrid
method for quantum edge detection based on the idea of a quantum artificial
neuron. Our method can be practically implemented on quantum computers,
especially on those of the current noisy intermediate-scale quantum era. We
compare six variants of the method to reduce the number of circuits and thus
the time required for the quantum edge detection. Taking advantage of the
scalability of our method, we can practically detect edges in images
considerably larger than reached before."
"Classification of multi-frequency RF signals by extreme learning, using magnetic tunnel junctions as neurons and synapses",0.0780593,"Extracting information from radiofrequency (RF) signals using artificial
neural networks at low energy cost is a critical need for a wide range of
applications from radars to health. These RF inputs are composed of multiples
frequencies. Here we show that magnetic tunnel junctions can process analogue
RF inputs with multiple frequencies in parallel and perform synaptic
operations. Using a backpropagation-free method called extreme learning, we
classify noisy images encoded by RF signals, using experimental data from
magnetic tunnel junctions functioning as both synapses and neurons. We achieve
the same accuracy as an equivalent software neural network. These results are a
key step for embedded radiofrequency artificial intelligence."
Decay No More: A Persistent Twitter Dataset for Learning Social Meaning,0.0253884,"With the proliferation of social media, many studies resort to social media
to construct datasets for developing social meaning understanding systems. For
the popular case of Twitter, most researchers distribute tweet IDs without the
actual text contents due to the data distribution policy of the platform. One
issue is that the posts become increasingly inaccessible over time, which leads
to unfair comparisons and a temporal bias in social media research. To
alleviate this challenge of data decay, we leverage a paraphrase model to
propose a new persistent English Twitter dataset for social meaning (PTSM).
PTSM consists of $17$ social meaning datasets in $10$ categories of tasks. We
experiment with two SOTA pre-trained language models and show that our PTSM can
substitute the actual tweets with paraphrases with marginal performance loss."
CoNFies: Controllable Neural Face Avatars,0.0619976,"Neural Radiance Fields (NeRF) are compelling techniques for modeling dynamic
3D scenes from 2D image collections. These volumetric representations would be
well suited for synthesizing novel facial expressions but for two problems.
First, deformable NeRFs are object agnostic and model holistic movement of the
scene: they can replay how the motion changes over time, but they cannot alter
it in an interpretable way. Second, controllable volumetric representations
typically require either time-consuming manual annotations or 3D supervision to
provide semantic meaning to the scene. We propose a controllable neural
representation for face self-portraits (CoNFies), that solves both of these
problems within a common framework, and it can rely on automated processing. We
use automated facial action recognition (AFAR) to characterize facial
expressions as a combination of action units (AU) and their intensities. AUs
provide both the semantic locations and control labels for the system. CoNFies
outperformed competing methods for novel view and expression synthesis in terms
of visual and anatomic fidelity of expressions."
Generalizability of Adversarial Robustness Under Distribution Shifts,0.0127137,"Recent progress in empirical and certified robustness promises to deliver
reliable and deployable Deep Neural Networks (DNNs). Despite that success, most
existing evaluations of DNN robustness have been done on images sampled from
the same distribution on which the model was trained. However, in the real
world, DNNs may be deployed in dynamic environments that exhibit significant
distribution shifts. In this work, we take a first step towards thoroughly
investigating the interplay between empirical and certified adversarial
robustness on one hand and domain generalization on another. To do so, we train
robust models on multiple domains and evaluate their accuracy and robustness on
an unseen domain. We observe that: (1) both empirical and certified robustness
generalize to unseen domains, and (2) the level of generalizability does not
correlate well with input visual similarity, measured by the FID between source
and target domains. We also extend our study to cover a real-world medical
application, in which adversarial augmentation significantly boosts the
generalization of robustness with minimal effect on clean data accuracy."
Mukayese: Turkish NLP Strikes Back,0.118667,"Having sufficient resources for language X lifts it from the under-resourced
languages class, but not necessarily from the under-researched class. In this
paper, we address the problem of the absence of organized benchmarks in the
Turkish language. We demonstrate that languages such as Turkish are left behind
the state-of-the-art in NLP applications. As a solution, we present Mukayese, a
set of NLP benchmarks for the Turkish language that contains several NLP tasks.
We work on one or more datasets for each benchmark and present two or more
baselines. Moreover, we present four new benchmarking datasets in Turkish for
language modeling, sentence segmentation, and spell checking. All datasets and
baselines are available under: https://github.com/alisafaya/mukayese"
What AI can do for horse-racing ?,0.0657076,"Since the 1980s, machine learning has been widely used for horse-racing
predictions, gradually expanding to where algorithms are now playing a huge
role in the betting market. Machine learning has changed the horse-racing
betting market over the last ten years, but main changes are still to come. The
paradigm shift of neural networks (deep learning) may not only improve our
ability to simply predict the outcome of a race, but it will also certainly
shake our entire way of thinking about horse-racing - and maybe more generally
about horses. Since 2012, deep learning provided more and more state-of-the-art
results in computer vision and now statistical learning or game theory. We
describe how the convergence of the three machine learning fields (computer
vision, statistical learning, and game theory) will be game-changers in the
next decade in our ability to predict and understand horse-racing. We consider
that horse-racing is a real world laboratory where we can work on the
animal-human interaction and build a non-anthropocentric Artificial
Intelligence. We believe that this will lead us to understand the horses better
and the interactions between animals and humans in general."
Do LSTMs See Gender? Probing the Ability of LSTMs to Learn Abstract Syntactic Rules,0.0484405,"LSTMs trained on next-word prediction can accurately perform linguistic tasks
that require tracking long-distance syntactic dependencies. Notably, model
accuracy approaches human performance on number agreement tasks (Gulordava et
al., 2018). However, we do not have a mechanistic understanding of how LSTMs
perform such linguistic tasks. Do LSTMs learn abstract grammatical rules, or do
they rely on simple heuristics? Here, we test gender agreement in French which
requires tracking both hierarchical syntactic structures and the inherent
gender of lexical units. Our model is able to reliably predict long-distance
gender agreement in two subject-predicate contexts: noun-adjective and
noun-passive-verb agreement. The model showed more inaccuracies on plural noun
phrases with gender attractors compared to singular cases, suggesting a
reliance on clues from gendered articles for agreement. Overall, our study
highlights key ways in which LSTMs deviate from human behaviour and questions
whether LSTMs genuinely learn abstract syntactic rules and categories. We
propose using gender agreement as a useful probe to investigate the underlying
mechanisms, internal representations, and linguistic capabilities of LSTM
language models."
Abstraction not Memory: BERT and the English Article System,0.127225,"Article prediction is a task that has long defied accurate linguistic
description. As such, this task is ideally suited to evaluate models on their
ability to emulate native-speaker intuition. To this end, we compare the
performance of native English speakers and pre-trained models on the task of
article prediction set up as a three way choice (a/an, the, zero). Our
experiments with BERT show that BERT outperforms humans on this task across all
articles. In particular, BERT is far superior to humans at detecting the zero
article, possibly because we insert them using rules that the deep neural model
can easily pick up. More interestingly, we find that BERT tends to agree more
with annotators than with the corpus when inter-annotator agreement is high but
switches to agreeing more with the corpus as inter-annotator agreement drops.
We contend that this alignment with annotators, despite being trained on the
corpus, suggests that BERT is not memorising article use, but captures a high
level generalisation of article use akin to human intuition."
SHREC 2022 Track on Online Detection of Heterogeneous Gestures,0.0820067,"This paper presents the outcomes of a contest organized to evaluate methods
for the online recognition of heterogeneous gestures from sequences of 3D hand
poses. The task is the detection of gestures belonging to a dictionary of 16
classes characterized by different pose and motion features. The dataset
features continuous sequences of hand tracking data where the gestures are
interleaved with non-significant motions. The data have been captured using the
Hololens 2 finger tracking system in a realistic use-case of mixed reality
interaction. The evaluation is based not only on the detection performances but
also on the latency and the false positives, making it possible to understand
the feasibility of practical interaction tools based on the algorithms
proposed. The outcomes of the contest's evaluation demonstrate the necessity of
further research to reduce recognition errors, while the computational cost of
the algorithms proposed is sufficiently low."
Computational Metacognition,0.079913,"Computational metacognition represents a cognitive systems perspective on
high-order reasoning in integrated artificial systems that seeks to leverage
ideas from human metacognition and from metareasoning approaches in artificial
intelligence. The key characteristic is to declaratively represent and then
monitor traces of cognitive activity in an intelligent system in order to
manage the performance of cognition itself. Improvements in cognition then lead
to improvements in behavior and thus performance. We illustrate these concepts
with an agent implementation in a cognitive architecture called MIDCA and show
the value of metacognition in problem-solving. The results illustrate how
computational metacognition improves performance by changing cognition through
meta-level goal operations and learning."
Continual Variational Autoencoder Learning via Online Cooperative Memorization,0.0879991,"Due to their inference, data representation and reconstruction properties,
Variational Autoencoders (VAE) have been successfully used in continual
learning classification tasks. However, their ability to generate images with
specifications corresponding to the classes and databases learned during
Continual Learning (CL) is not well understood and catastrophic forgetting
remains a significant challenge. In this paper, we firstly analyze the
forgetting behaviour of VAEs by developing a new theoretical framework that
formulates CL as a dynamic optimal transport problem. This framework proves
approximate bounds to the data likelihood without requiring the task
information and explains how the prior knowledge is lost during the training
process. We then propose a novel memory buffering approach, namely the Online
Cooperative Memorization (OCM) framework, which consists of a Short-Term Memory
(STM) that continually stores recent samples to provide future information for
the model, and a Long-Term Memory (LTM) aiming to preserve a wide diversity of
samples. The proposed OCM transfers certain samples from STM to LTM according
to the information diversity selection criterion without requiring any
supervised signals. The OCM framework is then combined with a dynamic VAE
expansion mixture network for further enhancing its performance."
Zero-shot Commonsense Question Answering with Cloze Translation and Consistency Optimization,0.219227,"Commonsense question answering (CQA) aims to test if models can answer
questions regarding commonsense knowledge that everyone knows. Prior works that
incorporate external knowledge bases have shown promising results, but
knowledge bases are expensive to construct and are often limited to a fixed set
of relations. In this paper, we instead focus on better utilizing the
\textit{implicit knowledge} stored in pre-trained language models. While
researchers have found that the knowledge embedded in pre-trained language
models can be extracted by having them fill in the blanks of carefully designed
prompts for relation extraction and text classification, it remains unclear if
we can adopt this paradigm in CQA where the inputs and outputs take much more
flexible forms. To this end, we investigate four translation methods that can
translate natural questions into cloze-style sentences to better solicit
commonsense knowledge from language models, including a syntactic-based model,
an unsupervised neural model, and two supervised neural models. In addition, to
combine the different translation methods, we propose to encourage consistency
among model predictions on different translated questions with unlabeled data.
We demonstrate the effectiveness of our methods on three CQA datasets in
zero-shot settings. We show that our methods are complementary to a knowledge
base improved model, and combining them can lead to state-of-the-art zero-shot
performance. Analyses also reveal distinct characteristics of the different
cloze translation methods and provide insights on why combining them can lead
to great improvements."
Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning,0.0833668,"There is a rising interest in further exploring the zero-shot learning
potential of large pre-trained language models (PLMs). A new paradigm called
data-generation-based zero-shot learning has achieved impressive success. In
this paradigm, the synthesized data from the PLM acts as the carrier of
knowledge, which is used to train a task-specific model with orders of
magnitude fewer parameters than the PLM, achieving both higher performance and
efficiency than prompt-based zero-shot learning methods on PLMs. The main
hurdle of this approach is that the synthesized data from PLM usually contains
a significant portion of low-quality samples. Fitting on such data will greatly
hamper the performance of the task-specific model, making it unreliable for
deployment. Previous methods remedy this issue mainly by filtering synthetic
data using heuristic metrics(e.g., output confidence), or refining the data
with the help of a human expert, which comes with excessive manual tuning or
expensive costs. In this paper, we propose a novel noise-robust re-weighting
framework SunGen to automatically construct high-quality data for zero-shot
classification problems. Our framework features the ability to learn the sample
weights indicating data quality without requiring any human annotation. We
theoretically and empirically verify the ability of our method to help
construct good-quality synthetic datasets. Notably, SunGen-LSTM yields a 9.8%
relative improvement than the baseline on average accuracy across eight
different established text classification tasks."
Coloring the Blank Slate: Pre-training Imparts a Hierarchical Inductive Bias to Sequence-to-sequence Models,0.034561,"Relations between words are governed by hierarchical structure rather than
linear ordering. Sequence-to-sequence (seq2seq) models, despite their success
in downstream NLP applications, often fail to generalize in a
hierarchy-sensitive manner when performing syntactic transformations - for
example, transforming declarative sentences into questions. However, syntactic
evaluations of seq2seq models have only observed models that were not
pre-trained on natural language data before being trained to perform syntactic
transformations, in spite of the fact that pre-training has been found to
induce hierarchical linguistic generalizations in language models; in other
words, the syntactic capabilities of seq2seq models may have been greatly
understated. We address this gap using the pre-trained seq2seq models T5 and
BART, as well as their multilingual variants mT5 and mBART. We evaluate whether
they generalize hierarchically on two transformations in two languages:
question formation and passivization in English and German. We find that
pre-trained seq2seq models generalize hierarchically when performing syntactic
transformations, whereas models trained from scratch on syntactic
transformations do not. This result presents evidence for the learnability of
hierarchical syntactic information from non-annotated natural language text
while also demonstrating that seq2seq models are capable of syntactic
generalization, though only after exposure to much more language data than
human learners receive."
The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory,0.0102106,"We describe the first steps in the development of an artificial agent focused
on the Brazilian maritime territory, a large region within the South Atlantic
also known as the Blue Amazon. The ""BLue Amazon Brain"" (BLAB) integrates a
number of services aimed at disseminating information about this region and its
importance, functioning as a tool for environmental awareness. The main service
provided by BLAB is a conversational facility that deals with complex questions
about the Blue Amazon, called BLAB-Chat; its central component is a controller
that manages several task-oriented natural language processing modules (e.g.,
question answering and summarizer systems). These modules have access to an
internal data lake as well as to third-party databases. A news reporter
(BLAB-Reporter) and a purposely-developed wiki (BLAB-Wiki) are also part of the
BLAB service architecture. In this paper, we describe our current version of
BLAB's architecture (interface, backend, web services, NLP modules, and
resources) and comment on the challenges we have faced so far, such as the lack
of training data and the scattered state of domain information. Solving these
issues presents a considerable challenge in the development of artificial
intelligence for technical domains."
Leveraging Pre-Trained Language Models to Streamline Natural Language Interaction for Self-Tracking,0.0778225,"Current natural language interaction for self-tracking tools largely depends
on bespoke implementation optimized for a specific tracking theme and data
format, which is neither generalizable nor scalable to a tremendous design
space of self-tracking. However, training machine learning models in the
context of self-tracking is challenging due to the wide variety of tracking
topics and data formats. In this paper, we propose a novel NLP task for
self-tracking that extracts close- and open-ended information from a
retrospective activity log described as a plain text, and a domain-agnostic,
GPT-3-based NLU framework that performs this task. The framework augments the
prompt using synthetic samples to transform the task into 10-shot learning, to
address a cold-start problem in bootstrapping a new tracking topic. Our
preliminary evaluation suggests that our approach significantly outperforms the
baseline QA models. Going further, we discuss future application domains toward
which the NLP and HCI researchers can collaborate."
EventGraph: Event Extraction as Semantic Graph Parsing,0.313955,"Event extraction involves the detection and extraction of both the event
triggers and corresponding event arguments. Existing systems often decompose
event extraction into multiple subtasks, without considering their possible
interactions. In this paper, we propose EventGraph, a joint framework for event
extraction, which encodes events as graphs. We represent event triggers and
arguments as nodes in a semantic graph. Event extraction therefore becomes a
graph parsing problem, which provides the following advantages: 1) performing
event detection and argument extraction jointly; 2) detecting and extracting
multiple events from a piece of text; and 3) capturing the complicated
interaction between event arguments and triggers. Experimental results on
ACE2005 show that our model is competitive to state-of-the-art systems and has
substantially improved the results on argument extraction. Additionally, we
create two new datasets from ACE2005 where we keep the entire text spans for
event arguments, instead of just the head word(s). Our code and models are
released as open-source."
CP-ViT: Cascade Vision Transformer Pruning via Progressive Sparsity Prediction,0.0732,"Vision transformer (ViT) has achieved competitive accuracy on a variety of
computer vision applications, but its computational cost impedes the deployment
on resource-limited mobile devices.
  We explore the sparsity in ViT and observe that informative patches and heads
are sufficient for accurate image recognition.
  In this paper, we propose a cascade pruning framework named CP-ViT by
predicting sparsity in ViT models progressively and dynamically to reduce
computational redundancy while minimizing the accuracy loss. Specifically, we
define the cumulative score to reserve the informative patches and heads across
the ViT model for better accuracy. We also propose the dynamic pruning ratio
adjustment technique based on layer-aware attention range. CP-ViT has great
general applicability for practical deployment, which can be applied to a wide
range of ViT models and can achieve superior accuracy with or without
fine-tuning.
  Extensive experiments on ImageNet, CIFAR-10, and CIFAR-100 with various
pre-trained models have demonstrated the effectiveness and efficiency of
CP-ViT. By progressively pruning 50\% patches, our CP-ViT method reduces over
40\% FLOPs while maintaining accuracy loss within 1\%."
NELA-GT-2022: A Large Multi-Labelled News Dataset for The Study of Misinformation in News Articles,0.0129939,"In this paper, we present the fifth installment of the NELA-GT datasets,
NELA-GT-2022. The dataset contains 1,778,361 articles from 361 outlets between
January 1st, 2022 and December 31st, 2022. Just as in past releases of the
dataset, NELA-GT-2022 includes outlet-level veracity labels from Media
Bias/Fact Check and tweets embedded in collected news articles. The
NELA-GT-2022 dataset can be found at: https://doi.org/10.7910/DVN/AMCV2H"
Perturbation Learning Based Anomaly Detection,0.0650518,"This paper presents a simple yet effective method for anomaly detection. The
main idea is to learn small perturbations to perturb normal data and learn a
classifier to classify the normal data and the perturbed data into two
different classes. The perturbator and classifier are jointly learned using
deep neural networks. Importantly, the perturbations should be as small as
possible but the classifier is still able to recognize the perturbed data from
unperturbed data. Therefore, the perturbed data are regarded as abnormal data
and the classifier provides a decision boundary between the normal data and
abnormal data, although the training data do not include any abnormal data.
Compared with the state-of-the-art of anomaly detection, our method does not
require any assumption about the shape (e.g. hypersphere) of the decision
boundary and has fewer hyper-parameters to determine. Empirical studies on
benchmark datasets verify the effectiveness and superiority of our method."
Beyond Plain Toxic: Detection of Inappropriate Statements on Flammable Topics for the Russian Language,0.0153678,"Toxicity on the Internet, such as hate speech, offenses towards particular
users or groups of people, or the use of obscene words, is an acknowledged
problem. However, there also exist other types of inappropriate messages which
are usually not viewed as toxic, e.g. as they do not contain explicit offences.
Such messages can contain covered toxicity or generalizations, incite harmful
actions (crime, suicide, drug use), provoke ""heated"" discussions. Such messages
are often related to particular sensitive topics, e.g. on politics, sexual
minorities, social injustice which more often than other topics, e.g. cars or
computing, yield toxic emotional reactions. At the same time, clearly not all
messages within such flammable topics are inappropriate.
  Towards this end, in this work, we present two text collections labelled
according to binary notion of inapropriateness and a multinomial notion of
sensitive topic. Assuming that the notion of inappropriateness is common among
people of the same culture, we base our approach on human intuitive
understanding of what is not acceptable and harmful. To objectivise the notion
of inappropriateness, we define it in a data-driven way though crowdsourcing.
Namely we run a large-scale annotation study asking workers if a given chatbot
textual statement could harm reputation of a company created it. Acceptably
high values of inter-annotator agreement suggest that the notion of
inappropriateness exists and can be uniformly understood by different people.
To define the notion of sensitive topics in an objective way we use on
guidelines suggested commonly by specialists of legal and PR department of a
large public company as potentially harmful."
Towards Tracing Factual Knowledge in Language Models Back to the Training Data,0.0614466,"Language models (LMs) have been shown to memorize a great deal of factual
knowledge contained in their training data. But when an LM generates an
assertion, it is often difficult to determine where it learned this information
and whether it is true. In this paper, we propose the problem of fact tracing:
identifying which training examples taught an LM to generate a particular
factual assertion. Prior work on training data attribution (TDA) may offer
effective tools for identifying such examples, known as ""proponents"". We
present the first quantitative benchmark to evaluate this. We compare two
popular families of TDA methods -- gradient-based and embedding-based -- and
find that much headroom remains. For example, both methods have lower
proponent-retrieval precision than an information retrieval baseline (BM25)
that does not have access to the LM at all. We identify key challenges that may
be necessary for further improvement such as overcoming the problem of gradient
saturation, and also show how several nuanced implementation details of
existing neural TDA methods can significantly improve overall fact tracing
performance."
Refining neural network predictions using background knowledge,0.0225432,"Recent work has shown logical background knowledge can be used in learning
systems to compensate for a lack of labeled training data. Many methods work by
creating a loss function that encodes this knowledge. However, often the logic
is discarded after training, even if it is still useful at test time. Instead,
we ensure neural network predictions satisfy the knowledge by refining the
predictions with an extra computation step. We introduce differentiable
refinement functions that find a corrected prediction close to the original
prediction. We study how to effectively and efficiently compute these
refinement functions. Using a new algorithm called Iterative Local Refinement
(ILR), we combine refinement functions to find refined predictions for logical
formulas of any complexity. ILR finds refinements on complex SAT formulas in
significantly fewer iterations and frequently finds solutions where gradient
descent can not. Finally, ILR produces competitive results in the MNIST
addition task."
Using Large Language Models to Generate Engaging Captions for Data Visualizations,0.0449548,"Creating compelling captions for data visualizations has been a longstanding
challenge. Visualization researchers are typically untrained in journalistic
reporting and hence the captions that are placed below data visualizations tend
to be not overly engaging and rather just stick to basic observations about the
data. In this work we explore the opportunities offered by the newly emerging
crop of large language models (LLM) which use sophisticated deep learning
technology to produce human-like prose. We ask, can these powerful software
devices be purposed to produce engaging captions for generic data
visualizations like a scatterplot. It turns out that the key challenge lies in
designing the most effective prompt for the LLM, a task called prompt
engineering. We report on first experiments using the popular LLM GPT-3 and
deliver some promising results."
Learning crop type mapping from regional label proportions in large-scale SAR and optical imagery,0.0381785,"The application of deep learning algorithms to Earth observation (EO) in
recent years has enabled substantial progress in fields that rely on remotely
sensed data. However, given the data scale in EO, creating large datasets with
pixel-level annotations by experts is expensive and highly time-consuming. In
this context, priors are seen as an attractive way to alleviate the burden of
manual labeling when training deep learning methods for EO. For some
applications, those priors are readily available. Motivated by the great
success of contrastive-learning methods for self-supervised feature
representation learning in many computer-vision tasks, this study proposes an
online deep clustering method using crop label proportions as priors to learn a
sample-level classifier based on government crop-proportion data for a whole
agricultural region. We evaluate the method using two large datasets from two
different agricultural regions in Brazil. Extensive experiments demonstrate
that the method is robust to different data types (synthetic-aperture radar and
optical images), reporting higher accuracy values considering the major crop
types in the target regions. Thus, it can alleviate the burden of large-scale
image annotation in EO applications."
End-to-End Speech to Intent Prediction to improve E-commerce Customer Support Voicebot in Hindi and English,0.0417622,"Automation of on-call customer support relies heavily on accurate and
efficient speech-to-intent (S2I) systems. Building such systems using
multi-component pipelines can pose various challenges because they require
large annotated datasets, have higher latency, and have complex deployment.
These pipelines are also prone to compounding errors. To overcome these
challenges, we discuss an end-to-end (E2E) S2I model for customer support
voicebot task in a bilingual setting. We show how we can solve E2E intent
classification by leveraging a pre-trained automatic speech recognition (ASR)
model with slight modification and fine-tuning on small annotated datasets.
Experimental results show that our best E2E model outperforms a conventional
pipeline by a relative ~27% on the F1 score."
Exposure Correction Model to Enhance Image Quality,0.0332694,"Exposure errors in an image cause a degradation in the contrast and low
visibility in the content. In this paper, we address this problem and propose
an end-to-end exposure correction model in order to handle both under- and
overexposure errors with a single model. Our model contains an image encoder,
consecutive residual blocks, and image decoder to synthesize the corrected
image. We utilize perceptual loss, feature matching loss, and multi-scale
discriminator to increase the quality of the generated image as well as to make
the training more stable. The experimental results indicate the effectiveness
of proposed model. We achieve the state-of-the-art result on a large-scale
exposure dataset. Besides, we investigate the effect of exposure setting of the
image on the portrait matting task. We find that under- and overexposed images
cause severe degradation in the performance of the portrait matting models. We
show that after applying exposure correction with the proposed model, the
portrait matting quality increases significantly.
https://github.com/yamand16/ExposureCorrection"
Unsupervised Boundary-Aware Language Model Pretraining for Chinese Sequence Labeling,0.0279651,"Boundary information is critical for various Chinese language processing
tasks, such as word segmentation, part-of-speech tagging, and named entity
recognition. Previous studies usually resorted to the use of a high-quality
external lexicon, where lexicon items can offer explicit boundary information.
However, to ensure the quality of the lexicon, great human effort is always
necessary, which has been generally ignored. In this work, we suggest
unsupervised statistical boundary information instead, and propose an
architecture to encode the information directly into pre-trained language
models, resulting in Boundary-Aware BERT (BABERT). We apply BABERT for feature
induction of Chinese sequence labeling tasks. Experimental results on ten
benchmarks of Chinese sequence labeling demonstrate that BABERT can provide
consistent improvements on all datasets. In addition, our method can complement
previous supervised lexicon exploration, where further improvements can be
achieved when integrated with external lexicon information."
Compositional Generalisation with Structured Reordering and Fertility Layers,0.167307,"Seq2seq models have been shown to struggle with compositional generalisation,
i.e. generalising to new and potentially more complex structures than seen
during training. Taking inspiration from grammar-based models that excel at
compositional generalisation, we present a flexible end-to-end differentiable
neural model that composes two structural operations: a fertility step, which
we introduce in this work, and a reordering step based on previous work (Wang
et al., 2021). To ensure differentiability, we use the expected value of each
step. Our model outperforms seq2seq models by a wide margin on challenging
compositional splits of realistic semantic parsing tasks that require
generalisation to longer examples. It also compares favourably to other models
targeting compositional generalisation."
Improving ProtoNet for Few-Shot Video Object Recognition: Winner of ORBIT Challenge 2022,0.334039,"In this work, we present the winning solution for ORBIT Few-Shot Video Object
Recognition Challenge 2022. Built upon the ProtoNet baseline, the performance
of our method is improved with three effective techniques. These techniques
include the embedding adaptation, the uniform video clip sampler and the
invalid frame detection. In addition, we re-factor and re-implement the
official codebase to encourage modularity, compatibility and improved
performance. Our implementation accelerates the data loading in both training
and testing."
Lexical Generalization Improves with Larger Models and Longer Training,0.0470754,"While fine-tuned language models perform well on many tasks, they were also
shown to rely on superficial surface features such as lexical overlap.
Excessive utilization of such heuristics can lead to failure on challenging
inputs. We analyze the use of lexical overlap heuristics in natural language
inference, paraphrase detection, and reading comprehension (using a novel
contrastive dataset), and find that larger models are much less susceptible to
adopting lexical overlap heuristics. We also find that longer training leads
models to abandon lexical overlap heuristics. Finally, we provide evidence that
the disparity between models size has its source in the pre-trained model"
On the Role of Field of View for Occlusion Removal with Airborne Optical Sectioning,0.0810318,"Occlusion caused by vegetation is an essential problem for remote sensing
applications in areas, such as search and rescue, wildfire detection, wildlife
observation, surveillance, border control, and others. Airborne Optical
Sectioning (AOS) is an optical, wavelength-independent synthetic aperture
imaging technique that supports computational occlusion removal in real-time.
It can be applied with manned or unmanned aircrafts, such as drones. In this
article, we demonstrate a relationship between forest density and field of view
(FOV) of applied imaging systems. This finding was made with the help of a
simulated procedural forest model which offers the consideration of more
realistic occlusion properties than our previous statistical model. While AOS
has been explored with automatic and autonomous research prototypes in the
past, we present a free AOS integration for DJI systems. It enables bluelight
organizations and others to use and explore AOS with compatible, manually
operated, off-the-shelf drones. The (digitally cropped) default FOV for this
implementation was chosen based on our new finding."
COVID-19-related Nepali Tweets Classification in a Low Resource Setting,0.0239332,"Billions of people across the globe have been using social media platforms in
their local languages to voice their opinions about the various topics related
to the COVID-19 pandemic. Several organizations, including the World Health
Organization, have developed automated social media analysis tools that
classify COVID-19-related tweets into various topics. However, these tools that
help combat the pandemic are limited to very few languages, making several
countries unable to take their benefit. While multi-lingual or low-resource
language-specific tools are being developed, they still need to expand their
coverage, such as for the Nepali language. In this paper, we identify the eight
most common COVID-19 discussion topics among the Twitter community using the
Nepali language, set up an online platform to automatically gather Nepali
tweets containing the COVID-19-related keywords, classify the tweets into the
eight topics, and visualize the results across the period in a web-based
dashboard. We compare the performance of two state-of-the-art multi-lingual
language models for Nepali tweet classification, one generic (mBERT) and the
other Nepali language family-specific model (MuRIL). Our results show that the
models' relative performance depends on the data size, with MuRIL doing better
for a larger dataset. The annotated data, models, and the web-based dashboard
are open-sourced at https://github.com/naamiinepal/covid-tweet-classification."
Context based lemmatizer for Polish language,0.0207285,"Lemmatization is the process of grouping together the inflected forms of a
word so they can be analysed as a single item, identified by the word's lemma,
or dictionary form. In computational linguistics, lemmatisation is the
algorithmic process of determining the lemma of a word based on its intended
meaning. Unlike stemming, lemmatisation depends on correctly identifying the
intended part of speech and meaning of a word in a sentence, as well as within
the larger context surrounding that sentence. As a result, developing efficient
lemmatisation algorithm is the complex task. In recent years it can be observed
that deep learning models used for this task outperform other methods including
machine learning algorithms. In this paper the polish lemmatizer based on
Google T5 model is presented. The training was run with different context
lengths. The model achieves the best results for polish language lemmatisation
process."
"Improving Depression estimation from facial videos with face alignment, training optimization and scheduling",0.0360217,"Deep learning models have shown promising results in recognizing depressive
states using video-based facial expressions. While successful models typically
leverage using 3D-CNNs or video distillation techniques, the different use of
pretraining, data augmentation, preprocessing, and optimization techniques
across experiments makes it difficult to make fair architectural comparisons.
We propose instead to enhance two simple models based on ResNet-50 that use
only static spatial information by using two specific face alignment methods
and improved data augmentation, optimization, and scheduling techniques. Our
extensive experiments on benchmark datasets obtain similar results to
sophisticated spatio-temporal models for single streams, while the score-level
fusion of two different streams outperforms state-of-the-art methods. Our
findings suggest that specific modifications in the preprocessing and training
process result in noticeable differences in the performance of the models and
could hide the actual originally attributed to the use of different neural
network architectures."
Fusing Frame and Event Vision for High-speed Optical Flow for Edge Application,0.0379038,"Optical flow computation with frame-based cameras provides high accuracy but
the speed is limited either by the model size of the algorithm or by the frame
rate of the camera. This makes it inadequate for high-speed applications. Event
cameras provide continuous asynchronous event streams overcoming the frame-rate
limitation. However, the algorithms for processing the data either borrow frame
like setup limiting the speed or suffer from lower accuracy. We fuse the
complementary accuracy and speed advantages of the frame and event-based
pipelines to provide high-speed optical flow while maintaining a low error
rate. Our bio-mimetic network is validated with the MVSEC dataset showing 19%
error degradation at 4x speed up. We then demonstrate the system with a
high-speed drone flight scenario where a high-speed event camera computes the
flow even before the optical camera sees the drone making it suited for
applications like tracking and segmentation. This work shows the fundamental
trade-offs in frame-based processing may be overcome by fusing data from other
modalities."
Reduce Catastrophic Forgetting of Dense Retrieval Training with Teleportation Negatives,0.046665,"In this paper, we investigate the instability in the standard dense retrieval
training, which iterates between model training and hard negative selection
using the being-trained model. We show the catastrophic forgetting phenomena
behind the training instability, where models learn and forget different
negative groups during training iterations. We then propose ANCE-Tele, which
accumulates momentum negatives from past iterations and approximates future
iterations using lookahead negatives, as ""teleportations"" along the time axis
to smooth the learning process. On web search and OpenQA, ANCE-Tele outperforms
previous state-of-the-art systems of similar size, eliminates the dependency on
sparse retrieval negatives, and is competitive among systems using
significantly more (50x) parameters. Our analysis demonstrates that
teleportation negatives reduce catastrophic forgetting and improve convergence
speed for dense retrieval training. Our code is available at
https://github.com/OpenMatch/ANCE-Tele."
A Psychological Theory of Explainability,0.00729494,"The goal of explainable Artificial Intelligence (XAI) is to generate
human-interpretable explanations, but there are no computationally precise
theories of how humans interpret AI generated explanations. The lack of theory
means that validation of XAI must be done empirically, on a case-by-case basis,
which prevents systematic theory-building in XAI. We propose a psychological
theory of how humans draw conclusions from saliency maps, the most common form
of XAI explanation, which for the first time allows for precise prediction of
explainee inference conditioned on explanation. Our theory posits that absent
explanation humans expect the AI to make similar decisions to themselves, and
that they interpret an explanation by comparison to the explanations they
themselves would give. Comparison is formalized via Shepard's universal law of
generalization in a similarity space, a classic theory from cognitive science.
A pre-registered user study on AI image classifications with saliency map
explanations demonstrate that our theory quantitatively matches participants'
predictions of the AI."
Detecting Context-Aware Deviations in Process Executions,0.0196007,"A deviation detection aims to detect deviating process instances, e.g.,
patients in the healthcare process and products in the manufacturing process. A
business process of an organization is executed in various contextual
situations, e.g., a COVID-19 pandemic in the case of hospitals and a lack of
semiconductor chip shortage in the case of automobile companies. Thus,
context-aware deviation detection is essential to provide relevant insights.
However, existing work 1) does not provide a systematic way of incorporating
various contexts, 2) is tailored to a specific approach without using an
extensive pool of existing deviation detection techniques, and 3) does not
distinguish positive and negative contexts that justify and refute deviation,
respectively. In this work, we provide a framework to bridge the aforementioned
gaps. We have implemented the proposed framework as a web service that can be
extended to various contexts and deviation detection methods. We have evaluated
the effectiveness of the proposed framework by conducting experiments using 255
different contextual scenarios."
Semantic features of object concepts generated with GPT-3,0.0278394,"Semantic features have been playing a central role in investigating the
nature of our conceptual representations. Yet the enormous time and effort
required to empirically sample and norm features from human raters has
restricted their use to a limited set of manually curated concepts. Given
recent promising developments with transformer-based language models, here we
asked whether it was possible to use such models to automatically generate
meaningful lists of properties for arbitrary object concepts and whether these
models would produce features similar to those found in humans. To this end, we
probed a GPT-3 model to generate semantic features for 1,854 objects and
compared automatically-generated features to existing human feature norms.
GPT-3 generated many more features than humans, yet showed a similar
distribution in the types of generated features. Generated feature norms
rivaled human norms in predicting similarity, relatedness, and category
membership, while variance partitioning demonstrated that these predictions
were driven by similar variance in humans and GPT-3. Together, these results
highlight the potential of large language models to capture important facets of
human knowledge and yield a new approach for automatically generating
interpretable feature sets, thus drastically expanding the potential use of
semantic features in psychological and linguistic studies."
Optimizing Fiducial Marker Placement for Improved Visual Localization,0.0230314,"Adding fiducial markers to a scene is a well-known strategy for making visual
localization algorithms more robust. Traditionally, these marker locations are
selected by humans who are familiar with visual localization techniques. This
paper explores the problem of automatic marker placement within a scene.
Specifically, given a predetermined set of markers and a scene model, we
compute optimized marker positions within the scene that can improve accuracy
in visual localization. Our main contribution is a novel framework for modeling
camera localizability that incorporates both natural scene features and
artificial fiducial markers added to the scene. We present optimized marker
placement (OMP), a greedy algorithm that is based on the camera localizability
framework. We have also designed a simulation framework for testing marker
placement algorithms on 3D models and images generated from synthetic scenes.
We have evaluated OMP within this testbed and demonstrate an improvement in the
localization rate by up to 20 percent on four different scenes."
E2PN: Efficient SE(3)-Equivariant Point Network,0.0964818,"This paper proposes a convolution structure for learning SE(3)-equivariant
features from 3D point clouds. It can be viewed as an equivariant version of
kernel point convolutions (KPConv), a widely used convolution form to process
point cloud data. Compared with existing equivariant networks, our design is
simple, lightweight, fast, and easy to be integrated with existing
task-specific point cloud learning pipelines. We achieve these desirable
properties by combining group convolutions and quotient representations.
Specifically, we discretize SO(3) to finite groups for their simplicity while
using SO(2) as the stabilizer subgroup to form spherical quotient feature
fields to save computations. We also propose a permutation layer to recover
SO(3) features from spherical features to preserve the capacity to distinguish
rotations. Experiments show that our method achieves comparable or superior
performance in various tasks, including object classification, pose estimation,
and keypoint-matching, while consuming much less memory and running faster than
existing work. The proposed method can foster the development of equivariant
models for real-world applications based on point clouds."
The COVID That Wasn't: Counterfactual Journalism Using GPT,0.0158641,"In this paper, we explore the use of large language models to assess human
interpretations of real world events. To do so, we use a language model trained
prior to 2020 to artificially generate news articles concerning COVID-19 given
the headlines of actual articles written during the pandemic. We then compare
stylistic qualities of our artificially generated corpus with a news corpus, in
this case 5,082 articles produced by CBC News between January 23 and May 5,
2020. We find our artificially generated articles exhibits a considerably more
negative attitude towards COVID and a significantly lower reliance on
geopolitical framing. Our methods and results hold importance for researchers
seeking to simulate large scale cultural processes via recent breakthroughs in
text generation."
Feature Overcorrelation in Deep Graph Neural Networks: A New Perspective,0.0167307,"Recent years have witnessed remarkable success achieved by graph neural
networks (GNNs) in many real-world applications such as recommendation and drug
discovery. Despite the success, oversmoothing has been identified as one of the
key issues which limit the performance of deep GNNs. It indicates that the
learned node representations are highly indistinguishable due to the stacked
aggregators. In this paper, we propose a new perspective to look at the
performance degradation of deep GNNs, i.e., feature overcorrelation. Through
empirical and theoretical study on this matter, we demonstrate the existence of
feature overcorrelation in deeper GNNs and reveal potential reasons leading to
this issue. To reduce the feature correlation, we propose a general framework
DeCorr which can encourage GNNs to encode less redundant information. Extensive
experiments have demonstrated that DeCorr can help enable deeper GNNs and is
complementary to existing techniques tackling the oversmoothing issue."
AbductionRules: Training Transformers to Explain Unexpected Inputs,0.281833,"Transformers have recently been shown to be capable of reliably performing
logical reasoning over facts and rules expressed in natural language, but
abductive reasoning - inference to the best explanation of an unexpected
observation - has been underexplored despite significant applications to
scientific discovery, common-sense reasoning, and model interpretability.
  We present AbductionRules, a group of natural language datasets designed to
train and test generalisable abduction over natural-language knowledge bases.
We use these datasets to finetune pretrained Transformers and discuss their
performance, finding that our models learned generalisable abductive techniques
but also learned to exploit the structure of our data. Finally, we discuss the
viability of this approach to abductive reasoning and ways in which it may be
improved in future work."
A Realism Metric for Generated LiDAR Point Clouds,0.0318383,"A considerable amount of research is concerned with the generation of
realistic sensor data. LiDAR point clouds are generated by complex simulations
or learned generative models. The generated data is usually exploited to enable
or improve downstream perception algorithms. Two major questions arise from
these procedures: First, how to evaluate the realism of the generated data?
Second, does more realistic data also lead to better perception performance?
This paper addresses both questions and presents a novel metric to quantify the
realism of LiDAR point clouds. Relevant features are learned from real-world
and synthetic point clouds by training on a proxy classification task. In a
series of experiments, we demonstrate the application of our metric to
determine the realism of generated LiDAR data and compare the realism
estimation of our metric to the performance of a segmentation model. We confirm
that our metric provides an indication for the downstream segmentation
performance."
Black-Box Attack against GAN-Generated Image Detector with Contrastive Perturbation,0.0200531,"Visually realistic GAN-generated facial images raise obvious concerns on
potential misuse. Many effective forensic algorithms have been developed to
detect such synthetic images in recent years. It is significant to assess the
vulnerability of such forensic detectors against adversarial attacks. In this
paper, we propose a new black-box attack method against GAN-generated image
detectors. A novel contrastive learning strategy is adopted to train the
encoder-decoder network based anti-forensic model under a contrastive loss
function. GAN images and their simulated real counterparts are constructed as
positive and negative samples, respectively. Leveraging on the trained attack
model, imperceptible contrastive perturbation could be applied to input
synthetic images for removing GAN fingerprint to some extent. As such, existing
GAN-generated image detectors are expected to be deceived. Extensive
experimental results verify that the proposed attack effectively reduces the
accuracy of three state-of-the-art detectors on six popular GANs. High visual
quality of the attacked images is also achieved. The source code will be
available at https://github.com/ZXMMD/BAttGAND."
Anytime Capacity Expansion in Medical Residency Match by Monte Carlo Tree Search,0.103709,"This paper considers the capacity expansion problem in two-sided matchings,
where the policymaker is allowed to allocate some extra seats as well as the
standard seats. In medical residency match, each hospital accepts a limited
number of doctors. Such capacity constraints are typically given in advance.
However, such exogenous constraints can compromise the welfare of the doctors;
some popular hospitals inevitably dismiss some of their favorite doctors.
Meanwhile, it is often the case that the hospitals are also benefited to accept
a few extra doctors. To tackle the problem, we propose an anytime method that
the upper confidence tree searches the space of capacity expansions, each of
which has a resident-optimal stable assignment that the deferred acceptance
method finds. Constructing a good search tree representation significantly
boosts the performance of the proposed method. Our simulation shows that the
proposed method identifies an almost optimal capacity expansion with a
significantly smaller computational budget than exact methods based on
mixed-integer programming."
Migrating Face Swap to Mobile Devices: A lightweight Framework and A Supervised Training Solution,-1.0,"Existing face swap methods rely heavily on large-scale networks for adequate
capacity to generate visually plausible results, which inhibits its
applications on resource-constraint platforms. In this work, we propose
MobileFSGAN, a novel lightweight GAN for face swap that can run on mobile
devices with much fewer parameters while achieving competitive performance. A
lightweight encoder-decoder structure is designed especially for image
synthesis tasks, which is only 10.2MB and can run on mobile devices at a
real-time speed. To tackle the unstability of training such a small network, we
construct the FSTriplets dataset utilizing facial attribute editing techniques.
FSTriplets provides source-target-result training triplets, yielding
pixel-level labels thus for the first time making the training process
supervised. We also designed multi-scale gradient losses for efficient
back-propagation, resulting in faster and better convergence. Experimental
results show that our model reaches comparable performance towards
state-of-the-art methods, while significantly reducing the number of network
parameters. Codes and the dataset have been released."
Towards Uniform Point Distribution in Feature-preserving Point Cloud Filtering,0.209351,"As a popular representation of 3D data, point cloud may contain noise and
need to be filtered before use. Existing point cloud filtering methods either
cannot preserve sharp features or result in uneven point distribution in the
filtered output. To address this problem, this paper introduces a point cloud
filtering method that considers both point distribution and feature
preservation during filtering. The key idea is to incorporate a repulsion term
with a data term in energy minimization. The repulsion term is responsible for
the point distribution, while the data term is to approximate the noisy
surfaces while preserving the geometric features. This method is capable of
handling models with fine-scale features and sharp features. Extensive
experiments show that our method yields better results with a more uniform
point distribution ($5.8\times10^{-5}$ Chamfer Distance on average) in seconds."
On-device Synaptic Memory Consolidation using Fowler-Nordheim Quantum-tunneling,0.154869,"Synaptic memory consolidation has been heralded as one of the key mechanisms
for supporting continual learning in neuromorphic Artificial Intelligence (AI)
systems. Here we report that a Fowler-Nordheim (FN) quantum-tunneling device
can implement synaptic memory consolidation similar to what can be achieved by
algorithmic consolidation models like the cascade and the elastic weight
consolidation (EWC) models. The proposed FN-synapse not only stores the
synaptic weight but also stores the synapse's historical usage statistic on the
device itself. We also show that the operation of the FN-synapse is
near-optimal in terms of the synaptic lifetime and we demonstrate that a
network comprising FN-synapses outperforms a comparable EWC network for a small
benchmark continual learning task. With an energy footprint of femtojoules per
synaptic update, we believe that the proposed FN-synapse provides an
ultra-energy-efficient approach for implementing both synaptic memory
consolidation and persistent learning."
Optical Flow Training under Limited Label Budget via Active Learning,0.019029,"Supervised training of optical flow predictors generally yields better
accuracy than unsupervised training. However, the improved performance comes at
an often high annotation cost. Semi-supervised training trades off accuracy
against annotation cost. We use a simple yet effective semi-supervised training
method to show that even a small fraction of labels can improve flow accuracy
by a significant margin over unsupervised training. In addition, we propose
active learning methods based on simple heuristics to further reduce the number
of labels required to achieve the same target accuracy. Our experiments on both
synthetic and real optical flow datasets show that our semi-supervised networks
generally need around 50% of the labels to achieve close to full-label
accuracy, and only around 20% with active learning on Sintel. We also analyze
and show insights on the factors that may influence active learning
performance. Code is available at
https://github.com/duke-vision/optical-flow-active-learning-release."
Jacobian Computation for Cumulative B-Splines on SE(3) and Application to Continuous-Time Object Tracking,0.0693218,"In this paper we propose a method that estimates the $SE(3)$ continuous
trajectories (orientation and translation) of the dynamic rigid objects present
in a scene, from multiple RGB-D views. Specifically, we fit the object
trajectories to cumulative B-Splines curves, which allow us to interpolate, at
any intermediate time stamp, not only their poses but also their linear and
angular velocities and accelerations. Additionally, we derive in this work the
analytical $SE(3)$ Jacobians needed by the optimization, being applicable to
any other approach that uses this type of curves. To the best of our knowledge
this is the first work that proposes 6-DoF continuous-time object tracking,
which we endorse with significant computational cost reduction thanks to our
analytical derivations. We evaluate our proposal in synthetic data and in a
public benchmark, showing competitive results in localization and significant
improvements in velocity estimation in comparison to discrete-time approaches."
Can Foundation Models Talk Causality?,0.030088,"Foundation models are subject to an ongoing heated debate, leaving open the
question of progress towards AGI and dividing the community into two camps: the
ones who see the arguably impressive results as evidence to the scaling
hypothesis, and the others who are worried about the lack of interpretability
and reasoning capabilities. By investigating to which extent causal
representations might be captured by these large scale language models, we make
a humble efforts towards resolving the ongoing philosophical conflicts."
SiRi: A Simple Selective Retraining Mechanism for Transformer-based Visual Grounding,0.256158,"In this paper, we investigate how to achieve better visual grounding with
modern vision-language transformers, and propose a simple yet powerful
Selective Retraining (SiRi) mechanism for this challenging task. Particularly,
SiRi conveys a significant principle to the research of visual grounding, i.e.,
a better initialized vision-language encoder would help the model converge to a
better local minimum, advancing the performance accordingly. In specific, we
continually update the parameters of the encoder as the training goes on, while
periodically re-initialize rest of the parameters to compel the model to be
better optimized based on an enhanced encoder. SiRi can significantly
outperform previous approaches on three popular benchmarks. Specifically, our
method achieves 83.04% Top1 accuracy on RefCOCO+ testA, outperforming the
state-of-the-art approaches (training from scratch) by more than 10.21%.
Additionally, we reveal that SiRi performs surprisingly superior even with
limited training data. We also extend it to transformer-based visual grounding
models and other vision-language tasks to verify the validity."
Instance-based Learning for Knowledge Base Completion,0.0620527,"In this paper, we propose a new method for knowledge base completion (KBC):
instance-based learning (IBL). For example, to answer (Jill Biden, lived city,?
), instead of going directly to Washington D.C., our goal is to find Joe Biden,
who has the same lived city as Jill Biden. Through prototype entities, IBL
provides interpretability. We develop theories for modeling prototypes and
combining IBL with translational models. Experiments on various tasks confirmed
the IBL model's effectiveness and interpretability.
  In addition, IBL shed light on the mechanism of rule-based KBC models.
Previous research has generally agreed that rule-based models provide rules
with semantically compatible premises and hypotheses. We challenge this view.
We begin by demonstrating that some logical rules represent {\it instance-based
equivalence} (i.e. prototypes) rather than semantic compatibility. These are
denoted as {\it IBL rules}. Surprisingly, despite occupying only a small
portion of the rule space, IBL rules outperform non-IBL rules in all four
benchmarks. We use a variety of experiments to demonstrate that rule-based
models work because they have the ability to represent instance-based
equivalence via IBL rules. The findings provide new insights of how rule-based
models work and how to interpret their rules."
Deep Reinforcement Learning for Multi-class Imbalanced Training,0.028321,"With the rapid growth of memory and computing power, datasets are becoming
increasingly complex and imbalanced. This is especially severe in the context
of clinical data, where there may be one rare event for many cases in the
majority class. We introduce an imbalanced classification framework, based on
reinforcement learning, for training extremely imbalanced data sets, and extend
it for use in multi-class settings. We combine dueling and double deep
Q-learning architectures, and formulate a custom reward function and
episode-training procedure, specifically with the added capability of handling
multi-class imbalanced training. Using real-world clinical case studies, we
demonstrate that our proposed framework outperforms current state-of-the-art
imbalanced learning methods, achieving more fair and balanced classification,
while also significantly improving the prediction of minority classes."
Deep Learning-based Facial Appearance Simulation Driven by Surgically Planned Craniomaxillofacial Bony Movement,0.0229279,"Simulating facial appearance change following bony movement is a critical
step in orthognathic surgical planning for patients with jaw deformities.
Conventional biomechanics-based methods such as the finite-element method (FEM)
are labor intensive and computationally inefficient. Deep learning-based
approaches can be promising alternatives due to their high computational
efficiency and strong modeling capability. However, the existing deep
learning-based method ignores the physical correspondence between facial soft
tissue and bony segments and thus is significantly less accurate compared to
FEM. In this work, we propose an Attentive Correspondence assisted Movement
Transformation network (ACMT-Net) to estimate the facial appearance by
transforming the bony movement to facial soft tissue through a point-to-point
attentive correspondence matrix. Experimental results on patients with jaw
deformity show that our proposed method can achieve comparable facial change
prediction accuracy compared with the state-of-the-art FEM-based approach with
significantly improved computational efficiency."
Channel Pruned YOLOv5-based Deep Learning Approach for Rapid and Accurate Outdoor Obstacles Detection,0.042631,"One-stage algorithm have been widely used in target detection systems that
need to be trained with massive data. Most of them perform well both in
real-time and accuracy. However, due to their convolutional structure, they
need more computing power and greater memory consumption. Hence, we applied
pruning strategy to target detection networks to reduce the number of
parameters and the size of model. To demonstrate the practicality of the
pruning method, we select the YOLOv5 model for experiments and provide a data
set of outdoor obstacles to show the effect of model. In this specific data
set, in the best circumstances, the volume of the network model is reduced by
49.7% compared with the original model, and the reasoning time is reduced by
52.5%. Meanwhile, it also uses data processing methods to compensate for the
drop in accuracy caused by pruning."
DrugEHRQA: A Question Answering Dataset on Structured and Unstructured Electronic Health Records For Medicine Related Queries,-1.0,"This paper develops the first question answering dataset (DrugEHRQA)
containing question-answer pairs from both structured tables and unstructured
notes from a publicly available Electronic Health Record (EHR). EHRs contain
patient records, stored in structured tables and unstructured clinical notes.
The information in structured and unstructured EHRs is not strictly disjoint:
information may be duplicated, contradictory, or provide additional context
between these sources. Our dataset has medication-related queries, containing
over 70,000 question-answer pairs. To provide a baseline model and help analyze
the dataset, we have used a simple model (MultimodalEHRQA) which uses the
predictions of a modality selection network to choose between EHR tables and
clinical notes to answer the questions. This is used to direct the questions to
the table-based or text-based state-of-the-art QA model. In order to address
the problem arising from complex, nested queries, this is the first time
Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers (RAT-SQL)
has been used to test the structure of query templates in EHR data. Our goal is
to provide a benchmark dataset for multi-modal QA systems, and to open up new
avenues of research in improving question answering over EHR structured data by
using context from unstructured clinical data."
Detecting the Role of an Entity in Harmful Memes: Techniques and Their Limitations,0.0579402,"Harmful or abusive online content has been increasing over time, raising
concerns for social media platforms, government agencies, and policymakers.
Such harmful or abusive content can have major negative impact on society,
e.g., cyberbullying can lead to suicides, rumors about COVID-19 can cause
vaccine hesitance, promotion of fake cures for COVID-19 can cause health harms
and deaths. The content that is posted and shared online can be textual,
visual, or a combination of both, e.g., in a meme. Here, we describe our
experiments in detecting the roles of the entities (hero, villain, victim) in
harmful memes, which is part of the CONSTRAINT-2022 shared task, as well as our
system for the task. We further provide a comparative analysis of different
experimental settings (i.e., unimodal, multimodal, attention, and
augmentation). For reproducibility, we make our experimental code publicly
available. \url{https://github.com/robi56/harmful_memes_block_fusion}"
Learning Entity Linking Features for Emerging Entities,0.0147139,"Entity linking (EL) is the process of linking entity mentions appearing in
text with their corresponding entities in a knowledge base. EL features of
entities (e.g., prior probability, relatedness score, and entity embedding) are
usually estimated based on Wikipedia. However, for newly emerging entities
(EEs) which have just been discovered in news, they may still not be included
in Wikipedia yet. As a consequence, it is unable to obtain required EL features
for those EEs from Wikipedia and EL models will always fail to link ambiguous
mentions with those EEs correctly as the absence of their EL features. To deal
with this problem, in this paper we focus on a new task of learning EL features
for emerging entities in a general way. We propose a novel approach called
STAMO to learn high-quality EL features for EEs automatically, which needs just
a small number of labeled documents for each EE collected from the Web, as it
could further leverage the knowledge hidden in the unlabeled data. STAMO is
mainly based on self-training, which makes it flexibly integrated with any EL
feature or EL model, but also makes it easily suffer from the error
reinforcement problem caused by the mislabeled data. Instead of some common
self-training strategies that try to throw the mislabeled data away explicitly,
we regard self-training as a multiple optimization process with respect to the
EL features of EEs, and propose both intra-slot and inter-slot optimizations to
alleviate the error reinforcement problem implicitly. We construct two EL
datasets involving selected EEs to evaluate the quality of obtained EL features
for EEs, and the experimental results show that our approach significantly
outperforms other baseline methods of learning EL features."
Fair Group-Shared Representations with Normalizing Flows,0.0565808,"The issue of fairness in machine learning stems from the fact that historical
data often displays biases against specific groups of people which have been
underprivileged in the recent past, or still are. In this context, one of the
possible approaches is to employ fair representation learning algorithms which
are able to remove biases from data, making groups statistically
indistinguishable. In this paper, we instead develop a fair representation
learning algorithm which is able to map individuals belonging to different
groups in a single group. This is made possible by training a pair of
Normalizing Flow models and constraining them to not remove information about
the ground truth by training a ranking or classification model on top of them.
The overall, ``chained'' model is invertible and has a tractable Jacobian,
which allows to relate together the probability densities for different groups
and ``translate'' individuals from one group to another. We show experimentally
that our methodology is competitive with other fair representation learning
algorithms. Furthermore, our algorithm achieves stronger invariance w.r.t. the
sensitive attribute."
Contrastive Learning for Online Semi-Supervised General Continual Learning,0.00872201,"We study Online Continual Learning with missing labels and propose SemiCon, a
new contrastive loss designed for partly labeled data. We demonstrate its
efficiency by devising a memory-based method trained on an unlabeled data
stream, where every data added to memory is labeled using an oracle. Our
approach outperforms existing semi-supervised methods when few labels are
available, and obtain similar results to state-of-the-art supervised methods
while using only 2.6% of labels on Split-CIFAR10 and 10% of labels on
Split-CIFAR100."
Prompt Compression and Contrastive Conditioning for Controllability and Toxicity Reduction in Language Models,0.578328,"We explore the idea of compressing the prompts used to condition language
models, and show that compressed prompts can retain a substantive amount of
information about the original prompt. For severely compressed prompts, while
fine-grained information is lost, abstract information and general sentiments
can be retained with surprisingly few parameters, which can be useful in the
context of decode-time algorithms for controllability and toxicity reduction.
We explore contrastive conditioning to steer language model generation towards
desirable text and away from undesirable text, and find that some complex
prompts can be effectively compressed into a single token to guide generation.
We also show that compressed prompts are largely compositional, and can be
constructed such that they can be used to control independent aspects of
generated text."
Adaptive Risk-Tendency: Nano Drone Navigation in Cluttered Environments with Distributional Reinforcement Learning,0.0579554,"Enabling the capability of assessing risk and making risk-aware decisions is
essential to applying reinforcement learning to safety-critical robots like
drones. In this paper, we investigate a specific case where a nano quadcopter
robot learns to navigate an apriori-unknown cluttered environment under partial
observability. We present a distributional reinforcement learning framework to
generate adaptive risk-tendency policies. Specifically, we propose to use lower
tail conditional variance of the learnt return distribution as intrinsic
uncertainty estimation, and use exponentially weighted average forecasting
(EWAF) to adapt the risk-tendency in accordance with the estimated uncertainty.
In simulation and real-world empirical results, we show that (1) the most
effective risk-tendency vary across states, (2) the agent with adaptive
risk-tendency achieves superior performance compared to risk-neutral policy or
risk-averse policy baselines."
Learning English with Peppa Pig,0.170098,"Recent computational models of the acquisition of spoken language via
grounding in perception exploit associations between the spoken and visual
modalities and learn to represent speech and visual data in a joint vector
space. A major unresolved issue from the point of ecological validity is the
training data, typically consisting of images or videos paired with spoken
descriptions of what is depicted. Such a setup guarantees an unrealistically
strong correlation between speech and the visual data. In the real world the
coupling between the linguistic and the visual modality is loose, and often
confounded by correlations with non-semantic aspects of the speech signal. Here
we address this shortcoming by using a dataset based on the children's cartoon
Peppa Pig. We train a simple bi-modal architecture on the portion of the data
consisting of dialog between characters, and evaluate on segments containing
descriptive narrations. Despite the weak and confounded signal in this training
data our model succeeds at learning aspects of the visual semantics of spoken
language."
PoseGU: 3D Human Pose Estimation with Novel Human Pose Generator and Unbiased Learning,-1.0,"3D pose estimation has recently gained substantial interests in computer
vision domain. Existing 3D pose estimation methods have a strong reliance on
large size well-annotated 3D pose datasets, and they suffer poor model
generalization on unseen poses due to limited diversity of 3D poses in training
sets. In this work, we propose PoseGU, a novel human pose generator that
generates diverse poses with access only to a small size of seed samples, while
equipping the Counterfactual Risk Minimization to pursue an unbiased evaluation
objective. Extensive experiments demonstrate PoseGU outforms almost all the
state-of-the-art 3D human pose methods under consideration over three popular
benchmark datasets. Empirical analysis also proves PoseGU generates 3D poses
with improved data diversity and better generalization ability."
Multi-View Reasoning: Consistent Contrastive Learning for Math Word Problem,0.0825292,"Math word problem solver requires both precise relation reasoning about
quantities in the text and reliable generation for the diverse equation.
Current sequence-to-tree or relation extraction methods regard this only from a
fixed view, struggling to simultaneously handle complex semantics and diverse
equations. However, human solving naturally involves two consistent reasoning
views: top-down and bottom-up, just as math equations also can be expressed in
multiple equivalent forms: pre-order and post-order. We propose a multi-view
consistent contrastive learning for a more complete semantics-to-equation
mapping. The entire process is decoupled into two independent but consistent
views: top-down decomposition and bottom-up construction, and the two reasoning
views are aligned in multi-granularity for consistency, enhancing global
generation and precise reasoning. Experiments on multiple datasets across two
languages show our approach significantly outperforms the existing baselines,
especially on complex problems. We also show after consistent alignment,
multi-view can absorb the merits of both views and generate more diverse
results consistent with the mathematical laws."
Automatic Severity Classification of Dysarthric speech by using Self-supervised Model with Multi-task Learning,0.0426828,"Automatic assessment of dysarthric speech is essential for sustained
treatments and rehabilitation. However, obtaining atypical speech is
challenging, often leading to data scarcity issues. To tackle the problem, we
propose a novel automatic severity assessment method for dysarthric speech,
using the self-supervised model in conjunction with multi-task learning.
Wav2vec 2.0 XLS-R is jointly trained for two different tasks: severity
classification and auxiliary automatic speech recognition (ASR). For the
baseline experiments, we employ hand-crafted acoustic features and machine
learning classifiers such as SVM, MLP, and XGBoost. Explored on the Korean
dysarthric speech QoLT database, our model outperforms the traditional baseline
methods, with a relative percentage increase of 1.25% for F1-score. In
addition, the proposed model surpasses the model trained without ASR head,
achieving 10.61% relative percentage improvements. Furthermore, we present how
multi-task learning affects the severity classification performance by
analyzing the latent representations and regularization effect."
A Reference Data Model for Process-Related User Interaction Logs,0.1161,"User interaction (UI) logs are high-resolution event logs that record
low-level activities performed by a user during the execution of a task in an
information system. Each event in a UI log corresponds to a single interaction
between the user and the interface, such as clicking a button or entering a
string into a text field. UI logs are used for purposes like task mining or
robotic process automation (RPA), but each study and tool relies on a different
conceptualization and implementation of the elements and attributes that
constitute user interactions. This lack of standardization makes it difficult
to integrate UI logs from different sources and to combine tools for UI data
collection with downstream analytics or automation solutions. To address this,
we propose a universally applicable reference data model for process-related UI
logs. Based on a review of scientific literature and industry solutions, this
model includes the core attributes of UI logs, but remains flexible with regard
to the scope, level of abstraction, and case notion. We provide an
implementation of the model as an extension to the XES interchange standard for
event logs and demonstrate its practical applicability in a real-life RPA
scenario."
Semiconductor Defect Pattern Classification by Self-Proliferation-and-Attention Neural Network,0.0740846,"Semiconductor manufacturing is on the cusp of a revolution: the Internet of
Things (IoT). With IoT we can connect all the equipment and feed information
back to the factory so that quality issues can be detected. In this situation,
more and more edge devices are used in wafer inspection equipment. This edge
device must have the ability to quickly detect defects. Therefore, how to
develop a high-efficiency architecture for automatic defect classification to
be suitable for edge devices is the primary task. In this paper, we present a
novel architecture that can perform defect classification in a more efficient
way. The first function is self-proliferation, using a series of linear
transformations to generate more feature maps at a cheaper cost. The second
function is self-attention, capturing the long-range dependencies of feature
map by the channel-wise and spatial-wise attention mechanism. We named this
method as self-proliferation-and-attention neural network. This method has been
successfully applied to various defect pattern classification tasks. Compared
with other latest methods, SP&A-Net has higher accuracy and lower computation
cost in many defect inspection tasks."
Learning Visual Explanations for DCNN-Based Image Classifiers Using an Attention Mechanism,0.0101659,"In this paper two new learning-based eXplainable AI (XAI) methods for deep
convolutional neural network (DCNN) image classifiers, called L-CAM-Fm and
L-CAM-Img, are proposed. Both methods use an attention mechanism that is
inserted in the original (frozen) DCNN and is trained to derive class
activation maps (CAMs) from the last convolutional layer's feature maps. During
training, CAMs are applied to the feature maps (L-CAM-Fm) or the input image
(L-CAM-Img) forcing the attention mechanism to learn the image regions
explaining the DCNN's outcome. Experimental evaluation on ImageNet shows that
the proposed methods achieve competitive results while requiring a single
forward pass at the inference stage. Moreover, based on the derived
explanations a comprehensive qualitative analysis is performed providing
valuable insight for understanding the reasons behind classification errors,
including possible dataset biases affecting the trained classifier."
RWT-SLAM: Robust Visual SLAM for Highly Weak-textured Environments,0.0210986,"As a fundamental task for intelligent robots, visual SLAM has made great
progress over the past decades. However, robust SLAM under highly weak-textured
environments still remains very challenging. In this paper, we propose a novel
visual SLAM system named RWT-SLAM to tackle this problem. We modify LoFTR
network which is able to produce dense point matching under low-textured scenes
to generate feature descriptors. To integrate the new features into the popular
ORB-SLAM framework, we develop feature masks to filter out the unreliable
features and employ KNN strategy to strengthen the matching robustness. We also
retrained visual vocabulary upon new descriptors for efficient loop closing.
The resulting RWT-SLAM is tested in various public datasets such as TUM and
OpenLORIS, as well as our own data. The results shows very promising
performance under highly weak-textured environments."
Benchmark datasets driving artificial intelligence development fail to capture the needs of medical professionals,0.05609,"Publicly accessible benchmarks that allow for assessing and comparing model
performances are important drivers of progress in artificial intelligence (AI).
While recent advances in AI capabilities hold the potential to transform
medical practice by assisting and augmenting the cognitive processes of
healthcare professionals, the coverage of clinically relevant tasks by AI
benchmarks is largely unclear. Furthermore, there is a lack of systematized
meta-information that allows clinical AI researchers to quickly determine
accessibility, scope, content and other characteristics of datasets and
benchmark datasets relevant to the clinical domain.
  To address these issues, we curated and released a comprehensive catalogue of
datasets and benchmarks pertaining to the broad domain of clinical and
biomedical natural language processing (NLP), based on a systematic review of
literature and online resources. A total of 450 NLP datasets were manually
systematized and annotated with rich metadata, such as targeted tasks, clinical
applicability, data types, performance metrics, accessibility and licensing
information, and availability of data splits. We then compared tasks covered by
AI benchmark datasets with relevant tasks that medical practitioners reported
as highly desirable targets for automation in a previous empirical study.
  Our analysis indicates that AI benchmarks of direct clinical relevance are
scarce and fail to cover most work activities that clinicians want to see
addressed. In particular, tasks associated with routine documentation and
patient data administration workflows are not represented despite significant
associated workloads. Thus, currently available AI benchmarks are improperly
aligned with desired targets for AI automation in clinical settings, and novel
benchmarks should be created to fill these gaps."
Mathematical Cookbook for Snapshot Compressive Imaging,0.0734141,"The author intends to provide you with a beautiful, elegant, user-friendly
cookbook for mathematics in Snapshot Compressive Imaging (SCI). Currently, the
cookbook is composed of introduction, conventional optimization, and deep
equilibrium models. The latest releases are strongly recommended! For any other
questions, suggestions, or comments, feel free to email the author."
HyperNST: Hyper-Networks for Neural Style Transfer,0.0400282,"We present HyperNST; a neural style transfer (NST) technique for the artistic
stylization of images, based on Hyper-networks and the StyleGAN2 architecture.
Our contribution is a novel method for inducing style transfer parameterized by
a metric space, pre-trained for style-based visual search (SBVS). We show for
the first time that such space may be used to drive NST, enabling the
application and interpolation of styles from an SBVS system. The technical
contribution is a hyper-network that predicts weight updates to a StyleGAN2
pre-trained over a diverse gamut of artistic content (portraits), tailoring the
style parameterization on a per-region basis using a semantic map of the facial
regions. We show HyperNST to exceed state of the art in content preservation
for our stylized content while retaining good style transfer performance."
NQE: N-ary Query Embedding for Complex Query Answering over Hyper-Relational Knowledge Graphs,0.0511849,"Complex query answering (CQA) is an essential task for multi-hop and logical
reasoning on knowledge graphs (KGs). Currently, most approaches are limited to
queries among binary relational facts and pay less attention to n-ary facts
(n>=2) containing more than two entities, which are more prevalent in the real
world. Moreover, previous CQA methods can only make predictions for a few given
types of queries and cannot be flexibly extended to more complex logical
queries, which significantly limits their applications. To overcome these
challenges, in this work, we propose a novel N-ary Query Embedding (NQE) model
for CQA over hyper-relational knowledge graphs (HKGs), which include massive
n-ary facts. The NQE utilizes a dual-heterogeneous Transformer encoder and
fuzzy logic theory to satisfy all n-ary FOL queries, including existential
quantifiers, conjunction, disjunction, and negation. We also propose a parallel
processing algorithm that can train or predict arbitrary n-ary FOL queries in a
single batch, regardless of the kind of each query, with good flexibility and
extensibility. In addition, we generate a new CQA dataset WD50K-NFOL, including
diverse n-ary FOL queries over WD50K. Experimental results on WD50K-NFOL and
other standard CQA datasets show that NQE is the state-of-the-art CQA method
over HKGs with good generalization capability. Our code and dataset are
publicly available."
Motion Prediction via Joint Dependency Modeling in Phase Space,0.0941315,"Motion prediction is a classic problem in computer vision, which aims at
forecasting future motion given the observed pose sequence. Various deep
learning models have been proposed, achieving state-of-the-art performance on
motion prediction. However, existing methods typically focus on modeling
temporal dynamics in the pose space. Unfortunately, the complicated and high
dimensionality nature of human motion brings inherent challenges for dynamic
context capturing. Therefore, we move away from the conventional pose based
representation and present a novel approach employing a phase space trajectory
representation of individual joints. Moreover, current methods tend to only
consider the dependencies between physically connected joints. In this paper,
we introduce a novel convolutional neural model to effectively leverage
explicit prior knowledge of motion anatomy, and simultaneously capture both
spatial and temporal information of joint trajectory dynamics. We then propose
a global optimization module that learns the implicit relationships between
individual joint features.
  Empirically, our method is evaluated on large-scale 3D human motion benchmark
datasets (i.e., Human3.6M, CMU MoCap). These results demonstrate that our
method sets the new state-of-the-art on the benchmark datasets. Our code will
be available at https://github.com/Pose-Group/TEID."
"For Learning in Symmetric Teams, Local Optima are Global Nash Equilibria",0.01963,"Although it has been known since the 1970s that a globally optimal strategy
profile in a common-payoff game is a Nash equilibrium, global optimality is a
strict requirement that limits the result's applicability. In this work, we
show that any locally optimal symmetric strategy profile is also a (global)
Nash equilibrium. Furthermore, we show that this result is robust to
perturbations to the common payoff and to the local optimum. Applied to machine
learning, our result provides a global guarantee for any gradient method that
finds a local optimum in symmetric strategy space. While this result indicates
stability to unilateral deviation, we nevertheless identify broad classes of
games where mixed local optima are unstable under joint, asymmetric deviations.
We analyze the prevalence of instability by running learning algorithms in a
suite of symmetric games, and we conclude by discussing the applicability of
our results to multi-agent RL, cooperative inverse RL, and decentralized
POMDPs."
Rethinking Audio-visual Synchronization for Active Speaker Detection,0.106856,"Active speaker detection (ASD) systems are important modules for analyzing
multi-talker conversations. They aim to detect which speakers or none are
talking in a visual scene at any given time. Existing research on ASD does not
agree on the definition of active speakers. We clarify the definition in this
work and require synchronization between the audio and visual speaking
activities. This clarification of definition is motivated by our extensive
experiments, through which we discover that existing ASD methods fail in
modeling the audio-visual synchronization and often classify unsynchronized
videos as active speaking. To address this problem, we propose a cross-modal
contrastive learning strategy and apply positional encoding in attention
modules for supervised ASD models to leverage the synchronization cue.
Experimental results suggest that our model can successfully detect
unsynchronized speaking as not speaking, addressing the limitation of current
models."
Towards Disentangled Speech Representations,0.0529856,"The careful construction of audio representations has become a dominant
feature in the design of approaches to many speech tasks. Increasingly, such
approaches have emphasized ""disentanglement"", where a representation contains
only parts of the speech signal relevant to transcription while discarding
irrelevant information. In this paper, we construct a representation learning
task based on joint modeling of ASR and TTS, and seek to learn a representation
of audio that disentangles that part of the speech signal that is relevant to
transcription from that part which is not. We present empirical evidence that
successfully finding such a representation is tied to the randomness inherent
in training. We then make the observation that these desired, disentangled
solutions to the optimization problem possess unique statistical properties.
Finally, we show that enforcing these properties during training improves WER
by 24.5% relative on average for our joint modeling task. These observations
motivate a novel approach to learning effective audio representations."
Unsupervised Cross-Modality Domain Adaptation for Vestibular Schwannoma Segmentation and Koos Grade Prediction based on Semi-Supervised Contrastive Learning,0.121909,"Domain adaptation has been widely adopted to transfer styles across
multi-vendors and multi-centers, as well as to complement the missing
modalities. In this challenge, we proposed an unsupervised domain adaptation
framework for cross-modality vestibular schwannoma (VS) and cochlea
segmentation and Koos grade prediction. We learn the shared representation from
both ceT1 and hrT2 images and recover another modality from the latent
representation, and we also utilize proxy tasks of VS segmentation and brain
parcellation to restrict the consistency of image structures in domain
adaptation. After generating missing modalities, the nnU-Net model is utilized
for VS and cochlea segmentation, while a semi-supervised contrastive learning
pre-train approach is employed to improve the model performance for Koos grade
prediction. On CrossMoDA validation phase Leaderboard, our method received rank
4 in task1 with a mean Dice score of 0.8394 and rank 2 in task2 with
Macro-Average Mean Square Error of 0.3941. Our code is available at
https://github.com/fiy2W/cmda2022.superpolymerization."
Exploring Diversity-based Active Learning for 3D Object Detection in Autonomous Driving,0.0260712,"3D object detection has recently received much attention due to its great
potential in autonomous vehicle (AV). The success of deep learning based object
detectors relies on the availability of large-scale annotated datasets, which
is time-consuming and expensive to compile, especially for 3D bounding box
annotation. In this work, we investigate diversity-based active learning (AL)
as a potential solution to alleviate the annotation burden. Given limited
annotation budget, only the most informative frames and objects are
automatically selected for human to annotate. Technically, we take the
advantage of the multimodal information provided in an AV dataset, and propose
a novel acquisition function that enforces spatial and temporal diversity in
the selected samples. We benchmark the proposed method against other AL
strategies under realistic annotation cost measurement, where the realistic
costs for annotating a frame and a 3D bounding box are both taken into
consideration. We demonstrate the effectiveness of the proposed method on the
nuScenes dataset and show that it outperforms existing AL strategies
significantly."
Discrete Factorial Representations as an Abstraction for Goal Conditioned Reinforcement Learning,0.0142688,"Goal-conditioned reinforcement learning (RL) is a promising direction for
training agents that are capable of solving multiple tasks and reach a diverse
set of objectives. How to \textit{specify} and \textit{ground} these goals in
such a way that we can both reliably reach goals during training as well as
generalize to new goals during evaluation remains an open area of research.
Defining goals in the space of noisy and high-dimensional sensory inputs poses
a challenge for training goal-conditioned agents, or even for generalization to
novel goals. We propose to address this by learning factorial representations
of goals and processing the resulting representation via a discretization
bottleneck, for coarser goal specification, through an approach we call DGRL.
We show that applying a discretizing bottleneck can improve performance in
goal-conditioned RL setups, by experimentally evaluating this method on tasks
ranging from maze environments to complex robotic navigation and manipulation.
Additionally, we prove a theorem lower-bounding the expected return on
out-of-distribution goals, while still allowing for specifying goals with
expressive combinatorial structure."
SAT: Self-adaptive training for fashion compatibility prediction,0.0487522,"This paper presents a self-adaptive training (SAT) model for fashion
compatibility prediction. It focuses on the learning of some hard items, such
as those that share similar color, texture, and pattern features but are
considered incompatible due to the aesthetics or temporal shifts. Specifically,
we first design a method to define hard outfits and a difficulty score (DS) is
defined and assigned to each outfit based on the difficulty in recommending an
item for it. Then, we propose a self-adaptive triplet loss (SATL), where the DS
of the outfit is considered. Finally, we propose a very simple conditional
similarity network combining the proposed SATL to achieve the learning of hard
items in the fashion compatibility prediction. Experiments on the publicly
available Polyvore Outfits and Polyvore Outfits-D datasets demonstrate our
SAT's effectiveness in fashion compatibility prediction. Besides, our SATL can
be easily extended to other conditional similarity networks to improve their
performance."
Learning to Detect Mobile Objects from LiDAR Scans Without Labels,0.253891,"Current 3D object detectors for autonomous driving are almost entirely
trained on human-annotated data. Although of high quality, the generation of
such data is laborious and costly, restricting them to a few specific locations
and object types. This paper proposes an alternative approach entirely based on
unlabeled data, which can be collected cheaply and in abundance almost
everywhere on earth. Our approach leverages several simple common sense
heuristics to create an initial set of approximate seed labels. For example,
relevant traffic participants are generally not persistent across multiple
traversals of the same route, do not fly, and are never under ground. We
demonstrate that these seed labels are highly effective to bootstrap a
surprisingly accurate detector through repeated self-training without a single
human annotated label."
A Low-Shot Object Counting Network With Iterative Prototype Adaptation,0.353208,"We consider low-shot counting of arbitrary semantic categories in the image
using only few annotated exemplars (few-shot) or no exemplars (no-shot). The
standard few-shot pipeline follows extraction of appearance queries from
exemplars and matching them with image features to infer the object counts.
Existing methods extract queries by feature pooling which neglects the shape
information (e.g., size and aspect) and leads to a reduced object localization
accuracy and count estimates. We propose a Low-shot Object Counting network
with iterative prototype Adaptation (LOCA). Our main contribution is the new
object prototype extraction module, which iteratively fuses the exemplar shape
and appearance information with image features. The module is easily adapted to
zero-shot scenarios, enabling LOCA to cover the entire spectrum of low-shot
counting problems. LOCA outperforms all recent state-of-the-art methods on
FSC147 benchmark by 20-30% in RMSE on one-shot and few-shot and achieves
state-of-the-art on zero-shot scenarios, while demonstrating better
generalization capabilities."
On three types of $L$-fuzzy $β$-covering-based rough sets,0.0371745,"In this paper, we mainly construct three types of $L$-fuzzy
$\beta$-covering-based rough set models and study the axiom sets, matrix
representations and interdependency of these three pairs of $L$-fuzzy
$\beta$-covering-based rough approximation operators. Firstly, we propose three
pairs of $L$-fuzzy $\beta$-covering-based rough approximation operators by
introducing the concepts such as $\beta$-degree of intersection and
$\beta$-subsethood degree, which are generalizations of degree of intersection
and subsethood degree, respectively. And then, the axiom set for each of these
$L$-fuzzy $\beta$-covering-based rough approximation operator is investigated.
Thirdly, we give the matrix representations of three types of $L$-fuzzy
$\beta$-covering-based rough approximation operators, which make it valid to
calculate the $L$-fuzzy $\beta$-covering-based lower and upper rough
approximation operators through operations on matrices. Finally, the
interdependency of the three pairs of rough approximation operators based on
$L$-fuzzy $\beta$-covering is studied by using the notion of reducible elements
and independent elements. In other words, we present the necessary and
sufficient conditions under which two $L$-fuzzy $\beta$-coverings can generate
the same lower and upper rough approximation operations."
Subword Segmental Language Modelling for Nguni Languages,0.0498461,"Subwords have become the standard units of text in NLP, enabling efficient
open-vocabulary models. With algorithms like byte-pair encoding (BPE), subword
segmentation is viewed as a preprocessing step applied to the corpus before
training. This can lead to sub-optimal segmentations for low-resource languages
with complex morphologies. We propose a subword segmental language model (SSLM)
that learns how to segment words while being trained for autoregressive
language modelling. By unifying subword segmentation and language modelling,
our model learns subwords that optimise LM performance. We train our model on
the 4 Nguni languages of South Africa. These are low-resource agglutinative
languages, so subword information is critical. As an LM, SSLM outperforms
existing approaches such as BPE-based models on average across the 4 languages.
Furthermore, it outperforms standard subword segmenters on unsupervised
morphological segmentation. We also train our model as a word-level sequence
model, resulting in an unsupervised morphological segmenter that outperforms
existing methods by a large margin for all 4 languages. Our results show that
learning subword segmentation is an effective alternative to existing subword
segmenters, enabling the model to discover morpheme-like subwords that improve
its LM capabilities."
Better Quality Estimation for Low Resource Corpus Mining,0.0271242,"Quality Estimation (QE) models have the potential to change how we evaluate
and maybe even train machine translation models. However, these models still
lack the robustness to achieve general adoption. We show that State-of-the-art
QE models, when tested in a Parallel Corpus Mining (PCM) setting, perform
unexpectedly bad due to a lack of robustness to out-of-domain examples. We
propose a combination of multitask training, data augmentation and contrastive
learning to achieve better and more robust QE performance. We show that our
method improves QE performance significantly in the MLQE challenge and the
robustness of QE models when tested in the Parallel Corpus Mining setup. We
increase the accuracy in PCM by more than 0.80, making it on par with
state-of-the-art PCM methods that use millions of sentence pairs to train their
models. In comparison, we use a thousand times less data, 7K parallel sentences
in total, and propose a novel low resource PCM method."
Multi Task Learning For Zero Shot Performance Prediction of Multilingual Models,0.111532,"Massively Multilingual Transformer based Language Models have been observed
to be surprisingly effective on zero-shot transfer across languages, though the
performance varies from language to language depending on the pivot language(s)
used for fine-tuning. In this work, we build upon some of the existing
techniques for predicting the zero-shot performance on a task, by modeling it
as a multi-task learning problem. We jointly train predictive models for
different tasks which helps us build more accurate predictors for tasks where
we have test data in very few languages to measure the actual performance of
the model. Our approach also lends us the ability to perform a much more robust
feature selection and identify a common set of features that influence
zero-shot performance across a variety of tasks."
Taylor Genetic Programming for Symbolic Regression,0.301101,"Genetic programming (GP) is a commonly used approach to solve symbolic
regression (SR) problems. Compared with the machine learning or deep learning
methods that depend on the pre-defined model and the training dataset for
solving SR problems, GP is more focused on finding the solution in a search
space. Although GP has good performance on large-scale benchmarks, it randomly
transforms individuals to search results without taking advantage of the
characteristics of the dataset. So, the search process of GP is usually slow,
and the final results could be unstable.To guide GP by these characteristics,
we propose a new method for SR, called Taylor genetic programming (TaylorGP)
(Code and appendix at https://kgae-cup.github.io/TaylorGP/). TaylorGP leverages
a Taylor polynomial to approximate the symbolic equation that fits the dataset.
It also utilizes the Taylor polynomial to extract the features of the symbolic
equation: low order polynomial discrimination, variable separability, boundary,
monotonic, and parity. GP is enhanced by these Taylor polynomial techniques.
Experiments are conducted on three kinds of benchmarks: classical SR, machine
learning, and physics. The experimental results show that TaylorGP not only has
higher accuracy than the nine baseline methods, but also is faster in finding
stable results."
Pre-trained Token-replaced Detection Model as Few-shot Learner,0.0639986,"Pre-trained masked language models have demonstrated remarkable ability as
few-shot learners. In this paper, as an alternative, we propose a novel
approach to few-shot learning with pre-trained token-replaced detection models
like ELECTRA. In this approach, we reformulate a classification or a regression
task as a token-replaced detection problem. Specifically, we first define a
template and label description words for each task and put them into the input
to form a natural language prompt. Then, we employ the pre-trained
token-replaced detection model to predict which label description word is the
most original (i.e., least replaced) among all label description words in the
prompt. A systematic evaluation on 16 datasets demonstrates that our approach
outperforms few-shot learners with pre-trained masked language models in both
one-sentence and two-sentence learning tasks."
On the Relationship Between Variational Inference and Auto-Associative Memory,0.00610859,"In this article, we propose a variational inference formulation of
auto-associative memories, allowing us to combine perceptual inference and
memory retrieval into the same mathematical framework. In this formulation, the
prior probability distribution onto latent representations is made memory
dependent, thus pulling the inference process towards previously stored
representations. We then study how different neural network approaches to
variational inference can be applied in this framework. We compare methods
relying on amortized inference such as Variational Auto Encoders and methods
relying on iterative inference such as Predictive Coding and suggest combining
both approaches to design new auto-associative memory models. We evaluate the
obtained algorithms on the CIFAR10 and CLEVR image datasets and compare them
with other associative memory models such as Hopfield Networks, End-to-End
Memory Networks and Neural Turing Machines."
Fine-grained Contrastive Learning for Relation Extraction,0.0684873,"Recent relation extraction (RE) works have shown encouraging improvements by
conducting contrastive learning on silver labels generated by distant
supervision before fine-tuning on gold labels. Existing methods typically
assume all these silver labels are accurate and treat them equally; however,
distant supervision is inevitably noisy -- some silver labels are more reliable
than others. In this paper, we propose fine-grained contrastive learning
(FineCL) for RE, which leverages fine-grained information about which silver
labels are and are not noisy to improve the quality of learned relationship
representations for RE. We first assess the quality of silver labels via a
simple and automatic approach we call ""learning order denoising,"" where we
train a language model to learn these relations and record the order of learned
training instances. We show that learning order largely corresponds to label
accuracy -- early-learned silver labels have, on average, more accurate labels
than later-learned silver labels. Then, during pre-training, we increase the
weights of accurate labels within a novel contrastive learning objective.
Experiments on several RE benchmarks show that FineCL makes consistent and
significant performance gains over state-of-the-art methods."
CD-FSOD: A Benchmark for Cross-domain Few-shot Object Detection,0.0530354,"In this paper, we propose a study of the cross-domain few-shot object
detection (CD-FSOD) benchmark, consisting of image data from a diverse data
domain. On the proposed benchmark, we evaluate state-of-art FSOD approaches,
including meta-learning FSOD approaches and fine-tuning FSOD approaches. The
results show that these methods tend to fall, and even underperform the naive
fine-tuning model. We analyze the reasons for their failure and introduce a
strong baseline that uses a mutually-beneficial manner to alleviate the
overfitting problem. Our approach is remarkably superior to existing approaches
by significant margins (2.0\% on average) on the proposed benchmark. Our code
is available at \url{https://github.com/FSOD/CD-FSOD}."
Evaluation Beyond Task Performance: Analyzing Concepts in AlphaZero in Hex,0.00528461,"AlphaZero, an approach to reinforcement learning that couples neural networks
and Monte Carlo tree search (MCTS), has produced state-of-the-art strategies
for traditional board games like chess, Go, shogi, and Hex. While researchers
and game commentators have suggested that AlphaZero uses concepts that humans
consider important, it is unclear how these concepts are captured in the
network. We investigate AlphaZero's internal representations in the game of Hex
using two evaluation techniques from natural language processing (NLP): model
probing and behavioral tests. In doing so, we introduce new evaluation tools to
the RL community and illustrate how evaluations other than task performance can
be used to provide a more complete picture of a model's strengths and
weaknesses. Our analyses in the game of Hex reveal interesting patterns and
generate some testable hypotheses about how such models learn in general. For
example, we find that MCTS discovers concepts before the neural network learns
to encode them. We also find that concepts related to short-term end-game
planning are best encoded in the final layers of the model, whereas concepts
related to long-term planning are encoded in the middle layers of the model."
Does Video Compression Impact Tracking Accuracy?,0.0170341,"Everyone ""knows"" that compressing a video will degrade the accuracy of object
tracking. Yet, a literature search on this topic reveals that there is very
little documented evidence for this presumed fact. Part of the reason is that,
until recently, there were no object tracking datasets for uncompressed video,
which made studying the effects of compression on tracking accuracy difficult.
In this paper, using a recently published dataset that contains tracking
annotations for uncompressed videos, we examined the degradation of tracking
accuracy due to video compression using rigorous statistical methods.
Specifically, we examined the impact of quantization parameter (QP) and motion
search range (MSR) on Multiple Object Tracking Accuracy (MOTA). The results
show that QP impacts MOTA at the 95% confidence level, while there is
insufficient evidence to claim that MSR impacts MOTA. Moreover, regression
analysis allows us to derive a quantitative relationship between MOTA and QP
for the specific tracker used in the experiments."
Low-complexity CNNs for Acoustic Scene Classification,0.108447,"This paper presents a low-complexity framework for acoustic scene
classification (ASC). Most of the frameworks designed for ASC use convolutional
neural networks (CNNs) due to their learning ability and improved performance
compared to hand-engineered features. However, CNNs are resource hungry due to
their large size and high computational complexity. Therefore, CNNs are
difficult to deploy on resource constrained devices. This paper addresses the
problem of reducing the computational complexity and memory requirement in
CNNs. We propose a low-complexity CNN architecture, and apply pruning and
quantization to further reduce the parameters and memory. We then propose an
ensemble framework that combines various low-complexity CNNs to improve the
overall performance. An experimental evaluation of the proposed framework is
performed on the publicly available DCASE 2022 Task 1 that focuses on ASC. The
proposed ensemble framework has approximately 60K parameters, requires 19M
multiply-accumulate operations and improves the performance by approximately
2-4 percentage points compared to the DCASE 2022 Task 1 baseline network."
That Slepen Al the Nyght with Open Ye! Cross-era Sequence Segmentation with Switch-memory,0.12289,"The evolution of language follows the rule of gradual change. Grammar,
vocabulary, and lexical semantic shifts take place over time, resulting in a
diachronic linguistic gap. As such, a considerable amount of texts are written
in languages of different eras, which creates obstacles for natural language
processing tasks, such as word segmentation and machine translation. Although
the Chinese language has a long history, previous Chinese natural language
processing research has primarily focused on tasks within a specific era.
Therefore, we propose a cross-era learning framework for Chinese word
segmentation (CWS), CROSSWISE, which uses the Switch-memory (SM) module to
incorporate era-specific linguistic knowledge. Experiments on four corpora from
different eras show that the performance of each corpus significantly improves.
Further analyses also demonstrate that the SM can effectively integrate the
knowledge of the eras into the neural network."
IoV Scenario: Implementation of a Bandwidth Aware Algorithm in Wireless Network Communication Mode,0.344612,"The wireless network communication mode represented by the Internet of
vehicles (IoV) has been widely used. However, due to the limitations of
traditional network architecture, resource scheduling in wireless network
environment is still facing great challenges. This paper focuses on the
allocation of bandwidth resources in the virtual network environment. This
paper proposes a bandwidth aware multi domain virtual network embedding
algorithm (BA-VNE). The algorithm is mainly aimed at the problem that users
need a lot of bandwidth in wireless communication mode, and solves the problem
of bandwidth resource allocation from the perspective of virtual network
embedding (VNE). In order to improve the performance of the algorithm, we
introduce particle swarm optimization (PSO) algorithm to optimize the
performance of the algorithm. In order to verify the effectiveness of the
algorithm, we have carried out simulation experiments from link bandwidth,
mapping cost and virtual network request (VNR) acceptance rate. The final
results show that the proposed algorithm is better than other representative
algorithms in the above indicators."
DiffDreamer: Towards Consistent Unsupervised Single-view Scene Extrapolation with Conditional Diffusion Models,0.0441653,"Scene extrapolation -- the idea of generating novel views by flying into a
given image -- is a promising, yet challenging task. For each predicted frame,
a joint inpainting and 3D refinement problem has to be solved, which is ill
posed and includes a high level of ambiguity. Moreover, training data for
long-range scenes is difficult to obtain and usually lacks sufficient views to
infer accurate camera poses. We introduce DiffDreamer, an unsupervised
framework capable of synthesizing novel views depicting a long camera
trajectory while training solely on internet-collected images of nature scenes.
Utilizing the stochastic nature of the guided denoising steps, we train the
diffusion models to refine projected RGBD images but condition the denoising
steps on multiple past and future frames for inference. We demonstrate that
image-conditioned diffusion models can effectively perform long-range scene
extrapolation while preserving consistency significantly better than prior
GAN-based methods. DiffDreamer is a powerful and efficient solution for scene
extrapolation, producing impressive results despite limited supervision.
Project page: https://primecai.github.io/diffdreamer."
Cross-Lingual Knowledge Transfer for Clinical Phenotyping,0.0576786,"Clinical phenotyping enables the automatic extraction of clinical conditions
from patient records, which can be beneficial to doctors and clinics worldwide.
However, current state-of-the-art models are mostly applicable to clinical
notes written in English. We therefore investigate cross-lingual knowledge
transfer strategies to execute this task for clinics that do not use the
English language and have a small amount of in-domain data available. We
evaluate these strategies for a Greek and a Spanish clinic leveraging clinical
notes from different clinical domains such as cardiology, oncology and the ICU.
Our results reveal two strategies that outperform the state-of-the-art:
Translation-based methods in combination with domain-specific encoders and
cross-lingual encoders plus adapters. We find that these strategies perform
especially well for classifying rare phenotypes and we advise on which method
to prefer in which situation. Our results show that using multilingual data
overall improves clinical phenotyping models and can compensate for data
sparseness."
Matching Tweets With Applicable Fact-Checks Across Languages,0.16573,"An important challenge for news fact-checking is the effective dissemination
of existing fact-checks. This in turn brings the need for reliable methods to
detect previously fact-checked claims. In this paper, we focus on automatically
finding existing fact-checks for claims made in social media posts (tweets). We
conduct both classification and retrieval experiments, in monolingual (English
only), multilingual (Spanish, Portuguese), and cross-lingual (Hindi-English)
settings using multilingual transformer models such as XLM-RoBERTa and
multilingual embeddings such as LaBSE and SBERT. We present promising results
for ""match"" classification (86% average accuracy) in four language pairs. We
also find that a BM25 baseline outperforms or is on par with state-of-the-art
multilingual embedding models for the retrieval task during our monolingual
experiments. We highlight and discuss NLP challenges while addressing this
problem in different languages, and we introduce a novel curated dataset of
fact-checks and corresponding tweets for future research."
Label Sleuth: From Unlabeled Text to a Classifier in a Few Hours,0.0145099,"Text classification can be useful in many real-world scenarios, saving a lot
of time for end users. However, building a custom classifier typically requires
coding skills and ML knowledge, which poses a significant barrier for many
potential users. To lift this barrier, we introduce Label Sleuth, a free open
source system for labeling and creating text classifiers. This system is unique
for (a) being a no-code system, making NLP accessible to non-experts, (b)
guiding users through the entire labeling process until they obtain a custom
classifier, making the process efficient -- from cold start to classifier in a
few hours, and (c) being open for configuration and extension by developers. By
open sourcing Label Sleuth we hope to build a community of users and developers
that will broaden the utilization of NLP models."
AugESC: Dialogue Augmentation with Large Language Models for Emotional Support Conversation,0.149081,"Crowdsourced dialogue corpora are usually limited in scale and topic coverage
due to the expensive cost of data curation. This would hinder the
generalization of downstream dialogue models to open-domain topics. In this
work, we leverage large language models for dialogue augmentation in the task
of emotional support conversation (ESC). By treating dialogue augmentation as a
dialogue completion task, we prompt a fine-tuned language model to complete
full dialogues from available dialogue posts of various topics, which are then
postprocessed based on heuristics. Applying this approach, we construct AugESC,
an augmented dataset for the ESC task, which largely extends the scale and
topic coverage of the crowdsourced ESConv corpus. Through comprehensive human
evaluation, we demonstrate that our approach is superior to strong baselines of
dialogue augmentation and that AugESC has comparable dialogue quality to the
crowdsourced corpus. We also conduct human interactive evaluation and prove
that post-training on AugESC improves downstream dialogue models'
generalization ability to open-domain topics. These results suggest the utility
of AugESC and highlight the potential of large language models in improving
data-scarce dialogue generation tasks."
A comparison of several AI techniques for authorship attribution on Romanian texts,0.0573299,"Determining the author of a text is a difficult task. Here we compare
multiple AI techniques for classifying literary texts written by multiple
authors by taking into account a limited number of speech parts (prepositions,
adverbs, and conjunctions). We also introduce a new dataset composed of texts
written in the Romanian language on which we have run the algorithms. The
compared methods are Artificial Neural Networks, Support Vector Machines, Multi
Expression Programming, Decision Trees with C5.0, and k-Nearest Neighbour.
Numerical experiments show, first of all, that the problem is difficult, but
some algorithms are able to generate decent errors on the test set."
Self-supervised Image Clustering from Multiple Incomplete Views via Constrastive Complementary Generation,0.130021,"Incomplete Multi-View Clustering aims to enhance clustering performance by
using data from multiple modalities. Despite the fact that several approaches
for studying this issue have been proposed, the following drawbacks still
persist: 1) It's difficult to learn latent representations that account for
complementarity yet consistency without using label information; 2) and thus
fails to take full advantage of the hidden information in incomplete data
results in suboptimal clustering performance when complete data is scarce. In
this paper, we propose Contrastive Incomplete Multi-View Image Clustering with
Generative Adversarial Networks (CIMIC-GAN), which uses GAN to fill in
incomplete data and uses double contrastive learning to learn consistency on
complete and incomplete data. More specifically, considering diversity and
complementary information among multiple modalities, we incorporate
autoencoding representation of complete and incomplete data into double
contrastive learning to achieve learning consistency. Integrating GANs into the
autoencoding process can not only take full advantage of new features of
incomplete data, but also better generalize the model in the presence of high
data missing rates. Experiments conducted on \textcolor{black}{four}
extensively-used datasets show that CIMIC-GAN outperforms state-of-the-art
incomplete multi-View clustering methods."
Active Self-Training for Weakly Supervised 3D Scene Semantic Segmentation,0.155596,"Since the preparation of labeled data for training semantic segmentation
networks of point clouds is a time-consuming process, weakly supervised
approaches have been introduced to learn from only a small fraction of data.
These methods are typically based on learning with contrastive losses while
automatically deriving per-point pseudo-labels from a sparse set of
user-annotated labels. In this paper, our key observation is that the selection
of what samples to annotate is as important as how these samples are used for
training. Thus, we introduce a method for weakly supervised segmentation of 3D
scenes that combines self-training with active learning. The active learning
selects points for annotation that likely result in performance improvements to
the trained model, while the self-training makes efficient use of the
user-provided labels for learning the model. We demonstrate that our approach
leads to an effective method that provides improvements in scene segmentation
over previous works and baselines, while requiring only a small number of user
annotations."
Seeking Diverse Reasoning Logic: Controlled Equation Expression Generation for Solving Math Word Problems,0.029869,"To solve Math Word Problems, human students leverage diverse reasoning logic
that reaches different possible equation solutions. However, the mainstream
sequence-to-sequence approach of automatic solvers aims to decode a fixed
solution equation supervised by human annotation. In this paper, we propose a
controlled equation generation solver by leveraging a set of control codes to
guide the model to consider certain reasoning logic and decode the
corresponding equations expressions transformed from the human reference. The
empirical results suggest that our method universally improves the performance
on single-unknown (Math23K) and multiple-unknown (DRAW1K, HMWP) benchmarks,
with substantial improvements up to 13.2% accuracy on the challenging
multiple-unknown datasets."
Continual Learning with Recursive Gradient Optimization,0.271006,"Learning multiple tasks sequentially without forgetting previous knowledge,
called Continual Learning(CL), remains a long-standing challenge for neural
networks. Most existing methods rely on additional network capacity or data
replay. In contrast, we introduce a novel approach which we refer to as
Recursive Gradient Optimization(RGO). RGO is composed of an iteratively updated
optimizer that modifies the gradient to minimize forgetting without data replay
and a virtual Feature Encoding Layer(FEL) that represents different long-term
structures with only task descriptors. Experiments demonstrate that RGO has
significantly better performance on popular continual classification benchmarks
when compared to the baselines and achieves new state-of-the-art performance on
20-split-CIFAR100(82.22%) and 20-split-miniImageNet(72.63%). With higher
average accuracy than Single-Task Learning(STL), this method is flexible and
reliable to provide continual learning capabilities for learning models that
rely on gradient descent."
How to Fine-Tune Vision Models with SGD,0.699011,"SGD and AdamW are the two most used optimizers for fine-tuning large neural
networks in computer vision. When the two methods perform the same, SGD is
preferable because it uses less memory (12 bytes/parameter with momentum and 8
bytes/parameter without) than AdamW (16 bytes/parameter). However, on a suite
of downstream tasks, especially those with distribution shifts, we find that
fine-tuning with AdamW performs substantially better than SGD on modern Vision
Transformer and ConvNeXt models. We find that large gaps in performance between
SGD and AdamW occur when the fine-tuning gradients in the first ""embedding""
layer are much larger than in the rest of the model. Our analysis suggests an
easy fix that works consistently across datasets and models: freezing the
embedding layer (less than 1% of the parameters) leads to SGD with or without
momentum performing slightly better than AdamW while using less memory (e.g.,
on ViT-L, SGD uses 33% less GPU memory). Our insights result in
state-of-the-art accuracies on five popular distribution shift benchmarks:
WILDS-FMoW, WILDS-Camelyon, BREEDS-Living-17, Waterbirds, and DomainNet."
Zero-shot Blind Image Denoising via Implicit Neural Representations,0.0606132,"Recent denoising algorithms based on the ""blind-spot"" strategy show
impressive blind image denoising performances, without utilizing any external
dataset. While the methods excel in recovering highly contaminated images, we
observe that such algorithms are often less effective under a low-noise or real
noise regime. To address this gap, we propose an alternative denoising strategy
that leverages the architectural inductive bias of implicit neural
representations (INRs), based on our two findings: (1) INR tends to fit the
low-frequency clean image signal faster than the high-frequency noise, and (2)
INR layers that are closer to the output play more critical roles in fitting
higher-frequency parts. Building on these observations, we propose a denoising
algorithm that maximizes the innate denoising capability of INRs by penalizing
the growth of deeper layer weights. We show that our method outperforms
existing zero-shot denoising methods under an extensive set of low-noise or
real-noise scenarios."
CONDA: Continual Unsupervised Domain Adaptation Learning in Visual Perception for Self-Driving Cars,0.0329088,"Although unsupervised domain adaptation methods have achieved remarkable
performance in semantic scene segmentation in visual perception for
self-driving cars, these approaches remain impractical in real-world use cases.
In practice, the segmentation models may encounter new data that have not been
seen yet. Also, the previous data training of segmentation models may be
inaccessible due to privacy problems. Therefore, to address these problems, in
this work, we propose a Continual Unsupervised Domain Adaptation (CONDA)
approach that allows the model to continuously learn and adapt with respect to
the presence of the new data. Moreover, our proposed approach is designed
without the requirement of accessing previous training data. To avoid the
catastrophic forgetting problem and maintain the performance of the
segmentation models, we present a novel Bijective Maximum Likelihood loss to
impose the constraint of predicted segmentation distribution shifts. The
experimental results on the benchmark of continual unsupervised domain
adaptation have shown the advanced performance of the proposed CONDA method."
CoHS-CQG: Context and History Selection for Conversational Question Generation,0.0804786,"Conversational question generation (CQG) serves as a vital task for machines
to assist humans, such as interactive reading comprehension, through
conversations. Compared to traditional single-turn question generation (SQG),
CQG is more challenging in the sense that the generated question is required
not only to be meaningful, but also to align with the occurred conversation
history. While previous studies mainly focus on how to model the flow and
alignment of the conversation, there has been no thorough study to date on
which parts of the context and history are necessary for the model. We argue
that shortening the context and history is crucial as it can help the model to
optimise more on the conversational alignment property. To this end, we propose
CoHS-CQG, a two-stage CQG framework, which adopts a CoHS module to shorten the
context and history of the input. In particular, CoHS selects contiguous
sentences and history turns according to their relevance scores by a top-p
strategy. Our model achieves state-of-the-art performances on CoQA in both the
answer-aware and answer-unaware settings."
What Makes Good Contrastive Learning on Small-Scale Wearable-based Tasks?,0.0512041,"Self-supervised learning establishes a new paradigm of learning
representations with much fewer or even no label annotations. Recently there
has been remarkable progress on large-scale contrastive learning models which
require substantial computing resources, yet such models are not practically
optimal for small-scale tasks. To fill the gap, we aim to study contrastive
learning on the wearable-based activity recognition task. Specifically, we
conduct an in-depth study of contrastive learning from both algorithmic-level
and task-level perspectives. For algorithmic-level analysis, we decompose
contrastive models into several key components and conduct rigorous
experimental evaluations to better understand the efficacy and rationale behind
contrastive learning. More importantly, for task-level analysis, we show that
the wearable-based signals bring unique challenges and opportunities to
existing contrastive models, which cannot be readily solved by existing
algorithms. Our thorough empirical studies suggest important practices and shed
light on future research challenges. In the meantime, this paper presents an
open-source PyTorch library \texttt{CL-HAR}, which can serve as a practical
tool for researchers. The library is highly modularized and easy to use, which
opens up avenues for exploring novel contrastive models quickly in the future."
Placing Human Animations into 3D Scenes by Learning Interaction- and Geometry-Driven Keyframes,0.10509,"We present a novel method for placing a 3D human animation into a 3D scene
while maintaining any human-scene interactions in the animation. We use the
notion of computing the most important meshes in the animation for the
interaction with the scene, which we call ""keyframes."" These keyframes allow us
to better optimize the placement of the animation into the scene such that
interactions in the animations (standing, laying, sitting, etc.) match the
affordances of the scene (e.g., standing on the floor or laying in a bed). We
compare our method, which we call PAAK, with prior approaches, including POSA,
PROX ground truth, and a motion synthesis method, and highlight the benefits of
our method with a perceptual study. Human raters preferred our PAAK method over
the PROX ground truth data 64.6\% of the time. Additionally, in direct
comparisons, the raters preferred PAAK over competing methods including 61.5\%
compared to POSA."
Choose Your QA Model Wisely: A Systematic Study of Generative and Extractive Readers for Question Answering,0.0312951,"While both extractive and generative readers have been successfully applied
to the Question Answering (QA) task, little attention has been paid toward the
systematic comparison of them. Characterizing the strengths and weaknesses of
the two readers is crucial not only for making a more informed reader selection
in practice but also for developing a deeper understanding to foster further
research on improving readers in a principled manner. Motivated by this goal,
we make the first attempt to systematically study the comparison of extractive
and generative readers for question answering. To be aligned with the
state-of-the-art, we explore nine transformer-based large pre-trained language
models (PrLMs) as backbone architectures. Furthermore, we organize our findings
under two main categories: (1) keeping the architecture invariant, and (2)
varying the underlying PrLMs. Among several interesting findings, it is
important to highlight that (1) the generative readers perform better in long
context QA, (2) the extractive readers perform better in short context while
also showing better out-of-domain generalization, and (3) the encoder of
encoder-decoder PrLMs (e.g., T5) turns out to be a strong extractive reader and
outperforms the standard choice of encoder-only PrLMs (e.g., RoBERTa). We also
study the effect of multi-task learning on the two types of readers varying the
underlying PrLMs and perform qualitative and quantitative diagnosis to provide
further insights into future directions in modeling better readers."
Bio-inspired Min-Nets Improve the Performance and Robustness of Deep Networks,0.115396,"Min-Nets are inspired by end-stopped cortical cells with units that output
the minimum of two learned filters. We insert such Min-units into
state-of-the-art deep networks, such as the popular ResNet and DenseNet, and
show that the resulting Min-Nets perform better on the Cifar-10 benchmark.
Moreover, we show that Min-Nets are more robust against JPEG compression
artifacts. We argue that the minimum operation is the simplest way of
implementing an AND operation on pairs of filters and that such AND operations
introduce a bias that is appropriate given the statistics of natural images."
Gym-saturation: an OpenAI Gym environment for saturation provers,0.0248099,"`gym-saturation` is an OpenAI Gym environment for reinforcement learning (RL)
agents capable of proving theorems. Currently, only theorems written in a
formal language of the Thousands of Problems for Theorem Provers (TPTP) library
in clausal normal form (CNF) are supported. `gym-saturation` implements the
'given clause' algorithm (similar to the one used in Vampire and E Prover).
Being written in Python, `gym-saturation` was inspired by PyRes. In contrast to
the monolithic architecture of a typical Automated Theorem Prover (ATP),
`gym-saturation` gives different agents opportunities to select clauses
themselves and train from their experience. Combined with a particular agent,
`gym-saturation` can work as an ATP. Even with a non trained agent based on
heuristics, `gym-saturation` can find refutations for 688 (of 8257) CNF
problems from TPTP v7.5.0."
Transformer based Urdu Handwritten Text Optical Character Reader,0.297542,"Extracting Handwritten text is one of the most important components of
digitizing information and making it available for large scale setting.
Handwriting Optical Character Reader (OCR) is a research problem in computer
vision and natural language processing computing, and a lot of work has been
done for English, but unfortunately, very little work has been done for low
resourced languages such as Urdu. Urdu language script is very difficult
because of its cursive nature and change of shape of characters based on it's
relative position, therefore, a need arises to propose a model which can
understand complex features and generalize it for every kind of handwriting
style. In this work, we propose a transformer based Urdu Handwritten text
extraction model. As transformers have been very successful in Natural Language
Understanding task, we explore them further to understand complex Urdu
Handwriting."
Lempel-Ziv Networks,0.011211,"Sequence processing has long been a central area of machine learning
research. Recurrent neural nets have been successful in processing sequences
for a number of tasks; however, they are known to be both ineffective and
computationally expensive when applied to very long sequences.
Compression-based methods have demonstrated more robustness when processing
such sequences -- in particular, an approach pairing the Lempel-Ziv Jaccard
Distance (LZJD) with the k-Nearest Neighbor algorithm has shown promise on long
sequence problems (up to $T=200,000,000$ steps) involving malware
classification. Unfortunately, use of LZJD is limited to discrete domains. To
extend the benefits of LZJD to a continuous domain, we investigate the
effectiveness of a deep-learning analog of the algorithm, the Lempel-Ziv
Network. While we achieve successful proof of concept, we are unable to improve
meaningfully on the performance of a standard LSTM across a variety of datasets
and sequence processing tasks. In addition to presenting this negative result,
our work highlights the problem of sub-par baseline tuning in newer research
areas."
DisCup: Discriminator Cooperative Unlikelihood Prompt-tuning for Controllable Text Generation,-1.0,"Prompt learning with immensely large Casual Language Models (CLMs) has been
shown promising for attribute-controllable text generation (CTG). However,
vanilla prompt tuning tends to imitate training corpus characteristics beyond
the control attributes, resulting in a poor generalization ability. Moreover,
it is less able to capture the relationship between different attributes,
further limiting the control performance. In this paper, we propose a new CTG
approach, namely DisCup, which incorporates the attribute knowledge of
discriminator to optimize the control-prompts, steering a frozen CLM to produce
attribute-specific texts. Specifically, the frozen CLM model, capable of
producing multitudinous texts, is first used to generate the next-token
candidates based on the context, so as to ensure the diversity of tokens to be
predicted. Then, we leverage an attribute-discriminator to select
desired/undesired tokens from those candidates, providing the inter-attribute
knowledge. Finally, we bridge the above two traits by an unlikelihood objective
for prompt-tuning. Extensive experimental results show that DisCup can achieve
a new state-of-the-art control performance while maintaining an efficient and
high-quality text generation, only relying on around 10 virtual tokens."
Improving Robustness of Convolutional Neural Networks Using Element-Wise Activation Scaling,0.0116389,"Recent works reveal that re-calibrating the intermediate activation of
adversarial examples can improve the adversarial robustness of a CNN model. The
state of the arts [Baiet al., 2021] and [Yanet al., 2021] explores this feature
at the channel level, i.e. the activation of a channel is uniformly scaled by a
factor. In this paper, we investigate the intermediate activation manipulation
at a more fine-grained level. Instead of uniformly scaling the activation, we
individually adjust each element within an activation and thus propose
Element-Wise Activation Scaling, dubbed EWAS, to improve CNNs' adversarial
robustness. Experimental results on ResNet-18 and WideResNet with CIFAR10 and
SVHN show that EWAS significantly improves the robustness accuracy. Especially
for ResNet18 on CIFAR10, EWAS increases the adversarial accuracy by 37.65% to
82.35% against C&W attack. EWAS is simple yet very effective in terms of
improving robustness. The codes are anonymously available at
https://anonymous.4open.science/r/EWAS-DD64."
Unifying Approaches in Active Learning and Active Sampling via Fisher Information and Information-Theoretic Quantities,0.0237294,"Recently proposed methods in data subset selection, that is active learning
and active sampling, use Fisher information, Hessians, similarity matrices
based on gradients, and gradient lengths to estimate how informative data is
for a model's training. Are these different approaches connected, and if so,
how? We revisit the fundamentals of Bayesian optimal experiment design and show
that these recently proposed methods can be understood as approximations to
information-theoretic quantities: among them, the mutual information between
predictions and model parameters, known as expected information gain or BALD in
machine learning, and the mutual information between predictions of acquisition
candidates and test samples, known as expected predictive information gain. We
develop a comprehensive set of approximations using Fisher information and
observed information and derive a unified framework that connects seemingly
disparate literature. Although Bayesian methods are often seen as separate from
non-Bayesian ones, the sometimes fuzzy notion of ""informativeness"" expressed in
various non-Bayesian objectives leads to the same couple of information
quantities, which were, in principle, already known by Lindley (1956) and
MacKay (1992)."
Dead or Murdered? Predicting Responsibility Perception in Femicide News Reports,0.0281695,"Different linguistic expressions can conceptualize the same event from
different viewpoints by emphasizing certain participants over others. Here, we
investigate a case where this has social consequences: how do linguistic
expressions of gender-based violence (GBV) influence who we perceive as
responsible? We build on previous psycholinguistic research in this area and
conduct a large-scale perception survey of GBV descriptions automatically
extracted from a corpus of Italian newspapers. We then train regression models
that predict the salience of GBV participants with respect to different
dimensions of perceived responsibility. Our best model (fine-tuned BERT) shows
solid overall performance, with large differences between dimensions and
participants: salient _focus_ is more predictable than salient _blame_, and
perpetrators' salience is more predictable than victims' salience. Experiments
with ridge regression models using different representations show that features
based on linguistic theory similarly to word-based features. Overall, we show
that different linguistic choices do trigger different perceptions of
responsibility, and that such perceptions can be modelled automatically. This
work can be a core instrument to raise awareness of the consequences of
different perspectivizations in the general public and in news producers alike."
A Reinforcement Learning Approach for Electric Vehicle Routing Problem with Vehicle-to-Grid Supply,0.18992,"The use of electric vehicles (EV) in the last mile is appealing from both
sustainability and operational cost perspectives. In addition to the inherent
cost efficiency of EVs, selling energy back to the grid during peak grid
demand, is a potential source of additional revenue to a fleet operator. To
achieve this, EVs have to be at specific locations (discharge points) during
specific points in time (peak period), even while meeting their core purpose of
delivering goods to customers. In this work, we consider the problem of EV
routing with constraints on loading capacity; time window; vehicle-to-grid
energy supply (CEVRPTW-D); which not only satisfy multiple system objectives,
but also scale efficiently to large problem sizes involving hundreds of
customers and discharge stations. We present QuikRouteFinder that uses
reinforcement learning (RL) for EV routing to overcome these challenges. Using
Solomon datasets, results from RL are compared against exact formulations based
on mixed-integer linear program (MILP) and genetic algorithm (GA)
metaheuristics. On an average, the results show that RL is 24 times faster than
MILP and GA, while being close in quality (within 20%) to the optimal."
A Dynamic Graph Interactive Framework with Label-Semantic Injection for Spoken Language Understanding,0.172606,"Multi-intent detection and slot filling joint models are gaining increasing
traction since they are closer to complicated real-world scenarios. However,
existing approaches (1) focus on identifying implicit correlations between
utterances and one-hot encoded labels in both tasks while ignoring explicit
label characteristics; (2) directly incorporate multi-intent information for
each token, which could lead to incorrect slot prediction due to the
introduction of irrelevant intent. In this paper, we propose a framework termed
DGIF, which first leverages the semantic information of labels to give the
model additional signals and enriched priors. Then, a multi-grain interactive
graph is constructed to model correlations between intents and slots.
Specifically, we propose a novel approach to construct the interactive graph
based on the injection of label semantics, which can automatically update the
graph to better alleviate error propagation. Experimental results show that our
framework significantly outperforms existing approaches, obtaining a relative
improvement of 13.7% over the previous best model on the MixATIS dataset in
overall accuracy."
Over-the-Air Computation over Balanced Numerals,0.0649398,"In this study, a digital over-the-air computation (OAC) scheme for achieving
continuous-valued gradient aggregation is proposed. It is shown that the
average of a set of real-valued parameters can be calculated approximately by
using the average of the corresponding numerals, where the numerals are
obtained based on a balanced number system. By using this property, the
proposed scheme encodes the local gradients into a set of numerals. It then
determines the positions of the activated orthogonal frequency division
multiplexing (OFDM) subcarriers by using the values of the numerals. To
eliminate the need for a precise sample-level time synchronization, channel
estimation overhead, and power instabilities due to the channel inversion, the
proposed scheme also uses a non-coherent receiver at the edge server (ES) and
does not utilize a pre-equalization at the edge devices (EDs). Finally, the
theoretical mean squared error (MSE) performance of the proposed scheme is
derived and its performance for federated edge learning (FEEL) is demonstrated."
Black-box Few-shot Knowledge Distillation,0.11866,"Knowledge distillation (KD) is an efficient approach to transfer the
knowledge from a large ""teacher"" network to a smaller ""student"" network.
Traditional KD methods require lots of labeled training samples and a white-box
teacher (parameters are accessible) to train a good student. However, these
resources are not always available in real-world applications. The distillation
process often happens at an external party side where we do not have access to
much data, and the teacher does not disclose its parameters due to security and
privacy concerns. To overcome these challenges, we propose a black-box few-shot
KD method to train the student with few unlabeled training samples and a
black-box teacher. Our main idea is to expand the training set by generating a
diverse set of out-of-distribution synthetic images using MixUp and a
conditional variational auto-encoder. These synthetic images along with their
labels obtained from the teacher are used to train the student. We conduct
extensive experiments to show that our method significantly outperforms recent
SOTA few/zero-shot KD methods on image classification tasks. The code and
models are available at: https://github.com/nphdang/FS-BBT"
Divert More Attention to Vision-Language Tracking,0.108333,"Relying on Transformer for complex visual feature learning, object tracking
has witnessed the new standard for state-of-the-arts (SOTAs). However, this
advancement accompanies by larger training data and longer training period,
making tracking increasingly expensive. In this paper, we demonstrate that the
Transformer-reliance is not necessary and the pure ConvNets are still
competitive and even better yet more economical and friendly in achieving SOTA
tracking. Our solution is to unleash the power of multimodal vision-language
(VL) tracking, simply using ConvNets. The essence lies in learning novel
unified-adaptive VL representations with our modality mixer (ModaMixer) and
asymmetrical ConvNet search. We show that our unified-adaptive VL
representation, learned purely with the ConvNets, is a simple yet strong
alternative to Transformer visual features, by unbelievably improving a
CNN-based Siamese tracker by 14.5% in SUC on challenging LaSOT (50.7% > 65.2%),
even outperforming several Transformer-based SOTA trackers. Besides empirical
results, we theoretically analyze our approach to evidence its effectiveness.
By revealing the potential of VL representation, we expect the community to
divert more attention to VL tracking and hope to open more possibilities for
future tracking beyond Transformer. Code and models will be released at
https://github.com/JudasDie/SOTS."
"Decentralized, Communication- and Coordination-free Learning in Structured Matching Markets",0.0318173,"We study the problem of online learning in competitive settings in the
context of two-sided matching markets. In particular, one side of the market,
the agents, must learn about their preferences over the other side, the firms,
through repeated interaction while competing with other agents for successful
matches. We propose a class of decentralized, communication- and
coordination-free algorithms that agents can use to reach to their stable match
in structured matching markets. In contrast to prior works, the proposed
algorithms make decisions based solely on an agent's own history of play and
requires no foreknowledge of the firms' preferences. Our algorithms are
constructed by splitting up the statistical problem of learning one's
preferences, from noisy observations, from the problem of competing for firms.
We show that under realistic structural assumptions on the underlying
preferences of the agents and firms, the proposed algorithms incur a regret
which grows at most logarithmically in the time horizon. Our results show that,
in the case of matching markets, competition need not drastically affect the
performance of decentralized, communication and coordination free online
learning algorithms."
Leveraging Graph-based Cross-modal Information Fusion for Neural Sign Language Translation,0.112966,"Sign Language (SL), as the mother tongue of the deaf community, is a special
visual language that most hearing people cannot understand. In recent years,
neural Sign Language Translation (SLT), as a possible way for bridging
communication gap between the deaf and the hearing people, has attracted
widespread academic attention. We found that the current mainstream end-to-end
neural SLT models, which tries to learning language knowledge in a weakly
supervised manner, could not mine enough semantic information under the
condition of low data resources. Therefore, we propose to introduce additional
word-level semantic knowledge of sign language linguistics to assist in
improving current end-to-end neural SLT models. Concretely, we propose a novel
neural SLT model with multi-modal feature fusion based on the dynamic graph, in
which the cross-modal information, i.e. text and video, is first assembled as a
dynamic graph according to their correlation, and then the graph is processed
by a multi-modal graph encoder to generate the multi-modal embeddings for
further usage in the subsequent neural translation models. To the best of our
knowledge, we are the first to introduce graph neural networks, for fusing
multi-modal information, into neural sign language translation models.
Moreover, we conducted experiments on a publicly available popular SLT dataset
RWTH-PHOENIX-Weather-2014T. and the quantitative experiments show that our
method can improve the model."
BoundaryFace: A mining framework with noise label self-correction for Face Recognition,-1.0,"Face recognition has made tremendous progress in recent years due to the
advances in loss functions and the explosive growth in training sets size. A
properly designed loss is seen as key to extract discriminative features for
classification. Several margin-based losses have been proposed as alternatives
of softmax loss in face recognition. However, two issues remain to consider: 1)
They overlook the importance of hard sample mining for discriminative learning.
2) Label noise ubiquitously exists in large-scale datasets, which can seriously
damage the model's performance. In this paper, starting from the perspective of
decision boundary, we propose a novel mining framework that focuses on the
relationship between a sample's ground truth class center and its nearest
negative class center. Specifically, a closed-set noise label self-correction
module is put forward, making this framework work well on datasets containing a
lot of label noise. The proposed method consistently outperforms SOTA methods
in various face recognition benchmarks. Training code has been released at
https://github.com/SWJTU-3DVision/BoundaryFace."
Learning Facial Liveness Representation for Domain Generalized Face Anti-spoofing,0.0164092,"Face anti-spoofing (FAS) aims at distinguishing face spoof attacks from the
authentic ones, which is typically approached by learning proper models for
performing the associated classification task. In practice, one would expect
such models to be generalized to FAS in different image domains. Moreover, it
is not practical to assume that the type of spoof attacks would be known in
advance. In this paper, we propose a deep learning model for addressing the
aforementioned domain-generalized face anti-spoofing task. In particular, our
proposed network is able to disentangle facial liveness representation from the
irrelevant ones (i.e., facial content and image domain features). The resulting
liveness representation exhibits sufficient domain invariant properties, and
thus it can be applied for performing domain-generalized FAS. In our
experiments, we conduct experiments on five benchmark datasets with various
settings, and we verify that our model performs favorably against
state-of-the-art approaches in identifying novel types of spoof attacks in
unseen image domains."
From Multi-agent to Multi-robot: A Scalable Training and Evaluation Platform for Multi-robot Reinforcement Learning,0.154587,"Multi-agent reinforcement learning (MARL) has been gaining extensive
attention from academia and industries in the past few decades. One of the
fundamental problems in MARL is how to evaluate different approaches
comprehensively. Most existing MARL methods are evaluated in either video games
or simplistic simulated scenarios. It remains unknown how these methods perform
in real-world scenarios, especially multi-robot systems. This paper introduces
a scalable emulation platform for multi-robot reinforcement learning (MRRL)
called SMART to meet this need. Precisely, SMART consists of two components: 1)
a simulation environment that provides a variety of complex interaction
scenarios for training and 2) a real-world multi-robot system for realistic
performance evaluation. Besides, SMART offers agent-environment APIs that are
plug-and-play for algorithm implementation. To illustrate the practicality of
our platform, we conduct a case study on the cooperative driving lane change
scenario. Building off the case study, we summarize several unique challenges
of MRRL, which are rarely considered previously. Finally, we open-source the
simulation environments, associated benchmark tasks, and state-of-the-art
baselines to encourage and empower MRRL research."
Selective Residual M-Net for Real Image Denoising,0.617815,"Image restoration is a low-level vision task which is to restore degraded
images to noise-free images. With the success of deep neural networks, the
convolutional neural networks surpass the traditional restoration methods and
become the mainstream in the computer vision area. To advance the performanceof
denoising algorithms, we propose a blind real image denoising network (SRMNet)
by employing a hierarchical architecture improved from U-Net. Specifically, we
use a selective kernel with residual block on the hierarchical structure called
M-Net to enrich the multi-scale semantic information. Furthermore, our SRMNet
has competitive performance results on two synthetic and two real-world noisy
datasets in terms of quantitative metrics and visual quality. The source code
and pretrained model are available at
https://github.com/TentativeGitHub/SRMNet."
Free-HeadGAN: Neural Talking Head Synthesis with Explicit Gaze Control,0.012757,"We present Free-HeadGAN, a person-generic neural talking head synthesis
system. We show that modeling faces with sparse 3D facial landmarks are
sufficient for achieving state-of-the-art generative performance, without
relying on strong statistical priors of the face, such as 3D Morphable Models.
Apart from 3D pose and facial expressions, our method is capable of fully
transferring the eye gaze, from a driving actor to a source identity. Our
complete pipeline consists of three components: a canonical 3D key-point
estimator that regresses 3D pose and expression-related deformations, a gaze
estimation network and a generator that is built upon the architecture of
HeadGAN. We further experiment with an extension of our generator to
accommodate few-shot learning using an attention mechanism, in case more than
one source images are available. Compared to the latest models for reenactment
and motion transfer, our system achieves higher photo-realism combined with
superior identity preservation, while offering explicit gaze control."
Back to the Roots: Reconstructing Large and Complex Cranial Defects using an Image-based Statistical Shape Model,0.0136326,"Designing implants for large and complex cranial defects is a challenging
task, even for professional designers. Current efforts on automating the design
process focused mainly on convolutional neural networks (CNN), which have
produced state-of-the-art results on reconstructing synthetic defects. However,
existing CNN-based methods have been difficult to translate to clinical
practice in cranioplasty, as their performance on complex and irregular cranial
defects remains unsatisfactory. In this paper, a statistical shape model (SSM)
built directly on the segmentation masks of the skulls is presented. We
evaluate the SSM on several cranial implant design tasks, and the results show
that, while the SSM performs suboptimally on synthetic defects compared to
CNN-based approaches, it is capable of reconstructing large and complex defects
with only minor manual corrections. The quality of the resulting implants is
examined and assured by experienced neurosurgeons. In contrast, CNN-based
approaches, even with massive data augmentation, fail or produce
less-than-satisfactory implants for these cases. Codes are publicly available
at https://github.com/Jianningli/ssm"
Enhancing Deformable Convolution based Video Frame Interpolation with Coarse-to-fine 3D CNN,0.105286,"This paper presents a new deformable convolution-based video frame
interpolation (VFI) method, using a coarse to fine 3D CNN to enhance the
multi-flow prediction. This model first extracts spatio-temporal features at
multiple scales using a 3D CNN, and estimates multi-flows using these features
in a coarse-to-fine manner. The estimated multi-flows are then used to warp the
original input frames as well as context maps, and the warped results are fused
by a synthesis network to produce the final output. This VFI approach has been
fully evaluated against 12 state-of-the-art VFI methods on three commonly used
test databases. The results evidently show the effectiveness of the proposed
method, which offers superior interpolation performance over other state of the
art algorithms, with PSNR gains up to 0.19dB."
Toward More Meaningful Resources for Lower-resourced Languages,0.291206,"In this position paper, we describe our perspective on how meaningful
resources for lower-resourced languages should be developed in connection with
the speakers of those languages. We first examine two massively multilingual
resources in detail. We explore the contents of the names stored in Wikidata
for a few lower-resourced languages and find that many of them are not in fact
in the languages they claim to be and require non-trivial effort to correct. We
discuss quality issues present in WikiAnn and evaluate whether it is a useful
supplement to hand annotated data. We then discuss the importance of creating
annotation for lower-resourced languages in a thoughtful and ethical way that
includes the languages' speakers as part of the development process. We
conclude with recommended guidelines for resource development."
Dialogue Meaning Representation for Task-Oriented Dialogue Systems,0.026946,"Dialogue meaning representation formulates natural language utterance
semantics in their conversational context in an explicit and machine-readable
form. Previous work typically follows the intent-slot framework, which is easy
for annotation yet limited in scalability for complex linguistic expressions. A
line of works alleviates the representation issue by introducing hierarchical
structures but challenging to express complex compositional semantics, such as
negation and coreference. We propose Dialogue Meaning Representation (DMR), a
pliable and easily extendable representation for task-oriented dialogue. Our
representation contains a set of nodes and edges to represent rich
compositional semantics. Moreover, we propose an inheritance hierarchy
mechanism focusing on domain extensibility. Additionally, we annotated
DMR-FastFood, a multi-turn dialogue dataset with more than 70k utterances, with
DMR. We propose two evaluation tasks to evaluate different dialogue models and
a novel coreference resolution model GNNCoref for the graph-based coreference
resolution task. Experiments show that DMR can be parsed well with pre-trained
Seq2Seq models, and GNNCoref outperforms the baseline models by a large margin."
Super-resolution 3D Human Shape from a Single Low-Resolution Image,0.0896018,"We propose a novel framework to reconstruct super-resolution human shape from
a single low-resolution input image. The approach overcomes limitations of
existing approaches that reconstruct 3D human shape from a single image, which
require high-resolution images together with auxiliary data such as surface
normal or a parametric model to reconstruct high-detail shape. The proposed
framework represents the reconstructed shape with a high-detail implicit
function. Analogous to the objective of 2D image super-resolution, the approach
learns the mapping from a low-resolution shape to its high-resolution
counterpart and it is applied to reconstruct 3D shape detail from
low-resolution images. The approach is trained end-to-end employing a novel
loss function which estimates the information lost between a low and
high-resolution representation of the same 3D surface shape. Evaluation for
single image reconstruction of clothed people demonstrates that our method
achieves high-detail surface reconstruction from low-resolution images without
auxiliary data. Extensive experiments show that the proposed approach can
estimate super-resolution human geometries with a significantly higher level of
detail than that obtained with previous approaches when applied to
low-resolution images."
Multi-channel Attentive Graph Convolutional Network With Sentiment Fusion For Multimodal Sentiment Analysis,0.102171,"Nowadays, with the explosive growth of multimodal reviews on social media
platforms, multimodal sentiment analysis has recently gained popularity because
of its high relevance to these social media posts. Although most previous
studies design various fusion frameworks for learning an interactive
representation of multiple modalities, they fail to incorporate sentimental
knowledge into inter-modality learning. This paper proposes a Multi-channel
Attentive Graph Convolutional Network (MAGCN), consisting of two main
components: cross-modality interactive learning and sentimental feature fusion.
For cross-modality interactive learning, we exploit the self-attention
mechanism combined with densely connected graph convolutional networks to learn
inter-modality dynamics. For sentimental feature fusion, we utilize multi-head
self-attention to merge sentimental knowledge into inter-modality feature
representations. Extensive experiments are conducted on three widely-used
datasets. The experimental results demonstrate that the proposed model achieves
competitive performance on accuracy and F1 scores compared to several
state-of-the-art approaches."
An Intermediate-level Attack Framework on The Basis of Linear Regression,0.0618903,"This paper substantially extends our work published at ECCV, in which an
intermediate-level attack was proposed to improve the transferability of some
baseline adversarial examples. Specifically, we advocate a framework in which a
direct linear mapping from the intermediate-level discrepancies (between
adversarial features and benign features) to prediction loss of the adversarial
example is established. By delving deep into the core components of such a
framework, we show that 1) a variety of linear regression models can all be
considered in order to establish the mapping, 2) the magnitude of the finally
obtained intermediate-level adversarial discrepancy is correlated with the
transferability, 3) further boost of the performance can be achieved by
performing multiple runs of the baseline attack with random initialization. In
addition, by leveraging these findings, we achieve new state-of-the-arts on
transfer-based $\ell_\infty$ and $\ell_2$ attacks. Our code is publicly
available at https://github.com/qizhangli/ila-plus-plus-lr."
AnyMorph: Learning Transferable Polices By Inferring Agent Morphology,0.148696,"The prototypical approach to reinforcement learning involves training
policies tailored to a particular agent from scratch for every new morphology.
Recent work aims to eliminate the re-training of policies by investigating
whether a morphology-agnostic policy, trained on a diverse set of agents with
similar task objectives, can be transferred to new agents with unseen
morphologies without re-training. This is a challenging problem that required
previous approaches to use hand-designed descriptions of the new agent's
morphology. Instead of hand-designing this description, we propose a
data-driven method that learns a representation of morphology directly from the
reinforcement learning objective. Ours is the first reinforcement learning
algorithm that can train a policy to generalize to new agent morphologies
without requiring a description of the agent's morphology in advance. We
evaluate our approach on the standard benchmark for agent-agnostic control, and
improve over the current state of the art in zero-shot generalization to new
agents. Importantly, our method attains good performance without an explicit
description of morphology."
Frontiers and Exact Learning of ELI Queries under DL-Lite Ontologies,0.977392,"We study ELI queries (ELIQs) in the presence of ontologies formulated in the
description logic DL-Lite. For the dialect DL-LiteH, we show that ELIQs have a
frontier (set of least general generalizations) that is of polynomial size and
can be computed in polynomial time. In the dialect DL-LiteF, in contrast,
frontiers may be infinite. We identify a natural syntactic restriction that
enables the same positive results as for DL-LiteH. We use out results on
frontiers to show that ELIQs are learnable in polynomial time in the presence
of a DL-LiteH / restricted DL-LiteF ontology in Angluin's framework of exact
learning with only membership queries."
Deep Hyperspectral-Depth Reconstruction Using Single Color-Dot Projection,0.0434247,"Depth reconstruction and hyperspectral reflectance reconstruction are two
active research topics in computer vision and image processing. Conventionally,
these two topics have been studied separately using independent imaging setups
and there is no existing method which can acquire depth and spectral
reflectance simultaneously in one shot without using special hardware. In this
paper, we propose a novel single-shot hyperspectral-depth reconstruction method
using an off-the-shelf RGB camera and projector. Our method is based on a
single color-dot projection, which simultaneously acts as structured light for
depth reconstruction and spatially-varying color illuminations for
hyperspectral reflectance reconstruction. To jointly reconstruct the depth and
the hyperspectral reflectance from a single color-dot image, we propose a novel
end-to-end network architecture that effectively incorporates a geometric
color-dot pattern loss and a photometric hyperspectral reflectance loss.
Through the experiments, we demonstrate that our hyperspectral-depth
reconstruction method outperforms the combination of an existing
state-of-the-art single-shot hyperspectral reflectance reconstruction method
and depth reconstruction method."
Test-Time Training for Graph Neural Networks,0.0176096,"Graph Neural Networks (GNNs) have made tremendous progress in the graph
classification task. However, a performance gap between the training set and
the test set has often been noticed. To bridge such gap, in this work we
introduce the first test-time training framework for GNNs to enhance the model
generalization capacity for the graph classification task. In particular, we
design a novel test-time training strategy with self-supervised learning to
adjust the GNN model for each test graph sample. Experiments on the benchmark
datasets have demonstrated the effectiveness of the proposed framework,
especially when there are distribution shifts between training set and test
set. We have also conducted exploratory studies and theoretical analysis to
gain deeper understandings on the rationality of the design of the proposed
graph test time training framework (GT3)."
In-context Learning Distillation: Transferring Few-shot Learning Ability of Pre-trained Language Models,0.617843,"Given the success with in-context learning of large pre-trained language
models, we introduce in-context learning distillation to transfer in-context
few-shot learning ability from large models to smaller models. We propose to
combine in-context learning objectives with language modeling objectives to
distill both the ability to read in-context examples and task knowledge to the
smaller models. We perform in-context learning distillation under two different
few-shot learning paradigms: Meta In-context Tuning (Meta-ICT) and Multitask
In-context Tuning (Multitask-ICT). Multitask-ICT performs better on multitask
few-shot learning but also requires more computation than Meta-ICT. Our method
shows consistent improvements for both Meta-ICT and Multitask-ICT on two
benchmarks: LAMA and CrossFit. Our extensive experiments and analysis reveal
that in-context learning objectives and language modeling objectives are
complementary under the Multitask-ICT paradigm. In-context learning objectives
achieve the best performance when combined with language modeling objectives."
Multi-task Active Learning for Pre-trained Transformer-based Models,0.179688,"Multi-task learning, in which several tasks are jointly learned by a single
model, allows NLP models to share information from multiple annotations and may
facilitate better predictions when the tasks are inter-related. This technique,
however, requires annotating the same text with multiple annotation schemes
which may be costly and laborious. Active learning (AL) has been demonstrated
to optimize annotation processes by iteratively selecting unlabeled examples
whose annotation is most valuable for the NLP model. Yet, multi-task active
learning (MT-AL) has not been applied to state-of-the-art pre-trained
Transformer-based NLP models. This paper aims to close this gap. We explore
various multi-task selection criteria in three realistic multi-task scenarios,
reflecting different relations between the participating tasks, and demonstrate
the effectiveness of multi-task compared to single-task selection. Our results
suggest that MT-AL can be effectively used in order to minimize annotation
efforts for multi-task NLP models."
DialCrowd 2.0: A Quality-Focused Dialog System Crowdsourcing Toolkit,0.033941,"Dialog system developers need high-quality data to train, fine-tune and
assess their systems. They often use crowdsourcing for this since it provides
large quantities of data from many workers. However, the data may not be of
sufficiently good quality. This can be due to the way that the requester
presents a task and how they interact with the workers. This paper introduces
DialCrowd 2.0 to help requesters obtain higher quality data by, for example,
presenting tasks more clearly and facilitating effective communication with
workers. DialCrowd 2.0 guides developers in creating improved Human
Intelligence Tasks (HITs) and is directly applicable to the workflows used
currently by developers and researchers."
Deep Speech Based End-to-End Automated Speech Recognition (ASR) for Indian-English Accents,0.186141,"Automated Speech Recognition (ASR) is an interdisciplinary application of
computer science and linguistics that enable us to derive the transcription
from the uttered speech waveform. It finds several applications in Military
like High-performance fighter aircraft, helicopters, air-traffic controller.
Other than military speech recognition is used in healthcare, persons with
disabilities and many more. ASR has been an active research area. Several
models and algorithms for speech to text (STT) have been proposed. One of the
most recent is Mozilla Deep Speech, it is based on the Deep Speech research
paper by Baidu. Deep Speech is a state-of-art speech recognition system is
developed using end-to-end deep learning, it is trained using well-optimized
Recurrent Neural Network (RNN) training system utilizing multiple Graphical
Processing Units (GPUs). This training is mostly done using American-English
accent datasets, which results in poor generalizability to other English
accents. India is a land of vast diversity. This can even be seen in the
speech, there are several English accents which vary from state to state. In
this work, we have used transfer learning approach using most recent Deep
Speech model i.e., deepspeech-0.9.3 to develop an end-to-end speech recognition
system for Indian-English accents. This work utilizes fine-tuning and data
argumentation to further optimize and improve the Deep Speech ASR system. Indic
TTS data of Indian-English accents is used for transfer learning and
fine-tuning the pre-trained Deep Speech model. A general comparison is made
among the untrained model, our trained model and other available speech
recognition services for Indian-English Accents."
Domain-Generalized Textured Surface Anomaly Detection,0.0629535,"Anomaly detection aims to identify abnormal data that deviates from the
normal ones, while typically requiring a sufficient amount of normal data to
train the model for performing this task. Despite the success of recent anomaly
detection methods, performing anomaly detection in an unseen domain remain a
challenging task. In this paper, we address the task of domain-generalized
textured surface anomaly detection. By observing normal and abnormal surface
data across multiple source domains, our model is expected to be generalized to
an unseen textured surface of interest, in which only a small number of normal
data can be observed during testing. Although with only image-level labels
observed in the training data, our patch-based meta-learning model exhibits
promising generalization ability: not only can it generalize to unseen image
domains, but it can also localize abnormal regions in the query image. Our
experiments verify that our model performs favorably against state-of-the-art
anomaly detection and domain generalization approaches in various settings."
Attention Distraction: Watermark Removal Through Continual Learning with Selective Forgetting,0.0345016,"Fine-tuning attacks are effective in removing the embedded watermarks in deep
learning models. However, when the source data is unavailable, it is
challenging to just erase the watermark without jeopardizing the model
performance. In this context, we introduce Attention Distraction (AD), a novel
source data-free watermark removal attack, to make the model selectively forget
the embedded watermarks by customizing continual learning. In particular, AD
first anchors the model's attention on the main task using some unlabeled data.
Then, through continual learning, a small number of \textit{lures} (randomly
selected natural images) that are assigned a new label distract the model's
attention away from the watermarks. Experimental results from different
datasets and networks corroborate that AD can thoroughly remove the watermark
with a small resource budget without compromising the model's performance on
the main task, which outperforms the state-of-the-art works."
Policy Optimization over General State and Action Spaces,0.0365223,"Reinforcement learning (RL) problems over general state and action spaces are
notoriously challenging. In contrast to the tableau setting, one can not
enumerate all the states and then iteratively update the policies for each
state. This prevents the application of many well-studied RL methods especially
those with provable convergence guarantees. In this paper, we first present a
substantial generalization of the recently developed policy mirror descent
method to deal with general state and action spaces. We introduce new
approaches to incorporate function approximation into this method, so that we
do not need to use explicit policy parameterization at all. Moreover, we
present a novel policy dual averaging method for which possibly simpler
function approximation techniques can be applied. We establish linear
convergence rate to global optimality or sublinear convergence to stationarity
for these methods applied to solve different classes of RL problems under exact
policy evaluation. We then define proper notions of the approximation errors
for policy evaluation and investigate their impact on the convergence of these
methods applied to general-state RL problems with either finite-action or
continuous-action spaces. To the best of our knowledge, the development of
these algorithmic frameworks as well as their convergence analysis appear to be
new in the literature."
Stochastic analysis of the Elo rating algorithm in round-robin tournaments,0.049866,"The Elo algorithm, renowned for its simplicity, is widely used for rating in
sports tournaments and other applications. However, despite its widespread use,
a detailed understanding of the convergence characteristics of the Elo
algorithm is still lacking. Aiming to fill this gap, this paper presents a
comprehensive (stochastic) analysis of the Elo algorithm, considering
round-robin tournaments. Specifically, analytical expressions are derived
describing the evolution of the skills and performance metrics. Then, taking
into account the relationship between the behavior of the algorithm and the
step-size value, which is a hyperparameter that can be controlled, design
guidelines and discussions about the performance of the algorithm are provided.
Experimental results are shown confirming the accuracy of the analysis and
illustrating the applicability of the theoretical findings using real-world
data obtained from SuperLega, the Italian volleyball league."
The Naughtyformer: A Transformer Understands Offensive Humor,0.0488934,"Jokes are intentionally written to be funny, but not all jokes are created
the same. Some jokes may be fit for a classroom of kindergarteners, but others
are best reserved for a more mature audience. While recent work has shown
impressive results on humor detection in text, here we instead investigate the
more nuanced task of detecting humor subtypes, especially of the less innocent
variety. To that end, we introduce a novel jokes dataset filtered from Reddit
and solve the subtype classification task using a finetuned Transformer dubbed
the Naughtyformer. Moreover, we show that our model is significantly better at
detecting offensiveness in jokes compared to state-of-the-art methods."
AI Art in Architecture,0.0,"Recent diffusion-based AI art platforms are able to create impressive images
from simple text descriptions. This makes them powerful tools for concept
design in any discipline that requires creativity in visual design tasks. This
is also true for early stages of architectural design with multiple stages of
ideation, sketching and modelling. In this paper, we investigate how applicable
diffusion-based models already are to these tasks. We research the
applicability of the platforms Midjourney, DALL-E 2 and StableDiffusion to a
series of common use cases in architectural design to determine which are
already solvable or might soon be. We also analyze how they are already being
used by analyzing a data set of 40 million Midjourney queries with NLP methods
to extract common usage patterns. With this insights we derived a workflow to
interior and exterior design that combines the strengths of the individual
platforms."
Vector Quantized Semantic Communication System,0.180754,"Although analog semantic communication systems have received considerable
attention in the literature, there is less work on digital semantic
communication systems. In this paper, we develop a deep learning (DL)-enabled
vector quantized (VQ) semantic communication system for image transmission,
named VQ-DeepSC. Specifically, we propose a convolutional neural network
(CNN)-based transceiver to extract multi-scale semantic features of images and
introduce multi-scale semantic embedding spaces to perform semantic feature
quantization, rendering the data compatible with digital communication systems.
Furthermore, we employ adversarial training to improve the quality of received
images by introducing a PatchGAN discriminator. Experimental results
demonstrate that the proposed VQ-DeepSC is more robustness than BPG in digital
communication systems and has comparable MS-SSIM performance to the DeepJSCC
method."
Constrained Bundle Adjustment for Structure From Motion Using Uncalibrated Multi-Camera Systems,0.0405732,"Structure from motion using uncalibrated multi-camera systems is a
challenging task. This paper proposes a bundle adjustment solution that
implements a baseline constraint respecting that these cameras are static to
each other. We assume these cameras are mounted on a mobile platform,
uncalibrated, and coarsely synchronized. To this end, we propose the baseline
constraint that is formulated for the scenario in which the cameras have
overlapping views. The constraint is incorporated in the bundle adjustment
solution to keep the relative motion of different cameras static. Experiments
were conducted using video frames of two collocated GoPro cameras mounted on a
vehicle with no system calibration. These two cameras were placed capturing
overlapping contents. We performed our bundle adjustment using the proposed
constraint and then produced 3D dense point clouds. Evaluations were performed
by comparing these dense point clouds against LiDAR reference data. We showed
that, as compared to traditional bundle adjustment, our proposed method
achieved an improvement of 29.38%."
Bilingual Synchronization: Restoring Translational Relationships with Editing Operations,0.031569,"Machine Translation (MT) is usually viewed as a one-shot process that
generates the target language equivalent of some source text from scratch. We
consider here a more general setting which assumes an initial target sequence,
that must be transformed into a valid translation of the source, thereby
restoring parallelism between source and target. For this bilingual
synchronization task, we consider several architectures (both autoregressive
and non-autoregressive) and training regimes, and experiment with multiple
practical settings such as simulated interactive MT, translating with
Translation Memory (TM) and TM cleaning. Our results suggest that one single
generic edit-based system, once fine-tuned, can compare with, or even
outperform, dedicated systems specifically trained for these tasks."
On the Utility of Prediction Sets in Human-AI Teams,0.0213838,"Research on human-AI teams usually provides experts with a single label,
which ignores the uncertainty in a model's recommendation. Conformal prediction
(CP) is a well established line of research that focuses on building a
theoretically grounded, calibrated prediction set, which may contain multiple
labels. We explore how such prediction sets impact expert decision-making in
human-AI teams. Our evaluation on human subjects finds that set valued
predictions positively impact experts. However, we notice that the predictive
sets provided by CP can be very large, which leads to unhelpful AI assistants.
To mitigate this, we introduce D-CP, a method to perform CP on some examples
and defer to experts. We prove that D-CP can reduce the prediction set size of
non-deferred examples. We show how D-CP performs in quantitative and in human
subject experiments ($n=120$). Our results suggest that CP prediction sets
improve human-AI team performance over showing the top-1 prediction alone, and
that experts find D-CP prediction sets are more useful than CP prediction sets."
Heterformer: Transformer-based Deep Node Representation Learning on Heterogeneous Text-Rich Networks,0.864665,"Representation learning on networks aims to derive a meaningful vector
representation for each node, thereby facilitating downstream tasks such as
link prediction, node classification, and node clustering. In heterogeneous
text-rich networks, this task is more challenging due to (1) presence or
absence of text: Some nodes are associated with rich textual information, while
others are not; (2) diversity of types: Nodes and edges of multiple types form
a heterogeneous network structure. As pretrained language models (PLMs) have
demonstrated their effectiveness in obtaining widely generalizable text
representations, a substantial amount of effort has been made to incorporate
PLMs into representation learning on text-rich networks. However, few of them
can jointly consider heterogeneous structure (network) information as well as
rich textual semantic information of each node effectively. In this paper, we
propose Heterformer, a Heterogeneous Network-Empowered Transformer that
performs contextualized text encoding and heterogeneous structure encoding in a
unified model. Specifically, we inject heterogeneous structure information into
each Transformer layer when encoding node texts. Meanwhile, Heterformer is
capable of characterizing node/edge type heterogeneity and encoding nodes with
or without texts. We conduct comprehensive experiments on three tasks (i.e.,
link prediction, node classification, and node clustering) on three large-scale
datasets from different domains, where Heterformer outperforms competitive
baselines significantly and consistently."
Czech Dataset for Cross-lingual Subjectivity Classification,0.1393,"In this paper, we introduce a new Czech subjectivity dataset of 10k manually
annotated subjective and objective sentences from movie reviews and
descriptions. Our prime motivation is to provide a reliable dataset that can be
used with the existing English dataset as a benchmark to test the ability of
pre-trained multilingual models to transfer knowledge between Czech and English
and vice versa. Two annotators annotated the dataset reaching 0.83 of the
Cohen's \k{appa} inter-annotator agreement. To the best of our knowledge, this
is the first subjectivity dataset for the Czech language. We also created an
additional dataset that consists of 200k automatically labeled sentences. Both
datasets are freely available for research purposes. Furthermore, we fine-tune
five pre-trained BERT-like models to set a monolingual baseline for the new
dataset and we achieve 93.56% of accuracy. We fine-tune models on the existing
English dataset for which we obtained results that are on par with the current
state-of-the-art results. Finally, we perform zero-shot cross-lingual
subjectivity classification between Czech and English to verify the usability
of our dataset as the cross-lingual benchmark. We compare and discuss the
cross-lingual and monolingual results and the ability of multilingual models to
transfer knowledge between languages."
Data-driven End-to-end Learning of Pole Placement Control for Nonlinear Dynamics via Koopman Invariant Subspaces,0.025636,"We propose a data-driven method for controlling the frequency and convergence
rate of black-box nonlinear dynamical systems based on the Koopman operator
theory. With the proposed method, a policy network is trained such that the
eigenvalues of a Koopman operator of controlled dynamics are close to the
target eigenvalues. The policy network consists of a neural network to find a
Koopman invariant subspace, and a pole placement module to adjust the
eigenvalues of the Koopman operator. Since the policy network is
differentiable, we can train it in an end-to-end fashion using reinforcement
learning. We demonstrate that the proposed method achieves better performance
than model-free reinforcement learning and model-based control with system
identification."
Lahjoita puhetta -- a large-scale corpus of spoken Finnish with some benchmarks,0.540019,"The Donate Speech campaign has so far succeeded in gathering approximately
3600 hours of ordinary, colloquial Finnish speech into the Lahjoita puhetta
(Donate Speech) corpus. The corpus includes over twenty thousand speakers from
all the regions of Finland and from all age brackets. The primary goals of the
collection were to create a representative, large-scale resource to study
spontaneous spoken Finnish and to accelerate the development of language
technology and speech-based services. In this paper, we present the collection
process and the collected corpus, and showcase its versatility through multiple
use cases. The evaluated use cases include: automatic speech recognition of
spontaneous speech, detection of age, gender, dialect and topic and metadata
analysis. We provide benchmarks for the use cases, as well down loadable,
trained baseline systems with open-source code for reproducibility. One further
use case is to verify the metadata and transcripts given in this corpus itself,
and to suggest artificial metadata and transcripts for the part of the corpus
where it is missing."
Applying wav2vec2 for Speech Recognition on Bengali Common Voices Dataset,0.846832,"Speech is inherently continuous, where discrete words, phonemes and other
units are not clearly segmented, and so speech recognition has been an active
research problem for decades. In this work we have fine-tuned wav2vec 2.0 to
recognize and transcribe Bengali speech -- training it on the Bengali Common
Voice Speech Dataset. After training for 71 epochs, on a training set
consisting of 36919 mp3 files, we achieved a training loss of 0.3172 and WER of
0.2524 on a validation set of size 7,747. Using a 5-gram language model, the
Levenshtein Distance was 2.6446 on a test set of size 7,747. Then the training
set and validation set were combined, shuffled and split into 85-15 ratio.
Training for 7 more epochs on this combined dataset yielded an improved
Levenshtein Distance of 2.60753 on the test set. Our model was the best
performing one, achieving a Levenshtein Distance of 6.234 on a hidden dataset,
which was 1.1049 units lower than other competing submissions."
Improving Retrieval Augmented Neural Machine Translation by Controlling Source and Fuzzy-Match Interactions,0.13271,"We explore zero-shot adaptation, where a general-domain model has access to
customer or domain specific parallel data at inference time, but not during
training. We build on the idea of Retrieval Augmented Translation (RAT) where
top-k in-domain fuzzy matches are found for the source sentence, and
target-language translations of those fuzzy-matched sentences are provided to
the translation model at inference time. We propose a novel architecture to
control interactions between a source sentence and the top-k fuzzy
target-language matches, and compare it to architectures from prior work. We
conduct experiments in two language pairs (En-De and En-Fr) by training models
on WMT data and testing them with five and seven multi-domain datasets,
respectively. Our approach consistently outperforms the alternative
architectures, improving BLEU across language pair, domain, and number k of
fuzzy matches."
Hearing voices at the National Library -- a speech corpus and acoustic model for the Swedish language,0.079097,"This paper explains our work in developing new acoustic models for automated
speech recognition (ASR) at KBLab, the infrastructure for data-driven research
at the National Library of Sweden (KB). We evaluate different approaches for a
viable speech-to-text pipeline for audiovisual resources in Swedish, using the
wav2vec 2.0 architecture in combination with speech corpuses created from KB's
collections. These approaches include pretraining an acoustic model for Swedish
from the ground up, and fine-tuning existing monolingual and multilingual
models. The collections-based corpuses we use have been sampled from millions
of hours of speech, with a conscious attempt to balance regional dialects to
produce a more representative, and thus more democratic, model. The acoustic
model this enabled, ""VoxRex"", outperforms existing models for Swedish ASR. We
also evaluate combining this model with various pretrained language models,
which further enhanced performance. We conclude by highlighting the potential
of such technology for cultural heritage institutions with vast collections of
previously unlabelled audiovisual data. Our models are released for further
exploration and research here: https://huggingface.co/KBLab."
Pushing the limits of fairness impossibility: Who's the fairest of them all?,0.0731101,"The impossibility theorem of fairness is a foundational result in the
algorithmic fairness literature. It states that outside of special cases, one
cannot exactly and simultaneously satisfy all three common and intuitive
definitions of fairness - demographic parity, equalized odds, and predictive
rate parity. This result has driven most works to focus on solutions for one or
two of the metrics. Rather than follow suit, in this paper we present a
framework that pushes the limits of the impossibility theorem in order to
satisfy all three metrics to the best extent possible. We develop an
integer-programming based approach that can yield a certifiably optimal
post-processing method for simultaneously satisfying multiple fairness criteria
under small violations. We show experiments demonstrating that our
post-processor can improve fairness across the different definitions
simultaneously with minimal model performance reduction. We also discuss
applications of our framework for model selection and fairness explainability,
thereby attempting to answer the question: who's the fairest of them all?"
Learning State-Aware Visual Representations from Audible Interactions,0.402428,"We propose a self-supervised algorithm to learn representations from
egocentric video data. Recently, significant efforts have been made to capture
humans interacting with their own environments as they go about their daily
activities. In result, several large egocentric datasets of interaction-rich
multi-modal data have emerged. However, learning representations from videos
can be challenging. First, given the uncurated nature of long-form continuous
videos, learning effective representations require focusing on moments in time
when interactions take place. Second, visual representations of daily
activities should be sensitive to changes in the state of the environment.
However, current successful multi-modal learning frameworks encourage
representation invariance over time. To address these challenges, we leverage
audio signals to identify moments of likely interactions which are conducive to
better learning. We also propose a novel self-supervised objective that learns
from audible state changes caused by interactions. We validate these
contributions extensively on two large-scale egocentric datasets,
EPIC-Kitchens-100 and the recently released Ego4D, and show improvements on
several downstream tasks, including action recognition, long-term action
anticipation, and object state change classification."
3D Equivariant Graph Implicit Functions,0.247297,"In recent years, neural implicit representations have made remarkable
progress in modeling of 3D shapes with arbitrary topology. In this work, we
address two key limitations of such representations, in failing to capture
local 3D geometric fine details, and to learn from and generalize to shapes
with unseen 3D transformations. To this end, we introduce a novel family of
graph implicit functions with equivariant layers that facilitates modeling fine
local details and guaranteed robustness to various groups of geometric
transformations, through local $k$-NN graph embeddings with sparse point set
observations at multiple resolutions. Our method improves over the existing
rotation-equivariant implicit function from 0.69 to 0.89 (IoU) on the ShapeNet
reconstruction task. We also show that our equivariant implicit function can be
extended to other types of similarity transformations and generalizes to unseen
translations and scaling."
"Self-supervised Learning for Human Activity Recognition Using 700,000 Person-days of Wearable Data",0.0584064,"Advances in deep learning for human activity recognition have been relatively
limited due to the lack of large labelled datasets. In this study, we leverage
self-supervised learning techniques on the UK-Biobank activity tracker
dataset--the largest of its kind to date--containing more than 700,000
person-days of unlabelled wearable sensor data. Our resulting activity
recognition model consistently outperformed strong baselines across seven
benchmark datasets, with an F1 relative improvement of 2.5%-100% (median
18.4%), the largest improvements occurring in the smaller datasets. In contrast
to previous studies, our results generalise across external datasets, devices,
and environments. Our open-source model will help researchers and developers to
build customisable and generalisable activity classifiers with high
performance."
Data Augmentation with Paraphrase Generation and Entity Extraction for Multimodal Dialogue System,0.233649,"Contextually aware intelligent agents are often required to understand the
users and their surroundings in real-time. Our goal is to build Artificial
Intelligence (AI) systems that can assist children in their learning process.
Within such complex frameworks, Spoken Dialogue Systems (SDS) are crucial
building blocks to handle efficient task-oriented communication with children
in game-based learning settings. We are working towards a multimodal dialogue
system for younger kids learning basic math concepts. Our focus is on improving
the Natural Language Understanding (NLU) module of the task-oriented SDS
pipeline with limited datasets. This work explores the potential benefits of
data augmentation with paraphrase generation for the NLU models trained on
small task-specific datasets. We also investigate the effects of extracting
entities for conceivably further data expansion. We have shown that
paraphrasing with model-in-the-loop (MITL) strategies using small seed data is
a promising approach yielding improved performance results for the Intent
Recognition task."
Towards Boosting the Open-Domain Chatbot with Human Feedback,0.0574009,"Many open-domain dialogue models pre-trained with social media comments can
generate coherent replies but have difficulties producing engaging responses
when interacting with real users. This phenomenon might mainly result from the
deficiency of annotated human-human conversations and the misalignment with
human preference. In this paper, we propose a novel and efficient approach
Diamante to boost the open-domain chatbot, where two kinds of human feedback
(including explicit demonstration and implicit preference) are collected and
leveraged. By asking annotators to select or amend the model-generated
candidate responses, Diamante efficiently collects the human demonstrated
responses and constructs a Chinese chit-chat dataset. To enhance the alignment
with human preference, Diamante leverages the implicit preference in the data
collection process and introduces the generation-evaluation joint training.
Comprehensive experiments indicate that the Diamante dataset and joint training
paradigm can significantly boost the performance of Chinese pre-trained
dialogue models."
FSCNN: A Fast Sparse Convolution Neural Network Inference System,0.0144875,"Convolution neural networks (CNNs) have achieved remarkable success, but
typically accompany high computation cost and numerous redundant weight
parameters. To reduce the FLOPs, structure pruning is a popular approach to
remove the entire hidden structures via introducing coarse-grained sparsity.
Meanwhile, plentiful pruning works leverage fine-grained sparsity instead
(sparsity are randomly distributed), whereas their sparse models lack special
designed computing library for potential speedup. In this technical report, we
study and present an efficient convolution neural network inference system to
accelerate its forward pass by utilizing the fine-grained sparsity of
compressed CNNs. Our developed FSCNN is established based on a set of
specialized designed sparse data structures, operators and associated
algorithms. Experimentally, we validate that FSCNN outperforms standard deep
learning library PyTorch on popular CNN architectures such as VGG16 if
sufficiently high sparsity exhibits. However, due to the contiguity issue of
sparse operators, FSCNN is typically not comparable with highly optimized dense
operator. Therefore, coarse-grained (structured) sparsity is our recommendation
for generic model compression."
Flexible Sampling for Long-tailed Skin Lesion Classification,0.0144632,"Most of the medical tasks naturally exhibit a long-tailed distribution due to
the complex patient-level conditions and the existence of rare diseases.
Existing long-tailed learning methods usually treat each class equally to
re-balance the long-tailed distribution. However, considering that some
challenging classes may present diverse intra-class distributions, re-balancing
all classes equally may lead to a significant performance drop. To address
this, in this paper, we propose a curriculum learning-based framework called
Flexible Sampling for the long-tailed skin lesion classification task.
Specifically, we initially sample a subset of training data as anchor points
based on the individual class prototypes. Then, these anchor points are used to
pre-train an inference model to evaluate the per-class learning difficulty.
Finally, we use a curriculum sampling module to dynamically query new samples
from the rest training samples with the learning difficulty-aware sampling
probability. We evaluated our model against several state-of-the-art methods on
the ISIC dataset. The results with two long-tailed settings have demonstrated
the superiority of our proposed training strategy, which achieves a new
benchmark for long-tailed skin lesion classification."
Model-Free Reinforcement Learning for Symbolic Automata-encoded Objectives,0.0941909,"Reinforcement learning (RL) is a popular approach for robotic path planning
in uncertain environments. However, the control policies trained for an RL
agent crucially depend on user-defined, state-based reward functions. Poorly
designed rewards can lead to policies that do get maximal rewards but fail to
satisfy desired task objectives or are unsafe. There are several examples of
the use of formal languages such as temporal logics and automata to specify
high-level task specifications for robots (in lieu of Markovian rewards).
Recent efforts have focused on inferring state-based rewards from formal
specifications; here, the goal is to provide (probabilistic) guarantees that
the policy learned using RL (with the inferred rewards) satisfies the
high-level formal specification. A key drawback of several of these techniques
is that the rewards that they infer are sparse: the agent receives positive
rewards only upon completion of the task and no rewards otherwise. This
naturally leads to poor convergence properties and high variance during RL. In
this work, we propose using formal specifications in the form of symbolic
automata: these serve as a generalization of both bounded-time temporal
logic-based specifications as well as automata. Furthermore, our use of
symbolic automata allows us to define non-sparse potential-based rewards which
empirically shape the reward surface, leading to better convergence during RL.
We also show that our potential-based rewarding strategy still allows us to
obtain the policy that maximizes the satisfaction of the given specification."
Spacecraft Pose Estimation Based on Unsupervised Domain Adaptation and on a 3D-Guided Loss Combination,0.0220509,"Spacecraft pose estimation is a key task to enable space missions in which
two spacecrafts must navigate around each other. Current state-of-the-art
algorithms for pose estimation employ data-driven techniques. However, there is
an absence of real training data for spacecraft imaged in space conditions due
to the costs and difficulties associated with the space environment. This has
motivated the introduction of 3D data simulators, solving the issue of data
availability but introducing a large gap between the training (source) and test
(target) domains. We explore a method that incorporates 3D structure into the
spacecraft pose estimation pipeline to provide robustness to intensity domain
shift and we present an algorithm for unsupervised domain adaptation with
robust pseudo-labelling. Our solution has ranked second in the two categories
of the 2021 Pose Estimation Challenge organised by the European Space Agency
and the Stanford University, achieving the lowest average error over the two
categories."
An Empirical Study on Disentanglement of Negative-free Contrastive Learning,0.0483385,"Negative-free contrastive learning methods have attracted a lot of attention
with simplicity and impressive performances for large-scale pretraining.
However, its disentanglement property remains unexplored. In this paper, we
examine negative-free contrastive learning methods to study the disentanglement
property empirically. We find that existing disentanglement metrics fail to
make meaningful measurements for high-dimensional representation models, so we
propose a new disentanglement metric based on Mutual Information between latent
representations and data factors. With this proposed metric, we benchmark the
disentanglement property of negative-free contrastive learning on both popular
synthetic datasets and a real-world dataset CelebA. Our study shows that the
investigated methods can learn a well-disentangled subset of representation. As
far as we know, we are the first to extend the study of disentangled
representation learning to high-dimensional representation space and introduce
negative-free contrastive learning methods into this area. The source code of
this paper is available at
\url{https://github.com/noahcao/disentanglement_lib_med}."
Detect Hate Speech in Unseen Domains using Multi-Task Learning: A Case Study of Political Public Figures,0.00737487,"Automatic identification of hateful and abusive content is vital in combating
the spread of harmful online content and its damaging effects. Most existing
works evaluate models by examining the generalization error on train-test
splits on hate speech datasets. These datasets often differ in their
definitions and labeling criteria, leading to poor model performance when
predicting across new domains and datasets. In this work, we propose a new
Multi-task Learning (MTL) pipeline that utilizes MTL to train simultaneously
across multiple hate speech datasets to construct a more encompassing
classification model. We simulate evaluation on new previously unseen datasets
by adopting a leave-one-out scheme in which we omit a target dataset from
training and jointly train on the other datasets. Our results consistently
outperform a large sample of existing work. We show strong results when
examining generalization error in train-test splits and substantial
improvements when predicting on previously unseen datasets. Furthermore, we
assemble a novel dataset, dubbed PubFigs, focusing on the problematic speech of
American Public Political Figures. We automatically detect problematic speech
in the $305,235$ tweets in PubFigs, and we uncover insights into the posting
behaviors of public figures."
Recovering Sign Bits of DCT Coefficients in Digital Images as an Optimization Problem,0.109841,"Recovering unknown, missing, damaged, distorted, or lost information in DCT
coefficients is a common task in multiple applications of digital image
processing, including image compression, selective image encryption, and image
communication. This paper investigates the recovery of sign bits in DCT
coefficients of digital images, by proposing two different approximation
methods to solve a mixed integer linear programming (MILP) problem, which is
NP-hard in general. One method is a relaxation of the MILP problem to a linear
programming (LP) problem, and the other splits the original MILP problem into
some smaller MILP problems and an LP problem. We considered how the proposed
methods can be applied to JPEG-encoded images and conducted extensive
experiments to validate their performances. The experimental results showed
that the proposed methods outperformed other existing methods by a substantial
margin, both according to objective quality metrics and our subjective
evaluation."
SOTIF Entropy: Online SOTIF Risk Quantification and Mitigation for Autonomous Driving,0.14918,"Autonomous driving confronts great challenges in complex traffic scenarios,
where the risk of Safety of the Intended Functionality (SOTIF) can be triggered
by the dynamic operational environment and system insufficiencies. The SOTIF
risk is reflected not only intuitively in the collision risk with objects
outside the autonomous vehicles (AVs), but also inherently in the performance
limitation risk of the implemented algorithms themselves. How to minimize the
SOTIF risk for autonomous driving is currently a critical, difficult, and
unresolved issue. Therefore, this paper proposes the ""Self-Surveillance and
Self-Adaption System"" as a systematic approach to online minimize the SOTIF
risk, which aims to provide a systematic solution for monitoring,
quantification, and mitigation of inherent and external risks. The core of this
system is the risk monitoring of the implemented artificial intelligence
algorithms within the AV. As a demonstration of the Self-Surveillance and
Self-Adaption System, the risk monitoring of the perception algorithm, i.e.,
YOLOv5 is highlighted. Moreover, the inherent perception algorithm risk and
external collision risk are jointly quantified via SOTIF entropy, which is then
propagated downstream to the decision-making module and mitigated. Finally,
several challenging scenarios are demonstrated, and the Hardware-in-the-Loop
experiments are conducted to verify the efficiency and effectiveness of the
system. The results demonstrate that the Self-Surveillance and Self-Adaption
System enables dependable online monitoring, quantification, and mitigation of
SOTIF risk in real-time critical traffic environments."
Learning MAX-SAT from Contextual Examples for Combinatorial Optimisation,0.203551,"Combinatorial optimisation problems are ubiquitous in artificial
intelligence. Designing the underlying models, however, requires substantial
expertise, which is a limiting factor in practice. The models typically consist
of hard and soft constraints, or combine hard constraints with an objective
function. We introduce a novel setting for learning combinatorial optimisation
problems from contextual examples. These positive and negative examples show -
in a particular context - whether the solutions are good enough or not. We
develop our framework using the MAX-SAT formalism as it is simple yet powerful
setting having these features. We study the learnability of MAX-SAT models. Our
theoretical results show that high-quality MAX-SAT models can be learned from
contextual examples in the realisable and agnostic settings, as long as the
data satisfies an intuitive ""representativeness"" condition. We also contribute
two implementations based on our theoretical results: one leverages ideas from
syntax-guided synthesis while the other makes use of stochastic local search
techniques. The two implementations are evaluated by recovering synthetic and
benchmark models from contextual examples. The experimental results support our
theoretical analysis, showing that MAX-SAT models can be learned from
contextual examples. Among the two implementations, the stochastic local search
learner scales much better than the syntax-guided implementation while
providing comparable or better models."
Clinical Prompt Learning with Frozen Language Models,0.0774517,"Prompt learning is a new paradigm in the Natural Language Processing (NLP)
field which has shown impressive performance on a number of natural language
tasks with common benchmarking text datasets in full, few-shot, and zero-shot
train-evaluation setups. Recently, it has even been observed that large but
frozen pre-trained language models (PLMs) with prompt learning outperform
smaller but fine-tuned models. However, as with many recent NLP trends, the
performance of even the largest PLMs such as GPT-3 do not perform well on
specialized domains (e.g. medical text), and the common practice to achieve
State of the Art (SoTA) results still consists of pre-training and fine-tuning
the PLMs on downstream tasks. The reliance on fine-tuning large PLMs is
problematic in clinical settings where data is often held in non-GPU
environments, and more resource efficient methods of training specialized
domain models is crucial. We investigated the viability of prompt learning on
clinically meaningful decision tasks and directly compared with more
traditional fine-tuning methods. Results are partially in line with the prompt
learning literature, with prompt learning able to match or improve on
traditional fine-tuning with substantially fewer trainable parameters and
requiring less training data. We argue that prompt learning therefore provides
lower computational resource costs applicable to clinical settings, that can
serve as an alternative to fine-tuning ever increasing in size PLMs.
Complementary code to reproduce experiments presented in this work can be found
at: https://github.com/NtaylorOX/Public_Clinical_Prompt."
Explaining Chest X-ray Pathologies in Natural Language,0.194063,"Most deep learning algorithms lack explanations for their predictions, which
limits their deployment in clinical practice. Approaches to improve
explainability, especially in medical imaging, have often been shown to convey
limited information, be overly reassuring, or lack robustness. In this work, we
introduce the task of generating natural language explanations (NLEs) to
justify predictions made on medical images. NLEs are human-friendly and
comprehensive, and enable the training of intrinsically explainable models. To
this goal, we introduce MIMIC-NLE, the first, large-scale, medical imaging
dataset with NLEs. It contains over 38,000 NLEs, which explain the presence of
various thoracic pathologies and chest X-ray findings. We propose a general
approach to solve the task and evaluate several architectures on this dataset,
including via clinician assessment."
Autonomous Mobile Clinics: Empowering Affordable Anywhere Anytime Healthcare Access,0.0649241,"We are facing a global healthcare crisis today as the healthcare cost is ever
climbing, but with the aging population, government fiscal revenue is ever
dropping. To create a more efficient and effective healthcare system, three
technical challenges immediately present themselves: healthcare access,
healthcare equity, and healthcare efficiency. An autonomous mobile clinic
solves the healthcare access problem by bringing healthcare services to the
patient by the order of the patient's fingertips. Nevertheless, to enable a
universal autonomous mobile clinic network, a three-stage technical roadmap
needs to be achieved: In stage one, we focus on solving the inequity challenge
in the existing healthcare system by combining autonomous mobility and
telemedicine. In stage two, we develop an AI doctor for primary care, which we
foster from infancy to adulthood with clean healthcare data. With the AI
doctor, we can solve the inefficiency problem. In stage three, after we have
proven that the autonomous mobile clinic network can truly solve the target
clinical use cases, we shall open up the platform for all medical verticals,
thus enabling universal healthcare through this whole new system."
Distilling Causal Effect from Miscellaneous Other-Class for Continual Named Entity Recognition,0.0455565,"Continual Learning for Named Entity Recognition (CL-NER) aims to learn a
growing number of entity types over time from a stream of data. However, simply
learning Other-Class in the same way as new entity types amplifies the
catastrophic forgetting and leads to a substantial performance drop. The main
cause behind this is that Other-Class samples usually contain old entity types,
and the old knowledge in these Other-Class samples is not preserved properly.
Thanks to the causal inference, we identify that the forgetting is caused by
the missing causal effect from the old data. To this end, we propose a unified
causal framework to retrieve the causality from both new entity types and
Other-Class. Furthermore, we apply curriculum learning to mitigate the impact
of label noise and introduce a self-adaptive weight for balancing the causal
effects between new entity types and Other-Class. Experimental results on three
benchmark datasets show that our method outperforms the state-of-the-art method
by a large margin. Moreover, our method can be combined with the existing
state-of-the-art methods to improve the performance in CL-NER"
K-level Reasoning for Zero-Shot Coordination in Hanabi,0.11141,"The standard problem setting in cooperative multi-agent settings is self-play
(SP), where the goal is to train a team of agents that works well together.
However, optimal SP policies commonly contain arbitrary conventions
(""handshakes"") and are not compatible with other, independently trained agents
or humans. This latter desiderata was recently formalized by Hu et al. 2020 as
the zero-shot coordination (ZSC) setting and partially addressed with their
Other-Play (OP) algorithm, which showed improved ZSC and human-AI performance
in the card game Hanabi. OP assumes access to the symmetries of the environment
and prevents agents from breaking these in a mutually incompatible way during
training. However, as the authors point out, discovering symmetries for a given
environment is a computationally hard problem. Instead, we show that through a
simple adaption of k-level reasoning (KLR) Costa Gomes et al. 2006,
synchronously training all levels, we can obtain competitive ZSC and ad-hoc
teamplay performance in Hanabi, including when paired with a human-like proxy
bot. We also introduce a new method, synchronous-k-level reasoning with a best
response (SyKLRBR), which further improves performance on our synchronous KLR
by co-training a best response."
Learning to Ask Like a Physician,-1.0,"Existing question answering (QA) datasets derived from electronic health
records (EHR) are artificially generated and consequently fail to capture
realistic physician information needs. We present Discharge Summary Clinical
Questions (DiSCQ), a newly curated question dataset composed of 2,000+
questions paired with the snippets of text (triggers) that prompted each
question. The questions are generated by medical experts from 100+ MIMIC-III
discharge summaries. We analyze this dataset to characterize the types of
information sought by medical experts. We also train baseline models for
trigger detection and question generation (QG), paired with unsupervised answer
retrieval over EHRs. Our baseline model is able to generate high quality
questions in over 62% of cases when prompted with human selected triggers. We
release this dataset (and all code to reproduce baseline model results) to
facilitate further research into realistic clinical QA and QG:
https://github.com/elehman16/discq."
Sentence-Select: Large-Scale Language Model Data Selection for Rare-Word Speech Recognition,0.140588,"Language model fusion helps smart assistants recognize words which are rare
in acoustic data but abundant in text-only corpora (typed search logs).
However, such corpora have properties that hinder downstream performance,
including being (1) too large, (2) beset with domain-mismatched content, and
(3) heavy-headed rather than heavy-tailed (excessively many duplicate search
queries such as ""weather""). We show that three simple strategies for selecting
language modeling data can dramatically improve rare-word recognition without
harming overall performance. First, to address the heavy-headedness, we
downsample the data according to a soft log function, which tunably reduces
high frequency (head) sentences. Second, to encourage rare-word exposure, we
explicitly filter for words rare in the acoustic data. Finally, we tackle
domain-mismatch via perplexity-based contrastive selection, filtering for
examples matched to the target domain. We down-select a large corpus of web
search queries by a factor of 53x and achieve better LM perplexities than
without down-selection. When shallow-fused with a state-of-the-art, production
speech engine, our LM achieves WER reductions of up to 24% relative on
rare-word sentences (without changing overall WER) compared to a baseline LM
trained on the raw corpus. These gains are further validated through favorable
side-by-side evaluations on live voice search traffic."
Tackling Online One-Class Incremental Learning by Removing Negative Contrasts,0.00816375,"Recent work studies the supervised online continual learning setting where a
learner receives a stream of data whose class distribution changes over time.
Distinct from other continual learning settings the learner is presented new
samples only once and must distinguish between all seen classes. A number of
successful methods in this setting focus on storing and replaying a subset of
samples alongside incoming data in a computationally efficient manner. One
recent proposal ER-AML achieved strong performance in this setting by applying
an asymmetric loss based on contrastive learning to the incoming data and
replayed data. However, a key ingredient of the proposed method is avoiding
contrasts between incoming data and stored data, which makes it impractical for
the setting where only one new class is introduced in each phase of the stream.
In this work we adapt a recently proposed approach (\textit{BYOL}) from
self-supervised learning to the supervised learning setting, unlocking the
constraint on contrasts. We then show that supplementing this with additional
regularization on class prototypes yields a new method that achieves strong
performance in the one-class incremental learning setting and is competitive
with the top performing methods in the multi-class incremental setting."
Robust Deep Learning for Autonomous Driving,0.0424739,"The last decade's research in artificial intelligence had a significant
impact on the advance of autonomous driving. Yet, safety remains a major
concern when it comes to deploying such systems in high-risk environments. The
objective of this thesis is to develop methodological tools which provide
reliable uncertainty estimates for deep neural networks. First, we introduce a
new criterion to reliably estimate model confidence: the true class probability
(TCP). We show that TCP offers better properties for failure prediction than
current uncertainty measures. Since the true class is by essence unknown at
test time, we propose to learn TCP criterion from data with an auxiliary model,
introducing a specific learning scheme adapted to this context. The relevance
of the proposed approach is validated on image classification and semantic
segmentation datasets. Then, we extend our learned confidence approach to the
task of domain adaptation where it improves the selection of pseudo-labels in
self-training methods. Finally, we tackle the challenge of jointly detecting
misclassification and out-of-distributions samples by introducing a new
uncertainty measure based on evidential models and defined on the simplex."
Deep neural networks for fine-grained surveillance of overdose mortality,0.127959,"Surveillance of drug overdose deaths relies on death certificates for
identification of the substances that caused death. Drugs and drug classes can
be identified through the International Classification of Diseases, 10th
Revision (ICD-10) codes present on death certificates. However, ICD-10 codes do
not always provide high levels of specificity in drug identification. To
achieve more fine-grained identification of substances on a death certificate,
the free-text cause of death section, completed by the medical certifier, must
be analyzed. Current methods for analyzing free-text death certificates rely
solely on look-up tables for identifying specific substances, which must be
frequently updated and maintained. To improve identification of drugs on death
certificates, a deep learning named-entity recognition model was developed,
which achieved an F1-score of 99.13%. This model can identify new drug
misspellings and novel substances that are not present on current surveillance
look-up tables, enhancing the surveillance of drug overdose deaths."
CTRLEval: An Unsupervised Reference-Free Metric for Evaluating Controlled Text Generation,0.864665,"Existing reference-free metrics have obvious limitations for evaluating
controlled text generation models. Unsupervised metrics can only provide a
task-agnostic evaluation result which correlates weakly with human judgments,
whereas supervised ones may overfit task-specific data with poor generalization
ability to other datasets. In this paper, we propose an unsupervised
reference-free metric called CTRLEval, which evaluates controlled text
generation from different aspects by formulating each aspect into multiple text
infilling tasks. On top of these tasks, the metric assembles the generation
probabilities from a pre-trained language model without any model training.
Experimental results show that our metric has higher correlations with human
judgments than other baselines, while obtaining better generalization of
evaluating generated texts from different models and with different qualities."
Supporting Medical Relation Extraction via Causality-Pruned Semantic Dependency Forest,0.0660193,"Medical Relation Extraction (MRE) task aims to extract relations between
entities in medical texts. Traditional relation extraction methods achieve
impressive success by exploring the syntactic information, e.g., dependency
tree. However, the quality of the 1-best dependency tree for medical texts
produced by an out-of-domain parser is relatively limited so that the
performance of medical relation extraction method may degenerate. To this end,
we propose a method to jointly model semantic and syntactic information from
medical texts based on causal explanation theory. We generate dependency
forests consisting of the semantic-embedded 1-best dependency tree. Then, a
task-specific causal explainer is adopted to prune the dependency forests,
which are further fed into a designed graph convolutional network to learn the
corresponding representation for downstream task. Empirically, the various
comparisons on benchmark medical datasets demonstrate the effectiveness of our
model."
Factorizing Content and Budget Decisions in Abstractive Summarization of Long Documents,0.0495418,"We argue that disentangling content selection from the budget used to cover
salient content improves the performance and applicability of abstractive
summarizers. Our method, FactorSum, does this disentanglement by factorizing
summarization into two steps through an energy function: (1) generation of
abstractive summary views; (2) combination of these views into a final summary,
following a budget and content guidance. This guidance may come from different
sources, including from an advisor model such as BART or BigBird, or in oracle
mode -- from the reference. This factorization achieves significantly higher
ROUGE scores on multiple benchmarks for long document summarization, namely
PubMed, arXiv, and GovReport. Most notably, our model is effective for domain
adaptation. When trained only on PubMed samples, it achieves a 46.29 ROUGE-1
score on arXiv, which indicates a strong performance due to more flexible
budget adaptation and content selection less dependent on domain-specific
textual structure."
Content Addressable Memory Without Catastrophic Forgetting by Heteroassociation with a Fixed Scaffold,-1.0,"Content-addressable memory (CAM) networks, so-called because stored items can
be recalled by partial or corrupted versions of the items, exhibit near-perfect
recall of a small number of information-dense patterns below capacity and a
'memory cliff' beyond, such that inserting a single additional pattern results
in catastrophic loss of all stored patterns. We propose a novel CAM
architecture, Memory Scaffold with Heteroassociation (MESH), that factorizes
the problems of internal attractor dynamics and association with external
content to generate a CAM continuum without a memory cliff: Small numbers of
patterns are stored with complete information recovery matching standard CAMs,
while inserting more patterns still results in partial recall of every pattern,
with a graceful trade-off between pattern number and pattern richness.
Motivated by the architecture of the Entorhinal-Hippocampal memory circuit in
the brain, MESH is a tripartite architecture with pairwise interactions that
uses a predetermined set of internally stabilized states together with
heteroassociation between the internal states and arbitrary external patterns.
We show analytically and experimentally that for any number of stored patterns,
MESH nearly saturates the total information bound (given by the number of
synapses) for CAM networks, outperforming all existing CAM models."
3DMODT: Attention-Guided Affinities for Joint Detection & Tracking in 3D Point Clouds,0.0465333,"We propose a method for joint detection and tracking of multiple objects in
3D point clouds, a task conventionally treated as a two-step process comprising
object detection followed by data association. Our method embeds both steps
into a single end-to-end trainable network eliminating the dependency on
external object detectors. Our model exploits temporal information employing
multiple frames to detect objects and track them in a single network, thereby
making it a utilitarian formulation for real-world scenarios. Computing
affinity matrix by employing features similarity across consecutive point cloud
scans forms an integral part of visual tracking. We propose an attention-based
refinement module to refine the affinity matrix by suppressing erroneous
correspondences. The module is designed to capture the global context in
affinity matrix by employing self-attention within each affinity matrix and
cross-attention across a pair of affinity matrices. Unlike competing
approaches, our network does not require complex post-processing algorithms,
and processes raw LiDAR frames to directly output tracking results. We
demonstrate the effectiveness of our method on the three tracking benchmarks:
JRDB, Waymo, and KITTI. Experimental evaluations indicate the ability of our
model to generalize well across datasets."
TTTFlow: Unsupervised Test-Time Training with Normalizing Flow,0.135259,"A major problem of deep neural networks for image classification is their
vulnerability to domain changes at test-time. Recent methods have proposed to
address this problem with test-time training (TTT), where a two-branch model is
trained to learn a main classification task and also a self-supervised task
used to perform test-time adaptation. However, these techniques require
defining a proxy task specific to the target application. To tackle this
limitation, we propose TTTFlow: a Y-shaped architecture using an unsupervised
head based on Normalizing Flows to learn the normal distribution of latent
features and detect domain shifts in test examples. At inference, keeping the
unsupervised head fixed, we adapt the model to domain-shifted examples by
maximizing the log likelihood of the Normalizing Flow. Our results show that
our method can significantly improve the accuracy with respect to previous
works."
PointSCNet: Point Cloud Structure and Correlation Learning Based on Space Filling Curve-Guided Sampling,-1.0,"Geometrical structures and the internal local region relationship, such as
symmetry, regular array, junction, etc., are essential for understanding a 3D
shape. This paper proposes a point cloud feature extraction network named
PointSCNet, to capture the geometrical structure information and local region
correlation information of a point cloud. The PointSCNet consists of three main
modules: the space-filling curve-guided sampling module, the information fusion
module, and the channel-spatial attention module. The space-filling
curve-guided sampling module uses Z-order curve coding to sample points that
contain geometrical correlation. The information fusion module uses a
correlation tensor and a set of skip connections to fuse the structure and
correlation information. The channel-spatial attention module enhances the
representation of key points and crucial feature channels to refine the
network. The proposed PointSCNet is evaluated on shape classification and part
segmentation tasks. The experimental results demonstrate that the PointSCNet
outperforms or is on par with state-of-the-art methods by learning the
structure and correlation of point clouds effectively."
A Temporal-Pattern Backdoor Attack to Deep Reinforcement Learning,0.235829,"Deep reinforcement learning (DRL) has made significant achievements in many
real-world applications. But these real-world applications typically can only
provide partial observations for making decisions due to occlusions and noisy
sensors. However, partial state observability can be used to hide malicious
behaviors for backdoors. In this paper, we explore the sequential nature of DRL
and propose a novel temporal-pattern backdoor attack to DRL, whose trigger is a
set of temporal constraints on a sequence of observations rather than a single
observation, and effect can be kept in a controllable duration rather than in
the instant. We validate our proposed backdoor attack to a typical job
scheduling task in cloud computing. Numerous experimental results show that our
backdoor can achieve excellent effectiveness, stealthiness, and sustainability.
Our backdoor's average clean data accuracy and attack success rate can reach
97.8% and 97.5%, respectively."
Measuring Inconsistency in Declarative Process Specifications,0.0866597,"We address the problem of measuring inconsistency in declarative process
specifications, with an emphasis on linear temporal logic on fixed traces
(LTLff). As we will show, existing inconsistency measures for classical logic
cannot provide a meaningful assessment of inconsistency in LTL in general, as
they cannot adequately handle the temporal operators. We therefore propose a
novel paraconsistent semantics as a framework for inconsistency measurement. We
then present two new inconsistency measures based on these semantics and show
that they satisfy important desirable properties. We show how these measures
can be applied to declarative process models and investigate the computational
complexity of the introduced approach."
On Mitigating Hard Clusters for Face Clustering,0.055154,"Face clustering is a promising way to scale up face recognition systems using
large-scale unlabeled face images. It remains challenging to identify small or
sparse face image clusters that we call hard clusters, which is caused by the
heterogeneity, \ie, high variations in size and sparsity, of the clusters.
Consequently, the conventional way of using a uniform threshold (to identify
clusters) often leads to a terrible misclassification for the samples that
should belong to hard clusters. We tackle this problem by leveraging the
neighborhood information of samples and inferring the cluster memberships (of
samples) in a probabilistic way. We introduce two novel modules,
Neighborhood-Diffusion-based Density (NDDe) and Transition-Probability-based
Distance (TPDi), based on which we can simply apply the standard Density Peak
Clustering algorithm with a uniform threshold. Our experiments on multiple
benchmarks show that each module contributes to the final performance of our
method, and by incorporating them into other advanced face clustering methods,
these two modules can boost the performance of these methods to a new
state-of-the-art. Code is available at:
https://github.com/echoanran/On-Mitigating-Hard-Clusters."
FixMatchSeg: Fixing FixMatch for Semi-Supervised Semantic Segmentation,0.0783292,"Supervised deep learning methods for semantic medical image segmentation are
getting increasingly popular in the past few years.However, in resource
constrained settings, getting large number of annotated images is very
difficult as it mostly requires experts, is expensive and
time-consuming.Semi-supervised segmentation can be an attractive solution where
a very few labeled images are used along with a large number of unlabeled ones.
While the gap between supervised and semi-supervised methods have been
dramatically reduced for classification problems in the past couple of years,
there still remains a larger gap in segmentation methods. In this work, we
adapt a state-of-the-art semi-supervised classification method FixMatch to
semantic segmentation task, introducing FixMatchSeg. FixMatchSeg is evaluated
in four different publicly available datasets of different anatomy and
different modality: cardiac ultrasound, chest X-ray, retinal fundus image, and
skin images. When there are few labels, we show that FixMatchSeg performs on
par with strong supervised baselines."
Encryption and encoding of facial images into quick response and high capacity color 2d code for biometric passport security system,0.0300982,"In this thesis, a multimodal biometric, secure encrypted data and encrypted
biometric encoded into the QR code-based biometric-passport authentication
method is proposed for national security applications. Firstly, using the
Extended Profile - Local Binary Patterns (EP-LBP), a Canny edge detector, and
the Scale Invariant Feature Transform (SIFT) algorithm with Image File
Information (IMFINFO) process, the facial mark size recognition is initially
achieved. Secondly, by using the Active Shape Model (ASM) into Active
Appearance Model (AAM) to follow the hand and infusion the hand geometry
characteristics for verification and identification, hand geometry recognition
is achieved. Thirdly, the encrypted biometric passport information that is
publicly accessible is encoded into the QR code and inserted into the
electronic passport to improve protection. Further, Personal information and
biometric data are encrypted by applying the Advanced Encryption Standard (AES)
and the Secure Hash Algorithm (SHA) 256 algorithm. It will enhance the
biometric passport security system."
Improving Few-Shot Part Segmentation using Coarse Supervision,0.0379066,"A significant bottleneck in training deep networks for part segmentation is
the cost of obtaining detailed annotations. We propose a framework to exploit
coarse labels such as figure-ground masks and keypoint locations that are
readily available for some categories to improve part segmentation models. A
key challenge is that these annotations were collected for different tasks and
with different labeling styles and cannot be readily mapped to the part labels.
To this end, we propose to jointly learn the dependencies between labeling
styles and the part segmentation model, allowing us to utilize supervision from
diverse labels. To evaluate our approach we develop a benchmark on the
Caltech-UCSD birds and OID Aircraft dataset. Our approach outperforms baselines
based on multi-task learning, semi-supervised learning, and competitive methods
relying on loss functions manually designed to exploit sparse-supervision."
Robust-by-Design Classification via Unitary-Gradient Neural Networks,0.0122798,"The use of neural networks in safety-critical systems requires safe and
robust models, due to the existence of adversarial attacks. Knowing the minimal
adversarial perturbation of any input x, or, equivalently, knowing the distance
of x from the classification boundary, allows evaluating the classification
robustness, providing certifiable predictions. Unfortunately, state-of-the-art
techniques for computing such a distance are computationally expensive and
hence not suited for online applications. This work proposes a novel family of
classifiers, namely Signed Distance Classifiers (SDCs), that, from a
theoretical perspective, directly output the exact distance of x from the
classification boundary, rather than a probability score (e.g., SoftMax). SDCs
represent a family of robust-by-design classifiers. To practically address the
theoretical requirements of a SDC, a novel network architecture named
Unitary-Gradient Neural Network is presented. Experimental results show that
the proposed architecture approximates a signed distance classifier, hence
allowing an online certifiable classification of x at the cost of a single
inference."
VLCDoC: Vision-Language Contrastive Pre-Training Model for Cross-Modal Document Classification,0.243268,"Multimodal learning from document data has achieved great success lately as
it allows to pre-train semantically meaningful features as a prior into a
learnable downstream task. In this paper, we approach the document
classification problem by learning cross-modal representations through language
and vision cues, considering intra- and inter-modality relationships. Instead
of merging features from different modalities into a joint representation
space, the proposed method exploits high-level interactions and learns relevant
semantic information from effective attention flows within and across
modalities. The proposed learning objective is devised between intra- and
inter-modality alignment tasks, where the similarity distribution per task is
computed by contracting positive sample pairs while simultaneously contrasting
negative ones in the joint representation space}. Extensive experiments on
public document classification datasets demonstrate the effectiveness and the
generality of our model on low-scale and large-scale datasets."
BiFSMN: Binary Neural Network for Keyword Spotting,-1.0,"The deep neural networks, such as the Deep-FSMN, have been widely studied for
keyword spotting (KWS) applications. However, computational resources for these
networks are significantly constrained since they usually run on-call on edge
devices. In this paper, we present BiFSMN, an accurate and extreme-efficient
binary neural network for KWS. We first construct a High-frequency Enhancement
Distillation scheme for the binarization-aware training, which emphasizes the
high-frequency information from the full-precision network's representation
that is more crucial for the optimization of the binarized network. Then, to
allow the instant and adaptive accuracy-efficiency trade-offs at runtime, we
also propose a Thinnable Binarization Architecture to further liberate the
acceleration potential of the binarized network from the topology perspective.
Moreover, we implement a Fast Bitwise Computation Kernel for BiFSMN on ARMv8
devices which fully utilizes registers and increases instruction throughput to
push the limit of deployment efficiency. Extensive experiments show that BiFSMN
outperforms existing binarization methods by convincing margins on various
datasets and is even comparable with the full-precision counterpart (e.g., less
than 3% drop on Speech Commands V1-12). We highlight that benefiting from the
thinnable architecture and the optimized 1-bit implementation, BiFSMN can
achieve an impressive 22.3x speedup and 15.5x storage-saving on real-world edge
hardware. Our code is released at https://github.com/htqin/BiFSMN."
Blockchain-based Monitoring for Poison Attack Detection in Decentralized Federated Learning,0.0689657,"Federated Learning (FL) is a machine learning technique that addresses the
privacy challenges in terms of access rights of local datasets by enabling the
training of a model across nodes holding their data samples locally. To achieve
decentralized federated learning, blockchain-based FL was proposed as a
distributed FL architecture. In decentralized FL, the chief is eliminated from
the learning process as workers collaborate between each other to train the
global model. Decentralized FL applications need to account for the additional
delay incurred by blockchain-based FL deployments. Particularly in this
setting, to detect targeted/untargeted poisoning attacks, we investigate the
end-to-end learning completion latency of a realistic decentralized FL process
protected against poisoning attacks. We propose a technique which consists in
decoupling the monitoring phase from the detection phase in defenses against
poisoning attacks in a decentralized federated learning deployment that aim at
monitoring the behavior of the workers. We demonstrate that our proposed
blockchain-based monitoring improved network scalability, robustness and time
efficiency. The parallelization of operations results in minimized latency over
the end-to-end communication, computation, and consensus delays incurred during
the FL and blockchain operations."
Storehouse: a Reinforcement Learning Environment for Optimizing Warehouse Management,0.0441457,"Warehouse Management Systems have been evolving and improving thanks to new
Data Intelligence techniques. However, many current optimizations have been
applied to specific cases or are in great need of manual interaction. Here is
where Reinforcement Learning techniques come into play, providing
automatization and adaptability to current optimization policies. In this
paper, we present Storehouse, a customizable environment that generalizes the
definition of warehouse simulations for Reinforcement Learning. We also
validate this environment against state-of-the-art reinforcement learning
algorithms and compare these results to human and random policies."
Stability and Generalization of Stochastic Optimization with Nonconvex and Nonsmooth Problems,0.0128577,"Stochastic optimization has found wide applications in minimizing objective
functions in machine learning, which motivates a lot of theoretical studies to
understand its practical success. Most of existing studies focus on the
convergence of optimization errors, while the generalization analysis of
stochastic optimization is much lagging behind. This is especially the case for
nonconvex and nonsmooth problems often encountered in practice. In this paper,
we initialize a systematic stability and generalization analysis of stochastic
optimization on nonconvex and nonsmooth problems. We introduce novel
algorithmic stability measures and establish their quantitative connection on
the gap between population gradients and empirical gradients, which is then
further extended to study the gap between the Moreau envelope of the empirical
risk and that of the population risk. To our knowledge, these quantitative
connection between stability and generalization in terms of either gradients or
Moreau envelopes have not been studied in the literature. We introduce a class
of sampling-determined algorithms, for which we develop bounds for three
stability measures. Finally, we apply these discussions to derive error bounds
for stochastic gradient descent and its adaptive variant, where we show how to
achieve an implicit regularization by tuning the step sizes and the number of
iterations."
TaxoCom: Topic Taxonomy Completion with Hierarchical Discovery of Novel Topic Clusters,0.137991,"Topic taxonomies, which represent the latent topic (or category) structure of
document collections, provide valuable knowledge of contents in many
applications such as web search and information filtering. Recently, several
unsupervised methods have been developed to automatically construct the topic
taxonomy from a text corpus, but it is challenging to generate the desired
taxonomy without any prior knowledge. In this paper, we study how to leverage
the partial (or incomplete) information about the topic structure as guidance
to find out the complete topic taxonomy. We propose a novel framework for topic
taxonomy completion, named TaxoCom, which recursively expands the topic
taxonomy by discovering novel sub-topic clusters of terms and documents. To
effectively identify novel topics within a hierarchical topic structure,
TaxoCom devises its embedding and clustering techniques to be closely-linked
with each other: (i) locally discriminative embedding optimizes the text
embedding space to be discriminative among known (i.e., given) sub-topics, and
(ii) novelty adaptive clustering assigns terms into either one of the known
sub-topics or novel sub-topics. Our comprehensive experiments on two real-world
datasets demonstrate that TaxoCom not only generates the high-quality topic
taxonomy in terms of term coherency and topic coverage but also outperforms all
other baselines for a downstream task."
On the expressive power of message-passing neural networks as global feature map transformers,0.0958993,"We investigate the power of message-passing neural networks (MPNNs) in their
capacity to transform the numerical features stored in the nodes of their input
graphs. Our focus is on global expressive power, uniformly over all input
graphs, or over graphs of bounded degree with features from a bounded domain.
Accordingly, we introduce the notion of a global feature map transformer
(GFMT). As a yardstick for expressiveness, we use a basic language for GFMTs,
which we call MPLang. Every MPNN can be expressed in MPLang, and our results
clarify to which extent the converse inclusion holds. We consider exact versus
approximate expressiveness; the use of arbitrary activation functions; and the
case where only the ReLU activation function is allowed."
Shared Coupling-bridge for Weakly Supervised Local Feature Learning,0.0446303,"Sparse local feature extraction is usually believed to be of important
significance in typical vision tasks such as simultaneous localization and
mapping, image matching and 3D reconstruction. At present, it still has some
deficiencies needing further improvement, mainly including the discrimination
power of extracted local descriptors, the localization accuracy of detected
keypoints, and the efficiency of local feature learning. This paper focuses on
promoting the currently popular sparse local feature learning with camera pose
supervision. Therefore, it pertinently proposes a Shared Coupling-bridge scheme
with four light-weight yet effective improvements for weakly-supervised local
feature (SCFeat) learning. It mainly contains: i) the
\emph{Feature-Fusion-ResUNet Backbone} (F2R-Backbone) for local descriptors
learning, ii) a shared coupling-bridge normalization to improve the decoupling
training of description network and detection network, iii) an improved
detection network with peakiness measurement to detect keypoints and iv) the
fundamental matrix error as a reward factor to further optimize feature
detection training. Extensive experiments prove that our SCFeat improvement is
effective. It could often obtain a state-of-the-art performance on classic
image matching and visual localization. In terms of 3D reconstruction, it could
still achieve competitive results. For sharing and communication, our source
codes are available at https://github.com/sunjiayuanro/SCFeat.git."
Grammar Detection for Sentiment Analysis through Improved Viterbi Algorithm,0.0305068,"Grammar Detection, also referred to as Parts of Speech Tagging of raw text,
is considered an underlying building block of the various Natural Language
Processing pipelines like named entity recognition, question answering, and
sentiment analysis. In short, forgiven a sentence, Parts of Speech tagging is
the task of specifying and tagging each word of a sentence with nouns, verbs,
adjectives, adverbs, and more. Sentiment Analysis may well be a procedure
accustomed to determining if a given sentence's emotional tone is neutral,
positive or negative. To assign polarity scores to the thesis or entities
within phrase, in-text analysis and analytics, machine learning and natural
language processing, approaches are incorporated. This Sentiment Analysis using
POS tagger helps us urge a summary of the broader public over a specific topic.
For this, we are using the Viterbi algorithm, Hidden Markov Model, Constraint
based Viterbi algorithm for POS tagging. By comparing the accuracies, we select
the foremost accurate result of the model for Sentiment Analysis for
determining the character of the sentence."
Automatic Depression Detection: An Emotional Audio-Textual Corpus and a GRU/BiLSTM-based Model,0.627124,"Depression is a global mental health problem, the worst case of which can
lead to suicide. An automatic depression detection system provides great help
in facilitating depression self-assessment and improving diagnostic accuracy.
In this work, we propose a novel depression detection approach utilizing speech
characteristics and linguistic contents from participants' interviews. In
addition, we establish an Emotional Audio-Textual Depression Corpus
(EATD-Corpus) which contains audios and extracted transcripts of responses from
depressed and non-depressed volunteers. To the best of our knowledge,
EATD-Corpus is the first and only public depression dataset that contains audio
and text data in Chinese. Evaluated on two depression datasets, the proposed
method achieves the state-of-the-art performances. The outperforming results
demonstrate the effectiveness and generalization ability of the proposed
method. The source code and EATD-Corpus are available at
https://github.com/speechandlanguageprocessing/ICASSP2022-Depression."
Tailor: A Prompt-Based Approach to Attribute-Based Controlled Text Generation,0.320553,"Attribute-based Controlled Text Generation (CTG) refers to generating
sentences that satisfy desirable attributes (e.g., emotions and topics).
Existing works often utilize fine-tuning or resort to extra attribute
classifiers, yet suffer from storage and inference time increases. To address
these concerns, we explore attribute-based CTG in a prompt-based manner. In
short, the proposed Tailor represents each attribute as a pre-trained
continuous vector (i.e., single-attribute prompt) and guides the generation of
a fixed PLM switch to a pre-specified attribute. We experimentally find that
these prompts can be simply concatenated as a whole to multi-attribute CTG
without any re-training, yet raises problems of fluency decrease and position
sensitivity. To this end, Tailor provides a multi-attribute prompt mask and a
re-indexing position-ids sequence to bridge the gap between the training (one
prompt for each task) and testing stage (concatenating more than one prompt).
To further enhance such single-attribute prompt combinations, Tailor also
introduces a trainable prompt connector, which can be concatenated with any two
single-attribute prompts to multi-attribute text generation. Experiments on 11
attribute-specific generation tasks demonstrate strong performances of Tailor
on both single-attribute and multi-attribute CTG, with 0.08\% training
parameters of a GPT-2."
MIA 2022 Shared Task: Evaluating Cross-lingual Open-Retrieval Question Answering for 16 Diverse Languages,0.138425,"We present the results of the Workshop on Multilingual Information Access
(MIA) 2022 Shared Task, evaluating cross-lingual open-retrieval question
answering (QA) systems in 16 typologically diverse languages. In this task, we
adapted two large-scale cross-lingual open-retrieval QA datasets in 14
typologically diverse languages, and newly annotated open-retrieval QA data in
2 underrepresented languages: Tagalog and Tamil. Four teams submitted their
systems. The best system leveraging iteratively mined diverse negative examples
and larger pretrained models achieves 32.2 F1, outperforming our baseline by
4.5 points. The second best system uses entity-aware contextualized
representations for document retrieval, and achieves significant improvements
in Tamil (20.8 F1), whereas most of the other systems yield nearly zero scores."
A-Eye: Driving with the Eyes of AI for Corner Case Generation,0.139499,"The overall goal of this work is to enrich training data for automated
driving with so called corner cases. In road traffic, corner cases are
critical, rare and unusual situations that challenge the perception by AI
algorithms. For this purpose, we present the design of a test rig to generate
synthetic corner cases using a human-in-the-loop approach. For the test rig, a
real-time semantic segmentation network is trained and integrated into the
driving simulation software CARLA in such a way that a human can drive on the
network's prediction. In addition, a second person gets to see the same scene
from the original CARLA output and is supposed to intervene with the help of a
second control unit as soon as the semantic driver shows dangerous driving
behavior. Interventions potentially indicate poor recognition of a critical
scene by the segmentation network and then represents a corner case. In our
experiments, we show that targeted enrichment of training data with corner
cases leads to improvements in pedestrian detection in safety relevant episodes
in road traffic."
Vector Quantized Image-to-Image Translation,0.0423941,"Current image-to-image translation methods formulate the task with
conditional generation models, leading to learning only the recolorization or
regional changes as being constrained by the rich structural information
provided by the conditional contexts. In this work, we propose introducing the
vector quantization technique into the image-to-image translation framework.
The vector quantized content representation can facilitate not only the
translation, but also the unconditional distribution shared among different
domains. Meanwhile, along with the disentangled style representation, the
proposed method further enables the capability of image extension with
flexibility in both intra- and inter-domains. Qualitative and quantitative
experiments demonstrate that our framework achieves comparable performance to
the state-of-the-art image-to-image translation and image extension methods.
Compared to methods for individual tasks, the proposed method, as a unified
framework, unleashes applications combining image-to-image translation,
unconditional generation, and image extension altogether. For example, it
provides style variability for image generation and extension, and equips
image-to-image translation with further extension capabilities."
Streamable Neural Fields,0.0234773,"Neural fields have emerged as a new data representation paradigm and have
shown remarkable success in various signal representations. Since they preserve
signals in their network parameters, the data transfer by sending and receiving
the entire model parameters prevents this emerging technology from being used
in many practical scenarios. We propose streamable neural fields, a single
model that consists of executable sub-networks of various widths. The proposed
architectural and training techniques enable a single network to be streamable
over time and reconstruct different qualities and parts of signals. For
example, a smaller sub-network produces smooth and low-frequency signals, while
a larger sub-network can represent fine details. Experimental results have
shown the effectiveness of our method in various domains, such as 2D images,
videos, and 3D signed distance functions. Finally, we demonstrate that our
proposed method improves training stability, by exploiting parameter sharing."
xCloth: Extracting Template-free Textured 3D Clothes from a Monocular Image,0.104426,"Existing approaches for 3D garment reconstruction either assume a predefined
template for the garment geometry (restricting them to fixed clothing styles)
or yield vertex colored meshes (lacking high-frequency textural details). Our
novel framework co-learns geometric and semantic information of garment surface
from the input monocular image for template-free textured 3D garment
digitization. More specifically, we propose to extend PeeledHuman
representation to predict the pixel-aligned, layered depth and semantic maps to
extract 3D garments. The layered representation is further exploited to UV
parametrize the arbitrary surface of the extracted garment without any human
intervention to form a UV atlas. The texture is then imparted on the UV atlas
in a hybrid fashion by first projecting pixels from the input image to UV space
for the visible region, followed by inpainting the occluded regions. Thus, we
are able to digitize arbitrarily loose clothing styles while retaining
high-frequency textural details from a monocular image. We achieve
high-fidelity 3D garment reconstruction results on three publicly available
datasets and generalization on internet images."
EmbryosFormer: Deformable Transformer and Collaborative Encoding-Decoding for Embryos Stage Development Classification,-1.0,"The timing of cell divisions in early embryos during the In-Vitro
Fertilization (IVF) process is a key predictor of embryo viability. However,
observing cell divisions in Time-Lapse Monitoring (TLM) is a time-consuming
process and highly depends on experts. In this paper, we propose EmbryosFormer,
a computational model to automatically detect and classify cell divisions from
original time-lapse images. Our proposed network is designed as an
encoder-decoder deformable transformer with collaborative heads. The
transformer contracting path predicts per-image labels and is optimized by a
classification head. The transformer expanding path models the temporal
coherency between embryo images to ensure monotonic non-decreasing constraint
and is optimized by a segmentation head. Both contracting and expanding paths
are synergetically learned by a collaboration head. We have benchmarked our
proposed EmbryosFormer on two datasets: a public dataset with mouse embryos
with 8-cell stage and an in-house dataset with human embryos with 4-cell stage.
Source code: https://github.com/UARK-AICV/Embryos."
Dual-former: Hybrid Self-attention Transformer for Efficient Image Restoration,0.0737297,"Recently, image restoration transformers have achieved comparable performance
with previous state-of-the-art CNNs. However, how to efficiently leverage such
architectures remains an open problem. In this work, we present Dual-former
whose critical insight is to combine the powerful global modeling ability of
self-attention modules and the local modeling ability of convolutions in an
overall architecture. With convolution-based Local Feature Extraction modules
equipped in the encoder and the decoder, we only adopt a novel Hybrid
Transformer Block in the latent layer to model the long-distance dependence in
spatial dimensions and handle the uneven distribution between channels. Such a
design eliminates the substantial computational complexity in previous image
restoration transformers and achieves superior performance on multiple image
restoration tasks. Experiments demonstrate that Dual-former achieves a 1.91dB
gain over the state-of-the-art MAXIM method on the Indoor dataset for single
image dehazing while consuming only 4.2% GFLOPs as MAXIM. For single image
deraining, it exceeds the SOTA method by 0.1dB PSNR on the average results of
five datasets with only 21.5% GFLOPs. Dual-former also substantially surpasses
the latest desnowing method on various datasets, with fewer parameters."
Open Challenges in Musical Metacreation,0.168475,"Musical Metacreation tries to obtain creative behaviors from computers
algorithms composing music. In this paper I briefly analyze how this field
evolved from algorithmic composition to be focused on the search for
creativity, and I point out some issues in pursuing this goal. Finally, I argue
that hybridization of algorithms can be a useful direction for research."
GT-GAN: General Purpose Time Series Synthesis with Generative Adversarial Networks,0.221326,"Time series synthesis is an important research topic in the field of deep
learning, which can be used for data augmentation. Time series data types can
be broadly classified into regular or irregular. However, there are no existing
generative models that show good performance for both types without any model
changes. Therefore, we present a general purpose model capable of synthesizing
regular and irregular time series data. To our knowledge, we are the first
designing a general purpose time series synthesis model, which is one of the
most challenging settings for time series synthesis. To this end, we design a
generative adversarial network-based method, where many related techniques are
carefully integrated into a single framework, ranging from neural
ordinary/controlled differential equations to continuous time-flow processes.
Our method outperforms all existing methods."
The solution set of fuzzy relation equations with addition-min composition,0.0482548,"This paper deals with the resolutions of fuzzy relation equations with
addition-min composition. When the fuzzy relation equations have a solution, we
first propose an algorithm to find all minimal solutions of the fuzzy relation
equations and also supply an algorithm to find all maximal solutions of the
fuzzy relation equations, which will be illustrated, respectively, by numeral
examples. Then we prove that every solution of the fuzzy relation equations is
between a minimal solution and a maximal one, so that we describe the solution
set of the fuzzy relation equations completely."
AiTLAS: Artificial Intelligence Toolbox for Earth Observation,0.0605564,"The AiTLAS toolbox (Artificial Intelligence Toolbox for Earth Observation)
includes state-of-the-art machine learning methods for exploratory and
predictive analysis of satellite imagery as well as repository of AI-ready
Earth Observation (EO) datasets. It can be easily applied for a variety of
Earth Observation tasks, such as land use and cover classification, crop type
prediction, localization of specific objects (semantic segmentation), etc. The
main goal of AiTLAS is to facilitate better usability and adoption of novel AI
methods (and models) by EO experts, while offering easy access and standardized
format of EO datasets to AI experts which further allows benchmarking of
various existing and novel AI methods tailored for EO data."
Discovering Salient Neurons in Deep NLP Models,0.0539453,"While a lot of work has been done in understanding representations learned
within deep NLP models and what knowledge they capture, little attention has
been paid towards individual neurons. We present a technique called as
Linguistic Correlation Analysis to extract salient neurons in the model, with
respect to any extrinsic property - with the goal of understanding how such a
knowledge is preserved within neurons. We carry out a fine-grained analysis to
answer the following questions: (i) can we identify subsets of neurons in the
network that capture specific linguistic properties? (ii) how localized or
distributed neurons are across the network? iii) how redundantly is the
information preserved? iv) how fine-tuning pre-trained models towards
downstream NLP tasks, impacts the learned linguistic knowledge? iv) how do
architectures vary in learning different linguistic properties? Our
data-driven, quantitative analysis illuminates interesting findings: (i) we
found small subsets of neurons that can predict different linguistic tasks, ii)
with neurons capturing basic lexical information (such as suffixation)
localized in lower most layers, iii) while those learning complex concepts
(such as syntactic role) predominantly in middle and higher layers, iii) that
salient linguistic neurons are relocated from higher to lower layers during
transfer learning, as the network preserve the higher layers for task specific
information, iv) we found interesting differences across pre-trained models,
with respect to how linguistic information is preserved within, and v) we found
that concept exhibit similar neuron distribution across different languages in
the multilingual transformer models. Our code is publicly available as part of
the NeuroX toolkit."
Robust Multi-Object Tracking by Marginal Inference,0.0809328,"Multi-object tracking in videos requires to solve a fundamental problem of
one-to-one assignment between objects in adjacent frames. Most methods address
the problem by first discarding impossible pairs whose feature distances are
larger than a threshold, followed by linking objects using Hungarian algorithm
to minimize the overall distance. However, we find that the distribution of the
distances computed from Re-ID features may vary significantly for different
videos. So there isn't a single optimal threshold which allows us to safely
discard impossible pairs. To address the problem, we present an efficient
approach to compute a marginal probability for each pair of objects in real
time. The marginal probability can be regarded as a normalized distance which
is significantly more stable than the original feature distance. As a result,
we can use a single threshold for all videos. The approach is general and can
be applied to the existing trackers to obtain about one point improvement in
terms of IDF1 metric. It achieves competitive results on MOT17 and MOT20
benchmarks. In addition, the computed probability is more interpretable which
facilitates subsequent post-processing operations."
ImPosing: Implicit Pose Encoding for Efficient Visual Localization,0.00585047,"We propose a novel learning-based formulation for visual localization of
vehicles that can operate in real-time in city-scale environments. Visual
localization algorithms determine the position and orientation from which an
image has been captured, using a set of geo-referenced images or a 3D scene
representation. Our new localization paradigm, named Implicit Pose Encoding
(ImPosing), embeds images and camera poses into a common latent representation
with 2 separate neural networks, such that we can compute a similarity score
for each image-pose pair. By evaluating candidates through the latent space in
a hierarchical manner, the camera position and orientation are not directly
regressed but incrementally refined. Very large environments force competitors
to store gigabytes of map data, whereas our method is very compact
independently of the reference database size. In this paper, we describe how to
effectively optimize our learned modules, how to combine them to achieve
real-time localization, and demonstrate results on diverse large scale
scenarios that significantly outperform prior work in accuracy and
computational efficiency."
Ada3Diff: Defending against 3D Adversarial Point Clouds via Adaptive Diffusion,0.0617698,"Deep 3D point cloud models are sensitive to adversarial attacks, which poses
threats to safety-critical applications such as autonomous driving. Robust
training and defend-by-denoising are typical strategies for defending
adversarial perturbations. However, they either induce massive computational
overhead or rely heavily upon specified priors, limiting generalized robustness
against attacks of all kinds. To remedy it, this paper introduces a novel
distortion-aware defense framework that can rebuild the pristine data
distribution with a tailored intensity estimator and a diffusion model. To
perform distortion-aware forward diffusion, we design a distortion estimation
algorithm that is obtained by summing the distance of each point to the
best-fitting plane of its local neighboring points, which is based on the
observation of the local spatial properties of the adversarial point cloud. By
iterative diffusion and reverse denoising, the perturbed point cloud under
various distortions can be restored back to a clean distribution. This approach
enables effective defense against adaptive attacks with varying noise budgets,
enhancing the robustness of existing 3D deep recognition models."
Practical Phase Retrieval Using Double Deep Image Priors,0.0952199,"Phase retrieval (PR) concerns the recovery of complex phases from complex
magnitudes. We identify the connection between the difficulty level and the
number and variety of symmetries in PR problems. We focus on the most difficult
far-field PR (FFPR), and propose a novel method using double deep image priors.
In realistic evaluation, our method outperforms all competing methods by large
margins. As a single-instance method, our method requires no training data and
minimal hyperparameter tuning, and hence enjoys good practicality."
Scalar is Not Enough: Vectorization-based Unbiased Learning to Rank,0.00874385,"Unbiased learning to rank (ULTR) aims to train an unbiased ranking model from
biased user click logs. Most of the current ULTR methods are based on the
examination hypothesis (EH), which assumes that the click probability can be
factorized into two scalar functions, one related to ranking features and the
other related to bias factors. Unfortunately, the interactions among features,
bias factors and clicks are complicated in practice, and usually cannot be
factorized in this independent way. Fitting click data with EH could lead to
model misspecification and bring the approximation error.
  In this paper, we propose a vector-based EH and formulate the click
probability as a dot product of two vector functions. This solution is complete
due to its universality in fitting arbitrary click functions. Based on it, we
propose a novel model named Vectorization to adaptively learn the relevance
embeddings and sort documents by projecting embeddings onto a base vector.
Extensive experiments show that our method significantly outperforms the
state-of-the-art ULTR methods on complex real clicks as well as simple
simulated clicks."
Por Qué Não Utiliser Alla Språk? Mixed Training with Gradient Optimization in Few-Shot Cross-Lingual Transfer,0.208634,"The current state-of-the-art for few-shot cross-lingual transfer learning
first trains on abundant labeled data in the source language and then
fine-tunes with a few examples on the target language, termed target-adapting.
Though this has been demonstrated to work on a variety of tasks, in this paper
we show some deficiencies of this approach and propose a one-step mixed
training method that trains on both source and target data with
\textit{stochastic gradient surgery}, a novel gradient-level optimization.
Unlike the previous studies that focus on one language at a time when
target-adapting, we use one model to handle all target languages simultaneously
to avoid excessively language-specific models. Moreover, we discuss the
unreality of utilizing large target development sets for model selection in
previous literature. We further show that our method is both development-free
for target languages, and is also able to escape from overfitting issues. We
conduct a large-scale experiment on 4 diverse NLP tasks across up to 48
languages. Our proposed method achieves state-of-the-art performance on all
tasks and outperforms target-adapting by a large margin, especially for
languages that are linguistically distant from the source language, e.g., 7.36%
F1 absolute gain on average for the NER task, up to 17.60% on Punjabi."
Font Shape-to-Impression Translation,0.0344389,"Different fonts have different impressions, such as elegant, scary, and cool.
This paper tackles part-based shape-impression analysis based on the
Transformer architecture, which is able to handle the correlation among local
parts by its self-attention mechanism. This ability will reveal how
combinations of local parts realize a specific impression of a font. The
versatility of Transformer allows us to realize two very different approaches
for the analysis, i.e., multi-label classification and translation. A
quantitative evaluation shows that our Transformer-based approaches estimate
the font impressions from a set of local parts more accurately than other
approaches. A qualitative evaluation then indicates the important local parts
for a specific impression."
Generalised Implicit Neural Representations,0.0519401,"We consider the problem of learning implicit neural representations (INRs)
for signals on non-Euclidean domains. In the Euclidean case, INRs are trained
on a discrete sampling of a signal over a regular lattice. Here, we assume that
the continuous signal exists on some unknown topological space from which we
sample a discrete graph. In the absence of a coordinate system to identify the
sampled nodes, we propose approximating their location with a spectral
embedding of the graph. This allows us to train INRs without knowing the
underlying continuous domain, which is the case for most graph signals in
nature, while also making the INRs independent of any choice of coordinate
system. We show experiments with our method on various real-world signals on
non-Euclidean domains."
Self-Distribution Distillation: Efficient Uncertainty Estimation,0.0244671,"Deep learning is increasingly being applied in safety-critical domains. For
these scenarios it is important to know the level of uncertainty in a model's
prediction to ensure appropriate decisions are made by the system. Deep
ensembles are the de-facto standard approach to obtaining various measures of
uncertainty. However, ensembles often significantly increase the resources
required in the training and/or deployment phases. Approaches have been
developed that typically address the costs in one of these phases. In this work
we propose a novel training approach, self-distribution distillation (S2D),
which is able to efficiently train a single model that can estimate
uncertainties. Furthermore it is possible to build ensembles of these models
and apply hierarchical ensemble distillation approaches. Experiments on
CIFAR-100 showed that S2D models outperformed standard models and Monte-Carlo
dropout. Additional out-of-distribution detection experiments on LSUN, Tiny
ImageNet, SVHN showed that even a standard deep ensemble can be outperformed
using S2D based ensembles and novel distilled models."
Meta-Learning Fast Weight Language Models,0.0554116,"Dynamic evaluation of language models (LMs) adapts model parameters at test
time using gradient information from previous tokens and substantially improves
LM performance. However, it requires over 3x more compute than standard
inference. We present Fast Weight Layers (FWLs), a neural component that
provides the benefits of dynamic evaluation much more efficiently by expressing
gradient updates as linear attention. A key improvement over dynamic evaluation
is that FWLs can also be applied at training time so the model learns to make
good use of gradient updates. FWLs can easily be added on top of existing
transformer models, require relatively little extra compute or memory to run,
and significantly improve language modeling perplexity."
Cold-Start Data Selection for Few-shot Language Model Fine-tuning: A Prompt-Based Uncertainty Propagation Approach,0.149337,"Large Language Models have demonstrated remarkable few-shot performance, but
the performance can be sensitive to the selection of few-shot instances. We
propose PATRON, a new method that uses prompt-based uncertainty estimation for
data selection for pre-trained language model fine-tuning under cold-start
scenarios, i.e., no initial labeled data are available. In PATRON, we design
(1) a prompt-based uncertainty propagation approach to estimate the importance
of data points and (2) a partition-then-rewrite (PTR) strategy to promote
sample diversity when querying for annotations. Experiments on six text
classification datasets show that PATRON outperforms the strongest cold-start
data selection baselines by up to 6.9%. Besides, with 128 labels only, PATRON
achieves 91.0% and 92.1% of the fully supervised performance based on vanilla
fine-tuning and prompt-based learning respectively. Our implementation of
PATRON is available at \url{https://github.com/yueyu1030/Patron}."
Entailment Semantics Can Be Extracted from an Ideal Language Model,0.185341,"Language models are often trained on text alone, without additional
grounding. There is debate as to how much of natural language semantics can be
inferred from such a procedure. We prove that entailment judgments between
sentences can be extracted from an ideal language model that has perfectly
learned its target distribution, assuming the training sentences are generated
by Gricean agents, i.e., agents who follow fundamental principles of
communication from the linguistic theory of pragmatics. We also show entailment
judgments can be decoded from the predictions of a language model trained on
such Gricean data. Our results reveal a pathway for understanding the semantic
information encoded in unlabeled linguistic data and a potential framework for
extracting semantics from language models."
Interstellar Object Accessibility and Mission Design,0.0199953,"Interstellar objects (ISOs) are fascinating and under-explored celestial
objects, providing physical laboratories to understand the formation of our
solar system and probe the composition and properties of material formed in
exoplanetary systems. This paper will discuss the accessibility of and mission
design to ISOs with varying characteristics, including a discussion of state
covariance estimation over the course of a cruise, handoffs from traditional
navigation approaches to novel autonomous navigation for fast flyby regimes,
and overall recommendations about preparing for the future in situ exploration
of these targets. The lessons learned also apply to the fast flyby of other
small bodies including long-period comets and potentially hazardous asteroids,
which also require a tactical response with similar characteristics"
Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise,0.189091,"In this paper, we introduce a novel dIffusion language modEl pre-training
framework for text generation, which we call GENIE. GENIE is a large-scale
pretrained diffusion language model that consists of an encoder and a
diffusion-based decoder, which can generate text by gradually transforming a
random noise sequence into a coherent text sequence. To pre-train GENIE on a
large-scale language corpus, we design a new continuous paragraph denoise
objective, which encourages the diffusion-decoder to reconstruct a clean text
paragraph from a corrupted version, while preserving the semantic and syntactic
coherence. We evaluate GENIE on four downstream text generation benchmarks,
namely XSum, CNN/DailyMail, Gigaword, and CommonGen. Our experimental results
show that GENIE achieves comparable performance with the state-of-the-art
autoregressive models on these benchmarks, and generates more diverse text
samples. The code and models of GENIE are available at
https://github.com/microsoft/ProphetNet/tree/master/GENIE."
Topic-Aware Response Generation in Task-Oriented Dialogue with Unstructured Knowledge Access,0.0481948,"To alleviate the problem of structured databases' limited coverage, recent
task-oriented dialogue systems incorporate external unstructured knowledge to
guide the generation of system responses. However, these usually use word or
sentence level similarities to detect the relevant knowledge context, which
only partially capture the topical level relevance. In this paper, we examine
how to better integrate topical information in knowledge grounded task-oriented
dialogue and propose ``Topic-Aware Response Generation'' (TARG), an end-to-end
response generation model. TARG incorporates multiple topic-aware attention
mechanisms to derive the importance weighting scheme over dialogue utterances
and external knowledge sources towards a better understanding of the dialogue
history. Experimental results indicate that TARG achieves state-of-the-art
performance in knowledge selection and response generation, outperforming
previous state-of-the-art by 3.2, 3.6, and 4.2 points in EM, F1 and BLEU-4
respectively on Doc2Dial, and performing comparably with previous work on
DSTC9; both being knowledge-grounded task-oriented dialogue datasets."
Adversarial Examples for Good: Adversarial Examples Guided Imbalanced Learning,0.277374,"Adversarial examples are inputs for machine learning models that have been
designed by attackers to cause the model to make mistakes. In this paper, we
demonstrate that adversarial examples can also be utilized for good to improve
the performance of imbalanced learning. We provide a new perspective on how to
deal with imbalanced data: adjust the biased decision boundary by training with
Guiding Adversarial Examples (GAEs). Our method can effectively increase the
accuracy of minority classes while sacrificing little accuracy on majority
classes. We empirically show, on several benchmark datasets, our proposed
method is comparable to the state-of-the-art method. To our best knowledge, we
are the first to deal with imbalanced learning with adversarial examples."
Unsupervised Multi-Granularity Summarization,0.0805175,"Text summarization is a user-preference based task, i.e., for one document,
users often have different priorities for summary. As a key aspect of
customization in summarization, granularity is used to measure the semantic
coverage between the summary and source document. However, developing systems
that can generate summaries with customizable semantic coverage is still an
under-explored topic. In this paper, we propose the first unsupervised
multi-granularity summarization framework, GranuSum. We take events as the
basic semantic units of the source documents and propose to rank these events
by their salience. We also develop a model to summarize input documents with
given events as anchors and hints. By inputting different numbers of events,
GranuSum is capable of producing multi-granular summaries in an unsupervised
manner. Meanwhile, we annotate a new benchmark GranuDUC that contains multiple
summaries at different granularities for each document cluster. Experimental
results confirm the substantial superiority of GranuSum on multi-granularity
summarization over strong baselines. Further, by exploiting the event
information, GranuSum also exhibits state-of-the-art performance under the
conventional unsupervised abstractive setting. Dataset for this paper can be
found at: https://github.com/maszhongming/GranuDUC"
"ESGBERT: Language Model to Help with Classification Tasks Related to Companies Environmental, Social, and Governance Practices",-1.0,"Environmental, Social, and Governance (ESG) are non-financial factors that
are garnering attention from investors as they increasingly look to apply these
as part of their analysis to identify material risks and growth opportunities.
Some of this attention is also driven by clients who, now more aware than ever,
are demanding for their money to be managed and invested responsibly. As the
interest in ESG grows, so does the need for investors to have access to
consumable ESG information. Since most of it is in text form in reports,
disclosures, press releases, and 10-Q filings, we see a need for sophisticated
NLP techniques for classification tasks for ESG text. We hypothesize that an
ESG domain-specific pre-trained model will help with such and study building of
the same in this paper. We explored doing this by fine-tuning BERTs pre-trained
weights using ESG specific text and then further fine-tuning the model for a
classification task. We were able to achieve accuracy better than the original
BERT and baseline models in environment-specific classification tasks."
AutoAttention: Automatic Field Pair Selection for Attention in User Behavior Modeling,0.698806,"In Click-through rate (CTR) prediction models, a user's interest is usually
represented as a fixed-length vector based on her history behaviors. Recently,
several methods are proposed to learn an attentive weight for each user
behavior and conduct weighted sum pooling. However, these methods only manually
select several fields from the target item side as the query to interact with
the behaviors, neglecting the other target item fields, as well as user and
context fields. Directly including all these fields in the attention may
introduce noise and deteriorate the performance. In this paper, we propose a
novel model named AutoAttention, which includes all item/user/context side
fields as the query, and assigns a learnable weight for each field pair between
behavior fields and query fields. Pruning on these field pairs via these
learnable weights lead to automatic field pair selection, so as to identify and
remove noisy field pairs. Though including more fields, the computation cost of
AutoAttention is still low due to using a simple attention function and field
pair selection. Extensive experiments on the public dataset and Tencent's
production dataset demonstrate the effectiveness of the proposed approach."
Dialect-robust Evaluation of Generated Text,0.199774,"Evaluation metrics that are not robust to dialect variation make it
impossible to tell how well systems perform for many groups of users, and can
even penalize systems for producing text in lower-resource dialects. However,
currently, there exists no way to quantify how metrics respond to change in the
dialect of a generated utterance. We thus formalize dialect robustness and
dialect awareness as goals for NLG evaluation metrics. We introduce a suite of
methods and corresponding statistical tests one can use to assess metrics in
light of the two goals. Applying the suite to current state-of-the-art metrics,
we demonstrate that they are not dialect-robust and that semantic perturbations
frequently lead to smaller decreases in a metric than the introduction of
dialect features. As a first step to overcome this limitation, we propose a
training schema, NANO, which introduces regional and language information to
the pretraining process of a metric. We demonstrate that NANO provides a
size-efficient way for models to improve the dialect robustness while
simultaneously improving their performance on the standard metric benchmark."
On Linking Level Segments,0.264245,"An increasingly common area of study in procedural content generation is the
creation of level segments: short pieces that can be used to form larger
levels. Previous work has used basic concatenation to form these larger levels.
However, even if the segments themselves are completable and well-formed,
concatenation can fail to produce levels that are completable and can cause
broken in-game structures (e.g. malformed pipes in Mario). We show this with
three tile-based games: a side-scrolling platformer, a vertical platformer, and
a top-down roguelike. Additionally, we present a Markov chain and a tree search
algorithm that finds a link between two level segments, which uses filters to
ensure completability and unbroken in-game structures in the linked segments.
We further show that these links work well for multi-segment levels. We find
that this method reliably finds links between segments and is customizable to
meet a designer's needs."
Self-Supervised Leaf Segmentation under Complex Lighting Conditions,0.342774,"As an essential prerequisite task in image-based plant phenotyping, leaf
segmentation has garnered increasing attention in recent years. While
self-supervised learning is emerging as an effective alternative to various
computer vision tasks, its adaptation for image-based plant phenotyping remains
rather unexplored. In this work, we present a self-supervised leaf segmentation
framework consisting of a self-supervised semantic segmentation model, a
color-based leaf segmentation algorithm, and a self-supervised color correction
model. The self-supervised semantic segmentation model groups the semantically
similar pixels by iteratively referring to the self-contained information,
allowing the pixels of the same semantic object to be jointly considered by the
color-based leaf segmentation algorithm for identifying the leaf regions.
Additionally, we propose to use a self-supervised color correction model for
images taken under complex illumination conditions. Experimental results on
datasets of different plant species demonstrate the potential of the proposed
self-supervised framework in achieving effective and generalizable leaf
segmentation."
On the focusing of thermal images,0.315678,"In this paper we present a new thermographic image database suitable for the
analysis of automatic focus measures. This database consists of 8 different
sets of scenes, where each scene contains one image for 96 different focus
positions. Using this database we evaluate the usefulness of six focus measures
with the goal to determine the optimal focus position. Experimental results
reveal that an accurate automatic detection of optimal focus position is
possible, even with a low computational burden. We also present an acquisition
tool able to help the acquisition of thermal images. To the best of our
knowledge, this is the first study about automatic focus of thermal images."
Robust PCA Unrolling Network for Super-resolution Vessel Extraction in X-ray Coronary Angiography,0.274827,"Although robust PCA has been increasingly adopted to extract vessels from
X-ray coronary angiography (XCA) images, challenging problems such as
inefficient vessel-sparsity modelling, noisy and dynamic background artefacts,
and high computational cost still remain unsolved. Therefore, we propose a
novel robust PCA unrolling network with sparse feature selection for
super-resolution XCA vessel imaging. Being embedded within a patch-wise
spatiotemporal super-resolution framework that is built upon a pooling layer
and a convolutional long short-term memory network, the proposed network can
not only gradually prune complex vessel-like artefacts and noisy backgrounds in
XCA during network training but also iteratively learn and select the
high-level spatiotemporal semantic information of moving contrast agents
flowing in the XCA-imaged vessels. The experimental results show that the
proposed method significantly outperforms state-of-the-art methods, especially
in the imaging of the vessel network and its distal vessels, by restoring the
intensity and geometry profiles of heterogeneous vessels against complex and
dynamic backgrounds."
Learning to Generalize to More: Continuous Semantic Augmentation for Neural Machine Translation,0.13953,"The principal task in supervised neural machine translation (NMT) is to learn
to generate target sentences conditioned on the source inputs from a set of
parallel sentence pairs, and thus produce a model capable of generalizing to
unseen instances. However, it is commonly observed that the generalization
performance of the model is highly influenced by the amount of parallel data
used in training. Although data augmentation is widely used to enrich the
training data, conventional methods with discrete manipulations fail to
generate diverse and faithful training samples. In this paper, we present a
novel data augmentation paradigm termed Continuous Semantic Augmentation
(CsaNMT), which augments each training instance with an adjacency semantic
region that could cover adequate variants of literal expression under the same
meaning. We conduct extensive experiments on both rich-resource and
low-resource settings involving various language pairs, including WMT14
English-{German,French}, NIST Chinese-English and multiple low-resource IWSLT
translation tasks. The provided empirical evidences show that CsaNMT sets a new
level of performance among existing augmentation techniques, improving on the
state-of-the-art by a large margin. The core codes are contained in Appendix E."
Computing Programs for Generalized Planning as Heuristic Search,0.0260868,"Although heuristic search is one of the most successful approaches to
classical planning, this planning paradigm does not apply straightforwardly to
Generalized Planning (GP). This paper adapts the planning as heuristic search
paradigm to the particularities of GP, and presents the first native heuristic
search approach to GP. First, the paper defines a program-based solution space
for GP that is independent of the number of planning instances in a GP problem,
and the size of these instances. Second, the paper defines the BFGP algorithm
for GP, that implements a best-first search in our program-based solution
space, and that is guided by different evaluation and heuristic functions."
AUC Maximization for Low-Resource Named Entity Recognition,0.0373597,"Current work in named entity recognition (NER) uses either cross entropy (CE)
or conditional random fields (CRF) as the objective/loss functions to optimize
the underlying NER model. Both of these traditional objective functions for the
NER problem generally produce adequate performance when the data distribution
is balanced and there are sufficient annotated training examples. But since NER
is inherently an imbalanced tagging problem, the model performance under the
low-resource settings could suffer using these standard objective functions.
Based on recent advances in area under the ROC curve (AUC) maximization, we
propose to optimize the NER model by maximizing the AUC score. We give evidence
that by simply combining two binary-classifiers that maximize the AUC score,
significant performance improvement over traditional loss functions is achieved
under low-resource NER settings. We also conduct extensive experiments to
demonstrate the advantages of our method under the low-resource and
highly-imbalanced data distribution settings. To the best of our knowledge,
this is the first work that brings AUC maximization to the NER setting.
Furthermore, we show that our method is agnostic to different types of NER
embeddings, models and domains. The code to replicate this work will be
provided upon request."
Image Search with Text Feedback by Additive Attention Compositional Learning,0.155086,"Effective image retrieval with text feedback stands to impact a range of
real-world applications, such as e-commerce. Given a source image and text
feedback that describes the desired modifications to that image, the goal is to
retrieve the target images that resemble the source yet satisfy the given
modifications by composing a multi-modal (image-text) query. We propose a novel
solution to this problem, Additive Attention Compositional Learning (AACL),
that uses a multi-modal transformer-based architecture and effectively models
the image-text contexts. Specifically, we propose a novel image-text
composition module based on additive attention that can be seamlessly plugged
into deep neural networks. We also introduce a new challenging benchmark
derived from the Shopping100k dataset. AACL is evaluated on three large-scale
datasets (FashionIQ, Fashion200k, and Shopping100k), each with strong
baselines. Extensive experiments show that AACL achieves new state-of-the-art
results on all three datasets."
Asking the Right Questions in Low Resource Template Extraction,0.0570454,"Information Extraction (IE) researchers are mapping tasks to Question
Answering (QA) in order to leverage existing large QA resources, and thereby
improve data efficiency. Especially in template extraction (TE), mapping an
ontology to a set of questions can be more time-efficient than collecting
labeled examples. We ask whether end users of TE systems can design these
questions, and whether it is beneficial to involve an NLP practitioner in the
process. We compare questions to other ways of phrasing natural language
prompts for TE. We propose a novel model to perform TE with prompts, and find
it benefits from questions over other styles of prompts, and that they do not
require an NLP background to author."
Competency Assessment for Autonomous Agents using Deep Generative Models,0.033462,"For autonomous agents to act as trustworthy partners to human users, they
must be able to reliably communicate their competency for the tasks they are
asked to perform. Towards this objective, we develop probabilistic world models
based on deep generative modelling that allow for the simulation of agent
trajectories and accurate calculation of tasking outcome probabilities. By
combining the strengths of conditional variational autoencoders with recurrent
neural networks, the deep generative world model can probabilistically forecast
trajectories over long horizons to task completion. We show how these
forecasted trajectories can be used to calculate outcome probability
distributions, which enable the precise assessment of agent competency for
specific tasks and initial settings."
MoDi: Unconditional Motion Synthesis from Diverse Data,0.246144,"The emergence of neural networks has revolutionized the field of motion
synthesis. Yet, learning to unconditionally synthesize motions from a given
distribution remains challenging, especially when the motions are highly
diverse. In this work, we present MoDi -- a generative model trained in an
unsupervised setting from an extremely diverse, unstructured and unlabeled
dataset. During inference, MoDi can synthesize high-quality, diverse motions.
Despite the lack of any structure in the dataset, our model yields a
well-behaved and highly structured latent space, which can be semantically
clustered, constituting a strong motion prior that facilitates various
applications including semantic editing and crowd simulation. In addition, we
present an encoder that inverts real motions into MoDi's natural motion
manifold, issuing solutions to various ill-posed challenges such as completion
from prefix and spatial editing. Our qualitative and quantitative experiments
achieve state-of-the-art results that outperform recent SOTA techniques. Code
and trained models are available at https://sigal-raab.github.io/MoDi."
LobsDICE: Offline Learning from Observation via Stationary Distribution Correction Estimation,0.0638299,"We consider the problem of learning from observation (LfO), in which the
agent aims to mimic the expert's behavior from the state-only demonstrations by
experts. We additionally assume that the agent cannot interact with the
environment but has access to the action-labeled transition data collected by
some agents with unknown qualities. This offline setting for LfO is appealing
in many real-world scenarios where the ground-truth expert actions are
inaccessible and the arbitrary environment interactions are costly or risky. In
this paper, we present LobsDICE, an offline LfO algorithm that learns to
imitate the expert policy via optimization in the space of stationary
distributions. Our algorithm solves a single convex minimization problem, which
minimizes the divergence between the two state-transition distributions induced
by the expert and the agent policy. Through an extensive set of offline LfO
tasks, we show that LobsDICE outperforms strong baseline methods."
Measuring Cognitive Workload Using Multimodal Sensors,0.153401,"This study aims to identify a set of indicators to estimate cognitive
workload using a multimodal sensing approach and machine learning. A set of
three cognitive tests were conducted to induce cognitive workload in twelve
participants at two levels of task difficulty (Easy and Hard). Four sensors
were used to measure the participants' physiological change, including,
Electrocardiogram (ECG), electrodermal activity (EDA), respiration (RESP), and
blood oxygen saturation (SpO2). To understand the perceived cognitive workload,
NASA-TLX was used after each test and analysed using Chi-Square test. Three
well-know classifiers (LDA, SVM, and DT) were trained and tested independently
using the physiological data. The statistical analysis showed that
participants' perceived cognitive workload was significantly different
(p<0.001) between the tests, which demonstrated the validity of the
experimental conditions to induce different cognitive levels. Classification
results showed that a fusion of ECG and EDA presented good discriminating power
(acc=0.74) for cognitive workload detection. This study provides preliminary
results in the identification of a possible set of indicators of cognitive
workload. Future work needs to be carried out to validate the indicators using
more realistic scenarios and with a larger population."
Depth Field Networks for Generalizable Multi-view Scene Representation,0.0471364,"Modern 3D computer vision leverages learning to boost geometric reasoning,
mapping image data to classical structures such as cost volumes or epipolar
constraints to improve matching. These architectures are specialized according
to the particular problem, and thus require significant task-specific tuning,
often leading to poor domain generalization performance. Recently, generalist
Transformer architectures have achieved impressive results in tasks such as
optical flow and depth estimation by encoding geometric priors as inputs rather
than as enforced constraints. In this paper, we extend this idea and propose to
learn an implicit, multi-view consistent scene representation, introducing a
series of 3D data augmentation techniques as a geometric inductive prior to
increase view diversity. We also show that introducing view synthesis as an
auxiliary task further improves depth estimation. Our Depth Field Networks
(DeFiNe) achieve state-of-the-art results in stereo and video depth estimation
without explicit geometric constraints, and improve on zero-shot domain
generalization by a wide margin."
Indian Commercial Truck License Plate Detection and Recognition for Weighbridge Automation,0.08508,"Detection and recognition of a licence plate is important when automating
weighbridge services. While many large databases are available for Latin and
Chinese alphanumeric license plates, data for Indian License Plates is
inadequate. In particular, databases of Indian commercial truck license plates
are inadequate, despite the fact that commercial vehicle license plate
recognition plays a profound role in terms of logistics management and
weighbridge automation. Moreover, models to recognise license plates are not
effectively able to generalise to such data due to its challenging nature, and
due to the abundant frequency of handwritten license plates, leading to the
usage of diverse font styles. Thus, a database and effective models to
recognise and detect such license plates are crucial. This paper provides a
database on commercial truck license plates, and using state-of-the-art models
in real-time object Detection: You Only Look Once Version 7, and SceneText
Recognition: Permuted Autoregressive Sequence Models, our method outperforms
the other cited references where the maximum accuracy obtained was less than
90%, while we have achieved 95.82% accuracy in our algorithm implementation on
the presented challenging license plate dataset. Index Terms- Automatic License
Plate Recognition, character recognition, license plate detection, vision
transformer."
SNeS: Learning Probably Symmetric Neural Surfaces from Incomplete Data,0.111281,"We present a method for the accurate 3D reconstruction of partly-symmetric
objects. We build on the strengths of recent advances in neural reconstruction
and rendering such as Neural Radiance Fields (NeRF). A major shortcoming of
such approaches is that they fail to reconstruct any part of the object which
is not clearly visible in the training image, which is often the case for
in-the-wild images and videos. When evidence is lacking, structural priors such
as symmetry can be used to complete the missing information. However,
exploiting such priors in neural rendering is highly non-trivial: while
geometry and non-reflective materials may be symmetric, shadows and reflections
from the ambient scene are not symmetric in general. To address this, we apply
a soft symmetry constraint to the 3D geometry and material properties, having
factored appearance into lighting, albedo colour and reflectivity. We evaluate
our method on the recently introduced CO3D dataset, focusing on the car
category due to the challenge of reconstructing highly-reflective materials. We
show that it can reconstruct unobserved regions with high fidelity and render
high-quality novel view images."
A Novel Self-Knowledge Distillation Approach with Siamese Representation Learning for Action Recognition,0.0297184,"Knowledge distillation is an effective transfer of knowledge from a heavy
network (teacher) to a small network (student) to boost students' performance.
Self-knowledge distillation, the special case of knowledge distillation, has
been proposed to remove the large teacher network training process while
preserving the student's performance. This paper introduces a novel
Self-knowledge distillation approach via Siamese representation learning, which
minimizes the difference between two representation vectors of the two
different views from a given sample. Our proposed method, SKD-SRL, utilizes
both soft label distillation and the similarity of representation vectors.
Therefore, SKD-SRL can generate more consistent predictions and representations
in various views of the same data point. Our benchmark has been evaluated on
various standard datasets. The experimental results have shown that SKD-SRL
significantly improves the accuracy compared to existing supervised learning
and knowledge distillation methods regardless of the networks."
arXivEdits: Understanding the Human Revision Process in Scientific Writing,0.0943967,"Scientific publications are the primary means to communicate research
discoveries, where the writing quality is of crucial importance. However, prior
work studying the human editing process in this domain mainly focused on the
abstract or introduction sections, resulting in an incomplete picture. In this
work, we provide a complete computational framework for studying text revision
in scientific writing. We first introduce arXivEdits, a new annotated corpus of
751 full papers from arXiv with gold sentence alignment across their multiple
versions of revision, as well as fine-grained span-level edits and their
underlying intentions for 1,000 sentence pairs. It supports our data-driven
analysis to unveil the common strategies practiced by researchers for revising
their papers. To scale up the analysis, we also develop automatic methods to
extract revision at document-, sentence-, and word-levels. A neural CRF
sentence alignment model trained on our corpus achieves 93.8 F1, enabling the
reliable matching of sentences between different versions. We formulate the
edit extraction task as a span alignment problem, and our proposed method
extracts more fine-grained and explainable edits, compared to the commonly used
diff algorithm. An intention classifier trained on our dataset achieves 78.9 F1
on the fine-grained intent classification task. Our data and system are
released at tiny.one/arxivedits."
Affective Behavior Analysis using Action Unit Relation Graph and Multi-task Cross Attention,0.0381792,"Facial behavior analysis is a broad topic with various categories such as
facial emotion recognition, age, and gender recognition. Many studies focus on
individual tasks while the multi-task learning approach is still an open
research issue and requires more research. In this paper, we present our
solution and experiment result for the Multi-Task Learning challenge of the
Affective Behavior Analysis in-the-wild competition. The challenge is a
combination of three tasks: action unit detection, facial expression
recognition, and valance-arousal estimation. To address this challenge, we
introduce a cross-attentive module to improve multi-task learning performance.
Additionally, a facial graph is applied to capture the association among action
units. As a result, we achieve the evaluation measure of 128.8 on the
validation data provided by the organizers, which outperforms the baseline
result of 30."
Wireless Ad Hoc Federated Learning: A Fully Distributed Cooperative Machine Learning,0.508806,"Privacy-sensitive data is stored in autonomous vehicles, smart devices, or
sensor nodes that can move around with making opportunistic contact with each
other. Federation among such nodes was mainly discussed in the context of
federated learning with a centralized mechanism in many works. However, because
of multi-vendor issues, those nodes do not want to rely on a specific server
operated by a third party for this purpose. In this paper, we propose a
wireless ad hoc federated learning (WAFL) -- a fully distributed cooperative
machine learning organized by the nodes physically nearby. WAFL can develop
generalized models from Non-IID datasets stored in distributed nodes locally by
exchanging and aggregating them with each other over opportunistic node-to-node
contacts. In our benchmark-based evaluation with various opportunistic
networks, WAFL has achieved higher accuracy of 94.8-96.3% than the
self-training case of 84.7%. All our evaluation results show that WAFL can
train and converge the model parameters from highly-partitioned Non-IID
datasets over opportunistic networks without any centralized mechanisms."
On Label Granularity and Object Localization,0.167957,"Weakly supervised object localization (WSOL) aims to learn representations
that encode object location using only image-level category labels. However,
many objects can be labeled at different levels of granularity. Is it an
animal, a bird, or a great horned owl? Which image-level labels should we use?
In this paper we study the role of label granularity in WSOL. To facilitate
this investigation we introduce iNatLoc500, a new large-scale fine-grained
benchmark dataset for WSOL. Surprisingly, we find that choosing the right
training label granularity provides a much larger performance boost than
choosing the best WSOL algorithm. We also show that changing the label
granularity can significantly improve data efficiency."
Building an Endangered Language Resource in the Classroom: Universal Dependencies for Kakataibo,0.0363114,"In this paper, we launch a new Universal Dependencies treebank for an
endangered language from Amazonia: Kakataibo, a Panoan language spoken in Peru.
We first discuss the collaborative methodology implemented, which proved
effective to create a treebank in the context of a Computational Linguistic
course for undergraduates. Then, we describe the general details of the
treebank and the language-specific considerations implemented for the proposed
annotation. We finally conduct some experiments on part-of-speech tagging and
syntactic dependency parsing. We focus on monolingual and transfer learning
settings, where we study the impact of a Shipibo-Konibo treebank, another
Panoan language resource."
Domain-Agnostic Prior for Transfer Semantic Segmentation,0.201728,"Unsupervised domain adaptation (UDA) is an important topic in the computer
vision community. The key difficulty lies in defining a common property between
the source and target domains so that the source-domain features can align with
the target-domain semantics. In this paper, we present a simple and effective
mechanism that regularizes cross-domain representation learning with a
domain-agnostic prior (DAP) that constrains the features extracted from source
and target domains to align with a domain-agnostic space. In practice, this is
easily implemented as an extra loss term that requires a little extra costs. In
the standard evaluation protocol of transferring synthesized data to real data,
we validate the effectiveness of different types of DAP, especially that
borrowed from a text embedding model that shows favorable performance beyond
the state-of-the-art UDA approaches in terms of segmentation accuracy. Our
research reveals that UDA benefits much from better proxies, possibly from
other data modalities."
Hyperbolic Relevance Matching for Neural Keyphrase Extraction,0.189627,"Keyphrase extraction is a fundamental task in natural language processing and
information retrieval that aims to extract a set of phrases with important
information from a source document. Identifying important keyphrase is the
central component of the keyphrase extraction task, and its main challenge is
how to represent information comprehensively and discriminate importance
accurately. In this paper, to address these issues, we design a new hyperbolic
matching model (HyperMatch) to represent phrases and documents in the same
hyperbolic space and explicitly estimate the phrase-document relevance via the
Poincar\'e distance as the important score of each phrase. Specifically, to
capture the hierarchical syntactic and semantic structure information,
HyperMatch takes advantage of the hidden representations in multiple layers of
RoBERTa and integrates them as the word embeddings via an adaptive mixing
layer. Meanwhile, considering the hierarchical structure hidden in the
document, HyperMatch embeds both phrases and documents in the same hyperbolic
space via a hyperbolic phrase encoder and a hyperbolic document encoder. This
strategy can further enhance the estimation of phrase-document relevance due to
the good properties of hyperbolic space. In this setting, the keyphrase
extraction can be taken as a matching problem and effectively implemented by
minimizing a hyperbolic margin-based triplet loss. Extensive experiments are
conducted on six benchmarks and demonstrate that HyperMatch outperforms the
state-of-the-art baselines."
A Hierarchical Interactive Network for Joint Span-based Aspect-Sentiment Analysis,0.0389585,"Recently, some span-based methods have achieved encouraging performances for
joint aspect-sentiment analysis, which first extract aspects (aspect
extraction) by detecting aspect boundaries and then classify the span-level
sentiments (sentiment classification). However, most existing approaches either
sequentially extract task-specific features, leading to insufficient feature
interactions, or they encode aspect features and sentiment features in a
parallel manner, implying that feature representation in each task is largely
independent of each other except for input sharing. Both of them ignore the
internal correlations between the aspect extraction and sentiment
classification. To solve this problem, we novelly propose a hierarchical
interactive network (HI-ASA) to model two-way interactions between two tasks
appropriately, where the hierarchical interactions involve two steps:
shallow-level interaction and deep-level interaction. First, we utilize
cross-stitch mechanism to combine the different task-specific features
selectively as the input to ensure proper two-way interactions. Second, the
mutual information technique is applied to mutually constrain learning between
two tasks in the output layer, thus the aspect input and the sentiment input
are capable of encoding features of the other task via backpropagation.
Extensive experiments on three real-world datasets demonstrate HI-ASA's
superiority over baselines."
SwinUNet3D -- A Hierarchical Architecture for Deep Traffic Prediction using Shifted Window Transformers,0.0734312,"Traffic forecasting is an important element of mobility management, an
important key that drives the logistics industry. Over the years, lots of work
have been done in Traffic forecasting using time series as well as
spatiotemporal dynamic forecasting. In this paper, we explore the use of vision
transformer in a UNet setting. We completely remove all convolution-based
building blocks in UNet, while using 3D shifted window transformer in both
encoder and decoder branches. In addition, we experiment with the use of
feature mixing just before patch encoding to control the inter-relationship of
the feature while avoiding contraction of the depth dimension of our
spatiotemporal input. The proposed network is tested on the data provided by
Traffic Map Movie Forecasting Challenge 2021(Traffic4cast2021), held in the
competition track of Neural Information Processing Systems (NeurIPS).
Traffic4cast2021 task is to predict an hour (6 frames) of traffic conditions
(volume and average speed)from one hour of given traffic state (12 frames
averaged in 5 minutes time span). Source code is available online at
https://github.com/bojesomo/Traffic4Cast2021-SwinUNet3D."
Why Deep Surgical Models Fail?: Revisiting Surgical Action Triplet Recognition through the Lens of Robustness,0.0937585,"Surgical action triplet recognition provides a better understanding of the
surgical scene. This task is of high relevance as it provides the surgeon with
context-aware support and safety. The current go-to strategy for improving
performance is the development of new network mechanisms. However, the
performance of current state-of-the-art techniques is substantially lower than
other surgical tasks. Why is this happening? This is the question that we
address in this work. We present the first study to understand the failure of
existing deep learning models through the lens of robustness and
explainability. Firstly, we study current existing models under weak and strong
$\delta-$perturbations via an adversarial optimisation scheme. We then analyse
the failure modes via feature based explanations. Our study reveals that the
key to improving performance and increasing reliability is in the core and
spurious attributes. Our work opens the door to more trustworthy and reliable
deep learning models in surgical data science."
Wukong-Reader: Multi-modal Pre-training for Fine-grained Visual Document Understanding,0.162849,"Unsupervised pre-training on millions of digital-born or scanned documents
has shown promising advances in visual document understanding~(VDU). While
various vision-language pre-training objectives are studied in existing
solutions, the document textline, as an intrinsic granularity in VDU, has
seldom been explored so far. A document textline usually contains words that
are spatially and semantically correlated, which can be easily obtained from
OCR engines. In this paper, we propose Wukong-Reader, trained with new
pre-training objectives to leverage the structural knowledge nested in document
textlines. We introduce textline-region contrastive learning to achieve
fine-grained alignment between the visual regions and texts of document
textlines. Furthermore, masked region modeling and textline-grid matching are
also designed to enhance the visual and layout representations of textlines.
Experiments show that our Wukong-Reader has superior performance on various VDU
tasks such as information extraction. The fine-grained alignment over textlines
also empowers Wukong-Reader with promising localization ability."
Self-distillation Augmented Masked Autoencoders for Histopathological Image Classification,0.348833,"Self-supervised learning (SSL) has drawn increasing attention in
histopathological image analysis in recent years. Compared to contrastive
learning which is troubled with the false negative problem, i.e., semantically
similar images are selected as negative samples, masked autoencoders (MAE)
building SSL from a generative paradigm is probably a more appropriate
pre-training. In this paper, we introduce MAE and verify the effect of visible
patches for histopathological image understanding. Moreover, a novel SD-MAE
model is proposed to enable a self-distillation augmented MAE. Besides the
reconstruction loss on masked image patches, SD-MAE further imposes the
self-distillation loss on visible patches to enhance the representational
capacity of the encoder located shallow layer. We apply SD-MAE to
histopathological image classification, cell segmentation and object detection.
Experiments demonstrate that SD-MAE shows highly competitive performance when
compared with other SSL methods in these tasks."
Effective Image Tampering Localization with Multi-Scale ConvNeXt Feature Fusion,0.0985381,"With the widespread use of powerful image editing tools, image tampering
becomes easy and realistic. Existing image forensic methods still face
challenges of low generalization performance and robustness. In this letter, we
propose an effective image tampering localization scheme based on ConvNeXt
network and multi-scale feature fusion. Stacked ConvNeXt blocks are used as an
encoder to capture hierarchical multi-scale features, which are then fused in
decoder for locating tampered pixels accurately. Combined loss and effective
data augmentation are adopted to further improve the model performance.
Extensive experimental results show that localization performance of our
proposed scheme outperforms other state-of-the-art ones. The source code will
be available at https://github.com/ZhuHC98/ITL-SSN."
DProQ: A Gated-Graph Transformer for Protein Complex Structure Assessment,0.0509451,"Proteins interact to form complexes to carry out essential biological
functions. Computational methods have been developed to predict the structures
of protein complexes. However, an important challenge in protein complex
structure prediction is to estimate the quality of predicted protein complex
structures without any knowledge of the corresponding native structures. Such
estimations can then be used to select high-quality predicted complex
structures to facilitate biomedical research such as protein function analysis
and drug discovery. We challenge this significant task with DProQ, which
introduces a gated neighborhood-modulating Graph Transformer (GGT) designed to
predict the quality of 3D protein complex structures. Notably, we incorporate
node and edge gates within a novel Graph Transformer framework to control
information flow during graph message passing. We train and evaluate DProQ on
four newly-developed datasets that we make publicly available in this work. Our
rigorous experiments demonstrate that DProQ achieves state-of-the-art
performance in ranking protein complex structures."
TSM: Measuring the Enticement of Honeyfiles with Natural Language Processing,0.0919002,"Honeyfile deployment is a useful breach detection method in cyber deception
that can also inform defenders about the intent and interests of intruders and
malicious insiders. A key property of a honeyfile, enticement, is the extent to
which the file can attract an intruder to interact with it. We introduce a
novel metric, Topic Semantic Matching (TSM), which uses topic modelling to
represent files in the repository and semantic matching in an embedding vector
space to compare honeyfile text and topic words robustly. We also present a
honeyfile corpus created with different Natural Language Processing (NLP)
methods. Experiments show that TSM is effective in inter-corpus comparisons and
is a promising tool to measure the enticement of honeyfiles. TSM is the first
measure to use NLP techniques to quantify the enticement of honeyfile content
that compares the essential topical content of local contexts to honeyfiles and
is robust to paraphrasing."
CTM -- A Model for Large-Scale Multi-View Tweet Topic Classification,0.196195,"Automatically associating social media posts with topics is an important
prerequisite for effective search and recommendation on many social media
platforms. However, topic classification of such posts is quite challenging
because of (a) a large topic space (b) short text with weak topical cues, and
(c) multiple topic associations per post. In contrast to most prior work which
only focuses on post classification into a small number of topics ($10$-$20$),
we consider the task of large-scale topic classification in the context of
Twitter where the topic space is $10$ times larger with potentially multiple
topic associations per Tweet. We address the challenges above by proposing a
novel neural model, CTM that (a) supports a large topic space of $300$ topics
and (b) takes a holistic approach to tweet content modeling -- leveraging
multi-modal content, author context, and deeper semantic cues in the Tweet. Our
method offers an effective way to classify Tweets into topics at scale by
yielding superior performance to other approaches (a relative lift of
$\mathbf{20}\%$ in median average precision score) and has been successfully
deployed in production at Twitter."
GeoUDF: Surface Reconstruction from 3D Point Clouds via Geometry-guided Distance Representation,0.0276087,"We present a learning-based method, namely GeoUDF,to tackle the long-standing
and challenging problem of reconstructing a discrete surface from a sparse
point cloud.To be specific, we propose a geometry-guided learning method for
UDF and its gradient estimation that explicitly formulates the unsigned
distance of a query point as the learnable affine averaging of its distances to
the tangent planes of neighboring points on the surface. Besides,we model the
local geometric structure of the input point clouds by explicitly learning a
quadratic polynomial for each point. This not only facilitates upsampling the
input sparse point cloud but also naturally induces unoriented normal, which
further augments UDF estimation. Finally, to extract triangle meshes from the
predicted UDF we propose a customized edge-based marching cube module. We
conduct extensive experiments and ablation studies to demonstrate the
significant advantages of our method over state-of-the-art methods in terms of
reconstruction accuracy, efficiency, and generality. The source code is
publicly available at https://github.com/rsy6318/GeoUDF."
In-BoXBART: Get Instructions into Biomedical Multi-Task Learning,0.121071,"Single-task models have proven pivotal in solving specific tasks; however,
they have limitations in real-world applications where multi-tasking is
necessary and domain shifts are exhibited. Recently, instructional prompts have
shown significant improvement towards multi-task generalization; however, the
effect of instructional prompts and Multi-Task Learning (MTL) has not been
systematically studied in the biomedical domain. Motivated by this, this paper
explores the impact of instructional prompts for biomedical MTL. We introduce
the BoX, a collection of 32 instruction tasks for Biomedical NLP across (X)
various categories. Using this meta-dataset, we propose a unified model termed
In-BoXBART, that can jointly learn all tasks of the BoX without any
task-specific modules. To the best of our knowledge, this is the first attempt
to propose a unified model in the biomedical domain and use instructions to
achieve generalization across several biomedical tasks. Experimental results
indicate that the proposed model: 1) outperforms the single-task baseline by
~3% and multi-task (without instruction) baseline by ~18% on an average, and 2)
shows ~23% improvement compared to the single-task baseline in few-shot
learning (i.e., 32 instances per task) on an average. Our analysis indicates
that there is significant room for improvement across tasks in the BoX,
implying the scope for future research direction."
Graph Coloring with Physics-Inspired Graph Neural Networks,0.333077,"We show how graph neural networks can be used to solve the canonical graph
coloring problem. We frame graph coloring as a multi-class node classification
problem and utilize an unsupervised training strategy based on the statistical
physics Potts model. Generalizations to other multi-class problems such as
community detection, data clustering, and the minimum clique cover problem are
straightforward. We provide numerical benchmark results and illustrate our
approach with an end-to-end application for a real-world scheduling use case
within a comprehensive encode-process-decode framework. Our optimization
approach performs on par or outperforms existing solvers, with the ability to
scale to problems with millions of variables."
DR.BENCH: Diagnostic Reasoning Benchmark for Clinical Natural Language Processing,0.138272,"The meaningful use of electronic health records (EHR) continues to progress
in the digital era with clinical decision support systems augmented by
artificial intelligence. A priority in improving provider experience is to
overcome information overload and reduce the cognitive burden so fewer medical
errors and cognitive biases are introduced during patient care. One major type
of medical error is diagnostic error due to systematic or predictable errors in
judgment that rely on heuristics. The potential for clinical natural language
processing (cNLP) to model diagnostic reasoning in humans with forward
reasoning from data to diagnosis and potentially reduce the cognitive burden
and medical error has not been investigated. Existing tasks to advance the
science in cNLP have largely focused on information extraction and named entity
recognition through classification tasks. We introduce a novel suite of tasks
coined as Diagnostic Reasoning Benchmarks, DR.BENCH, as a new benchmark for
developing and evaluating cNLP models with clinical diagnostic reasoning
ability. The suite includes six tasks from ten publicly available datasets
addressing clinical text understanding, medical knowledge reasoning, and
diagnosis generation. DR.BENCH is the first clinical suite of tasks designed to
be a natural language generation framework to evaluate pre-trained language
models. Experiments with state-of-the-art pre-trained generative language
models using large general domain models and models that were continually
trained on a medical corpus demonstrate opportunities for improvement when
evaluated in DR. BENCH. We share DR. BENCH as a publicly available GitLab
repository with a systematic approach to load and evaluate models for the cNLP
community."
Learning to Merge Tokens in Vision Transformers,-1.0,"Transformers are widely applied to solve natural language understanding and
computer vision tasks. While scaling up these architectures leads to improved
performance, it often comes at the expense of much higher computational costs.
In order for large-scale models to remain practical in real-world systems,
there is a need for reducing their computational overhead. In this work, we
present the PatchMerger, a simple module that reduces the number of patches or
tokens the network has to process by merging them between two consecutive
intermediate layers. We show that the PatchMerger achieves a significant
speedup across various model sizes while matching the original performance both
upstream and downstream after fine-tuning."
Impact of Adversarial Training on Robustness and Generalizability of Language Models,0.0128457,"Adversarial training is widely acknowledged as the most effective defense
against adversarial attacks. However, it is also well established that
achieving both robustness and generalization in adversarially trained models
involves a trade-off. The goal of this work is to provide an in depth
comparison of different approaches for adversarial training in language models.
Specifically, we study the effect of pre-training data augmentation as well as
training time input perturbations vs. embedding space perturbations on the
robustness and generalization of transformer-based language models. Our
findings suggest that better robustness can be achieved by pre-training data
augmentation or by training with input space perturbation. However, training
with embedding space perturbation significantly improves generalization. A
linguistic correlation analysis of neurons of the learned models reveals that
the improved generalization is due to 'more specialized' neurons. To the best
of our knowledge, this is the first work to carry out a deep qualitative
analysis of different methods of generating adversarial examples in adversarial
training of language models."
Maze Learning using a Hyperdimensional Predictive Processing Cognitive Architecture,0.118469,"We present the COGnitive Neural GENerative system (CogNGen), a cognitive
architecture that combines two neurobiologically-plausible, computational
models: predictive processing and hyperdimensional/vector-symbolic models. We
draw inspiration from architectures such as ACT-R and Spaun/Nengo. CogNGen is
in broad agreement with these, providing a level of detail between ACT-R's
high-level symbolic description of human cognition and Spaun's low-level
neurobiological description, furthermore creating the groundwork for designing
agents that learn continually from diverse tasks and model human performance at
larger scales than what is possible with current systems. We test CogNGen on
four maze-learning tasks, including those that test memory and planning, and
find that CogNGen matches performance of deep reinforcement learning models and
exceeds on a task designed to test memory."
Adapting the Exploration Rate for Value-of-Information-Based Reinforcement Learning,0.0322313,"In this paper, we consider the problem of adjusting the exploration rate when
using value-of-information-based exploration. We do this by converting the
value-of-information optimization into a problem of finding equilibria of a
flow for a changing exploration rate. We then develop an efficient
path-following scheme for converging to these equilibria and hence uncovering
optimal action-selection policies. Under this scheme, the exploration rate is
automatically adapted according to the agent's experiences. Global convergence
is theoretically assured.
  We first evaluate our exploration-rate adaptation on the Nintendo GameBoy
games Centipede and Millipede. We demonstrate aspects of the search process,
like that it yields a hierarchy of state abstractions. We also show that our
approach returns better policies in fewer episodes than conventional search
strategies relying on heuristic, annealing-based exploration-rate adjustments.
We then illustrate that these trends hold for deep, value-of-information-based
agents that learn to play ten simple games and over forty more complicated
games for the Nintendo GameBoy system. Performance either near or well above
the level of human play is observed."
What's Behind the Mask: Understanding Masked Graph Modeling for Graph Autoencoders,0.196193,"The last years have witnessed the emergence of a promising self-supervised
learning strategy, referred to as masked autoencoding. However, there is a lack
of theoretical understanding of how masking matters on graph autoencoders
(GAEs). In this work, we present masked graph autoencoder (MaskGAE), a
self-supervised learning framework for graph-structured data. Different from
standard GAEs, MaskGAE adopts masked graph modeling (MGM) as a principled
pretext task - masking a portion of edges and attempting to reconstruct the
missing part with partially visible, unmasked graph structure. To understand
whether MGM can help GAEs learn better representations, we provide both
theoretical and empirical evidence to comprehensively justify the benefits of
this pretext task. Theoretically, we establish close connections between GAEs
and contrastive learning, showing that MGM significantly improves the
self-supervised learning scheme of GAEs. Empirically, we conduct extensive
experiments on a variety of graph benchmarks, demonstrating the superiority of
MaskGAE over several state-of-the-arts on both link prediction and node
classification tasks."
Coalescing Global and Local Information for Procedural Text Understanding,0.0515823,"Procedural text understanding is a challenging language reasoning task that
requires models to track entity states across the development of a narrative. A
complete procedural understanding solution should combine three core aspects:
local and global views of the inputs, and global view of outputs. Prior methods
considered a subset of these aspects, resulting in either low precision or low
recall. In this paper, we propose Coalescing Global and Local Information
(CGLI), a new model that builds entity- and timestep-aware input
representations (local input) considering the whole context (global input), and
we jointly model the entity states with a structured prediction objective
(global output). Thus, CGLI simultaneously optimizes for both precision and
recall. We extend CGLI with additional output layers and integrate it into a
story reasoning framework. Extensive experiments on a popular procedural text
understanding dataset show that our model achieves state-of-the-art results;
experiments on a story reasoning benchmark show the positive impact of our
model on downstream reasoning."
Unseen Object Instance Segmentation with Fully Test-time RGB-D Embeddings Adaptation,0.288035,"Segmenting unseen objects is a crucial ability for the robot since it may
encounter new environments during the operation. Recently, a popular solution
is leveraging RGB-D features of large-scale synthetic data and directly
applying the model to unseen real-world scenarios. However, the domain shift
caused by the sim2real gap is inevitable, posing a crucial challenge to the
segmentation model. In this paper, we emphasize the adaptation process across
sim2real domains and model it as a learning problem on the BatchNorm parameters
of a simulation-trained model. Specifically, we propose a novel non-parametric
entropy objective, which formulates the learning objective for the test-time
adaptation in an open-world manner. Then, a cross-modality knowledge
distillation objective is further designed to encourage the test-time knowledge
transfer for feature enhancement. Our approach can be efficiently implemented
with only test images, without requiring annotations or revisiting the
large-scale synthetic training data. Besides significant time savings, the
proposed method consistently improves segmentation results on the overlap and
boundary metrics, achieving state-of-the-art performance on unseen object
instance segmentation."
The Whole Truth and Nothing But the Truth: Faithful and Controllable Dialogue Response Generation with Dataflow Transduction and Constrained Decoding,0.146645,"In a real-world dialogue system, generated text must be truthful and
informative while remaining fluent and adhering to a prescribed style.
Satisfying these constraints simultaneously is difficult for the two
predominant paradigms in language generation: neural language modeling and
rule-based generation. We describe a hybrid architecture for dialogue response
generation that combines the strengths of both paradigms. The first component
of this architecture is a rule-based content selection model defined using a
new formal framework called dataflow transduction, which uses declarative rules
to transduce a dialogue agent's actions and their results (represented as
dataflow graphs) into context-free grammars representing the space of
contextually acceptable responses. The second component is a constrained
decoding procedure that uses these grammars to constrain the output of a neural
language model, which selects fluent utterances. Our experiments show that this
system outperforms both rule-based and learned approaches in human evaluations
of fluency, relevance, and truthfulness."
CMNEROne at SemEval-2022 Task 11: Code-Mixed Named Entity Recognition by leveraging multilingual data,0.136365,"Identifying named entities is, in general, a practical and challenging task
in the field of Natural Language Processing. Named Entity Recognition on the
code-mixed text is further challenging due to the linguistic complexity
resulting from the nature of the mixing. This paper addresses the submission of
team CMNEROne to the SEMEVAL 2022 shared task 11 MultiCoNER. The Code-mixed NER
task aimed to identify named entities on the code-mixed dataset. Our work
consists of Named Entity Recognition (NER) on the code-mixed dataset by
leveraging the multilingual data. We achieved a weighted average F1 score of
0.7044, i.e., 6% greater than the baseline."
How does fake news use a thumbnail? CLIP-based Multimodal Detection on the Unrepresentative News Image,0.018055,"This study investigates how fake news uses a thumbnail for a news article
with a focus on whether a news article's thumbnail represents the news content
correctly. A news article shared with an irrelevant thumbnail can mislead
readers into having a wrong impression of the issue, especially in social media
environments where users are less likely to click the link and consume the
entire content. We propose to capture the degree of semantic incongruity in the
multimodal relation by using the pretrained CLIP representation. From a
source-level analysis, we found that fake news employs a more incongruous image
to the main content than general news. Going further, we attempted to detect
news articles with image-text incongruity. Evaluation experiments suggest that
CLIP-based methods can successfully detect news articles in which the thumbnail
is semantically irrelevant to news text. This study contributes to the research
by providing a novel view on tackling online fake news and misinformation. Code
and datasets are available at
https://github.com/ssu-humane/fake-news-thumbnail."
Generating Natural Language Proofs with Verifier-Guided Search,0.378094,"Reasoning over natural language is a challenging problem in NLP. In this
work, we focus on proof generation: Given a hypothesis and a set of supporting
facts, the model generates a proof tree indicating how to derive the hypothesis
from supporting facts. Compared to generating the entire proof in one shot,
stepwise generation can better exploit the compositionality and generalize to
longer proofs but has achieved limited success on real-world data. Existing
stepwise methods struggle to generate proof steps that are both logically valid
and relevant to the hypothesis. Instead, they tend to hallucinate invalid steps
given the hypothesis. In this paper, we present a novel stepwise method,
NLProofS (Natural Language Proof Search), which learns to generate relevant
steps conditioning on the hypothesis. At the core of our approach, we train an
independent verifier to check the validity of the proof steps to prevent
hallucination. Instead of generating steps greedily, we search for proofs
maximizing a global proof score judged by the verifier. NLProofS achieves
state-of-the-art performance on EntailmentBank and RuleTaker. Specifically, it
improves the correctness of predicted proofs from 27.7% to 33.3% in the
distractor setting of EntailmentBank, demonstrating the effectiveness of
NLProofS in generating challenging human-authored proofs."
Sparse2Dense: Learning to Densify 3D Features for 3D Object Detection,0.555502,"LiDAR-produced point clouds are the major source for most state-of-the-art 3D
object detectors. Yet, small, distant, and incomplete objects with sparse or
few points are often hard to detect. We present Sparse2Dense, a new framework
to efficiently boost 3D detection performance by learning to densify point
clouds in latent space. Specifically, we first train a dense point 3D detector
(DDet) with a dense point cloud as input and design a sparse point 3D detector
(SDet) with a regular point cloud as input. Importantly, we formulate the
lightweight plug-in S2D module and the point cloud reconstruction module in
SDet to densify 3D features and train SDet to produce 3D features, following
the dense 3D features in DDet. So, in inference, SDet can simulate dense 3D
features from regular (sparse) point cloud inputs without requiring dense
inputs. We evaluate our method on the large-scale Waymo Open Dataset and the
Waymo Domain Adaptation Dataset, showing its high performance and efficiency
over the state of the arts."
Semantic-Oriented Unlabeled Priming for Large-Scale Language Models,0.495175,"Due to the high costs associated with finetuning large language models,
various recent works propose to adapt them to specific tasks without any
parameter updates through in-context learning. Unfortunately, for in-context
learning there is currently no way to leverage unlabeled data, which is often
much easier to obtain in large quantities than labeled examples. In this work,
we therefore investigate ways to make use of unlabeled examples to improve the
zero-shot performance of pretrained language models without any finetuning: We
introduce Semantic-Oriented Unlabeled Priming (SOUP), a method that classifies
examples by retrieving semantically similar unlabeled examples, assigning
labels to them in a zero-shot fashion, and then using them for in-context
learning. We also propose bag-of-contexts priming, a new priming strategy that
is more suitable for our setting and enables the usage of more examples than
fit into the context window."
A study on cross-corpus speech emotion recognition and data augmentation,0.126733,"Models that can handle a wide range of speakers and acoustic conditions are
essential in speech emotion recognition (SER). Often, these models tend to show
mixed results when presented with speakers or acoustic conditions that were not
visible during training. This paper investigates the impact of cross-corpus
data complementation and data augmentation on the performance of SER models in
matched (test-set from same corpus) and mismatched (test-set from different
corpus) conditions. Investigations using six emotional speech corpora that
include single and multiple speakers as well as variations in emotion style
(acted, elicited, natural) and recording conditions are presented. Observations
show that, as expected, models trained on single corpora perform best in
matched conditions while performance decreases between 10-40% in mismatched
conditions, depending on corpus specific features. Models trained on mixed
corpora can be more stable in mismatched contexts, and the performance
reductions range from 1 to 8% when compared with single corpus models in
matched conditions. Data augmentation yields additional gains up to 4% and seem
to benefit mismatched conditions more than matched ones."
Consistent Style Transfer,0.0935844,"Recently, attentional arbitrary style transfer methods have been proposed to
achieve fine-grained results, which manipulates the point-wise similarity
between content and style features for stylization. However, the attention
mechanism based on feature points ignores the feature multi-manifold
distribution, where each feature manifold corresponds to a semantic region in
the image. Consequently, a uniform content semantic region is rendered by
highly different patterns from various style semantic regions, producing
inconsistent stylization results with visual artifacts. We proposed the
progressive attentional manifold alignment (PAMA) to alleviate this problem,
which repeatedly applies attention operations and space-aware interpolations.
The attention operation rearranges style features dynamically according to the
spatial distribution of content features. This makes the content and style
manifolds correspond on the feature map. Then the space-aware interpolation
adaptively interpolates between the corresponding content and style manifolds
to increase their similarity. By gradually aligning the content manifolds to
style manifolds, the proposed PAMA achieves state-of-the-art performance while
avoiding the inconsistency of semantic regions. Codes are available at
https://github.com/computer-vision2022/PAMA."
Layer or Representation Space: What makes BERT-based Evaluation Metrics Robust?,0.356865,"The evaluation of recent embedding-based evaluation metrics for text
generation is primarily based on measuring their correlation with human
evaluations on standard benchmarks. However, these benchmarks are mostly from
similar domains to those used for pretraining word embeddings. This raises
concerns about the (lack of) generalization of embedding-based metrics to new
and noisy domains that contain a different vocabulary than the pretraining
data. In this paper, we examine the robustness of BERTScore, one of the most
popular embedding-based metrics for text generation. We show that (a) an
embedding-based metric that has the highest correlation with human evaluations
on a standard benchmark can have the lowest correlation if the amount of input
noise or unknown tokens increases, (b) taking embeddings from the first layer
of pretrained models improves the robustness of all metrics, and (c) the
highest robustness is achieved when using character-level embeddings, instead
of token-based embeddings, from the first layer of the pretrained model."
Pre-training Language Models with Deterministic Factual Knowledge,0.0293546,"Previous works show that Pre-trained Language Models (PLMs) can capture
factual knowledge. However, some analyses reveal that PLMs fail to perform it
robustly, e.g., being sensitive to the changes of prompts when extracting
factual knowledge. To mitigate this issue, we propose to let PLMs learn the
deterministic relationship between the remaining context and the masked
content. The deterministic relationship ensures that the masked factual content
can be deterministically inferable based on the existing clues in the context.
That would provide more stable patterns for PLMs to capture factual knowledge
than randomly masking. Two pre-training tasks are further introduced to
motivate PLMs to rely on the deterministic relationship when filling masks.
Specifically, we use an external Knowledge Base (KB) to identify deterministic
relationships and continuously pre-train PLMs with the proposed methods. The
factual knowledge probing experiments indicate that the continuously
pre-trained PLMs achieve better robustness in factual knowledge capturing.
Further experiments on question-answering datasets show that trying to learn a
deterministic relationship with the proposed methods can also help other
knowledge-intensive tasks."
A description of Turkish Discourse Bank 1.2 and an examination of common dependencies in Turkish discourse,0.0273446,"We describe Turkish Discourse Bank 1.2, the latest version of a discourse
corpus annotated for explicitly or implicitly conveyed discourse relations,
their constitutive units, and senses in the Penn Discourse Treebank style. We
present an evaluation of the recently added tokens and examine three commonly
occurring dependency patterns that hold among the constitutive units of a pair
of adjacent discourse relations, namely, shared arguments, full embedding and
partial containment of a discourse relation. We present three major findings:
(a) implicitly conveyed relations occur more often than explicitly conveyed
relations in the data; (b) it is much more common for two adjacent implicit
discourse relations to share an argument than for two adjacent explicit
relations to do so; (c) both full embedding and partial containment of
discourse relations are pervasive in the corpus, which can be partly due to
subordinator connectives whose preposed subordinate clause tends to be selected
together with the matrix clause rather than being selected alone. Finally, we
briefly discuss the implications of our findings for Turkish discourse parsing."
"Two ways to make your robot proactive: reasoning about human intentions, or reasoning about possible futures",0.029901,"Robots sharing their space with humans need to be proactive in order to be
helpful. Proactive robots are able to act on their own initiative in an
anticipatory way to benefit humans. In this work, we investigate two ways to
make robots proactive. One way is to recognize humans' intentions and to act to
fulfill them, like opening the door that you are about to cross. The other way
is to reason about possible future threats or opportunities and to act to
prevent or to foster them, like recommending you to take an umbrella since rain
has been forecasted. In this paper, we present approaches to realize these two
types of proactive behavior. We then present an integrated system that can
generate proactive robot behavior by reasoning on both factors: intentions and
predictions. We illustrate our system on a sample use case including a domestic
robot and a human. We first run this use case with the two separate proactive
systems, intention-based and prediction-based, and then run it with our
integrated system. The results show that the integrated system is able to take
into account a broader variety of aspects that are needed for proactivity."
HSE-NN Team at the 4th ABAW Competition: Multi-task Emotion Recognition and Learning from Synthetic Images,0.101834,"In this paper, we present the results of the HSE-NN team in the 4th
competition on Affective Behavior Analysis in-the-wild (ABAW). The novel
multi-task EfficientNet model is trained for simultaneous recognition of facial
expressions and prediction of valence and arousal on static photos. The
resulting MT-EmotiEffNet extracts visual features that are fed into simple
feed-forward neural networks in the multi-task learning challenge. We obtain
performance measure 1.3 on the validation set, which is significantly greater
when compared to either performance of baseline (0.3) or existing models that
are trained only on the s-Aff-Wild2 database. In the learning from synthetic
data challenge, the quality of the original synthetic training set is increased
by using the super-resolution techniques, such as Real-ESRGAN. Next, the
MT-EmotiEffNet is fine-tuned on the new training set. The final prediction is a
simple blending ensemble of pre-trained and fine-tuned MT-EmotiEffNets. Our
average validation F1 score is 18% greater than the baseline convolutional
neural network."
FL Games: A federated learning framework for distribution shifts,0.151028,"Federated learning aims to train predictive models for data that is
distributed across clients, under the orchestration of a server. However,
participating clients typically each hold data from a different distribution,
whereby predictive models with strong in-distribution generalization can fail
catastrophically on unseen domains. In this work, we argue that in order to
generalize better across non-i.i.d. clients, it is imperative to only learn
correlations that are stable and invariant across domains. We propose FL Games,
a game-theoretic framework for federated learning for learning causal features
that are invariant across clients. While training to achieve the Nash
equilibrium, the traditional best response strategy suffers from high-frequency
oscillations. We demonstrate that FL Games effectively resolves this challenge
and exhibits smooth performance curves. Further, FL Games scales well in the
number of clients, requires significantly fewer communication rounds, and is
agnostic to device heterogeneity. Through empirical evaluation, we demonstrate
that FL Games achieves high out-of-distribution performance on various
benchmarks."
An End-to-End Dialogue Summarization System for Sales Calls,0.187388,"Summarizing sales calls is a routine task performed manually by salespeople.
We present a production system which combines generative models fine-tuned for
customer-agent setting, with a human-in-the-loop user experience for an
interactive summary curation process. We address challenging aspects of
dialogue summarization task in a real-world setting including long input
dialogues, content validation, lack of labeled data and quality evaluation. We
show how GPT-3 can be leveraged as an offline data labeler to handle training
data scarcity and accommodate privacy constraints in an industrial setting.
Experiments show significant improvements by our models in tackling the
summarization and content validation tasks on public datasets."
Fairness Increases Adversarial Vulnerability,0.0378866,"The remarkable performance of deep learning models and their applications in
consequential domains (e.g., facial recognition) introduces important
challenges at the intersection of equity and security. Fairness and robustness
are two desired notions often required in learning models. Fairness ensures
that models do not disproportionately harm (or benefit) some groups over
others, while robustness measures the models' resilience against small input
perturbations.
  This paper shows the existence of a dichotomy between fairness and
robustness, and analyzes when achieving fairness decreases the model robustness
to adversarial samples. The reported analysis sheds light on the factors
causing such contrasting behavior, suggesting that distance to the decision
boundary across groups as a key explainer for this behavior. Extensive
experiments on non-linear models and different architectures validate the
theoretical findings in multiple vision domains. Finally, the paper proposes a
simple, yet effective, solution to construct models achieving good tradeoffs
between fairness and robustness."
Towards Generalizable and Robust Text-to-SQL Parsing,0.209627,"Text-to-SQL parsing tackles the problem of mapping natural language questions
to executable SQL queries. In practice, text-to-SQL parsers often encounter
various challenging scenarios, requiring them to be generalizable and robust.
While most existing work addresses a particular generalization or robustness
challenge, we aim to study it in a more comprehensive manner. In specific, we
believe that text-to-SQL parsers should be (1) generalizable at three levels of
generalization, namely i.i.d., zero-shot, and compositional, and (2) robust
against input perturbations. To enhance these capabilities of the parser, we
propose a novel TKK framework consisting of Task decomposition, Knowledge
acquisition, and Knowledge composition to learn text-to-SQL parsing in stages.
By dividing the learning process into multiple stages, our framework improves
the parser's ability to acquire general SQL knowledge instead of capturing
spurious patterns, making it more generalizable and robust. Experimental
results under various generalization and robustness settings show that our
framework is effective in all scenarios and achieves state-of-the-art
performance on the Spider, SParC, and CoSQL datasets. Code can be found at
https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/tkk."
IronDepth: Iterative Refinement of Single-View Depth using Surface Normal and its Uncertainty,0.343075,"Single image surface normal estimation and depth estimation are closely
related problems as the former can be calculated from the latter. However, the
surface normals computed from the output of depth estimation methods are
significantly less accurate than the surface normals directly estimated by
networks. To reduce such discrepancy, we introduce a novel framework that uses
surface normal and its uncertainty to recurrently refine the predicted
depth-map. The depth of each pixel can be propagated to a query pixel, using
the predicted surface normal as guidance. We thus formulate depth refinement as
a classification of choosing the neighboring pixel to propagate from. Then, by
propagating to sub-pixel points, we upsample the refined, low-resolution
output. The proposed method shows state-of-the-art performance on NYUv2 and
iBims-1 - both in terms of depth and normal. Our refinement module can also be
attached to the existing depth estimation methods to improve their accuracy. We
also show that our framework, only trained for depth estimation, can also be
used for depth completion. The code is available at
https://github.com/baegwangbin/IronDepth."
In-Vehicle Interface Adaptation to Environment-Induced Cognitive Workload,0.0412657,"Many car accidents are caused by human distractions, including cognitive
distractions. In-vehicle human-machine interfaces (HMIs) have evolved
throughout the years, providing more and more functions. Interaction with the
HMIs can, however, also lead to further distractions and, as a consequence,
accidents. To tackle this problem, we propose using adaptive HMIs that change
according to the mental workload of the driver. In this work, we present the
current status as well as preliminary results of a user study using
naturalistic secondary tasks while driving (i.e., the primary task) that
attempt to understand the effects of one such interface."
One Step at a Time: Long-Horizon Vision-and-Language Navigation with Milestones,0.575011,"We study the problem of developing autonomous agents that can follow human
instructions to infer and perform a sequence of actions to complete the
underlying task. Significant progress has been made in recent years, especially
for tasks with short horizons. However, when it comes to long-horizon tasks
with extended sequences of actions, an agent can easily ignore some
instructions or get stuck in the middle of the long instructions and eventually
fail the task. To address this challenge, we propose a model-agnostic
milestone-based task tracker (M-TRACK) to guide the agent and monitor its
progress. Specifically, we propose a milestone builder that tags the
instructions with navigation and interaction milestones which the agent needs
to complete step by step, and a milestone checker that systemically checks the
agent's progress in its current milestone and determines when to proceed to the
next. On the challenging ALFRED dataset, our M-TRACK leads to a notable 33% and
52% relative improvement in unseen success rate over two competitive base
models."
A two-step approach to leverage contextual data: speech recognition in air-traffic communications,0.0402931,"Automatic Speech Recognition (ASR), as the assistance of speech communication
between pilots and air-traffic controllers, can significantly reduce the
complexity of the task and increase the reliability of transmitted information.
ASR application can lead to a lower number of incidents caused by
misunderstanding and improve air traffic management (ATM) efficiency.
Evidently, high accuracy predictions, especially, of key information, i.e.,
callsigns and commands, are required to minimize the risk of errors. We prove
that combining the benefits of ASR and Natural Language Processing (NLP)
methods to make use of surveillance data (i.e. additional modality) helps to
considerably improve the recognition of callsigns (named entity). In this
paper, we investigate a two-step callsign boosting approach: (1) at the 1 step
(ASR), weights of probable callsign n-grams are reduced in G.fst and/or in the
decoding FST (lattices), (2) at the 2 step (NLP), callsigns extracted from the
improved recognition outputs with Named Entity Recognition (NER) are correlated
with the surveillance data to select the most suitable one. Boosting callsign
n-grams with the combination of ASR and NLP methods eventually leads up to
53.7% of an absolute, or 60.4% of a relative, improvement in callsign
recognition."
Pretrained Domain-Specific Language Model for General Information Retrieval Tasks in the AEC Domain,0.0512436,"As an essential task for the architecture, engineering, and construction
(AEC) industry, information retrieval (IR) from unstructured textual data based
on natural language processing (NLP) is gaining increasing attention. Although
various deep learning (DL) models for IR tasks have been investigated in the
AEC domain, it is still unclear how domain corpora and domain-specific
pretrained DL models can improve performance in various IR tasks. To this end,
this work systematically explores the impacts of domain corpora and various
transfer learning techniques on the performance of DL models for IR tasks and
proposes a pretrained domain-specific language model for the AEC domain. First,
both in-domain and close-domain corpora are developed. Then, two types of
pretrained models, including traditional wording embedding models and
BERT-based models, are pretrained based on various domain corpora and transfer
learning strategies. Finally, several widely used DL models for IR tasks are
further trained and tested based on various configurations and pretrained
models. The result shows that domain corpora have opposite effects on
traditional word embedding models for text classification and named entity
recognition tasks but can further improve the performance of BERT-based models
in all tasks. Meanwhile, BERT-based models dramatically outperform traditional
methods in all IR tasks, with maximum improvements of 5.4% and 10.1% in the F1
score, respectively. This research contributes to the body of knowledge in two
ways: 1) demonstrating the advantages of domain corpora and pretrained DL
models and 2) opening the first domain-specific dataset and pretrained language
model for the AEC domain, to the best of our knowledge. Thus, this work sheds
light on the adoption and application of pretrained models in the AEC domain."
An Item Response Theory Framework for Persuasion,0.0,"In this paper, we apply Item Response Theory, popular in education and
political science research, to the analysis of argument persuasiveness in
language. We empirically evaluate the model's performance on three datasets,
including a novel dataset in the area of political advocacy. We show the
advantages of separating these components under several style and content
representations, including evaluating the ability of the speaker embeddings
generated by the model to parallel real-world observations about
persuadability."
Joint Learning Content and Degradation Aware Feature for Blind Super-Resolution,0.0413059,"To achieve promising results on blind image super-resolution (SR), some
attempts leveraged the low resolution (LR) images to predict the kernel and
improve the SR performance. However, these Supervised Kernel Prediction (SKP)
methods are impractical due to the unavailable real-world blur kernels.
Although some Unsupervised Degradation Prediction (UDP) methods are proposed to
bypass this problem, the \textit{inconsistency} between degradation embedding
and SR feature is still challenging. By exploring the correlations between
degradation embedding and SR feature, we observe that jointly learning the
content and degradation aware feature is optimal. Based on this observation, a
Content and Degradation aware SR Network dubbed CDSR is proposed. Specifically,
CDSR contains three newly-established modules: (1) a Lightweight Patch-based
Encoder (LPE) is applied to jointly extract content and degradation features;
(2) a Domain Query Attention based module (DQA) is employed to adaptively
reduce the inconsistency; (3) a Codebook-based Space Compress module (CSC) that
can suppress the redundant information. Extensive experiments on several
benchmarks demonstrate that the proposed CDSR outperforms the existing UDP
models and achieves competitive performance on PSNR and SSIM even compared with
the state-of-the-art SKP methods."
Deep Model-Based Super-Resolution with Non-uniform Blur,0.055798,"We propose a state-of-the-art method for super-resolution with non-uniform
blur. Single-image super-resolution methods seek to restore a high-resolution
image from blurred, subsampled, and noisy measurements. Despite their
impressive performance, existing techniques usually assume a uniform blur
kernel. Hence, these techniques do not generalize well to the more general case
of non-uniform blur. Instead, in this paper, we address the more realistic and
computationally challenging case of spatially-varying blur. To this end, we
first propose a fast deep plug-and-play algorithm, based on linearized ADMM
splitting techniques, which can solve the super-resolution problem with
spatially-varying blur. Second, we unfold our iterative algorithm into a single
network and train it end-to-end. In this way, we overcome the intricacy of
manually tuning the parameters involved in the optimization scheme. Our
algorithm presents remarkable performance and generalizes well after a single
training to a large family of spatially-varying blur kernels, noise levels and
scale factors."
Dreamento: an open-source dream engineering toolbox for sleep EEG wearables,0.022995,"We introduce Dreamento (Dream engineering toolbox), an open-source Python
package for dream engineering using sleep electroencephalography (EEG)
wearables. Dreamento main functions are (1) real-time recording, monitoring,
analysis, and sensory stimulation, and (2) offline post-processing of the
resulting data, both in a graphical user interface (GUI). In real-time,
Dreamento is capable of (1) data recording, visualization, and navigation, (2)
power-spectrum analysis, (3) automatic sleep scoring, (4) sensory stimulation
(visual, auditory, tactile), (5) establishing text-to-speech communication, and
(6) managing annotations of automatic and manual events. The offline functions
aid in post-processing the acquired data with features to reformat the wearable
data and integrate it with non-wearable recorded modalities such as
electromyography (EMG). While Dreamento was primarily developed for (lucid)
dreaming studies, its applications can be extended to other areas of sleep
research such as closed-loop auditory stimulation and targeted memory
reactivation."
WaveGAN: Frequency-aware GAN for High-Fidelity Few-shot Image Generation,0.683889,"Existing few-shot image generation approaches typically employ fusion-based
strategies, either on the image or the feature level, to produce new images.
However, previous approaches struggle to synthesize high-frequency signals with
fine details, deteriorating the synthesis quality. To address this, we propose
WaveGAN, a frequency-aware model for few-shot image generation. Concretely, we
disentangle encoded features into multiple frequency components and perform
low-frequency skip connections to preserve outline and structural information.
Then we alleviate the generator's struggles of synthesizing fine details by
employing high-frequency skip connections, thus providing informative frequency
information to the generator. Moreover, we utilize a frequency L1-loss on the
generated and real images to further impede frequency information loss.
Extensive experiments demonstrate the effectiveness and advancement of our
method on three datasets. Noticeably, we achieve new state-of-the-art with FID
42.17, LPIPS 0.3868, FID 30.35, LPIPS 0.5076, and FID 4.96, LPIPS 0.3822
respectively on Flower, Animal Faces, and VGGFace. GitHub:
https://github.com/kobeshegu/ECCV2022_WaveGAN"
longhorns at DADC 2022: How many linguists does it take to fool a Question Answering model? A systematic approach to adversarial attacks,0.0287271,"Developing methods to adversarially challenge NLP systems is a promising
avenue for improving both model performance and interpretability. Here, we
describe the approach of the team ""longhorns"" on Task 1 of the The First
Workshop on Dynamic Adversarial Data Collection (DADC), which asked teams to
manually fool a model on an Extractive Question Answering task. Our team
finished first, with a model error rate of 62%. We advocate for a systematic,
linguistically informed approach to formulating adversarial questions, and we
describe the results of our pilot experiments, as well as our official
submission."
On Improving Cross-dataset Generalization of Deepfake Detectors,0.303505,"Facial manipulation by deep fake has caused major security risks and raised
severe societal concerns. As a countermeasure, a number of deep fake detection
methods have been proposed recently. Most of them model deep fake detection as
a binary classification problem using a backbone convolutional neural network
(CNN) architecture pretrained for the task. These CNN-based methods have
demonstrated very high efficacy in deep fake detection with the Area under the
Curve (AUC) as high as 0.99. However, the performance of these methods degrades
significantly when evaluated across datasets. In this paper, we formulate deep
fake detection as a hybrid combination of supervised and reinforcement learning
(RL) to improve its cross-dataset generalization performance. The proposed
method chooses the top-k augmentations for each test sample by an RL agent in
an image-specific manner. The classification scores, obtained using CNN, of all
the augmentations of each test image are averaged together for final real or
fake classification. Through extensive experimental validation, we demonstrate
the superiority of our method over existing published research in cross-dataset
generalization of deep fake detectors, thus obtaining state-of-the-art
performance."
Detecting Driver Drowsiness as an Anomaly Using LSTM Autoencoders,0.0114765,"In this paper, an LSTM autoencoder-based architecture is utilized for
drowsiness detection with ResNet-34 as feature extractor. The problem is
considered as anomaly detection for a single subject; therefore, only the
normal driving representations are learned and it is expected that drowsiness
representations, yielding higher reconstruction losses, are to be distinguished
according to the knowledge of the network. In our study, the confidence levels
of normal and anomaly clips are investigated through the methodology of label
assignment such that training performance of LSTM autoencoder and
interpretation of anomalies encountered during testing are analyzed under
varying confidence rates. Our method is experimented on NTHU-DDD and
benchmarked with a state-of-the-art anomaly detection method for driver
drowsiness. Results show that the proposed model achieves detection rate of
0.8740 area under curve (AUC) and is able to provide significant improvements
on certain scenarios."
Keypoint Cascade Voting for Point Cloud Based 6DoF Pose Estimation,0.220729,"We propose a novel keypoint voting 6DoF object pose estimation method, which
takes pure unordered point cloud geometry as input without RGB information. The
proposed cascaded keypoint voting method, called RCVPose3D, is based upon a
novel architecture which separates the task of semantic segmentation from that
of keypoint regression, thereby increasing the effectiveness of both and
improving the ultimate performance. The method also introduces a pairwise
constraint in between different keypoints to the loss function when regressing
the quantity for keypoint estimation, which is shown to be effective, as well
as a novel Voter Confident Score which enhances both the learning and inference
stages. Our proposed RCVPose3D achieves state-of-the-art performance on the
Occlusion LINEMOD (74.5%) and YCB-Video (96.9%) datasets, outperforming
existing pure RGB and RGB-D based methods, as well as being competitive with
RGB plus point cloud methods."
Argus++: Robust Real-time Activity Detection for Unconstrained Video Streams with Overlapping Cube Proposals,0.0434839,"Activity detection is one of the attractive computer vision tasks to exploit
the video streams captured by widely installed cameras. Although achieving
impressive performance, conventional activity detection algorithms are usually
designed under certain constraints, such as using trimmed and/or
object-centered video clips as inputs. Therefore, they failed to deal with the
multi-scale multi-instance cases in real-world unconstrained video streams,
which are untrimmed and have large field-of-views. Real-time requirements for
streaming analysis also mark brute force expansion of them unfeasible.
  To overcome these issues, we propose Argus++, a robust real-time activity
detection system for analyzing unconstrained video streams. The design of
Argus++ introduces overlapping spatio-temporal cubes as an intermediate concept
of activity proposals to ensure coverage and completeness of activity detection
through over-sampling. The overall system is optimized for real-time processing
on standalone consumer-level hardware. Extensive experiments on different
surveillance and driving scenarios demonstrated its superior performance in a
series of activity detection benchmarks, including CVPR ActivityNet ActEV 2021,
NIST ActEV SDL UF/KF, TRECVID ActEV 2020/2021, and ICCV ROAD 2021."
DeepStruct: Pretraining of Language Models for Structure Prediction,0.0610388,"We introduce a method for improving the structural understanding abilities of
language models. Unlike previous approaches that finetune the models with
task-specific augmentation, we pretrain language models on a collection of
task-agnostic corpora to generate structures from text. Our structure
pretraining enables zero-shot transfer of the learned knowledge that models
have about the structure tasks. We study the performance of this approach on 28
datasets, spanning 10 structure prediction tasks including open information
extraction, joint entity and relation extraction, named entity recognition,
relation classification, semantic role labeling, event extraction, coreference
resolution, factual probe, intent detection, and dialogue state tracking. We
further enhance the pretraining with the task-specific training sets. We show
that a 10B parameter language model transfers non-trivially to most tasks and
obtains state-of-the-art performance on 21 of 28 datasets that we evaluate."
A Human-Centric Assessment Framework for AI,0.153976,"With the rise of AI systems in real-world applications comes the need for
reliable and trustworthy AI. An essential aspect of this are explainable AI
systems. However, there is no agreed standard on how explainable AI systems
should be assessed. Inspired by the Turing test, we introduce a human-centric
assessment framework where a leading domain expert accepts or rejects the
solutions of an AI system and another domain expert. By comparing the
acceptance rates of provided solutions, we can assess how the AI system
performs compared to the domain expert, and whether the AI system's
explanations (if provided) are human-understandable. This setup -- comparable
to the Turing test -- can serve as a framework for a wide range of
human-centric AI system assessments. We demonstrate this by presenting two
instantiations: (1) an assessment that measures the classification accuracy of
a system with the option to incorporate label uncertainties; (2) an assessment
where the usefulness of provided explanations is determined in a human-centric
manner."
Modern Machine-Learning Predictive Models for Diagnosing Infectious Diseases,0.300479,"Controlling infectious diseases is a major health priority because they can
spread and infect humans, thus evolving into epidemics or pandemics. Therefore,
early detection of infectious diseases is a significant need, and many
researchers have developed models to diagnose them in the early stages. This
paper reviewed research articles for recent machine-learning (ML) algorithms
applied to infectious disease diagnosis. We searched the Web of Science,
ScienceDirect, PubMed, Springer, and IEEE databases from 2015 to 2022,
identified the pros and cons of the reviewed ML models, and discussed the
possible recommendations to advance the studies in this field. We found that
most of the articles used small datasets, and few of them used real-time data.
Our results demonstrated that a suitable ML technique depends on the nature of
the dataset and the desired goal."
A Robust Learning Methodology for Uncertainty-aware Scientific Machine Learning models,0.0667601,"Robust learning is an important issue in Scientific Machine Learning (SciML).
There are several works in the literature addressing this topic. However, there
is an increasing demand for methods that can simultaneously consider all the
different uncertainty components involved in SciML model identification. Hence,
this work proposes a comprehensive methodology for uncertainty evaluation of
the SciML that also considers several possible sources of uncertainties
involved in the identification process. The uncertainties considered in the
proposed method are the absence of theory and causal models, the sensitiveness
to data corruption or imperfection, and the computational effort. Therefore, it
was possible to provide an overall strategy for the uncertainty-aware models in
the SciML field. The methodology is validated through a case study, developing
a Soft Sensor for a polymerization reactor. The results demonstrated that the
identified Soft Sensor are robust for uncertainties, corroborating with the
consistency of the proposed approach."
ParkPredict+: Multimodal Intent and Motion Prediction for Vehicles in Parking Lots with CNN and Transformer,0.113318,"The problem of multimodal intent and trajectory prediction for human-driven
vehicles in parking lots is addressed in this paper. Using models designed with
CNN and Transformer networks, we extract temporal-spatial and contextual
information from trajectory history and local bird's eye view (BEV) semantic
images, and generate predictions about intent distribution and future
trajectory sequences. Our methods outperform existing models in accuracy, while
allowing an arbitrary number of modes, encoding complex multi-agent scenarios,
and adapting to different parking maps. To train and evaluate our method, we
present the first public 4K video dataset of human driving in parking lots with
accurate annotation, high frame rate, and rich traffic scenarios."
Learning First-Order Symbolic Planning Representations That Are Grounded,0.0818474,"Two main approaches have been developed for learning first-order planning
(action) models from unstructured data: combinatorial approaches that yield
crisp action schemas from the structure of the state space, and deep learning
approaches that produce action schemas from states represented by images. A
benefit of the former approach is that the learned action schemas are similar
to those that can be written by hand; a benefit of the latter is that the
learned representations (predicates) are grounded on the images, and as a
result, new instances can be given in terms of images. In this work, we develop
a new formulation for learning crisp first-order planning models that are
grounded on parsed images, a step to combine the benefits of the two
approaches. Parsed images are assumed to be given in a simple O2D language
(objects in 2D) that involves a small number of unary and binary predicates
like ""left"", ""above"", ""shape"", etc. After learning, new planning instances can
be given in terms of pairs of parsed images, one for the initial situation and
the other for the goal. Learning and planning experiments are reported for
several domains including Blocks, Sokoban, IPC Grid, and Hanoi."
Findings of the The RuATD Shared Task 2022 on Artificial Text Detection in Russian,0.236385,"We present the shared task on artificial text detection in Russian, which is
organized as a part of the Dialogue Evaluation initiative, held in 2022. The
shared task dataset includes texts from 14 text generators, i.e., one human
writer and 13 text generative models fine-tuned for one or more of the
following generation tasks: machine translation, paraphrase generation, text
summarization, text simplification. We also consider back-translation and
zero-shot generation approaches. The human-written texts are collected from
publicly available resources across multiple domains. The shared task consists
of two sub-tasks: (i) to determine if a given text is automatically generated
or written by a human; (ii) to identify the author of a given text. The first
task is framed as a binary classification problem. The second task is a
multi-class classification problem. We provide count-based and BERT-based
baselines, along with the human evaluation on the first sub-task. A total of 30
and 8 systems have been submitted to the binary and multi-class sub-tasks,
correspondingly. Most teams outperform the baselines by a wide margin. We
publicly release our codebase, human evaluation results, and other materials in
our GitHub repository (https://github.com/dialogue-evaluation/RuATD)."
Multi-Scale Representation Learning on Proteins,0.311931,"Proteins are fundamental biological entities mediating key roles in cellular
function and disease. This paper introduces a multi-scale graph construction of
a protein -- HoloProt -- connecting surface to structure and sequence. The
surface captures coarser details of the protein, while sequence as primary
component and structure -- comprising secondary and tertiary components --
capture finer details. Our graph encoder then learns a multi-scale
representation by allowing each level to integrate the encoding from level(s)
below with the graph at that level. We test the learned representation on
different tasks, (i.) ligand binding affinity (regression), and (ii.) protein
function prediction (classification). On the regression task, contrary to
previous methods, our model performs consistently and reliably across different
dataset splits, outperforming all baselines on most splits. On the
classification task, it achieves a performance close to the top-performing
model while using 10x fewer parameters. To improve the memory efficiency of our
construction, we segment the multiplex protein surface manifold into molecular
superpixels and substitute the surface with these superpixels at little to no
performance loss."
Training Naturalized Semantic Parsers with Very Little Data,0.0442042,"Semantic parsing is an important NLP problem, particularly for voice
assistants such as Alexa and Google Assistant. State-of-the-art (SOTA) semantic
parsers are seq2seq architectures based on large language models that have been
pretrained on vast amounts of text. To better leverage that pretraining, recent
work has explored a reformulation of semantic parsing whereby the output
sequences are themselves natural language sentences, but in a controlled
fragment of natural language. This approach delivers strong results,
particularly for few-shot semantic parsing, which is of key importance in
practice and the focus of our paper. We push this line of work forward by
introducing an automated methodology that delivers very significant additional
improvements by utilizing modest amounts of unannotated data, which is
typically easy to obtain. Our method is based on a novel synthesis of four
techniques: joint training with auxiliary unsupervised tasks; constrained
decoding; self-training; and paraphrasing. We show that this method delivers
new SOTA few-shot performance on the Overnight dataset, particularly in very
low-resource settings, and very compelling few-shot results on a new semantic
parsing dataset."
Design of High-Throughput Mixed-Precision CNN Accelerators on FPGA,0.069347,"Convolutional Neural Networks (CNNs) reach high accuracies in various
application domains, but require large amounts of computation and incur costly
data movements. One method to decrease these costs while trading accuracy is
weight and/or activation word-length reduction. Thereby, layer-wise
mixed-precision quantization allows for more efficient results while inflating
the design space. In this work, we present an in-depth quantitative methodology
to efficiently explore the design space considering the limited hardware
resources of a given FPGA. Our holistic exploration approach vertically
traverses the various design entry levels from the architectural down to the
logic level, and laterally covers optimization from processing elements to
dataflow for an efficient mixed-precision CNN accelerator. Our resulting
hardware accelerators implement truly mixed-precision operations that enable
efficient execution of layer-wise and channel-wise quantized CNNs. Mapping
feed-forward and identity-shortcut-connection mixed-precision CNNs result in
competitive accuracy-throughout trade-offs: 245 frames/s with 87.48% Top-5
accuracy for ResNet-18 and 92.9% Top-5 accuracy with 1.13 TOps/s for
ResNet-152, respectively. Thereby, the required memory footprint for parameters
is reduced by 4.9x and 9.4x compared to the respective floating-point baseline."
Arabic Word-level Readability Visualization for Assisted Text Simplification,0.0454465,"This demo paper presents a Google Docs add-on for automatic Arabic word-level
readability visualization. The add-on includes a lemmatization component that
is connected to a five-level readability lexicon and Arabic WordNet-based
substitution suggestions. The add-on can be used for assessing the reading
difficulty of a text and identifying difficult words as part of the task of
manual text simplification. We make our add-on and its code publicly available."
Live Stream Temporally Embedded 3D Human Body Pose and Shape Estimation,0.864665,"3D Human body pose and shape estimation within a temporal sequence can be
quite critical for understanding human behavior. Despite the significant
progress in human pose estimation in the recent years, which are often based on
single images or videos, human motion estimation on live stream videos is still
a rarely-touched area considering its special requirements for real-time output
and temporal consistency. To address this problem, we present a temporally
embedded 3D human body pose and shape estimation (TePose) method to improve the
accuracy and temporal consistency of pose estimation in live stream videos.
TePose uses previous predictions as a bridge to feedback the error for better
estimation in the current frame and to learn the correspondence between data
frames and predictions in the history. A multi-scale spatio-temporal graph
convolutional network is presented as the motion discriminator for adversarial
training using datasets without any 3D labeling. We propose a sequential data
loading strategy to meet the special start-to-end data processing requirement
of live stream. We demonstrate the importance of each proposed module with
extensive experiments. The results show the effectiveness of TePose on
widely-used human pose benchmarks with state-of-the-art performance."
Smart Speech Segmentation using Acousto-Linguistic Features with look-ahead,0.0433704,"Segmentation for continuous Automatic Speech Recognition (ASR) has
traditionally used silence timeouts or voice activity detectors (VADs), which
are both limited to acoustic features. This segmentation is often overly
aggressive, given that people naturally pause to think as they speak.
Consequently, segmentation happens mid-sentence, hindering both punctuation and
downstream tasks like machine translation for which high-quality segmentation
is critical. Model-based segmentation methods that leverage acoustic features
are powerful, but without an understanding of the language itself, these
approaches are limited. We present a hybrid approach that leverages both
acoustic and language information to improve segmentation. Furthermore, we show
that including one word as a look-ahead boosts segmentation quality. On
average, our models improve segmentation-F0.5 score by 9.8% over baseline. We
show that this approach works for multiple languages. For the downstream task
of machine translation, it improves the translation BLEU score by an average of
1.05 points."
InFIP: An Explainable DNN Intellectual Property Protection Method based on Intrinsic Features,0.0487837,"Intellectual property (IP) protection for Deep Neural Networks (DNNs) has
raised serious concerns in recent years. Most existing works embed watermarks
in the DNN model for IP protection, which need to modify the model and lack of
interpretability. In this paper, for the first time, we propose an
interpretable intellectual property protection method for DNN based on
explainable artificial intelligence. Compared with existing works, the proposed
method does not modify the DNN model, and the decision of the ownership
verification is interpretable. We extract the intrinsic features of the DNN
model by using Deep Taylor Decomposition. Since the intrinsic feature is
composed of unique interpretation of the model's decision, the intrinsic
feature can be regarded as fingerprint of the model. If the fingerprint of a
suspected model is the same as the original model, the suspected model is
considered as a pirated model. Experimental results demonstrate that the
fingerprints can be successfully used to verify the ownership of the model and
the test accuracy of the model is not affected. Furthermore, the proposed
method is robust to fine-tuning attack, pruning attack, watermark overwriting
attack, and adaptive attack."
e-CARE: a New Dataset for Exploring Explainable Causal Reasoning,0.311227,"Understanding causality has vital importance for various Natural Language
Processing (NLP) applications. Beyond the labeled instances, conceptual
explanations of the causality can provide deep understanding of the causal
facts to facilitate the causal reasoning process. However, such explanation
information still remains absent in existing causal reasoning resources. In
this paper, we fill this gap by presenting a human-annotated explainable CAusal
REasoning dataset (e-CARE), which contains over 21K causal reasoning questions,
together with natural language formed explanations of the causal questions.
Experimental results show that generating valid explanations for causal facts
still remains especially challenging for the state-of-the-art models, and the
explanation information can be helpful for promoting the accuracy and stability
of causal reasoning models."
Read Top News First: A Document Reordering Approach for Multi-Document News Summarization,0.182287,"A common method for extractive multi-document news summarization is to
re-formulate it as a single-document summarization problem by concatenating all
documents as a single meta-document. However, this method neglects the relative
importance of documents. We propose a simple approach to reorder the documents
according to their relative importance before concatenating and summarizing
them. The reordering makes the salient content easier to learn by the
summarization model. Experiments show that our approach outperforms previous
state-of-the-art methods with more complex architectures."
Improving Contextual Recognition of Rare Words with an Alternate Spelling Prediction Model,0.0654332,"Contextual ASR, which takes a list of bias terms as input along with audio,
has drawn recent interest as ASR use becomes more widespread. We are releasing
contextual biasing lists to accompany the Earnings21 dataset, creating a public
benchmark for this task. We present baseline results on this benchmark using a
pretrained end-to-end ASR model from the WeNet toolkit. We show results for
shallow fusion contextual biasing applied to two different decoding algorithms.
Our baseline results confirm observations that end-to-end models struggle in
particular with words that are rarely or never seen during training, and that
existing shallow fusion techniques do not adequately address this problem. We
propose an alternate spelling prediction model that improves recall of rare
words by 34.7% relative and of out-of-vocabulary words by 97.2% relative,
compared to contextual biasing without alternate spellings. This model is
conceptually similar to ones used in prior work, but is simpler to implement as
it does not rely on either a pronunciation dictionary or an existing
text-to-speech system."
LighTN: Light-weight Transformer Network for Performance-overhead Tradeoff in Point Cloud Downsampling,0.138399,"Compared with traditional task-irrelevant downsampling methods, task-oriented
neural networks have shown improved performance in point cloud downsampling
range. Recently, Transformer family of networks has shown a more powerful
learning capacity in visual tasks. However, Transformer-based architectures
potentially consume too many resources which are usually worthless for low
overhead task networks in downsampling range. This paper proposes a novel
light-weight Transformer network (LighTN) for task-oriented point cloud
downsampling, as an end-to-end and plug-and-play solution. In LighTN, a
single-head self-correlation module is presented to extract refined global
contextual features, where three projection matrices are simultaneously
eliminated to save resource overhead, and the output of symmetric matrix
satisfies the permutation invariant. Then, we design a novel downsampling loss
function to guide LighTN focuses on critical point cloud regions with more
uniform distribution and prominent points coverage. Furthermore, We introduce a
feed-forward network scaling mechanism to enhance the learnable capacity of
LighTN according to the expand-reduce strategy. The result of extensive
experiments on classification and registration tasks demonstrates LighTN can
achieve state-of-the-art performance with limited resource overhead."
TetGAN: A Convolutional Neural Network for Tetrahedral Mesh Generation,0.161524,"We present TetGAN, a convolutional neural network designed to generate
tetrahedral meshes. We represent shapes using an irregular tetrahedral grid
which encodes an occupancy and displacement field. Our formulation enables
defining tetrahedral convolution, pooling, and upsampling operations to
synthesize explicit mesh connectivity with variable topological genus. The
proposed neural network layers learn deep features over each tetrahedron and
learn to extract patterns within spatial regions across multiple scales. We
illustrate the capabilities of our technique to encode tetrahedral meshes into
a semantically meaningful latent-space which can be used for shape editing and
synthesis. Our project page is at https://threedle.github.io/tetGAN/."
Hierarchical Semi-Supervised Contrastive Learning for Contamination-Resistant Anomaly Detection,0.0902364,"Anomaly detection aims at identifying deviant samples from the normal data
distribution. Contrastive learning has provided a successful way to sample
representation that enables effective discrimination on anomalies. However,
when contaminated with unlabeled abnormal samples in training set under
semi-supervised settings, current contrastive-based methods generally 1) ignore
the comprehensive relation between training data, leading to suboptimal
performance, and 2) require fine-tuning, resulting in low efficiency. To
address the above two issues, in this paper, we propose a novel hierarchical
semi-supervised contrastive learning (HSCL) framework, for
contamination-resistant anomaly detection. Specifically, HSCL hierarchically
regulates three complementary relations: sample-to-sample, sample-to-prototype,
and normal-to-abnormal relations, enlarging the discrimination between normal
and abnormal samples with a comprehensive exploration of the contaminated data.
Besides, HSCL is an end-to-end learning approach that can efficiently learn
discriminative representations without fine-tuning. HSCL achieves
state-of-the-art performance in multiple scenarios, such as one-class
classification and cross-dataset detection. Extensive ablation studies further
verify the effectiveness of each considered relation. The code is available at
https://github.com/GaoangW/HSCL."
Universal Conditional Masked Language Pre-training for Neural Machine Translation,0.279802,"Pre-trained sequence-to-sequence models have significantly improved Neural
Machine Translation (NMT). Different from prior works where pre-trained models
usually adopt an unidirectional decoder, this paper demonstrates that
pre-training a sequence-to-sequence model but with a bidirectional decoder can
produce notable performance gains for both Autoregressive and
Non-autoregressive NMT. Specifically, we propose CeMAT, a conditional masked
language model pre-trained on large-scale bilingual and monolingual corpora in
many languages. We also introduce two simple but effective methods to enhance
the CeMAT, aligned code-switching & masking and dynamic dual-masking. We
conduct extensive experiments and show that our CeMAT can achieve significant
performance improvement for all scenarios from low- to extremely high-resource
languages, i.e., up to +14.4 BLEU on low resource and +7.9 BLEU improvements on
average for Autoregressive NMT. For Non-autoregressive NMT, we demonstrate it
can also produce consistent performance gains, i.e., up to +5.3 BLEU. To the
best of our knowledge, this is the first work to pre-train a unified model for
fine-tuning on both NMT tasks. Code, data, and pre-trained models are available
at https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/CeMAT."
Causal Balancing for Domain Generalization,0.0742411,"While machine learning models rapidly advance the state-of-the-art on various
real-world tasks, out-of-domain (OOD) generalization remains a challenging
problem given the vulnerability of these models to spurious correlations. We
propose a balanced mini-batch sampling strategy to transform a biased data
distribution into a spurious-free balanced distribution, based on the
invariance of the underlying causal mechanisms for the data generation process.
We argue that the Bayes optimal classifiers trained on such balanced
distribution are minimax optimal across a diverse enough environment space. We
also provide an identifiability guarantee of the latent variable model of the
proposed data generation process, when utilizing enough train environments.
Experiments are conducted on DomainBed, demonstrating empirically that our
method obtains the best performance across 20 baselines reported on the
benchmark."
GaitTAKE: Gait Recognition by Temporal Attention and Keypoint-guided Embedding,0.139762,"Gait recognition, which refers to the recognition or identification of a
person based on their body shape and walking styles, derived from video data
captured from a distance, is widely used in crime prevention, forensic
identification, and social security. However, to the best of our knowledge,
most of the existing methods use appearance, posture and temporal feautures
without considering a learned temporal attention mechanism for global and local
information fusion. In this paper, we propose a novel gait recognition
framework, called Temporal Attention and Keypoint-guided Embedding (GaitTAKE),
which effectively fuses temporal-attention-based global and local appearance
feature and temporal aggregated human pose feature. Experimental results show
that our proposed method achieves a new SOTA in gait recognition with rank-1
accuracy of 98.0% (normal), 97.5% (bag) and 92.2% (coat) on the CASIA-B gait
dataset; 90.4% accuracy on the OU-MVLP gait dataset."
Combining Humor and Sarcasm for Improving Political Parody Detection,0.0989714,"Parody is a figurative device used for mimicking entities for comedic or
critical purposes. Parody is intentionally humorous and often involves sarcasm.
This paper explores jointly modelling these figurative tropes with the goal of
improving performance of political parody detection in tweets. To this end, we
present a multi-encoder model that combines three parallel encoders to enrich
parody-specific representations with humor and sarcasm information. Experiments
on a publicly available data set of political parody tweets demonstrate that
our approach outperforms previous state-of-the-art methods."
Hand-Object Interaction Image Generation,0.0540551,"In this work, we are dedicated to a new task, i.e., hand-object interaction
image generation, which aims to conditionally generate the hand-object image
under the given hand, object and their interaction status. This task is
challenging and research-worthy in many potential application scenarios, such
as AR/VR games and online shopping, etc. To address this problem, we propose a
novel HOGAN framework, which utilizes the expressive model-aware hand-object
representation and leverages its inherent topology to build the unified surface
space. In this space, we explicitly consider the complex self- and mutual
occlusion during interaction. During final image synthesis, we consider
different characteristics of hand and object and generate the target image in a
split-and-combine manner. For evaluation, we build a comprehensive protocol to
access both the fidelity and structure preservation of the generated image.
Extensive experiments on two large-scale datasets, i.e., HO3Dv3 and DexYCB,
demonstrate the effectiveness and superiority of our framework both
quantitatively and qualitatively. The project page is available at
https://play-with-hoi-generation.github.io/."
Controllable Evaluation and Generation of Physical Adversarial Patch on Face Recognition,0.0830101,"Recent studies have revealed the vulnerability of face recognition models
against physical adversarial patches, which raises security concerns about the
deployed face recognition systems. However, it is still challenging to ensure
the reproducibility for most attack algorithms under complex physical
conditions, which leads to the lack of a systematic evaluation of the existing
methods. It is therefore imperative to develop a framework that can enable a
comprehensive evaluation of the vulnerability of face recognition in the
physical world. To this end, we propose to simulate the complex transformations
of faces in the physical world via 3D-face modeling, which serves as a digital
counterpart of physical faces. The generic framework allows us to control
different face variations and physical conditions to conduct reproducible
evaluations comprehensively. With this digital simulator, we further propose a
Face3DAdv method considering the 3D face transformations and realistic physical
variations. Extensive experiments validate that Face3DAdv can significantly
improve the effectiveness of diverse physically realizable adversarial patches
in both simulated and physical environments, against various white-box and
black-box face recognition models."
Geometric Graph Representation Learning via Maximizing Rate Reduction,0.0983848,"Learning discriminative node representations benefits various downstream
tasks in graph analysis such as community detection and node classification.
Existing graph representation learning methods (e.g., based on random walk and
contrastive learning) are limited to maximizing the local similarity of
connected nodes. Such pair-wise learning schemes could fail to capture the
global distribution of representations, since it has no explicit constraints on
the global geometric properties of representation space. To this end, we
propose Geometric Graph Representation Learning (G2R) to learn node
representations in an unsupervised manner via maximizing rate reduction. In
this way, G2R maps nodes in distinct groups (implicitly stored in the adjacency
matrix) into different subspaces, while each subspace is compact and different
subspaces are dispersedly distributed. G2R adopts a graph neural network as the
encoder and maximizes the rate reduction with the adjacency matrix.
Furthermore, we theoretically and empirically demonstrate that rate reduction
maximization is equivalent to maximizing the principal angles between different
subspaces. Experiments on real-world datasets show that G2R outperforms various
baselines on node classification and community detection tasks."
Can Large Language Models Truly Understand Prompts? A Case Study with Negated Prompts,0.252805,"Previous work has shown that there exists a scaling law between the size of
Language Models (LMs) and their zero-shot performance on different downstream
NLP tasks. In this work, we show that this phenomenon does not hold when
evaluating large LMs on tasks with negated prompts, but instead shows an
inverse scaling law. We evaluate 9 different tasks with negated prompts on (1)
pretrained LMs (OPT & GPT-3) of varying sizes (125M - 175B), (2) LMs further
pretrained to generalize to novel prompts (InstructGPT), (3) LMs provided with
few-shot examples, and (4) LMs fine-tuned specifically on negated prompts; all
LM types perform worse on negated prompts as they scale and show a huge
performance gap between the human performance when comparing the average score
on both original and negated prompts. By highlighting a critical limitation of
existing LMs and methods, we urge the community to develop new approaches of
developing LMs that actually follow the given instructions. We provide the code
and the datasets to explore negated prompts at
https://github.com/joeljang/negated-prompts-for-llms"
"Multi-modal Misinformation Detection: Approaches, Challenges and Opportunities",0.151826,"As social media platforms are evolving from text-based forums into
multi-modal environments, the nature of misinformation in social media is also
transforming accordingly. Taking advantage of the fact that visual modalities
such as images and videos are more favorable and attractive to the users and
textual contents are sometimes skimmed carelessly, misinformation spreaders
have recently targeted contextual connections between the modalities e.g., text
and image. Hence many researchers have developed automatic techniques for
detecting possible cross-modal discordance in web-based content. We analyze,
categorize and identify existing approaches in addition to challenges and
shortcomings they face in order to unearth new research opportunities in the
field of multi-modal misinformation detection."
VeriDark: A Large-Scale Benchmark for Authorship Verification on the Dark Web,0.113647,"The DarkWeb represents a hotbed for illicit activity, where users communicate
on different market forums in order to exchange goods and services. Law
enforcement agencies benefit from forensic tools that perform authorship
analysis, in order to identify and profile users based on their textual
content. However, authorship analysis has been traditionally studied using
corpora featuring literary texts such as fragments from novels or fan fiction,
which may not be suitable in a cybercrime context. Moreover, the few works that
employ authorship analysis tools for cybercrime prevention usually employ
ad-hoc experimental setups and datasets. To address these issues, we release
VeriDark: a benchmark comprised of three large scale authorship verification
datasets and one authorship identification dataset obtained from user activity
from either Dark Web related Reddit communities or popular illicit Dark Web
market forums. We evaluate competitive NLP baselines on the three datasets and
perform an analysis of the predictions to better understand the limitations of
such approaches. We make the datasets and baselines publicly available at
https://github.com/bit-ml/VeriDark"
Chemotaxis of sea urchin sperm cells through deep reinforcement learning,0.0971203,"By imitating biological microswimmers, microrobots can be designed to
accomplish targeted delivery of cargos and biomedical manipulations at
microscale. However, it is still a great challenge to enable microrobots to
maneuver in a complex environment. Machine learning algorithms offer a tool to
boost mobility and flexibility of a synthetic microswimmer, hence could help us
design truly smart microrobots. In this work, we investigate how a model of sea
urchin sperm cell can self-learn chemotactic motion in a chemoattractant
concentration field. We employ an artificial neural network to act as a
decision-making agent and facilitate the sperm cell to discover efficient
maneuver strategies through a deep reinforcement learning (DRL) algorithm. Our
results show that chemotactic behaviours, very similar to the realistic ones,
can be achieved by the DRL utilizing only limited environmental information. In
most cases, the DRL algorithm discovers more efficient strategies than the
human-devised one. Furthermore, the DRL can even utilize an external
disturbance to facilitate the chemotactic motion if the extra flow information
is also taken into account by the artificial neural network. Our results
provide insights to the chemotactic process of sea urchin sperm cells and also
prepare guidance for the intelligent maneuver of microrobots."
Learning to Fold Real Garments with One Arm: A Case Study in Cloud-Based Robotics Research,0.195379,"Autonomous fabric manipulation is a longstanding challenge in robotics, but
evaluating progress is difficult due to the cost and diversity of robot
hardware. Using Reach, a cloud robotics platform that enables low-latency
remote execution of control policies on physical robots, we present the first
systematic benchmarking of fabric manipulation algorithms on physical hardware.
We develop 4 novel learning-based algorithms that model expert actions,
keypoints, reward functions, and dynamic motions, and we compare these against
4 learning-free and inverse dynamics algorithms on the task of folding a
crumpled T-shirt with a single robot arm. The entire lifecycle of data
collection, model training, and policy evaluation is performed remotely without
physical access to the robot workcell. Results suggest a new algorithm
combining imitation learning with analytic methods achieves 84% of human-level
performance on the folding task. See
https://sites.google.com/berkeley.edu/cloudfolding for all data, code, models,
and supplemental material."
An Online Semantic Mapping System for Extending and Enhancing Visual SLAM,0.323573,"We present a real-time semantic mapping approach for mobile vision systems
with a 2D to 3D object detection pipeline and rapid data association for
generated landmarks. Besides the semantic map enrichment the associated
detections are further introduced as semantic constraints into a simultaneous
localization and mapping (SLAM) system for pose correction purposes. This way,
we are able generate additional meaningful information that allows to achieve
higher-level tasks, while simultaneously leveraging the view-invariance of
object detections to improve the accuracy and the robustness of the odometry
estimation. We propose tracklets of locally associated object observations to
handle ambiguous and false predictions and an uncertainty-based greedy
association scheme for an accelerated processing time. Our system reaches
real-time capabilities with an average iteration duration of 65~ms and is able
to improve the pose estimation of a state-of-the-art SLAM by up to 68% on a
public dataset. Additionally, we implemented our approach as a modular ROS
package that makes it straightforward for integration in arbitrary graph-based
SLAM methods."
Learning Sketches for Decomposing Planning Problems into Subproblems of Bounded Width: Extended Version,0.0184864,"Recently, sketches have been introduced as a general language for
representing the subgoal structure of instances drawn from the same domain.
Sketches are collections of rules of the form C -> E over a given set of
features where C expresses Boolean conditions and E expresses qualitative
changes. Each sketch rule defines a subproblem: going from a state that
satisfies C to a state that achieves the change expressed by E or a goal state.
Sketches can encode simple goal serializations, general policies, or
decompositions of bounded width that can be solved greedily, in polynomial
time, by the SIW_R variant of the SIW algorithm. Previous work has shown the
computational value of sketches over benchmark domains that, while tractable,
are challenging for domain-independent planners. In this work, we address the
problem of learning sketches automatically given a planning domain, some
instances of the target class of problems, and the desired bound on the sketch
width. We present a logical formulation of the problem, an implementation using
the ASP solver Clingo, and experimental results. The sketch learner and the
SIW_R planner yield a domain-independent planner that learns and exploits
domain structure in a crisp and explicit form."
Conformance Checking with Uncertainty via SMT (Extended Version),0.569054,"Logs of real-life processes often feature uncertainty pertaining the recorded
timestamps, data values, and/or events. We consider the problem of checking
conformance of uncertain logs against data-aware reference processes.
Specifically, we show how to solve it via SMT encodings, lifting previous work
on data-aware SMT-based conformance checking to this more sophisticated
setting. Our approach is modular, in that it homogeneously accommodates for
different types of uncertainty. Moreover, using appropriate cost functions,
different conformance checking tasks can be addressed. We show the correctness
of our approach and witness feasibility through a proof-of-concept
implementation."
Unsupervised Sentence Textual Similarity with Compositional Phrase Semantics,0.0263546,"Measuring Sentence Textual Similarity (STS) is a classic task that can be
applied to many downstream NLP applications such as text generation and
retrieval. In this paper, we focus on unsupervised STS that works on various
domains but only requires minimal data and computational resources.
Theoretically, we propose a light-weighted Expectation-Correction (EC)
formulation for STS computation. EC formulation unifies unsupervised STS
approaches including the cosine similarity of Additively Composed (AC) sentence
embeddings, Optimal Transport (OT), and Tree Kernels (TK). Moreover, we propose
the Recursive Optimal Transport Similarity (ROTS) algorithm to capture the
compositional phrase semantics by composing multiple recursive EC formulations.
ROTS finishes in linear time and is faster than its predecessors. ROTS is
empirically more effective and scalable than previous approaches. Extensive
experiments on 29 STS tasks under various settings show the clear advantage of
ROTS over existing approaches. Detailed ablation studies demonstrate the
effectiveness of our approaches."
Iterative Scene Graph Generation,0.299179,"The task of scene graph generation entails identifying object entities and
their corresponding interaction predicates in a given image (or video). Due to
the combinatorially large solution space, existing approaches to scene graph
generation assume certain factorization of the joint distribution to make the
estimation feasible (e.g., assuming that objects are conditionally independent
of predicate predictions). However, this fixed factorization is not ideal under
all scenarios (e.g., for images where an object entailed in interaction is
small and not discernible on its own). In this work, we propose a novel
framework for scene graph generation that addresses this limitation, as well as
introduces dynamic conditioning on the image, using message passing in a Markov
Random Field. This is implemented as an iterative refinement procedure wherein
each modification is conditioned on the graph generated in the previous
iteration. This conditioning across refinement steps allows joint reasoning
over entities and relations. This framework is realized via a novel and
end-to-end trainable transformer-based architecture. In addition, the proposed
framework can improve existing approach performance. Through extensive
experiments on Visual Genome and Action Genome benchmark datasets we show
improved performance on the scene graph generation."
Region Embedding with Intra and Inter-View Contrastive Learning,0.111176,"Unsupervised region representation learning aims to extract dense and
effective features from unlabeled urban data. While some efforts have been made
for solving this problem based on multiple views, existing methods are still
insufficient in extracting representations in a view and/or incorporating
representations from different views. Motivated by the success of contrastive
learning for representation learning, we propose to leverage it for multi-view
region representation learning and design a model called ReMVC (Region
Embedding with Multi-View Contrastive Learning) by following two guidelines: i)
comparing a region with others within each view for effective representation
extraction and ii) comparing a region with itself across different views for
cross-view information sharing. We design the intra-view contrastive learning
module which helps to learn distinguished region embeddings and the inter-view
contrastive learning module which serves as a soft co-regularizer to constrain
the embedding parameters and transfer knowledge across multi-views. We exploit
the learned region embeddings in two downstream tasks named land usage
clustering and region popularity prediction. Extensive experiments demonstrate
that our model achieves impressive improvements compared with seven
state-of-the-art baseline methods, and the margins are over 30% in the land
usage clustering task."
Pyramid Frequency Network with Spatial Attention Residual Refinement Module for Monocular Depth Estimation,0.114659,"Deep-learning-based approaches to depth estimation are rapidly advancing,
offering superior performance over existing methods. To estimate the depth in
real-world scenarios, depth estimation models require the robustness of various
noise environments. In this work, a Pyramid Frequency Network(PFN) with Spatial
Attention Residual Refinement Module(SARRM) is proposed to deal with the weak
robustness of existing deep-learning methods. To reconstruct depth maps with
accurate details, the SARRM constructs a residual fusion method with an
attention mechanism to refine the blur depth. The frequency division strategy
is designed, and the frequency pyramid network is developed to extract features
from multiple frequency bands. With the frequency strategy, PFN achieves better
visual accuracy than state-of-the-art methods in both indoor and outdoor scenes
on Make3D, KITTI depth, and NYUv2 datasets. Additional experiments on the noisy
NYUv2 dataset demonstrate that PFN is more reliable than existing deep-learning
methods in high-noise scenes."
Saga: A Platform for Continuous Construction and Serving of Knowledge At Scale,0.0485768,"We introduce Saga, a next-generation knowledge construction and serving
platform for powering knowledge-based applications at industrial scale. Saga
follows a hybrid batch-incremental design to continuously integrate billions of
facts about real-world entities and construct a central knowledge graph that
supports multiple production use cases with diverse requirements around data
freshness, accuracy, and availability. In this paper, we discuss the unique
challenges associated with knowledge graph construction at industrial scale,
and review the main components of Saga and how they address these challenges.
Finally, we share lessons-learned from a wide array of production use cases
powered by Saga."
Efficient CNN with uncorrelated Bag of Features pooling,0.00986672,"Despite the superior performance of CNN, deploying them on low computational
power devices is still limited as they are typically computationally expensive.
One key cause of the high complexity is the connection between the convolution
layers and the fully connected layers, which typically requires a high number
of parameters. To alleviate this issue, Bag of Features (BoF) pooling has been
recently proposed. BoF learns a dictionary, that is used to compile a histogram
representation of the input. In this paper, we propose an approach that builds
on top of BoF pooling to boost its efficiency by ensuring that the items of the
learned dictionary are non-redundant. We propose an additional loss term, based
on the pair-wise correlation of the items of the dictionary, which complements
the standard loss to explicitly regularize the model to learn a more diverse
and rich dictionary. The proposed strategy yields an efficient variant of BoF
and further boosts its performance, without any additional parameters."
"Graphs, Constraints, and Search for the Abstraction and Reasoning Corpus",0.771684,"The Abstraction and Reasoning Corpus (ARC) aims at benchmarking the
performance of general artificial intelligence algorithms. The ARC's focus on
broad generalization and few-shot learning has made it difficult to solve using
pure machine learning. A more promising approach has been to perform program
synthesis within an appropriately designed Domain Specific Language (DSL).
However, these too have seen limited success. We propose Abstract Reasoning
with Graph Abstractions (ARGA), a new object-centric framework that first
represents images using graphs and then performs a search for a correct program
in a DSL that is based on the abstracted graph space. The complexity of this
combinatorial search is tamed through the use of constraint acquisition, state
hashing, and Tabu search. An extensive set of experiments demonstrates the
promise of ARGA in tackling some of the complicated object-centric tasks of the
ARC rather efficiently, producing programs that are correct and easy to
understand."
The SIGMORPHON 2022 Shared Task on Morpheme Segmentation,0.11548,"The SIGMORPHON 2022 shared task on morpheme segmentation challenged systems
to decompose a word into a sequence of morphemes and covered most types of
morphology: compounds, derivations, and inflections. Subtask 1, word-level
morpheme segmentation, covered 5 million words in 9 languages (Czech, English,
Spanish, Hungarian, French, Italian, Russian, Latin, Mongolian) and received 13
system submissions from 7 teams and the best system averaged 97.29% F1 score
across all languages, ranging English (93.84%) to Latin (99.38%). Subtask 2,
sentence-level morpheme segmentation, covered 18,735 sentences in 3 languages
(Czech, English, Mongolian), received 10 system submissions from 3 teams, and
the best systems outperformed all three state-of-the-art subword tokenization
methods (BPE, ULM, Morfessor2) by 30.71% absolute. To facilitate error analysis
and support any type of future studies, we released all system predictions, the
evaluation script, and all gold standard datasets."
Attention Option-Critic,0.0210231,"Temporal abstraction in reinforcement learning is the ability of an agent to
learn and use high-level behaviors, called options. The option-critic
architecture provides a gradient-based end-to-end learning method to construct
options. We propose an attention-based extension to this framework, which
enables the agent to learn to focus different options on different aspects of
the observation space. We show that this leads to behaviorally diverse options
which are also capable of state abstraction, and prevents the degeneracy
problems of option domination and frequent option switching that occur in
option-critic, while achieving a similar sample complexity. We also demonstrate
the more efficient, interpretable, and reusable nature of the learned options
in comparison with option-critic, through different transfer learning tasks.
Experimental results in a relatively simple four-rooms environment and the more
complex ALE (Arcade Learning Environment) showcase the efficacy of our
approach."
Coarse-to-Fine Sparse Sequential Recommendation,0.648534,"Sequential recommendation aims to model dynamic user behavior from historical
interactions. Self-attentive methods have proven effective at capturing
short-term dynamics and long-term preferences. Despite their success, these
approaches still struggle to model sparse data, on which they struggle to learn
high-quality item representations. We propose to model user dynamics from
shopping intents and interacted items simultaneously. The learned intents are
coarse-grained and work as prior knowledge for item recommendation. To this
end, we present a coarse-to-fine self-attention framework, namely CaFe, which
explicitly learns coarse-grained and fine-grained sequential dynamics.
Specifically, CaFe first learns intents from coarse-grained sequences which are
dense and hence provide high-quality user intent representations. Then, CaFe
fuses intent representations into item encoder outputs to obtain improved item
representations. Finally, we infer recommended items based on representations
of items and corresponding intents. Experiments on sparse datasets show that
CaFe outperforms state-of-the-art self-attentive recommenders by 44.03% NDCG@5
on average."
Causal Analysis of Syntactic Agreement Neurons in Multilingual Language Models,0.0856483,"Structural probing work has found evidence for latent syntactic information
in pre-trained language models. However, much of this analysis has focused on
monolingual models, and analyses of multilingual models have employed
correlational methods that are confounded by the choice of probing tasks. In
this study, we causally probe multilingual language models (XGLM and
multilingual BERT) as well as monolingual BERT-based models across various
languages; we do this by performing counterfactual perturbations on neuron
activations and observing the effect on models' subject-verb agreement
probabilities. We observe where in the model and to what extent syntactic
agreement is encoded in each language. We find significant neuron overlap
across languages in autoregressive multilingual language models, but not masked
language models. We also find two distinct layer-wise effect patterns and two
distinct sets of neurons used for syntactic agreement, depending on whether the
subject and verb are separated by other tokens. Finally, we find that
behavioral analyses of language models are likely underestimating how sensitive
masked language models are to syntactic information."
A Streamlit-based Artificial Intelligence Trust Platform for Next-Generation Wireless Networks,0.0288089,"With the rapid development and integration of artificial intelligence (AI)
methods in next-generation networks (NextG), AI algorithms have provided
significant advantages for NextG in terms of frequency spectrum usage,
bandwidth, latency, and security. A key feature of NextG is the integration of
AI, i.e., self-learning architecture based on self-supervised algorithms, to
improve the performance of the network. A secure AI-powered structure is also
expected to protect NextG networks against cyber-attacks. However, AI itself
may be attacked, i.e., model poisoning targeted by attackers, and it results in
cybersecurity violations. This paper proposes an AI trust platform using
Streamlit for NextG networks that allows researchers to evaluate, defend,
certify, and verify their AI models and applications against adversarial
threats of evasion, poisoning, extraction, and interference."
Deep Virtual-to-Real Distillation for Pedestrian Crossing Prediction,0.165789,"Pedestrian crossing is one of the most typical behavior which conflicts with
natural driving behavior of vehicles. Consequently, pedestrian crossing
prediction is one of the primary task that influences the vehicle planning for
safe driving. However, current methods that rely on the practically collected
data in real driving scenes cannot depict and cover all kinds of scene
condition in real traffic world. To this end, we formulate a deep virtual to
real distillation framework by introducing the synthetic data that can be
generated conveniently, and borrow the abundant information of pedestrian
movement in synthetic videos for the pedestrian crossing prediction in real
data with a simple and lightweight implementation. In order to verify this
framework, we construct a benchmark with 4667 virtual videos owning about 745k
frames (called Virtual-PedCross-4667), and evaluate the proposed method on two
challenging datasets collected in real driving situations, i.e., JAAD and PIE
datasets. State-of-the-art performance of this framework is demonstrated by
exhaustive experiment analysis. The dataset and code can be downloaded from the
website \url{http://www.lotvs.net/code_data/}."
Processing the structure of documents: Logical Layout Analysis of historical newspapers in French,0.125131,"Background. In recent years, libraries and archives led important
digitisation campaigns that opened the access to vast collections of historical
documents. While such documents are often available as XML ALTO documents, they
lack information about their logical structure. In this paper, we address the
problem of Logical Layout Analysis applied to historical documents in French.
We propose a rule-based method, that we evaluate and compare with two
Machine-Learning models, namely RIPPER and Gradient Boosting. Our data set
contains French newspapers, periodicals and magazines, published in the first
half of the twentieth century in the Franche-Comt\'e Region. Results. Our
rule-based system outperforms the two other models in nearly all evaluations.
It has especially better Recall results, indicating that our system covers more
types of every logical label than the other two models. When comparing RIPPER
with Gradient Boosting, we can observe that Gradient Boosting has better
Precision scores but RIPPER has better Recall scores. Conclusions. The
evaluation shows that our system outperforms the two Machine Learning models,
and provides significantly higher Recall. It also confirms that our system can
be used to produce annotated data sets that are large enough to envisage
Machine Learning or Deep Learning approaches for the task of Logical Layout
Analysis. Combining rules and Machine Learning models into hybrid systems could
potentially provide even better performances. Furthermore, as the layout in
historical documents evolves rapidly, one possible solution to overcome this
problem would be to apply Rule Learning algorithms to bootstrap rule sets
adapted to different publication periods."
Differentiable Agent-based Epidemiology,0.173609,"Mechanistic simulators are an indispensable tool for epidemiology to explore
the behavior of complex, dynamic infections under varying conditions and
navigate uncertain environments. Agent-based models (ABMs) are an increasingly
popular simulation paradigm that can represent the heterogeneity of contact
interactions with granular detail and agency of individual behavior. However,
conventional ABM frameworks are not differentiable and present challenges in
scalability; due to which it is non-trivial to connect them to auxiliary data
sources. In this paper, we introduce GradABM: a scalable, differentiable design
for agent-based modeling that is amenable to gradient-based learning with
automatic differentiation. GradABM can quickly simulate million-size
populations in few seconds on commodity hardware, integrate with deep neural
networks and ingest heterogeneous data sources. This provides an array of
practical benefits for calibration, forecasting, and evaluating policy
interventions. We demonstrate the efficacy of GradABM via extensive experiments
with real COVID-19 and influenza datasets."
Grounding Aleatoric Uncertainty for Unsupervised Environment Design,0.156145,"Adaptive curricula in reinforcement learning (RL) have proven effective for
producing policies robust to discrepancies between the train and test
environment. Recently, the Unsupervised Environment Design (UED) framework
generalized RL curricula to generating sequences of entire environments,
leading to new methods with robust minimax regret properties. Problematically,
in partially-observable or stochastic settings, optimal policies may depend on
the ground-truth distribution over aleatoric parameters of the environment in
the intended deployment setting, while curriculum learning necessarily shifts
the training distribution. We formalize this phenomenon as curriculum-induced
covariate shift (CICS), and describe how its occurrence in aleatoric parameters
can lead to suboptimal policies. Directly sampling these parameters from the
ground-truth distribution avoids the issue, but thwarts curriculum learning. We
propose SAMPLR, a minimax regret UED method that optimizes the ground-truth
utility function, even when the underlying training data is biased due to CICS.
We prove, and validate on challenging domains, that our approach preserves
optimality under the ground-truth distribution, while promoting robustness
across the full range of environment settings."
D2A-BSP: Distilled Data Association Belief Space Planning with Performance Guarantees Under Budget Constraints,0.23873,"Unresolved data association in ambiguous and perceptually aliased
environments leads to multi-modal hypotheses on both the robot's and the
environment state. To avoid catastrophic results, when operating in such
ambiguous environments, it is crucial to reason about data association within
Belief Space Planning (BSP). However, explicitly considering all possible data
associations, the number of hypotheses grows exponentially with the planning
horizon and determining the optimal action sequence quickly becomes
intractable. Moreover, with hard budget constraints where some non-negligible
hypotheses must be pruned, achieving performance guarantees is crucial. In this
work we present a computationally efficient novel approach that utilizes only a
distilled subset of hypotheses to solve BSP problems while reasoning about data
association. Furthermore, to provide performance guarantees, we derive error
bounds with respect to the optimal solution. We then demonstrate our approach
in an extremely aliased environment, where we manage to significantly reduce
computation time without compromising on the quality of the solution."
Towards Open Set Video Anomaly Detection,0.190223,"Open Set Video Anomaly Detection (OpenVAD) aims to identify abnormal events
from video data where both known anomalies and novel ones exist in testing.
Unsupervised models learned solely from normal videos are applicable to any
testing anomalies but suffer from a high false positive rate. In contrast,
weakly supervised methods are effective in detecting known anomalies but could
fail in an open world. We develop a novel weakly supervised method for the
OpenVAD problem by integrating evidential deep learning (EDL) and normalizing
flows (NFs) into a multiple instance learning (MIL) framework. Specifically, we
propose to use graph neural networks and triplet loss to learn discriminative
features for training the EDL classifier, where the EDL is capable of
identifying the unknown anomalies by quantifying the uncertainty. Moreover, we
develop an uncertainty-aware selection strategy to obtain clean anomaly
instances and a NFs module to generate the pseudo anomalies. Our method is
superior to existing approaches by inheriting the advantages of both the
unsupervised NFs and the weakly-supervised MIL framework. Experimental results
on multiple real-world video datasets show the effectiveness of our method."
Investigating data partitioning strategies for crosslinguistic low-resource ASR evaluation,0.0102124,"Many automatic speech recognition (ASR) data sets include a single
pre-defined test set consisting of one or more speakers whose speech never
appears in the training set. This ""hold-speaker(s)-out"" data partitioning
strategy, however, may not be ideal for data sets in which the number of
speakers is very small. This study investigates ten different data split
methods for five languages with minimal ASR training resources. We find that
(1) model performance varies greatly depending on which speaker is selected for
testing; (2) the average word error rate (WER) across all held-out speakers is
comparable not only to the average WER over multiple random splits but also to
any given individual random split; (3) WER is also generally comparable when
the data is split heuristically or adversarially; (4) utterance duration and
intensity are comparatively more predictive factors of variability regardless
of the data split. These results suggest that the widely used hold-speakers-out
approach to ASR data partitioning can yield results that do not reflect model
performance on unseen data or speakers. Random splits can yield more reliable
and generalizable estimates when facing data sparsity."
Egocentric Prediction of Action Target in 3D,0.188295,"We are interested in anticipating as early as possible the target location of
a person's object manipulation action in a 3D workspace from egocentric vision.
It is important in fields like human-robot collaboration, but has not yet
received enough attention from vision and learning communities. To stimulate
more research on this challenging egocentric vision task, we propose a large
multimodality dataset of more than 1 million frames of RGB-D and IMU streams,
and provide evaluation metrics based on our high-quality 2D and 3D labels from
semi-automatic annotation. Meanwhile, we design baseline methods using
recurrent neural networks and conduct various ablation studies to validate
their effectiveness. Our results demonstrate that this new task is worthy of
further study by researchers in robotics, vision, and learning communities."
Improving Low-Resource Speech Recognition with Pretrained Speech Models: Continued Pretraining vs. Semi-Supervised Training,0.0240993,"Self-supervised Transformer based models, such as wav2vec 2.0 and HuBERT,
have produced significant improvements over existing approaches to automatic
speech recognition (ASR). This is evident in the performance of the wav2vec 2.0
based pretrained XLSR-53 model across many languages when fine-tuned with
available labeled data. However, the performance from finetuning these models
can be dependent on the amount of in-language or similar-to-in-language data
included in the pretraining dataset. In this paper we investigate continued
pretraining (CoPT) with unlabeled in-language audio data on the XLSR-53
pretrained model in several low-resource languages. CoPT is more
computationally efficient than semi-supervised training (SST), the standard
approach of utilizing unlabeled data in ASR, since it omits the need for
pseudo-labeling of the unlabeled data. We show CoPT results in word error rates
(WERs), equal to or slightly better than using SST. In addition, we show that
using the CoPT model for pseudo-labeling, and using these labels in SST,
results in further improvements in WER."
CNSNet: A Cleanness-Navigated-Shadow Network for Shadow Removal,0.191235,"The key to shadow removal is recovering the contents of the shadow regions
with the guidance of the non-shadow regions. Due to the inadequate long-range
modeling, the CNN-based approaches cannot thoroughly investigate the
information from the non-shadow regions. To solve this problem, we propose a
novel cleanness-navigated-shadow network (CNSNet), with a shadow-oriented
adaptive normalization (SOAN) module and a shadow-aware aggregation with
transformer (SAAT) module based on the shadow mask. Under the guidance of the
shadow mask, the SOAN module formulates the statistics from the non-shadow
region and adaptively applies them to the shadow region for region-wise
restoration. The SAAT module utilizes the shadow mask to precisely guide the
restoration of each shadowed pixel by considering the highly relevant pixels
from the shadow-free regions for global pixel-wise restoration. Extensive
experiments on three benchmark datasets (ISTD, ISTD+, and SRD) show that our
method achieves superior de-shadowing performance."
TODE-Trans: Transparent Object Depth Estimation with Transformer,0.0839233,"Transparent objects are widely used in industrial automation and daily life.
However, robust visual recognition and perception of transparent objects have
always been a major challenge. Currently, most commercial-grade depth cameras
are still not good at sensing the surfaces of transparent objects due to the
refraction and reflection of light. In this work, we present a
transformer-based transparent object depth estimation approach from a single
RGB-D input. We observe that the global characteristics of the transformer make
it easier to extract contextual information to perform depth estimation of
transparent areas. In addition, to better enhance the fine-grained features, a
feature fusion module (FFM) is designed to assist coherent prediction. Our
empirical evidence demonstrates that our model delivers significant
improvements in recent popular datasets, e.g., 25% gain on RMSE and 21% gain on
REL compared to previous state-of-the-art convolutional-based counterparts in
ClearGrasp dataset. Extensive results show that our transformer-based model
enables better aggregation of the object's RGB and inaccurate depth information
to obtain a better depth representation. Our code and the pre-trained model
will be available at https://github.com/yuchendoudou/TODE."
FSGANv2: Improved Subject Agnostic Face Swapping and Reenactment,0.242347,"We present Face Swapping GAN (FSGAN) for face swapping and reenactment.
Unlike previous work, we offer a subject agnostic swapping scheme that can be
applied to pairs of faces without requiring training on those faces. We derive
a novel iterative deep learning--based approach for face reenactment which
adjusts significant pose and expression variations that can be applied to a
single image or a video sequence. For video sequences, we introduce a
continuous interpolation of the face views based on reenactment, Delaunay
Triangulation, and barycentric coordinates. Occluded face regions are handled
by a face completion network. Finally, we use a face blending network for
seamless blending of the two faces while preserving the target skin color and
lighting conditions. This network uses a novel Poisson blending loss combining
Poisson optimization with a perceptual loss. We compare our approach to
existing state-of-the-art systems and show our results to be both qualitatively
and quantitatively superior. This work describes extensions of the FSGAN
method, proposed in an earlier conference version of our work, as well as
additional experiments and results."
On the Transformation of Latent Space in Fine-Tuned NLP Models,0.140874,"We study the evolution of latent space in fine-tuned NLP models. Different
from the commonly used probing-framework, we opt for an unsupervised method to
analyze representations. More specifically, we discover latent concepts in the
representational space using hierarchical clustering. We then use an alignment
function to gauge the similarity between the latent space of a pre-trained
model and its fine-tuned version. We use traditional linguistic concepts to
facilitate our understanding and also study how the model space transforms
towards task-specific information. We perform a thorough analysis, comparing
pre-trained and fine-tuned models across three models and three downstream
tasks. The notable findings of our work are: i) the latent space of the higher
layers evolve towards task-specific concepts, ii) whereas the lower layers
retain generic concepts acquired in the pre-trained model, iii) we discovered
that some concepts in the higher layers acquire polarity towards the output
class, and iv) that these concepts can be used for generating adversarial
triggers."
A-NeSI: A Scalable Approximate Method for Probabilistic Neurosymbolic Inference,0.0236129,"We study the problem of combining neural networks with symbolic reasoning.
Recently introduced frameworks for Probabilistic Neurosymbolic Learning (PNL),
such as DeepProbLog, perform exponential-time exact inference, limiting the
scalability of PNL solutions. We introduce Approximate Neurosymbolic Inference
(A-NeSI): a new framework for PNL that uses neural networks for scalable
approximate inference. A-NeSI 1) performs approximate inference in polynomial
time without changing the semantics of probabilistic logics; 2) is trained
using data generated by the background knowledge; 3) can generate symbolic
explanations of predictions; and 4) can guarantee the satisfaction of logical
constraints at test time, which is vital in safety-critical applications. Our
experiments show that A-NeSI is the first end-to-end method to solve three
neurosymbolic tasks with exponential combinatorial scaling. Finally, our
experiments show that A-NeSI achieves explainability and safety without a
penalty in performance."
On Web-based Visual Corpus Construction for Visual Document Understanding,0.022225,"In recent years, research on visual document understanding (VDU) has grown
significantly, with a particular emphasis on the development of self-supervised
learning methods. However, one of the significant challenges faced in this
field is the limited availability of publicly accessible visual corpora or
extensive collections of images with detailed text annotations, particularly
for non-Latin or resource-scarce languages. To address this challenge, we
propose Web-based Visual Corpus Builder (Webvicob), a dataset generator engine
capable of constructing large-scale, multilingual visual corpora from raw
Wikipedia HTML dumps. Our experiments demonstrate that the data generated by
Webvicob can be used to train robust VDU models that perform well on various
downstream tasks, such as DocVQA and post-OCR parsing. Furthermore, when using
a dataset of 1 million images generated by Webvicob, we observed an improvement
of over 13% on the DocVQA Task 3 compared to a dataset of 11 million images
from the IIT-CDIP. The implementation of our engine is publicly available on
https://github.com/clovaai/webvicob"
Improving Simultaneous Machine Translation with Monolingual Data,0.101356,"Simultaneous machine translation (SiMT) is usually done via sequence-level
knowledge distillation (Seq-KD) from a full-sentence neural machine translation
(NMT) model. However, there is still a significant performance gap between NMT
and SiMT. In this work, we propose to leverage monolingual data to improve
SiMT, which trains a SiMT student on the combination of bilingual data and
external monolingual data distilled by Seq-KD. Preliminary experiments on En-Zh
and En-Ja news domain corpora demonstrate that monolingual data can
significantly improve translation quality (e.g., +3.15 BLEU on En-Zh). Inspired
by the behavior of human simultaneous interpreters, we propose a novel
monolingual sampling strategy for SiMT, considering both chunk length and
monotonicity. Experimental results show that our sampling strategy consistently
outperforms the random sampling strategy (and other conventional typical NMT
monolingual sampling strategies) by avoiding the key problem of SiMT --
hallucination, and has better scalability. We achieve +0.72 BLEU improvements
on average against random sampling on En-Zh and En-Ja. Data and codes can be
found at https://github.com/hexuandeng/Mono4SiMT."
"Detecting and Mitigating Hallucinations in Machine Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even Better",0.563233,"While the problem of hallucinations in neural machine translation has long
been recognized, so far the progress on its alleviation is very little. Indeed,
recently it turned out that without artificially encouraging models to
hallucinate, previously existing methods fall short and even the standard
sequence log-probability is more informative. It means that characteristics
internal to the model can give much more information than we expect, and before
using external models and measures, we first need to ask: how far can we go if
we use nothing but the translation model itself ? We propose to use a method
that evaluates the percentage of the source contribution to a generated
translation. Intuitively, hallucinations are translations ""detached"" from the
source, hence they can be identified by low source contribution. This method
improves detection accuracy for the most severe hallucinations by a factor of 2
and is able to alleviate hallucinations at test time on par with the previous
best approach that relies on external models. Next, if we move away from
internal model characteristics and allow external tools, we show that using
sentence similarity from cross-lingual embeddings further improves these
results."
FolkScope: Intention Knowledge Graph Construction for E-commerce Commonsense Discovery,0.0262085,"Understanding users' intentions in e-commerce platforms requires commonsense
knowledge. In this paper, we present FolkScope, an intention knowledge graph
construction framework to reveal the structure of humans' minds about
purchasing items. As commonsense knowledge is usually ineffable and not
expressed explicitly, it is challenging to perform information extraction.
Thus, we propose a new approach that leverages the generation power of large
language models~(LLMs) and human-in-the-loop annotation to semi-automatically
construct the knowledge graph. LLMs first generate intention assertions via
e-commerce-specific prompts to explain shopping behaviors, where the intention
can be an open reason or a predicate falling into one of 18 categories aligning
with ConceptNet, e.g., IsA, MadeOf, UsedFor, etc. Then we annotate plausibility
and typicality labels of sampled intentions as training data in order to
populate human judgments to all automatic generations. Last, to structurize the
assertions, we propose pattern mining and conceptualization to form more
condensed and abstract knowledge. Extensive evaluations and studies demonstrate
that our constructed knowledge graph can well model e-commerce knowledge and
have many potential applications."
Depth-aware Neural Style Transfer using Instance Normalization,0.103069,"Neural Style Transfer (NST) is concerned with the artistic stylization of
visual media. It can be described as the process of transferring the style of
an artistic image onto an ordinary photograph. Recently, a number of studies
have considered the enhancement of the depth-preserving capabilities of the NST
algorithms to address the undesired effects that occur when the input content
images include numerous objects at various depths. Our approach uses a deep
residual convolutional network with instance normalization layers that utilizes
an advanced depth prediction network to integrate depth preservation as an
additional loss function to content and style. We demonstrate results that are
effective in retaining the depth and global structure of content images. Three
different evaluation processes show that our system is capable of preserving
the structure of the stylized results while exhibiting style-capture
capabilities and aesthetic qualities comparable or superior to state-of-the-art
methods. Project page:
https://ioannoue.github.io/depth-aware-nst-using-in.html."
Standby-Based Deadlock Avoidance Method for Multi-Agent Pickup and Delivery Tasks,0.300571,"The multi-agent pickup and delivery (MAPD) problem, in which multiple agents
iteratively carry materials without collisions, has received significant
attention. However, many conventional MAPD algorithms assume a specifically
designed grid-like environment, such as an automated warehouse. Therefore, they
have many pickup and delivery locations where agents can stay for a lengthy
period, as well as plentiful detours to avoid collisions owing to the freedom
of movement in a grid. By contrast, because a maze-like environment such as a
search-and-rescue or construction site has fewer pickup/delivery locations and
their numbers may be unbalanced, many agents concentrate on such locations
resulting in inefficient operations, often becoming stuck or deadlocked. Thus,
to improve the transportation efficiency even in a maze-like restricted
environment, we propose a deadlock avoidance method, called standby-based
deadlock avoidance (SBDA). SBDA uses standby nodes determined in real-time
using the articulation-point-finding algorithm, and the agent is guaranteed to
stay there for a finite amount of time. We demonstrated that our proposed
method outperforms a conventional approach. We also analyzed how the parameters
used for selecting standby nodes affect the performance."
A Combined Approach of Process Mining and Rule-based AI for Study Planning and Monitoring in Higher Education,0.0263593,"This paper presents an approach of using methods of process mining and
rule-based artificial intelligence to analyze and understand study paths of
students based on campus management system data and study program models.
Process mining techniques are used to characterize successful study paths, as
well as to detect and visualize deviations from expected plans. These insights
are combined with recommendations and requirements of the corresponding study
programs extracted from examination regulations. Here, event calculus and
answer set programming are used to provide models of the study programs which
support planning and conformance checking while providing feedback on possible
study plan violations. In its combination, process mining and rule-based
artificial intelligence are used to support study planning and monitoring by
deriving rules and recommendations for guiding students to more suitable study
paths with higher success rates. Two applications will be implemented, one for
students and one for study program designers."
Human-Centered Concept Explanations for Neural Networks,0.168384,"Understanding complex machine learning models such as deep neural networks
with explanations is crucial in various applications. Many explanations stem
from the model perspective, and may not necessarily effectively communicate why
the model is making its predictions at the right level of abstraction. For
example, providing importance weights to individual pixels in an image can only
express which parts of that particular image are important to the model, but
humans may prefer an explanation which explains the prediction by concept-based
thinking. In this work, we review the emerging area of concept based
explanations. We start by introducing concept explanations including the class
of Concept Activation Vectors (CAV) which characterize concepts using vectors
in appropriate spaces of neural activations, and discuss different properties
of useful concepts, and approaches to measure the usefulness of concept
vectors. We then discuss approaches to automatically extract concepts, and
approaches to address some of their caveats. Finally, we discuss some case
studies that showcase the utility of such concept-based explanations in
synthetic settings and real world applications."
MentSum: A Resource for Exploring Summarization of Mental Health Online Posts,0.0,"Mental health remains a significant challenge of public health worldwide.
With increasing popularity of online platforms, many use the platforms to share
their mental health conditions, express their feelings, and seek help from the
community and counselors. Some of these platforms, such as Reachout, are
dedicated forums where the users register to seek help. Others such as Reddit
provide subreddits where the users publicly but anonymously post their mental
health distress. Although posts are of varying length, it is beneficial to
provide a short, but informative summary for fast processing by the counselors.
To facilitate research in summarization of mental health online posts, we
introduce Mental Health Summarization dataset, MentSum, containing over 24k
carefully selected user posts from Reddit, along with their short user-written
summary (called TLDR) in English from 43 mental health subreddits. This
domain-specific dataset could be of interest not only for generating short
summaries on Reddit, but also for generating summaries of posts on the
dedicated mental health forums such as Reachout. We further evaluate both
extractive and abstractive state-of-the-art summarization baselines in terms of
Rouge scores, and finally conduct an in-depth human evaluation study of both
user-written and system-generated summaries, highlighting challenges in this
research."
Measuring Geographic Performance Disparities of Offensive Language Classifiers,0.0313544,"Text classifiers are applied at scale in the form of one-size-fits-all
solutions. Nevertheless, many studies show that classifiers are biased
regarding different languages and dialects. When measuring and discovering
these biases, some gaps present themselves and should be addressed. First,
``Does language, dialect, and topical content vary across geographical
regions?'' and secondly ``If there are differences across the regions, do they
impact model performance?''. We introduce a novel dataset called GeoOLID with
more than 14 thousand examples across 15 geographically and demographically
diverse cities to address these questions. We perform a comprehensive analysis
of geographical-related content and their impact on performance disparities of
offensive language detection models. Overall, we find that current models do
not generalize across locations. Likewise, we show that while offensive
language models produce false positives on African American English, model
performance is not correlated with each city's minority population proportions.
Warning: This paper contains offensive language."
Deep Learning based Automatic Detection of Dicentric Chromosome,0.0111227,"Automatic detection of dicentric chromosomes is an essential step to estimate
radiation exposure and development of end to end emergency bio dosimetry
systems. During accidents, a large amount of data is required to be processed
for extensive testing to formulate a medical treatment plan for the masses,
which requires this process to be automated. Current approaches require human
adjustments according to the data and therefore need a human expert to
calibrate the system. This paper proposes a completely data driven framework
which requires minimum intervention of field experts and can be deployed in
emergency cases with relative ease. Our approach involves YOLOv4 to detect the
chromosomes and remove the debris in each image, followed by a classifier that
differentiates between an analysable chromosome and a non-analysable one.
Images are extracted from YOLOv4 based on the protocols described by
WHO-BIODOSNET. The analysable chromosome is classified as Monocentric or
Dicentric and an image is accepted for consideration of dose estimation based
on the analysable chromosome count. We report an accuracy in dicentric
identification of 94.33% on a 1:1 split of Dicentric and Monocentric
Chromosomes."
Overview of the WANLP 2022 Shared Task on Propaganda Detection in Arabic,0.991252,"Propaganda is the expression of an opinion or an action by an individual or a
group deliberately designed to influence the opinions or the actions of other
individuals or groups with reference to predetermined ends, which is achieved
by means of well-defined rhetorical and psychological devices. Propaganda
techniques are commonly used in social media to manipulate or to mislead users.
Thus, there has been a lot of recent research on automatic detection of
propaganda techniques in text as well as in memes. However, so far the focus
has been primarily on English. With the aim to bridge this language gap, we ran
a shared task on detecting propaganda techniques in Arabic tweets as part of
the WANLP 2022 workshop, which included two subtasks. Subtask~1 asks to
identify the set of propaganda techniques used in a tweet, which is a
multilabel classification problem, while Subtask~2 asks to detect the
propaganda techniques used in a tweet together with the exact span(s) of text
in which each propaganda technique appears. The task attracted 63 team
registrations, and eventually 14 and 3 teams made submissions for subtask 1 and
2, respectively. Finally, 11 teams submitted system description papers."
Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction,0.20498,"Dimensionality reduction is crucial both for visualization and preprocessing
high dimensional data for machine learning. We introduce a novel method based
on a hierarchy built on 1-nearest neighbor graphs in the original space which
is used to preserve the grouping properties of the data distribution on
multiple levels. The core of the proposal is an optimization-free projection
that is competitive with the latest versions of t-SNE and UMAP in performance
and visualization quality while being an order of magnitude faster in run-time.
Furthermore, its interpretable mechanics, the ability to project new data, and
the natural separation of data clusters in visualizations make it a general
purpose unsupervised dimension reduction technique. In the paper, we argue
about the soundness of the proposed method and evaluate it on a diverse
collection of datasets with sizes varying from 1K to 11M samples and dimensions
from 28 to 16K. We perform comparisons with other state-of-the-art methods on
multiple metrics and target dimensions highlighting its efficiency and
performance. Code is available at https://github.com/koulakis/h-nne"
Facial Action Unit Recognition Based on Transfer Learning,0.0671004,"Facial action unit recognition is an important task for facial analysis.
Owing to the complex collection environment, facial action unit recognition in
the wild is still challenging. The 3rd competition on affective behavior
analysis in-the-wild (ABAW) has provided large amount of facial images with
facial action unit annotations. In this paper, we introduce a facial action
unit recognition method based on transfer learning. We first use available
facial images with expression labels to train the feature extraction network.
Then we fine-tune the network for facial action unit recognition."
PLM-ICD: Automatic ICD Coding with Pretrained Language Models,0.718648,"Automatically classifying electronic health records (EHRs) into diagnostic
codes has been challenging to the NLP community. State-of-the-art methods
treated this problem as a multilabel classification problem and proposed
various architectures to model this problem. However, these systems did not
leverage the superb performance of pretrained language models, which achieved
superb performance on natural language understanding tasks. Prior work has
shown that pretrained language models underperformed on this task with the
regular finetuning scheme. Therefore, this paper aims at analyzing the causes
of the underperformance and developing a framework for automatic ICD coding
with pretrained language models. We spotted three main issues through the
experiments: 1) large label space, 2) long input sequences, and 3) domain
mismatch between pretraining and fine-tuning. We propose PLMICD, a framework
that tackles the challenges with various strategies. The experimental results
show that our proposed framework can overcome the challenges and achieves
state-of-the-art performance in terms of multiple metrics on the benchmark
MIMIC data. The source code is available at https://github.com/MiuLab/PLM-ICD"
Learning to Reuse Distractors to support Multiple Choice Question Generation in Education,0.10301,"Multiple choice questions (MCQs) are widely used in digital learning systems,
as they allow for automating the assessment process. However, due to the
increased digital literacy of students and the advent of social media
platforms, MCQ tests are widely shared online, and teachers are continuously
challenged to create new questions, which is an expensive and time-consuming
task. A particularly sensitive aspect of MCQ creation is to devise relevant
distractors, i.e., wrong answers that are not easily identifiable as being
wrong. This paper studies how a large existing set of manually created answers
and distractors for questions over a variety of domains, subjects, and
languages can be leveraged to help teachers in creating new MCQs, by the smart
reuse of existing distractors. We built several data-driven models based on
context-aware question and distractor representations, and compared them with
static feature-based models. The proposed models are evaluated with automated
metrics and in a realistic user test with teachers. Both automatic and human
evaluations indicate that context-aware models consistently outperform a static
feature-based approach. For our best-performing context-aware model, on average
3 distractors out of the 10 shown to teachers were rated as high-quality
distractors. We create a performance benchmark, and make it public, to enable
comparison between different approaches and to introduce a more standardized
evaluation of the task. The benchmark contains a test of 298 educational
questions covering multiple subjects & languages and a 77k multilingual pool of
distractor vocabulary for future research."
A Multimodal German Dataset for Automatic Lip Reading Systems and Transfer Learning,0.0116928,"Large datasets as required for deep learning of lip reading do not exist in
many languages. In this paper we present the dataset GLips (German Lips)
consisting of 250,000 publicly available videos of the faces of speakers of the
Hessian Parliament, which was processed for word-level lip reading using an
automatic pipeline. The format is similar to that of the English language LRW
(Lip Reading in the Wild) dataset, with each video encoding one word of
interest in a context of 1.16 seconds duration, which yields compatibility for
studying transfer learning between both datasets. By training a deep neural
network, we investigate whether lip reading has language-independent features,
so that datasets of different languages can be used to improve lip reading
models. We demonstrate learning from scratch and show that transfer learning
from LRW to GLips and vice versa improves learning speed and performance, in
particular for the validation set."
Aggregate effects of advertising decisions: a complex systems look at search engine advertising via an experimental study,0.365903,"Purpose: We model group advertising decisions, which are the collective
decisions of every single advertiser within the set of advertisers who are
competing in the same auction or vertical industry, and examine resulting
market outcomes, via a proposed simulation framework named EXP-SEA
(Experimental Platform for Search Engine Advertising) supporting experimental
studies of collective behaviors in the context of search engine advertising.
Design: We implement the EXP-SEA to validate the proposed simulation framework,
also conduct three experimental studies on the aggregate impact of electronic
word-of-mouth, the competition level, and strategic bidding behaviors. EXP-SEA
supports heterogeneous participants, various auction mechanisms, and also
ranking and pricing algorithms. Findings: Findings from our three experiments
show that (a) both the market profit and advertising indexes such as number of
impressions and number of clicks are larger when the eWOM effect presents,
meaning social media certainly has some effect on search engine advertising
outcomes, (b) the competition level has a monotonic increasing effect on the
market performance, thus search engines have an incentive to encourage both the
eWOM among search users and competition among advertisers, and (c) given the
market-level effect of the percentage of advertisers employing a dynamic greedy
bidding strategy, there is a cut-off point for strategic bidding behaviors.
Originality: This is one of the first research works to explore collective
group decisions and resulting phenomena in the complex context of search engine
advertising via developing and validating a simulation framework that supports
assessments of various advertising strategies and estimations of the impact of
mechanisms on the search market."
Using Deep Mixture-of-Experts to Detect Word Meaning Shift for TempoWiC,0.416355,"This paper mainly describes the dma submission to the TempoWiC task, which
achieves a macro-F1 score of 77.05% and attains the first place in this task.
We first explore the impact of different pre-trained language models. Then we
adopt data cleaning, data augmentation, and adversarial training strategies to
enhance the model generalization and robustness. For further improvement, we
integrate POS information and word semantic representation using a
Mixture-of-Experts (MoE) approach. The experimental results show that MoE can
overcome the feature overuse issue and combine the context, POS, and word
semantic features well. Additionally, we use a model ensemble method for the
final prediction, which has been proven effective by many research works."
Towards Large-Scale Interpretable Knowledge Graph Reasoning for Dialogue Systems,0.226315,"Users interacting with voice assistants today need to phrase their requests
in a very specific manner to elicit an appropriate response. This limits the
user experience, and is partly due to the lack of reasoning capabilities of
dialogue platforms and the hand-crafted rules that require extensive labor. One
possible way to improve user experience and relieve the manual efforts of
designers is to build an end-to-end dialogue system that can do reasoning
itself while perceiving user's utterances. In this work, we propose a novel
method to incorporate the knowledge reasoning capability into dialogue systems
in a more scalable and generalizable manner. Our proposed method allows a
single transformer model to directly walk on a large-scale knowledge graph to
generate responses. To the best of our knowledge, this is the first work to
have transformer models generate responses by reasoning over differentiable
knowledge graphs. We investigate the reasoning abilities of the proposed method
on both task-oriented and domain-specific chit-chat dialogues. Empirical
results show that this method can effectively and efficiently incorporate a
knowledge graph into a dialogue system with fully-interpretable reasoning
paths."
Report from the NSF Future Directions Workshop on Automatic Evaluation of Dialog: Research Directions and Challenges,0.260691,"This is a report on the NSF Future Directions Workshop on Automatic
Evaluation of Dialog. The workshop explored the current state of the art along
with its limitations and suggested promising directions for future work in this
important and very rapidly changing area of research."
Transcending Scaling Laws with 0.1% Extra Compute,0.187019,"Scaling language models improves performance but comes with significant
computational costs. This paper proposes UL2R, a method that substantially
improves existing language models and their scaling curves with a relatively
tiny amount of extra compute. The key idea is to continue training a
state-of-the-art large language model (e.g., PaLM) on a few more steps with
UL2's mixture-of-denoiser objective. We show that, with almost negligible extra
computational costs and no new sources of data, we are able to substantially
improve the scaling properties of large language models on downstream metrics.
In this paper, we continue training PaLM with UL2R, introducing a new set of
models at 8B, 62B, and 540B scale which we call U-PaLM. Impressively, at 540B
scale, we show an approximately 2x computational savings rate where U-PaLM
achieves the same performance as the final PaLM 540B model at around half its
computational budget (i.e., saving $\sim$4.4 million TPUv4 hours). We further
show that this improved scaling curve leads to 'emergent abilities' on
challenging BIG-Bench tasks -- for instance, U-PaLM does much better than PaLM
on some tasks or demonstrates better quality at much smaller scale (62B as
opposed to 540B). Overall, we show that U-PaLM outperforms PaLM on many
few-shot setups, i.e., English NLP tasks (e.g., commonsense reasoning, question
answering), reasoning tasks with chain-of-thought (e.g., GSM8K), multilingual
tasks (MGSM, TydiQA), MMLU and challenging BIG-Bench tasks. Finally, we provide
qualitative examples showing the new capabilities of U-PaLM for single and
multi-span infilling."
Task-Balanced Distillation for Object Detection,0.104887,"Mainstream object detectors are commonly constituted of two sub-tasks,
including classification and regression tasks, implemented by two parallel
heads. This classic design paradigm inevitably leads to inconsistent spatial
distributions between classification score and localization quality (IOU).
Therefore, this paper alleviates this misalignment in the view of knowledge
distillation. First, we observe that the massive teacher achieves a higher
proportion of harmonious predictions than the lightweight student. Based on
this intriguing observation, a novel Harmony Score (HS) is devised to estimate
the alignment of classification and regression qualities. HS models the
relationship between two sub-tasks and is seen as prior knowledge to promote
harmonious predictions for the student. Second, this spatial misalignment will
result in inharmonious region selection when distilling features. To alleviate
this problem, a novel Task-decoupled Feature Distillation (TFD) is proposed by
flexibly balancing the contributions of classification and regression tasks.
Eventually, HD and TFD constitute the proposed method, named Task-Balanced
Distillation (TBD). Extensive experiments demonstrate the considerable
potential and generalization of the proposed method. Specifically, when
equipped with TBD, RetinaNet with ResNet-50 achieves 41.0 mAP under the COCO
benchmark, outperforming the recent FGD and FRS."
Generating Authentic Adversarial Examples beyond Meaning-preserving with Doubly Round-trip Translation,0.219117,"Generating adversarial examples for Neural Machine Translation (NMT) with
single Round-Trip Translation (RTT) has achieved promising results by releasing
the meaning-preserving restriction. However, a potential pitfall for this
approach is that we cannot decide whether the generated examples are
adversarial to the target NMT model or the auxiliary backward one, as the
reconstruction error through the RTT can be related to either. To remedy this
problem, we propose a new criterion for NMT adversarial examples based on the
Doubly Round-Trip Translation (DRTT). Specifically, apart from the
source-target-source RTT, we also consider the target-source-target one, which
is utilized to pick out the authentic adversarial examples for the target NMT
model. Additionally, to enhance the robustness of the NMT model, we introduce
the masked language models to construct bilingual adversarial pairs based on
DRTT, which are used to train the NMT model directly. Extensive experiments on
both the clean and noisy test sets (including the artificial and natural noise)
show that our approach substantially improves the robustness of NMT models."
Image Segmentation-based Unsupervised Multiple Objects Discovery,0.027201,"Unsupervised object discovery aims to localize objects in images, while
removing the dependence on annotations required by most deep learning-based
methods. To address this problem, we propose a fully unsupervised, bottom-up
approach, for multiple objects discovery. The proposed approach is a two-stage
framework. First, instances of object parts are segmented by using the
intra-image similarity between self-supervised local features. The second step
merges and filters the object parts to form complete object instances. The
latter is performed by two CNN models that capture semantic information on
objects from the entire dataset. We demonstrate that the pseudo-labels
generated by our method provide a better precision-recall trade-off than
existing single and multiple objects discovery methods. In particular, we
provide state-of-the-art results for both unsupervised class-agnostic object
detection and unsupervised image segmentation."
Positive Unlabeled Contrastive Learning,0.0900314,"Self-supervised pretraining on unlabeled data followed by supervised
fine-tuning on labeled data is a popular paradigm for learning from limited
labeled examples. We extend this paradigm to the classical positive unlabeled
(PU) setting, where the task is to learn a binary classifier given only a few
labeled positive samples, and (often) a large amount of unlabeled samples
(which could be positive or negative).
  We first propose a simple extension of standard infoNCE family of contrastive
losses, to the PU setting; and show that this learns superior representations,
as compared to existing unsupervised and supervised approaches. We then develop
a simple methodology to pseudo-label the unlabeled samples using a new
PU-specific clustering scheme; these pseudo-labels can then be used to train
the final (positive vs. negative) classifier. Our method handily outperforms
state-of-the-art PU methods over several standard PU benchmark datasets, while
not requiring a-priori knowledge of any class prior (which is a common
assumption in other PU methods). We also provide a simple theoretical analysis
that motivates our methods."
A Web Application for Experimenting and Validating Remote Measurement of Vital Signs,0.0251424,"With a surge in online medical advising remote monitoring of patient vitals
is required. This can be facilitated with the Remote Photoplethysmography
(rPPG) techniques that compute vital signs from facial videos. It involves
processing video frames to obtain skin pixels, extracting the cardiac data from
it and applying signal processing filters to extract the Blood Volume Pulse
(BVP) signal. Different algorithms are applied to the BVP signal to estimate
the various vital signs. We implemented a web application framework to measure
a person's Heart Rate (HR), Heart Rate Variability (HRV), Oxygen Saturation
(SpO2), Respiration Rate (RR), Blood Pressure (BP), and stress from the face
video. The rPPG technique is highly sensitive to illumination and motion
variation. The web application guides the users to reduce the noise due to
these variations and thereby yield a cleaner BVP signal. The accuracy and
robustness of the framework was validated with the help of volunteers."
Adaptive Discrete Communication Bottlenecks with Dynamic Vector Quantization,0.0985149,"Vector Quantization (VQ) is a method for discretizing latent representations
and has become a major part of the deep learning toolkit. It has been
theoretically and empirically shown that discretization of representations
leads to improved generalization, including in reinforcement learning where
discretization can be used to bottleneck multi-agent communication to promote
agent specialization and robustness. The discretization tightness of most
VQ-based methods is defined by the number of discrete codes in the
representation vector and the codebook size, which are fixed as
hyperparameters. In this work, we propose learning to dynamically select
discretization tightness conditioned on inputs, based on the hypothesis that
data naturally contains variations in complexity that call for different levels
of representational coarseness. We show that dynamically varying tightness in
communication bottlenecks can improve model performance on visual reasoning and
reinforcement learning tasks."
Improving Cross-Modal Retrieval with Set of Diverse Embeddings,0.00939534,"Cross-modal retrieval across image and text modalities is a challenging task
due to its inherent ambiguity: An image often exhibits various situations, and
a caption can be coupled with diverse images. Set-based embedding has been
studied as a solution to this problem. It seeks to encode a sample into a set
of different embedding vectors that capture different semantics of the sample.
In this paper, we present a novel set-based embedding method, which is distinct
from previous work in two aspects. First, we present a new similarity function
called smooth-Chamfer similarity, which is designed to alleviate the side
effects of existing similarity functions for set-based embedding. Second, we
propose a novel set prediction module to produce a set of embedding vectors
that effectively captures diverse semantics of input by the slot attention
mechanism. Our method is evaluated on the COCO and Flickr30K datasets across
different visual backbones, where it outperforms existing methods including
ones that demand substantially larger computation at inference."
Test-time image-to-image translation ensembling improves out-of-distribution generalization in histopathology,0.109145,"Histopathology whole slide images (WSIs) can reveal significant
inter-hospital variability such as illumination, color or optical artifacts.
These variations, caused by the use of different scanning protocols across
medical centers (staining, scanner), can strongly harm algorithms
generalization on unseen protocols. This motivates development of new methods
to limit such drop of performances. In this paper, to enhance robustness on
unseen target protocols, we propose a new test-time data augmentation based on
multi domain image-to-image translation. It allows to project images from
unseen protocol into each source domain before classifying them and ensembling
the predictions. This test-time augmentation method results in a significant
boost of performances for domain generalization. To demonstrate its
effectiveness, our method has been evaluated on 2 different histopathology
tasks where it outperforms conventional domain generalization, standard H&E
specific color augmentation/normalization and standard test-time augmentation
techniques. Our code is publicly available at
https://gitlab.com/vitadx/articles/test-time-i2i-translation-ensembling."
An Intelligent Assistant for Converting City Requirements to Formal Specification,0.061598,"As more and more monitoring systems have been deployed to smart cities, there
comes a higher demand for converting new human-specified requirements to
machine-understandable formal specifications automatically. However, these
human-specific requirements are often written in English and bring missing,
inaccurate, or ambiguous information. In this paper, we present CitySpec, an
intelligent assistant system for requirement specification in smart cities.
CitySpec not only helps overcome the language differences brought by English
requirements and formal specifications, but also offers solutions to those
missing, inaccurate, or ambiguous information. The goal of this paper is to
demonstrate how CitySpec works. Specifically, we present three demos: (1)
interactive completion of requirements in CitySpec; (2) human-in-the-loop
correction while CitySepc encounters exceptions; (3) online learning in
CitySpec."
Box2Seg: Learning Semantics of 3D Point Clouds with Box-Level Supervision,0.0,"Learning dense point-wise semantics from unstructured 3D point clouds with
fewer labels, although a realistic problem, has been under-explored in
literature. While existing weakly supervised methods can effectively learn
semantics with only a small fraction of point-level annotations, we find that
the vanilla bounding box-level annotation is also informative for semantic
segmentation of large-scale 3D point clouds. In this paper, we introduce a
neural architecture, termed Box2Seg, to learn point-level semantics of 3D point
clouds with bounding box-level supervision. The key to our approach is to
generate accurate pseudo labels by exploring the geometric and topological
structure inside and outside each bounding box. Specifically, an
attention-based self-training (AST) technique and Point Class Activation
Mapping (PCAM) are utilized to estimate pseudo-labels. The network is further
trained and refined with pseudo labels. Experiments on two large-scale
benchmarks including S3DIS and ScanNet demonstrate the competitive performance
of the proposed method. In particular, the proposed network can be trained with
cheap, or even off-the-shelf bounding box-level annotations and subcloud-level
tags."
Reducing Position Bias in Simultaneous Machine Translation with Length-Aware Framework,0.106779,"Simultaneous machine translation (SiMT) starts translating while receiving
the streaming source inputs, and hence the source sentence is always incomplete
during translating. Different from the full-sentence MT using the conventional
seq-to-seq architecture, SiMT often applies prefix-to-prefix architecture,
which forces each target word to only align with a partial source prefix to
adapt to the incomplete source in streaming inputs. However, the source words
in the front positions are always illusoryly considered more important since
they appear in more prefixes, resulting in position bias, which makes the model
pay more attention on the front source positions in testing. In this paper, we
first analyze the phenomenon of position bias in SiMT, and develop a
Length-Aware Framework to reduce the position bias by bridging the structural
gap between SiMT and full-sentence MT. Specifically, given the streaming
inputs, we first predict the full-sentence length and then fill the future
source position with positional encoding, thereby turning the streaming inputs
into a pseudo full-sentence. The proposed framework can be integrated into most
existing SiMT methods to further improve performance. Experiments on two
representative SiMT methods, including the state-of-the-art adaptive policy,
show that our method successfully reduces the position bias and thereby
achieves better SiMT performance."
SupMAE: Supervised Masked Autoencoders Are Efficient Vision Learners,0.165422,"Recently, self-supervised Masked Autoencoders (MAE) have attracted
unprecedented attention for their impressive representation learning ability.
However, the pretext task, Masked Image Modeling (MIM), reconstructs the
missing local patches, lacking the global understanding of the image. This
paper extends MAE to a fully supervised setting by adding a supervised
classification branch, thereby enabling MAE to learn global features from
golden labels effectively. The proposed Supervised MAE (SupMAE) only exploits a
visible subset of image patches for classification, unlike the standard
supervised pre-training where all image patches are used. Through experiments,
we demonstrate that SupMAE is not only more training efficient but it also
learns more robust and transferable features. Specifically, SupMAE achieves
comparable performance with MAE using only 30% of compute when evaluated on
ImageNet with the ViT-B/16 model. SupMAE's robustness on ImageNet variants and
transfer learning performance outperforms MAE and standard supervised
pre-training counterparts. Codes are available at
https://github.com/enyac-group/supmae."
Explainability in reinforcement learning: perspective and position,0.0866628,"Artificial intelligence (AI) has been embedded into many aspects of people's
daily lives and it has become normal for people to have AI make decisions for
them. Reinforcement learning (RL) models increase the space of solvable
problems with respect to other machine learning paradigms. Some of the most
interesting applications are in situations with non-differentiable expected
reward function, operating in unknown or underdefined environment, as well as
for algorithmic discovery that surpasses performance of any teacher, whereby
agent learns from experimental experience through simple feedback. The range of
applications and their social impact is vast, just to name a few: genomics,
game-playing (chess, Go, etc.), general optimization, financial investment,
governmental policies, self-driving cars, recommendation systems, etc. It is
therefore essential to improve the trust and transparency of RL-based systems
through explanations. Most articles dealing with explainability in artificial
intelligence provide methods that concern supervised learning and there are
very few articles dealing with this in the area of RL. The reasons for this are
the credit assignment problem, delayed rewards, and the inability to assume
that data is independently and identically distributed (i.i.d.). This position
paper attempts to give a systematic overview of existing methods in the
explainable RL area and propose a novel unified taxonomy, building and
expanding on the existing ones. The position section describes pragmatic
aspects of how explainability can be observed. The gap between the parties
receiving and generating the explanation is especially emphasized. To reduce
the gap and achieve honesty and truthfulness of explanations, we set up three
pillars: proactivity, risk attitudes, and epistemological constraints. To this
end, we illustrate our proposal on simple variants of the shortest path
problem."
Prediction-based One-shot Dynamic Parking Pricing,0.0223606,"Many U.S. metropolitan cities are notorious for their severe shortage of
parking spots. To this end, we present a proactive prediction-driven
optimization framework to dynamically adjust parking prices. We use
state-of-the-art deep learning technologies such as neural ordinary
differential equations (NODEs) to design our future parking occupancy rate
prediction model given historical occupancy rates and price information. Owing
to the continuous and bijective characteristics of NODEs, in addition, we
design a one-shot price optimization method given a pre-trained prediction
model, which requires only one iteration to find the optimal solution. In other
words, we optimize the price input to the pre-trained prediction model to
achieve targeted occupancy rates in the parking blocks. We conduct experiments
with the data collected in San Francisco and Seattle for years. Our prediction
model shows the best accuracy in comparison with various temporal or
spatio-temporal forecasting models. Our one-shot optimization method greatly
outperforms other black-box and white-box search methods in terms of the search
time and always returns the optimal price solution."
Human-centric Image Cropping with Partition-aware and Content-preserving Features,0.0915717,"Image cropping aims to find visually appealing crops in an image, which is an
important yet challenging task. In this paper, we consider a specific and
practical application: human-centric image cropping, which focuses on the
depiction of a person. To this end, we propose a human-centric image cropping
method with two novel feature designs for the candidate crop: partition-aware
feature and content-preserving feature. For partition-aware feature, we divide
the whole image into nine partitions based on the human bounding box and treat
different partitions in a candidate crop differently conditioned on the human
information. For content-preserving feature, we predict a heatmap indicating
the important content to be included in a good crop, and extract the geometric
relation between the heatmap and a candidate crop. Extensive experiments
demonstrate that our method can perform favorably against state-of-the-art
image cropping methods on human-centric image cropping task. Code is available
at https://github.com/bcmi/Human-Centric-Image-Cropping."
Discovering Bugs in Vision Models using Off-the-shelf Image Generation and Captioning,0.147612,"Automatically discovering failures in vision models under real-world settings
remains an open challenge. This work demonstrates how off-the-shelf,
large-scale, image-to-text and text-to-image models, trained on vast amounts of
data, can be leveraged to automatically find such failures. In essence, a
conditional text-to-image generative model is used to generate large amounts of
synthetic, yet realistic, inputs given a ground-truth label. Misclassified
inputs are clustered and a captioning model is used to describe each cluster.
Each cluster's description is used in turn to generate more inputs and assess
whether specific clusters induce more failures than expected. We use this
pipeline to demonstrate that we can effectively interrogate classifiers trained
on ImageNet to find specific failure cases and discover spurious correlations.
We also show that we can scale the approach to generate adversarial datasets
targeting specific classifier architectures. This work serves as a
proof-of-concept demonstrating the utility of large-scale generative models to
automatically discover bugs in vision models in an open-ended manner. We also
describe a number of limitations and pitfalls related to this approach."
Evolved Open-Endedness in Cultural Evolution: A New Dimension in Open-Ended Evolution Research,0.0416543,"The goal of Artificial Life research, as articulated by Chris Langton, is ""to
contribute to theoretical biology by locating life-as-we-know-it within the
larger picture of life-as-it-could-be"" (1989, p.1). The study and pursuit of
open-ended evolution in artificial evolutionary systems exemplifies this goal.
However, open-ended evolution research is hampered by two fundamental issues;
the struggle to replicate open-endedness in an artificial evolutionary system,
and the fact that we only have one system (genetic evolution) from which to
draw inspiration. Here we argue that cultural evolution should be seen not only
as another real-world example of an open-ended evolutionary system, but that
the unique qualities seen in cultural evolution provide us with a new
perspective from which we can assess the fundamental properties of, and ask new
questions about, open-ended evolutionary systems, especially in regard to
evolved open-endedness and transitions from bounded to unbounded evolution.
Here we provide an overview of culture as an evolutionary system, highlight the
interesting case of human cultural evolution as an open-ended evolutionary
system, and contextualise cultural evolution under the framework of (evolved)
open-ended evolution. We go on to provide a set of new questions that can be
asked once we consider cultural evolution within the framework of open-ended
evolution, and introduce new insights that we may be able to gain about evolved
open-endedness as a result of asking these questions."
Missingness Bias in Model Debugging,0.0450498,"Missingness, or the absence of features from an input, is a concept
fundamental to many model debugging tools. However, in computer vision, pixels
cannot simply be removed from an image. One thus tends to resort to heuristics
such as blacking out pixels, which may in turn introduce bias into the
debugging process. We study such biases and, in particular, show how
transformer-based architectures can enable a more natural implementation of
missingness, which side-steps these issues and improves the reliability of
model debugging in practice. Our code is available at
https://github.com/madrylab/missingness"
First Competitive Ant Colony Scheme for the CARP,0.176177,"This paper addresses the Capacitated Arc Routing Problem (CARP) using an Ant
Colony Optimization scheme. Ant Colony schemes can compute solutions for medium
scale instances of VRP. The proposed Ant Colony is dedicated to large-scale
instances of CARP with more than 140 nodes and 190 arcs to service. The Ant
Colony scheme is coupled with a local search procedure and provides high
quality solutions. The benchmarks we carried out prove possible to obtain
solutions as profitable as CARPET ones can be obtained using such scheme when a
sufficient number of iterations is devoted to the ants. It competes with the
Genetic Algorithm of Lacomme et al. regarding solution quality but it is more
time consuming on large scale instances. The method has been intensively
benchmarked on the well-known instances of Eglese, DeArmon and the last ones of
Belenguer and Benavent. This research report is a step forward CARP resolution
by Ant Colony proving ant schemes can compete with Taboo search methods and
Genetic Algorithms"
Deep Convolutional Learning-Aided Detector for Generalized Frequency Division Multiplexing with Index Modulation,0.11584,"In this paper, a deep convolutional neural network-based symbol detection and
demodulation is proposed for generalized frequency division multiplexing with
index modulation (GFDM-IM) scheme in order to improve the error performance of
the system. The proposed method first pre-processes the received signal by
using a zero-forcing (ZF) detector and then uses a neural network consisting of
a convolutional neural network (CNN) followed by a fully-connected neural
network (FCNN). The FCNN part uses only two fully-connected layers, which can
be adapted to yield a trade-off between complexity and bit error rate (BER)
performance. This two-stage approach prevents the getting stuck of neural
network in a saddle point and enables IM blocks processing independently. It
has been demonstrated that the proposed deep convolutional neural network-based
detection and demodulation scheme provides better BER performance compared to
ZF detector with a reasonable complexity increase. We conclude that
non-orthogonal waveforms combined with IM schemes with the help of deep
learning is a promising physical layer (PHY) scheme for future wireless
networks"
Multimodal data matters: language model pre-training over structured and unstructured electronic health records,0.0537785,"As two important textual modalities in electronic health records (EHR), both
structured data (clinical codes) and unstructured data (clinical narratives)
have recently been increasingly applied to the healthcare domain. Most existing
EHR-oriented studies, however, either focus on a particular modality or
integrate data from different modalities in a straightforward manner, which
usually treats structured and unstructured data as two independent sources of
information about patient admission and ignore the intrinsic interactions
between them. In fact, the two modalities are documented during the same
encounter where structured data inform the documentation of unstructured data
and vice versa. In this paper, we proposed a Medical Multimodal Pre-trained
Language Model, named MedM-PLM, to learn enhanced EHR representations over
structured and unstructured data and explore the interaction of two modalities.
In MedM-PLM, two Transformer-based neural network components are firstly
adopted to learn representative characteristics from each modality. A
cross-modal module is then introduced to model their interactions. We
pre-trained MedM-PLM on the MIMIC-III dataset and verified the effectiveness of
the model on three downstream clinical tasks, i.e., medication recommendation,
30-day readmission prediction and ICD coding. Extensive experiments demonstrate
the power of MedM-PLM compared with state-of-the-art methods. Further analyses
and visualizations show the robustness of our model, which could potentially
provide more comprehensive interpretations for clinical decision-making."
Mathematical model of printing-imaging channel for blind detection of fake copy detection patterns,0.14588,"Nowadays, copy detection patterns (CDP) appear as a very promising
anti-counterfeiting technology for physical object protection. However, the
advent of deep learning as a powerful attacking tool has shown that the general
authentication schemes are unable to compete and fail against such attacks. In
this paper, we propose a new mathematical model of printing-imaging channel for
the authentication of CDP together with a new detection scheme based on it. The
results show that even deep learning created copy fakes unknown at the training
stage can be reliably authenticated based on the proposed approach and using
only digital references of CDP during authentication."
Learning Uncertainty with Artificial Neural Networks for Improved Predictive Process Monitoring,0.0989542,"The inability of artificial neural networks to assess the uncertainty of
their predictions is an impediment to their widespread use. We distinguish two
types of learnable uncertainty: model uncertainty due to a lack of training
data and noise-induced observational uncertainty. Bayesian neural networks use
solid mathematical foundations to learn the model uncertainties of their
predictions. The observational uncertainty can be calculated by adding one
layer to these networks and augmenting their loss functions. Our contribution
is to apply these uncertainty concepts to predictive process monitoring tasks
to train uncertainty-based models to predict the remaining time and outcomes.
Our experiments show that uncertainty estimates allow more and less accurate
predictions to be differentiated and confidence intervals to be constructed in
both regression and classification tasks. These conclusions remain true even in
early stages of running processes. Moreover, the deployed techniques are fast
and produce more accurate predictions. The learned uncertainty could increase
users' confidence in their process prediction systems, promote better
cooperation between humans and these systems, and enable earlier
implementations with smaller datasets."
Watching the News: Towards VideoQA Models that can Read,0.950213,"Video Question Answering methods focus on commonsense reasoning and visual
cognition of objects or persons and their interactions over time. Current
VideoQA approaches ignore the textual information present in the video.
Instead, we argue that textual information is complementary to the action and
provides essential contextualisation cues to the reasoning process. To this
end, we propose a novel VideoQA task that requires reading and understanding
the text in the video. To explore this direction, we focus on news videos and
require QA systems to comprehend and answer questions about the topics
presented by combining visual and textual cues in the video. We introduce the
``NewsVideoQA'' dataset that comprises more than $8,600$ QA pairs on $3,000+$
news videos obtained from diverse news channels from around the world. We
demonstrate the limitations of current Scene Text VQA and VideoQA methods and
propose ways to incorporate scene text information into VideoQA methods."
An Effective Iterated Two-stage Heuristic Algorithm for the Multiple Traveling Salesmen Problem,0.0268297,"The multiple Traveling Salesmen Problem (mTSP) is a general extension of the
famous NP-hard Traveling Salesmen Problem (TSP), that there are m (m > 1)
salesmen to visit the cities. In this paper, we address the mTSP with both the
minsum objective and minmax objective, which aims at minimizing the total
length of the $m$ tours and the length of the longest tour among all the m
tours, respectively. We propose an iterated two-stage heuristic algorithm
called ITSHA for the mTSP. Each iteration of ITSHA consists of an
initialization stage and an improvement stage. The initialization stage aims to
generate high-quality and diverse initial solutions. The improvement stage
mainly applies the variable neighborhood search (VNS) approach based on our
proposed effective local search neighborhoods to optimize the initial solution.
Moreover, some local optima escaping approaches are employed to enhance the
search ability of the algorithm. Extensive experimental results on a wide range
of public benchmark instances show that ITSHA significantly outperforms the
state-of-the-art heuristic algorithms in solving the mTSP on both the
objectives."
Formal Contracts Mitigate Social Dilemmas in Multi-Agent RL,0.124733,"Multi-agent Reinforcement Learning (MARL) is a powerful tool for training
autonomous agents acting independently in a common environment. However, it can
lead to sub-optimal behavior when individual incentives and group incentives
diverge. Humans are remarkably capable at solving these social dilemmas. It is
an open problem in MARL to replicate such cooperative behaviors in selfish
agents. In this work, we draw upon the idea of formal contracting from
economics to overcome diverging incentives between agents in MARL. We propose
an augmentation to a Markov game where agents voluntarily agree to binding
transfers of reward, under pre-specified conditions. Our contributions are
theoretical and empirical. First, we show that this augmentation makes all
subgame-perfect equilibria of all Fully Observable Markov Games exhibit
socially optimal behavior, given a sufficiently rich space of contracts. Next,
we show that for general contract spaces, and even under partial observability,
richer contract spaces lead to higher welfare. Hence, contract space design
solves an exploration-exploitation tradeoff, sidestepping incentive issues. We
complement our theoretical analysis with experiments. Issues of exploration in
the contracting augmentation are mitigated using a training methodology
inspired by multi-objective reinforcement learning: Multi-Objective Contract
Augmentation Learning (MOCA). We test our methodology in static, single-move
games, as well as dynamic domains that simulate traffic, pollution management
and common pool resource management."
PEANUT: Predicting and Navigating to Unseen Targets,0.217298,"Efficient ObjectGoal navigation (ObjectNav) in novel environments requires an
understanding of the spatial and semantic regularities in environment layouts.
In this work, we present a straightforward method for learning these
regularities by predicting the locations of unobserved objects from incomplete
semantic maps. Our method differs from previous prediction-based navigation
methods, such as frontier potential prediction or egocentric map completion, by
directly predicting unseen targets while leveraging the global context from all
previously explored areas. Our prediction model is lightweight and can be
trained in a supervised manner using a relatively small amount of passively
collected data. Once trained, the model can be incorporated into a modular
pipeline for ObjectNav without the need for any reinforcement learning. We
validate the effectiveness of our method on the HM3D and MP3D ObjectNav
datasets. We find that it achieves the state-of-the-art on both datasets,
despite not using any additional data for training."
Tele-Knowledge Pre-training for Fault Analysis,0.100149,"In this work, we share our experience on tele-knowledge pre-training for
fault analysis, a crucial task in telecommunication applications that requires
a wide range of knowledge normally found in both machine log data and product
documents. To organize this knowledge from experts uniformly, we propose to
create a Tele-KG (tele-knowledge graph). Using this valuable data, we further
propose a tele-domain language pre-training model TeleBERT and its
knowledge-enhanced version, a tele-knowledge re-training model KTeleBERT. which
includes effective prompt hints, adaptive numerical data encoding, and two
knowledge injection paradigms. Concretely, our proposal includes two stages:
first, pre-training TeleBERT on 20 million tele-related corpora, and then
re-training it on 1 million causal and machine-related corpora to obtain
KTeleBERT. Our evaluation on multiple tasks related to fault analysis in
tele-applications, including root-cause analysis, event association prediction,
and fault chain tracing, shows that pre-training a language model with
tele-domain data is beneficial for downstream tasks. Moreover, the KTeleBERT
re-training further improves the performance of task models, highlighting the
effectiveness of incorporating diverse tele-knowledge into the model."
Unobserved Local Structures Make Compositional Generalization Hard,0.304974,"While recent work has convincingly showed that sequence-to-sequence models
struggle to generalize to new compositions (termed compositional
generalization), little is known on what makes compositional generalization
hard on a particular test instance. In this work, we investigate what are the
factors that make generalization to certain test instances challenging. We
first substantiate that indeed some examples are more difficult than others by
showing that different models consistently fail or succeed on the same test
instances. Then, we propose a criterion for the difficulty of an example: a
test instance is hard if it contains a local structure that was not observed at
training time. We formulate a simple decision rule based on this criterion and
empirically show it predicts instance-level generalization well across 5
different semantic parsing datasets, substantially better than alternative
decision rules. Last, we show local structures can be leveraged for creating
difficult adversarial compositional splits and also to improve compositional
generalization under limited training budgets by strategically selecting
examples for the training set."
NeReF: Neural Refractive Field for Fluid Surface Reconstruction and Implicit Representation,0.0475887,"Existing neural reconstruction schemes such as Neural Radiance Field (NeRF)
are largely focused on modeling opaque objects. We present a novel neural
refractive field(NeReF) to recover wavefront of transparent fluids by
simultaneously estimating the surface position and normal of the fluid front.
Unlike prior arts that treat the reconstruction target as a single layer of the
surface, NeReF is specifically formulated to recover a volumetric normal field
with its corresponding density field. A query ray will be refracted by NeReF
according to its accumulated refractive point and normal, and we employ the
correspondences and uniqueness of refracted ray for NeReF optimization. We show
NeReF, as a global optimization scheme, can more robustly tackle refraction
distortions detrimental to traditional methods for correspondence matching.
Furthermore, the continuous NeReF representation of wavefront enables view
synthesis as well as normal integration. We validate our approach on both
synthetic and real data and show it is particularly suitable for sparse
multi-view acquisition. We hence build a small light field array and experiment
on various surface shapes to demonstrate high fidelity NeReF reconstruction."
Audio-visual speech enhancement with a deep Kalman filter generative model,0.00852009,"Deep latent variable generative models based on variational autoencoder (VAE)
have shown promising performance for audiovisual speech enhancement (AVSE). The
underlying idea is to learn a VAEbased audiovisual prior distribution for clean
speech data, and then combine it with a statistical noise model to recover a
speech signal from a noisy audio recording and video (lip images) of the target
speaker. Existing generative models developed for AVSE do not take into account
the sequential nature of speech data, which prevents them from fully
incorporating the power of visual data. In this paper, we present an
audiovisual deep Kalman filter (AV-DKF) generative model which assumes a
first-order Markov chain model for the latent variables and effectively fuses
audiovisual data. Moreover, we develop an efficient inference methodology to
estimate speech signals at test time. We conduct a set of experiments to
compare different variants of generative models for speech enhancement. The
results demonstrate the superiority of the AV-DKF model compared with both its
audio-only version and the non-sequential audio-only and audiovisual VAE-based
models."
RIM-Net: Recursive Implicit Fields for Unsupervised Learning of Hierarchical Shape Structures,0.0901979,"We introduce RIM-Net, a neural network which learns recursive implicit fields
for unsupervised inference of hierarchical shape structures. Our network
recursively decomposes an input 3D shape into two parts, resulting in a binary
tree hierarchy. Each level of the tree corresponds to an assembly of shape
parts, represented as implicit functions, to reconstruct the input shape. At
each node of the tree, simultaneous feature decoding and shape decomposition
are carried out by their respective feature and part decoders, with weight
sharing across the same hierarchy level. As an implicit field decoder, the part
decoder is designed to decompose a sub-shape, via a two-way branched
reconstruction, where each branch predicts a set of parameters defining a
Gaussian to serve as a local point distribution for shape reconstruction. With
reconstruction losses accounted for at each hierarchy level and a decomposition
loss at each node, our network training does not require any ground-truth
segmentations, let alone hierarchies. Through extensive experiments and
comparisons to state-of-the-art alternatives, we demonstrate the quality,
consistency, and interpretability of hierarchical structural inference by
RIM-Net."
MotionSC: Data Set and Network for Real-Time Semantic Mapping in Dynamic Environments,-1.0,"This work addresses a gap in semantic scene completion (SSC) data by creating
a novel outdoor data set with accurate and complete dynamic scenes. Our data
set is formed from randomly sampled views of the world at each time step, which
supervises generalizability to complete scenes without occlusions or traces. We
create SSC baselines from state-of-the-art open source networks and construct a
benchmark real-time dense local semantic mapping algorithm, MotionSC, by
leveraging recent 3D deep learning architectures to enhance SSC with temporal
information. Our network shows that the proposed data set can quantify and
supervise accurate scene completion in the presence of dynamic objects, which
can lead to the development of improved dynamic mapping algorithms. All
software is available at https://github.com/UMich-CURLY/3DMapping."
On Calibrating Semantic Segmentation Models: Analyses and An Algorithm,0.0,"We study the problem of semantic segmentation calibration. Lots of solutions
have been proposed to approach model miscalibration of confidence in image
classification. However, to date, confidence calibration research on semantic
segmentation is still limited. We provide a systematic study on the calibration
of semantic segmentation models and propose a simple yet effective approach.
First, we find that model capacity, crop size, multi-scale testing, and
prediction correctness have impact on calibration. Among them, prediction
correctness, especially misprediction, is more important to miscalibration due
to over-confidence. Next, we propose a simple, unifying, and effective
approach, namely selective scaling, by separating correct/incorrect prediction
for scaling and more focusing on misprediction logit smoothing. Then, we study
popular existing calibration methods and compare them with selective scaling on
semantic segmentation calibration. We conduct extensive experiments with a
variety of benchmarks on both in-domain and domain-shift calibration and show
that selective scaling consistently outperforms other methods."
Discrete-Constrained Regression for Local Counting Models,0.0779338,"Local counts, or the number of objects in a local area, is a continuous value
by nature. Yet recent state-of-the-art methods show that formulating counting
as a classification task performs better than regression. Through a series of
experiments on carefully controlled synthetic data, we show that this
counter-intuitive result is caused by imprecise ground truth local counts.
Factors such as biased dot annotations and incorrectly matched Gaussian kernels
used to generate ground truth counts introduce deviations from the true local
counts. Standard continuous regression is highly sensitive to these errors,
explaining the performance gap between classification and regression. To
mitigate the sensitivity, we loosen the regression formulation from a
continuous scale to a discrete ordering and propose a novel
discrete-constrained (DC) regression. Applied to crowd counting, DC-regression
is more accurate than both classification and standard regression on three
public benchmarks. A similar advantage also holds for the age estimation task,
verifying the overall effectiveness of DC-regression."
Event-Based Dense Reconstruction Pipeline,0.0661083,"Event cameras are a new type of sensors that are different from traditional
cameras. Each pixel is triggered asynchronously by event. The trigger event is
the change of the brightness irradiated on the pixel. If the increment or
decrement of brightness is higher than a certain threshold, an event is output.
Compared with traditional cameras, event cameras have the advantages of high
dynamic range and no motion blur. Since events are caused by the apparent
motion of intensity edges, the majority of 3D reconstructed maps consist only
of scene edges, i.e., semi-dense maps, which is not enough for some
applications. In this paper, we propose a pipeline to realize event-based dense
reconstruction. First, deep learning is used to reconstruct intensity images
from events. And then, structure from motion (SfM) is used to estimate camera
intrinsic, extrinsic and sparse point cloud. Finally, multi-view stereo (MVS)
is used to complete dense reconstruction."
Balancing Stability and Plasticity through Advanced Null Space in Continual Learning,0.17419,"Continual learning is a learning paradigm that learns tasks sequentially with
resources constraints, in which the key challenge is stability-plasticity
dilemma, i.e., it is uneasy to simultaneously have the stability to prevent
catastrophic forgetting of old tasks and the plasticity to learn new tasks
well. In this paper, we propose a new continual learning approach, Advanced
Null Space (AdNS), to balance the stability and plasticity without storing any
old data of previous tasks. Specifically, to obtain better stability, AdNS
makes use of low-rank approximation to obtain a novel null space and projects
the gradient onto the null space to prevent the interference on the past tasks.
To control the generation of the null space, we introduce a non-uniform
constraint strength to further reduce forgetting. Furthermore, we present a
simple but effective method, intra-task distillation, to improve the
performance of the current task. Finally, we theoretically find that null space
plays a key role in plasticity and stability, respectively. Experimental
results show that the proposed method can achieve better performance compared
to state-of-the-art continual learning approaches."
Self-consistent Reasoning For Solving Math Word Problems,0.038944,"Math word problems (MWPs) is a task that automatically derives solution
expression from a giving math problems in text. The previous studies suffer
from spurious correlations between input text and output expression. To
mitigate this issue, we propose a self-consistent reasoning framework called
SCR, which attempts to adopt a pruning strategy to correct the output
distribution shift so as to implicitly fix those spurious correlative samples.
Specifically, we firstly obtain a sub-network by pruning a roberta2tree model,
for the sake to use the gap on output distribution between the original
roberta2tree model and the pruned sub-network to expose spurious correlative
samples. Then, we calibrate the output distribution shift by applying symmetric
Kullback-Leibler divergence to alleviate spurious correlations. In addition,
SCR generates equivalent expressions, thereby, capturing the original text's
logic rather than relying on hints from original text. Extensive experiments on
two large-scale benchmarks demonstrate that our model substantially outperforms
the strong baseline methods."
CHARD: Clinical Health-Aware Reasoning Across Dimensions for Text Generation Models,0.190023,"We motivate and introduce CHARD: Clinical Health-Aware Reasoning across
Dimensions, to investigate the capability of text generation models to act as
implicit clinical knowledge bases and generate free-flow textual explanations
about various health-related conditions across several dimensions. We collect
and present an associated dataset, CHARDat, consisting of explanations about 52
health conditions across three clinical dimensions. We conduct extensive
experiments using BART and T5 along with data augmentation, and perform
automatic, human, and qualitative analyses. We show that while our models can
perform decently, CHARD is very challenging with strong potential for further
exploration."
Domain Adaptation meets Individual Fairness. And they get along,0.0872508,"Many instances of algorithmic bias are caused by distributional shifts. For
example, machine learning (ML) models often perform worse on demographic groups
that are underrepresented in the training data. In this paper, we leverage this
connection between algorithmic fairness and distribution shifts to show that
algorithmic fairness interventions can help ML models overcome distribution
shifts, and that domain adaptation methods (for overcoming distribution shifts)
can mitigate algorithmic biases. In particular, we show that (i) enforcing
suitable notions of individual fairness (IF) can improve the
out-of-distribution accuracy of ML models under the covariate shift assumption
and that (ii) it is possible to adapt representation alignment methods for
domain adaptation to enforce individual fairness. The former is unexpected
because IF interventions were not developed with distribution shifts in mind.
The latter is also unexpected because representation alignment is not a common
approach in the individual fairness literature."
Calibrated Interpretation: Confidence Estimation in Semantic Parsing,0.0687773,"Sequence generation models are increasingly being used to translate natural
language into programs, i.e. to perform executable semantic parsing. The fact
that semantic parsing aims to predict programs that can lead to executed
actions in the real world motivates developing safe systems. This in turn makes
measuring calibration -- a central component to safety -- particularly
important. We investigate the calibration of popular generation models across
four popular semantic parsing datasets, finding that it varies across models
and datasets. We then analyze factors associated with calibration error and
release new confidence-based challenge splits of two parsing datasets. To
facilitate the inclusion of calibration in semantic parsing evaluations, we
release a library for computing calibration metrics."
KERPLE: Kernelized Relative Positional Embedding for Length Extrapolation,0.864665,"Relative positional embeddings (RPE) have received considerable attention
since RPEs effectively model the relative distance among tokens and enable
length extrapolation. We propose KERPLE, a framework that generalizes relative
position embedding for extrapolation by kernelizing positional differences. We
achieve this goal using conditionally positive definite (CPD) kernels, a class
of functions known for generalizing distance metrics. To maintain the inner
product interpretation of self-attention, we show that a CPD kernel can be
transformed into a PD kernel by adding a constant offset. This offset is
implicitly absorbed in the Softmax normalization during self-attention. The
diversity of CPD kernels allows us to derive various RPEs that enable length
extrapolation in a principled way. Experiments demonstrate that the logarithmic
variant achieves excellent extrapolation performance on three large language
modeling datasets. Our implementation and pretrained checkpoints are released
at https://github.com/chijames/KERPLE.git."
Can Requirements Engineering Support Explainable Artificial Intelligence? Towards a User-Centric Approach for Explainability Requirements,0.0493507,"With the recent proliferation of artificial intelligence systems, there has
been a surge in the demand for explainability of these systems. Explanations
help to reduce system opacity, support transparency, and increase stakeholder
trust. In this position paper, we discuss synergies between requirements
engineering (RE) and Explainable AI (XAI). We highlight challenges in the field
of XAI, and propose a framework and research directions on how RE practices can
help to mitigate these challenges."
Retrieval Augmentation for Commonsense Reasoning: A Unified Approach,0.349357,"A common thread of retrieval-augmented methods in the existing literature
focuses on retrieving encyclopedic knowledge, such as Wikipedia, which
facilitates well-defined entity and relation spaces that can be modeled.
However, applying such methods to commonsense reasoning tasks faces two unique
challenges, i.e., the lack of a general large-scale corpus for retrieval and a
corresponding effective commonsense retriever. In this paper, we systematically
investigate how to leverage commonsense knowledge retrieval to improve
commonsense reasoning tasks. We proposed a unified framework of
retrieval-augmented commonsense reasoning (called RACo), including a newly
constructed commonsense corpus with over 20 million documents and novel
strategies for training a commonsense retriever. We conducted experiments on
four different commonsense reasoning tasks. Extensive evaluation results showed
that our proposed RACo can significantly outperform other knowledge-enhanced
method counterparts, achieving new SoTA performance on the CommonGen and CREAK
leaderboards."
Mapless Navigation of a Hybrid Aerial Underwater Vehicle with Deep Reinforcement Learning Through Environmental Generalization,0.357525,"Previous works showed that Deep-RL can be applied to perform mapless
navigation, including the medium transition of Hybrid Unmanned Aerial
Underwater Vehicles (HUAUVs). This paper presents new approaches based on the
state-of-the-art actor-critic algorithms to address the navigation and medium
transition problems for a HUAUV. We show that a double critic Deep-RL with
Recurrent Neural Networks improves the navigation performance of HUAUVs using
solely range data and relative localization. Our Deep-RL approaches achieved
better navigation and transitioning capabilities with a solid generalization of
learning through distinct simulated scenarios, outperforming previous
approaches."
MISeval: a Metric Library for Medical Image Segmentation Evaluation,0.099136,"Correct performance assessment is crucial for evaluating modern artificial
intelligence algorithms in medicine like deep-learning based medical image
segmentation models. However, there is no universal metric library in Python
for standardized and reproducible evaluation. Thus, we propose our open-source
publicly available Python package MISeval: a metric library for Medical Image
Segmentation Evaluation. The implemented metrics can be intuitively used and
easily integrated into any performance assessment pipeline. The package
utilizes modern CI/CD strategies to ensure functionality and stability. MISeval
is available from PyPI (miseval) and GitHub:
https://github.com/frankkramer-lab/miseval."
Attention-based Random Forest and Contamination Model,0.0253792,"A new approach called ABRF (the attention-based random forest) and its
modifications for applying the attention mechanism to the random forest (RF)
for regression and classification are proposed. The main idea behind the
proposed ABRF models is to assign attention weights with trainable parameters
to decision trees in a specific way. The weights depend on the distance between
an instance, which falls into a corresponding leaf of a tree, and instances,
which fall in the same leaf. This idea stems from representation of the
Nadaraya-Watson kernel regression in the form of a RF. Three modifications of
the general approach are proposed. The first one is based on applying the
Huber's contamination model and on computing the attention weights by solving
quadratic or linear optimization problems. The second and the third
modifications use the gradient-based algorithms for computing trainable
parameters. Numerical experiments with various regression and classification
datasets illustrate the proposed method."
Rethinking the Role of Pre-Trained Networks in Source-Free Domain Adaptation,0.0491142,"Source-free domain adaptation (SFDA) aims to adapt a source model trained on
a fully-labeled source domain to an unlabeled target domain. Large-data
pre-trained networks are used to initialize source models during source
training, and subsequently discarded. However, source training can cause the
model to overfit to source data distribution and lose applicable target domain
knowledge. We propose to integrate the pre-trained network into the target
adaptation process as it has diversified features important for generalization
and provides an alternate view of features and classification decisions
different from the source model. We propose to distil useful target domain
information through a co-learning strategy to improve target pseudolabel
quality for finetuning the source model. Evaluation on 4 benchmark datasets
show that our proposed strategy improves adaptation performance and can be
successfully integrated with existing SFDA methods. Leveraging modern
pre-trained networks that have stronger representation learning ability in the
co-learning strategy further boosts performance."
Error Compensation Framework for Flow-Guided Video Inpainting,0.742475,"The key to video inpainting is to use correlation information from as many
reference frames as possible. Existing flow-based propagation methods split the
video synthesis process into multiple steps: flow completion -> pixel
propagation -> synthesis. However, there is a significant drawback that the
errors in each step continue to accumulate and amplify in the next step. To
this end, we propose an Error Compensation Framework for Flow-guided Video
Inpainting (ECFVI), which takes advantage of the flow-based method and offsets
its weaknesses. We address the weakness with the newly designed flow completion
module and the error compensation network that exploits the error guidance map.
Our approach greatly improves the temporal consistency and the visual quality
of the completed videos. Experimental results show the superior performance of
our proposed method with the speed up of x6, compared to the state-of-the-art
methods. In addition, we present a new benchmark dataset for evaluation by
supplementing the weaknesses of existing test datasets."
An Outlier Exposure Approach to Improve Visual Anomaly Detection Performance for Mobile Robots,0.0371808,"We consider the problem of building visual anomaly detection systems for
mobile robots. Standard anomaly detection models are trained using large
datasets composed only of non-anomalous data. However, in robotics
applications, it is often the case that (potentially very few) examples of
anomalies are available. We tackle the problem of exploiting these data to
improve the performance of a Real-NVP anomaly detection model, by minimizing,
jointly with the Real-NVP loss, an auxiliary outlier exposure margin loss. We
perform quantitative experiments on a novel dataset (which we publish as
supplementary material) designed for anomaly detection in an indoor patrolling
scenario. On a disjoint test set, our approach outperforms alternatives and
shows that exposing even a small number of anomalous frames yields significant
performance improvements."
Enhancing Document-level Relation Extraction by Entity Knowledge Injection,0.131847,"Document-level relation extraction (RE) aims to identify the relations
between entities throughout an entire document. It needs complex reasoning
skills to synthesize various knowledge such as coreferences and commonsense.
Large-scale knowledge graphs (KGs) contain a wealth of real-world facts, and
can provide valuable knowledge to document-level RE. In this paper, we propose
an entity knowledge injection framework to enhance current document-level RE
models. Specifically, we introduce coreference distillation to inject
coreference knowledge, endowing an RE model with the more general capability of
coreference reasoning. We also employ representation reconciliation to inject
factual knowledge and aggregate KG representations and document representations
into a unified space. The experiments on two benchmark datasets validate the
generalization of our entity knowledge injection framework and the consistent
improvement to several document-level RE models."
AsPOS: Assamese Part of Speech Tagger using Deep Learning Approach,0.515258,"Part of Speech (POS) tagging is crucial to Natural Language Processing (NLP).
It is a well-studied topic in several resource-rich languages. However, the
development of computational linguistic resources is still in its infancy
despite the existence of numerous languages that are historically and literary
rich. Assamese, an Indian scheduled language, spoken by more than 25 million
people, falls under this category. In this paper, we present a Deep Learning
(DL)-based POS tagger for Assamese. The development process is divided into two
stages. In the first phase, several pre-trained word embeddings are employed to
train several tagging models. This allows us to evaluate the performance of the
word embeddings in the POS tagging task. The top-performing model from the
first phase is employed to annotate another set of new sentences. In the second
phase, the model is trained further using the fresh dataset. Finally, we attain
a tagging accuracy of 86.52% in F1 score. The model may serve as a baseline for
further study on DL-based Assamese POS tagging."
Neural Architecture Search for Dense Prediction Tasks in Computer Vision,0.0369878,"The success of deep learning in recent years has lead to a rising demand for
neural network architecture engineering. As a consequence, neural architecture
search (NAS), which aims at automatically designing neural network
architectures in a data-driven manner rather than manually, has evolved as a
popular field of research. With the advent of weight sharing strategies across
architectures, NAS has become applicable to a much wider range of problems. In
particular, there are now many publications for dense prediction tasks in
computer vision that require pixel-level predictions, such as semantic
segmentation or object detection. These tasks come with novel challenges, such
as higher memory footprints due to high-resolution data, learning multi-scale
representations, longer training times, and more complex and larger neural
architectures. In this manuscript, we provide an overview of NAS for dense
prediction tasks by elaborating on these novel challenges and surveying ways to
address them to ease future research and application of existing methods to
novel problems."
Learning to Break the Loop: Analyzing and Mitigating Repetitions for Neural Text Generation,0.381437,"While large-scale neural language models, such as GPT2 and BART, have
achieved impressive results on various text generation tasks, they tend to get
stuck in undesirable sentence-level loops with maximization-based decoding
algorithms (\textit{e.g.}, greedy search). This phenomenon is counter-intuitive
since there are few consecutive sentence-level repetitions in human corpora
(e.g., 0.02\% in Wikitext-103). To investigate the underlying reasons for
generating consecutive sentence-level repetitions, we study the relationship
between the probabilities of the repetitive tokens and their previous
repetitions in the context. Through our quantitative experiments, we find that
1) Language models have a preference to repeat the previous sentence; 2) The
sentence-level repetitions have a \textit{self-reinforcement effect}: the more
times a sentence is repeated in the context, the higher the probability of
continuing to generate that sentence; 3) The sentences with higher initial
probabilities usually have a stronger self-reinforcement effect. Motivated by
our findings, we propose a simple and effective training method \textbf{DITTO}
(Pseu\underline{D}o-Repet\underline{IT}ion
Penaliza\underline{T}i\underline{O}n), where the model learns to penalize
probabilities of sentence-level repetitions from pseudo repetitive data.
Although our method is motivated by mitigating repetitions, experiments show
that DITTO not only mitigates the repetition issue without sacrificing
perplexity, but also achieves better generation quality. Extensive experiments
on open-ended text generation (Wikitext-103) and text summarization
(CNN/DailyMail) demonstrate the generality and effectiveness of our method."
Lagrangian Manifold Monte Carlo on Monge Patches,0.349657,"The efficiency of Markov Chain Monte Carlo (MCMC) depends on how the
underlying geometry of the problem is taken into account. For distributions
with strongly varying curvature, Riemannian metrics help in efficient
exploration of the target distribution. Unfortunately, they have significant
computational overhead due to e.g. repeated inversion of the metric tensor, and
current geometric MCMC methods using the Fisher information matrix to induce
the manifold are in practice slow. We propose a new alternative Riemannian
metric for MCMC, by embedding the target distribution into a higher-dimensional
Euclidean space as a Monge patch and using the induced metric determined by
direct geometric reasoning. Our metric only requires first-order gradient
information and has fast inverse and determinants, and allows reducing the
computational complexity of individual iterations from cubic to quadratic in
the problem dimensionality. We demonstrate how Lagrangian Monte Carlo in this
metric efficiently explores the target distributions."
Asking for Knowledge: Training RL Agents to Query External Knowledge Using Language,0.165064,"To solve difficult tasks, humans ask questions to acquire knowledge from
external sources. In contrast, classical reinforcement learning agents lack
such an ability and often resort to exploratory behavior. This is exacerbated
as few present-day environments support querying for knowledge. In order to
study how agents can be taught to query external knowledge via language, we
first introduce two new environments: the grid-world-based Q-BabyAI and the
text-based Q-TextWorld. In addition to physical interactions, an agent can
query an external knowledge source specialized for these environments to gather
information. Second, we propose the ""Asking for Knowledge"" (AFK) agent, which
learns to generate language commands to query for meaningful knowledge that
helps solve the tasks. AFK leverages a non-parametric memory, a pointer
mechanism and an episodic exploration bonus to tackle (1) irrelevant
information, (2) a large query language space, (3) delayed reward for making
meaningful queries. Extensive experiments demonstrate that the AFK agent
outperforms recent baselines on the challenging Q-BabyAI and Q-TextWorld
environments."
Evaluating Long-Term Memory in 3D Mazes,0.346024,"Intelligent agents need to remember salient information to reason in
partially-observed environments. For example, agents with a first-person view
should remember the positions of relevant objects even if they go out of view.
Similarly, to effectively navigate through rooms agents need to remember the
floor plan of how rooms are connected. However, most benchmark tasks in
reinforcement learning do not test long-term memory in agents, slowing down
progress in this important research direction. In this paper, we introduce the
Memory Maze, a 3D domain of randomized mazes specifically designed for
evaluating long-term memory in agents. Unlike existing benchmarks, Memory Maze
measures long-term memory separate from confounding agent abilities and
requires the agent to localize itself by integrating information over time.
With Memory Maze, we propose an online reinforcement learning benchmark, a
diverse offline dataset, and an offline probing evaluation. Recording a human
player establishes a strong baseline and verifies the need to build up and
retain memories, which is reflected in their gradually increasing rewards
within each episode. We find that current algorithms benefit from training with
truncated backpropagation through time and succeed on small mazes, but fall
short of human performance on the large mazes, leaving room for future
algorithmic designs to be evaluated on the Memory Maze."
Zero-Shot Text Classification with Self-Training,0.0704144,"Recent advances in large pretrained language models have increased attention
to zero-shot text classification. In particular, models finetuned on natural
language inference datasets have been widely adopted as zero-shot classifiers
due to their promising results and off-the-shelf availability. However, the
fact that such models are unfamiliar with the target task can lead to
instability and performance issues. We propose a plug-and-play method to bridge
this gap using a simple self-training approach, requiring only the class names
along with an unlabeled dataset, and without the need for domain expertise or
trial and error. We show that fine-tuning the zero-shot classifier on its most
confident predictions leads to significant performance gains across a wide
range of text classification tasks, presumably since self-training adapts the
zero-shot model to the task at hand."
SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control,0.439925,"Despite the growing success of diffusion models in continuous-valued domains
(e.g., images), similar efforts for discrete domains such as text have yet to
match the performance of autoregressive language models. In this work, we
present SSD-LM -- a diffusion-based language model with two key design choices.
First, SSD-LM is semi-autoregressive, iteratively generating blocks of text,
allowing for flexible output length at decoding time while enabling local
bidirectional context updates. Second, it is simplex-based, performing
diffusion on the natural vocabulary space rather than a learned latent space,
allowing us to incorporate classifier guidance and modular control using
off-the-shelf classifiers without any adaptation. We evaluate SSD-LM on
unconstrained text generation benchmarks, and show that it matches or
outperforms strong autoregressive GPT-2 models across standard quality and
diversity metrics, while vastly outperforming diffusion-based baselines. On
controlled text generation, SSD-LM also outperforms competitive baselines, with
an extra advantage in modularity."
Enhanced Physics-Informed Neural Networks with Augmented Lagrangian Relaxation Method (AL-PINNs),0.20289,"Physics-Informed Neural Networks (PINNs) have become a prominent application
of deep learning in scientific computation, as they are powerful approximators
of solutions to nonlinear partial differential equations (PDEs). There have
been numerous attempts to facilitate the training process of PINNs by adjusting
the weight of each component of the loss function, called adaptive
loss-balancing algorithms. In this paper, we propose an Augmented Lagrangian
relaxation method for PINNs (AL-PINNs). We treat the initial and boundary
conditions as constraints for the optimization problem of the PDE residual. By
employing Augmented Lagrangian relaxation, the constrained optimization problem
becomes a sequential max-min problem so that the learnable parameters $\lambda$
adaptively balance each loss component. Our theoretical analysis reveals that
the sequence of minimizers of the proposed loss functions converges to an
actual solution for the Helmholtz, viscous Burgers, and Klein--Gordon
equations. We demonstrate through various numerical experiments that AL-PINNs
yield a much smaller relative error compared with that of state-of-the-art
adaptive loss-balancing algorithms."
ActMAD: Activation Matching to Align Distributions for Test-Time-Training,-1.0,"Test-Time-Training (TTT) is an approach to cope with out-of-distribution
(OOD) data by adapting a trained model to distribution shifts occurring at
test-time. We propose to perform this adaptation via Activation Matching
(ActMAD): We analyze activations of the model and align activation statistics
of the OOD test data to those of the training data. In contrast to existing
methods, which model the distribution of entire channels in the ultimate layer
of the feature extractor, we model the distribution of each feature in multiple
layers across the network. This results in a more fine-grained supervision and
makes ActMAD attain state of the art performance on CIFAR-100C and Imagenet-C.
ActMAD is also architecture- and task-agnostic, which lets us go beyond image
classification, and score 15.4% improvement over previous approaches when
evaluating a KITTI-trained object detector on KITTI-Fog. Our experiments
highlight that ActMAD can be applied to online adaptation in realistic
scenarios, requiring little data to attain its full performance."
Gradient-Based Constrained Sampling from Language Models,0.213554,"Large pretrained language models generate fluent text but are notoriously
hard to controllably sample from. In this work, we study constrained sampling
from such language models: generating text that satisfies user-defined
constraints, while maintaining fluency and the model's performance in a
downstream task. We propose MuCoLa -- a sampling procedure that combines the
log-likelihood of the language model with arbitrary (differentiable)
constraints in a single energy function, and then generates samples in a
non-autoregressive manner. Specifically, it initializes the entire output
sequence with noise and follows a Markov chain defined by Langevin Dynamics
using the gradients of the energy function. We evaluate MuCoLa on text
generation with soft and hard constraints as well as their combinations
obtaining significant improvements over competitive baselines for toxicity
avoidance, sentiment control, and keyword-guided generation."
Hollywood Identity Bias Dataset: A Context Oriented Bias Analysis of Movie Dialogues,0.0330328,"Movies reflect society and also hold power to transform opinions. Social
biases and stereotypes present in movies can cause extensive damage due to
their reach. These biases are not always found to be the need of storyline but
can creep in as the author's bias. Movie production houses would prefer to
ascertain that the bias present in a script is the story's demand. Today, when
deep learning models can give human-level accuracy in multiple tasks, having an
AI solution to identify the biases present in the script at the writing stage
can help them avoid the inconvenience of stalled release, lawsuits, etc. Since
AI solutions are data intensive and there exists no domain specific data to
address the problem of biases in scripts, we introduce a new dataset of movie
scripts that are annotated for identity bias. The dataset contains dialogue
turns annotated for (i) bias labels for seven categories, viz., gender,
race/ethnicity, religion, age, occupation, LGBTQ, and other, which contains
biases like body shaming, personality bias, etc. (ii) labels for sensitivity,
stereotype, sentiment, emotion, emotion intensity, (iii) all labels annotated
with context awareness, (iv) target groups and reason for bias labels and (v)
expert-driven group-validation process for high quality annotations. We also
report various baseline performances for bias identification and category
detection on our dataset."
Continual Spatio-Temporal Graph Convolutional Networks,0.070485,"Graph-based reasoning over skeleton data has emerged as a promising approach
for human action recognition. However, the application of prior graph-based
methods, which predominantly employ whole temporal sequences as their input, to
the setting of online inference entails considerable computational redundancy.
In this paper, we tackle this issue by reformulating the Spatio-Temporal Graph
Convolutional Neural Network as a Continual Inference Network, which can
perform step-by-step predictions in time without repeat frame processing. To
evaluate our method, we create a continual version of ST-GCN, CoST-GCN,
alongside two derived methods with different self-attention mechanisms, CoAGCN
and CoS-TR. We investigate weight transfer strategies and architectural
modifications for inference acceleration, and perform experiments on the NTU
RGB+D 60, NTU RGB+D 120, and Kinetics Skeleton 400 datasets. Retaining similar
predictive accuracy, we observe up to 109x reduction in time complexity,
on-hardware accelerations of 26x, and reductions in maximum allocated memory of
52% during online inference."
Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks,0.232683,"In the pursuit of explaining implicit regularization in deep learning,
prominent focus was given to matrix and tensor factorizations, which correspond
to simplified neural networks. It was shown that these models exhibit an
implicit tendency towards low matrix and tensor ranks, respectively. Drawing
closer to practical deep learning, the current paper theoretically analyzes the
implicit regularization in hierarchical tensor factorization, a model
equivalent to certain deep convolutional neural networks. Through a dynamical
systems lens, we overcome challenges associated with hierarchy, and establish
implicit regularization towards low hierarchical tensor rank. This translates
to an implicit regularization towards locality for the associated convolutional
networks. Inspired by our theory, we design explicit regularization
discouraging locality, and demonstrate its ability to improve the performance
of modern convolutional networks on non-local tasks, in defiance of
conventional wisdom by which architectural changes are needed. Our work
highlights the potential of enhancing neural networks via theoretical analysis
of their implicit regularization."
Word Order Matters when you Increase Masking,0.0363693,"Word order, an essential property of natural languages, is injected in
Transformer-based neural language models using position encoding. However,
recent experiments have shown that explicit position encoding is not always
useful, since some models without such feature managed to achieve state-of-the
art performance on some tasks. To understand better this phenomenon, we examine
the effect of removing position encodings on the pre-training objective itself
(i.e., masked language modelling), to test whether models can reconstruct
position information from co-occurrences alone. We do so by controlling the
amount of masked tokens in the input sentence, as a proxy to affect the
importance of position information for the task. We find that the necessity of
position information increases with the amount of masking, and that masked
language models without position encodings are not able to reconstruct this
information on the task. These findings point towards a direct relationship
between the amount of masking and the ability of Transformers to capture
order-sensitive aspects of language using position encoding."
SLiDE: Self-supervised LiDAR De-snowing through Reconstruction Difficulty,0.295948,"LiDAR is widely used to capture accurate 3D outdoor scene structures.
However, LiDAR produces many undesirable noise points in snowy weather, which
hamper analyzing meaningful 3D scene structures. Semantic segmentation with
snow labels would be a straightforward solution for removing them, but it
requires laborious point-wise annotation. To address this problem, we propose a
novel self-supervised learning framework for snow points removal in LiDAR point
clouds. Our method exploits the structural characteristic of the noise points:
low spatial correlation with their neighbors. Our method consists of two deep
neural networks: Point Reconstruction Network (PR-Net) reconstructs each point
from its neighbors; Reconstruction Difficulty Network (RD-Net) predicts
point-wise difficulty of the reconstruction by PR-Net, which we call
reconstruction difficulty. With simple post-processing, our method effectively
detects snow points without any label. Our method achieves the state-of-the-art
performance among label-free approaches and is comparable to the
fully-supervised method. Moreover, we demonstrate that our method can be
exploited as a pretext task to improve label-efficiency of supervised training
of de-snowing."
Segmentation Enhanced Lameness Detection in Dairy Cows from RGB and Depth Video,0.270865,"Cow lameness is a severe condition that affects the life cycle and life
quality of dairy cows and results in considerable economic losses. Early
lameness detection helps farmers address illnesses early and avoid negative
effects caused by the degeneration of cows' condition. We collected a dataset
of short clips of cows passing through a hallway exiting a milking station and
annotated the degree of lameness of the cows. This paper explores the resulting
dataset and provides a detailed description of the data collection process.
Additionally, we proposed a lameness detection method that leverages
pre-trained neural networks to extract discriminative features from videos and
assign a binary score to each cow indicating its condition: ""healthy"" or
""lame."" We improve this approach by forcing the model to focus on the structure
of the cow, which we achieve by substituting the RGB videos with binary
segmentation masks predicted with a trained segmentation model. This work aims
to encourage research and provide insights into the applicability of computer
vision models for cow lameness detection on farms."
Frequency-Aware Self-Supervised Monocular Depth Estimation,0.04854,"We present two versatile methods to generally enhance self-supervised
monocular depth estimation (MDE) models. The high generalizability of our
methods is achieved by solving the fundamental and ubiquitous problems in
photometric loss function. In particular, from the perspective of spatial
frequency, we first propose Ambiguity-Masking to suppress the incorrect
supervision under photometric loss at specific object boundaries, the cause of
which could be traced to pixel-level ambiguity. Second, we present a novel
frequency-adaptive Gaussian low-pass filter, designed to robustify the
photometric loss in high-frequency regions. We are the first to propose
blurring images to improve depth estimators with an interpretable analysis.
Both modules are lightweight, adding no parameters and no need to manually
change the network structures. Experiments show that our methods provide
performance boosts to a large number of existing models, including those who
claimed state-of-the-art, while introducing no extra inference computation at
all."
MMGL: Multi-Scale Multi-View Global-Local Contrastive learning for Semi-supervised Cardiac Image Segmentation,0.153213,"With large-scale well-labeled datasets, deep learning has shown significant
success in medical image segmentation. However, it is challenging to acquire
abundant annotations in clinical practice due to extensive expertise
requirements and costly labeling efforts. Recently, contrastive learning has
shown a strong capacity for visual representation learning on unlabeled data,
achieving impressive performance rivaling supervised learning in many domains.
In this work, we propose a novel multi-scale multi-view global-local
contrastive learning (MMGL) framework to thoroughly explore global and local
features from different scales and views for robust contrastive learning
performance, thereby improving segmentation performance with limited
annotations. Extensive experiments on the MM-WHS dataset demonstrate the
effectiveness of MMGL framework on semi-supervised cardiac image segmentation,
outperforming the state-of-the-art contrastive learning methods by a large
margin."
Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes,0.265738,"We study offline reinforcement learning (RL) in partially observable Markov
decision processes. In particular, we aim to learn an optimal policy from a
dataset collected by a behavior policy which possibly depends on the latent
state. Such a dataset is confounded in the sense that the latent state
simultaneously affects the action and the observation, which is prohibitive for
existing offline RL algorithms. To this end, we propose the \underline{P}roxy
variable \underline{P}essimistic \underline{P}olicy \underline{O}ptimization
(\texttt{P3O}) algorithm, which addresses the confounding bias and the
distributional shift between the optimal and behavior policies in the context
of general function approximation. At the core of \texttt{P3O} is a coupled
sequence of pessimistic confidence regions constructed via proximal causal
inference, which is formulated as minimax estimation. Under a partial coverage
assumption on the confounded dataset, we prove that \texttt{P3O} achieves a
$n^{-1/2}$-suboptimality, where $n$ is the number of trajectories in the
dataset. To our best knowledge, \texttt{P3O} is the first provably efficient
offline RL algorithm for POMDPs with a confounded dataset."
Graph-Based Multilingual Label Propagation for Low-Resource Part-of-Speech Tagging,0.0407773,"Part-of-Speech (POS) tagging is an important component of the NLP pipeline,
but many low-resource languages lack labeled data for training. An established
method for training a POS tagger in such a scenario is to create a labeled
training set by transferring from high-resource languages. In this paper, we
propose a novel method for transferring labels from multiple high-resource
source to low-resource target languages. We formalize POS tag projection as
graph-based label propagation. Given translations of a sentence in multiple
languages, we create a graph with words as nodes and alignment links as edges
by aligning words for all language pairs. We then propagate node labels from
source to target using a Graph Neural Network augmented with transformer
layers. We show that our propagation creates training sets that allow us to
train POS taggers for a diverse set of languages. When combined with enhanced
contextualized embeddings, our method achieves a new state-of-the-art for
unsupervised POS tagging of low-resource languages."
Using Multi-Encoder Fusion Strategies to Improve Personalized Response Selection,0.0521568,"Personalized response selection systems are generally grounded on persona.
However, there exists a co-relation between persona and empathy, which is not
explored well in these systems. Also, faithfulness to the conversation context
plunges when a contradictory or an off-topic response is selected. This paper
attempts to address these issues by proposing a suite of fusion strategies that
capture the interaction between persona, emotion, and entailment information of
the utterances. Ablation studies on the Persona-Chat dataset show that
incorporating emotion and entailment improves the accuracy of response
selection. We combine our fusion strategies and concept-flow encoding to train
a BERT-based model which outperforms the previous methods by margins larger
than 2.3 % on original personas and 1.9 % on revised personas in terms of
hits@1 (top-1 accuracy), achieving a new state-of-the-art performance on the
Persona-Chat dataset."
Attention-Aware Anime Line Drawing Colorization,0.0739663,"Automatic colorization of anime line drawing has attracted much attention in
recent years since it can substantially benefit the animation industry.
User-hint based methods are the mainstream approach for line drawing
colorization, while reference-based methods offer a more intuitive approach.
Nevertheless, although reference-based methods can improve feature aggregation
of the reference image and the line drawing, the colorization results are not
compelling in terms of color consistency or semantic correspondence. In this
paper, we introduce an attention-based model for anime line drawing
colorization, in which a channel-wise and spatial-wise Convolutional Attention
module is used to improve the ability of the encoder for feature extraction and
key area perception, and a Stop-Gradient Attention module with cross-attention
and self-attention is used to tackle the cross-domain long-range dependency
problem. Extensive experiments show that our method outperforms other SOTA
methods, with more accurate line structure and semantic color information."
ET5: A Novel End-to-end Framework for Conversational Machine Reading Comprehension,0.0318155,"Conversational machine reading comprehension (CMRC) aims to assist computers
to understand an natural language text and thereafter engage in a multi-turn
conversation to answer questions related to the text. Existing methods
typically require three steps: (1) decision making based on entailment
reasoning; (2) span extraction if required by the above decision; (3) question
rephrasing based on the extracted span. However, for nearly all these methods,
the span extraction and question rephrasing steps cannot fully exploit the
fine-grained entailment reasoning information in decision making step because
of their relative independence, which will further enlarge the information gap
between decision making and question phrasing. Thus, to tackle this problem, we
propose a novel end-to-end framework for conversational machine reading
comprehension based on shared parameter mechanism, called entailment reasoning
T5 (ET5). Despite the lightweight of our proposed framework, experimental
results show that the proposed ET5 achieves new state-of-the-art results on the
ShARC leaderboard with the BLEU-4 score of 55.2. Our model and code are
publicly available at https://github.com/Yottaxx/ET5."
Zero-Shot Cost Models for Out-of-the-box Learned Cost Prediction,0.155043,"In this paper, we introduce zero-shot cost models which enable learned cost
estimation that generalizes to unseen databases. In contrast to
state-of-the-art workload-driven approaches which require to execute a large
set of training queries on every new database, zero-shot cost models thus allow
to instantiate a learned cost model out-of-the-box without expensive training
data collection. To enable such zero-shot cost models, we suggest a new
learning paradigm based on pre-trained cost models. As core contributions to
support the transfer of such a pre-trained cost model to unseen databases, we
introduce a new model architecture and representation technique for encoding
query workloads as input to those models. As we will show in our evaluation,
zero-shot cost estimation can provide more accurate cost estimates than
state-of-the-art models for a wide range of (real-world) databases without
requiring any query executions on unseen databases. Furthermore, we show that
zero-shot cost models can be used in a few-shot mode that further improves
their quality by retraining them just with a small number of additional
training queries on the unseen database."
Semantic-aligned Fusion Transformer for One-shot Object Detection,0.692228,"One-shot object detection aims at detecting novel objects according to merely
one given instance. With extreme data scarcity, current approaches explore
various feature fusions to obtain directly transferable meta-knowledge. Yet,
their performances are often unsatisfactory. In this paper, we attribute this
to inappropriate correlation methods that misalign query-support semantics by
overlooking spatial structures and scale variances. Upon analysis, we leverage
the attention mechanism and propose a simple but effective architecture named
Semantic-aligned Fusion Transformer (SaFT) to resolve these issues.
Specifically, we equip SaFT with a vertical fusion module (VFM) for cross-scale
semantic enhancement and a horizontal fusion module (HFM) for cross-sample
feature fusion. Together, they broaden the vision for each feature point from
the support to a whole augmented feature pyramid from the query, facilitating
semantic-aligned associations. Extensive experiments on multiple benchmarks
demonstrate the superiority of our framework. Without fine-tuning on novel
classes, it brings significant performance gains to one-stage baselines,
lifting state-of-the-art results to a higher level."
ASR Error Correction with Constrained Decoding on Operation Prediction,0.0335647,"Error correction techniques remain effective to refine outputs from automatic
speech recognition (ASR) models. Existing end-to-end error correction methods
based on an encoder-decoder architecture process all tokens in the decoding
phase, creating undesirable latency. In this paper, we propose an ASR error
correction method utilizing the predictions of correction operations. More
specifically, we construct a predictor between the encoder and the decoder to
learn if a token should be kept (""K""), deleted (""D""), or changed (""C"") to
restrict decoding to only part of the input sequence embeddings (the ""C""
tokens) for fast inference. Experiments on three public datasets demonstrate
the effectiveness of the proposed approach in reducing the latency of the
decoding process in ASR correction. It enhances the inference speed by at least
three times (3.4 and 5.7 times) while maintaining the same level of accuracy
(with WER reductions of 0.53% and 1.69% respectively) for our two proposed
models compared to a solid encoder-decoder baseline. In the meantime, we
produce and release a benchmark dataset contributing to the ASR error
correction community to foster research along this line."
"Streaming, fast and accurate on-device Inverse Text Normalization for Automatic Speech Recognition",0.0327378,"Automatic Speech Recognition (ASR) systems typically yield output in lexical
form. However, humans prefer a written form output. To bridge this gap, ASR
systems usually employ Inverse Text Normalization (ITN).
  In previous works, Weighted Finite State Transducers (WFST) have been
employed to do ITN. WFSTs are nicely suited to this task but their size and
run-time costs can make deployment on embedded applications challenging.
  In this paper, we describe the development of an on-device ITN system that is
streaming, lightweight & accurate. At the core of our system is a streaming
transformer tagger, that tags lexical tokens from ASR. The tag informs which
ITN category might be applied, if at all. Following that, we apply an
ITN-category-specific WFST, only on the tagged text, to reliably perform the
ITN conversion. We show that the proposed ITN solution performs equivalent to
strong baselines, while being significantly smaller in size and retaining
customization capabilities."
Spiking Approximations of the MaxPooling Operation in Deep SNNs,0.0316409,"Spiking Neural Networks (SNNs) are an emerging domain of biologically
inspired neural networks that have shown promise for low-power AI. A number of
methods exist for building deep SNNs, with Artificial Neural Network
(ANN)-to-SNN conversion being highly successful. MaxPooling layers in
Convolutional Neural Networks (CNNs) are an integral component to downsample
the intermediate feature maps and introduce translational invariance, but the
absence of their hardware-friendly spiking equivalents limits such CNNs'
conversion to deep SNNs. In this paper, we present two hardware-friendly
methods to implement Max-Pooling in deep SNNs, thus facilitating easy
conversion of CNNs with MaxPooling layers to SNNs. In a first, we also execute
SNNs with spiking-MaxPooling layers on Intel's Loihi neuromorphic hardware
(with MNIST, FMNIST, & CIFAR10 dataset); thus, showing the feasibility of our
approach."
Multi-label Transformer for Action Unit Detection,0.300782,"Action Unit (AU) Detection is the branch of affective computing that aims at
recognizing unitary facial muscular movements. It is key to unlock unbiased
computational face representations and has therefore aroused great interest in
the past few years. One of the main obstacles toward building efficient deep
learning based AU detection system is the lack of wide facial image databases
annotated by AU experts. In that extent the ABAW challenge paves the way toward
better AU detection as it involves a 2M frames AU annotated dataset. In this
paper, we present our submission to the ABAW3 challenge. In a nutshell, we
applied a multi-label detection transformer that leverage multi-head attention
to learn which part of the face image is the most relevant to predict each AU."
Efficient and Robust 2D-to-BEV Representation Learning via Geometry-guided Kernel Transformer,0.750273,"Learning Bird's Eye View (BEV) representation from surrounding-view cameras
is of great importance for autonomous driving. In this work, we propose a
Geometry-guided Kernel Transformer (GKT), a novel 2D-to-BEV representation
learning mechanism. GKT leverages the geometric priors to guide the transformer
to focus on discriminative regions and unfolds kernel features to generate BEV
representation. For fast inference, we further introduce a look-up table (LUT)
indexing method to get rid of the camera's calibrated parameters at runtime.
GKT can run at $72.3$ FPS on 3090 GPU / $45.6$ FPS on 2080ti GPU and is robust
to the camera deviation and the predefined BEV height. And GKT achieves the
state-of-the-art real-time segmentation results, i.e., 38.0 mIoU
(100m$\times$100m perception range at a 0.5m resolution) on the nuScenes val
set. Given the efficiency, effectiveness, and robustness, GKT has great
practical values in autopilot scenarios, especially for real-time running
systems. Code and models will be available at
\url{https://github.com/hustvl/GKT}."
PanoDepth: A Two-Stage Approach for Monocular Omnidirectional Depth Estimation,0.0835791,"Omnidirectional 3D information is essential for a wide range of applications
such as Virtual Reality, Autonomous Driving, Robotics, etc. In this paper, we
propose a novel, model-agnostic, two-stage pipeline for omnidirectional
monocular depth estimation. Our proposed framework PanoDepth takes one 360
image as input, produces one or more synthesized views in the first stage, and
feeds the original image and the synthesized images into the subsequent stereo
matching stage. In the second stage, we propose a differentiable Spherical
Warping Layer to handle omnidirectional stereo geometry efficiently and
effectively. By utilizing the explicit stereo-based geometric constraints in
the stereo matching stage, PanoDepth can generate dense high-quality depth. We
conducted extensive experiments and ablation studies to evaluate PanoDepth with
both the full pipeline as well as the individual modules in each stage. Our
results show that PanoDepth outperforms the state-of-the-art approaches by a
large margin for 360 monocular depth estimation."
Abstraction for Deep Reinforcement Learning,0.0117083,"We characterise the problem of abstraction in the context of deep
reinforcement learning. Various well established approaches to analogical
reasoning and associative memory might be brought to bear on this issue, but
they present difficulties because of the need for end-to-end differentiability.
We review developments in AI and machine learning that could facilitate their
adoption."
GCDT: A Chinese RST Treebank for Multigenre and Multilingual Discourse Parsing,0.156064,"A lack of large-scale human-annotated data has hampered the hierarchical
discourse parsing of Chinese. In this paper, we present GCDT, the largest
hierarchical discourse treebank for Mandarin Chinese in the framework of
Rhetorical Structure Theory (RST). GCDT covers over 60K tokens across five
genres of freely available text, using the same relation inventory as
contemporary RST treebanks for English. We also report on this dataset's
parsing experiments, including state-of-the-art (SOTA) scores for Chinese RST
parsing and RST parsing on the English GUM dataset, using cross-lingual
training in Chinese and English with multilingual embeddings."
From Indoor To Outdoor: Unsupervised Domain Adaptive Gait Recognition,0.156882,"Gait recognition is an important AI task, which has been progressed rapidly
with the development of deep learning. However, existing learning based gait
recognition methods mainly focus on the single domain, especially the
constrained laboratory environment. In this paper, we study a new problem of
unsupervised domain adaptive gait recognition (UDA-GR), that learns a gait
identifier with supervised labels from the indoor scenes (source domain), and
is applied to the outdoor wild scenes (target domain). For this purpose, we
develop an uncertainty estimation and regularization based UDA-GR method.
Specifically, we investigate the characteristic of gaits in the indoor and
outdoor scenes, for estimating the gait sample uncertainty, which is used in
the unsupervised fine-tuning on the target domain to alleviate the noises of
the pseudo labels. We also establish a new benchmark for the proposed problem,
experimental results on which show the effectiveness of the proposed method. We
will release the benchmark and source code in this work to the public."
Meta Policy Learning for Cold-Start Conversational Recommendation,0.117734,"Conversational recommender systems (CRS) explicitly solicit users'
preferences for improved recommendations on the fly. Most existing CRS
solutions count on a single policy trained by reinforcement learning for a
population of users. However, for users new to the system, such a global policy
becomes ineffective to satisfy them, i.e., the cold-start challenge. In this
paper, we study CRS policy learning for cold-start users via meta-reinforcement
learning. We propose to learn a meta policy and adapt it to new users with only
a few trials of conversational recommendations. To facilitate fast policy
adaptation, we design three synergetic components. Firstly, we design a
meta-exploration policy dedicated to identifying user preferences via a few
exploratory conversations, which accelerates personalized policy adaptation
from the meta policy. Secondly, we adapt the item recommendation module for
each user to maximize the recommendation quality based on the collected
conversation states during conversations. Thirdly, we propose a
Transformer-based state encoder as the backbone to connect the previous two
components. It provides comprehensive state representations by modeling
complicated relations between positive and negative feedback during the
conversation. Extensive experiments on three datasets demonstrate the advantage
of our solution in serving new users, compared with a rich set of
state-of-the-art CRS solutions."
Weakly Supervised 3D Point Cloud Segmentation via Multi-Prototype Learning,0.365344,"Addressing the annotation challenge in 3D Point Cloud segmentation has
inspired research into weakly supervised learning. Existing approaches mainly
focus on exploiting manifold and pseudo-labeling to make use of large unlabeled
data points. A fundamental challenge here lies in the large intra-class
variations of local geometric structure, resulting in subclasses within a
semantic class. In this work, we leverage this intuition and opt for
maintaining an individual classifier for each subclass. Technically, we design
a multi-prototype classifier, each prototype serves as the classifier weights
for one subclass. To enable effective updating of multi-prototype classifier
weights, we propose two constraints respectively for updating the prototypes
w.r.t. all point features and for encouraging the learning of diverse
prototypes. Experiments on weakly supervised 3D point cloud segmentation tasks
validate the efficacy of proposed method in particular at low-label regime. Our
hypothesis is also verified given the consistent discovery of semantic
subclasses at no cost of additional annotations."
Accurate Polygonal Mapping of Buildings in Satellite Imagery,0.212006,"This paper studies the problem of polygonal mapping of buildings by tackling
the issue of mask reversibility that leads to a notable performance gap between
the predicted masks and polygons from the learning-based methods. We addressed
such an issue by exploiting the hierarchical supervision (of bottom-level
vertices, mid-level line segments and the high-level regional masks) and
proposed a novel interaction mechanism of feature embedding sourced from
different levels of supervision signals to obtain reversible building masks for
polygonal mapping of buildings. As a result, we show that the learned
reversible building masks take all the merits of the advances of deep
convolutional neural networks for high-performing polygonal mapping of
buildings. In the experiments, we evaluated our method on the two public
benchmarks of AICrowd and Inria. On the AICrowd dataset, our proposed method
obtains unanimous improvements on the metrics of AP, APboundary and PoLiS. For
the Inria dataset, our proposed method also obtains very competitive results on
the metrics of IoU and Accuracy. The models and source code are available at
https://github.com/SarahwXU."
Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs,0.41179,"Question answering over temporal knowledge graphs (KGs) efficiently uses
facts contained in a temporal KG, which records entity relations and when they
occur in time, to answer natural language questions (e.g., ""Who was the
president of the US before Obama?""). These questions often involve three
time-related challenges that previous work fail to adequately address: 1)
questions often do not specify exact timestamps of interest (e.g., ""Obama""
instead of 2000); 2) subtle lexical differences in time relations (e.g.,
""before"" vs ""after""); 3) off-the-shelf temporal KG embeddings that previous
work builds on ignore the temporal order of timestamps, which is crucial for
answering temporal-order related questions. In this paper, we propose a
time-sensitive question answering (TSQA) framework to tackle these problems.
TSQA features a timestamp estimation module to infer the unwritten timestamp
from the question. We also employ a time-sensitive KG encoder to inject
ordering information into the temporal KG embeddings that TSQA is based on.
With the help of techniques to reduce the search space for potential answers,
TSQA significantly outperforms the previous state of the art on a new benchmark
for question answering over temporal KGs, especially achieving a 32% (absolute)
error reduction on complex questions that require multiple steps of reasoning
over facts in the temporal KG."
SCVRL: Shuffled Contrastive Video Representation Learning,0.0967325,"We propose SCVRL, a novel contrastive-based framework for self-supervised
learning for videos. Differently from previous contrast learning based methods
that mostly focus on learning visual semantics (e.g., CVRL), SCVRL is capable
of learning both semantic and motion patterns. For that, we reformulate the
popular shuffling pretext task within a modern contrastive learning paradigm.
We show that our transformer-based network has a natural capacity to learn
motion in self-supervised settings and achieves strong performance,
outperforming CVRL on four benchmarks."
Cross-view and Cross-domain Underwater Localization based on Optical Aerial and Acoustic Underwater Images,0.197529,"Cross-view image matches have been widely explored on terrestrial image
localization using aerial images from drones or satellites. This study expands
the cross-view image match idea and proposes a cross-domain and cross-view
localization framework. The method identifies the correlation between color
aerial images and underwater acoustic images to improve the localization of
underwater vehicles that travel in partially structured environments such as
harbors and marinas. The approach is validated on a real dataset acquired by an
underwater vehicle in a marina. The results show an improvement in the
localization when compared to the dead reckoning of the vehicle."
FaceDancer: Pose- and Occlusion-Aware High Fidelity Face Swapping,0.148432,"In this work, we present a new single-stage method for subject agnostic face
swapping and identity transfer, named FaceDancer. We have two major
contributions: Adaptive Feature Fusion Attention (AFFA) and Interpreted Feature
Similarity Regularization (IFSR). The AFFA module is embedded in the decoder
and adaptively learns to fuse attribute features and features conditioned on
identity information without requiring any additional facial segmentation
process. In IFSR, we leverage the intermediate features in an identity encoder
to preserve important attributes such as head pose, facial expression,
lighting, and occlusion in the target face, while still transferring the
identity of the source face with high fidelity. We conduct extensive
quantitative and qualitative experiments on various datasets and show that the
proposed FaceDancer outperforms other state-of-the-art networks in terms of
identityn transfer, while having significantly better pose preservation than
most of the previous methods."
OPD: Single-view 3D Openable Part Detection,0.386091,"We address the task of predicting what parts of an object can open and how
they move when they do so. The input is a single image of an object, and as
output we detect what parts of the object can open, and the motion parameters
describing the articulation of each openable part. To tackle this task, we
create two datasets of 3D objects: OPDSynth based on existing synthetic
objects, and OPDReal based on RGBD reconstructions of real objects. We then
design OPDRCNN, a neural architecture that detects openable parts and predicts
their motion parameters. Our experiments show that this is a challenging task
especially when considering generalization across object categories, and the
limited amount of information in a single image. Our architecture outperforms
baselines and prior work especially for RGB image inputs. Short video summary
at https://www.youtube.com/watch?v=P85iCaD0rfc"
Rediscovering Argumentation Principles Utilizing Collective Attacks,0.0722339,"Argumentation Frameworks (AFs) are a key formalism in AI research. Their
semantics have been investigated in terms of principles, which define
characteristic properties in order to deliver guidance for analysing
established and developing new semantics. Because of the simple structure of
AFs, many desired properties hold almost trivially, at the same time hiding
interesting concepts behind syntactic notions. We extend the principle-based
approach to Argumentation Frameworks with Collective Attacks (SETAFs) and
provide a comprehensive overview of common principles for their semantics. Our
analysis shows that investigating principles based on decomposing the given
SETAF (e.g. directionality or SCC-recursiveness) poses additional challenges in
comparison to usual AFs. We introduce the notion of the reduct as well as the
modularization principle for SETAFs which will prove beneficial for this kind
of investigation. We then demonstrate how our findings can be utilized for
incremental computation of extensions and give a novel parameterized
tractability result for verifying preferred extensions."
Who's the Expert? On Multi-source Belief Change,0.0432163,"Consider the following belief change/merging scenario. A group of information
sources gives a sequence of reports about the state of the world at various
instances (e.g. different points in time). The true states at these instances
are unknown to us. The sources have varying levels of expertise, also unknown
to us, and may be knowledgeable on some topics but not others. This may cause
sources to report false statements in areas they lack expertise. What should we
believe on the basis of these reports? We provide a framework in which to
explore this problem, based on an extension of propositional logic with
expertise formulas. This extended language allows us to express beliefs about
the state of the world at each instance, as well as beliefs about the expertise
of each source. We propose several postulates, provide a couple of families of
concrete operators, and analyse these operators with respect to the postulates."
Multilingual Pre-training with Language and Task Adaptation for Multilingual Text Style Transfer,0.208626,"We exploit the pre-trained seq2seq model mBART for multilingual text style
transfer. Using machine translated data as well as gold aligned English
sentences yields state-of-the-art results in the three target languages we
consider. Besides, in view of the general scarcity of parallel data, we propose
a modular approach for multilingual formality transfer, which consists of two
training strategies that target adaptation to both language and task. Our
approach achieves competitive performance without monolingual task-specific
parallel data and can be applied to other style transfer tasks as well as to
other languages."
Frame-wise Action Representations for Long Videos via Sequence Contrastive Learning,0.477596,"Prior works on action representation learning mainly focus on designing
various architectures to extract the global representations for short video
clips. In contrast, many practical applications such as video alignment have
strong demand for learning dense representations for long videos. In this
paper, we introduce a novel contrastive action representation learning (CARL)
framework to learn frame-wise action representations, especially for long
videos, in a self-supervised manner. Concretely, we introduce a simple yet
efficient video encoder that considers spatio-temporal context to extract
frame-wise representations. Inspired by the recent progress of self-supervised
learning, we present a novel sequence contrastive loss (SCL) applied on two
correlated views obtained through a series of spatio-temporal data
augmentations. SCL optimizes the embedding space by minimizing the
KL-divergence between the sequence similarity of two augmented views and a
prior Gaussian distribution of timestamp distance. Experiments on FineGym,
PennAction and Pouring datasets show that our method outperforms previous
state-of-the-art by a large margin for downstream fine-grained action
classification. Surprisingly, although without training on paired videos, our
approach also shows outstanding performance on video alignment and fine-grained
frame retrieval tasks. Code and models are available at
https://github.com/minghchen/CARL_code."
Efficient Training of Neural Transducer for Speech Recognition,0.0331364,"As one of the most popular sequence-to-sequence modeling approaches for
speech recognition, the RNN-Transducer has achieved evolving performance with
more and more sophisticated neural network models of growing size and
increasing training epochs. While strong computation resources seem to be the
prerequisite of training superior models, we try to overcome it by carefully
designing a more efficient training pipeline. In this work, we propose an
efficient 3-stage progressive training pipeline to build highly-performing
neural transducer models from scratch with very limited computation resources
in a reasonable short time period. The effectiveness of each stage is
experimentally verified on both Librispeech and Switchboard corpora. The
proposed pipeline is able to train transducer models approaching
state-of-the-art performance with a single GPU in just 2-3 weeks. Our best
conformer transducer achieves 4.1% WER on Librispeech test-other with only 35
epochs of training."
Transformer-Based Named Entity Recognition for French Using Adversarial Adaptation to Similar Domain Corpora,0.0420105,"Named Entity Recognition (NER) involves the identification and classification
of named entities in unstructured text into predefined classes. NER in
languages with limited resources, like French, is still an open problem due to
the lack of large, robust, labelled datasets. In this paper, we propose a
transformer-based NER approach for French using adversarial adaptation to
similar domain or general corpora for improved feature extraction and better
generalization. We evaluate our approach on three labelled datasets and show
that our adaptation framework outperforms the corresponding non-adaptive models
for various combinations of transformer models, source datasets and target
corpora."
"Investigating Selective Prediction Approaches Across Several Tasks in IID, OOD, and Adversarial Settings",0.313047,"In order to equip NLP systems with selective prediction capability, several
task-specific approaches have been proposed. However, which approaches work
best across tasks or even if they consistently outperform the simplest baseline
'MaxProb' remains to be explored. To this end, we systematically study
'selective prediction' in a large-scale setup of 17 datasets across several NLP
tasks. Through comprehensive experiments under in-domain (IID), out-of-domain
(OOD), and adversarial (ADV) settings, we show that despite leveraging
additional resources (held-out data/computation), none of the existing
approaches consistently and considerably outperforms MaxProb in all three
settings. Furthermore, their performance does not translate well across tasks.
For instance, Monte-Carlo Dropout outperforms all other approaches on Duplicate
Detection datasets but does not fare well on NLI datasets, especially in the
OOD setting. Thus, we recommend that future selective prediction approaches
should be evaluated across tasks and settings for reliable estimation of their
capabilities."
Sample Constrained Treatment Effect Estimation,0.113525,"Treatment effect estimation is a fundamental problem in causal inference. We
focus on designing efficient randomized controlled trials, to accurately
estimate the effect of some treatment on a population of $n$ individuals. In
particular, we study sample-constrained treatment effect estimation, where we
must select a subset of $s \ll n$ individuals from the population to experiment
on. This subset must be further partitioned into treatment and control groups.
Algorithms for partitioning the entire population into treatment and control
groups, or for choosing a single representative subset, have been well-studied.
The key challenge in our setting is jointly choosing a representative subset
and a partition for that set.
  We focus on both individual and average treatment effect estimation, under a
linear effects model. We give provably efficient experimental designs and
corresponding estimators, by identifying connections to discrepancy
minimization and leverage-score-based sampling used in randomized numerical
linear algebra. Our theoretical results obtain a smooth transition to known
guarantees when $s$ equals the population size. We also empirically demonstrate
the performance of our algorithms."
SimReg: Regression as a Simple Yet Effective Tool for Self-supervised Knowledge Distillation,0.122721,"Feature regression is a simple way to distill large neural network models to
smaller ones. We show that with simple changes to the network architecture,
regression can outperform more complex state-of-the-art approaches for
knowledge distillation from self-supervised models. Surprisingly, the addition
of a multi-layer perceptron head to the CNN backbone is beneficial even if used
only during distillation and discarded in the downstream task. Deeper
non-linear projections can thus be used to accurately mimic the teacher without
changing inference architecture and time. Moreover, we utilize independent
projection heads to simultaneously distill multiple teacher networks. We also
find that using the same weakly augmented image as input for both teacher and
student networks aids distillation. Experiments on ImageNet dataset demonstrate
the efficacy of the proposed changes in various self-supervised distillation
settings."
Speciesist bias in AI -- How AI applications perpetuate discrimination and unfair outcomes against animals,0.0240382,"Massive efforts are made to reduce biases in both data and algorithms in
order to render AI applications fair. These efforts are propelled by various
high-profile cases where biased algorithmic decision-making caused harm to
women, people of color, minorities, etc. However, the AI fairness field still
succumbs to a blind spot, namely its insensitivity to discrimination against
animals. This paper is the first to describe the 'speciesist bias' and
investigate it in several different AI systems. Speciesist biases are learned
and solidified by AI applications when they are trained on datasets in which
speciesist patterns prevail. These patterns can be found in image recognition
systems, large language models, and recommender systems. Therefore, AI
technologies currently play a significant role in perpetuating and normalizing
violence against animals. This can only be changed when AI fairness frameworks
widen their scope and include mitigation measures for speciesist biases. This
paper addresses the AI community in this regard and stresses the influence AI
systems can have on either increasing or reducing the violence that is
inflicted on animals, and especially on farmed animals."
PedRecNet: Multi-task deep neural network for full 3D human pose and orientation estimation,-1.0,"We present a multitask network that supports various deep neural network
based pedestrian detection functions. Besides 2D and 3D human pose, it also
supports body and head orientation estimation based on full body bounding box
input. This eliminates the need for explicit face recognition. We show that the
performance of 3D human pose estimation and orientation estimation is
comparable to the state-of-the-art. Since very few data sets exist for 3D human
pose and in particular body and head orientation estimation based on full body
data, we further show the benefit of particular simulation data to train the
network. The network architecture is relatively simple, yet powerful, and
easily adaptable for further research and applications."
Investigation of Ensemble features of Self-Supervised Pretrained Models for Automatic Speech Recognition,0.0350972,"Self-supervised learning (SSL) based models have been shown to generate
powerful representations that can be used to improve the performance of
downstream speech tasks. Several state-of-the-art SSL models are available, and
each of these models optimizes a different loss which gives rise to the
possibility of their features being complementary. This paper proposes using an
ensemble of such SSL representations and models, which exploits the
complementary nature of the features extracted by the various pretrained
models. We hypothesize that this results in a richer feature representation and
shows results for the ASR downstream task. To this end, we use three SSL models
that have shown excellent results on ASR tasks, namely HuBERT, Wav2vec2.0, and
WaveLM. We explore the ensemble of models fine-tuned for the ASR task and the
ensemble of features using the embeddings obtained from the pre-trained models
for a downstream ASR task. We get improved performance over individual models
and pre-trained features using Librispeech(100h) and WSJ dataset for the
downstream tasks."
Coordinating CAV Swarms at Intersections with a Deep Learning Model,0.256302,"Connected and automated vehicles (CAVs) are viewed as a special kind of
robots that have the potential to significantly improve the safety and
efficiency of traffic. In contrast to many swarm robotics studies that are
demonstrated in labs by employing a small number of robots, CAV studies aims to
achieve cooperative driving of unceasing robot swarm flows. However, how to get
the optimal passing order of such robot swarm flows even for a signal-free
intersection is an NP-hard problem (specifically, enumerating based algorithm
takes days to find the optimal solution to a 20-CAV scenario). Here, we
introduce a novel cooperative driving algorithm (AlphaOrder) that combines
offline deep learning and online tree searching to find a near-optimal passing
order in real-time. AlphaOrder builds a pointer network model from solved
scenarios and generates near-optimal passing orders instantaneously for new
scenarios. Furthermore, our approach provides a general approach to managing
preemptive resource sharing between swarm robotics (e.g., scheduling multiple
automated guided vehicles (AGVs) and unmanned aerial vehicles (UAVs) at
conflicting areas"
Model-based Multi-agent Reinforcement Learning: Recent Progress and Prospects,0.209551,"Significant advances have recently been achieved in Multi-Agent Reinforcement
Learning (MARL) which tackles sequential decision-making problems involving
multiple participants. However, MARL requires a tremendous number of samples
for effective training. On the other hand, model-based methods have been shown
to achieve provable advantages of sample efficiency. However, the attempts of
model-based methods to MARL have just started very recently. This paper
presents a review of the existing research on model-based MARL, including
theoretical analyses, algorithms, and applications, and analyzes the advantages
and potential of model-based MARL. Specifically, we provide a detailed taxonomy
of the algorithms and point out the pros and cons for each algorithm according
to the challenges inherent to multi-agent scenarios. We also outline promising
directions for future development of this field."
Large Language Models with Controllable Working Memory,0.274222,"Large language models (LLMs) have led to a series of breakthroughs in natural
language processing (NLP), owing to their excellent understanding and
generation abilities. Remarkably, what further sets these models apart is the
massive amounts of world knowledge they internalize during pretraining. While
many downstream applications provide the model with an informational context to
aid its performance on the underlying task, how the model's world knowledge
interacts with the factual information presented in the context remains under
explored. As a desirable behavior, an LLM should give precedence to the context
whenever it contains task-relevant information that conflicts with the model's
memorized knowledge. This enables model predictions to be grounded in the
context, which can then be used to update or correct specific model predictions
without frequent retraining. By contrast, when the context is irrelevant to the
task, the model should ignore it and fall back on its internal knowledge. In
this paper, we undertake a first joint study of the aforementioned two
properties, namely controllability and robustness, in the context of LLMs. We
demonstrate that state-of-the-art T5 and PaLM (both pretrained and finetuned)
could exhibit poor controllability and robustness, which do not scale with
increasing model size. As a solution, we propose a novel method - Knowledge
Aware FineTuning (KAFT) - to strengthen both controllability and robustness by
incorporating counterfactual and irrelevant contexts to standard supervised
datasets. Our comprehensive evaluation showcases the utility of KAFT across
model architectures and sizes."
NewsStories: Illustrating articles with visual summaries,0.0723251,"Recent self-supervised approaches have used large-scale image-text datasets
to learn powerful representations that transfer to many tasks without
finetuning. These methods often assume that there is one-to-one correspondence
between its images and their (short) captions. However, many tasks require
reasoning about multiple images and long text narratives, such as describing
news articles with visual summaries. Thus, we explore a novel setting where the
goal is to learn a self-supervised visual-language representation that is
robust to varying text length and the number of images. In addition, unlike
prior work which assumed captions have a literal relation to the image, we
assume images only contain loose illustrative correspondence with the text. To
explore this problem, we introduce a large-scale multimodal dataset containing
over 31M articles, 22M images and 1M videos. We show that state-of-the-art
image-text alignment methods are not robust to longer narratives with multiple
images. Finally, we introduce an intuitive baseline that outperforms these
methods on zero-shot image-set retrieval by 10% on the GoodNews dataset."
Multi-View Object Pose Refinement With Differentiable Renderer,0.309528,"This paper introduces a novel multi-view 6 DoF object pose refinement
approach focusing on improving methods trained on synthetic data. It is based
on the DPOD detector, which produces dense 2D-3D correspondences between the
model vertices and the image pixels in each frame. We have opted for the use of
multiple frames with known relative camera transformations, as it allows
introduction of geometrical constraints via an interpretable ICP-like loss
function. The loss function is implemented with a differentiable renderer and
is optimized iteratively. We also demonstrate that a full detection and
refinement pipeline, which is trained solely on synthetic data, can be used for
auto-labeling real data. We perform quantitative evaluation on LineMOD,
Occlusion, Homebrewed and YCB-V datasets and report excellent performance in
comparison to the state-of-the-art methods trained on the synthetic and real
data. We demonstrate empirically that our approach requires only a few frames
and is robust to close camera locations and noise in extrinsic camera
calibration, making its practical usage easier and more ubiquitous."
HuBERT-EE: Early Exiting HuBERT for Efficient Speech Recognition,0.409595,"Pre-training with self-supervised models, such as Hidden-unit BERT (HuBERT)
and wav2vec 2.0, has brought significant improvements in automatic speech
recognition (ASR). However, these models usually require an expensive
computational cost to achieve outstanding performance, slowing down the
inference speed. To improve the model efficiency, we propose an early exit
scheme for ASR, namely HuBERT-EE, that allows the model to stop the inference
dynamically. In HuBERT-EE, multiple early exit branches are added at the
intermediate layers, and each branch is used to decide whether a prediction can
be exited early. Experimental results on the LibriSpeech dataset show that
HuBERT-EE can accelerate the inference of a large-scale HuBERT model while
simultaneously balancing the trade-off between the word error rate (WER)
performance and the latency."
Scalable Joint Learning of Wireless Multiple-Access Policies and their Signaling,0.0841056,"In this paper, we apply an multi-agent reinforcement learning (MARL)
framework allowing the base station (BS) and the user equipments (UEs) to
jointly learn a channel access policy and its signaling in a wireless multiple
access scenario. In this framework, the BS and UEs are reinforcement learning
(RL) agents that need to cooperate in order to deliver data. The comparison
with a contention-free and a contention-based baselines shows that our
framework achieves a superior performance in terms of goodput even in high
traffic situations while maintaining a low collision rate. The scalability of
the proposed method is studied, since it is a major problem in MARL and this
paper provides the first results in order to address it."
Towards Privacy-Preserving Person Re-identification via Person Identify Shift,0.0236535,"Recently privacy concerns of person re-identification (ReID) raise more and
more attention and preserving the privacy of the pedestrian images used by ReID
methods become essential. De-identification (DeID) methods alleviate privacy
issues by removing the identity-related of the ReID data. However, most of the
existing DeID methods tend to remove all personal identity-related information
and compromise the usability of de-identified data on the ReID task. In this
paper, we aim to develop a technique that can achieve a good trade-off between
privacy protection and data usability for person ReID. To achieve this, we
propose a novel de-identification method designed explicitly for person ReID,
named Person Identify Shift (PIS). PIS removes the absolute identity in a
pedestrian image while preserving the identity relationship between image
pairs. By exploiting the interpolation property of variational auto-encoder,
PIS shifts each pedestrian image from the current identity to another with a
new identity, resulting in images still preserving the relative identities.
Experimental results show that our method has a better trade-off between
privacy-preserving and model performance than existing de-identification
methods and can defend against human and model attacks for data privacy."
Optimal Transport for Unsupervised Hallucination Detection in Neural Machine Translation,0.104874,"Neural machine translation (NMT) has become the de-facto standard in
real-world machine translation applications. However, NMT models can
unpredictably produce severely pathological translations, known as
hallucinations, that seriously undermine user trust. It becomes thus crucial to
implement effective preventive strategies to guarantee their proper
functioning. In this paper, we address the problem of hallucination detection
in NMT by following a simple intuition: as hallucinations are detached from the
source content, they exhibit encoder-decoder attention patterns that are
statistically different from those of good quality translations. We frame this
problem with an optimal transport formulation and propose a fully unsupervised,
plug-in detector that can be used with any attention-based NMT model.
Experimental results show that our detector not only outperforms all previous
model-based detectors, but is also competitive with detectors that employ large
models trained on millions of samples."
Neural Neighbor Style Transfer,0.844796,"We propose Neural Neighbor Style Transfer (NNST), a pipeline that offers
state-of-the-art quality, generalization, and competitive efficiency for
artistic style transfer. Our approach is based on explicitly replacing neural
features extracted from the content input (to be stylized) with those from a
style exemplar, then synthesizing the final output based on these rearranged
features. While the spirit of our approach is similar to prior work, we show
that our design decisions dramatically improve the final visual quality."
Distance Matters in Human-Object Interaction Detection,0.108058,"Human-Object Interaction (HOI) detection has received considerable attention
in the context of scene understanding. Despite the growing progress on
benchmarks, we realize that existing methods often perform unsatisfactorily on
distant interactions, where the leading causes are two-fold: 1) Distant
interactions are by nature more difficult to recognize than close ones. A
natural scene often involves multiple humans and objects with intricate spatial
relations, making the interaction recognition for distant human-object largely
affected by complex visual context. 2) Insufficient number of distant
interactions in benchmark datasets results in under-fitting on these instances.
To address these problems, in this paper, we propose a novel two-stage method
for better handling distant interactions in HOI detection. One essential
component in our method is a novel Far Near Distance Attention module. It
enables information propagation between humans and objects, whereby the spatial
distance is skillfully taken into consideration. Besides, we devise a novel
Distance-Aware loss function which leads the model to focus more on distant yet
rare interactions. We conduct extensive experiments on two challenging datasets
- HICO-DET and V-COCO. The results demonstrate that the proposed method can
surpass existing approaches by a large margin, resulting in new
state-of-the-art performance."
Iterative Next Boundary Detection for Instance Segmentation of Tree Rings in Microscopy Images of Shrub Cross Sections,0.0261334,"We address the problem of detecting tree rings in microscopy images of shrub
cross sections. This can be regarded as a special case of the instance
segmentation task with several unique challenges such as the concentric
circular ring shape of the objects and high precision requirements that result
in inadequate performance of existing methods. We propose a new iterative
method which we term Iterative Next Boundary Detection (INBD). It intuitively
models the natural growth direction, starting from the center of the shrub
cross section and detecting the next ring boundary in each iteration step. In
our experiments, INBD shows superior performance to generic instance
segmentation methods and is the only one with a built-in notion of
chronological order. Our dataset and source code are available at
http://github.com/alexander-g/INBD."
Fusing Local Similarities for Retrieval-based 3D Orientation Estimation of Unseen Objects,0.195651,"In this paper, we tackle the task of estimating the 3D orientation of
previously-unseen objects from monocular images. This task contrasts with the
one considered by most existing deep learning methods which typically assume
that the testing objects have been observed during training. To handle the
unseen objects, we follow a retrieval-based strategy and prevent the network
from learning object-specific features by computing multi-scale local
similarities between the query image and synthetically-generated reference
images. We then introduce an adaptive fusion module that robustly aggregates
the local similarities into a global similarity score of pairwise images.
Furthermore, we speed up the retrieval process by developing a fast retrieval
strategy. Our experiments on the LineMOD, LineMOD-Occluded, and T-LESS datasets
show that our method yields a significantly better generalization to unseen
objects than previous works. Our code and pre-trained models are available at
https://sailor-z.github.io/projects/Unseen_Object_Pose.html."
Instance-Specific Feature Propagation for Referring Segmentation,0.389129,"Referring segmentation aims to generate a segmentation mask for the target
instance indicated by a natural language expression. There are typically two
kinds of existing methods: one-stage methods that directly perform segmentation
on the fused vision and language features; and two-stage methods that first
utilize an instance segmentation model for instance proposal and then select
one of these instances via matching them with language features. In this work,
we propose a novel framework that simultaneously detects the target-of-interest
via feature propagation and generates a fine-grained segmentation mask. In our
framework, each instance is represented by an Instance-Specific Feature (ISF),
and the target-of-referring is identified by exchanging information among all
ISFs using our proposed Feature Propagation Module (FPM). Our instance-aware
approach learns the relationship among all objects, which helps to better
locate the target-of-interest than one-stage methods. Comparing to two-stage
methods, our approach collaboratively and interactively utilizes both vision
and language information for synchronous identification and segmentation. In
the experimental tests, our method outperforms previous state-of-the-art
methods on all three RefCOCO series datasets."
Full-Text Argumentation Mining on Scientific Publications,0.0224286,"Scholarly Argumentation Mining (SAM) has recently gained attention due to its
potential to help scholars with the rapid growth of published scientific
literature. It comprises two subtasks: argumentative discourse unit recognition
(ADUR) and argumentative relation extraction (ARE), both of which are
challenging since they require e.g. the integration of domain knowledge, the
detection of implicit statements, and the disambiguation of argument structure.
While previous work focused on dataset construction and baseline methods for
specific document sections, such as abstract or results, full-text scholarly
argumentation mining has seen little progress. In this work, we introduce a
sequential pipeline model combining ADUR and ARE for full-text SAM, and provide
a first analysis of the performance of pretrained language models (PLMs) on
both subtasks. We establish a new SotA for ADUR on the Sci-Arg corpus,
outperforming the previous best reported result by a large margin (+7% F1). We
also present the first results for ARE, and thus for the full AM pipeline, on
this benchmark dataset. Our detailed error analysis reveals that non-contiguous
ADUs as well as the interpretation of discourse connectors pose major
challenges and that data annotation needs to be more consistent."
Expanding Pretrained Models to Thousands More Languages via Lexicon-based Adaptation,0.556403,"The performance of multilingual pretrained models is highly dependent on the
availability of monolingual or parallel text present in a target language.
Thus, the majority of the world's languages cannot benefit from recent progress
in NLP as they have no or limited textual data. To expand possibilities of
using NLP technology in these under-represented languages, we systematically
study strategies that relax the reliance on conventional language resources
through the use of bilingual lexicons, an alternative resource with much better
language coverage. We analyze different strategies to synthesize textual or
labeled data using lexicons, and how this data can be combined with monolingual
or parallel text when available. For 19 under-represented languages across 3
tasks, our methods lead to consistent improvements of up to 5 and 15 points
with and without extra monolingual text respectively. Overall, our study
highlights how NLP methods can be adapted to thousands more languages that are
under-served by current technology"
Benchmarking Long-tail Generalization with Likelihood Splits,0.0099038,"In order to reliably process natural language, NLP systems must generalize to
the long tail of rare utterances. We propose a method to create challenging
benchmarks that require generalizing to the tail of the distribution by
re-splitting existing datasets. We create 'Likelihood Splits' where examples
that are assigned lower likelihood by a pre-trained language model (LM) are
placed in the test set, and more likely examples are in the training set. This
simple approach can be customized to construct meaningful train-test splits for
a wide range of tasks. Likelihood Splits surface more challenges than random
splits: relative error rates of state-of-the-art models increase by 59% for
semantic parsing on Spider, 93% for natural language inference on SNLI, and 33%
for yes/no question answering on BoolQ, on our splits compared with the
corresponding random splits. Moreover, Likelihood Splits create fairer
benchmarks than adversarial filtering; when the LM used to create the splits is
also employed as the task model, our splits do not unfairly penalize the LM."
MSP-Former: Multi-Scale Projection Transformer for Single Image Desnowing,0.728664,"Snow removal causes challenges due to its characteristic of complex
degradations. To this end, targeted treatment of multi-scale snow degradations
is critical for the network to learn effective snow removal. In order to handle
the diverse scenes, we propose a multi-scale projection transformer
(MSP-Former), which understands and covers a variety of snow degradation
features in a multi-path manner, and integrates comprehensive scene context
information for clean reconstruction via self-attention operation. For the
local details of various snow degradations, the local capture module is
introduced in parallel to assist in the rebuilding of a clean image. Such
design achieves the SOTA performance on three desnowing benchmark datasets
while costing the low parameters and computational complexity, providing a
guarantee of practicality."
QuantArt: Quantizing Image Style Transfer Towards High Visual Fidelity,-1.0,"The mechanism of existing style transfer algorithms is by minimizing a hybrid
loss function to push the generated image toward high similarities in both
content and style. However, this type of approach cannot guarantee visual
fidelity, i.e., the generated artworks should be indistinguishable from real
ones. In this paper, we devise a new style transfer framework called QuantArt
for high visual-fidelity stylization. QuantArt pushes the latent representation
of the generated artwork toward the centroids of the real artwork distribution
with vector quantization. By fusing the quantized and continuous latent
representations, QuantArt allows flexible control over the generated artworks
in terms of content preservation, style similarity, and visual fidelity.
Experiments on various style transfer settings show that our QuantArt framework
achieves significantly higher visual fidelity compared with the existing style
transfer methods."
Heatmap Distribution Matching for Human Pose Estimation,0.0382242,"For tackling the task of 2D human pose estimation, the great majority of the
recent methods regard this task as a heatmap estimation problem, and optimize
the heatmap prediction using the Gaussian-smoothed heatmap as the optimization
objective and using the pixel-wise loss (e.g. MSE) as the loss function. In
this paper, we show that optimizing the heatmap prediction in such a way, the
model performance of body joint localization, which is the intrinsic objective
of this task, may not be consistently improved during the optimization process
of the heatmap prediction. To address this problem, from a novel perspective,
we propose to formulate the optimization of the heatmap prediction as a
distribution matching problem between the predicted heatmap and the dot
annotation of the body joint directly. By doing so, our proposed method does
not need to construct the Gaussian-smoothed heatmap and can achieve a more
consistent model performance improvement during the optimization of the heatmap
prediction. We show the effectiveness of our proposed method through extensive
experiments on the COCO dataset and the MPII dataset."
Neutral Utterances are Also Causes: Enhancing Conversational Causal Emotion Entailment with Social Commonsense Knowledge,0.605682,"Conversational Causal Emotion Entailment aims to detect causal utterances for
a non-neutral targeted utterance from a conversation. In this work, we build
conversations as graphs to overcome implicit contextual modelling of the
original entailment style. Following the previous work, we further introduce
the emotion information into graphs. Emotion information can markedly promote
the detection of causal utterances whose emotion is the same as the targeted
utterance. However, it is still hard to detect causal utterances with different
emotions, especially neutral ones. The reason is that models are limited in
reasoning causal clues and passing them between utterances. To alleviate this
problem, we introduce social commonsense knowledge (CSK) and propose a
Knowledge Enhanced Conversation graph (KEC). KEC propagates the CSK between two
utterances. As not all CSK is emotionally suitable for utterances, we therefore
propose a sentiment-realized knowledge selecting strategy to filter CSK. To
process KEC, we further construct the Knowledge Enhanced Directed Acyclic Graph
networks. Experimental results show that our method outperforms baselines and
infers more causes with different emotions from the targeted utterance."
WeakM3D: Towards Weakly Supervised Monocular 3D Object Detection,0.148902,"Monocular 3D object detection is one of the most challenging tasks in 3D
scene understanding. Due to the ill-posed nature of monocular imagery, existing
monocular 3D detection methods highly rely on training with the manually
annotated 3D box labels on the LiDAR point clouds. This annotation process is
very laborious and expensive. To dispense with the reliance on 3D box labels,
in this paper we explore the weakly supervised monocular 3D detection.
Specifically, we first detect 2D boxes on the image. Then, we adopt the
generated 2D boxes to select corresponding RoI LiDAR points as the weak
supervision. Eventually, we adopt a network to predict 3D boxes which can
tightly align with associated RoI LiDAR points. This network is learned by
minimizing our newly-proposed 3D alignment loss between the 3D box estimates
and the corresponding RoI LiDAR points. We will illustrate the potential
challenges of the above learning problem and resolve these challenges by
introducing several effective designs into our method. Codes will be available
at https://github.com/SPengLiang/WeakM3D."
CRUSH: Contextually Regularized and User anchored Self-supervised Hate speech Detection,0.147823,"The last decade has witnessed a surge in the interaction of people through
social networking platforms. While there are several positive aspects of these
social platforms, the proliferation has led them to become the breeding ground
for cyber-bullying and hate speech. Recent advances in NLP have often been used
to mitigate the spread of such hateful content. Since the task of hate speech
detection is usually applicable in the context of social networks, we introduce
CRUSH, a framework for hate speech detection using user-anchored
self-supervision and contextual regularization. Our proposed approach secures ~
1-12% improvement in test set metrics over best performing previous approaches
on two types of tasks and multiple popular english social media datasets."
A unified 3D framework for Organs at Risk Localization and Segmentation for Radiation Therapy Planning,0.164469,"Automatic localization and segmentation of organs-at-risk (OAR) in CT are
essential pre-processing steps in medical image analysis tasks, such as
radiation therapy planning. For instance, the segmentation of OAR surrounding
tumors enables the maximization of radiation to the tumor area without
compromising the healthy tissues. However, the current medical workflow
requires manual delineation of OAR, which is prone to errors and is
annotator-dependent. In this work, we aim to introduce a unified 3D pipeline
for OAR localization-segmentation rather than novel localization or
segmentation architectures. To the best of our knowledge, our proposed
framework fully enables the exploitation of 3D context information inherent in
medical imaging. In the first step, a 3D multi-variate regression network
predicts organs' centroids and bounding boxes. Secondly, 3D organ-specific
segmentation networks are leveraged to generate a multi-organ segmentation map.
Our method achieved an overall Dice score of $0.9260\pm 0.18 \%$ on the
VISCERAL dataset containing CT scans with varying fields of view and multiple
organs."
NamedMask: Distilling Segmenters from Complementary Foundation Models,-1.0,"The goal of this work is to segment and name regions of images without access
to pixel-level labels during training. To tackle this task, we construct
segmenters by distilling the complementary strengths of two foundation models.
The first, CLIP (Radford et al. 2021), exhibits the ability to assign names to
image content but lacks an accessible representation of object structure. The
second, DINO (Caron et al. 2021), captures the spatial extent of objects but
has no knowledge of object names. Our method, termed NamedMask, begins by using
CLIP to construct category-specific archives of images. These images are
pseudo-labelled with a category-agnostic salient object detector bootstrapped
from DINO, then refined by category-specific segmenters using the CLIP archive
labels. Thanks to the high quality of the refined masks, we show that a
standard segmentation architecture trained on these archives with appropriate
data augmentation achieves impressive semantic segmentation abilities for both
single-object and multi-object images. As a result, our proposed NamedMask
performs favourably against a range of prior work on five benchmarks including
the VOC2012, COCO and large-scale ImageNet-S datasets."
Looking at the Overlooked: An Analysis on the Word-Overlap Bias in Natural Language Inference,0.0217908,"It has been shown that NLI models are usually biased with respect to the
word-overlap between premise and hypothesis; they take this feature as a
primary cue for predicting the entailment label. In this paper, we focus on an
overlooked aspect of the overlap bias in NLI models: the reverse word-overlap
bias. Our experimental results demonstrate that current NLI models are highly
biased towards the non-entailment label on instances with low overlap, and the
existing debiasing methods, which are reportedly successful on existing
challenge datasets, are generally ineffective in addressing this category of
bias. We investigate the reasons for the emergence of the overlap bias and the
role of minority examples in its mitigation. For the former, we find that the
word-overlap bias does not stem from pre-training, and for the latter, we
observe that in contrast to the accepted assumption, eliminating minority
examples does not affect the generalizability of debiasing methods with respect
to the overlap bias."
CL3D: Unsupervised Domain Adaptation for Cross-LiDAR 3D Detection,0.0675324,"Domain adaptation for Cross-LiDAR 3D detection is challenging due to the
large gap on the raw data representation with disparate point densities and
point arrangements. By exploring domain-invariant 3D geometric characteristics
and motion patterns, we present an unsupervised domain adaptation method that
overcomes above difficulties. First, we propose the Spatial Geometry Alignment
module to extract similar 3D shape geometric features of the same object class
to align two domains, while eliminating the effect of distinct point
distributions. Second, we present Temporal Motion Alignment module to utilize
motion features in sequential frames of data to match two domains. Prototypes
generated from two modules are incorporated into the pseudo-label reweighting
procedure and contribute to our effective self-training framework for the
target domain. Extensive experiments show that our method achieves
state-of-the-art performance on cross-device datasets, especially for the
datasets with large gaps captured by mechanical scanning LiDARs and solid-state
LiDARs in various scenes. Project homepage is at
https://github.com/4DVLab/CL3D.git"
"A Distant Supervision Corpus for Extracting Biomedical Relationships Between Chemicals, Diseases and Genes",0.130882,"We introduce ChemDisGene, a new dataset for training and evaluating
multi-class multi-label document-level biomedical relation extraction models.
Our dataset contains 80k biomedical research abstracts labeled with mentions of
chemicals, diseases, and genes, portions of which human experts labeled with 18
types of biomedical relationships between these entities (intended for
evaluation), and the remainder of which (intended for training) has been
distantly labeled via the CTD database with approximately 78\% accuracy. In
comparison to similar preexisting datasets, ours is both substantially larger
and cleaner; it also includes annotations linking mentions to their entities.
We also provide three baseline deep neural network relation extraction models
trained and evaluated on our new dataset."
Unbiased Knowledge Distillation for Recommendation,0.0803389,"As a promising solution for model compression, knowledge distillation (KD)
has been applied in recommender systems (RS) to reduce inference latency.
Traditional solutions first train a full teacher model from the training data,
and then transfer its knowledge (\ie \textit{soft labels}) to supervise the
learning of a compact student model. However, we find such a standard
distillation paradigm would incur serious bias issue -- popular items are more
heavily recommended after the distillation. This effect prevents the student
model from making accurate and fair recommendations, decreasing the
effectiveness of RS.
  In this work, we identify the origin of the bias in KD -- it roots in the
biased soft labels from the teacher, and is further propagated and intensified
during the distillation. To rectify this, we propose a new KD method with a
stratified distillation strategy. It first partitions items into multiple
groups according to their popularity, and then extracts the ranking knowledge
within each group to supervise the learning of the student. Our method is
simple and teacher-agnostic -- it works on distillation stage without affecting
the training of the teacher model. We conduct extensive theoretical and
empirical studies to validate the effectiveness of our proposal. We release our
code at: https://github.com/chengang95/UnKD."
Receding Horizon Inverse Reinforcement Learning,0.375268,"Inverse reinforcement learning (IRL) seeks to infer a cost function that
explains the underlying goals and preferences of expert demonstrations. This
paper presents receding horizon inverse reinforcement learning (RHIRL), a new
IRL algorithm for high-dimensional, noisy, continuous systems with black-box
dynamic models. RHIRL addresses two key challenges of IRL: scalability and
robustness. To handle high-dimensional continuous systems, RHIRL matches the
induced optimal trajectories with expert demonstrations locally in a receding
horizon manner and 'stitches' together the local solutions to learn the cost;
it thereby avoids the 'curse of dimensionality'. This contrasts sharply with
earlier algorithms that match with expert demonstrations globally over the
entire high-dimensional state space. To be robust against imperfect expert
demonstrations and control noise, RHIRL learns a state-dependent cost function
'disentangled' from system dynamics under mild conditions. Experiments on
benchmark tasks show that RHIRL outperforms several leading IRL algorithms in
most instances. We also prove that the cumulative error of RHIRL grows linearly
with the task duration."
Interpretable Multimodal Emotion Recognition using Hybrid Fusion of Speech and Image Data,0.0,"This paper proposes a multimodal emotion recognition system based on hybrid
fusion that classifies the emotions depicted by speech utterances and
corresponding images into discrete classes. A new interpretability technique
has been developed to identify the important speech & image features leading to
the prediction of particular emotion classes. The proposed system's
architecture has been determined through intensive ablation studies. It fuses
the speech & image features and then combines speech, image, and intermediate
fusion outputs. The proposed interpretability technique incorporates the divide
& conquer approach to compute shapely values denoting each speech & image
feature's importance. We have also constructed a large-scale dataset (IIT-R
SIER dataset), consisting of speech utterances, corresponding images, and class
labels, i.e., 'anger,' 'happy,' 'hate,' and 'sad.' The proposed system has
achieved 83.29% accuracy for emotion recognition. The enhanced performance of
the proposed system advocates the importance of utilizing complementary
information from multiple modalities for emotion recognition."
One Agent To Rule Them All: Towards Multi-agent Conversational AI,0.183114,"The increasing volume of commercially available conversational agents (CAs)
on the market has resulted in users being burdened with learning and adopting
multiple agents to accomplish their tasks. Though prior work has explored
supporting a multitude of domains within the design of a single agent, the
interaction experience suffers due to the large action space of desired
capabilities. To address these problems, we introduce a new task BBAI:
Black-Box Agent Integration, focusing on combining the capabilities of multiple
black-box CAs at scale. We explore two techniques: question agent pairing and
question response pairing aimed at resolving this task. Leveraging these
techniques, we design One For All (OFA), a scalable system that provides a
unified interface to interact with multiple CAs. Additionally, we introduce
MARS: Multi-Agent Response Selection, a new encoder model for question response
pairing that jointly encodes user question and agent response pairs. We
demonstrate that OFA is able to automatically and accurately integrate an
ensemble of commercially available CAs spanning disparate domains.
Specifically, using the MARS encoder we achieve the highest accuracy on our
BBAI task, outperforming strong baselines."
FaiRR: Faithful and Robust Deductive Reasoning over Natural Language,0.277523,"Transformers have been shown to be able to perform deductive reasoning on a
logical rulebase containing rules and statements written in natural language.
Recent works show that such models can also produce the reasoning steps (i.e.,
the proof graph) that emulate the model's logical reasoning process. Currently,
these black-box models generate both the proof graph and intermediate
inferences within the same model and thus may be unfaithful. In this work, we
frame the deductive logical reasoning task by defining three modular
components: rule selection, fact selection, and knowledge composition. The rule
and fact selection steps select the candidate rule and facts to be used and
then the knowledge composition combines them to generate new inferences. This
ensures model faithfulness by assured causal relation from the proof step to
the inference reasoning. To test our framework, we propose FaiRR (Faithful and
Robust Reasoner) where the above three components are independently modeled by
transformers. We observe that FaiRR is robust to novel language perturbations,
and is faster at inference than previous works on existing reasoning datasets.
Additionally, in contrast to black-box generative models, the errors made by
FaiRR are more interpretable due to the modular approach."
Watermarking Pre-trained Language Models with Backdooring,0.127135,"Large pre-trained language models (PLMs) have proven to be a crucial
component of modern natural language processing systems. PLMs typically need to
be fine-tuned on task-specific downstream datasets, which makes it hard to
claim the ownership of PLMs and protect the developer's intellectual property
due to the catastrophic forgetting phenomenon. We show that PLMs can be
watermarked with a multi-task learning framework by embedding backdoors
triggered by specific inputs defined by the owners, and those watermarks are
hard to remove even though the watermarked PLMs are fine-tuned on multiple
downstream tasks. In addition to using some rare words as triggers, we also
show that the combination of common words can be used as backdoor triggers to
avoid them being easily detected. Extensive experiments on multiple datasets
demonstrate that the embedded watermarks can be robustly extracted with a high
success rate and less influenced by the follow-up fine-tuning."
Detecting Deepfake by Creating Spatio-Temporal Regularity Disruption,0.324802,"Despite encouraging progress in deepfake detection, generalization to unseen
forgery types remains a significant challenge due to the limited forgery clues
explored during training. In contrast, we notice a common phenomenon in
deepfake: fake video creation inevitably disrupts the statistical regularity in
original videos. Inspired by this observation, we propose to boost the
generalization of deepfake detection by distinguishing the ""regularity
disruption"" that does not appear in real videos. Specifically, by carefully
examining the spatial and temporal properties, we propose to disrupt a real
video through a Pseudo-fake Generator and create a wide range of pseudo-fake
videos for training. Such practice allows us to achieve deepfake detection
without using fake videos and improves the generalization ability in a simple
and efficient manner. To jointly capture the spatial and temporal disruptions,
we propose a Spatio-Temporal Enhancement block to learn the regularity
disruption across space and time on our self-created videos. Through
comprehensive experiments, our method exhibits excellent performance on several
datasets."
Neural Contourlet Network for Monocular 360 Depth Estimation,0.0071068,"For a monocular 360 image, depth estimation is a challenging because the
distortion increases along the latitude. To perceive the distortion, existing
methods devote to designing a deep and complex network architecture. In this
paper, we provide a new perspective that constructs an interpretable and sparse
representation for a 360 image. Considering the importance of the geometric
structure in depth estimation, we utilize the contourlet transform to capture
an explicit geometric cue in the spectral domain and integrate it with an
implicit cue in the spatial domain. Specifically, we propose a neural
contourlet network consisting of a convolutional neural network and a
contourlet transform branch. In the encoder stage, we design a spatial-spectral
fusion module to effectively fuse two types of cues. Contrary to the encoder,
we employ the inverse contourlet transform with learned low-pass subbands and
band-pass directional subbands to compose the depth in the decoder. Experiments
on the three popular panoramic image datasets demonstrate that the proposed
approach outperforms the state-of-the-art schemes with faster convergence. Code
is available at
https://github.com/zhijieshen-bjtu/Neural-Contourlet-Network-for-MODE."
MMKGR: Multi-hop Multi-modal Knowledge Graph Reasoning,0.33275,"Multi-modal knowledge graphs (MKGs) include not only the relation triplets,
but also related multi-modal auxiliary data (i.e., texts and images), which
enhance the diversity of knowledge. However, the natural incompleteness has
significantly hindered the applications of MKGs. To tackle the problem,
existing studies employ the embedding-based reasoning models to infer the
missing knowledge after fusing the multi-modal features. However, the reasoning
performance of these methods is limited due to the following problems: (1)
ineffective fusion of multi-modal auxiliary features; (2) lack of complex
reasoning ability as well as inability to conduct the multi-hop reasoning which
is able to infer more missing knowledge. To overcome these problems, we propose
a novel model entitled MMKGR (Multi-hop Multi-modal Knowledge Graph Reasoning).
Specifically, the model contains the following two components: (1) a unified
gate-attention network which is designed to generate effective multi-modal
complementary features through sufficient attention interaction and noise
reduction; (2) a complementary feature-aware reinforcement learning method
which is proposed to predict missing elements by performing the multi-hop
reasoning process, based on the features obtained in component (1). The
experimental results demonstrate that MMKGR outperforms the state-of-the-art
approaches in the MKG reasoning task."
Referee: Reference-Free Sentence Summarization with Sharper Controllability through Symbolic Knowledge Distillation,0.352096,"We present Referee, a novel framework for sentence summarization that can be
trained reference-free (i.e., requiring no gold summaries for supervision),
while allowing direct control for compression ratio. Our work is the first to
demonstrate that reference-free, controlled sentence summarization is feasible
via the conceptual framework of Symbolic Knowledge Distillation (West et al.,
2022), where latent knowledge in pre-trained language models is distilled via
explicit examples sampled from the teacher models, further purified with three
types of filters: length, fidelity, and Information Bottleneck. Moreover, we
uniquely propose iterative distillation of knowledge, where student models from
the previous iteration of distillation serve as teacher models in the next
iteration. Starting off from a relatively modest set of GPT3-generated
summaries, we demonstrate how iterative knowledge distillation can lead to
considerably smaller, but better summarizers with sharper controllability. A
useful by-product of this iterative distillation process is a high-quality
dataset of sentence-summary pairs with varying degrees of compression ratios.
Empirical results demonstrate that the final student models vastly outperform
the much larger GPT3-Instruct model in terms of the controllability of
compression ratios, without compromising the quality of resulting
summarization."
Online Learning of Reusable Abstract Models for Object Goal Navigation,0.0201566,"In this paper, we present a novel approach to incrementally learn an Abstract
Model of an unknown environment, and show how an agent can reuse the learned
model for tackling the Object Goal Navigation task. The Abstract Model is a
finite state machine in which each state is an abstraction of a state of the
environment, as perceived by the agent in a certain position and orientation.
The perceptions are high-dimensional sensory data (e.g., RGB-D images), and the
abstraction is reached by exploiting image segmentation and the Taskonomy model
bank. The learning of the Abstract Model is accomplished by executing actions,
observing the reached state, and updating the Abstract Model with the acquired
information. The learned models are memorized by the agent, and they are reused
whenever it recognizes to be in an environment that corresponds to the stored
model. We investigate the effectiveness of the proposed approach for the Object
Goal Navigation task, relying on public benchmarks. Our results show that the
reuse of learned Abstract Models can boost performance on Object Goal
Navigation."
Understanding and Improving Knowledge Distillation for Quantization-Aware Training of Large Transformer Encoders,0.0759059,"Knowledge distillation (KD) has been a ubiquitous method for model
compression to strengthen the capability of a lightweight model with the
transferred knowledge from the teacher. In particular, KD has been employed in
quantization-aware training (QAT) of Transformer encoders like BERT to improve
the accuracy of the student model with the reduced-precision weight parameters.
However, little is understood about which of the various KD approaches best
fits the QAT of Transformers. In this work, we provide an in-depth analysis of
the mechanism of KD on attention recovery of quantized large Transformers. In
particular, we reveal that the previously adopted MSE loss on the attention
score is insufficient for recovering the self-attention information. Therefore,
we propose two KD methods; attention-map and attention-output losses.
Furthermore, we explore the unification of both losses to address
task-dependent preference between attention-map and output losses. The
experimental results on various Transformer encoder models demonstrate that the
proposed KD methods achieve state-of-the-art accuracy for QAT with sub-2-bit
weight quantization."
A2: Efficient Automated Attacker for Boosting Adversarial Training,0.0870884,"Based on the significant improvement of model robustness by AT (Adversarial
Training), various variants have been proposed to further boost the
performance. Well-recognized methods have focused on different components of AT
(e.g., designing loss functions and leveraging additional unlabeled data). It
is generally accepted that stronger perturbations yield more robust models.
However, how to generate stronger perturbations efficiently is still missed. In
this paper, we propose an efficient automated attacker called A2 to boost AT by
generating the optimal perturbations on-the-fly during training. A2 is a
parameterized automated attacker to search in the attacker space for the best
attacker against the defense model and examples. Extensive experiments across
different datasets demonstrate that A2 generates stronger perturbations with
low extra cost and reliably improves the robustness of various AT methods
against different attacks."
Proportional Fairness in Federated Learning,0.139622,"With the increasingly broad deployment of federated learning (FL) systems in
the real world, it is critical but challenging to ensure fairness in FL, i.e.
reasonably satisfactory performances for each of the numerous diverse clients.
In this work, we introduce and study a new fairness notion in FL, called
proportional fairness (PF), which is based on the relative change of each
client's performance. From its connection with the bargaining games, we propose
PropFair, a novel and easy-to-implement algorithm for finding proportionally
fair solutions in FL and study its convergence properties. Through extensive
experiments on vision and language datasets, we demonstrate that PropFair can
approximately find PF solutions, and it achieves a good balance between the
average performances of all clients and of the worst 10% clients. Our code is
available at
\url{https://github.com/huawei-noah/Federated-Learning/tree/main/FairFL}."
Efficient Federated Learning on Knowledge Graphs via Privacy-preserving Relation Embedding Aggregation,0.375568,"Federated learning (FL) can be essential in knowledge representation,
reasoning, and data mining applications over multi-source knowledge graphs
(KGs). A recent study FedE first proposes an FL framework that shares entity
embeddings of KGs across all clients. However, entity embedding sharing from
FedE would incur a severe privacy leakage. Specifically, the known entity
embedding can be used to infer whether a specific relation between two entities
exists in a private client. In this paper, we introduce a novel attack method
that aims to recover the original data based on the embedding information,
which is further used to evaluate the vulnerabilities of FedE. Furthermore, we
propose a Federated learning paradigm with privacy-preserving Relation
embedding aggregation (FedR) to tackle the privacy issue in FedE. Besides,
relation embedding sharing can significantly reduce the communication cost due
to its smaller size of queries. We conduct extensive experiments to evaluate
FedR with five different KG embedding models and three datasets. Compared to
FedE, FedR achieves similar utility and significant improvements regarding
privacy-preserving effect and communication efficiency on the link prediction
task."
Towards Responsible AI: A Design Space Exploration of Human-Centered Artificial Intelligence User Interfaces to Investigate Fairness,0.355797,"With Artificial intelligence (AI) to aid or automate decision-making
advancing rapidly, a particular concern is its fairness. In order to create
reliable, safe and trustworthy systems through human-centred artificial
intelligence (HCAI) design, recent efforts have produced user interfaces (UIs)
for AI experts to investigate the fairness of AI models. In this work, we
provide a design space exploration that supports not only data scientists but
also domain experts to investigate AI fairness. Using loan applications as an
example, we held a series of workshops with loan officers and data scientists
to elicit their requirements. We instantiated these requirements into FairHIL,
a UI to support human-in-the-loop fairness investigations, and describe how
this UI could be generalized to other use cases. We evaluated FairHIL through a
think-aloud user study. Our work contributes better designs to investigate an
AI model's fairness-and move closer towards responsible AI."
3D Random Occlusion and Multi-Layer Projection for Deep Multi-Camera Pedestrian Localization,0.156893,"Although deep-learning based methods for monocular pedestrian detection have
made great progress, they are still vulnerable to heavy occlusions. Using
multi-view information fusion is a potential solution but has limited
applications, due to the lack of annotated training samples in existing
multi-view datasets, which increases the risk of overfitting. To address this
problem, a data augmentation method is proposed to randomly generate 3D
cylinder occlusions, on the ground plane, which are of the average size of
pedestrians and projected to multiple views, to relieve the impact of
overfitting in the training. Moreover, the feature map of each view is
projected to multiple parallel planes at different heights, by using
homographies, which allows the CNNs to fully utilize the features across the
height of each pedestrian to infer the locations of pedestrians on the ground
plane. The proposed 3DROM method has a greatly improved performance in
comparison with the state-of-the-art deep-learning based methods for multi-view
pedestrian detection."
Domain-General Crowd Counting in Unseen Scenarios,0.048108,"Domain shift across crowd data severely hinders crowd counting models to
generalize to unseen scenarios. Although domain adaptive crowd counting
approaches close this gap to a certain extent, they are still dependent on the
target domain data to adapt (e.g. finetune) their models to the specific
domain. In this paper, we aim to train a model based on a single source domain
which can generalize well on any unseen domain. This falls into the realm of
domain generalization that remains unexplored in crowd counting. We first
introduce a dynamic sub-domain division scheme which divides the source domain
into multiple sub-domains such that we can initiate a meta-learning framework
for domain generalization. The sub-domain division is dynamically refined
during the meta-learning. Next, in order to disentangle domain-invariant
information from domain-specific information in image features, we design the
domain-invariant and -specific crowd memory modules to re-encode image
features. Two types of losses, i.e. feature reconstruction and orthogonal
losses, are devised to enable this disentanglement. Extensive experiments on
several standard crowd counting benchmarks i.e. SHA, SHB, QNRF, and NWPU, show
the strong generalizability of our method."
Toward Fairness in Speech Recognition: Discovery and mitigation of performance disparities,0.161478,"As for other forms of AI, speech recognition has recently been examined with
respect to performance disparities across different user cohorts. One approach
to achieve fairness in speech recognition is to (1) identify speaker cohorts
that suffer from subpar performance and (2) apply fairness mitigation measures
targeting the cohorts discovered. In this paper, we report on initial findings
with both discovery and mitigation of performance disparities using data from a
product-scale AI assistant speech recognition system. We compare cohort
discovery based on geographic and demographic information to a more scalable
method that groups speakers without human labels, using speaker embedding
technology. For fairness mitigation, we find that oversampling of
underrepresented cohorts, as well as modeling speaker cohort membership by
additional input variables, reduces the gap between top- and bottom-performing
cohorts, without deteriorating overall recognition accuracy."
nerf2nerf: Pairwise Registration of Neural Radiance Fields,0.132844,"We introduce a technique for pairwise registration of neural fields that
extends classical optimization-based local registration (i.e. ICP) to operate
on Neural Radiance Fields (NeRF) -- neural 3D scene representations trained
from collections of calibrated images. NeRF does not decompose illumination and
color, so to make registration invariant to illumination, we introduce the
concept of a ''surface field'' -- a field distilled from a pre-trained NeRF
model that measures the likelihood of a point being on the surface of an
object. We then cast nerf2nerf registration as a robust optimization that
iteratively seeks a rigid transformation that aligns the surface fields of the
two scenes. We evaluate the effectiveness of our technique by introducing a
dataset of pre-trained NeRF scenes -- our synthetic scenes enable quantitative
evaluations and comparisons to classical registration techniques, while our
real scenes demonstrate the validity of our technique in real-world scenarios.
Additional results available at: https://nerf2nerf.github.io"
Enhancing Diffusion-Based Image Synthesis with Robust Classifier Guidance,0.306752,"Denoising diffusion probabilistic models (DDPMs) are a recent family of
generative models that achieve state-of-the-art results. In order to obtain
class-conditional generation, it was suggested to guide the diffusion process
by gradients from a time-dependent classifier. While the idea is theoretically
sound, deep learning-based classifiers are infamously susceptible to
gradient-based adversarial attacks. Therefore, while traditional classifiers
may achieve good accuracy scores, their gradients are possibly unreliable and
might hinder the improvement of the generation results. Recent work discovered
that adversarially robust classifiers exhibit gradients that are aligned with
human perception, and these could better guide a generative process towards
semantically meaningful images. We utilize this observation by defining and
training a time-dependent adversarially robust classifier and use it as
guidance for a generative diffusion model. In experiments on the highly
challenging and diverse ImageNet dataset, our scheme introduces significantly
more intelligible intermediate gradients, better alignment with theoretical
findings, as well as improved generation results under several evaluation
metrics. Furthermore, we conduct an opinion survey whose findings indicate that
human raters prefer our method's results."
"From Perception to Programs: Regularize, Overparameterize, and Amortize",0.0758003,"Toward combining inductive reasoning with perception abilities, we develop
techniques for neurosymbolic program synthesis where perceptual input is first
parsed by neural nets into a low-dimensional interpretable representation,
which is then processed by a synthesized program. We explore several techniques
for relaxing the problem and jointly learning all modules end-to-end with
gradient descent: multitask learning; amortized inference;
overparameterization; and a differentiable strategy for penalizing lengthy
programs. Collectedly this toolbox improves the stability of gradient-guided
program search, and suggests ways of learning both how to perceive input as
discrete abstractions, and how to symbolically process those abstractions as
programs."
IRISformer: Dense Vision Transformers for Single-Image Inverse Rendering in Indoor Scenes,0.446895,"Indoor scenes exhibit significant appearance variations due to myriad
interactions between arbitrarily diverse object shapes, spatially-changing
materials, and complex lighting. Shadows, highlights, and inter-reflections
caused by visible and invisible light sources require reasoning about
long-range interactions for inverse rendering, which seeks to recover the
components of image formation, namely, shape, material, and lighting. In this
work, our intuition is that the long-range attention learned by transformer
architectures is ideally suited to solve longstanding challenges in
single-image inverse rendering. We demonstrate with a specific instantiation of
a dense vision transformer, IRISformer, that excels at both single-task and
multi-task reasoning required for inverse rendering. Specifically, we propose a
transformer architecture to simultaneously estimate depths, normals,
spatially-varying albedo, roughness and lighting from a single image of an
indoor scene. Our extensive evaluations on benchmark datasets demonstrate
state-of-the-art results on each of the above tasks, enabling applications like
object insertion and material editing in a single unconstrained real image,
with greater photorealism than prior works. Code and data are publicly released
at https://github.com/ViLab-UCSD/IRISformer."
PaCo: Parameter-Compositional Multi-Task Reinforcement Learning,0.127767,"The purpose of multi-task reinforcement learning (MTRL) is to train a single
policy that can be applied to a set of different tasks. Sharing parameters
allows us to take advantage of the similarities among tasks. However, the gaps
between contents and difficulties of different tasks bring us challenges on
both which tasks should share the parameters and what parameters should be
shared, as well as the optimization challenges due to parameter sharing. In
this work, we introduce a parameter-compositional approach (PaCo) as an attempt
to address these challenges. In this framework, a policy subspace represented
by a set of parameters is learned. Policies for all the single tasks lie in
this subspace and can be composed by interpolating with the learned set. It
allows not only flexible parameter sharing but also a natural way to improve
training. We demonstrate the state-of-the-art performance on Meta-World
benchmarks, verifying the effectiveness of the proposed approach."
A Simple Hash-Based Early Exiting Approach For Language Understanding and Generation,0.629889,"Early exiting allows instances to exit at different layers according to the
estimation of difficulty. Previous works usually adopt heuristic metrics such
as the entropy of internal outputs to measure instance difficulty, which
suffers from generalization and threshold-tuning. In contrast, learning to
exit, or learning to predict instance difficulty is a more appealing way.
Though some effort has been devoted to employing such ""learn-to-exit"" modules,
it is still unknown whether and how well the instance difficulty can be
learned. As a response, we first conduct experiments on the learnability of
instance difficulty, which demonstrates that modern neural models perform
poorly on predicting instance difficulty. Based on this observation, we propose
a simple-yet-effective Hash-based Early Exiting approach (HashEE) that replaces
the learn-to-exit modules with hash functions to assign each token to a fixed
exiting layer. Different from previous methods, HashEE requires no internal
classifiers nor extra parameters, and therefore is more efficient. Experimental
results on classification, regression, and generation tasks demonstrate that
HashEE can achieve higher performance with fewer FLOPs and inference time
compared with previous state-of-the-art early exiting methods."
Interacting Hand-Object Pose Estimation via Dense Mutual Attention,0.0578264,"3D hand-object pose estimation is the key to the success of many computer
vision applications. The main focus of this task is to effectively model the
interaction between the hand and an object. To this end, existing works either
rely on interaction constraints in a computationally-expensive iterative
optimization, or consider only a sparse correlation between sampled hand and
object keypoints. In contrast, we propose a novel dense mutual attention
mechanism that is able to model fine-grained dependencies between the hand and
the object. Specifically, we first construct the hand and object graphs
according to their mesh structures. For each hand node, we aggregate features
from every object node by the learned attention and vice versa for each object
node. Thanks to such dense mutual attention, our method is able to produce
physically plausible poses with high quality and real-time inference speed.
Extensive quantitative and qualitative experiments on large benchmark datasets
show that our method outperforms state-of-the-art methods. The code is
available at https://github.com/rongakowang/DenseMutualAttention.git."
Prompt Consistency for Zero-Shot Task Generalization,0.434231,"One of the most impressive results of recent NLP history is the ability of
pre-trained language models to solve new tasks in a zero-shot setting. To
achieve this, NLP tasks are framed as natural language prompts, generating a
response indicating the predicted output. Nonetheless, the performance in such
settings often lags far behind its supervised counterpart, suggesting a large
space for potential improvement. In this paper, we explore methods to utilize
unlabeled data to improve zero-shot performance. Specifically, we take
advantage of the fact that multiple prompts can be used to specify a single
task, and propose to regularize prompt consistency, encouraging consistent
predictions over this diverse set of prompts. Our method makes it possible to
fine-tune the model either with extra unlabeled training data, or directly on
test input at inference time in an unsupervised manner. In experiments, our
approach outperforms the state-of-the-art zero-shot learner, T0 (Sanh et al.,
2022), on 9 out of 11 datasets across 4 NLP tasks by up to 10.6 absolute points
in terms of accuracy. The gains are often attained with a small number of
unlabeled examples."
Flattening-Net: Deep Regular 2D Representation for 3D Point Cloud Analysis,0.115337,"Point clouds are characterized by irregularity and unstructuredness, which
pose challenges in efficient data exploitation and discriminative feature
extraction. In this paper, we present an unsupervised deep neural architecture
called Flattening-Net to represent irregular 3D point clouds of arbitrary
geometry and topology as a completely regular 2D point geometry image (PGI)
structure, in which coordinates of spatial points are captured in colors of
image pixels. \mr{Intuitively, Flattening-Net implicitly approximates a locally
smooth 3D-to-2D surface flattening process while effectively preserving
neighborhood consistency.} \mr{As a generic representation modality, PGI
inherently encodes the intrinsic property of the underlying manifold structure
and facilitates surface-style point feature aggregation.} To demonstrate its
potential, we construct a unified learning framework directly operating on PGIs
to achieve \mr{diverse types of high-level and low-level} downstream
applications driven by specific task networks, including classification,
segmentation, reconstruction, and upsampling. Extensive experiments demonstrate
that our methods perform favorably against the current state-of-the-art
competitors. We will make the code and data publicly available at
https://github.com/keeganhk/Flattening-Net."
Qtrade AI at SemEval-2022 Task 11: An Unified Framework for Multilingual NER Task,0.0491661,"This paper describes our system, which placed third in the Multilingual Track
(subtask 11), fourth in the Code-Mixed Track (subtask 12), and seventh in the
Chinese Track (subtask 9) in the SemEval 2022 Task 11: MultiCoNER Multilingual
Complex Named Entity Recognition. Our system's key contributions are as
follows: 1) For multilingual NER tasks, we offer an unified framework with
which one can easily execute single-language or multilingual NER tasks, 2) for
low-resource code-mixed NER task, one can easily enhance his or her dataset
through implementing several simple data augmentation methods and 3) for
Chinese tasks, we propose a model that can capture Chinese lexical semantic,
lexical border, and lexical graph structural information. Finally, our system
achieves macro-f1 scores of 77.66, 84.35, and 74.00 on subtasks 11, 12, and 9,
respectively, during the testing phase."
Hierarchical Decision Transformer,0.0362703,"Sequence models in reinforcement learning require task knowledge to estimate
the task policy. This paper presents a hierarchical algorithm for learning a
sequence model from demonstrations. The high-level mechanism guides the
low-level controller through the task by selecting sub-goals for the latter to
reach. This sequence replaces the returns-to-go of previous methods, improving
its performance overall, especially in tasks with longer episodes and scarcer
rewards. We validate our method in multiple tasks of OpenAIGym, D4RL and
RoboMimic benchmarks. Our method outperforms the baselines in eight out of ten
tasks of varied horizons and reward frequencies without prior task knowledge,
showing the advantages of the hierarchical model approach for learning from
demonstrations using a sequence model."
Open Domain Multi-document Summarization: A Comprehensive Study of Model Brittleness under Retrieval,0.110502,"Multi-document summarization (MDS) assumes a set of topic-related documents
are provided as input. In practice, this document set is not always available;
it would need to be retrieved given an information need, i.e. a question or
topic statement, a setting we dub ""open-domain"" MDS. We study this more
challenging setting by formalizing the task and bootstrapping it using existing
datasets, retrievers and summarizers. Via extensive automatic and human
evaluation, we determine: (1) state-of-the-art summarizers suffer large
reductions in performance when applied to open-domain MDS, (2) additional
training in the open-domain setting can reduce this sensitivity to imperfect
retrieval, and (3) summarizers are insensitive to the retrieval of duplicate
documents and the order of retrieved documents, but highly sensitive to other
errors, like the retrieval of irrelevant documents. Based on our results, we
provide practical guidelines to enable future work on open-domain MDS, e.g. how
to choose the number of retrieved documents to summarize. Our results suggest
that new retrieval and summarization methods and annotated resources for
training and evaluation are necessary for further progress in the open-domain
setting."
Hierarchical Attention Network for Explainable Depression Detection on Twitter Aided by Metaphor Concept Mappings,0.390131,"Automatic depression detection on Twitter can help individuals privately and
conveniently understand their mental health status in the early stages before
seeing mental health professionals. Most existing black-box-like deep learning
methods for depression detection largely focused on improving classification
performance. However, explaining model decisions is imperative in health
research because decision-making can often be high-stakes and life-and-death.
Reliable automatic diagnosis of mental health problems including depression
should be supported by credible explanations justifying models' predictions. In
this work, we propose a novel explainable model for depression detection on
Twitter. It comprises a novel encoder combining hierarchical attention
mechanisms and feed-forward neural networks. To support psycholinguistic
studies, our model leverages metaphorical concept mappings as input. Thus, it
not only detects depressed individuals, but also identifies features of such
users' tweets and associated metaphor concept mappings."
Defending Black-box Skeleton-based Human Activity Classifiers,0.113883,"Skeletal motions have been heavily replied upon for human activity
recognition (HAR). Recently, a universal vulnerability of skeleton-based HAR
has been identified across a variety of classifiers and data, calling for
mitigation. To this end, we propose the first black-box defense method for
skeleton-based HAR to our best knowledge. Our method is featured by full
Bayesian treatments of the clean data, the adversaries and the classifier,
leading to (1) a new Bayesian Energy-based formulation of robust discriminative
classifiers, (2) a new adversary sampling scheme based on natural motion
manifolds, and (3) a new post-train Bayesian strategy for black-box defense. We
name our framework Bayesian Energy-based Adversarial Training or BEAT. BEAT is
straightforward but elegant, which turns vulnerable black-box classifiers into
robust ones without sacrificing accuracy. It demonstrates surprising and
universal effectiveness across a wide range of skeletal HAR classifiers and
datasets, under various attacks. Code is available at
https://github.com/realcrane/RobustActionRecogniser."
AdaLoGN: Adaptive Logic Graph Network for Reasoning-Based Machine Reading Comprehension,-1.0,"Recent machine reading comprehension datasets such as ReClor and LogiQA
require performing logical reasoning over text. Conventional neural models are
insufficient for logical reasoning, while symbolic reasoners cannot directly
apply to text. To meet the challenge, we present a neural-symbolic approach
which, to predict an answer, passes messages over a graph representing logical
relations between text units. It incorporates an adaptive logic graph network
(AdaLoGN) which adaptively infers logical relations to extend the graph and,
essentially, realizes mutual and iterative reinforcement between neural and
symbolic reasoning. We also implement a novel subgraph-to-node message passing
mechanism to enhance context-option interaction for answering multiple-choice
questions. Our approach shows promising results on ReClor and LogiQA."
Mixture of Input-Output Hidden Markov Models for Heterogeneous Disease Progression Modeling,0.0707383,"A particular challenge for disease progression modeling is the heterogeneity
of a disease and its manifestations in the patients. Existing approaches often
assume the presence of a single disease progression characteristics which is
unlikely for neurodegenerative disorders such as Parkinson's disease. In this
paper, we propose a hierarchical time-series model that can discover multiple
disease progression dynamics. The proposed model is an extension of an
input-output hidden Markov model that takes into account the clinical
assessments of patients' health status and prescribed medications. We
illustrate the benefits of our model using a synthetically generated dataset
and a real-world longitudinal dataset for Parkinson's disease."
A Transfer Learning Based Model for Text Readability Assessment in German,0.0348457,"Text readability assessment has a wide range of applications for different
target people, from language learners to people with disabilities. The fast
pace of textual content production on the web makes it impossible to measure
text complexity without the benefit of machine learning and natural language
processing techniques. Although various research addressed the readability
assessment of English text in recent years, there is still room for improvement
of the models for other languages. In this paper, we proposed a new model for
text complexity assessment for German text based on transfer learning. Our
results show that the model outperforms more classical solutions based on
linguistic features extraction from input text. The best model is based on the
BERT pre-trained language model achieved the Root Mean Square Error (RMSE) of
0.483."
Contrastive Learning of Coarse-Grained Force Fields,0.0324126,"Coarse-grained models have proven helpful for simulating complex systems over
long timescales to provide molecular insights into various processes.
Methodologies for systematic parameterization of the underlying energy
function, or force field that describes the interactions among different
components of the system are of great interest for ensuring simulation
accuracy. We present a new method, potential contrasting, to enable efficient
learning of force fields that can accurately reproduce the conformational
distribution produced with all-atom simulations. Potential contrasting
generalizes the noise contrastive estimation method with umbrella sampling to
better learn the complex energy landscape of molecular systems. When applied to
the Trp-cage protein, we found that the technique produces force fields that
thoroughly capture the thermodynamics of the folding process despite the use of
only $\alpha$-Carbons in the coarse-grained model. We further showed that
potential contrasting could be applied over large datasets that combine the
conformational ensembles of many proteins to ensure the transferability of
coarse-grained force fields. We anticipate potential contrasting to be a
powerful tool for building general-purpose coarse-grained force fields."
Tools and Practices for Responsible AI Engineering,0.32918,"Responsible Artificial Intelligence (AI) - the practice of developing,
evaluating, and maintaining accurate AI systems that also exhibit essential
properties such as robustness and explainability - represents a multifaceted
challenge that often stretches standard machine learning tooling, frameworks,
and testing methods beyond their limits. In this paper, we present two new
software libraries - hydra-zen and the rAI-toolbox - that address critical
needs for responsible AI engineering. hydra-zen dramatically simplifies the
process of making complex AI applications configurable, and their behaviors
reproducible. The rAI-toolbox is designed to enable methods for evaluating and
enhancing the robustness of AI-models in a way that is scalable and that
composes naturally with other popular ML frameworks. We describe the design
principles and methodologies that make these tools effective, including the use
of property-based testing to bolster the reliability of the tools themselves.
Finally, we demonstrate the composability and flexibility of the tools by
showing how various use cases from adversarial robustness and explainable AI
can be concisely implemented with familiar APIs."
Cerebral Palsy Prediction with Frequency Attention Informed Graph Convolutional Networks,0.0308773,"Early diagnosis and intervention are clinically considered the paramount part
of treating cerebral palsy (CP), so it is essential to design an efficient and
interpretable automatic prediction system for CP. We highlight a significant
difference between CP infants' frequency of human movement and that of the
healthy group, which improves prediction performance. However, the existing
deep learning-based methods did not use the frequency information of infants'
movement for CP prediction. This paper proposes a frequency attention informed
graph convolutional network and validates it on two consumer-grade RGB video
datasets, namely MINI-RGBD and RVI-38 datasets. Our proposed frequency
attention module aids in improving both classification performance and system
interpretability. In addition, we design a frequency-binning method that
retains the critical frequency of the human joint position data while filtering
the noise. Our prediction performance achieves state-of-the-art research on
both datasets. Our work demonstrates the effectiveness of frequency information
in supporting the prediction of CP non-intrusively and provides a way for
supporting the early diagnosis of CP in the resource-limited regions where the
clinical resources are not abundant."
Generative Category-Level Shape and Pose Estimation with Semantic Primitives,0.13557,"Empowering autonomous agents with 3D understanding for daily objects is a
grand challenge in robotics applications. When exploring in an unknown
environment, existing methods for object pose estimation are still not
satisfactory due to the diversity of object shapes. In this paper, we propose a
novel framework for category-level object shape and pose estimation from a
single RGB-D image. To handle the intra-category variation, we adopt a semantic
primitive representation that encodes diverse shapes into a unified latent
space, which is the key to establish reliable correspondences between observed
point clouds and estimated shapes. Then, by using a SIM(3)-invariant shape
descriptor, we gracefully decouple the shape and pose of an object, thus
supporting latent shape optimization of target objects in arbitrary poses.
Extensive experiments show that the proposed method achieves SOTA pose
estimation performance and better generalization in the real-world dataset.
Code and video are available at https://zju3dv.github.io/gCasp."
C-Pack of IPAs: A C90 Program Benchmark of Introductory Programming Assignments,0.13291,"Due to the vast number of students enrolled in Massive Open Online Courses
(MOOCs), there has been an increasing number of automated program repair
techniques focused on introductory programming assignments (IPAs). Such
techniques take advantage of previous correct student implementations in order
to provide automated, comprehensive, and personalized feedback to students.
  This paper presents C-Pack-IPAs, a publicly available benchmark of students'
programs submitted for 25 different IPAs. C-Pack-IPAs contains semantically
correct, semantically incorrect, and syntactically incorrect programs plus a
test suite for each IPA. Hence, C-Pack-IPAs can be used to help evaluate the
development of novel semantic, as well as syntactic, automated program repair
frameworks, focused on providing feedback to novice programmers."
A Hierarchical Bayesian Approach to Inverse Reinforcement Learning with Symbolic Reward Machines,0.0569389,"A misspecified reward can degrade sample efficiency and induce undesired
behaviors in reinforcement learning (RL) problems. We propose symbolic reward
machines for incorporating high-level task knowledge when specifying the reward
signals. Symbolic reward machines augment existing reward machine formalism by
allowing transitions to carry predicates and symbolic reward outputs. This
formalism lends itself well to inverse reinforcement learning, whereby the key
challenge is determining appropriate assignments to the symbolic values from a
few expert demonstrations. We propose a hierarchical Bayesian approach for
inferring the most likely assignments such that the concretized reward machine
can discriminate expert demonstrated trajectories from other trajectories with
high accuracy. Experimental results show that learned reward machines can
significantly improve training efficiency for complex RL tasks and generalize
well across different task environment configurations."
Cycle-Consistent Counterfactuals by Latent Transformations,0.248931,"CounterFactual (CF) visual explanations try to find images similar to the
query image that change the decision of a vision system to a specified outcome.
Existing methods either require inference-time optimization or joint training
with a generative adversarial model which makes them time-consuming and
difficult to use in practice. We propose a novel approach, Cycle-Consistent
Counterfactuals by Latent Transformations (C3LT), which learns a latent
transformation that automatically generates visual CFs by steering in the
latent space of generative models. Our method uses cycle consistency between
the query and CF latent representations which helps our training to find better
solutions. C3LT can be easily plugged into any state-of-the-art pretrained
generative network. This enables our method to generate high-quality and
interpretable CF images at high resolution such as those in ImageNet. In
addition to several established metrics for evaluating CF explanations, we
introduce a novel metric tailored to assess the quality of the generated CF
examples and validate the effectiveness of our method on an extensive set of
experiments."
Solutions for Fine-grained and Long-tailed Snake Species Recognition in SnakeCLEF 2022,0.067733,"Automatic snake species recognition is important because it has vast
potential to help lower deaths and disabilities caused by snakebites. We
introduce our solution in SnakeCLEF 2022 for fine-grained snake species
recognition on a heavy long-tailed class distribution. First, a network
architecture is designed to extract and fuse features from multiple modalities,
i.e. photograph from visual modality and geographic locality information from
language modality. Then, logit adjustment based methods are studied to relieve
the impact caused by the severe class imbalance. Next, a combination of
supervised and self-supervised learning method is proposed to make full use of
the dataset, including both labeled training data and unlabeled testing data.
Finally, post processing strategies, such as multi-scale and multi-crop
test-time-augmentation, location filtering and model ensemble, are employed for
better performance. With an ensemble of several different models, a private
score 82.65%, ranking the 3rd, is achieved on the final leaderboard."
Pruning Neural Networks via Coresets and Convex Geometry: Towards No Assumptions,0.203454,"Pruning is one of the predominant approaches for compressing deep neural
networks (DNNs). Lately, coresets (provable data summarizations) were leveraged
for pruning DNNs, adding the advantage of theoretical guarantees on the
trade-off between the compression rate and the approximation error. However,
coresets in this domain were either data-dependent or generated under
restrictive assumptions on both the model's weights and inputs. In real-world
scenarios, such assumptions are rarely satisfied, limiting the applicability of
coresets. To this end, we suggest a novel and robust framework for computing
such coresets under mild assumptions on the model's weights and without any
assumption on the training data. The idea is to compute the importance of each
neuron in each layer with respect to the output of the following layer. This is
achieved by a combination of L\""{o}wner ellipsoid and Caratheodory theorem. Our
method is simultaneously data-independent, applicable to various networks and
datasets (due to the simplified assumptions), and theoretically supported.
Experimental results show that our method outperforms existing coreset based
neural pruning approaches across a wide range of networks and datasets. For
example, our method achieved a $62\%$ compression rate on ResNet50 on ImageNet
with $1.09\%$ drop in accuracy."
Mutation Models: Learning to Generate Levels by Imitating Evolution,0.0343829,"Search-based procedural content generation (PCG) is a well-known method for
level generation in games. Its key advantage is that it is generic and able to
satisfy functional constraints. However, due to the heavy computational costs
to run these algorithms online, search-based PCG is rarely utilized for
real-time generation. In this paper, we introduce mutation models, a new type
of iterative level generator based on machine learning. We train a model to
imitate the evolutionary process and use the trained model to generate levels.
This trained model is able to modify noisy levels sequentially to create better
levels without the need for a fitness function during inference. We evaluate
our trained models on a 2D maze generation task. We compare several different
versions of the method: training the models either at the end of evolution
(normal evolution) or every 100 generations (assisted evolution) and using the
model as a mutation function during evolution. Using the assisted evolution
process, the final trained models are able to generate mazes with a success
rate of 99% and high diversity of 86%. The trained model is many times faster
than the evolutionary process it was trained on. This work opens the door to a
new way of learning level generators guided by an evolutionary process, meaning
automatic creation of generators with specifiable constraints and objectives
that are fast enough for runtime deployment in games."
EditableNeRF: Editing Topologically Varying Neural Radiance Fields by Key Points,0.287269,"Neural radiance fields (NeRF) achieve highly photo-realistic novel-view
synthesis, but it's a challenging problem to edit the scenes modeled by
NeRF-based methods, especially for dynamic scenes. We propose editable neural
radiance fields that enable end-users to easily edit dynamic scenes and even
support topological changes. Input with an image sequence from a single camera,
our network is trained fully automatically and models topologically varying
dynamics using our picked-out surface key points. Then end-users can edit the
scene by easily dragging the key points to desired new positions. To achieve
this, we propose a scene analysis method to detect and initialize key points by
considering the dynamics in the scene, and a weighted key points strategy to
model topologically varying dynamics by joint key points and weights
optimization. Our method supports intuitive multi-dimensional (up to 3D)
editing and can generate novel scenes that are unseen in the input sequence.
Experiments demonstrate that our method achieves high-quality editing on
various dynamic scenes and outperforms the state-of-the-art. Our code and
captured data are available at https://chengwei-zheng.github.io/EditableNeRF/."
Learning by Distilling Context,0.318681,"Language models significantly benefit from context tokens, such as prompts or
scratchpads. They perform better when prompted with informative instructions,
and they acquire new reasoning capabilities by generating a scratch-pad before
predicting the final answers. However, they do not \textit{internalize} these
performance gains, which disappear when the context tokens are gone. Our work
proposes to apply context distillation so that a language model can improve
itself by internalizing these gains. Concretely, given a synthetic unlabeled
input for the target task, we condition the model on ``[instructions] +
[task-input]'' to predict ``[scratch-pad] + [final answer]''; then we fine-tune
the same model to predict its own ``[final answer]'' conditioned on the
``[task-input]'', without seeing the ``[instructions]'' or using the
``[scratch-pad]''.
  We show that context distillation is a general method to train language
models, and it can effectively internalize 3 types of training signals. First,
it can internalize abstract task instructions and explanations, so we can
iteratively update the model parameters with new instructions and overwrite old
ones. Second, it can internalize step-by-step reasoning for complex tasks
(e.g., 8-digit addition), and such a newly acquired capability proves to be
useful for other downstream tasks. Finally, it can internalize concrete
training examples, and it outperforms directly learning with gradient descent
by 9\% on the SPIDER Text-to-SQL dataset; furthermore, combining context
distillation operations can internalize more training examples than the context
window size allows."
Improving Speech Emotion Recognition Through Focus and Calibration Attention Mechanisms,0.101086,"Attention has become one of the most commonly used mechanisms in deep
learning approaches. The attention mechanism can help the system focus more on
the feature space's critical regions. For example, high amplitude regions can
play an important role for Speech Emotion Recognition (SER). In this paper, we
identify misalignments between the attention and the signal amplitude in the
existing multi-head self-attention. To improve the attention area, we propose
to use a Focus-Attention (FA) mechanism and a novel Calibration-Attention (CA)
mechanism in combination with the multi-head self-attention. Through the FA
mechanism, the network can detect the largest amplitude part in the segment. By
employing the CA mechanism, the network can modulate the information flow by
assigning different weights to each attention head and improve the utilization
of surrounding contexts. To evaluate the proposed method, experiments are
performed with the IEMOCAP and RAVDESS datasets. Experimental results show that
the proposed framework significantly outperforms the state-of-the-art
approaches on both datasets."
MPANet: Multi-Patch Attention For Infrared Small Target object Detection,0.140356,"Infrared small target detection (ISTD) has attracted widespread attention and
been applied in various fields. Due to the small size of infrared targets and
the noise interference from complex backgrounds, the performance of ISTD using
convolutional neural networks (CNNs) is restricted. Moreover, the constriant
that long-distance dependent features can not be encoded by the vanilla CNNs
also impairs the robustness of capturing targets' shapes and locations in
complex scenarios. To this end, a multi-patch attention network (MPANet) based
on the axial-attention encoder and the multi-scale patch branch (MSPB)
structure is proposed. Specially, an axial-attention-improved encoder
architecture is designed to highlight the effective features of small targets
and suppress background noises. Furthermore, the developed MSPB structure fuses
the coarse-grained and fine-grained features from different semantic scales.
Extensive experiments on the SIRST dataset show the superiority performance and
effectiveness of the proposed MPANet compared to the state-of-the-art methods."
Editable Indoor Lighting Estimation,0.0564228,"We present a method for estimating lighting from a single perspective image
of an indoor scene. Previous methods for predicting indoor illumination usually
focus on either simple, parametric lighting that lack realism, or on richer
representations that are difficult or even impossible to understand or modify
after prediction. We propose a pipeline that estimates a parametric light that
is easy to edit and allows renderings with strong shadows, alongside with a
non-parametric texture with high-frequency information necessary for realistic
rendering of specular objects. Once estimated, the predictions obtained with
our model are interpretable and can easily be modified by an artist/user with a
few mouse clicks. Quantitative and qualitative results show that our approach
makes indoor lighting estimation easier to handle by a casual user, while still
producing competitive results."
Phrase-level Textual Adversarial Attack with Label Preservation,0.0634167,"Generating high-quality textual adversarial examples is critical for
investigating the pitfalls of natural language processing (NLP) models and
further promoting their robustness. Existing attacks are usually realized
through word-level or sentence-level perturbations, which either limit the
perturbation space or sacrifice fluency and textual quality, both affecting the
attack effectiveness. In this paper, we propose Phrase-Level Textual
Adversarial aTtack (PLAT) that generates adversarial samples through
phrase-level perturbations. PLAT first extracts the vulnerable phrases as
attack targets by a syntactic parser, and then perturbs them by a pre-trained
blank-infilling model. Such flexible perturbation design substantially expands
the search space for more effective attacks without introducing too many
modifications, and meanwhile maintaining the textual fluency and grammaticality
via contextualized generation using surrounding texts. Moreover, we develop a
label-preservation filter leveraging the likelihoods of language models
fine-tuned on each class, rather than textual similarity, to rule out those
perturbations that potentially alter the original class label for humans.
Extensive experiments and human evaluation demonstrate that PLAT has a superior
attack effectiveness as well as a better label consistency than strong
baselines."
HLT-MT: High-resource Language-specific Training for Multilingual Neural Machine Translation,0.103051,"Multilingual neural machine translation (MNMT) trained in multiple language
pairs has attracted considerable attention due to fewer model parameters and
lower training costs by sharing knowledge among multiple languages.
Nonetheless, multilingual training is plagued by language interference
degeneration in shared parameters because of the negative interference among
different translation directions, especially on high-resource languages. In
this paper, we propose the multilingual translation model with the
high-resource language-specific training (HLT-MT) to alleviate the negative
interference, which adopts the two-stage training with the language-specific
selection mechanism. Specifically, we first train the multilingual model only
with the high-resource pairs and select the language-specific modules at the
top of the decoder to enhance the translation quality of high-resource
directions. Next, the model is further trained on all available corpora to
transfer knowledge from high-resource languages (HRLs) to low-resource
languages (LRLs). Experimental results show that HLT-MT outperforms various
strong baselines on WMT-10 and OPUS-100 benchmarks. Furthermore, the analytic
experiments validate the effectiveness of our method in mitigating the negative
interference in multilingual training."
Enhanced Training of Query-Based Object Detection via Selective Query Recollection,0.20579,"This paper investigates a phenomenon where query-based object detectors
mispredict at the last decoding stage while predicting correctly at an
intermediate stage. We review the training process and attribute the overlooked
phenomenon to two limitations: lack of training emphasis and cascading errors
from decoding sequence. We design and present Selective Query Recollection
(SQR), a simple and effective training strategy for query-based object
detectors. It cumulatively collects intermediate queries as decoding stages go
deeper and selectively forwards the queries to the downstream stages aside from
the sequential structure. Such-wise, SQR places training emphasis on later
stages and allows later stages to work with intermediate queries from earlier
stages directly. SQR can be easily plugged into various query-based object
detectors and significantly enhances their performance while leaving the
inference pipeline unchanged. As a result, we apply SQR on Adamixer, DAB-DETR,
and Deformable-DETR across various settings (backbone, number of queries,
schedule) and consistently brings 1.4-2.8 AP improvement."
Keep Me Updated! Memory Management in Long-term Conversations,0.0809541,"Remembering important information from the past and continuing to talk about
it in the present are crucial in long-term conversations. However, previous
literature does not deal with cases where the memorized information is
outdated, which may cause confusion in later conversations. To address this
issue, we present a novel task and a corresponding dataset of memory management
in long-term conversations, in which bots keep track of and bring up the latest
information about users while conversing through multiple sessions. In order to
support more precise and interpretable memory, we represent memory as
unstructured text descriptions of key information and propose a new mechanism
of memory management that selectively eliminates invalidated or redundant
information. Experimental results show that our approach outperforms the
baselines that leave the stored memory unchanged in terms of engagingness and
humanness, with larger performance gap especially in the later sessions."
Learning Deformable Object Manipulation from Expert Demonstrations,0.300517,"We present a novel Learning from Demonstration (LfD) method, Deformable
Manipulation from Demonstrations (DMfD), to solve deformable manipulation tasks
using states or images as inputs, given expert demonstrations. Our method uses
demonstrations in three different ways, and balances the trade-off between
exploring the environment online and using guidance from experts to explore
high dimensional spaces effectively. We test DMfD on a set of representative
manipulation tasks for a 1-dimensional rope and a 2-dimensional cloth from the
SoftGym suite of tasks, each with state and image observations. Our method
exceeds baseline performance by up to 12.9% for state-based tasks and up to
33.44% on image-based tasks, with comparable or better robustness to
randomness. Additionally, we create two challenging environments for folding a
2D cloth using image-based observations, and set a performance benchmark for
them. We deploy DMfD on a real robot with a minimal loss in normalized
performance during real-world execution compared to simulation (~6%). Source
code is on github.com/uscresl/dmfd"
Multi-level Consistency Learning for Semi-supervised Domain Adaptation,0.17978,"Semi-supervised domain adaptation (SSDA) aims to apply knowledge learned from
a fully labeled source domain to a scarcely labeled target domain. In this
paper, we propose a Multi-level Consistency Learning (MCL) framework for SSDA.
Specifically, our MCL regularizes the consistency of different views of target
domain samples at three levels: (i) at inter-domain level, we robustly and
accurately align the source and target domains using a prototype-based optimal
transport method that utilizes the pros and cons of different views of target
samples; (ii) at intra-domain level, we facilitate the learning of both
discriminative and compact target feature representations by proposing a novel
class-wise contrastive clustering loss; (iii) at sample level, we follow
standard practice and improve the prediction accuracy by conducting a
consistency-based self-training. Empirically, we verified the effectiveness of
our MCL framework on three popular SSDA benchmarks, i.e., VisDA2017, DomainNet,
and Office-Home datasets, and the experimental results demonstrate that our MCL
framework achieves the state-of-the-art performance."
Context Matters for Image Descriptions for Accessibility: Challenges for Referenceless Evaluation Metrics,0.0709868,"Few images on the Web receive alt-text descriptions that would make them
accessible to blind and low vision (BLV) users. Image-based NLG systems have
progressed to the point where they can begin to address this persistent
societal problem, but these systems will not be fully successful unless we
evaluate them on metrics that guide their development correctly. Here, we argue
against current referenceless metrics -- those that don't rely on
human-generated ground-truth descriptions -- on the grounds that they do not
align with the needs of BLV users. The fundamental shortcoming of these metrics
is that they do not take context into account, whereas contextual information
is highly valued by BLV users. To substantiate these claims, we present a study
with BLV participants who rated descriptions along a variety of dimensions. An
in-depth analysis reveals that the lack of context-awareness makes current
referenceless metrics inadequate for advancing image accessibility. As a
proof-of-concept, we provide a contextual version of the referenceless metric
CLIPScore which begins to address the disconnect to the BLV data. An accessible
HTML version of this paper is available at
https://elisakreiss.github.io/contextual-description-evaluation/paper/reflessmetrics.html"
NL2INTERFACE: Interactive Visualization Interface Generation from Natural Language Queries,0.0512775,"We develop NL2INTERFACE to explore the potential of generating usable
interactive multi-visualization interfaces from natural language queries. With
NL2INTERFACE, users can directly write natural language queries to
automatically generate a fully interactive multi-visualization interface
without any extra effort of learning a tool or programming language. Further,
users can interact with the interfaces to easily transform the data and quickly
see the results in the visualizations."
Event Collapse in Contrast Maximization Frameworks,0.314508,"Contrast maximization (CMax) is a framework that provides state-of-the-art
results on several event-based computer vision tasks, such as ego-motion or
optical flow estimation. However, it may suffer from a problem called event
collapse, which is an undesired solution where events are warped into too few
pixels. As prior works have largely ignored the issue or proposed workarounds,
it is imperative to analyze this phenomenon in detail. Our work demonstrates
event collapse in its simplest form and proposes collapse metrics by using
first principles of space-time deformation based on differential geometry and
physics. We experimentally show on publicly available datasets that the
proposed metrics mitigate event collapse and do not harm well-posed warps. To
the best of our knowledge, regularizers based on the proposed metrics are the
only effective solution against event collapse in the experimental settings
considered, compared with other methods. We hope that this work inspires
further research to tackle more complex warp models."
DKM: Dense Kernelized Feature Matching for Geometry Estimation,0.440571,"Feature matching is a challenging computer vision task that involves finding
correspondences between two images of a 3D scene. In this paper we consider the
dense approach instead of the more common sparse paradigm, thus striving to
find all correspondences. Perhaps counter-intuitively, dense methods have
previously shown inferior performance to their sparse and semi-sparse
counterparts for estimation of two-view geometry. This changes with our novel
dense method, which outperforms both dense and sparse methods on geometry
estimation. The novelty is threefold: First, we propose a kernel regression
global matcher. Secondly, we propose warp refinement through stacked feature
maps and depthwise convolution kernels. Thirdly, we propose learning dense
confidence through consistent depth and a balanced sampling approach for dense
confidence maps. Through extensive experiments we confirm that our proposed
dense method, \textbf{D}ense \textbf{K}ernelized Feature \textbf{M}atching,
sets a new state-of-the-art on multiple geometry estimation benchmarks. In
particular, we achieve an improvement on MegaDepth-1500 of +4.9 and +8.9
AUC$@5^{\circ}$ compared to the best previous sparse method and dense method
respectively. Our code is provided at https://github.com/Parskatt/dkm"
PSDoodle: Searching for App Screens via Interactive Sketching,0.0891442,"Keyword-based mobile screen search does not account for screen content and
fails to operate as a universal tool for all levels of users. Visual searching
(e.g., image, sketch) is structured and easy to adopt. Current visual search
approaches count on a complete screen and are therefore slow and tedious.
PSDoodle employs a deep neural network to recognize partial screen element
drawings instantly on a digital drawing interface and shows results in
real-time. PSDoodle is the first tool that utilizes partial sketches and
searches for screens in an interactive iterative way. PSDoodle supports
different drawing styles and retrieves search results that are relevant to the
user's sketch query. A short video demonstration is available online at:
https://youtu.be/3cVLHFm5pY4"
Search to Pass Messages for Temporal Knowledge Graph Completion,0.0207208,"Completing missing facts is a fundamental task for temporal knowledge graphs
(TKGs). Recently, graph neural network (GNN) based methods, which can
simultaneously explore topological and temporal information, have become the
state-of-the-art (SOTA) to complete TKGs. However, these studies are based on
hand-designed architectures and fail to explore the diverse topological and
temporal properties of TKG. To address this issue, we propose to use neural
architecture search (NAS) to design data-specific message passing architecture
for TKG completion. In particular, we develop a generalized framework to
explore topological and temporal information in TKGs. Based on this framework,
we design an expressive search space to fully capture various properties of
different TKGs. Meanwhile, we adopt a search algorithm, which trains a supernet
structure by sampling single path for efficient search with less cost. We
further conduct extensive experiments on three benchmark datasets. The results
show that the searched architectures by our method achieve the SOTA
performances. Besides, the searched models can also implicitly reveal diverse
properties in different TKGs. Our code is released in
https://github.com/striderdu/SPA."
CarFi: Rider Localization Using Wi-Fi CSI,0.0640184,"With the rise of hailing services, people are increasingly relying on shared
mobility (e.g., Uber, Lyft) drivers to pick up for transportation. However,
such drivers and riders have difficulties finding each other in urban areas as
GPS signals get blocked by skyscrapers, in crowded environments (e.g., in
stadiums, airports, and bars), at night, and in bad weather. It wastes their
time, creates a bad user experience, and causes more CO2 emissions due to idle
driving. In this work, we explore the potential of Wi-Fi to help drivers to
determine the street side of the riders. Our proposed system is called CarFi
that uses Wi-Fi CSI from two antennas placed inside a moving vehicle and a
data-driven technique to determine the street side of the rider. By collecting
real-world data in realistic and challenging settings by blocking the signal
with other people and other parked cars, we see that CarFi is 95.44% accurate
in rider-side determination in both line of sight (LoS) and non-line of sight
(nLoS) conditions, and can be run on an embedded GPU in real-time."
GitNet: Geometric Prior-based Transformation for Birds-Eye-View Segmentation,0.0510388,"Birds-eye-view (BEV) semantic segmentation is critical for autonomous driving
for its powerful spatial representation ability. It is challenging to estimate
the BEV semantic maps from monocular images due to the spatial gap, since it is
implicitly required to realize both the perspective-to-BEV transformation and
segmentation. We present a novel two-stage Geometry Prior-based Transformation
framework named GitNet, consisting of (i) the geometry-guided pre-alignment and
(ii) ray-based transformer. In the first stage, we decouple the BEV
segmentation into the perspective image segmentation and geometric prior-based
mapping, with explicit supervision by projecting the BEV semantic labels onto
the image plane to learn visibility-aware features and learnable geometry to
translate into BEV space. Second, the pre-aligned coarse BEV features are
further deformed by ray-based transformers to take visibility knowledge into
account. GitNet achieves the leading performance on the challenging nuScenes
and Argoverse Datasets."
A Knowledge Graph Embeddings based Approach for Author Name Disambiguation using Literals,0.0952867,"Scholarly data is growing continuously containing information about the
articles from a plethora of venues including conferences, journals, etc. Many
initiatives have been taken to make scholarly data available as Knowledge
Graphs (KGs). These efforts to standardize these data and make them accessible
have also led to many challenges such as exploration of scholarly articles,
ambiguous authors, etc. This study more specifically targets the problem of
Author Name Disambiguation (AND) on Scholarly KGs and presents a novel
framework, Literally Author Name Disambiguation (LAND), which utilizes
Knowledge Graph Embeddings (KGEs) using multimodal literal information
generated from these KGs. This framework is based on three components: 1)
Multimodal KGEs, 2) A blocking procedure, and finally, 3) Hierarchical
Agglomerative Clustering. Extensive experiments have been conducted on two
newly created KGs: (i) KG containing information from Scientometrics Journal
from 1978 onwards (OC-782K), and (ii) a KG extracted from a well-known
benchmark for AND provided by AMiner (AMiner-534K). The results show that our
proposed architecture outperforms our baselines of 8-14% in terms of the F1
score and shows competitive performances on a challenging benchmark such as
AMiner. The code and the datasets are publicly available through Github:
https://github.com/sntcristian/and-kge and
Zenodo:https://doi.org/10.5281/zenodo.6309855 respectively."
FiDO: Fusion-in-Decoder optimized for stronger performance and faster inference,0.842614,"Fusion-in-Decoder (FiD) is a powerful retrieval-augmented language model that
sets the state-of-the-art on many knowledge-intensive NLP tasks. However, the
architecture used for FiD was chosen by making minimal modifications to a
standard T5 model, which our analysis shows to be highly suboptimal for a
retrieval-augmented model. In particular, FiD allocates the bulk of FLOPs to
the encoder, while the majority of inference time results from memory bandwidth
constraints in the decoder. We propose two simple changes to the FiD
architecture to alleviate memory bandwidth constraints, and speed up inference
by 7x. This allows us to use a much larger decoder at modest cost. We denote
FiD with the above modifications as FiDO, and show that it strongly improves
performance over existing FiD models for a wide range of inference budgets. For
example, FiDO-Large-XXL performs faster inference than FiD-Base and achieves
better performance than FiD-Large."
Differentiable Point-Based Radiance Fields for Efficient View Synthesis,0.485825,"We propose a differentiable rendering algorithm for efficient novel view
synthesis. By departing from volume-based representations in favor of a learned
point representation, we improve on existing methods more than an order of
magnitude in memory and runtime, both in training and inference. The method
begins with a uniformly-sampled random point cloud and learns per-point
position and view-dependent appearance, using a differentiable splat-based
renderer to evolve the model to match a set of input images. Our method is up
to 300x faster than NeRF in both training and inference, with only a marginal
sacrifice in quality, while using less than 10~MB of memory for a static scene.
For dynamic scenes, our method trains two orders of magnitude faster than
STNeRF and renders at near interactive rate, while maintaining high image
quality and temporal coherence even without imposing any temporal-coherency
regularizers."
No Parameters Left Behind: Sensitivity Guided Adaptive Learning Rate for Training Large Transformer Models,0.0772127,"Recent research has shown the existence of significant redundancy in large
Transformer models. One can prune the redundant parameters without
significantly sacrificing the generalization performance. However, we question
whether the redundant parameters could have contributed more if they were
properly trained. To answer this question, we propose a novel training strategy
that encourages all parameters to be trained sufficiently. Specifically, we
adaptively adjust the learning rate for each parameter according to its
sensitivity, a robust gradient-based measure reflecting this parameter's
contribution to the model performance. A parameter with low sensitivity is
redundant, and we improve its fitting by increasing its learning rate. In
contrast, a parameter with high sensitivity is well-trained, and we regularize
it by decreasing its learning rate to prevent further overfitting. We conduct
extensive experiments on natural language understanding, neural machine
translation, and image classification to demonstrate the effectiveness of the
proposed schedule. Analysis shows that the proposed schedule indeed reduces the
redundancy and improves generalization performance."
User-Centric Gender Rewriting,0.151459,"In this paper, we define the task of gender rewriting in contexts involving
two users (I and/or You) - first and second grammatical persons with
independent grammatical gender preferences. We focus on Arabic, a
gender-marking morphologically rich language. We develop a multi-step system
that combines the positive aspects of both rule-based and neural rewriting
models. Our results successfully demonstrate the viability of this approach on
a recently created corpus for Arabic gender rewriting, achieving 88.42 M2 F0.5
on a blind test set. Our proposed system improves over previous work on the
first-person-only version of this task, by 3.05 absolute increase in M2 F0.5.
We demonstrate a use case of our gender rewriting system by using it to
post-edit the output of a commercial MT system to provide personalized outputs
based on the users' grammatical gender preferences. We make our code, data, and
models publicly available."
An Accelerator for Rule Induction in Fuzzy Rough Theory,0.0421142,"Rule-based classifier, that extract a subset of induced rules to efficiently
learn/mine while preserving the discernibility information, plays a crucial
role in human-explainable artificial intelligence. However, in this era of big
data, rule induction on the whole datasets is computationally intensive. So
far, to the best of our knowledge, no known method focusing on accelerating
rule induction has been reported. This is first study to consider the
acceleration technique to reduce the scale of computation in rule induction. We
propose an accelerator for rule induction based on fuzzy rough theory; the
accelerator can avoid redundant computation and accelerate the building of a
rule classifier. First, a rule induction method based on consistence degree,
called Consistence-based Value Reduction (CVR), is proposed and used as basis
to accelerate. Second, we introduce a compacted search space termed Key Set,
which only contains the key instances required to update the induced rule, to
conduct value reduction. The monotonicity of Key Set ensures the feasibility of
our accelerator. Third, a rule-induction accelerator is designed based on Key
Set, and it is theoretically guaranteed to display the same results as the
unaccelerated version. Specifically, the rank preservation property of Key Set
ensures consistency between the rule induction achieved by the accelerator and
the unaccelerated method. Finally, extensive experiments demonstrate that the
proposed accelerator can perform remarkably faster than the unaccelerated
rule-based classifier methods, especially on datasets with numerous instances."
3D Dual-Fusion: Dual-Domain Dual-Query Camera-LiDAR Fusion for 3D Object Detection,0.426232,"Fusing data from cameras and LiDAR sensors is an essential technique to
achieve robust 3D object detection. One key challenge in camera-LiDAR fusion
involves mitigating the large domain gap between the two sensors in terms of
coordinates and data distribution when fusing their features. In this paper, we
propose a novel camera-LiDAR fusion architecture called, 3D Dual-Fusion, which
is designed to mitigate the gap between the feature representations of camera
and LiDAR data. The proposed method fuses the features of the camera-view and
3D voxel-view domain and models their interactions through deformable
attention. We redesign the transformer fusion encoder to aggregate the
information from the two domains. Two major changes include 1) dual query-based
deformable attention to fuse the dual-domain features interactively and 2) 3D
local self-attention to encode the voxel-domain queries prior to dual-query
decoding. The results of an experimental evaluation show that the proposed
camera-LiDAR fusion architecture achieved competitive performance on the KITTI
and nuScenes datasets, with state-of-the-art performances in some 3D object
detection benchmarks categories."
Differentiable Inference of Temporal Logic Formulas,0.0345488,"We demonstrate the first Recurrent Neural Network architecture for learning
Signal Temporal Logic formulas, and present the first systematic comparison of
formula inference methods. Legacy systems embed much expert knowledge which is
not explicitly formalized. There is great interest in learning formal
specifications that characterize the ideal behavior of such systems -- that is,
formulas in temporal logic that are satisfied by the system's output signals.
Such specifications can be used to better understand the system's behavior and
improve design of its next iteration. Previous inference methods either assumed
certain formula templates, or did a heuristic enumeration of all possible
templates. This work proposes a neural network architecture that infers the
formula structure via gradient descent, eliminating the need for imposing any
specific templates. It combines learning of formula structure and parameters in
one optimization. Through systematic comparison, we demonstrate that this
method achieves similar or better mis-classification rates (MCR) than
enumerative and lattice methods. We also observe that different formulas can
achieve similar MCR, empirically demonstrating the under-determinism of the
problem of temporal logic inference."
NAN: Noise-Aware NeRFs for Burst-Denoising,0.106838,"Burst denoising is now more relevant than ever, as computational photography
helps overcome sensitivity issues inherent in mobile phones and small cameras.
A major challenge in burst-denoising is in coping with pixel misalignment,
which was so far handled with rather simplistic assumptions of simple motion,
or the ability to align in pre-processing. Such assumptions are not realistic
in the presence of large motion and high levels of noise. We show that Neural
Radiance Fields (NeRFs), originally suggested for physics-based novel-view
rendering, can serve as a powerful framework for burst denoising. NeRFs have an
inherent capability of handling noise as they integrate information from
multiple images, but they are limited in doing so, mainly since they build on
pixel-wise operations which are suitable to ideal imaging conditions. Our
approach, termed NAN, leverages inter-view and spatial information in NeRFs to
better deal with noise. It achieves state-of-the-art results in burst denoising
and is especially successful in coping with large movement and occlusions,
under very high levels of noise. With the rapid advances in accelerating NeRFs,
it could provide a powerful platform for denoising in challenging environments."
Improving Monocular Visual Odometry Using Learned Depth,0.0599123,"Monocular visual odometry (VO) is an important task in robotics and computer
vision. Thus far, how to build accurate and robust monocular VO systems that
can work well in diverse scenarios remains largely unsolved. In this paper, we
propose a framework to exploit monocular depth estimation for improving VO. The
core of our framework is a monocular depth estimation module with a strong
generalization capability for diverse scenes. It consists of two separate
working modes to assist the localization and mapping. With a single monocular
image input, the depth estimation module predicts a relative depth to help the
localization module on improving the accuracy. With a sparse depth map and an
RGB image input, the depth estimation module can generate accurate
scale-consistent depth for dense mapping. Compared with current learning-based
VO methods, our method demonstrates a stronger generalization ability to
diverse scenes. More significantly, our framework is able to boost the
performances of existing geometry-based VO methods by a large margin."
AdaPrompt: Adaptive Model Training for Prompt-based NLP,0.758025,"Prompt-based learning, with its capability to tackle zero-shot and few-shot
NLP tasks, has gained much attention in community. The main idea is to bridge
the gap between NLP downstream tasks and language modeling (LM), by mapping
these tasks into natural language prompts, which are then filled by pre-trained
language models (PLMs). However, for prompt learning, there are still two
salient gaps between NLP tasks and pretraining. First, prompt information is
not necessarily sufficiently present during LM pretraining. Second,
task-specific data are not necessarily well represented during pretraining. We
address these two issues by proposing AdaPrompt, adaptively retrieving external
data for continual pretraining of PLMs by making use of both task and prompt
characteristics. In addition, we make use of knowledge in Natural Language
Inference models for deriving adaptive verbalizers. Experimental results on
five NLP benchmarks show that AdaPrompt can improve over standard PLMs in
few-shot settings. In addition, in zero-shot settings, our method outperforms
standard prompt-based methods by up to 26.35\% relative error reduction."
User-Controllable Latent Transformer for StyleGAN Image Layout Editing,0.381482,"Latent space exploration is a technique that discovers interpretable latent
directions and manipulates latent codes to edit various attributes in images
generated by generative adversarial networks (GANs). However, in previous work,
spatial control is limited to simple transformations (e.g., translation and
rotation), and it is laborious to identify appropriate latent directions and
adjust their parameters. In this paper, we tackle the problem of editing the
StyleGAN image layout by annotating the image directly. To do so, we propose an
interactive framework for manipulating latent codes in accordance with the user
inputs. In our framework, the user annotates a StyleGAN image with locations
they want to move or not and specifies a movement direction by mouse dragging.
From these user inputs and initial latent codes, our latent transformer based
on a transformer encoder-decoder architecture estimates the output latent
codes, which are fed to the StyleGAN generator to obtain a result image. To
train our latent transformer, we utilize synthetic data and pseudo-user inputs
generated by off-the-shelf StyleGAN and optical flow models, without manual
supervision. Quantitative and qualitative evaluations demonstrate the
effectiveness of our method over existing methods."
Quantum policy gradient algorithms,0.0545127,"Understanding the power and limitations of quantum access to data in machine
learning tasks is primordial to assess the potential of quantum computing in
artificial intelligence. Previous works have already shown that speed-ups in
learning are possible when given quantum access to reinforcement learning
environments. Yet, the applicability of quantum algorithms in this setting
remains very limited, notably in environments with large state and action
spaces. In this work, we design quantum algorithms to train state-of-the-art
reinforcement learning policies by exploiting quantum interactions with an
environment. However, these algorithms only offer full quadratic speed-ups in
sample complexity over their classical analogs when the trained policies
satisfy some regularity conditions. Interestingly, we find that reinforcement
learning policies derived from parametrized quantum circuits are well-behaved
with respect to these conditions, which showcases the benefit of a
fully-quantum reinforcement learning framework."
Unsupervised Segmentation of Hyperspectral Remote Sensing Images with Superpixels,0.453867,"In this paper, we propose an unsupervised method for hyperspectral remote
sensing image segmentation. The method exploits the mean-shift clustering
algorithm that takes as input a preliminary hyperspectral superpixels
segmentation together with the spectral pixel information. The proposed method
does not require the number of segmentation classes as input parameter, and it
does not exploit any a-priori knowledge about the type of land-cover or
land-use to be segmented (e.g. water, vegetation, building etc.). Experiments
on Salinas, SalinasA, Pavia Center and Pavia University datasets are carried
out. Performance are measured in terms of normalized mutual information,
adjusted Rand index and F1-score. Results demonstrate the validity of the
proposed method in comparison with the state of the art."
Backdoor Attack is a Devil in Federated GAN-based Medical Image Synthesis,0.135652,"Deep Learning-based image synthesis techniques have been applied in
healthcare research for generating medical images to support open research.
Training generative adversarial neural networks (GAN) usually requires large
amounts of training data. Federated learning (FL) provides a way of training a
central model using distributed data from different medical institutions while
keeping raw data locally. However, FL is vulnerable to backdoor attack, an
adversarial by poisoning training data, given the central server cannot access
the original data directly. Most backdoor attack strategies focus on
classification models and centralized domains. In this study, we propose a way
of attacking federated GAN (FedGAN) by treating the discriminator with a
commonly used data poisoning strategy in backdoor attack classification models.
We demonstrate that adding a small trigger with size less than 0.5 percent of
the original image size can corrupt the FL-GAN model. Based on the proposed
attack, we provide two effective defense strategies: global malicious detection
and local training regularization. We show that combining the two defense
strategies yields a robust medical image generation."
Optimizing Relevance Maps of Vision Transformers Improves Robustness,0.304706,"It has been observed that visual classification models often rely mostly on
the image background, neglecting the foreground, which hurts their robustness
to distribution changes. To alleviate this shortcoming, we propose to monitor
the model's relevancy signal and manipulate it such that the model is focused
on the foreground object. This is done as a finetuning step, involving
relatively few samples consisting of pairs of images and their associated
foreground masks. Specifically, we encourage the model's relevancy map (i) to
assign lower relevance to background regions, (ii) to consider as much
information as possible from the foreground, and (iii) we encourage the
decisions to have high confidence. When applied to Vision Transformer (ViT)
models, a marked improvement in robustness to domain shifts is observed.
Moreover, the foreground masks can be obtained automatically, from a
self-supervised variant of the ViT model itself; therefore no additional
supervision is required."
Federated Learning with Position-Aware Neurons,0.153098,"Federated Learning (FL) fuses collaborative models from local nodes without
centralizing users' data. The permutation invariance property of neural
networks and the non-i.i.d. data across clients make the locally updated
parameters imprecisely aligned, disabling the coordinate-based parameter
averaging. Traditional neurons do not explicitly consider position information.
Hence, we propose Position-Aware Neurons (PANs) as an alternative, fusing
position-related values (i.e., position encodings) into neuron outputs. PANs
couple themselves to their positions and minimize the possibility of
dislocation, even updating on heterogeneous data. We turn on/off PANs to
disable/enable the permutation invariance property of neural networks. PANs are
tightly coupled with positions when applied to FL, making parameters across
clients pre-aligned and facilitating coordinate-based parameter averaging. PANs
are algorithm-agnostic and could universally improve existing FL algorithms.
Furthermore, ""FL with PANs"" is simple to implement and computationally
friendly."
Transformer Embeddings of Irregularly Spaced Events and Their Participants,0.134577,"The neural Hawkes process (Mei & Eisner, 2017) is a generative model of
irregularly spaced sequences of discrete events. To handle complex domains with
many event types, Mei et al. (2020a) further consider a setting in which each
event in the sequence updates a deductive database of facts (via
domain-specific pattern-matching rules); future events are then conditioned on
the database contents. They show how to convert such a symbolic system into a
neuro-symbolic continuous-time generative model, in which each database fact
and the possible event has a time-varying embedding that is derived from its
symbolic provenance.
  In this paper, we modify both models, replacing their recurrent LSTM-based
architectures with flatter attention-based architectures (Vaswani et al.,
2017), which are simpler and more parallelizable. This does not appear to hurt
our accuracy, which is comparable to or better than that of the original models
as well as (where applicable) previous attention-based methods (Zuo et al.,
2020; Zhang et al., 2020a)."
Anomaly detection optimization using big data and deep learning to reduce false-positive,0.125993,"Anomaly-based Intrusion Detection System (IDS) has been a hot research topic
because of its ability to detect new threats rather than only memorized
signatures threats of signature-based IDS. Especially after the availability of
advanced technologies that increase the number of hacking tools and increase
the risk impact of an attack. The problem of any anomaly-based model is its
high false-positive rate. The high false-positive rate is the reason why
anomaly IDS is not commonly applied in practice. Because anomaly-based models
classify an unseen pattern as a threat where it may be normal but not included
in the training dataset. This type of problem is called overfitting where the
model is not able to generalize. Optimizing Anomaly-based models by having a
big training dataset that includes all possible normal cases may be an optimal
solution but could not be applied in practice. Although we can increase the
number of training samples to include much more normal cases, still we need a
model that has more ability to generalize. In this research paper, we propose
applying deep model instead of traditional models because it has more ability
to generalize. Thus, we will obtain less false-positive by using big data and
deep model. We made a comparison between machine learning and deep learning
algorithms in the optimization of anomaly-based IDS by decreasing the
false-positive rate. We did an experiment on the NSL-KDD benchmark and compared
our results with one of the best used classifiers in traditional learning in
IDS optimization. The experiment shows 10% lower false-positive by using deep
learning instead of traditional learning."
Robust Local Preserving and Global Aligning Network for Adversarial Domain Adaptation,0.192469,"Unsupervised domain adaptation (UDA) requires source domain samples with
clean ground truth labels during training. Accurately labeling a large number
of source domain samples is time-consuming and laborious. An alternative is to
utilize samples with noisy labels for training. However, training with noisy
labels can greatly reduce the performance of UDA. In this paper, we address the
problem that learning UDA models only with access to noisy labels and propose a
novel method called robust local preserving and global aligning network
(RLPGA). RLPGA improves the robustness of the label noise from two aspects. One
is learning a classifier by a robust informative-theoretic-based loss function.
The other is constructing two adjacency weight matrices and two negative weight
matrices by the proposed local preserving module to preserve the local topology
structures of input data. We conduct theoretical analysis on the robustness of
the proposed RLPGA and prove that the robust informative-theoretic-based loss
and the local preserving module are beneficial to reduce the empirical risk of
the target domain. A series of empirical studies show the effectiveness of our
proposed RLPGA."
Feedback Gradient Descent: Efficient and Stable Optimization with Orthogonality for DNNs,0.0341998,"The optimization with orthogonality has been shown useful in training deep
neural networks (DNNs). To impose orthogonality on DNNs, both computational
efficiency and stability are important. However, existing methods utilizing
Riemannian optimization or hard constraints can only ensure stability while
those using soft constraints can only improve efficiency. In this paper, we
propose a novel method, named Feedback Gradient Descent (FGD), to our
knowledge, the first work showing high efficiency and stability simultaneously.
FGD induces orthogonality based on the simple yet indispensable Euler
discretization of a continuous-time dynamical system on the tangent bundle of
the Stiefel manifold. In particular, inspired by a numerical integration method
on manifolds called Feedback Integrators, we propose to instantiate it on the
tangent bundle of the Stiefel manifold for the first time. In the extensive
image classification experiments, FGD comprehensively outperforms the existing
state-of-the-art methods in terms of accuracy, efficiency, and stability."
NoisyQuant: Noisy Bias-Enhanced Post-Training Activation Quantization for Vision Transformers,-1.0,"The complicated architecture and high training cost of vision transformers
urge the exploration of post-training quantization. However, the heavy-tailed
distribution of vision transformer activations hinders the effectiveness of
previous post-training quantization methods, even with advanced quantizer
designs. Instead of tuning the quantizer to better fit the complicated
activation distribution, this paper proposes NoisyQuant, a quantizer-agnostic
enhancement for the post-training activation quantization performance of vision
transformers. We make a surprising theoretical discovery that for a given
quantizer, adding a fixed Uniform noisy bias to the values being quantized can
significantly reduce the quantization error under provable conditions. Building
on the theoretical insight, NoisyQuant achieves the first success on actively
altering the heavy-tailed activation distribution with additive noisy bias to
fit a given quantizer. Extensive experiments show NoisyQuant largely improves
the post-training quantization performance of vision transformer with minimal
computation overhead. For instance, on linear uniform 6-bit activation
quantization, NoisyQuant improves SOTA top-1 accuracy on ImageNet by up to
1.7%, 1.1% and 0.5% for ViT, DeiT, and Swin Transformer respectively, achieving
on-par or even higher performance than previous nonlinear, mixed-precision
quantization."
Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering,0.140885,"Most Outside-Knowledge Visual Question Answering (OK-VQA) systems employ a
two-stage framework that first retrieves external knowledge given the visual
question and then predicts the answer based on the retrieved content. However,
the retrieved knowledge is often inadequate. Retrievals are frequently too
general and fail to cover specific knowledge needed to answer the question.
Also, the naturally available supervision (whether the passage contains the
correct answer) is weak and does not guarantee question relevancy. To address
these issues, we propose an Entity-Focused Retrieval (EnFoRe) model that
provides stronger supervision during training and recognizes question-relevant
entities to help retrieve more specific knowledge. Experiments show that our
EnFoRe model achieves superior retrieval performance on OK-VQA, the currently
largest outside-knowledge VQA dataset. We also combine the retrieved knowledge
with state-of-the-art VQA models, and achieve a new state-of-the-art
performance on OK-VQA."
MGTR: End-to-End Mutual Gaze Detection with Transformer,0.0616853,"People's looking at each other or mutual gaze is ubiquitous in our daily
interactions, and detecting mutual gaze is of great significance for
understanding human social scenes. Current mutual gaze detection methods focus
on two-stage methods, whose inference speed is limited by the two-stage
pipeline and the performance in the second stage is affected by the first one.
In this paper, we propose a novel one-stage mutual gaze detection framework
called Mutual Gaze TRansformer or MGTR to perform mutual gaze detection in an
end-to-end manner. By designing mutual gaze instance triples, MGTR can detect
each human head bounding box and simultaneously infer mutual gaze relationship
based on global image information, which streamlines the whole process with
simplicity. Experimental results on two mutual gaze datasets show that our
method is able to accelerate mutual gaze detection process without losing
performance. Ablation study shows that different components of MGTR can capture
different levels of semantic information in images. Code is available at
https://github.com/Gmbition/MGTR"
Revealing interactions between HVDC cross-area flows and frequency stability with explainable AI,0.0838132,"The energy transition introduces more volatile energy sources into the power
grids. In this context, power transfer between different synchronous areas
through High Voltage Direct Current (HVDC) links becomes increasingly
important. Such links can balance volatile generation by enabling long-distance
transport or by leveraging their fast control behavior. Here, we investigate
the interaction of power imbalances - represented through the power grid
frequency - and power flows on HVDC links between synchronous areas in Europe.
We use explainable machine learning to identify key dependencies and
disentangle the interaction of critical features. Our results show that
market-based HVDC flows introduce deterministic frequency deviations, which
however can be mitigated through strict ramping limits. Moreover, varying HVDC
operation modes strongly affect the interaction with the grid. In particular,
we show that load-frequency control via HVDC links can both have control-like
or disturbance-like impacts on frequency stability."
"Global Counterfactual Explanations: Investigations, Implementations and Improvements",0.15848,"Counterfactual explanations have been widely studied in explainability, with
a range of application dependent methods emerging in fairness, recourse and
model understanding. However, the major shortcoming associated with these
methods is their inability to provide explanations beyond the local or
instance-level. While some works touch upon the notion of a global explanation,
typically suggesting to aggregate masses of local explanations in the hope of
ascertaining global properties, few provide frameworks that are either reliable
or computationally tractable. Meanwhile, practitioners are requesting more
efficient and interactive explainability tools. We take this opportunity to
investigate existing global methods, with a focus on implementing and improving
Actionable Recourse Summaries (AReS), the only known global counterfactual
explanation framework for recourse."
Help Me Explore: Minimal Social Interventions for Graph-Based Autotelic Agents,0.076653,"In the quest for autonomous agents learning open-ended repertoires of skills,
most works take a Piagetian perspective: learning trajectories are the results
of interactions between developmental agents and their physical environment.
The Vygotskian perspective, on the other hand, emphasizes the centrality of the
socio-cultural environment: higher cognitive functions emerge from
transmissions of socio-cultural processes internalized by the agent. This paper
argues that both perspectives could be coupled within the learning of autotelic
agents to foster their skill acquisition. To this end, we make two
contributions: 1) a novel social interaction protocol called Help Me Explore
(HME), where autotelic agents can benefit from both individual and socially
guided exploration. In social episodes, a social partner suggests goals at the
frontier of the learning agent knowledge. In autotelic episodes, agents can
either learn to master their own discovered goals or autonomously rehearse
failed social goals; 2) GANGSTR, a graph-based autotelic agent for manipulation
domains capable of decomposing goals into sequences of intermediate sub-goals.
We show that when learning within HME, GANGSTR overcomes its individual
learning limits by mastering the most complex configurations (e.g. stacks of 5
blocks) with only few social interventions."
Mediators: Conversational Agents Explaining NLP Model Behavior,0.0212622,"The human-centric explainable artificial intelligence (HCXAI) community has
raised the need for framing the explanation process as a conversation between
human and machine. In this position paper, we establish desiderata for
Mediators, text-based conversational agents which are capable of explaining the
behavior of neural models interactively using natural language. From the
perspective of natural language processing (NLP) research, we engineer a
blueprint of such a Mediator for the task of sentiment analysis and assess how
far along current research is on the path towards dialogue-based explanations."
FNeVR: Neural Volume Rendering for Face Animation,-1.0,"Face animation, one of the hottest topics in computer vision, has achieved a
promising performance with the help of generative models. However, it remains a
critical challenge to generate identity preserving and photo-realistic images
due to the sophisticated motion deformation and complex facial detail modeling.
To address these problems, we propose a Face Neural Volume Rendering (FNeVR)
network to fully explore the potential of 2D motion warping and 3D volume
rendering in a unified framework. In FNeVR, we design a 3D Face Volume
Rendering (FVR) module to enhance the facial details for image rendering.
Specifically, we first extract 3D information with a well-designed
architecture, and then introduce an orthogonal adaptive ray-sampling module for
efficient rendering. We also design a lightweight pose editor, enabling FNeVR
to edit the facial pose in a simple yet effective way. Extensive experiments
show that our FNeVR obtains the best overall quality and performance on widely
used talking-head benchmarks."
Diagnostics for Deep Neural Networks with Automated Copy/Paste Attacks,0.154868,"This paper considers the problem of helping humans exercise scalable
oversight over deep neural networks (DNNs). Adversarial examples can be useful
by helping to reveal weaknesses in DNNs, but they can be difficult to interpret
or draw actionable conclusions from. Some previous works have proposed using
human-interpretable adversarial attacks including copy/paste attacks in which
one natural image pasted into another causes an unexpected misclassification.
We build on these with two contributions. First, we introduce Search for
Natural Adversarial Features Using Embeddings (SNAFUE) which offers a fully
automated method for finding copy/paste attacks. Second, we use SNAFUE to red
team an ImageNet classifier. We reproduce copy/paste attacks from previous
works and find hundreds of other easily-describable vulnerabilities, all
without a human in the loop. Code is available at
https://github.com/thestephencasper/snafue"
Robust Region Feature Synthesizer for Zero-Shot Object Detection,0.167227,"Zero-shot object detection aims at incorporating class semantic vectors to
realize the detection of (both seen and) unseen classes given an unconstrained
test image. In this study, we reveal the core challenges in this research area:
how to synthesize robust region features (for unseen objects) that are as
intra-class diverse and inter-class separable as the real samples, so that
strong unseen object detectors can be trained upon them. To address these
challenges, we build a novel zero-shot object detection framework that contains
an Intra-class Semantic Diverging component and an Inter-class Structure
Preserving component. The former is used to realize the one-to-more mapping to
obtain diverse visual features from each class semantic vector, preventing
miss-classifying the real unseen objects as image backgrounds. While the latter
is used to avoid the synthesized features too scattered to mix up the
inter-class and foreground-background relationship. To demonstrate the
effectiveness of the proposed approach, comprehensive experiments on PASCAL
VOC, COCO, and DIOR datasets are conducted. Notably, our approach achieves the
new state-of-the-art performance on PASCAL VOC and COCO and it is the first
study to carry out zero-shot object detection in remote sensing imagery."
Ensembles for Uncertainty Estimation: Benefits of Prior Functions and Bootstrapping,0.0,"In machine learning, an agent needs to estimate uncertainty to efficiently
explore and adapt and to make effective decisions. A common approach to
uncertainty estimation maintains an ensemble of models. In recent years,
several approaches have been proposed for training ensembles, and conflicting
views prevail with regards to the importance of various ingredients of these
approaches. In this paper, we aim to address the benefits of two ingredients --
prior functions and bootstrapping -- which have come into question. We show
that prior functions can significantly improve an ensemble agent's joint
predictions across inputs and that bootstrapping affords additional benefits if
the signal-to-noise ratio varies across inputs. Our claims are justified by
both theoretical and experimental results."
UniCLIP: Unified Framework for Contrastive Language-Image Pre-training,0.976482,"Pre-training vision-language models with contrastive objectives has shown
promising results that are both scalable to large uncurated datasets and
transferable to many downstream applications. Some following works have
targeted to improve data efficiency by adding self-supervision terms, but
inter-domain (image-text) contrastive loss and intra-domain (image-image)
contrastive loss are defined on individual spaces in those works, so many
feasible combinations of supervision are overlooked. To overcome this issue, we
propose UniCLIP, a Unified framework for Contrastive Language-Image
Pre-training. UniCLIP integrates the contrastive loss of both inter-domain
pairs and intra-domain pairs into a single universal space. The discrepancies
that occur when integrating contrastive loss between different domains are
resolved by the three key components of UniCLIP: (1) augmentation-aware feature
embedding, (2) MP-NCE loss, and (3) domain dependent similarity measure.
UniCLIP outperforms previous vision-language pre-training methods on various
single- and multi-modality downstream tasks. In our experiments, we show that
each component that comprises UniCLIP contributes well to the final
performance."
LCP-dropout: Compression-based Multiple Subword Segmentation for Neural Machine Translation,0.0145887,"In this study, we propose a simple and effective preprocessing method for
subword segmentation based on a data compression algorithm. Compression-based
subword segmentation has recently attracted significant attention as a
preprocessing method for training data in Neural Machine Translation. Among
them, BPE/BPE-dropout is one of the fastest and most effective method compared
to conventional approaches. However, compression-based approach has a drawback
in that generating multiple segmentations is difficult due to the determinism.
To overcome this difficulty, we focus on a probabilistic string algorithm,
called locally-consistent parsing (LCP), that has been applied to achieve
optimum compression. Employing the probabilistic mechanism of LCP, we propose
LCP-dropout for multiple subword segmentation that improves BPE/BPE-dropout,
and show that it outperforms various baselines in learning from especially
small training data."
ReSel: N-ary Relation Extraction from Scientific Text and Tables by Learning to Retrieve and Select,0.56112,"We study the problem of extracting N-ary relation tuples from scientific
articles. This task is challenging because the target knowledge tuples can
reside in multiple parts and modalities of the document. Our proposed method
ReSel decomposes this task into a two-stage procedure that first retrieves the
most relevant paragraph/table and then selects the target entity from the
retrieved component. For the high-level retrieval stage, ReSel designs a simple
and effective feature set, which captures multi-level lexical and semantic
similarities between the query and components. For the low-level selection
stage, ReSel designs a cross-modal entity correlation graph along with a
multi-view architecture, which models both semantic and document-structural
relations between entities. Our experiments on three scientific information
extraction datasets show that ReSel outperforms state-of-the-art baselines
significantly."
Learning Personalized Human-Aware Robot Navigation Using Virtual Reality Demonstrations from a User Study,0.0570904,"For the most comfortable, human-aware robot navigation, subjective user
preferences need to be taken into account. This paper presents a novel
reinforcement learning framework to train a personalized navigation controller
along with an intuitive virtual reality demonstration interface. The conducted
user study provides evidence that our personalized approach significantly
outperforms classical approaches with more comfortable human-robot experiences.
We achieve these results using only a few demonstration trajectories from
non-expert users, who predominantly appreciate the intuitive demonstration
setup. As we show in the experiments, the learned controller generalizes well
to states not covered in the demonstration data, while still reflecting user
preferences during navigation. Finally, we transfer the navigation controller
without loss in performance to a real robot."
Self-Sustaining Representation Expansion for Non-Exemplar Class-Incremental Learning,0.499211,"Non-exemplar class-incremental learning is to recognize both the old and new
classes when old class samples cannot be saved. It is a challenging task since
representation optimization and feature retention can only be achieved under
supervision from new classes. To address this problem, we propose a novel
self-sustaining representation expansion scheme. Our scheme consists of a
structure reorganization strategy that fuses main-branch expansion and
side-branch updating to maintain the old features, and a main-branch
distillation scheme to transfer the invariant knowledge. Furthermore, a
prototype selection mechanism is proposed to enhance the discrimination between
the old and new classes by selectively incorporating new samples into the
distillation process. Extensive experiments on three benchmarks demonstrate
significant incremental performance, outperforming the state-of-the-art methods
by a margin of 3%, 3% and 6%, respectively."
Online Easy Example Mining for Weakly-supervised Gland Segmentation from Histology Images,0.13716,"Developing an AI-assisted gland segmentation method from histology images is
critical for automatic cancer diagnosis and prognosis; however, the high cost
of pixel-level annotations hinders its applications to broader diseases.
Existing weakly-supervised semantic segmentation methods in computer vision
achieve degenerative results for gland segmentation, since the characteristics
and problems of glandular datasets are different from general object datasets.
We observe that, unlike natural images, the key problem with histology images
is the confusion of classes owning to morphological homogeneity and low color
contrast among different tissues. To this end, we propose a novel method Online
Easy Example Mining (OEEM) that encourages the network to focus on credible
supervision signals rather than noisy signals, therefore mitigating the
influence of inevitable false predictions in pseudo-masks. According to the
characteristics of glandular datasets, we design a strong framework for gland
segmentation. Our results exceed many fully-supervised methods and
weakly-supervised methods for gland segmentation over 4.4% and 6.04% at mIoU,
respectively. Code is available at https://github.com/xmed-lab/OEEM."
Real Time Egocentric Segmentation for Video-self Avatar in Mixed Reality,0.0571824,"In this work we present our real-time egocentric body segmentation algorithm.
Our algorithm achieves a frame rate of 66 fps for an input resolution of
640x480, thanks to our shallow network inspired in Thundernet's architecture.
Besides, we put a strong emphasis on the variability of the training data. More
concretely, we describe the creation process of our Egocentric Bodies
(EgoBodies) dataset, composed of almost 10,000 images from three datasets,
created both from synthetic methods and real capturing. We conduct experiments
to understand the contribution of the individual datasets; compare Thundernet
model trained with EgoBodies with simpler and more complex previous approaches
and discuss their corresponding performance in a real-life setup in terms of
segmentation quality and inference times. The described trained semantic
segmentation algorithm is already integrated in an end-to-end system for Mixed
Reality (MR), making it possible for users to see his/her own body while being
immersed in a MR scene."
"Sampling-based inference for large linear models, with application to linearised Laplace",0.0546013,"Large-scale linear models are ubiquitous throughout machine learning, with
contemporary application as surrogate models for neural network uncertainty
quantification; that is, the linearised Laplace method. Alas, the computational
cost associated with Bayesian linear models constrains this method's
application to small networks, small output spaces and small datasets. We
address this limitation by introducing a scalable sample-based Bayesian
inference method for conjugate Gaussian multi-output linear models, together
with a matching method for hyperparameter (regularisation) selection.
Furthermore, we use a classic feature normalisation method (the g-prior) to
resolve a previously highlighted pathology of the linearised Laplace method.
Together, these contributions allow us to perform linearised neural network
inference with ResNet-18 on CIFAR100 (11M parameters, 100 outputs x 50k
datapoints), with ResNet-50 on Imagenet (50M parameters, 1000 outputs x 1.2M
datapoints) and with a U-Net on a high-resolution tomographic reconstruction
task (2M parameters, 251k output~dimensions)."
AugTriever: Unsupervised Dense Retrieval by Scalable Data Augmentation,0.105288,"Dense retrievers have made significant strides in text retrieval and
open-domain question answering, even though most achievements were made
possible only with large amounts of human supervision. In this work, we aim to
develop unsupervised methods by proposing two methods that create pseudo
query-document pairs and train dense retrieval models in an annotation-free and
scalable manner: query extraction and transferred query generation. The former
method produces pseudo queries by selecting salient spans from the original
document. The latter utilizes generation models trained for other NLP tasks
(e.g., summarization) to produce pseudo queries. Extensive experiments show
that models trained with the proposed augmentation methods can perform
comparably well (or better) to multiple strong baselines. Combining those
strategies leads to further improvements, achieving the state-of-the-art
performance of unsupervised dense retrieval on both BEIR and ODQA datasets."
HYPRO: A Hybridly Normalized Probabilistic Model for Long-Horizon Prediction of Event Sequences,0.589843,"In this paper, we tackle the important yet under-investigated problem of
making long-horizon prediction of event sequences. Existing state-of-the-art
models do not perform well at this task due to their autoregressive structure.
We propose HYPRO, a hybridly normalized probabilistic model that naturally fits
this task: its first part is an autoregressive base model that learns to
propose predictions; its second part is an energy function that learns to
reweight the proposals such that more realistic predictions end up with higher
probabilities. We also propose efficient training and inference algorithms for
this model. Experiments on multiple real-world datasets demonstrate that our
proposed HYPRO model can significantly outperform previous models at making
long-horizon predictions of future events. We also conduct a range of ablation
studies to investigate the effectiveness of each component of our proposed
methods."
Audio-Adaptive Activity Recognition Across Video Domains,0.385063,"This paper strives for activity recognition under domain shift, for example
caused by change of scenery or camera viewpoint. The leading approaches reduce
the shift in activity appearance by adversarial training and self-supervised
learning. Different from these vision-focused works we leverage activity sounds
for domain adaptation as they have less variance across domains and can
reliably indicate which activities are not happening. We propose an
audio-adaptive encoder and associated learning methods that discriminatively
adjust the visual feature representation as well as addressing shifts in the
semantic distribution. To further eliminate domain-specific features and
include domain-invariant activity sounds for recognition, an audio-infused
recognizer is proposed, which effectively models the cross-modal interaction
across domains. We also introduce the new task of actor shift, with a
corresponding audio-visual dataset, to challenge our method with situations
where the activity appearance changes dramatically. Experiments on this
dataset, EPIC-Kitchens and CharadesEgo show the effectiveness of our approach."
Unified Vision and Language Prompt Learning,0.515446,"Prompt tuning, a parameter- and data-efficient transfer learning paradigm
that tunes only a small number of parameters in a model's input space, has
become a trend in the vision community since the emergence of large
vision-language models like CLIP. We present a systematic study on two
representative prompt tuning methods, namely text prompt tuning and visual
prompt tuning. A major finding is that none of the unimodal prompt tuning
methods performs consistently well: text prompt tuning fails on data with high
intra-class visual variances while visual prompt tuning cannot handle low
inter-class variances. To combine the best from both worlds, we propose a
simple approach called Unified Prompt Tuning (UPT), which essentially learns a
tiny neural network to jointly optimize prompts across different modalities.
Extensive experiments on over 11 vision datasets show that UPT achieves a
better trade-off than the unimodal counterparts on few-shot learning
benchmarks, as well as on domain generalization benchmarks. Code and models
will be released to facilitate future research."
"Env-Aware Anomaly Detection: Ignore Style Changes, Stay True to Content!",0.205522,"We introduce a formalization and benchmark for the unsupervised anomaly
detection task in the distribution-shift scenario. Our work builds upon the
iWildCam dataset, and, to the best of our knowledge, we are the first to
propose such an approach for visual data. We empirically validate that
environment-aware methods perform better in such cases when compared with the
basic Empirical Risk Minimization (ERM). We next propose an extension for
generating positive samples for contrastive methods that considers the
environment labels when training, improving the ERM baseline score by 8.7%."
Claim-Dissector: An Interpretable Fact-Checking System with Joint Re-ranking and Veracity Prediction,0.0834575,"We present Claim-Dissector: a novel latent variable model for fact-checking
and analysis, which given a claim and a set of retrieved evidences jointly
learns to identify: (i) the relevant evidences to the given claim, (ii) the
veracity of the claim. We propose to disentangle the per-evidence relevance
probability and its contribution to the final veracity probability in an
interpretable way -- the final veracity probability is proportional to a linear
ensemble of per-evidence relevance probabilities. In this way, the individual
contributions of evidences towards the final predicted probability can be
identified. In per-evidence relevance probability, our model can further
distinguish whether each relevant evidence is supporting (S) or refuting (R)
the claim. This allows to quantify how much the S/R probability contributes to
the final verdict or to detect disagreeing evidence.
  Despite its interpretable nature, our system achieves results competitive
with state-of-the-art on the FEVER dataset, as compared to typical two-stage
system pipelines, while using significantly fewer parameters. It also sets new
state-of-the-art on FAVIQ and RealFC datasets. Furthermore, our analysis shows
that our model can learn fine-grained relevance cues while using coarse-grained
supervision, and we demonstrate it in 2 ways. (i) We show that our model can
achieve competitive sentence recall while using only paragraph-level relevance
supervision. (ii) Traversing towards the finest granularity of relevance, we
show that our model is capable of identifying relevance at the token level. To
do this, we present a new benchmark TLR-FEVER focusing on token-level
interpretability -- humans annotate tokens in relevant evidences they
considered essential when making their judgment. Then we measure how similar
are these annotations to the tokens our model is focusing on."
ImplantFormer: Vision Transformer based Implant Position Regression Using Dental CBCT Data,0.140551,"Implant prosthesis is the most appropriate treatment for dentition defect or
dentition loss, which usually involves a surgical guide design process to
decide the implant position. However, such design heavily relies on the
subjective experiences of dentists. In this paper, a transformer-based Implant
Position Regression Network, ImplantFormer, is proposed to automatically
predict the implant position based on the oral CBCT data. We creatively propose
to predict the implant position using the 2D axial view of the tooth crown area
and fit a centerline of the implant to obtain the actual implant position at
the tooth root. Convolutional stem and decoder are designed to coarsely extract
image features before the operation of patch embedding and integrate
multi-level feature maps for robust prediction, respectively. As both
long-range relationship and local features are involved, our approach can
better represent global information and achieves better location performance.
Extensive experiments on a dental implant dataset through five-fold
cross-validation demonstrated that the proposed ImplantFormer achieves superior
performance than existing methods."
Generative Pretraining for Black-Box Optimization,0.073136,"Many problems in science and engineering involve optimizing an expensive
black-box function over a high-dimensional space. For such black-box
optimization (BBO) problems, we typically assume a small budget for online
function evaluations, but also often have access to a fixed, offline dataset
for pretraining. Prior approaches seek to utilize the offline data to
approximate the function or its inverse but are not sufficiently accurate far
from the data distribution. We propose BONET, a generative framework for
pretraining a novel black-box optimizer using offline datasets. In BONET, we
train an autoregressive model on fixed-length trajectories derived from an
offline dataset. We design a sampling strategy to synthesize trajectories from
offline data using a simple heuristic of rolling out monotonic transitions from
low-fidelity to high-fidelity samples. Empirically, we instantiate BONET using
a causally masked Transformer and evaluate it on Design-Bench, where we rank
the best on average, outperforming state-of-the-art baselines."
Breaking Bad News in the Era of Artificial Intelligence and Algorithmic Medicine: An Exploration of Disclosure and its Ethical Justification using the Hedonic Calculus,0.0,"An appropriate ethical framework around the use of Artificial Intelligence
(AI) in healthcare has become a key desirable with the increasingly widespread
deployment of this technology. Advances in AI hold the promise of improving the
precision of outcome prediction at the level of the individual. However, the
addition of these technologies to patient-clinician interactions, as with any
complex human interaction, has potential pitfalls. While physicians have always
had to carefully consider the ethical background and implications of their
actions, detailed deliberations around fast-moving technological progress may
not have kept up. We use a common but key challenge in healthcare interactions,
the disclosure of bad news (likely imminent death), to illustrate how the
philosophical framework of the 'Felicific Calculus' developed in the 18th
century by Jeremy Bentham, may have a timely quasi-quantitative application in
the age of AI. We show how this ethical algorithm can be used to assess, across
seven mutually exclusive and exhaustive domains, whether an AI-supported action
can be morally justified."
SARAS-Net: Scale and Relation Aware Siamese Network for Change Detection,0.0279308,"Change detection (CD) aims to find the difference between two images at
different times and outputs a change map to represent whether the region has
changed or not. To achieve a better result in generating the change map, many
State-of-The-Art (SoTA) methods design a deep learning model that has a
powerful discriminative ability. However, these methods still get lower
performance because they ignore spatial information and scaling changes between
objects, giving rise to blurry or wrong boundaries. In addition to these, they
also neglect the interactive information of two different images. To alleviate
these problems, we propose our network, the Scale and Relation-Aware Siamese
Network (SARAS-Net) to deal with this issue. In this paper, three modules are
proposed that include relation-aware, scale-aware, and cross-transformer to
tackle the problem of scene change detection more effectively. To verify our
model, we tested three public datasets, including LEVIR-CD, WHU-CD, and DSFIN,
and obtained SoTA accuracy. Our code is available at
https://github.com/f64051041/SARAS-Net."
Meta-Learning Sparse Compression Networks,0.0702609,"Recent work in Deep Learning has re-imagined the representation of data as
functions mapping from a coordinate space to an underlying continuous signal.
When such functions are approximated by neural networks this introduces a
compelling alternative to the more common multi-dimensional array
representation. Recent work on such Implicit Neural Representations (INRs) has
shown that - following careful architecture search - INRs can outperform
established compression methods such as JPEG (e.g. Dupont et al., 2021). In
this paper, we propose crucial steps towards making such ideas scalable:
Firstly, we employ state-of-the-art network sparsification techniques to
drastically improve compression. Secondly, introduce the first method allowing
for sparsification to be employed in the inner-loop of commonly used
Meta-Learning algorithms, drastically improving both compression and the
computational cost of learning INRs. The generality of this formalism allows us
to present results on diverse data modalities such as images, manifolds, signed
distance functions, 3D shapes and scenes, several of which establish new
state-of-the-art results."
StepGame: A New Benchmark for Robust Multi-Hop Spatial Reasoning in Texts,0.547094,"Inferring spatial relations in natural language is a crucial ability an
intelligent system should possess. The bAbI dataset tries to capture tasks
relevant to this domain (task 17 and 19). However, these tasks have several
limitations. Most importantly, they are limited to fixed expressions, they are
limited in the number of reasoning steps required to solve them, and they fail
to test the robustness of models to input that contains irrelevant or redundant
information. In this paper, we present a new Question-Answering dataset called
StepGame for robust multi-hop spatial reasoning in texts. Our experiments
demonstrate that state-of-the-art models on the bAbI dataset struggle on the
StepGame dataset. Moreover, we propose a Tensor-Product based Memory-Augmented
Neural Network (TP-MANN) specialized for spatial reasoning tasks. Experimental
results on both datasets show that our model outperforms all the baselines with
superior generalization and robustness performance."
Gaussian Multi-head Attention for Simultaneous Machine Translation,0.299599,"Simultaneous machine translation (SiMT) outputs translation while receiving
the streaming source inputs, and hence needs a policy to determine where to
start translating. The alignment between target and source words often implies
the most informative source word for each target word, and hence provides the
unified control over translation quality and latency, but unfortunately the
existing SiMT methods do not explicitly model the alignment to perform the
control. In this paper, we propose Gaussian Multi-head Attention (GMA) to
develop a new SiMT policy by modeling alignment and translation in a unified
manner. For SiMT policy, GMA models the aligned source position of each target
word, and accordingly waits until its aligned position to start translating. To
integrate the learning of alignment into the translation model, a Gaussian
distribution centered on predicted aligned position is introduced as an
alignment-related prior, which cooperates with translation-related soft
attention to determine the final attention. Experiments on En-Vi and De-En
tasks show that our method outperforms strong baselines on the trade-off
between translation and latency."
Classification of Hyperspectral Images Using SVM with Shape-adaptive Reconstruction and Smoothed Total Variation,0.0523907,"In this work, a novel algorithm called SVM with Shape-adaptive Reconstruction
and Smoothed Total Variation (SaR-SVM-STV) is introduced to classify
hyperspectral images, which makes full use of spatial and spectral information.
The Shape-adaptive Reconstruction (SaR) is introduced to preprocess each pixel
based on the Pearson Correlation between pixels in its shape-adaptive (SA)
region. Support Vector Machines (SVMs) are trained to estimate the pixel-wise
probability maps of each class. Then the Smoothed Total Variation (STV) model
is applied to denoise and generate the final classification map. Experiments
show that SaR-SVM-STV outperforms the SVM-STV method with a few training
labels, demonstrating the significance of reconstructing hyperspectral images
before classification."
RangeUDF: Semantic Surface Reconstruction from 3D Point Clouds,0.0692941,"We present RangeUDF, a new implicit representation based framework to recover
the geometry and semantics of continuous 3D scene surfaces from point clouds.
Unlike occupancy fields or signed distance fields which can only model closed
3D surfaces, our approach is not restricted to any type of topology. Being
different from the existing unsigned distance fields, our framework does not
suffer from any surface ambiguity. In addition, our RangeUDF can jointly
estimate precise semantics for continuous surfaces. The key to our approach is
a range-aware unsigned distance function together with a surface-oriented
semantic segmentation module. Extensive experiments show that RangeUDF clearly
surpasses state-of-the-art approaches for surface reconstruction on four point
cloud datasets. Moreover, RangeUDF demonstrates superior generalization
capability across multiple unseen datasets, which is nearly impossible for all
existing approaches."
CORL: Research-oriented Deep Offline Reinforcement Learning Library,0.482613,"CORL is an open-source library that provides thoroughly benchmarked
single-file implementations of both deep offline and offline-to-online
reinforcement learning algorithms. It emphasizes a simple developing experience
with a straightforward codebase and a modern analysis tracking tool. In CORL,
we isolate methods implementation into separate single files, making
performance-relevant details easier to recognize. Additionally, an experiment
tracking feature is available to help log metrics, hyperparameters,
dependencies, and more to the cloud. Finally, we have ensured the reliability
of the implementations by benchmarking commonly employed D4RL datasets
providing a transparent source of results that can be reused for robust
evaluation tools such as performance profiles, probability of improvement, or
expected online performance."
S$^2$SQL: Injecting Syntax to Question-Schema Interaction Graph Encoder for Text-to-SQL Parsers,0.656669,"The task of converting a natural language question into an executable SQL
query, known as text-to-SQL, is an important branch of semantic parsing. The
state-of-the-art graph-based encoder has been successfully used in this task
but does not model the question syntax well. In this paper, we propose
S$^2$SQL, injecting Syntax to question-Schema graph encoder for Text-to-SQL
parsers, which effectively leverages the syntactic dependency information of
questions in text-to-SQL to improve the performance. We also employ the
decoupling constraint to induce diverse relational edge embedding, which
further improves the network's performance. Experiments on the Spider and
robustness setting Spider-Syn demonstrate that the proposed approach
outperforms all existing methods when pre-training models are used, resulting
in a performance ranks first on the Spider leaderboard."
Private Quantiles Estimation in the Presence of Atoms,0.0431577,"We consider the differentially private estimation of multiple quantiles (MQ)
of a distribution from a dataset, a key building block in modern data analysis.
We apply the recent non-smoothed Inverse Sensitivity (IS) mechanism to this
specific problem. We establish that the resulting method is closely related to
the recently published ad hoc algorithm JointExp. In particular, they share the
same computational complexity and a similar efficiency. We prove the
statistical consistency of these two algorithms for continuous distributions.
Furthermore, we demonstrate both theoretically and empirically that this method
suffers from an important lack of performance in the case of peaked
distributions, which can degrade up to a potentially catastrophic impact in the
presence of atoms. Its smoothed version (i.e. by applying a max kernel to its
output density) would solve this problem, but remains an open challenge to
implement. As a proxy, we propose a simple and numerically efficient method
called Heuristically Smoothed JointExp (HSJointExp), which is endowed with
performance guarantees for a broad class of distributions and achieves results
that are orders of magnitude better on problematic datasets."
MoEC: Mixture of Expert Clusters,0.202376,"Sparsely Mixture of Experts (MoE) has received great interest due to its
promising scaling capability with affordable computational overhead. MoE
converts dense layers into sparse experts, and utilizes a gated routing network
to make experts conditionally activated. However, as the number of experts
grows, MoE with outrageous parameters suffers from overfitting and sparse data
allocation. Such problems are especially severe on tasks with limited data,
thus hindering the progress for MoE models to improve performance by scaling
up. In this work, we propose Mixture of Expert Clusters - a general approach to
enable expert layers to learn more diverse and appropriate knowledge by
imposing variance-based constraints on the routing stage. We further propose a
cluster-level expert dropout strategy specifically designed for the expert
cluster structure. Our experiments reveal that MoEC could improve performance
on machine translation and natural language understanding tasks, and raise the
performance upper bound for scaling up experts under limited data. We also
verify that MoEC plays a positive role in mitigating overfitting and sparse
data allocation."
Impact of Tokenization on Language Models: An Analysis for Turkish,0.113866,"Tokenization is an important text preprocessing step to prepare input tokens
for deep language models. WordPiece and BPE are de facto methods employed by
important models, such as BERT and GPT. However, the impact of tokenization can
be different for morphologically rich languages, such as Turkic languages,
where many words can be generated by adding prefixes and suffixes. We compare
five tokenizers at different granularity levels, i.e. their outputs vary from
smallest pieces of characters to the surface form of words, including a
Morphological-level tokenizer. We train these tokenizers and pretrain
medium-sized language models using RoBERTa pretraining procedure on the Turkish
split of the OSCAR corpus. We then fine-tune our models on six downstream
tasks. Our experiments, supported by statistical tests, reveal that
Morphological-level tokenizer has challenging performance with de facto
tokenizers. Furthermore, we find that increasing the vocabulary size improves
the performance of Morphological and Word-level tokenizers more than that of de
facto tokenizers. The ratio of the number of vocabulary parameters to the total
number of model parameters can be empirically chosen as 20% for de facto
tokenizers and 40% for other tokenizers to obtain a reasonable trade-off
between model size and performance."
Towards Equalised Odds as Fairness Metric in Academic Performance Prediction,0.02998,"The literature for fairness-aware machine learning knows a plethora of
different fairness notions. It is however wellknown, that it is impossible to
satisfy all of them, as certain notions contradict each other. In this paper,
we take a closer look at academic performance prediction (APP) systems and try
to distil which fairness notions suit this task most. For this, we scan recent
literature proposing guidelines as to which fairness notion to use and apply
these guidelines onto APP. Our findings suggest equalised odds as most suitable
notion for APP, based on APP's WYSIWYG worldview as well as potential long-term
improvements for the population."
SVG Vector Font Generation for Chinese Characters with Transformer,0.269779,"Designing fonts for Chinese characters is highly labor-intensive and
time-consuming. While the latest methods successfully generate the English
alphabet vector font, despite the high demand for automatic font generation,
Chinese vector font generation has been an unsolved problem owing to its
complex shape and numerous characters. This study addressed the problem of
automatically generating Chinese vector fonts from only a single style and
content reference. We proposed a novel network architecture with Transformer
and loss functions to capture structural features without differentiable
rendering. Although the dataset range was still limited to the sans-serif
family, we successfully generated the Chinese vector font for the first time
using the proposed method."
Generating Multiple-Length Summaries via Reinforcement Learning for Unsupervised Sentence Summarization,0.0286216,"Sentence summarization shortens given texts while maintaining core contents
of the texts. Unsupervised approaches have been studied to summarize texts
without human-written summaries. However, recent unsupervised models are
extractive, which remove words from texts and thus they are less flexible than
abstractive summarization. In this work, we devise an abstractive model based
on reinforcement learning without ground-truth summaries. We formulate the
unsupervised summarization based on the Markov decision process with rewards
representing the summary quality. To further enhance the summary quality, we
develop a multi-summary learning mechanism that generates multiple summaries
with varying lengths for a given text, while making the summaries mutually
enhance each other. Experimental results show that the proposed model
substantially outperforms both abstractive and extractive models, yet
frequently generating new words not contained in input texts."
Proximal PanNet: A Model-Based Deep Network for Pansharpening,0.0667985,"Recently, deep learning techniques have been extensively studied for
pansharpening, which aims to generate a high resolution multispectral (HRMS)
image by fusing a low resolution multispectral (LRMS) image with a high
resolution panchromatic (PAN) image. However, existing deep learning-based
pansharpening methods directly learn the mapping from LRMS and PAN to HRMS.
These network architectures always lack sufficient interpretability, which
limits further performance improvements. To alleviate this issue, we propose a
novel deep network for pansharpening by combining the model-based methodology
with the deep learning method. Firstly, we build an observation model for
pansharpening using the convolutional sparse coding (CSC) technique and design
a proximal gradient algorithm to solve this model. Secondly, we unfold the
iterative algorithm into a deep network, dubbed as Proximal PanNet, by learning
the proximal operators using convolutional neural networks. Finally, all the
learnable modules can be automatically learned in an end-to-end manner.
Experimental results on some benchmark datasets show that our network performs
better than other advanced methods both quantitatively and qualitatively."
Hyper-parameter tuning of physics-informed neural networks: Application to Helmholtz problems,0.0629597,"We consider physics-informed neural networks (PINNs) [Raissi et al.,
J.~Comput. Phys. 278 (2019) 686-707] for forward physical problems. In order to
find optimal PINNs configuration, we introduce a hyper-parameter optimization
(HPO) procedure via Gaussian processes-based Bayesian optimization. We apply
the HPO to Helmholtz equation for bounded domains and conduct a thorough study,
focusing on: (i) performance, (ii) the collocation points density $r$ and (iii)
the frequency $\kappa$, confirming the applicability and necessity of the
method. Numerical experiments are performed in two and three dimensions,
including comparison to finite element methods."
Sparse Conditional Hidden Markov Model for Weakly Supervised Named Entity Recognition,0.113824,"Weakly supervised named entity recognition methods train label models to
aggregate the token annotations of multiple noisy labeling functions (LFs)
without seeing any manually annotated labels. To work well, the label model
needs to contextually identify and emphasize well-performed LFs while
down-weighting the under-performers. However, evaluating the LFs is challenging
due to the lack of ground truths. To address this issue, we propose the sparse
conditional hidden Markov model (Sparse-CHMM). Instead of predicting the entire
emission matrix as other HMM-based methods, Sparse-CHMM focuses on estimating
its diagonal elements, which are considered as the reliability scores of the
LFs. The sparse scores are then expanded to the full-fledged emission matrix
with pre-defined expansion functions. We also augment the emission with
weighted XOR scores, which track the probabilities of an LF observing incorrect
entities. Sparse-CHMM is optimized through unsupervised learning with a
three-stage training pipeline that reduces the training difficulty and prevents
the model from falling into local optima. Compared with the baselines in the
Wrench benchmark, Sparse-CHMM achieves a 3.01 average F1 score improvement on
five comprehensive datasets. Experiments show that each component of
Sparse-CHMM is effective, and the estimated LF reliabilities strongly correlate
with true LF F1 scores."
A Graph-Based Method for Soccer Action Spotting Using Unsupervised Player Classification,0.160044,"Action spotting in soccer videos is the task of identifying the specific time
when a certain key action of the game occurs. Lately, it has received a large
amount of attention and powerful methods have been introduced. Action spotting
involves understanding the dynamics of the game, the complexity of events, and
the variation of video sequences. Most approaches have focused on the latter,
given that their models exploit the global visual features of the sequences. In
this work, we focus on the former by (a) identifying and representing the
players, referees, and goalkeepers as nodes in a graph, and by (b) modeling
their temporal interactions as sequences of graphs. For the player
identification, or player classification task, we obtain an accuracy of 97.72%
in our annotated benchmark. For the action spotting task, our method obtains an
overall performance of 57.83% average-mAP by combining it with other
audiovisual modalities. This performance surpasses similar graph-based methods
and has competitive results with heavy computing methods. Code and data are
available at https://github.com/IPCV/soccer_action_spotting."
DialogUSR: Complex Dialogue Utterance Splitting and Reformulation for Multiple Intent Detection,0.0696536,"While interacting with chatbots, users may elicit multiple intents in a
single dialogue utterance. Instead of training a dedicated multi-intent
detection model, we propose DialogUSR, a dialogue utterance splitting and
reformulation task that first splits multi-intent user query into several
single-intent sub-queries and then recovers all the coreferred and omitted
information in the sub-queries. DialogUSR can serve as a plug-in and
domain-agnostic module that empowers the multi-intent detection for the
deployed chatbots with minimal efforts. We collect a high-quality naturally
occurring dataset that covers 23 domains with a multi-step crowd-souring
procedure. To benchmark the proposed dataset, we propose multiple action-based
generative models that involve end-to-end and two-stage training, and conduct
in-depth analyses on the pros and cons of the proposed baselines."
Transformers are Adaptable Task Planners,0.0334752,"Every home is different, and every person likes things done in their
particular way. Therefore, home robots of the future need to both reason about
the sequential nature of day-to-day tasks and generalize to user's preferences.
To this end, we propose a Transformer Task Planner(TTP) that learns high-level
actions from demonstrations by leveraging object attribute-based
representations. TTP can be pre-trained on multiple preferences and shows
generalization to unseen preferences using a single demonstration as a prompt
in a simulated dishwasher loading task. Further, we demonstrate real-world dish
rearrangement using TTP with a Franka Panda robotic arm, prompted using a
single human demonstration."
Improving Generalizability in Implicitly Abusive Language Detection with Concept Activation Vectors,0.230276,"Robustness of machine learning models on ever-changing real-world data is
critical, especially for applications affecting human well-being such as
content moderation. New kinds of abusive language continually emerge in online
discussions in response to current events (e.g., COVID-19), and the deployed
abuse detection systems should be updated regularly to remain accurate. In this
paper, we show that general abusive language classifiers tend to be fairly
reliable in detecting out-of-domain explicitly abusive utterances but fail to
detect new types of more subtle, implicit abuse. Next, we propose an
interpretability technique, based on the Testing Concept Activation Vector
(TCAV) method from computer vision, to quantify the sensitivity of a trained
model to the human-defined concepts of explicit and implicit abusive language,
and use that to explain the generalizability of the model on new data, in this
case, COVID-related anti-Asian hate speech. Extending this technique, we
introduce a novel metric, Degree of Explicitness, for a single instance and
show that the new metric is beneficial in suggesting out-of-domain unlabeled
examples to effectively enrich the training data with informative, implicitly
abusive texts."
Face Relighting with Geometrically Consistent Shadows,0.260233,"Most face relighting methods are able to handle diffuse shadows, but struggle
to handle hard shadows, such as those cast by the nose. Methods that propose
techniques for handling hard shadows often do not produce geometrically
consistent shadows since they do not directly leverage the estimated face
geometry while synthesizing them. We propose a novel differentiable algorithm
for synthesizing hard shadows based on ray tracing, which we incorporate into
training our face relighting model. Our proposed algorithm directly utilizes
the estimated face geometry to synthesize geometrically consistent hard
shadows. We demonstrate through quantitative and qualitative experiments on
Multi-PIE and FFHQ that our method produces more geometrically consistent
shadows than previous face relighting methods while also achieving
state-of-the-art face relighting performance under directional lighting. In
addition, we demonstrate that our differentiable hard shadow modeling improves
the quality of the estimated face geometry over diffuse shading models."
Ray Priors through Reprojection: Improving Neural Radiance Fields for Novel View Extrapolation,0.163209,"Neural Radiance Fields (NeRF) have emerged as a potent paradigm for
representing scenes and synthesizing photo-realistic images. A main limitation
of conventional NeRFs is that they often fail to produce high-quality
renderings under novel viewpoints that are significantly different from the
training viewpoints. In this paper, instead of exploiting few-shot image
synthesis, we study the novel view extrapolation setting that (1) the training
images can well describe an object, and (2) there is a notable discrepancy
between the training and test viewpoints' distributions. We present RapNeRF
(RAy Priors) as a solution. Our insight is that the inherent appearances of a
3D surface's arbitrary visible projections should be consistent. We thus
propose a random ray casting policy that allows training unseen views using
seen views. Furthermore, we show that a ray atlas pre-computed from the
observed rays' viewing directions could further enhance the rendering quality
for extrapolated views. A main limitation is that RapNeRF would remove the
strong view-dependent effects because it leverages the multi-view consistency
property."
Disentangled Federated Learning for Tackling Attributes Skew via Invariant Aggregation and Diversity Transferring,0.10243,"Attributes skew hinders the current federated learning (FL) frameworks from
consistent optimization directions among the clients, which inevitably leads to
performance reduction and unstable convergence. The core problems lie in that:
1) Domain-specific attributes, which are non-causal and only locally valid, are
indeliberately mixed into global aggregation. 2) The one-stage optimizations of
entangled attributes cannot simultaneously satisfy two conflicting objectives,
i.e., generalization and personalization. To cope with these, we proposed
disentangled federated learning (DFL) to disentangle the domain-specific and
cross-invariant attributes into two complementary branches, which are trained
by the proposed alternating local-global optimization independently.
Importantly, convergence analysis proves that the FL system can be stably
converged even if incomplete client models participate in the global
aggregation, which greatly expands the application scope of FL. Extensive
experiments verify that DFL facilitates FL with higher performance, better
interpretability, and faster convergence rate, compared with SOTA FL methods on
both manually synthesized and realistic attributes skew datasets."
Color Image Inpainting via Robust Pure Quaternion Matrix Completion: Error Bound and Weighted Loss,0.734401,"In this paper, we study color image inpainting as a pure quaternion matrix
completion problem. In the literature, the theoretical guarantee for quaternion
matrix completion is not well-established. Our main aim is to propose a new
minimization problem with an objective combining nuclear norm and a quadratic
loss weighted among three channels. To fill the theoretical vacancy, we obtain
the error bound in both clean and corrupted regimes, which relies on some new
results of quaternion matrices. A general Gaussian noise is considered in
robust completion where all observations are corrupted. Motivated by the error
bound, we propose to handle unbalanced or correlated noise via a cross-channel
weight in the quadratic loss, with the main purpose of rebalancing noise level,
or removing noise correlation. Extensive experimental results on synthetic and
color image data are presented to confirm and demonstrate our theoretical
findings."
The Quest for a Common Model of the Intelligent Decision Maker,0.373907,"The premise of the Multi-disciplinary Conference on Reinforcement Learning
and Decision Making is that multiple disciplines share an interest in
goal-directed decision making over time. The idea of this paper is to sharpen
and deepen this premise by proposing a perspective on the decision maker that
is substantive and widely held across psychology, artificial intelligence,
economics, control theory, and neuroscience, which I call the ""common model of
the intelligent agent"". The common model does not include anything specific to
any organism, world, or application domain. The common model does include
aspects of the decision maker's interaction with its world (there must be input
and output, and a goal) and internal components of the decision maker (for
perception, decision-making, internal evaluation, and a world model). I
identify these aspects and components, note that they are given different names
in different disciplines but refer essentially to the same ideas, and discuss
the challenges and benefits of devising a neutral terminology that can be used
across disciplines. It is time to recognize and build on the convergence of
multiple diverse disciplines on a substantive common model of the intelligent
agent."
MABEL: Attenuating Gender Bias using Textual Entailment Data,0.183385,"Pre-trained language models encode undesirable social biases, which are
further exacerbated in downstream use. To this end, we propose MABEL (a Method
for Attenuating Gender Bias using Entailment Labels), an intermediate
pre-training approach for mitigating gender bias in contextualized
representations. Key to our approach is the use of a contrastive learning
objective on counterfactually augmented, gender-balanced entailment pairs from
natural language inference (NLI) datasets. We also introduce an alignment
regularizer that pulls identical entailment pairs along opposite gender
directions closer. We extensively evaluate our approach on intrinsic and
extrinsic metrics, and show that MABEL outperforms previous task-agnostic
debiasing approaches in terms of fairness. It also preserves task performance
after fine-tuning on downstream tasks. Together, these findings demonstrate the
suitability of NLI data as an effective means of bias mitigation, as opposed to
only using unlabeled sentences in the literature. Finally, we identify that
existing approaches often use evaluation settings that are insufficient or
inconsistent. We make an effort to reproduce and compare previous methods, and
call for unifying the evaluation settings across gender debiasing methods for
better future comparison."
Federated Learning with Heterogeneous Architectures using Graph HyperNetworks,0.192381,"Standard Federated Learning (FL) techniques are limited to clients with
identical network architectures. This restricts potential use-cases like
cross-platform training or inter-organizational collaboration when both data
privacy and architectural proprietary are required. We propose a new FL
framework that accommodates heterogeneous client architecture by adopting a
graph hypernetwork for parameter sharing. A property of the graph hyper network
is that it can adapt to various computational graphs, thereby allowing
meaningful parameter sharing across models. Unlike existing solutions, our
framework does not limit the clients to share the same architecture type, makes
no use of external data and does not require clients to disclose their model
architecture. Compared with distillation-based and non-graph hypernetwork
baselines, our method performs notably better on standard benchmarks. We
additionally show encouraging generalization performance to unseen
architectures."
CamoFormer: Masked Separable Attention for Camouflaged Object Detection,-1.0,"How to identify and segment camouflaged objects from the background is
challenging. Inspired by the multi-head self-attention in Transformers, we
present a simple masked separable attention (MSA) for camouflaged object
detection. We first separate the multi-head self-attention into three parts,
which are responsible for distinguishing the camouflaged objects from the
background using different mask strategies. Furthermore, we propose to capture
high-resolution semantic representations progressively based on a simple
top-down decoder with the proposed MSA to attain precise segmentation results.
These structures plus a backbone encoder form a new model, dubbed CamoFormer.
Extensive experiments show that CamoFormer surpasses all existing
state-of-the-art methods on three widely-used camouflaged object detection
benchmarks. There are on average around 5% relative improvements over previous
methods in terms of S-measure and weighted F-measure."
Masked Event Modeling: Self-Supervised Pretraining for Event Cameras,0.140199,"Event cameras asynchronously capture brightness changes with low latency,
high temporal resolution, and high dynamic range. However, annotation of event
data is a costly and laborious process, which limits the use of deep learning
methods for classification and other semantic tasks with the event modality. To
reduce the dependency on labeled event data, we introduce Masked Event Modeling
(MEM), a self-supervised framework for events. Our method pretrains a neural
network on unlabeled events, which can originate from any event camera
recording. Subsequently, the pretrained model is finetuned on a downstream
task, leading to a consistent improvement of the task accuracy. For example,
our method reaches state-of-the-art classification accuracy across three
datasets, N-ImageNet, N-Cars, and N-Caltech101, increasing the top-1 accuracy
of previous work by significant margins. When tested on real-world event data,
MEM is even superior to supervised RGB-based pretraining. The models pretrained
with MEM are also label-efficient and generalize well to the dense task of
semantic image segmentation."
On the Role of Bidirectionality in Language Model Pre-Training,0.0363403,"Prior work on language model pre-training has explored different
architectures and learning objectives, but differences in data, hyperparameters
and evaluation make a principled comparison difficult. In this work, we focus
on bidirectionality as a key factor that differentiates existing approaches,
and present a comprehensive study of its role in next token prediction, text
infilling, zero-shot priming and fine-tuning. We propose a new framework that
generalizes prior approaches, including fully unidirectional models like GPT,
fully bidirectional models like BERT, and hybrid models like CM3 and prefix LM.
Our framework distinguishes between two notions of bidirectionality
(bidirectional context and bidirectional attention) and allows us to control
each of them separately. We find that the optimal configuration is largely
application-dependent (e.g., bidirectional attention is beneficial for
fine-tuning and infilling, but harmful for next token prediction and zero-shot
priming). We train models with up to 6.7B parameters, and find differences to
remain consistent at scale. While prior work on scaling has focused on
left-to-right autoregressive models, our results suggest that this approach
comes with some trade-offs, and it might be worthwhile to develop very large
bidirectional models."
"3MASSIV: Multilingual, Multimodal and Multi-Aspect dataset of Social Media Short Videos",0.0594032,"We present 3MASSIV, a multilingual, multimodal and multi-aspect,
expertly-annotated dataset of diverse short videos extracted from short-video
social media platform - Moj. 3MASSIV comprises of 50k short videos (20 seconds
average duration) and 100K unlabeled videos in 11 different languages and
captures popular short video trends like pranks, fails, romance, comedy
expressed via unique audio-visual formats like self-shot videos, reaction
videos, lip-synching, self-sung songs, etc. 3MASSIV presents an opportunity for
multimodal and multilingual semantic understanding on these unique videos by
annotating them for concepts, affective states, media types, and audio
language. We present a thorough analysis of 3MASSIV and highlight the variety
and unique aspects of our dataset compared to other contemporary popular
datasets with strong baselines. We also show how the social media content in
3MASSIV is dynamic and temporal in nature, which can be used for semantic
understanding tasks and cross-lingual analysis."
HyperShot: Few-Shot Learning by Kernel HyperNetworks,0.0336622,"Few-shot models aim at making predictions using a minimal number of labeled
examples from a given task. The main challenge in this area is the one-shot
setting where only one element represents each class. We propose HyperShot -
the fusion of kernels and hypernetwork paradigm. Compared to reference
approaches that apply a gradient-based adjustment of the parameters, our model
aims to switch the classification module parameters depending on the task's
embedding. In practice, we utilize a hypernetwork, which takes the aggregated
information from support data and returns the classifier's parameters
handcrafted for the considered problem. Moreover, we introduce the kernel-based
representation of the support examples delivered to hypernetwork to create the
parameters of the classification module. Consequently, we rely on relations
between embeddings of the support examples instead of direct feature values
provided by the backbone models. Thanks to this approach, our model can adapt
to highly different tasks."
A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models,0.173265,"We have recently witnessed a number of impressive results on hard
mathematical reasoning problems with language models. At the same time, the
robustness of these models has also been called into question; recent works
have shown that models can rely on shallow patterns in the problem description
when generating a solution. Building on the idea of behavioral testing, we
propose a novel framework, which pins down the causal effect of various factors
in the input, e.g., the surface form of the problem text, the operands, and
math operators on the output solution. By grounding the behavioral analysis in
a causal graph describing an intuitive reasoning process, we study the behavior
of language models in terms of robustness and sensitivity to direct
interventions in the input space. We apply our framework on a test bed of math
word problems. Our analysis shows that robustness does not appear to
continuously improve as a function of size, but the GPT-3 Davinci models (175B)
achieve a dramatic improvement in both robustness and sensitivity compared to
all other GPT variants."
Volume Rendering Digest (for NeRF),0.333182,"Neural Radiance Fields employ simple volume rendering as a way to overcome
the challenges of differentiating through ray-triangle intersections by
leveraging a probabilistic notion of visibility. This is achieved by assuming
the scene is composed by a cloud of light-emitting particles whose density
changes in space. This technical report summarizes the derivations for
differentiable volume rendering. It is a condensed version of previous reports,
but rewritten in the context of NeRF, and adopting its commonly used notation."
Putting the Con in Context: Identifying Deceptive Actors in the Game of Mafia,0.0272929,"While neural networks demonstrate a remarkable ability to model linguistic
content, capturing contextual information related to a speaker's conversational
role is an open area of research. In this work, we analyze the effect of
speaker role on language use through the game of Mafia, in which participants
are assigned either an honest or a deceptive role. In addition to building a
framework to collect a dataset of Mafia game records, we demonstrate that there
are differences in the language produced by players with different roles. We
confirm that classification models are able to rank deceptive players as more
suspicious than honest ones based only on their use of language. Furthermore,
we show that training models on two auxiliary tasks outperforms a standard
BERT-based text classification approach. We also present methods for using our
trained models to identify features that distinguish between player roles,
which could be used to assist players during the Mafia game."
Adaptive Mean-Residue Loss for Robust Facial Age Estimation,0.158796,"Automated facial age estimation has diverse real-world applications in
multimedia analysis, e.g., video surveillance, and human-computer interaction.
However, due to the randomness and ambiguity of the aging process, age
assessment is challenging. Most research work over the topic regards the task
as one of age regression, classification, and ranking problems, and cannot well
leverage age distribution in representing labels with age ambiguity. In this
work, we propose a simple yet effective loss function for robust facial age
estimation via distribution learning, i.e., adaptive mean-residue loss, in
which, the mean loss penalizes the difference between the estimated age
distribution's mean and the ground-truth age, whereas the residue loss
penalizes the entropy of age probability out of dynamic top-K in the
distribution. Experimental results in the datasets FG-NET and CLAP2016 have
validated the effectiveness of the proposed loss. Our code is available at
https://github.com/jacobzhaoziyuan/AMR-Loss."
Cross-Lingual Retrieval Augmented Prompt for Low-Resource Languages,0.208133,"Multilingual Pretrained Language Models (MPLMs) have shown their strong
multilinguality in recent empirical cross-lingual transfer studies. In this
paper, we propose the Prompts Augmented by Retrieval Crosslingually (PARC)
pipeline to improve the zero-shot performance on low-resource languages (LRLs)
by augmenting the context with semantically similar sentences retrieved from a
high-resource language (HRL) as prompts. PARC improves the zero-shot
performance on three downstream tasks (binary sentiment classification, topic
categorization and natural language inference) with multilingual parallel test
sets across 10 LRLs covering 6 language families in both unlabeled settings
(+5.1%) and labeled settings (+16.3%). PARC-labeled also outperforms the
finetuning baseline by 3.7%. We find a significant positive correlation between
cross-lingual transfer performance on one side, and the similarity between the
high- and low-resource languages as well as the amount of low-resource
pretraining data on the other side. A robustness analysis suggests that PARC
has the potential to achieve even stronger performance with more powerful
MPLMs."
UIT-ViCoV19QA: A Dataset for COVID-19 Community-based Question Answering on Vietnamese Language,0.0,"For the last two years, from 2020 to 2021, COVID-19 has broken disease
prevention measures in many countries, including Vietnam, and negatively
impacted various aspects of human life and the social community. Besides, the
misleading information in the community and fake news about the pandemic are
also serious situations. Therefore, we present the first Vietnamese
community-based question answering dataset for developing question answering
systems for COVID-19 called UIT-ViCoV19QA. The dataset comprises 4,500
question-answer pairs collected from trusted medical sources, with at least one
answer and at most four unique paraphrased answers per question. Along with the
dataset, we set up various deep learning models as baseline to assess the
quality of our dataset and initiate the benchmark results for further research
through commonly used metrics such as BLEU, METEOR, and ROUGE-L. We also
illustrate the positive effects of having multiple paraphrased answers
experimented on these models, especially on Transformer - a dominant
architecture in the field of study."
Who Says Elephants Can't Run: Bringing Large Scale MoE Models into Cloud Scale Production,0.0823805,"Mixture of Experts (MoE) models with conditional execution of sparsely
activated layers have enabled training models with a much larger number of
parameters. As a result, these models have achieved significantly better
quality on various natural language processing tasks including machine
translation. However, it remains challenging to deploy such models in real-life
scenarios due to the large memory requirements and inefficient inference. In
this work, we introduce a highly efficient inference framework with several
optimization approaches to accelerate the computation of sparse models and cut
down the memory consumption significantly. While we achieve up to 26x speed-up
in terms of throughput, we also reduce the model size almost to one eighth of
the original 32-bit float model by quantizing expert weights into 4-bit
integers. As a result, we are able to deploy 136x larger models with 27% less
cost and significantly better quality compared to the existing solutions. This
enables a paradigm shift in deploying large scale multilingual MoE transformers
models replacing the traditional practice of distilling teacher models into
dozens of smaller models per language or task."
Hidden Agenda: a Social Deduction Game with Diverse Learned Equilibria,0.133866,"A key challenge in the study of multiagent cooperation is the need for
individual agents not only to cooperate effectively, but to decide with whom to
cooperate. This is particularly critical in situations when other agents have
hidden, possibly misaligned motivations and goals. Social deduction games offer
an avenue to study how individuals might learn to synthesize potentially
unreliable information about others, and elucidate their true motivations. In
this work, we present Hidden Agenda, a two-team social deduction game that
provides a 2D environment for studying learning agents in scenarios of unknown
team alignment. The environment admits a rich set of strategies for both teams.
Reinforcement learning agents trained in Hidden Agenda show that agents can
learn a variety of behaviors, including partnering and voting without need for
communication in natural language."
Distillation-Resistant Watermarking for Model Protection in NLP,0.422039,"How can we protect the intellectual property of trained NLP models? Modern
NLP models are prone to stealing by querying and distilling from their publicly
exposed APIs. However, existing protection methods such as watermarking only
work for images but are not applicable to text. We propose
Distillation-Resistant Watermarking (DRW), a novel technique to protect NLP
models from being stolen via distillation. DRW protects a model by injecting
watermarks into the victim's prediction probability corresponding to a secret
key and is able to detect such a key by probing a suspect model. We prove that
a protected model still retains the original accuracy within a certain bound.
We evaluate DRW on a diverse set of NLP tasks including text classification,
part-of-speech tagging, and named entity recognition. Experiments show that DRW
protects the original model and detects stealing suspects at 100% mean average
precision for all four tasks while the prior method fails on two."
Attribution-aware Weight Transfer: A Warm-Start Initialization for Class-Incremental Semantic Segmentation,0.375914,"In class-incremental semantic segmentation (CISS), deep learning
architectures suffer from the critical problems of catastrophic forgetting and
semantic background shift. Although recent works focused on these issues,
existing classifier initialization methods do not address the background shift
problem and assign the same initialization weights to both background and new
foreground class classifiers. We propose to address the background shift with a
novel classifier initialization method which employs gradient-based attribution
to identify the most relevant weights for new classes from the classifier's
weights for the previous background and transfers these weights to the new
classifier. This warm-start weight initialization provides a general solution
applicable to several CISS methods. Furthermore, it accelerates learning of new
classes while mitigating forgetting. Our experiments demonstrate significant
improvement in mIoU compared to the state-of-the-art CISS methods on the
Pascal-VOC 2012, ADE20K and Cityscapes datasets."
Intelligent analysis of EEG signals to assess consumer decisions: A Study on Neuromarketing,0.30263,"Neuromarketing is an emerging field that combines neuroscience and marketing
to understand the factors that influence consumer decisions better. The study
proposes a method to understand consumers' positive and negative reactions to
advertisements (ads) and products by analysing electroencephalogram (EEG)
signals. These signals are recorded using a low-cost single electrode headset
from volunteers belonging to the ages 18-22. A detailed subject dependent (SD)
and subject independent (SI) analysis was performed employing machine learning
methods like Naive Bayes (NB), Support Vector Machine (SVM), k-nearest
neighbour and Decision Tree and the proposed deep learning (DL) model. SVM and
NB yielded an accuracy (Acc.) of 0.63 for the SD analysis. In SI analysis, SVM
performed better for the advertisement, product and gender-based analysis.
Furthermore, the performance of the DL model was on par with that of SVM,
especially, in product and ads-based analysis."
FFC-SE: Fast Fourier Convolution for Speech Enhancement,0.18841,"Fast Fourier convolution (FFC) is the recently proposed neural operator
showing promising performance in several computer vision problems. The FFC
operator allows employing large receptive field operations within early layers
of the neural network. It was shown to be especially helpful for inpainting of
periodic structures which are common in audio processing. In this work, we
design neural network architectures which adapt FFC for speech enhancement. We
hypothesize that a large receptive field allows these networks to produce more
coherent phases than vanilla convolutional models, and validate this hypothesis
experimentally. We found that neural networks based on Fast Fourier convolution
outperform analogous convolutional models and show better or comparable results
with other speech enhancement baselines."
Planning Assembly Sequence with Graph Transformer,0.233167,"Assembly sequence planning (ASP) is the essential process for modern
manufacturing, proven to be NP-complete thus its effective and efficient
solution has been a challenge for researchers in the field. In this paper, we
present a graph-transformer based framework for the ASP problem which is
trained and demonstrated on a self-collected ASP database. The ASP database
contains a self-collected set of LEGO models. The LEGO model is abstracted to a
heterogeneous graph structure after a thorough analysis of the original
structure and feature extraction. The ground truth assembly sequence is first
generated by brute-force search and then adjusted manually to in line with
human rational habits. Based on this self-collected ASP dataset, we propose a
heterogeneous graph-transformer framework to learn the latent rules for
assembly planning. We evaluated the proposed framework in a series of
experiment. The results show that the similarity of the predicted and ground
truth sequences can reach 0.44, a medium correlation measured by Kendall's
$\tau$. Meanwhile, we compared the different effects of node features and edge
features and generated a feasible and reasonable assembly sequence as a
benchmark for further research. Our data set and code is available on
https://github.com/AIR-DISCOVER/ICRA\_ASP."
Disentangling Visual Embeddings for Attributes and Objects,0.232578,"We study the problem of compositional zero-shot learning for object-attribute
recognition. Prior works use visual features extracted with a backbone network,
pre-trained for object classification and thus do not capture the subtly
distinct features associated with attributes. To overcome this challenge, these
studies employ supervision from the linguistic space, and use pre-trained word
embeddings to better separate and compose attribute-object pairs for
recognition. Analogous to linguistic embedding space, which already has unique
and agnostic embeddings for object and attribute, we shift the focus back to
the visual space and propose a novel architecture that can disentangle
attribute and object features in the visual space. We use visual decomposed
features to hallucinate embeddings that are representative for the seen and
novel compositions to better regularize the learning of our model. Extensive
experiments show that our method outperforms existing work with significant
margin on three datasets: MIT-States, UT-Zappos, and a new benchmark created
based on VAW. The code, models, and dataset splits are publicly available at
https://github.com/nirat1606/OADis."
Investigation of Data Augmentation Techniques for Disordered Speech Recognition,0.121116,"Disordered speech recognition is a highly challenging task. The underlying
neuro-motor conditions of people with speech disorders, often compounded with
co-occurring physical disabilities, lead to the difficulty in collecting large
quantities of speech required for system development. This paper investigates a
set of data augmentation techniques for disordered speech recognition,
including vocal tract length perturbation (VTLP), tempo perturbation and speed
perturbation. Both normal and disordered speech were exploited in the
augmentation process. Variability among impaired speakers in both the original
and augmented data was modeled using learning hidden unit contributions (LHUC)
based speaker adaptive training. The final speaker adapted system constructed
using the UASpeech corpus and the best augmentation approach based on speed
perturbation produced up to 2.92% absolute (9.3% relative) word error rate
(WER) reduction over the baseline system without data augmentation, and gave an
overall WER of 26.37% on the test set containing 16 dysarthric speakers."
Changing the Representation: Examining Language Representation for Neural Sign Language Production,0.0225934,"Neural Sign Language Production (SLP) aims to automatically translate from
spoken language sentences to sign language videos. Historically the SLP task
has been broken into two steps; Firstly, translating from a spoken language
sentence to a gloss sequence and secondly, producing a sign language video
given a sequence of glosses. In this paper we apply Natural Language Processing
techniques to the first step of the SLP pipeline. We use language models such
as BERT and Word2Vec to create better sentence level embeddings, and apply
several tokenization techniques, demonstrating how these improve performance on
the low resource translation task of Text to Gloss. We introduce Text to
HamNoSys (T2H) translation, and show the advantages of using a phonetic
representation for sign language translation rather than a sign level gloss
representation. Furthermore, we use HamNoSys to extract the hand shape of a
sign and use this as additional supervision during training, further increasing
the performance on T2H. Assembling best practise, we achieve a BLEU-4 score of
26.99 on the MineDGS dataset and 25.09 on PHOENIX14T, two new state-of-the-art
baselines."
Continuous diffusion for categorical data,0.987363,"Diffusion models have quickly become the go-to paradigm for generative
modelling of perceptual signals (such as images and sound) through iterative
refinement. Their success hinges on the fact that the underlying physical
phenomena are continuous. For inherently discrete and categorical data such as
language, various diffusion-inspired alternatives have been proposed. However,
the continuous nature of diffusion models conveys many benefits, and in this
work we endeavour to preserve it. We propose CDCD, a framework for modelling
categorical data with diffusion models that are continuous both in time and
input space. We demonstrate its efficacy on several language modelling tasks."
Perceptual Quality Assessment for Digital Human Heads,0.0507855,"Digital humans are attracting more and more research interest during the last
decade, the generation, representation, rendering, and animation of which have
been put into large amounts of effort. However, the quality assessment of
digital humans has fallen behind. Therefore, to tackle the challenge of digital
human quality assessment issues, we propose the first large-scale quality
assessment database for three-dimensional (3D) scanned digital human heads
(DHHs). The constructed database consists of 55 reference DHHs and 1,540
distorted DHHs along with the subjective perceptual ratings. Then, a simple yet
effective full-reference (FR) projection-based method is proposed to evaluate
the visual quality of DHHs. The pretrained Swin Transformer tiny is employed
for hierarchical feature extraction and the multi-head attention module is
utilized for feature fusion. The experimental results reveal that the proposed
method exhibits state-of-the-art performance among the mainstream FR metrics.
The database is released at https://github.com/zzc-1998/DHHQA."
The Theory of Artificial Immutability: Protecting Algorithmic Groups Under Anti-Discrimination Law,0.0274627,"Artificial Intelligence (AI) is increasingly used to make important decisions
about people. While issues of AI bias and proxy discrimination are well
explored, less focus has been paid to the harms created by profiling based on
groups that do not map to or correlate with legally protected groups such as
sex or ethnicity. This raises a question: are existing equality laws able to
protect against emergent AI-driven inequality? This article examines the legal
status of algorithmic groups in North American and European non-discrimination
doctrine, law, and jurisprudence and will show that algorithmic groups are not
comparable to traditional protected groups. Nonetheless, these new groups are
worthy of protection. I propose a new theory of harm - ""the theory of
artificial immutability"" - that aims to bring AI groups within the scope of the
law. My theory describes how algorithmic groups act as de facto immutable
characteristics in practice that limit people's autonomy and prevent them from
achieving important goals."
Identifying Ethical Issues in AI Partners in Human-AI Co-Creation,0.0452746,"Human-AI co-creativity involves humans and AI collaborating on a shared
creative product as partners. In many existing co-creative systems, users
communicate with the AI using buttons or sliders. However, typically, the AI in
co-creative systems cannot communicate back to humans, limiting their potential
to be perceived as partners. This paper starts with an overview of a
comparative study with 38 participants to explore the impact of AI-to-human
communication on user perception and engagement in co-creative systems and the
results show improved collaborative experience and user engagement with the
system incorporating AI-to-human communication. The results also demonstrate
that users perceive co-creative AI as more reliable, personal and intelligent
when it can communicate with the users. The results indicate a need to identify
potential ethical issues from an engaging communicating co-creative AI. Later
in the paper, we present some potential ethical issues in human-AI co-creation
and propose to use participatory design fiction as the research methodology to
investigate the ethical issues associated with a co-creative AI that
communicates with users."
Leveraging Language for Accelerated Learning of Tool Manipulation,0.121862,"Robust and generalized tool manipulation requires an understanding of the
properties and affordances of different tools. We investigate whether
linguistic information about a tool (e.g., its geometry, common uses) can help
control policies adapt faster to new tools for a given task. We obtain diverse
descriptions of various tools in natural language and use pre-trained language
models to generate their feature representations. We then perform
language-conditioned meta-learning to learn policies that can efficiently adapt
to new tools given their corresponding text descriptions. Our results
demonstrate that combining linguistic information and meta-learning
significantly accelerates tool learning in several manipulation tasks including
pushing, lifting, sweeping, and hammering."
Semantic optical fiber communication system,0.0844534,"The current optical communication systems minimize bit or symbol errors
without considering the semantic meaning behind digital bits, thus transmitting
a lot of unnecessary information. We propose and experimentally demonstrate a
semantic optical fiber communication (SOFC) system. Instead of encoding
information into bits for transmission, semantic information is extracted from
the source using deep learning. The generated semantic symbols are then
directly transmitted through an optical fiber. Compared with the bit-based
structure, the SOFC system achieved higher information compression and a more
stable performance, especially in the low received optical power regime, and
enhanced the robustness against optical link impairments. This work introduces
an intelligent optical communication system at the human analytical thinking
level, which is a significant step toward a breakthrough in the current optical
communication architecture."
Semi-supervised New Event Type Induction and Description via Contrastive Loss-Enforced Batch Attention,0.0496441,"Most event extraction methods have traditionally relied on an annotated set
of event types. However, creating event ontologies and annotating supervised
training data are expensive and time-consuming. Previous work has proposed
semi-supervised approaches which leverage seen (annotated) types to learn how
to automatically discover new event types. State-of-the-art methods, both
semi-supervised or fully unsupervised, use a form of reconstruction loss on
specific tokens in a context. In contrast, we present a novel approach to
semi-supervised new event type induction using a masked contrastive loss, which
learns similarities between event mentions by enforcing an attention mechanism
over the data minibatch. We further disentangle the discovered clusters by
approximating the underlying manifolds in the data, which allows us to increase
normalized mutual information and Fowlkes-Mallows scores by over 20% absolute.
Building on these clustering results, we extend our approach to two new tasks:
predicting the type name of the discovered clusters and linking them to
FrameNet frames."
Robust Double-Encoder Network for RGB-D Panoptic Segmentation,0.0172717,"Perception is crucial for robots that act in real-world environments, as
autonomous systems need to see and understand the world around them to act
properly. Panoptic segmentation provides an interpretation of the scene by
computing a pixelwise semantic label together with instance IDs. In this paper,
we address panoptic segmentation using RGB-D data of indoor scenes. We propose
a novel encoder-decoder neural network that processes RGB and depth separately
through two encoders. The features of the individual encoders are progressively
merged at different resolutions, such that the RGB features are enhanced using
complementary depth information. We propose a novel merging approach called
ResidualExcite, which reweighs each entry of the feature map according to its
importance. With our double-encoder architecture, we are robust to missing
cues. In particular, the same model can train and infer on RGB-D, RGB-only, and
depth-only input data, without the need to train specialized models. We
evaluate our method on publicly available datasets and show that our approach
achieves superior results compared to other common approaches for panoptic
segmentation."
Unified Fourier-based Kernel and Nonlinearity Design for Equivariant Networks on Homogeneous Spaces,0.124379,"We introduce a unified framework for group equivariant networks on
homogeneous spaces derived from a Fourier perspective. We consider
tensor-valued feature fields, before and after a convolutional layer. We
present a unified derivation of kernels via the Fourier domain by leveraging
the sparsity of Fourier coefficients of the lifted feature fields. The sparsity
emerges when the stabilizer subgroup of the homogeneous space is a compact Lie
group. We further introduce a nonlinear activation, via an elementwise
nonlinearity on the regular representation after lifting and projecting back to
the field through an equivariant convolution. We show that other methods
treating features as the Fourier coefficients in the stabilizer subgroup are
special cases of our activation. Experiments on $SO(3)$ and $SE(3)$ show
state-of-the-art performance in spherical vector field regression, point cloud
classification, and molecular completion."
Detecting Arbitrary Keypoints on Limbs and Skis with Sparse Partly Correct Segmentation Masks,0.323584,"Analyses based on the body posture are crucial for top-class athletes in many
sports disciplines. If at all, coaches label only the most important keypoints,
since manual annotations are very costly. This paper proposes a method to
detect arbitrary keypoints on the limbs and skis of professional ski jumpers
that requires a few, only partly correct segmentation masks during training.
Our model is based on the Vision Transformer architecture with a special design
for the input tokens to query for the desired keypoints. Since we use
segmentation masks only to generate ground truth labels for the freely
selectable keypoints, partly correct segmentation masks are sufficient for our
training procedure. Hence, there is no need for costly hand-annotated
segmentation masks. We analyze different training techniques for freely
selected and standard keypoints, including pseudo labels, and show in our
experiments that only a few partly correct segmentation masks are sufficient
for learning to detect arbitrary keypoints on limbs and skis."
Neural Enhanced Belief Propagation for Data Association in Multiobject Tracking,0.120501,"Situation-aware technologies enabled by multiobject tracking (MOT) methods
will create new services and applications in fields such as autonomous
navigation and applied ocean sciences. Belief propagation (BP) is a
state-of-the-art method for Bayesian MOT but fully relies on a statistical
model and preprocessed sensor measurements. In this paper, we establish a
hybrid method for model-based and data-driven MOT. The proposed neural enhanced
belief propagation (NEBP) approach complements BP by information learned from
raw sensor data with the goal to improve data association and to reject false
alarm measurements. We evaluate the performance of our NEBP approach for MOT on
the nuScenes autonomous driving dataset and demonstrate that it can outperform
state-of-the-art reference methods."
MCoNaLa: A Benchmark for Code Generation from Multiple Natural Languages,0.0744702,"While there has been a recent burgeoning of applications at the intersection
of natural and programming languages, such as code generation and code
summarization, these applications are usually English-centric. This creates a
barrier for program developers who are not proficient in English. To mitigate
this gap in technology development across languages, we propose a multilingual
dataset, MCoNaLa, to benchmark code generation from natural language commands
extending beyond English. Modeled off of the methodology from the English
Code/Natural Language Challenge (CoNaLa) dataset, we annotated a total of 896
NL-code pairs in three languages: Spanish, Japanese, and Russian. We present a
quantitative evaluation of performance on the MCoNaLa dataset by testing with
state-of-the-art code generation systems. While the difficulties vary across
these three languages, all systems lag significantly behind their English
counterparts, revealing the challenges in adapting code generation to new
languages."
Robust Contrastive Learning against Noisy Views,0.313825,"Contrastive learning relies on an assumption that positive pairs contain
related views, e.g., patches of an image or co-occurring multimodal signals of
a video, that share certain underlying information about an instance. But what
if this assumption is violated? The literature suggests that contrastive
learning produces suboptimal representations in the presence of noisy views,
e.g., false positive pairs with no apparent shared information. In this work,
we propose a new contrastive loss function that is robust against noisy views.
We provide rigorous theoretical justifications by showing connections to robust
symmetric losses for noisy binary classification and by establishing a new
contrastive bound for mutual information maximization based on the Wasserstein
distance measure. The proposed loss is completely modality-agnostic and a
simple drop-in replacement for the InfoNCE loss, which makes it easy to apply
to existing contrastive frameworks. We show that our approach provides
consistent improvements over the state-of-the-art on image, video, and graph
contrastive learning benchmarks that exhibit a variety of real-world noise
patterns."
Scribble2D5: Weakly-Supervised Volumetric Image Segmentation via Scribble Annotations,0.18496,"Recently, weakly-supervised image segmentation using weak annotations like
scribbles has gained great attention, since such annotations are much easier to
obtain compared to time-consuming and label-intensive labeling at the
pixel/voxel level. However, because scribbles lack structure information of
region of interest (ROI), existing scribble-based methods suffer from poor
boundary localization. Furthermore, most current methods are designed for 2D
image segmentation, which do not fully leverage the volumetric information if
directly applied to image slices. In this paper, we propose a scribble-based
volumetric image segmentation, Scribble2D5, which tackles 3D anisotropic image
segmentation and improves boundary prediction. To achieve this, we augment a
2.5D attention UNet with a proposed label propagation module to extend semantic
information from scribbles and a combination of static and active boundary
prediction to learn ROI's boundary and regularize its shape. Extensive
experiments on three public datasets demonstrate Scribble2D5 significantly
outperforms current scribble-based methods and approaches the performance of
fully-supervised ones. Our code is available online."
Confidence Based Bidirectional Global Context Aware Training Framework for Neural Machine Translation,0.0604272,"Most dominant neural machine translation (NMT) models are restricted to make
predictions only according to the local context of preceding words in a
left-to-right manner. Although many previous studies try to incorporate global
information into NMT models, there still exist limitations on how to
effectively exploit bidirectional global context. In this paper, we propose a
Confidence Based Bidirectional Global Context Aware (CBBGCA) training framework
for NMT, where the NMT model is jointly trained with an auxiliary conditional
masked language model (CMLM). The training consists of two stages: (1)
multi-task joint training; (2) confidence based knowledge distillation. At the
first stage, by sharing encoder parameters, the NMT model is additionally
supervised by the signal from the CMLM decoder that contains bidirectional
global contexts. Moreover, at the second stage, using the CMLM as teacher, we
further pertinently incorporate bidirectional global context to the NMT model
on its unconfidently-predicted target words via knowledge distillation.
Experimental results show that our proposed CBBGCA training framework
significantly improves the NMT model by +1.02, +1.30 and +0.57 BLEU scores on
three large-scale translation datasets, namely WMT'14 English-to-German, WMT'19
Chinese-to-English and WMT'14 English-to-French, respectively."
Bounding Counterfactuals under Selection Bias,0.0304364,"Causal analysis may be affected by selection bias, which is defined as the
systematic exclusion of data from a certain subpopulation. Previous work in
this area focused on the derivation of identifiability conditions. We propose
instead a first algorithm to address both identifiable and unidentifiable
queries. We prove that, in spite of the missingness induced by the selection
bias, the likelihood of the available data is unimodal. This enables us to use
the causal expectation-maximisation scheme to obtain the values of causal
queries in the identifiable case, and to compute bounds otherwise. Experiments
demonstrate the approach to be practically viable. Theoretical convergence
characterisations are provided."
DyNCA: Real-time Dynamic Texture Synthesis Using Neural Cellular Automata,0.111865,"Current Dynamic Texture Synthesis (DyTS) models can synthesize realistic
videos. However, they require a slow iterative optimization process to
synthesize a single fixed-size short video, and they do not offer any
post-training control over the synthesis process. We propose Dynamic Neural
Cellular Automata (DyNCA), a framework for real-time and controllable dynamic
texture synthesis. Our method is built upon the recently introduced NCA models
and can synthesize infinitely long and arbitrary-sized realistic video textures
in real time. We quantitatively and qualitatively evaluate our model and show
that our synthesized videos appear more realistic than the existing results. We
improve the SOTA DyTS performance by $2\sim 4$ orders of magnitude. Moreover,
our model offers several real-time video controls including motion speed,
motion direction, and an editing brush tool. We exhibit our trained models in
an online interactive demo that runs on local hardware and is accessible on
personal computers and smartphones."
Image Classification with Small Datasets: Overview and Benchmark,0.01992,"Image classification with small datasets has been an active research area in
the recent past. However, as research in this scope is still in its infancy,
two key ingredients are missing for ensuring reliable and truthful progress: a
systematic and extensive overview of the state of the art, and a common
benchmark to allow for objective comparisons between published methods. This
article addresses both issues. First, we systematically organize and connect
past studies to consolidate a community that is currently fragmented and
scattered. Second, we propose a common benchmark that allows for an objective
comparison of approaches. It consists of five datasets spanning various domains
(e.g., natural images, medical imagery, satellite data) and data types (RGB,
grayscale, multispectral). We use this benchmark to re-evaluate the standard
cross-entropy baseline and ten existing methods published between 2017 and 2021
at renowned venues. Surprisingly, we find that thorough hyper-parameter tuning
on held-out validation data results in a highly competitive baseline and
highlights a stunted growth of performance over the years. Indeed, only a
single specialized method dating back to 2019 clearly wins our benchmark and
outperforms the baseline classifier."
Towards Efficient Use of Multi-Scale Features in Transformer-Based Object Detectors,0.0491637,"Multi-scale features have been proven highly effective for object detection
but often come with huge and even prohibitive extra computation costs,
especially for the recent Transformer-based detectors. In this paper, we
propose Iterative Multi-scale Feature Aggregation (IMFA) -- a generic paradigm
that enables efficient use of multi-scale features in Transformer-based object
detectors. The core idea is to exploit sparse multi-scale features from just a
few crucial locations, and it is achieved with two novel designs. First, IMFA
rearranges the Transformer encoder-decoder pipeline so that the encoded
features can be iteratively updated based on the detection predictions. Second,
IMFA sparsely samples scale-adaptive features for refined detection from just a
few keypoint locations under the guidance of prior detection predictions. As a
result, the sampled multi-scale features are sparse yet still highly beneficial
for object detection. Extensive experiments show that the proposed IMFA boosts
the performance of multiple Transformer-based object detectors significantly
yet with only slight computational overhead."
Localized Vision-Language Matching for Open-vocabulary Object Detection,0.139618,"In this work, we propose an open-vocabulary object detection method that,
based on image-caption pairs, learns to detect novel object classes along with
a given set of known classes. It is a two-stage training approach that first
uses a location-guided image-caption matching technique to learn class labels
for both novel and known classes in a weakly-supervised manner and second
specializes the model for the object detection task using known class
annotations. We show that a simple language model fits better than a large
contextualized language model for detecting novel objects. Moreover, we
introduce a consistency-regularization technique to better exploit
image-caption pair information. Our method compares favorably to existing
open-vocabulary detection approaches while being data-efficient. Source code is
available at https://github.com/lmb-freiburg/locov ."
Robust Anytime Learning of Markov Decision Processes,0.0255625,"Markov decision processes (MDPs) are formal models commonly used in
sequential decision-making. MDPs capture the stochasticity that may arise, for
instance, from imprecise actuators via probabilities in the transition
function. However, in data-driven applications, deriving precise probabilities
from (limited) data introduces statistical errors that may lead to unexpected
or undesirable outcomes. Uncertain MDPs (uMDPs) do not require precise
probabilities but instead use so-called uncertainty sets in the transitions,
accounting for such limited data. Tools from the formal verification community
efficiently compute robust policies that provably adhere to formal
specifications, like safety constraints, under the worst-case instance in the
uncertainty set. We continuously learn the transition probabilities of an MDP
in a robust anytime-learning approach that combines a dedicated Bayesian
inference scheme with the computation of robust policies. In particular, our
method (1) approximates probabilities as intervals, (2) adapts to new data that
may be inconsistent with an intermediate model, and (3) may be stopped at any
time to compute a robust policy on the uMDP that faithfully captures the data
so far. Furthermore, our method is capable of adapting to changes in the
environment. We show the effectiveness of our approach and compare it to robust
policies computed on uMDPs learned by the UCRL2 reinforcement learning
algorithm in an experimental evaluation on several benchmarks."
Concept Graph Neural Networks for Surgical Video Understanding,0.0,"We constantly integrate our knowledge and understanding of the world to
enhance our interpretation of what we see.
  This ability is crucial in application domains which entail reasoning about
multiple entities and concepts, such as AI-augmented surgery. In this paper, we
propose a novel way of integrating conceptual knowledge into temporal analysis
tasks via temporal concept graph networks. In the proposed networks, a global
knowledge graph is incorporated into the temporal analysis of surgical
instances, learning the meaning of concepts and relations as they apply to the
data. We demonstrate our results in surgical video data for tasks such as
verification of critical view of safety, as well as estimation of Parkland
grading scale. The results show that our method improves the recognition and
detection of complex benchmarks as well as enables other analytic applications
of interest."
Understanding Interpersonal Conflict Types and their Impact on Perception Classification,0.034471,"Studies on interpersonal conflict have a long history and contain many
suggestions for conflict typology. We use this as the basis of a novel
annotation scheme and release a new dataset of situations and conflict aspect
annotations. We then build a classifier to predict whether someone will
perceive the actions of one individual as right or wrong in a given situation.
Our analyses include conflict aspects, but also generated clusters, which are
human validated, and show differences in conflict content based on the
relationship of participants to the author. Our findings have important
implications for understanding conflict and social norms."
GreenPLM: Cross-Lingual Transfer of Monolingual Pre-Trained Language Models at Almost No Cost,0.208634,"Large pre-trained models have revolutionized natural language processing
(NLP) research and applications, but high training costs and limited data
resources have prevented their benefits from being shared equally amongst
speakers of all the world's languages. To address issues of cross-linguistic
access to such models and reduce energy consumption for sustainability during
large-scale model training, this study proposes an effective and
energy-efficient framework called GreenPLM that uses bilingual lexicons to
directly ""translate"" pre-trained language models of one language into another
at almost no additional cost. We validate this approach in 18 languages' BERT
models and show that this framework is comparable to, if not better than, other
heuristics with high training costs. In addition, given lightweight continued
pre-training on limited data where available, this framework outperforms the
original monolingual language models in six out of seven tested languages with
up to 200x less pre-training efforts. Aiming at the Leave No One Behind
Principle (LNOB), our approach manages to reduce inequalities between languages
and energy consumption greatly. We make our codes and models publicly available
here: \url{https://github.com/qcznlp/GreenPLMs}"
Super forecasting the technological singularity risks from artificial intelligence,0.474144,"The article forecasts emerging cyber-risks from the integration of AI in
cybersecurity."
Learning-based Motion Planning in Dynamic Environments Using GNNs and Temporal Encoding,0.0364763,"Learning-based methods have shown promising performance for accelerating
motion planning, but mostly in the setting of static environments. For the more
challenging problem of planning in dynamic environments, such as multi-arm
assembly tasks and human-robot interaction, motion planners need to consider
the trajectories of the dynamic obstacles and reason about temporal-spatial
interactions in very large state spaces. We propose a GNN-based approach that
uses temporal encoding and imitation learning with data aggregation for
learning both the embeddings and the edge prioritization policies. Experiments
show that the proposed methods can significantly accelerate online planning
over state-of-the-art complete dynamic planning algorithms. The learned models
can often reduce costly collision checking operations by more than 1000x, and
thus accelerating planning by up to 95%, while achieving high success rates on
hard instances as well."
Introducing BEREL: BERT Embeddings for Rabbinic-Encoded Language,0.0913355,"We present a new pre-trained language model (PLM) for Rabbinic Hebrew, termed
Berel (BERT Embeddings for Rabbinic-Encoded Language). Whilst other PLMs exist
for processing Hebrew texts (e.g., HeBERT, AlephBert), they are all trained on
modern Hebrew texts, which diverges substantially from Rabbinic Hebrew in terms
of its lexicographical, morphological, syntactic and orthographic norms. We
demonstrate the superiority of Berel on Rabbinic texts via a challenge set of
Hebrew homographs. We release the new model and homograph challenge set for
unrestricted use."
Enhancing Task Bot Engagement with Synthesized Open-Domain Dialog,0.0420489,"Many efforts have been made to construct dialog systems for different types
of conversations, such as task-oriented dialog (TOD) and open-domain dialog
(ODD). To better mimic human-level conversations that usually fuse various
dialog modes, it is essential to build a system that can effectively handle
both TOD and ODD and access different knowledge sources. To address the lack of
available data for the fused task, we propose a framework for automatically
generating dialogues that combine knowledge-grounded ODDs and TODs in various
settings. Additionally, we introduce a unified model PivotBot that is capable
of appropriately adopting TOD and ODD modes and accessing different knowledge
sources in order to effectively tackle the fused task. Evaluation results
demonstrate the superior ability of the proposed model to switch seamlessly
between TOD and ODD tasks."
KnowGL: Knowledge Generation and Linking from Text,0.0349317,"We propose KnowGL, a tool that allows converting text into structured
relational data represented as a set of ABox assertions compliant with the TBox
of a given Knowledge Graph (KG), such as Wikidata. We address this problem as a
sequence generation task by leveraging pre-trained sequence-to-sequence
language models, e.g. BART. Given a sentence, we fine-tune such models to
detect pairs of entity mentions and jointly generate a set of facts consisting
of the full set of semantic annotations for a KG, such as entity labels, entity
types, and their relationships. To showcase the capabilities of our tool, we
build a web application consisting of a set of UI widgets that help users to
navigate through the semantic data extracted from a given input text. We make
the KnowGL model available at https://huggingface.co/ibm/knowgl-large."
"A Comprehensive Study of Image Classification Model Sensitivity to Foregrounds, Backgrounds, and Visual Attributes",0.244512,"While datasets with single-label supervision have propelled rapid advances in
image classification, additional annotations are necessary in order to
quantitatively assess how models make predictions. To this end, for a subset of
ImageNet samples, we collect segmentation masks for the entire object and $18$
informative attributes. We call this dataset RIVAL10 (RIch Visual Attributes
with Localization), consisting of roughly $26k$ instances over $10$ classes.
Using RIVAL10, we evaluate the sensitivity of a broad set of models to noise
corruptions in foregrounds, backgrounds and attributes. In our analysis, we
consider diverse state-of-the-art architectures (ResNets, Transformers) and
training procedures (CLIP, SimCLR, DeiT, Adversarial Training). We find that,
somewhat surprisingly, in ResNets, adversarial training makes models more
sensitive to the background compared to foreground than standard training.
Similarly, contrastively-trained models also have lower relative foreground
sensitivity in both transformers and ResNets. Lastly, we observe intriguing
adaptive abilities of transformers to increase relative foreground sensitivity
as corruption level increases. Using saliency methods, we automatically
discover spurious features that drive the background sensitivity of models and
assess alignment of saliency maps with foregrounds. Finally, we quantitatively
study the attribution problem for neural features by comparing feature saliency
with ground-truth localization of semantic attributes."
A Robust Document Image Watermarking Scheme using Deep Neural Network,0.0,"Watermarking is an important copyright protection technology which generally
embeds the identity information into the carrier imperceptibly. Then the
identity can be extracted to prove the copyright from the watermarked carrier
even after suffering various attacks. Most of the existing watermarking
technologies take the nature images as carriers. Different from the natural
images, document images are not so rich in color and texture, and thus have
less redundant information to carry watermarks. This paper proposes an
end-to-end document image watermarking scheme using the deep neural network.
Specifically, an encoder and a decoder are designed to embed and extract the
watermark. A noise layer is added to simulate the various attacks that could be
encountered in reality, such as the Cropout, Dropout, Gaussian blur, Gaussian
noise, Resize, and JPEG Compression. A text-sensitive loss function is designed
to limit the embedding modification on characters. An embedding strength
adjustment strategy is proposed to improve the quality of watermarked image
with little loss of extraction accuracy. Experimental results show that the
proposed document image watermarking technology outperforms three
state-of-the-arts in terms of the robustness and image quality."
VPAIR -- Aerial Visual Place Recognition and Localization in Large-scale Outdoor Environments,0.900509,"Visual Place Recognition and Visual Localization are essential components in
navigation and mapping for autonomous vehicles especially in GNSS-denied
navigation scenarios. Recent work has focused on ground or close to ground
applications such as self-driving cars or indoor-scenarios and low-altitude
drone flights. However, applications such as Urban Air Mobility require
operations in large-scale outdoor environments at medium to high altitudes. We
present a new dataset named VPAIR. The dataset was recorded on board a light
aircraft flying at an altitude of more than 300 meters above ground capturing
images with a downwardfacing camera. Each image is paired with a high
resolution reference render including dense depth information and 6-DoF
reference poses. The dataset covers a more than one hundred kilometers long
trajectory over various types of challenging landscapes, e.g. urban, farmland
and forests. Experiments on this dataset illustrate the challenges introduced
by the change in perspective to a bird's eye view such as in-plane rotations."
Relative Behavioral Attributes: Filling the Gap between Symbolic Goal Specification and Reward Learning from Human Preferences,0.0417663,"Generating complex behaviors that satisfy the preferences of non-expert users
is a crucial requirement for AI agents. Interactive reward learning from
trajectory comparisons (a.k.a. RLHF) is one way to allow non-expert users to
convey complex objectives by expressing preferences over short clips of agent
behaviors. Even though this parametric method can encode complex tacit
knowledge present in the underlying tasks, it implicitly assumes that the human
is unable to provide richer feedback than binary preference labels, leading to
intolerably high feedback complexity and poor user experience. While providing
a detailed symbolic closed-form specification of the objectives might be
tempting, it is not always feasible even for an expert user. However, in most
cases, humans are aware of how the agent should change its behavior along
meaningful axes to fulfill their underlying purpose, even if they are not able
to fully specify task objectives symbolically. Using this as motivation, we
introduce the notion of Relative Behavioral Attributes, which allows the users
to tweak the agent behavior through symbolic concepts (e.g., increasing the
softness or speed of agents' movement). We propose two practical methods that
can learn to model any kind of behavioral attributes from ordered behavior
clips. We demonstrate the effectiveness of our methods on four tasks with nine
different behavioral attributes, showing that once the attributes are learned,
end users can produce desirable agent behaviors relatively effortlessly, by
providing feedback just around ten times. This is over an order of magnitude
less than that required by the popular learning-from-human-preferences
baselines. The supplementary video and source code are available at:
https://guansuns.github.io/pages/rba."
Boosting 3D Adversarial Attacks with Attacking On Frequency,0.00391449,"Deep neural networks (DNNs) have been shown to be vulnerable to adversarial
attacks. Recently, 3D adversarial attacks, especially adversarial attacks on
point clouds, have elicited mounting interest. However, adversarial point
clouds obtained by previous methods show weak transferability and are easy to
defend. To address these problems, in this paper we propose a novel point cloud
attack (dubbed AOF) that pays more attention on the low-frequency component of
point clouds. We combine the losses from point cloud and its low-frequency
component to craft adversarial samples. Extensive experiments validate that AOF
can improve the transferability significantly compared to state-of-the-art
(SOTA) attacks, and is more robust to SOTA 3D defense methods. Otherwise,
compared to clean point clouds, adversarial point clouds obtained by AOF
contain more deformation than outlier."
An Intelligent Self-driving Truck System For Highway Transportation,0.0822899,"Recently, there have been many advances in autonomous driving society,
attracting a lot of attention from academia and industry. However, existing
works mainly focus on cars, extra development is still required for
self-driving truck algorithms and models. In this paper, we introduce an
intelligent self-driving truck system. Our presented system consists of three
main components, 1) a realistic traffic simulation module for generating
realistic traffic flow in testing scenarios, 2) a high-fidelity truck model
which is designed and evaluated for mimicking real truck response in real-world
deployment, 3) an intelligent planning module with learning-based decision
making algorithm and multi-mode trajectory planner, taking into account the
truck's constraints, road slope changes, and the surrounding traffic flow. We
provide quantitative evaluations for each component individually to demonstrate
the fidelity and performance of each part. We also deploy our proposed system
on a real truck and conduct real world experiments which shows our system's
capacity of mitigating sim-to-real gap. Our code is available at
https://github.com/InceptioResearch/IITS"
On the Effectiveness of Compact Biomedical Transformers,0.368471,"Language models pre-trained on biomedical corpora, such as BioBERT, have
recently shown promising results on downstream biomedical tasks. Many existing
pre-trained models, on the other hand, are resource-intensive and
computationally heavy owing to factors such as embedding size, hidden
dimension, and number of layers. The natural language processing (NLP)
community has developed numerous strategies to compress these models utilising
techniques such as pruning, quantisation, and knowledge distillation, resulting
in models that are considerably faster, smaller, and subsequently easier to use
in practice. By the same token, in this paper we introduce six lightweight
models, namely, BioDistilBERT, BioTinyBERT, BioMobileBERT, DistilBioBERT,
TinyBioBERT, and CompactBioBERT which are obtained either by knowledge
distillation from a biomedical teacher or continual learning on the Pubmed
dataset via the Masked Language Modelling (MLM) objective. We evaluate all of
our models on three biomedical tasks and compare them with BioBERT-v1.1 to
create efficient lightweight models that perform on par with their larger
counterparts. All the models will be publicly available on our Huggingface
profile at https://huggingface.co/nlpie and the codes used to run the
experiments will be available at
https://github.com/nlpie-research/Compact-Biomedical-Transformers."
Flow-Guided Transformer for Video Inpainting,0.332367,"We propose a flow-guided transformer, which innovatively leverage the motion
discrepancy exposed by optical flows to instruct the attention retrieval in
transformer for high fidelity video inpainting. More specially, we design a
novel flow completion network to complete the corrupted flows by exploiting the
relevant flow features in a local temporal window. With the completed flows, we
propagate the content across video frames, and adopt the flow-guided
transformer to synthesize the rest corrupted regions. We decouple transformers
along temporal and spatial dimension, so that we can easily integrate the
locally relevant completed flows to instruct spatial attention only.
Furthermore, we design a flow-reweight module to precisely control the impact
of completed flows on each spatial transformer. For the sake of efficiency, we
introduce window partition strategy to both spatial and temporal transformers.
Especially in spatial transformer, we design a dual perspective spatial MHSA,
which integrates the global tokens to the window-based attention. Extensive
experiments demonstrate the effectiveness of the proposed method qualitatively
and quantitatively. Codes are available at https://github.com/hitachinsk/FGT."
Transformer Based Multi-Grained Features for Unsupervised Person Re-Identification,0.0369992,"Multi-grained features extracted from convolutional neural networks (CNNs)
have demonstrated their strong discrimination ability in supervised person
re-identification (Re-ID) tasks. Inspired by them, this work investigates the
way of extracting multi-grained features from a pure transformer network to
address the unsupervised Re-ID problem that is label-free but much more
challenging. To this end, we build a dual-branch network architecture based
upon a modified Vision Transformer (ViT). The local tokens output in each
branch are reshaped and then uniformly partitioned into multiple stripes to
generate part-level features, while the global tokens of two branches are
averaged to produce a global feature. Further, based upon offline-online
associated camera-aware proxies (O2CAP) that is a top-performing unsupervised
Re-ID method, we define offline and online contrastive learning losses with
respect to both global and part-level features to conduct unsupervised
learning. Extensive experiments on three person Re-ID datasets show that the
proposed method outperforms state-of-the-art unsupervised methods by a
considerable margin, greatly mitigating the gap to supervised counterparts.
Code will be available soon at https://github.com/RikoLi/WACV23-workshop-TMGF."
Learning Controllable 3D Level Generators,-1.0,"Procedural Content Generation via Reinforcement Learning (PCGRL) foregoes the
need for large human-authored data-sets and allows agents to train explicitly
on functional constraints, using computable, user-defined measures of quality
instead of target output. We explore the application of PCGRL to 3D domains, in
which content-generation tasks naturally have greater complexity and potential
pertinence to real-world applications. Here, we introduce several PCGRL tasks
for the 3D domain, Minecraft (Mojang Studios, 2009). These tasks will challenge
RL-based generators using affordances often found in 3D environments, such as
jumping, multiple dimensional movement, and gravity. We train an agent to
optimize each of these tasks to explore the capabilities of previous research
in PCGRL. This agent is able to generate relatively complex and diverse levels,
and generalize to random initial states and control targets. Controllability
tests in the presented tasks demonstrate their utility to analyze success and
failure for 3D generators."
HSGNet: Object Re-identification with Hierarchical Similarity Graph Network,0.0603983,"Object re-identification method is made up of backbone network, feature
aggregation, and loss function. However, most backbone networks lack a special
mechanism to handle rich scale variations and mine discriminative feature
representations. In this paper, we firstly design a hierarchical similarity
graph module (HSGM) to reduce the conflict of backbone and re-identification
networks. The designed HSGM builds a rich hierarchical graph to mine the
mapping relationships between global-local and local-local. Secondly, we divide
the feature map along with the spatial and channel directions in each
hierarchical graph. The HSGM applies the spatial features and channel features
extracted from different locations as nodes, respectively, and utilizes the
similarity scores between nodes to construct spatial and channel similarity
graphs. During the learning process of HSGM, we utilize a learnable parameter
to re-optimize the importance of each position, as well as evaluate the
correlation between different nodes. Thirdly, we develop a novel hierarchical
similarity graph network (HSGNet) by embedding the HSGM in the backbone
network. Furthermore, HSGM can be easily embedded into backbone networks of any
depth to improve object re-identification ability. Finally, extensive
experiments on three large-scale object datasets demonstrate that the proposed
HSGNet is superior to state-of-the-art object re-identification approaches."
Mitigating Artifacts in Real-World Video Super-Resolution Models,0.436746,"The recurrent structure is a prevalent framework for the task of video
super-resolution, which models the temporal dependency between frames via
hidden states. When applied to real-world scenarios with unknown and complex
degradations, hidden states tend to contain unpleasant artifacts and propagate
them to restored frames. In this circumstance, our analyses show that such
artifacts can be largely alleviated when the hidden state is replaced with a
cleaner counterpart. Based on the observations, we propose a Hidden State
Attention (HSA) module to mitigate artifacts in real-world video
super-resolution. Specifically, we first adopt various cheap filters to produce
a hidden state pool. For example, Gaussian blur filters are for smoothing
artifacts while sharpening filters are for enhancing details. To aggregate a
new hidden state that contains fewer artifacts from the hidden state pool, we
devise a Selective Cross Attention (SCA) module, in which the attention between
input features and each hidden state is calculated. Equipped with HSA, our
proposed method, namely FastRealVSR, is able to achieve 2x speedup while
obtaining better performance than Real-BasicVSR. Codes will be available at
https://github.com/TencentARC/FastRealVSR"
Reconstruction of observed mechanical motions with Artificial Intelligence tools,0.0433225,"The goal of this paper is to determine the laws of observed trajectories
assuming that there is a mechanical system in the background and using these
laws to continue the observed motion in a plausible way. The laws are
represented by neural networks with a limited number of parameters. The
training of the networks follows the Extreme Learning Machine idea. We
determine laws for different levels of embedding, thus we can represent not
only the equation of motion but also the symmetries of different kinds. In the
recursive numerical evolution of the system, we require the fulfillment of all
the observed laws, within the determined numerical precision. In this way, we
can successfully reconstruct both integrable and chaotic motions, as we
demonstrate in the example of the gravity pendulum and the double pendulum."
Guess What Moves: Unsupervised Video and Image Segmentation by Anticipating Motion,0.210135,"Motion, measured via optical flow, provides a powerful cue to discover and
learn objects in images and videos. However, compared to using appearance, it
has some blind spots, such as the fact that objects become invisible if they do
not move. In this work, we propose an approach that combines the strengths of
motion-based and appearance-based segmentation. We propose to supervise an
image segmentation network with the pretext task of predicting regions that are
likely to contain simple motion patterns, and thus likely to correspond to
objects. As the model only uses a single image as input, we can apply it in two
settings: unsupervised video segmentation, and unsupervised image segmentation.
We achieve state-of-the-art results for videos, and demonstrate the viability
of our approach on still images containing novel objects. Additionally we
experiment with different motion models and optical flow backbones and find the
method to be robust to these change. Project page and code available at
https://www.robots.ox.ac.uk/~vgg/research/gwm."
Consistency Learning via Decoding Path Augmentation for Transformers in Human Object Interaction Detection,0.0588264,"Human-Object Interaction detection is a holistic visual recognition task that
entails object detection as well as interaction classification. Previous works
of HOI detection has been addressed by the various compositions of subset
predictions, e.g., Image -> HO -> I, Image -> HI -> O. Recently, transformer
based architecture for HOI has emerged, which directly predicts the HOI
triplets in an end-to-end fashion (Image -> HOI). Motivated by various
inference paths for HOI detection, we propose cross-path consistency learning
(CPC), which is a novel end-to-end learning strategy to improve HOI detection
for transformers by leveraging augmented decoding paths. CPC learning enforces
all the possible predictions from permuted inference sequences to be
consistent. This simple scheme makes the model learn consistent
representations, thereby improving generalization without increasing model
capacity. Our experiments demonstrate the effectiveness of our method, and we
achieved significant improvement on V-COCO and HICO-DET compared to the
baseline models. Our code is available at https://github.com/mlvlab/CPChoi."
Are disentangled representations all you need to build speaker anonymization systems?,0.100921,"Speech signals contain a lot of sensitive information, such as the speaker's
identity, which raises privacy concerns when speech data get collected. Speaker
anonymization aims to transform a speech signal to remove the source speaker's
identity while leaving the spoken content unchanged. Current methods perform
the transformation by relying on content/speaker disentanglement and voice
conversion. Usually, an acoustic model from an automatic speech recognition
system extracts the content representation while an x-vector system extracts
the speaker representation. Prior work has shown that the extracted features
are not perfectly disentangled. This paper tackles how to improve features
disentanglement, and thus the converted anonymized speech. We propose enhancing
the disentanglement by removing speaker information from the acoustic model
using vector quantization. Evaluation done using the VoicePrivacy 2022 toolkit
showed that vector quantization helps conceal the original speaker identity
while maintaining utility for speech recognition."
Domain Adaptation for Time-Series Classification to Mitigate Covariate Shift,0.0541704,"The performance of a machine learning model degrades when it is applied to
data from a similar but different domain than the data it has initially been
trained on. To mitigate this domain shift problem, domain adaptation (DA)
techniques search for an optimal transformation that converts the (current)
input data from a source domain to a target domain to learn a domain-invariant
representation that reduces domain discrepancy. This paper proposes a novel
supervised DA based on two steps. First, we search for an optimal
class-dependent transformation from the source to the target domain from a few
samples. We consider optimal transport methods such as the earth mover's
distance, Sinkhorn transport and correlation alignment. Second, we use
embedding similarity techniques to select the corresponding transformation at
inference. We use correlation metrics and higher-order moment matching
techniques. We conduct an extensive evaluation on time-series datasets with
domain shift including simulated and various online handwriting datasets to
demonstrate the performance."
Walk this Way! Entity Walks and Property Walks for RDF2vec,0.349561,"RDF2vec is a knowledge graph embedding mechanism which first extracts
sequences from knowledge graphs by performing random walks, then feeds those
into the word embedding algorithm word2vec for computing vector representations
for entities. In this poster, we introduce two new flavors of walk extraction
coined e-walks and p-walks, which put an emphasis on the structure or the
neighborhood of an entity respectively, and thereby allow for creating
embeddings which focus on similarity or relatedness. By combining the walk
strategies with order-aware and classic RDF2vec, as well as CBOW and skip-gram
word2vec embeddings, we conduct a preliminary evaluation with a total of 12
RDF2vec variants."
Hybrid-Regressive Neural Machine Translation,0.0985043,"In this work, we empirically confirm that non-autoregressive translation with
an iterative refinement mechanism (IR-NAT) suffers from poor acceleration
robustness because it is more sensitive to decoding batch size and computing
device setting than autoregressive translation (AT). Inspired by it, we attempt
to investigate how to combine the strengths of autoregressive and
non-autoregressive translation paradigms better. To this end, we demonstrate
through synthetic experiments that prompting a small number of AT's predictions
can promote one-shot non-autoregressive translation to achieve the equivalent
performance of IR-NAT. Following this line, we propose a new two-stage
translation prototype called hybrid-regressive translation (HRT). Specifically,
HRT first generates discontinuous sequences via autoregression (e.g., make a
prediction every k tokens, k>1) and then fills in all previously skipped tokens
at once in a non-autoregressive manner. We also propose a bag of techniques to
effectively and efficiently train HRT without adding any model parameters. HRT
achieves the state-of-the-art BLEU score of 28.49 on the WMT En-De task and is
at least 1.5x faster than AT, regardless of batch size and device. In addition,
another bonus of HRT is that it successfully inherits the good characteristics
of AT in the deep-encoder-shallow-decoder architecture. Concretely, compared to
the vanilla HRT with a 6-layer encoder and 6-layer decoder, the inference speed
of HRT with a 12-layer encoder and 1-layer decoder is further doubled on both
GPU and CPU without BLEU loss."
Brain tumor detection using artificial convolutional neural networks,0.194736,"In this paper, a convolutional neural network (CNN) was used to classify NMR
images of human brains with 4 different types of tumors: meningioma, glioma and
pituitary gland tumors. During the training phase of this project, an accuracy
of 100% was obtained, meanwhile, in the evaluation phase the precision was 96%."
Data Feedback Loops: Model-driven Amplification of Dataset Biases,0.0981219,"Datasets scraped from the internet have been critical to the successes of
large-scale machine learning. Yet, this very success puts the utility of future
internet-derived datasets at potential risk, as model outputs begin to replace
human annotations as a source of supervision.
  In this work, we first formalize a system where interactions with one model
are recorded as history and scraped as training data in the future. We then
analyze its stability over time by tracking changes to a test-time bias
statistic (e.g. gender bias of model predictions). We find that the degree of
bias amplification is closely linked to whether the model's outputs behave like
samples from the training distribution, a behavior which we characterize and
define as consistent calibration. Experiments in three conditional prediction
scenarios - image classification, visual role-labeling, and language generation
- demonstrate that models that exhibit a sampling-like behavior are more
calibrated and thus more stable. Based on this insight, we propose an
intervention to help calibrate and stabilize unstable feedback systems.
  Code is available at https://github.com/rtaori/data_feedback."
Swin MAE: Masked Autoencoders for Small Datasets,0.12798,"The development of deep learning models in medical image analysis is majorly
limited by the lack of large-sized and well-annotated datasets. Unsupervised
learning does not require labels and is more suitable for solving medical image
analysis problems. However, most of the current unsupervised learning methods
need to be applied to large datasets. To make unsupervised learning applicable
to small datasets, we proposed Swin MAE, which is a masked autoencoder with
Swin Transformer as its backbone. Even on a dataset of only a few thousand
medical images and without using any pre-trained models, Swin MAE is still able
to learn useful semantic features purely from images. It can equal or even
slightly outperform the supervised model obtained by Swin Transformer trained
on ImageNet in terms of the transfer learning results of downstream tasks. The
code is publicly available at https://github.com/Zian-Xu/Swin-MAE."
Single-Turn Debate Does Not Help Humans Answer Hard Reading-Comprehension Questions,0.284149,"Current QA systems can generate reasonable-sounding yet false answers without
explanation or evidence for the generated answer, which is especially
problematic when humans cannot readily check the model's answers. This presents
a challenge for building trust in machine learning systems. We take inspiration
from real-world situations where difficult questions are answered by
considering opposing sides (see Irving et al., 2018). For multiple-choice QA
examples, we build a dataset of single arguments for both a correct and
incorrect answer option in a debate-style set-up as an initial step in training
models to produce explanations for two candidate answers. We use long contexts
-- humans familiar with the context write convincing explanations for
pre-selected correct and incorrect answers, and we test if those explanations
allow humans who have not read the full context to more accurately determine
the correct answer. We do not find that explanations in our set-up improve
human accuracy, but a baseline condition shows that providing human-selected
text snippets does improve accuracy. We use these findings to suggest ways of
improving the debate set up for future data collection efforts."
FRAME: Evaluating Rationale-Label Consistency Metrics for Free-Text Rationales,0.0682532,"Following how humans communicate, free-text rationales aim to use natural
language to explain neural language model (LM) behavior. However, free-text
rationales' unconstrained nature makes them prone to hallucination, so it is
important to have metrics for free-text rationale quality. Existing free-text
rationale metrics measure how consistent the rationale is with the LM's
predicted label, but there is no protocol for assessing such metrics'
reliability. Thus, we propose FRAME, a framework for evaluating rationale-label
consistency (RLC) metrics for free-text rationales. FRAME is based on three
axioms: (1) good metrics should yield highest scores for reference rationales,
which maximize RLC by construction; (2) good metrics should be appropriately
sensitive to semantic perturbation of rationales; and (3) good metrics should
be robust to variation in the LM's task performance. Across three text
classification datasets, we show that existing RLC metrics cannot satisfy all
three FRAME axioms, since they are implemented via model pretraining which
muddles the metric's signal. Then, we introduce a non-pretraining RLC metric
that greatly outperforms baselines on (1) and (3), while performing
competitively on (2). Finally, we discuss the limitations of using RLC to
evaluate free-text rationales."
Concept Bottleneck Model with Additional Unsupervised Concepts,0.901364,"With the increasing demands for accountability, interpretability is becoming
an essential capability for real-world AI applications. However, most methods
utilize post-hoc approaches rather than training the interpretable model. In
this article, we propose a novel interpretable model based on the concept
bottleneck model (CBM). CBM uses concept labels to train an intermediate layer
as the additional visible layer. However, because the number of concept labels
restricts the dimension of this layer, it is difficult to obtain high accuracy
with a small number of labels. To address this issue, we integrate supervised
concepts with unsupervised ones trained with self-explaining neural networks
(SENNs). By seamlessly training these two types of concepts while reducing the
amount of computation, we can obtain both supervised and unsupervised concepts
simultaneously, even for large-sized images. We refer to the proposed model as
the concept bottleneck model with additional unsupervised concepts (CBM-AUC).
We experimentally confirmed that the proposed model outperformed CBM and SENN.
We also visualized the saliency map of each concept and confirmed that it was
consistent with the semantic meanings."
Fine-tuned Sentiment Analysis of COVID-19 Vaccine-Related Social Media Data: Comparative Study,0.0457077,"This study investigated and compared public sentiment related to COVID-19
vaccines expressed on two popular social media platforms, Reddit and Twitter,
harvested from January 1, 2020, to March 1, 2022. To accomplish this task, we
created a fine-tuned DistilRoBERTa model to predict sentiments of approximately
9.5 million Tweets and 70 thousand Reddit comments. To fine-tune our model, our
team manually labeled the sentiment of 3600 Tweets and then augmented our
dataset by the method of back-translation. Text sentiment for each social media
platform was then classified with our fine-tuned model using Python and the
Huggingface sentiment analysis pipeline. Our results determined that the
average sentiment expressed on Twitter was more negative (52% positive) than
positive and the sentiment expressed on Reddit was more positive than negative
(53% positive). Though average sentiment was found to vary between these social
media platforms, both displayed similar behavior related to sentiment shared at
key vaccine-related developments during the pandemic. Considering this similar
trend in shared sentiment demonstrated across social media platforms, Twitter
and Reddit continue to be valuable data sources that public health officials
can utilize to strengthen vaccine confidence and combat misinformation. As the
spread of misinformation poses a range of psychological and psychosocial risks
(anxiety, fear, etc.), there is an urgency in understanding the public
perspective and attitude toward shared falsities. Comprehensive educational
delivery systems tailored to the population's expressed sentiments that
facilitate digital literacy, health information-seeking behavior, and precision
health promotion could aid in clarifying such misinformation."
Lightweight Monocular Depth Estimation through Guided Decoding,0.154182,"We present a lightweight encoder-decoder architecture for monocular depth
estimation, specifically designed for embedded platforms. Our main contribution
is the Guided Upsampling Block (GUB) for building the decoder of our model.
Motivated by the concept of guided image filtering, GUB relies on the image to
guide the decoder on upsampling the feature representation and the depth map
reconstruction, achieving high resolution results with fine-grained details.
Based on multiple GUBs, our model outperforms the related methods on the NYU
Depth V2 dataset in terms of accuracy while delivering up to 35.1 fps on the
NVIDIA Jetson Nano and up to 144.5 fps on the NVIDIA Xavier NX. Similarly, on
the KITTI dataset, inference is possible with up to 23.7 fps on the Jetson Nano
and 102.9 fps on the Xavier NX. Our code and models are made publicly
available."
Learned k-NN Distance Estimation,0.0755769,"Big data mining is well known to be an important task for data science,
because it can provide useful observations and new knowledge hidden in given
large datasets. Proximity-based data analysis is particularly utilized in many
real-life applications. In such analysis, the distances to k nearest neighbors
are usually employed, thus its main bottleneck is derived from data retrieval.
Much efforts have been made to improve the efficiency of these analyses.
However, they still incur large costs, because they essentially need many data
accesses. To avoid this issue, we propose a machine-learning technique that
quickly and accurately estimates the k-NN distances (i.e., distances to the k
nearest neighbors) of a given query. We train a fully connected neural network
model and utilize pivots to achieve accurate estimation. Our model is designed
to have useful advantages: it infers distances to the k-NNs at a time, its
inference time is O(1) (no data accesses are incurred), but it keeps high
accuracy. Our experimental results and case studies on real datasets
demonstrate the efficiency and effectiveness of our solution."
Splatting-based Synthesis for Video Frame Interpolation,0.269029,"Frame interpolation is an essential video processing technique that adjusts
the temporal resolution of an image sequence. While deep learning has brought
great improvements to the area of video frame interpolation, techniques that
make use of neural networks can typically not easily be deployed in practical
applications like a video editor since they are either computationally too
demanding or fail at high resolutions. In contrast, we propose a deep learning
approach that solely relies on splatting to synthesize interpolated frames.
This splatting-based synthesis for video frame interpolation is not only much
faster than similar approaches, especially for multi-frame interpolation, but
can also yield new state-of-the-art results at high resolutions."
Unsupervised 4D LiDAR Moving Object Segmentation in Stationary Settings with Multivariate Occupancy Time Series,0.0848638,"In this work, we address the problem of unsupervised moving object
segmentation (MOS) in 4D LiDAR data recorded from a stationary sensor, where no
ground truth annotations are involved. Deep learning-based state-of-the-art
methods for LiDAR MOS strongly depend on annotated ground truth data, which is
expensive to obtain and scarce in existence. To close this gap in the
stationary setting, we propose a novel 4D LiDAR representation based on
multivariate time series that relaxes the problem of unsupervised MOS to a time
series clustering problem. More specifically, we propose modeling the change in
occupancy of a voxel by a multivariate occupancy time series (MOTS), which
captures spatio-temporal occupancy changes on the voxel level and its
surrounding neighborhood. To perform unsupervised MOS, we train a neural
network in a self-supervised manner to encode MOTS into voxel-level feature
representations, which can be partitioned by a clustering algorithm into moving
or stationary. Experiments on stationary scenes from the Raw KITTI dataset show
that our fully unsupervised approach achieves performance that is comparable to
that of supervised state-of-the-art approaches."
Contrastive Language-Image Pre-Training with Knowledge Graphs,0.061424,"Recent years have witnessed the fast development of large-scale pre-training
frameworks that can extract multi-modal representations in a unified form and
achieve promising performances when transferred to downstream tasks.
Nevertheless, existing approaches mainly focus on pre-training with simple
image-text pairs, while neglecting the semantic connections between concepts
from different modalities. In this paper, we propose a knowledge-based
pre-training framework, dubbed Knowledge-CLIP, which injects semantic
information into the widely used CLIP model. Through introducing
knowledge-based objectives in the pre-training process and utilizing different
types of knowledge graphs as training data, our model can semantically align
the representations in vision and language with higher quality, and enhance the
reasoning ability across scenarios and modalities. Extensive experiments on
various vision-language downstream tasks demonstrate the effectiveness of
Knowledge-CLIP compared with the original CLIP and competitive baselines."
SoK: Differential Privacy on Graph-Structured Data,0.06181,"In this work, we study the applications of differential privacy (DP) in the
context of graph-structured data. We discuss the formulations of DP applicable
to the publication of graphs and their associated statistics as well as machine
learning on graph-based data, including graph neural networks (GNNs). The
formulation of DP in the context of graph-structured data is difficult, as
individual data points are interconnected (often non-linearly or sparsely).
This connectivity complicates the computation of individual privacy loss in
differentially private learning. The problem is exacerbated by an absence of a
single, well-established formulation of DP in graph settings. This issue
extends to the domain of GNNs, rendering private machine learning on
graph-structured data a challenging task. A lack of prior systematisation work
motivated us to study graph-based learning from a privacy perspective. In this
work, we systematise different formulations of DP on graphs, discuss challenges
and promising applications, including the GNN domain. We compare and separate
works into graph analysis tasks and graph learning tasks with GNNs. Finally, we
conclude our work with a discussion of open questions and potential directions
for further research in this area."
UViM: A Unified Modeling Approach for Vision with Learned Guiding Codes,0.930517,"We introduce UViM, a unified approach capable of modeling a wide range of
computer vision tasks. In contrast to previous models, UViM has the same
functional form for all tasks; it requires no task-specific modifications which
require extensive human expertise. The approach involves two components: (I) a
base model (feed-forward) which is trained to directly predict raw vision
outputs, guided by a learned discrete code and (II) a language model
(autoregressive) that is trained to generate the guiding code. These components
complement each other: the language model is well-suited to modeling structured
interdependent data, while the base model is efficient at dealing with
high-dimensional outputs. We demonstrate the effectiveness of UViM on three
diverse and challenging vision tasks: panoptic segmentation, depth prediction
and image colorization, where we achieve competitive and near state-of-the-art
results. Our experimental results suggest that UViM is a promising candidate
for a unified modeling approach in computer vision."
Learning Task-relevant Representations for Generalization via Characteristic Functions of Reward Sequence Distributions,0.0710647,"Generalization across different environments with the same tasks is critical
for successful applications of visual reinforcement learning (RL) in real
scenarios. However, visual distractions -- which are common in real scenes --
from high-dimensional observations can be hurtful to the learned
representations in visual RL, thus degrading the performance of generalization.
To tackle this problem, we propose a novel approach, namely Characteristic
Reward Sequence Prediction (CRESP), to extract the task-relevant information by
learning reward sequence distributions (RSDs), as the reward signals are
task-relevant in RL and invariant to visual distractions. Specifically, to
effectively capture the task-relevant information via RSDs, CRESP introduces an
auxiliary task -- that is, predicting the characteristic functions of RSDs --
to learn task-relevant representations, because we can well approximate the
high-dimensional distributions by leveraging the corresponding characteristic
functions. Experiments demonstrate that CRESP significantly improves the
performance of generalization on unseen environments, outperforming several
state-of-the-arts on DeepMind Control tasks with different visual distractions."
The State of Sparse Training in Deep Reinforcement Learning,0.0412124,"The use of sparse neural networks has seen rapid growth in recent years,
particularly in computer vision. Their appeal stems largely from the reduced
number of parameters required to train and store, as well as in an increase in
learning efficiency. Somewhat surprisingly, there have been very few efforts
exploring their use in Deep Reinforcement Learning (DRL). In this work we
perform a systematic investigation into applying a number of existing sparse
training techniques on a variety of DRL agents and environments. Our results
corroborate the findings from sparse training in the computer vision domain -
sparse networks perform better than dense networks for the same parameter count
- in the DRL domain. We provide detailed analyses on how the various components
in DRL are affected by the use of sparse networks and conclude by suggesting
promising avenues for improving the effectiveness of sparse training methods,
as well as for advancing their use in DRL."
Learning Quantum Entanglement Distillation with Noisy Classical Communications,0.0705383,"Quantum networking relies on the management and exploitation of entanglement.
Practical sources of entangled qubits are imperfect, producing mixed quantum
state with reduced fidelity with respect to ideal Bell pairs. Therefore, an
important primitive for quantum networking is entanglement distillation, whose
goal is to enhance the fidelity of entangled qubits through local operations
and classical communication (LOCC). Existing distillation protocols assume the
availability of ideal, noiseless, communication channels. In this paper, we
study the case in which communication takes place over noisy binary symmetric
channels. We propose to implement local processing through parameterized
quantum circuits (PQCs) that are optimized to maximize the average fidelity,
while accounting for communication errors. The introduced approach, Noise
Aware-LOCCNet (NA-LOCCNet), is shown to have significant advantages over
existing protocols designed for noiseless communications."
"""Think Before You Speak"": Improving Multi-Action Dialog Policy by Planning Single-Action Dialogs",0.0985866,"Multi-action dialog policy (MADP), which generates multiple atomic dialog
actions per turn, has been widely applied in task-oriented dialog systems to
provide expressive and efficient system responses. Existing MADP models usually
imitate action combinations from the labeled multi-action dialog samples. Due
to data limitations, they generalize poorly toward unseen dialog flows. While
interactive learning and reinforcement learning algorithms can be applied to
incorporate external data sources of real users and user simulators, they take
significant manual effort to build and suffer from instability. To address
these issues, we propose Planning Enhanced Dialog Policy (PEDP), a novel
multi-task learning framework that learns single-action dialog dynamics to
enhance multi-action prediction. Our PEDP method employs model-based planning
for conceiving what to express before deciding the current response through
simulating single-action dialogs. Experimental results on the MultiWOZ dataset
demonstrate that our fully supervised learning-based method achieves a solid
task success rate of 90.6%, improving 3% compared to the state-of-the-art
methods."
Adversarially-Aware Robust Object Detector,0.122694,"Object detection, as a fundamental computer vision task, has achieved a
remarkable progress with the emergence of deep neural networks. Nevertheless,
few works explore the adversarial robustness of object detectors to resist
adversarial attacks for practical applications in various real-world scenarios.
Detectors have been greatly challenged by unnoticeable perturbation, with sharp
performance drop on clean images and extremely poor performance on adversarial
images. In this work, we empirically explore the model training for adversarial
robustness in object detection, which greatly attributes to the conflict
between learning clean images and adversarial images. To mitigate this issue,
we propose a Robust Detector (RobustDet) based on adversarially-aware
convolution to disentangle gradients for model learning on clean and
adversarial images. RobustDet also employs the Adversarial Image Discriminator
(AID) and Consistent Features with Reconstruction (CFR) to ensure a reliable
robustness. Extensive experiments on PASCAL VOC and MS-COCO demonstrate that
our model effectively disentangles gradients and significantly enhances the
detection robustness with maintaining the detection ability on clean images."
Domain-Oriented Prefix-Tuning: Towards Efficient and Generalizable Fine-tuning for Zero-Shot Dialogue Summarization,0.552302,"The most advanced abstractive dialogue summarizers lack generalization
ability on new domains and the existing researches for domain adaptation in
summarization generally rely on large-scale pre-trainings. To explore the
lightweight fine-tuning methods for domain adaptation of dialogue
summarization, in this paper, we propose an efficient and generalizable
Domain-Oriented Prefix-tuning model, which utilizes a domain word initialized
prefix module to alleviate domain entanglement and adopts discrete prompts to
guide the model to focus on key contents of dialogues and enhance model
generalization. We conduct zero-shot experiments and build domain adaptation
benchmarks on two multi-domain dialogue summarization datasets, TODSum and
QMSum. Adequate experiments and qualitative analysis prove the effectiveness of
our methods."
An LSTM model for Twitter Sentiment Analysis,0.0364171,"Sentiment analysis on social media such as Twitter provides organizations and
individuals an effective way to monitor public emotions towards them and their
competitors. As a result, sentiment analysis has become an important and
challenging task. In this work, we have collected seven publicly available and
manually annotated twitter sentiment datasets. We create a new training and
testing dataset from the collected datasets. We develop an LSTM model to
classify sentiment of a tweet and evaluate the model with the new dataset."
Learning to See Through with Events,0.211256,"Although synthetic aperture imaging (SAI) can achieve the seeing-through
effect by blurring out off-focus foreground occlusions while recovering
in-focus occluded scenes from multi-view images, its performance is often
deteriorated by dense occlusions and extreme lighting conditions. To address
the problem, this paper presents an Event-based SAI (E-SAI) method by relying
on the asynchronous events with extremely low latency and high dynamic range
acquired by an event camera. Specifically, the collected events are first
refocused by a Refocus-Net module to align in-focus events while scattering out
off-focus ones. Following that, a hybrid network composed of spiking neural
networks (SNNs) and convolutional neural networks (CNNs) is proposed to encode
the spatio-temporal information from the refocused events and reconstruct a
visual image of the occluded targets. Extensive experiments demonstrate that
our proposed E-SAI method can achieve remarkable performance in dealing with
very dense occlusions and extreme lighting conditions and produce high-quality
images from pure events. Codes and datasets are available at
https://dvs-whu.cn/projects/esai/."
DSI++: Updating Transformer Memory with New Documents,0.638969,"Differentiable Search Indices (DSIs) encode a corpus of documents in model
parameters and use the same model to answer user queries directly. Despite the
strong performance of DSI models, deploying them in situations where the corpus
changes over time is computationally expensive because reindexing the corpus
requires re-training the model. In this work, we introduce DSI++, a continual
learning challenge for DSI to incrementally index new documents while being
able to answer queries related to both previously and newly indexed documents.
Across different model scales and document identifier representations, we show
that continual indexing of new documents leads to considerable forgetting of
previously indexed documents. We also hypothesize and verify that the model
experiences forgetting events during training, leading to unstable learning. To
mitigate these issues, we investigate two approaches. The first focuses on
modifying the training dynamics. Flatter minima implicitly alleviate
forgetting, so we optimize for flatter loss basins and show that the model
stably memorizes more documents ($+12\%$). Next, we introduce a generative
memory to sample pseudo-queries for documents and supplement them during
continual indexing to prevent forgetting for the retrieval task. Extensive
experiments on novel continual indexing benchmarks based on Natural Questions
(NQ) and MS MARCO demonstrate that our proposed solution mitigates forgetting
significantly. Concretely, it improves the average Hits@10 by $+21.1\%$ over
competitive baselines for NQ and requires $6$ times fewer model updates
compared to re-training the DSI model for incrementally indexing five corpora
in a sequence."
Apport des ontologies pour le calcul de la similarité sémantique au sein d'un système de recommandation,0.136331,"Measurement of the semantic relatedness or likeness between terms, words, or
text data plays an important role in different applications dealing with
textual data such as knowledge acquisition, recommender system, and natural
language processing. Over the past few years, many ontologies have been
developed and used as a form of structured representation of knowledge bases
for information systems. The calculation of semantic similarity from ontology
has developed and depending on the context is complemented by other similarity
calculation methods. In this paper, we propose and carry on an approach for the
calculation of ontology-based semantic similarity using in the context of a
recommender system."
ADAS: A Direct Adaptation Strategy for Multi-Target Domain Adaptive Semantic Segmentation,0.184127,"In this paper, we present a direct adaptation strategy (ADAS), which aims to
directly adapt a single model to multiple target domains in a semantic
segmentation task without pretrained domain-specific models. To do so, we
design a multi-target domain transfer network (MTDT-Net) that aligns visual
attributes across domains by transferring the domain distinctive features
through a new target adaptive denormalization (TAD) module. Moreover, we
propose a bi-directional adaptive region selection (BARS) that reduces the
attribute ambiguity among the class labels by adaptively selecting the regions
with consistent feature statistics. We show that our single MTDT-Net can
synthesize visually pleasing domain transferred images with complex driving
datasets, and BARS effectively filters out the unnecessary region of training
images for each target domain. With the collaboration of MTDT-Net and BARS, our
ADAS achieves state-of-the-art performance for multi-target domain adaptation
(MTDA). To the best of our knowledge, our method is the first MTDA method that
directly adapts to multiple domains in semantic segmentation."
Using Forwards-Backwards Models to Approximate MDP Homomorphisms,0.0,"Reinforcement learning agents must painstakingly learn through trial and
error what sets of state-action pairs are value equivalent -- requiring an
often prohibitively large amount of environment experience. MDP homomorphisms
have been proposed that reduce the MDP of an environment to an abstract MDP,
enabling better sample efficiency. Consequently, impressive improvements have
been achieved when a suitable homomorphism can be constructed a priori --
usually by exploiting a practitioner's knowledge of environment symmetries. We
propose a novel approach to constructing homomorphisms in discrete action
spaces, which uses a learnt model of environment dynamics to infer which
state-action pairs lead to the same state -- which can reduce the size of the
state-action space by a factor as large as the cardinality of the original
action space. In MinAtar, we report an almost 4x improvement over a value-based
off-policy baseline in the low sample limit, when averaging over all games and
optimizers."
Using Natural Language and Program Abstractions to Instill Human Inductive Biases in Machines,0.169591,"Strong inductive biases give humans the ability to quickly learn to perform a
variety of tasks. Although meta-learning is a method to endow neural networks
with useful inductive biases, agents trained by meta-learning may sometimes
acquire very different strategies from humans. We show that co-training these
agents on predicting representations from natural language task descriptions
and programs induced to generate such tasks guides them toward more human-like
inductive biases. Human-generated language descriptions and program induction
models that add new learned primitives both contain abstract concepts that can
compress description length. Co-training on these representations result in
more human-like behavior in downstream meta-reinforcement learning agents than
less abstract controls (synthetic language descriptions, program induction
without learned primitives), suggesting that the abstraction supported by these
representations is key."
CrossFormer: Cross Spatio-Temporal Transformer for 3D Human Pose Estimation,0.394304,"3D human pose estimation can be handled by encoding the geometric
dependencies between the body parts and enforcing the kinematic constraints.
Recently, Transformer has been adopted to encode the long-range dependencies
between the joints in the spatial and temporal domains. While they had shown
excellence in long-range dependencies, studies have noted the need for
improving the locality of vision Transformers. In this direction, we propose a
novel pose estimation Transformer featuring rich representations of body joints
critical for capturing subtle changes across frames (i.e., inter-feature
representation). Specifically, through two novel interaction modules;
Cross-Joint Interaction and Cross-Frame Interaction, the model explicitly
encodes the local and global dependencies between the body joints. The proposed
architecture achieved state-of-the-art performance on two popular 3D human pose
estimation datasets, Human3.6 and MPI-INF-3DHP. In particular, our proposed
CrossFormer method boosts performance by 0.9% and 0.3%, compared to the closest
counterpart, PoseFormer, using the detected 2D poses and ground-truth settings
respectively."
Pre-training to Match for Unified Low-shot Relation Extraction,0.536421,"Low-shot relation extraction~(RE) aims to recognize novel relations with very
few or even no samples, which is critical in real scenario application.
Few-shot and zero-shot RE are two representative low-shot RE tasks, which seem
to be with similar target but require totally different underlying abilities.
In this paper, we propose Multi-Choice Matching Networks to unify low-shot
relation extraction. To fill in the gap between zero-shot and few-shot RE, we
propose the triplet-paraphrase meta-training, which leverages triplet
paraphrase to pre-train zero-shot label matching ability and uses meta-learning
paradigm to learn few-shot instance summarizing ability. Experimental results
on three different low-shot RE tasks show that the proposed method outperforms
strong baselines by a large margin, and achieve the best performance on
few-shot RE leaderboard."
"When a sentence does not introduce a discourse entity, Transformer-based models still sometimes refer to it",0.231077,"Understanding longer narratives or participating in conversations requires
tracking of discourse entities that have been mentioned. Indefinite noun
phrases (NPs), such as 'a dog', frequently introduce discourse entities but
this behavior is modulated by sentential operators such as negation. For
example, 'a dog' in 'Arthur doesn't own a dog' does not introduce a discourse
entity due to the presence of negation. In this work, we adapt the
psycholinguistic assessment of language models paradigm to higher-level
linguistic phenomena and introduce an English evaluation suite that targets the
knowledge of the interactions between sentential operators and indefinite NPs.
We use this evaluation suite for a fine-grained investigation of the entity
tracking abilities of the Transformer-based models GPT-2 and GPT-3. We find
that while the models are to a certain extent sensitive to the interactions we
investigate, they are all challenged by the presence of multiple NPs and their
behavior is not systematic, which suggests that even models at the scale of
GPT-3 do not fully acquire basic entity tracking abilities."
Robots-Dont-Cry: Understanding Falsely Anthropomorphic Utterances in Dialog Systems,0.0285097,"Dialog systems are often designed or trained to output human-like responses.
However, some responses may be impossible for a machine to truthfully say (e.g.
""that movie made me cry""). Highly anthropomorphic responses might make users
uncomfortable or implicitly deceive them into thinking they are interacting
with a human. We collect human ratings on the feasibility of approximately 900
two-turn dialogs sampled from 9 diverse data sources. Ratings are for two
hypothetical machine embodiments: a futuristic humanoid robot and a digital
assistant. We find that for some data-sources commonly used to train dialog
systems, 20-30% of utterances are not viewed as possible for a machine. Rating
is marginally affected by machine embodiment. We explore qualitative and
quantitative reasons for these ratings. Finally, we build classifiers and
explore how modeling configuration might affect output permissibly, and discuss
implications for building less falsely anthropomorphic dialog systems."
Zero Experience Required: Plug & Play Modular Transfer Learning for Semantic Visual Navigation,0.205302,"In reinforcement learning for visual navigation, it is common to develop a
model for each new task, and train that model from scratch with task-specific
interactions in 3D environments. However, this process is expensive; massive
amounts of interactions are needed for the model to generalize well. Moreover,
this process is repeated whenever there is a change in the task type or the
goal modality. We present a unified approach to visual navigation using a novel
modular transfer learning model. Our model can effectively leverage its
experience from one source task and apply it to multiple target tasks (e.g.,
ObjectNav, RoomNav, ViewNav) with various goal modalities (e.g., image, sketch,
audio, label). Furthermore, our model enables zero-shot experience learning,
whereby it can solve the target tasks without receiving any task-specific
interactive training. Our experiments on multiple photorealistic datasets and
challenging tasks show that our approach learns faster, generalizes better, and
outperforms SoTA models by a significant margin."
Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling,0.0281999,"Recent studies in using deep reinforcement learning (DRL) to solve Job-shop
scheduling problems (JSSP) focus on construction heuristics. However, their
performance is still far from optimality, mainly because the underlying graph
representation scheme is unsuitable for modelling partial solutions at each
construction step. This paper proposes a novel DRL-guided improvement heuristic
for solving JSSP, where graph representation is employed to encode complete
solutions. We design a Graph Neural-Network-based representation scheme,
consisting of two modules to effectively capture the information of dynamic
topology and different types of nodes in graphs encountered during the
improvement process. To speed up solution evaluation during improvement, we
present a novel message-passing mechanism that can evaluate multiple solutions
simultaneously. We prove that the computational complexity of our method scales
linearly with problem size. Experiments on classic benchmarks show that the
improvement policy learned by our method outperforms state-of-the-art DRL-based
methods by a large margin."
Few-Shot Fine-Grained Entity Typing with Automatic Label Interpretation and Instance Generation,0.127394,"We study the problem of few-shot Fine-grained Entity Typing (FET), where only
a few annotated entity mentions with contexts are given for each entity type.
Recently, prompt-based tuning has demonstrated superior performance to standard
fine-tuning in few-shot scenarios by formulating the entity type classification
task as a ''fill-in-the-blank'' problem. This allows effective utilization of
the strong language modeling capability of Pre-trained Language Models (PLMs).
Despite the success of current prompt-based tuning approaches, two major
challenges remain: (1) the verbalizer in prompts is either manually designed or
constructed from external knowledge bases, without considering the target
corpus and label hierarchy information, and (2) current approaches mainly
utilize the representation power of PLMs, but have not explored their
generation power acquired through extensive general-domain pre-training. In
this work, we propose a novel framework for few-shot FET consisting of two
modules: (1) an entity type label interpretation module automatically learns to
relate type labels to the vocabulary by jointly leveraging few-shot instances
and the label hierarchy, and (2) a type-based contextualized instance generator
produces new instances based on given instances to enlarge the training set for
better generalization. On three benchmark datasets, our model outperforms
existing methods by significant margins. Code can be found at
https://github.com/teapot123/Fine-Grained-Entity-Typing."
Stain Isolation-based Guidance for Improved Stain Translation,0.17324,"Unsupervised and unpaired domain translation using generative adversarial
neural networks, and more precisely CycleGAN, is state of the art for the stain
translation of histopathology images. It often, however, suffers from the
presence of cycle-consistent but non structure-preserving errors. We propose an
alternative approach to the set of methods which, relying on segmentation
consistency, enable the preservation of pathology structures. Focusing on
immunohistochemistry (IHC) and multiplexed immunofluorescence (mIF), we
introduce a simple yet effective guidance scheme as a loss function that
leverages the consistency of stain translation with stain isolation.
Qualitative and quantitative experiments show the ability of the proposed
approach to improve translation between the two domains."
Why Should Adversarial Perturbations be Imperceptible? Rethink the Research Paradigm in Adversarial NLP,0.057532,"Textual adversarial samples play important roles in multiple subfields of NLP
research, including security, evaluation, explainability, and data
augmentation. However, most work mixes all these roles, obscuring the problem
definitions and research goals of the security role that aims to reveal the
practical concerns of NLP models. In this paper, we rethink the research
paradigm of textual adversarial samples in security scenarios. We discuss the
deficiencies in previous work and propose our suggestions that the research on
the Security-oriented adversarial NLP (SoadNLP) should: (1) evaluate their
methods on security tasks to demonstrate the real-world concerns; (2) consider
real-world attackers' goals, instead of developing impractical methods. To this
end, we first collect, process, and release a security datasets collection
Advbench. Then, we reformalize the task and adjust the emphasis on different
goals in SoadNLP. Next, we propose a simple method based on heuristic rules
that can easily fulfill the actual adversarial goals to simulate real-world
attack methods. We conduct experiments on both the attack and the defense sides
on Advbench. Experimental results show that our method has higher practical
value, indicating that the research paradigm in SoadNLP may start from our new
benchmark. All the code and data of Advbench can be obtained at
\url{https://github.com/thunlp/Advbench}."
Controllable User Dialogue Act Augmentation for Dialogue State Tracking,0.0925982,"Prior work has demonstrated that data augmentation is useful for improving
dialogue state tracking. However, there are many types of user utterances,
while the prior method only considered the simplest one for augmentation,
raising the concern about poor generalization capability. In order to better
cover diverse dialogue acts and control the generation quality, this paper
proposes controllable user dialogue act augmentation (CUDA-DST) to augment user
utterances with diverse behaviors. With the augmented data, different state
trackers gain improvement and show better robustness, achieving the
state-of-the-art performance on MultiWOZ 2.1"
PalGAN: Image Colorization with Palette Generative Adversarial Networks,0.0383625,"Multimodal ambiguity and color bleeding remain challenging in colorization.
To tackle these problems, we propose a new GAN-based colorization approach
PalGAN, integrated with palette estimation and chromatic attention. To
circumvent the multimodality issue, we present a new colorization formulation
that estimates a probabilistic palette from the input gray image first, then
conducts color assignment conditioned on the palette through a generative
model. Further, we handle color bleeding with chromatic attention. It studies
color affinities by considering both semantic and intensity correlation. In
extensive experiments, PalGAN outperforms state-of-the-arts in quantitative
evaluation and visual comparison, delivering notable diverse, contrastive, and
edge-preserving appearances. With the palette design, our method enables color
transfer between images even with irrelevant contexts."
Multi-Attribute Open Set Recognition,0.134951,"Open Set Recognition (OSR) extends image classification to an open-world
setting, by simultaneously classifying known classes and identifying unknown
ones. While conventional OSR approaches can detect Out-of-Distribution (OOD)
samples, they cannot provide explanations indicating which underlying visual
attribute(s) (e.g., shape, color or background) cause a specific sample to be
unknown. In this work, we introduce a novel problem setup that generalizes
conventional OSR to a multi-attribute setting, where multiple visual attributes
are simultaneously recognized. Here, OOD samples can be not only identified but
also categorized by their unknown attribute(s). We propose simple extensions of
common OSR baselines to handle this novel scenario. We show that these
baselines are vulnerable to shortcuts when spurious correlations exist in the
training dataset. This leads to poor OOD performance which, according to our
experiments, is mainly due to unintended cross-attribute correlations of the
predicted confidence scores. We provide an empirical evidence showing that this
behavior is consistent across different baselines on both synthetic and real
world datasets."
Explainability of Predictive Process Monitoring Results: Can You See My Data Issues?,0.0679808,"Predictive business process monitoring (PPM) has been around for several
years as a use case of process mining. PPM enables foreseeing the future of a
business process through predicting relevant information about how a running
process instance might end, related performance indicators, and other
predictable aspects. A big share of PPM approaches adopts a Machine Learning
(ML) technique to address a prediction task, especially non-process-aware PPM
approaches. Consequently, PPM inherits the challenges faced by ML approaches.
One of these challenges concerns the need to gain user trust in the predictions
generated. The field of explainable artificial intelligence (XAI) addresses
this issue. However, the choices made, and the techniques employed in a PPM
task, in addition to ML model characteristics, influence resulting
explanations. A comparison of the influence of different settings on the
generated explanations is missing. To address this gap, we investigate the
effect of different PPM settings on resulting data fed into an ML model and
consequently to a XAI method. We study how differences in resulting
explanations may indicate several issues in underlying data. We construct a
framework for our experiments including different settings at each stage of PPM
with XAI integrated as a fundamental part. Our experiments reveal several
inconsistencies, as well as agreements, between data characteristics (and hence
expectations about these data), important data used by the ML model as a result
of querying it, and explanations of predictions of the investigated ML model."
"Continual Learning, Fast and Slow",0.90107,"According to the Complementary Learning Systems (CLS)
theory~\cite{mcclelland1995there} in neuroscience, humans do effective
\emph{continual learning} through two complementary systems: a fast learning
system centered on the hippocampus for rapid learning of the specifics,
individual experiences; and a slow learning system located in the neocortex for
the gradual acquisition of structured knowledge about the environment.
Motivated by this theory, we propose \emph{DualNets} (for Dual Networks), a
general continual learning framework comprising a fast learning system for
supervised learning of pattern-separated representation from specific tasks and
a slow learning system for representation learning of task-agnostic general
representation via Self-Supervised Learning (SSL). DualNets can seamlessly
incorporate both representation types into a holistic framework to facilitate
better continual learning in deep neural networks. Via extensive experiments,
we demonstrate the promising results of DualNets on a wide range of continual
learning protocols, ranging from the standard offline, task-aware setting to
the challenging online, task-free scenario. Notably, on the
CTrL~\cite{veniat2020efficient} benchmark that has unrelated tasks with vastly
different visual images, DualNets can achieve competitive performance with
existing state-of-the-art dynamic architecture
strategies~\cite{ostapenko2021continual}. Furthermore, we conduct comprehensive
ablation studies to validate DualNets efficacy, robustness, and scalability.
Code will be made available at \url{https://github.com/phquang/DualNet}."
Relighting4D: Neural Relightable Human from Videos,0.0817647,"Human relighting is a highly desirable yet challenging task. Existing works
either require expensive one-light-at-a-time (OLAT) captured data using light
stage or cannot freely change the viewpoints of the rendered body. In this
work, we propose a principled framework, Relighting4D, that enables
free-viewpoints relighting from only human videos under unknown illuminations.
Our key insight is that the space-time varying geometry and reflectance of the
human body can be decomposed as a set of neural fields of normal, occlusion,
diffuse, and specular maps. These neural fields are further integrated into
reflectance-aware physically based rendering, where each vertex in the neural
field absorbs and reflects the light from the environment. The whole framework
can be learned from videos in a self-supervised manner, with physically
informed priors designed for regularization. Extensive experiments on both real
and synthetic datasets demonstrate that our framework is capable of relighting
dynamic human actors with free-viewpoints."
Polysemanticity and Capacity in Neural Networks,0.933014,"Individual neurons in neural networks often represent a mixture of unrelated
features. This phenomenon, called polysemanticity, can make interpreting neural
networks more difficult and so we aim to understand its causes. We propose
doing so through the lens of feature \emph{capacity}, which is the fractional
dimension each feature consumes in the embedding space. We show that in a toy
model the optimal capacity allocation tends to monosemantically represent the
most important features, polysemantically represent less important features (in
proportion to their impact on the loss), and entirely ignore the least
important features. Polysemanticity is more prevalent when the inputs have
higher kurtosis or sparsity and more prevalent in some architectures than
others. Given an optimal allocation of capacity, we go on to study the geometry
of the embedding space. We find a block-semi-orthogonal structure, with
differing block sizes in different models, highlighting the impact of model
architecture on the interpretability of its neurons."
Dynamic Local Aggregation Network with Adaptive Clusterer for Anomaly Detection,0.0599841,"Existing methods for anomaly detection based on memory-augmented autoencoder
(AE) have the following drawbacks: (1) Establishing a memory bank requires
additional memory space. (2) The fixed number of prototypes from subjective
assumptions ignores the data feature differences and diversity. To overcome
these drawbacks, we introduce DLAN-AC, a Dynamic Local Aggregation Network with
Adaptive Clusterer, for anomaly detection. First, The proposed DLAN can
automatically learn and aggregate high-level features from the AE to obtain
more representative prototypes, while freeing up extra memory space. Second,
The proposed AC can adaptively cluster video data to derive initial prototypes
with prior information. In addition, we also propose a dynamic redundant
clustering strategy (DRCS) to enable DLAN for automatically eliminating feature
clusters that do not contribute to the construction of prototypes. Extensive
experiments on benchmarks demonstrate that DLAN-AC outperforms most existing
methods, validating the effectiveness of our method. Our code is publicly
available at https://github.com/Beyond-Zw/DLAN-AC."
Check and Link: Pairwise Lesion Correspondence Guides Mammogram Mass Detection,0.118631,"Detecting mass in mammogram is significant due to the high occurrence and
mortality of breast cancer. In mammogram mass detection, modeling pairwise
lesion correspondence explicitly is particularly important. However, most of
the existing methods build relatively coarse correspondence and have not
utilized correspondence supervision. In this paper, we propose a new
transformer-based framework CL-Net to learn lesion detection and pairwise
correspondence in an end-to-end manner. In CL-Net, View-Interactive Lesion
Detector is proposed to achieve dynamic interaction across candidates of cross
views, while Lesion Linker employs the correspondence supervision to guide the
interaction process more accurately. The combination of these two designs
accomplishes precise understanding of pairwise lesion correspondence for
mammograms. Experiments show that CL-Net yields state-of-the-art performance on
the public DDSM dataset and our in-house dataset. Moreover, it outperforms
previous methods by a large margin in low FPI regime."
DEER: Descriptive Knowledge Graph for Explaining Entity Relationships,0.115866,"We propose DEER (Descriptive Knowledge Graph for Explaining Entity
Relationships) - an open and informative form of modeling entity relationships.
In DEER, relationships between entities are represented by free-text relation
descriptions. For instance, the relationship between entities of machine
learning and algorithm can be represented as ``Machine learning explores the
study and construction of algorithms that can learn from and make predictions
on data.'' To construct DEER, we propose a self-supervised learning method to
extract relation descriptions with the analysis of dependency patterns and
generate relation descriptions with a transformer-based relation description
synthesizing model, where no human labeling is required. Experiments
demonstrate that our system can extract and generate high-quality relation
descriptions for explaining entity relationships. The results suggest that we
can build an open and informative knowledge graph without human annotation."
Filler Word Detection and Classification: A Dataset and Benchmark,0.0556088,"Filler words such as `uh' or `um' are sounds or words people use to signal
they are pausing to think. Finding and removing filler words from recordings is
a common and tedious task in media editing. Automatically detecting and
classifying filler words could greatly aid in this task, but few studies have
been published on this problem to date. A key reason is the absence of a
dataset with annotated filler words for model training and evaluation. In this
work, we present a novel speech dataset, PodcastFillers, with 35K annotated
filler words and 50K annotations of other sounds that commonly occur in
podcasts such as breaths, laughter, and word repetitions. We propose a pipeline
that leverages VAD and ASR to detect filler candidates and a classifier to
distinguish between filler word types. We evaluate our proposed pipeline on
PodcastFillers, compare to several baselines, and present a detailed ablation
study. In particular, we evaluate the importance of using ASR and how it
compares to a transcription-free approach resembling keyword spotting. We show
that our pipeline obtains state-of-the-art results, and that leveraging ASR
strongly outperforms a keyword spotting approach. We make PodcastFillers
publicly available, in the hope that our work serves as a benchmark for future
research."
Testing predictive automated driving systems: lessons learned and future recommendations,0.01095,"Conventional vehicles are certified through classical approaches, where
different physical certification tests are set up on test tracks to assess
required safety levels. These approaches are well suited for vehicles with
limited complexity and limited interactions with other entities as last-second
resources. However, these approaches do not allow to evaluate safety with real
behaviors for critical and edge cases, nor to evaluate the ability to
anticipate them in the mid or long term. This is particularly relevant for
automated and autonomous driving functions that make use of advanced predictive
systems to anticipate future actions and motions to be considered in the path
planning layer. In this paper, we present and analyze the results of physical
tests on proving grounds of several predictive systems in automated driving
functions developed within the framework of the BRAVE project. Based on our
experience in testing predictive automated driving functions, we identify the
main limitations of current physical testing approaches when dealing with
predictive systems, analyze the main challenges ahead, and provide a set of
practical actions and recommendations to consider in future physical testing
procedures for automated and autonomous driving functions."
A Fast Post-Training Pruning Framework for Transformers,0.579286,"Pruning is an effective way to reduce the huge inference cost of Transformer
models. However, prior work on pruning Transformers requires retraining the
models. This can add high training cost and high complexity to model
deployment, making it difficult to use in many practical situations. To address
this, we propose a fast post-training pruning framework for Transformers that
does not require any retraining. Given a resource constraint and a sample
dataset, our framework automatically prunes the Transformer model using
structured sparsity methods. To retain high accuracy without retraining, we
introduce three novel techniques: (i) a lightweight mask search algorithm that
finds which heads and filters to prune based on the Fisher information; (ii)
mask rearrangement that complements the search algorithm; and (iii) mask tuning
that reconstructs the output activations for each layer. We apply our method to
BERT-base and DistilBERT, and we evaluate its effectiveness on GLUE and SQuAD
benchmarks. Our framework achieves up to 2.0x reduction in FLOPs and 1.56x
speedup in inference latency, while maintaining < 1% loss in accuracy.
Importantly, our framework prunes Transformers in less than 3 minutes on a
single GPU, which is over two orders of magnitude faster than existing pruning
approaches that retrain the models."
Training Language Models with Language Feedback,0.22071,"Pretrained language models often do not perform tasks in ways that are in
line with our preferences, e.g., generating offensive text or factually
incorrect summaries. Recent work approaches the above issue by learning from a
simple form of human evaluation: comparisons between pairs of model-generated
task outputs. Comparison feedback conveys limited information about human
preferences per human evaluation. Here, we propose to learn from natural
language feedback, which conveys more information per human evaluation. We
learn from language feedback on model outputs using a three-step learning
algorithm. First, we condition the language model on the initial output and
feedback to generate many refinements. Second, we choose the refinement with
the highest similarity to the feedback. Third, we finetune a language model to
maximize the likelihood of the chosen refinement given the input. In synthetic
experiments, we first evaluate whether language models accurately incorporate
feedback to produce refinements, finding that only large language models (175B
parameters) do so. Using only 100 samples of human-written feedback, our
learning algorithm finetunes a GPT-3 model to roughly human-level summarization
ability."
Practical Exposure Correction: Great Truths Are Always Simple,0.415105,"Improving the visual quality of the given degraded observation by correcting
exposure level is a fundamental task in the computer vision community. Existing
works commonly lack adaptability towards unknown scenes because of the
data-driven patterns (deep networks) and limited regularization (traditional
optimization), and they usually need time-consuming inference. These two points
heavily limit their practicability. In this paper, we establish a Practical
Exposure Corrector (PEC) that assembles the characteristics of efficiency and
performance. To be concrete, we rethink the exposure correction to provide a
linear solution with exposure-sensitive compensation. Around generating the
compensation, we introduce an exposure adversarial function as the key engine
to fully extract valuable information from the observation. By applying the
defined function, we construct a segmented shrinkage iterative scheme to
generate the desired compensation. Its shrinkage nature supplies powerful
support for algorithmic stability and robustness. Extensive experimental
evaluations fully reveal the superiority of our proposed PEC. The code is
available at https://rsliu.tech/PEC."
Data-driven prediction of Air Traffic Controllers reactions to resolving conflicts,0.100555,"With the aim to enhance automation in conflict detection and resolution
(CD&R) tasks in the Air Traffic Management domain, in this paper we propose
deep learning techniques (DL) that can learn models of Air Traffic Controllers'
(ATCO) reactions in resolving conflicts that can violate separation minimum
constraints among aircraft trajectories: This implies learning when the ATCO
will react towards resolving a conflict, and how he/she will react. Timely
reactions, to which this paper aims, focus on when do reactions happen, aiming
to predict the trajectory points, as the trajectory evolves, that the ATCO
issues a conflict resolution action, while also predicting the type of
resolution action (if any). Towards this goal, the paper formulates the ATCO
reactions prediction problem for CD&R, and presents DL methods that can model
ATCO timely reactions and evaluates these methods in real-world data sets,
showing their efficacy in prediction with very high accuracy."
BlazePose GHUM Holistic: Real-time 3D Human Landmarks and Pose Estimation,0.930517,"We present BlazePose GHUM Holistic, a lightweight neural network pipeline for
3D human body landmarks and pose estimation, specifically tailored to real-time
on-device inference. BlazePose GHUM Holistic enables motion capture from a
single RGB image including avatar control, fitness tracking and AR/VR effects.
Our main contributions include i) a novel method for 3D ground truth data
acquisition, ii) updated 3D body tracking with additional hand landmarks and
iii) full body pose estimation from a monocular image."
The Neural Race Reduction: Dynamics of Abstraction in Gated Networks,0.0579237,"Our theoretical understanding of deep learning has not kept pace with its
empirical success. While network architecture is known to be critical, we do
not yet understand its effect on learned representations and network behavior,
or how this architecture should reflect task structure.In this work, we begin
to address this gap by introducing the Gated Deep Linear Network framework that
schematizes how pathways of information flow impact learning dynamics within an
architecture. Crucially, because of the gating, these networks can compute
nonlinear functions of their input. We derive an exact reduction and, for
certain cases, exact solutions to the dynamics of learning. Our analysis
demonstrates that the learning dynamics in structured networks can be
conceptualized as a neural race with an implicit bias towards shared
representations, which then govern the model's ability to systematically
generalize, multi-task, and transfer. We validate our key insights on
naturalistic datasets and with relaxed assumptions. Taken together, our work
gives rise to general hypotheses relating neural architecture to learning and
provides a mathematical approach towards understanding the design of more
complex architectures and the role of modularity and compositionality in
solving real-world problems. The code and results are available at
https://www.saxelab.org/gated-dln ."
Towards Robust k-Nearest-Neighbor Machine Translation,0.11967,"k-Nearest-Neighbor Machine Translation (kNN-MT) becomes an important research
direction of NMT in recent years. Its main idea is to retrieve useful key-value
pairs from an additional datastore to modify translations without updating the
NMT model. However, the underlying retrieved noisy pairs will dramatically
deteriorate the model performance. In this paper, we conduct a preliminary
study and find that this problem results from not fully exploiting the
prediction of the NMT model. To alleviate the impact of noise, we propose a
confidence-enhanced kNN-MT model with robust training. Concretely, we introduce
the NMT confidence to refine the modeling of two important components of
kNN-MT: kNN distribution and the interpolation weight. Meanwhile we inject two
types of perturbations into the retrieved pairs for robust training.
Experimental results on four benchmark datasets demonstrate that our model not
only achieves significant improvements over current kNN-MT models, but also
exhibits better robustness. Our code is available at
https://github.com/DeepLearnXMU/Robust-knn-mt."
Synthesizing Personalized Non-speech Vocalization from Discrete Speech Representations,0.132106,"We formulated non-speech vocalization (NSV) modeling as a text-to-speech task
and verified its viability. Specifically, we evaluated the phonetic
expressivity of HUBERT speech units on NSVs and verified our model's ability to
control over speaker timbre even though the training data is speaker few-shot.
In addition, we substantiated that the heterogeneity in recording conditions is
the major obstacle for NSV modeling. Finally, we discussed five improvements
over our method for future research. Audio samples of synthesized NSVs are
available on our demo page: https://resemble-ai.github.io/reLaugh."
InducT-GCN: Inductive Graph Convolutional Networks for Text Classification,0.0701222,"Text classification aims to assign labels to textual units by making use of
global information. Recent studies have applied graph neural network (GNN) to
capture the global word co-occurrence in a corpus. Existing approaches require
that all the nodes (training and test) in a graph are present during training,
which are transductive and do not naturally generalise to unseen nodes. To make
those models inductive, they use extra resources, like pretrained word
embedding. However, high-quality resource is not always available and hard to
train. Under the extreme settings with no extra resource and limited amount of
training set, can we still learn an inductive graph-based text classification
model? In this paper, we introduce a novel inductive graph-based text
classification framework, InducT-GCN (InducTive Graph Convolutional Networks
for Text classification). Compared to transductive models that require test
documents in training, we construct a graph based on the statistics of training
documents only and represent document vectors with a weighted sum of word
vectors. We then conduct one-directional GCN propagation during testing. Across
five text classification benchmarks, our InducT-GCN outperformed
state-of-the-art methods that are either transductive in nature or pre-trained
additional resources. We also conducted scalability testing by gradually
increasing the data size and revealed that our InducT-GCN can reduce the time
and space complexity. The code is available on:
https://github.com/usydnlp/InductTGCN."
I Know What You Do Not Know: Knowledge Graph Embedding via Co-distillation Learning,0.0633187,"Knowledge graph (KG) embedding seeks to learn vector representations for
entities and relations. Conventional models reason over graph structures, but
they suffer from the issues of graph incompleteness and long-tail entities.
Recent studies have used pre-trained language models to learn embeddings based
on the textual information of entities and relations, but they cannot take
advantage of graph structures. In the paper, we show empirically that these two
kinds of features are complementary for KG embedding. To this end, we propose
CoLE, a Co-distillation Learning method for KG Embedding that exploits the
complementarity of graph structures and text information. Its graph embedding
model employs Transformer to reconstruct the representation of an entity from
its neighborhood subgraph. Its text embedding model uses a pre-trained language
model to generate entity representations from the soft prompts of their names,
descriptions, and relational neighbors. To let the two model promote each
other, we propose co-distillation learning that allows them to distill
selective knowledge from each other's prediction logits. In our co-distillation
learning, each model serves as both a teacher and a student. Experiments on
benchmark datasets demonstrate that the two models outperform their related
baselines, and the ensemble method CoLE with co-distillation learning advances
the state-of-the-art of KG embedding."
Improving Multilingual Neural Machine Translation System for Indic Languages,0.0371719,"Machine Translation System (MTS) serves as an effective tool for
communication by translating text or speech from one language to another
language. The need of an efficient translation system becomes obvious in a
large multilingual environment like India, where English and a set of Indian
Languages (ILs) are officially used. In contrast with English, ILs are still
entreated as low-resource languages due to unavailability of corpora. In order
to address such asymmetric nature, multilingual neural machine translation
(MNMT) system evolves as an ideal approach in this direction. In this paper, we
propose a MNMT system to address the issues related to low-resource language
translation. Our model comprises of two MNMT systems i.e. for English-Indic
(one-to-many) and the other for Indic-English (many-to-one) with a shared
encoder-decoder containing 15 language pairs (30 translation directions). Since
most of IL pairs have scanty amount of parallel corpora, not sufficient for
training any machine translation model. We explore various augmentation
strategies to improve overall translation quality through the proposed model. A
state-of-the-art transformer architecture is used to realize the proposed
model. Trials over a good amount of data reveal its superiority over the
conventional models. In addition, the paper addresses the use of language
relationships (in terms of dialect, script, etc.), particularly about the role
of high-resource languages of the same family in boosting the performance of
low-resource languages. Moreover, the experimental results also show the
advantage of backtranslation and domain adaptation for ILs to enhance the
translation quality of both source and target languages. Using all these key
approaches, our proposed model emerges to be more efficient than the baseline
model in terms of evaluation metrics i.e BLEU (BiLingual Evaluation Understudy)
score for a set of ILs."
Unpaired Image Translation via Vector Symbolic Architectures,0.0839373,"Image-to-image translation has played an important role in enabling synthetic
data for computer vision. However, if the source and target domains have a
large semantic mismatch, existing techniques often suffer from source content
corruption aka semantic flipping. To address this problem, we propose a new
paradigm for image-to-image translation using Vector Symbolic Architectures
(VSA), a theoretical framework which defines algebraic operations in a
high-dimensional vector (hypervector) space. We introduce VSA-based constraints
on adversarial learning for source-to-target translations by learning a
hypervector mapping that inverts the translation to ensure consistency with
source content. We show both qualitatively and quantitatively that our method
improves over other state-of-the-art techniques."
Exploration of Machine Learning Classification Models Used for Behavioral Biometrics Authentication,0.0927617,"Mobile devices have been manufactured and enhanced at growing rates in the
past decades. While this growth has significantly evolved the capability of
these devices, their security has been falling behind. This contrast in
development between capability and security of mobile devices is a significant
problem with the sensitive information of the public at risk. Continuing the
previous work in this field, this study identifies key Machine Learning
algorithms currently being used for behavioral biometric mobile authentication
schemes and aims to provide a comprehensive review of these algorithms when
used with touch dynamics and phone movement. Throughout this paper the
benefits, limitations, and recommendations for future work will be discussed."
ALLSH: Active Learning Guided by Local Sensitivity and Hardness,0.0537378,"Active learning, which effectively collects informative unlabeled data for
annotation, reduces the demand for labeled data. In this work, we propose to
retrieve unlabeled samples with a local sensitivity and hardness-aware
acquisition function. The proposed method generates data copies through local
perturbations and selects data points whose predictive likelihoods diverge the
most from their copies. We further empower our acquisition function by
injecting the select-worst case perturbation. Our method achieves consistent
gains over the commonly used active learning strategies in various
classification tasks. Furthermore, we observe consistent improvements over the
baselines on the study of prompt selection in prompt-based few-shot learning.
These experiments demonstrate that our acquisition guided by local sensitivity
and hardness can be effective and beneficial for many NLP tasks."
Hierarchical Phrase-based Sequence-to-Sequence Learning,0.0478948,"We describe a neural transducer that maintains the flexibility of standard
sequence-to-sequence (seq2seq) models while incorporating hierarchical phrases
as a source of inductive bias during training and as explicit constraints
during inference. Our approach trains two models: a discriminative parser based
on a bracketing transduction grammar whose derivation tree hierarchically
aligns source and target phrases, and a neural seq2seq model that learns to
translate the aligned phrases one-by-one. We use the same seq2seq model to
translate at all phrase scales, which results in two inference modes: one mode
in which the parser is discarded and only the seq2seq component is used at the
sequence-level, and another in which the parser is combined with the seq2seq
model. Decoding in the latter mode is done with the cube-pruned CKY algorithm,
which is more involved but can make use of new translation rules during
inference. We formalize our model as a source-conditioned synchronous grammar
and develop an efficient variational inference algorithm for training. When
applied on top of both randomly initialized and pretrained seq2seq models, we
find that both inference modes performs well compared to baselines on small
scale machine translation benchmarks."
Towards WinoQueer: Developing a Benchmark for Anti-Queer Bias in Large Language Models,0.864665,"This paper presents exploratory work on whether and to what extent biases
against queer and trans people are encoded in large language models (LLMs) such
as BERT. We also propose a method for reducing these biases in downstream
tasks: finetuning the models on data written by and/or about queer people. To
measure anti-queer bias, we introduce a new benchmark dataset, WinoQueer,
modeled after other bias-detection benchmarks but addressing homophobic and
transphobic biases. We found that BERT shows significant homophobic bias, but
this bias can be mostly mitigated by finetuning BERT on a natural language
corpus written by members of the LGBTQ+ community."
WinoDict: Probing language models for in-context word acquisition,0.0583544,"We introduce a new in-context learning paradigm to measure Large Language
Models' (LLMs) ability to learn novel words during inference. In particular, we
rewrite Winograd-style co-reference resolution problems by replacing the key
concept word with a synthetic but plausible word that the model must understand
to complete the task. Solving this task requires the model to make use of the
dictionary definition of the new word given in the prompt. This benchmark
addresses word acquisition, one important aspect of the diachronic degradation
known to afflict LLMs. As LLMs are frozen in time at the moment they are
trained, they are normally unable to reflect the way language changes over
time. We show that the accuracy of LLMs compared to the original Winograd tasks
decreases radically in our benchmark, thus identifying a limitation of current
models and providing a benchmark to measure future improvements in LLMs ability
to do in-context learning."
MiniViT: Compressing Vision Transformers with Weight Multiplexing,0.967283,"Vision Transformer (ViT) models have recently drawn much attention in
computer vision due to their high model capability. However, ViT models suffer
from huge number of parameters, restricting their applicability on devices with
limited memory. To alleviate this problem, we propose MiniViT, a new
compression framework, which achieves parameter reduction in vision
transformers while retaining the same performance. The central idea of MiniViT
is to multiplex the weights of consecutive transformer blocks. More
specifically, we make the weights shared across layers, while imposing a
transformation on the weights to increase diversity. Weight distillation over
self-attention is also applied to transfer knowledge from large-scale ViT
models to weight-multiplexed compact models. Comprehensive experiments
demonstrate the efficacy of MiniViT, showing that it can reduce the size of the
pre-trained Swin-B transformer by 48\%, while achieving an increase of 1.0\% in
Top-1 accuracy on ImageNet. Moreover, using a single-layer of parameters,
MiniViT is able to compress DeiT-B by 9.7 times from 86M to 9M parameters,
without seriously compromising the performance. Finally, we verify the
transferability of MiniViT by reporting its performance on downstream
benchmarks. Code and models are available at here."
Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing,0.412992,"Despite their strong performance on many tasks, pre-trained language models
have been shown to struggle on out-of-distribution compositional
generalization. Meanwhile, recent work has shown considerable improvements on
many NLP tasks from model scaling. Can scaling up model size also improve
compositional generalization in semantic parsing? We evaluate encoder-decoder
models up to 11B parameters and decoder-only models up to 540B parameters, and
compare model scaling curves for three different methods for applying a
pre-trained language model to a new task: fine-tuning all parameters, prompt
tuning, and in-context learning. We observe that fine-tuning generally has flat
or negative scaling curves on out-of-distribution compositional generalization
in semantic parsing evaluations. In-context learning has positive scaling
curves, but is generally outperformed by much smaller fine-tuned models.
Prompt-tuning can outperform fine-tuning, suggesting further potential
improvements from scaling as it exhibits a more positive scaling curve.
Additionally, we identify several error trends that vary with model scale. For
example, larger models are generally better at modeling the syntax of the
output space, but are also more prone to certain types of overfitting. Overall,
our study highlights limitations of current techniques for effectively
leveraging model scale for compositional generalization, while our analysis
also suggests promising directions for future work."
A Computational Inflection for Scientific Discovery,0.0419618,"We stand at the foot of a significant inflection in the trajectory of
scientific discovery. As society continues on its fast-paced digital
transformation, so does humankind's collective scientific knowledge and
discourse. We now read and write papers in digitized form, and a great deal of
the formal and informal processes of science are captured digitally --
including papers, preprints and books, code and datasets, conference
presentations, and interactions in social networks and collaboration and
communication platforms. The transition has led to the creation and growth of a
tremendous amount of information -- much of which is available for public
access -- opening exciting opportunities for computational models and systems
that analyze and harness it. In parallel, exponential growth in data processing
power has fueled remarkable advances in artificial intelligence, including
large neural language models capable of learning powerful representations from
unstructured text. Dramatic changes in scientific communication -- such as the
advent of the first scientific journal in the 17th century -- have historically
catalyzed revolutions in scientific thought. The confluence of societal and
computational trends suggests that computer science is poised to ignite a
revolution in the scientific process itself."
AdaTest:Reinforcement Learning and Adaptive Sampling for On-chip Hardware Trojan Detection,0.204335,"This paper proposes AdaTest, a novel adaptive test pattern generation
framework for efficient and reliable Hardware Trojan (HT) detection. HT is a
backdoor attack that tampers with the design of victim integrated circuits
(ICs). AdaTest improves the existing HT detection techniques in terms of
scalability and accuracy of detecting smaller Trojans in the presence of noise
and variations. To achieve high trigger coverage, AdaTest leverages
Reinforcement Learning (RL) to produce a diverse set of test inputs.
Particularly, we progressively generate test vectors with high reward values in
an iterative manner. In each iteration, the test set is evaluated and
adaptively expanded as needed. Furthermore, AdaTest integrates adaptive
sampling to prioritize test samples that provide more information for HT
detection, thus reducing the number of samples while improving the sample
quality for faster exploration. We develop AdaTest with a Software/Hardware
co-design principle and provide an optimized on-chip architecture solution.
AdaTest's architecture minimizes the hardware overhead in two ways:(i)
Deploying circuit emulation on programmable hardware to accelerate reward
evaluation of the test input; (ii) Pipelining each computation stage in AdaTest
by automatically constructing auxiliary circuit for test input generation,
reward evaluation, and adaptive sampling. We evaluate AdaTest's performance on
various HT benchmarks and compare it with two prior works that use logic
testing for HT detection. Experimental results show that AdaTest engenders up
to two orders of test generation speedup and two orders of test set size
reduction compared to the prior works while achieving the same level or higher
Trojan detection rate."
A Self-Guided Framework for Radiology Report Generation,0.323976,"Automatic radiology report generation is essential to computer-aided
diagnosis. Through the success of image captioning, medical report generation
has been achievable. However, the lack of annotated disease labels is still the
bottleneck of this area. In addition, the image-text data bias problem and
complex sentences make it more difficult to generate accurate reports. To
address these gaps, we pre-sent a self-guided framework (SGF), a suite of
unsupervised and supervised deep learning methods to mimic the process of human
learning and writing. In detail, our framework obtains the domain knowledge
from medical reports with-out extra disease labels and guides itself to extract
fined-grain visual features as-sociated with the text. Moreover, SGF
successfully improves the accuracy and length of medical report generation by
incorporating a similarity comparison mechanism that imitates the process of
human self-improvement through compar-ative practice. Extensive experiments
demonstrate the utility of our SGF in the majority of cases, showing its
superior performance over state-of-the-art meth-ods. Our results highlight the
capacity of the proposed framework to distinguish fined-grained visual details
between words and verify its advantage in generating medical reports."
Bridging POMDPs and Bayesian decision making for robust maintenance planning under model uncertainty: An application to railway systems,0.0878442,"Structural Health Monitoring (SHM) describes a process for inferring
quantifiable metrics of structural condition, which can serve as input to
support decisions on the operation and maintenance of infrastructure assets.
Given the long lifespan of critical structures, this problem can be cast as a
sequential decision making problem over prescribed horizons. Partially
Observable Markov Decision Processes (POMDPs) offer a formal framework to solve
the underlying optimal planning task. However, two issues can undermine the
POMDP solutions. Firstly, the need for a model that can adequately describe the
evolution of the structural condition under deterioration or corrective actions
and, secondly, the non-trivial task of recovery of the observation process
parameters from available monitoring data. Despite these potential challenges,
the adopted POMDP models do not typically account for uncertainty on model
parameters, leading to solutions which can be unrealistically confident. In
this work, we address both key issues. We present a framework to estimate POMDP
transition and observation model parameters directly from available data, via
Markov Chain Monte Carlo (MCMC) sampling of a Hidden Markov Model (HMM)
conditioned on actions. The MCMC inference estimates distributions of the
involved model parameters. We then form and solve the POMDP problem by
exploiting the inferred distributions, to derive solutions that are robust to
model uncertainty. We successfully apply our approach on maintenance planning
for railway track assets on the basis of a ""fractal value"" indicator, which is
computed from actual railway monitoring data."
Multiple Instance Neuroimage Transformer,0.0140595,"For the first time, we propose using a multiple instance learning based
convolution-free transformer model, called Multiple Instance Neuroimage
Transformer (MINiT), for the classification of T1weighted (T1w) MRIs. We first
present several variants of transformer models adopted for neuroimages. These
models extract non-overlapping 3D blocks from the input volume and perform
multi-headed self-attention on a sequence of their linear projections. MINiT,
on the other hand, treats each of the non-overlapping 3D blocks of the input
MRI as its own instance, splitting it further into non-overlapping 3D patches,
on which multi-headed self-attention is computed. As a proof-of-concept, we
evaluate the efficacy of our model by training it to identify sex from T1w-MRIs
of two public datasets: Adolescent Brain Cognitive Development (ABCD) and the
National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA).
The learned attention maps highlight voxels contributing to identifying sex
differences in brain morphometry. The code is available at
https://github.com/singlaayush/MINIT."
Diverse Imagenet Models Transfer Better,0.00360202,"A commonly accepted hypothesis is that models with higher accuracy on
Imagenet perform better on other downstream tasks, leading to much research
dedicated to optimizing Imagenet accuracy. Recently this hypothesis has been
challenged by evidence showing that self-supervised models transfer better than
their supervised counterparts, despite their inferior Imagenet accuracy. This
calls for identifying the additional factors, on top of Imagenet accuracy, that
make models transferable. In this work we show that high diversity of the
features learnt by the model promotes transferability jointly with Imagenet
accuracy. Encouraged by the recent transferability results of self-supervised
models, we propose a method that combines self-supervised and supervised
pretraining to generate models with both high diversity and high accuracy, and
as a result high transferability. We demonstrate our results on several
architectures and multiple downstream tasks, including both single-label and
multi-label classification."
Smoothing Matters: Momentum Transformer for Domain Adaptive Semantic Segmentation,0.0229858,"After the great success of Vision Transformer variants (ViTs) in computer
vision, it has also demonstrated great potential in domain adaptive semantic
segmentation. Unfortunately, straightforwardly applying local ViTs in domain
adaptive semantic segmentation does not bring in expected improvement. We find
that the pitfall of local ViTs is due to the severe high-frequency components
generated during both the pseudo-label construction and features alignment for
target domains. These high-frequency components make the training of local ViTs
very unsmooth and hurt their transferability. In this paper, we introduce a
low-pass filtering mechanism, momentum network, to smooth the learning dynamics
of target domain features and pseudo labels. Furthermore, we propose a dynamic
of discrepancy measurement to align the distributions in the source and target
domains via dynamic weights to evaluate the importance of the samples. After
tackling the above issues, extensive experiments on sim2real benchmarks show
that the proposed method outperforms the state-of-the-art methods. Our codes
are available at https://github.com/alpc91/TransDA"
Extreme Compression for Pre-trained Transformers Made Simple and Efficient,0.455049,"Extreme compression, particularly ultra-low bit precision (binary/ternary)
quantization, has been proposed to fit large NLP models on resource-constraint
devices. However, to preserve the accuracy for such aggressive compression
schemes, cutting-edge methods usually introduce complicated compression
pipelines, e.g., multi-stage expensive knowledge distillation with extensive
hyperparameter tuning. Also, they oftentimes focus less on smaller transformer
models that have already been heavily compressed via knowledge distillation and
lack a systematic study to show the effectiveness of their methods. In this
paper, we perform a very comprehensive systematic study to measure the impact
of many key hyperparameters and training strategies from previous works. As a
result, we find out that previous baselines for ultra-low bit precision
quantization are significantly under-trained. Based on our study, we propose a
simple yet effective compression pipeline for extreme compression, named XTC.
XTC demonstrates that (1) we can skip the pre-training knowledge distillation
to obtain a 5-layer BERT while achieving better performance than previous
state-of-the-art methods, e.g., the 6-layer TinyBERT; (2) extreme quantization
plus layer reduction is able to reduce the model size by 50x, resulting in new
state-of-the-art results on GLUE tasks."
StretchBEV: Stretching Future Instance Prediction Spatially and Temporally,-1.0,"In self-driving, predicting future in terms of location and motion of all the
agents around the vehicle is a crucial requirement for planning. Recently, a
new joint formulation of perception and prediction has emerged by fusing rich
sensory information perceived from multiple cameras into a compact bird's-eye
view representation to perform prediction. However, the quality of future
predictions degrades over time while extending to longer time horizons due to
multiple plausible predictions. In this work, we address this inherent
uncertainty in future predictions with a stochastic temporal model. Our model
learns temporal dynamics in a latent space through stochastic residual updates
at each time step. By sampling from a learned distribution at each time step,
we obtain more diverse future predictions that are also more accurate compared
to previous work, especially stretching both spatially further regions in the
scene and temporally over longer time horizons. Despite separate processing of
each time step, our model is still efficient through decoupling of the learning
of dynamics and the generation of future predictions."
Human Evaluation of Conversations is an Open Problem: comparing the sensitivity of various methods for evaluating dialogue agents,0.0789382,"At the heart of improving conversational AI is the open problem of how to
evaluate conversations. Issues with automatic metrics are well known (Liu et
al., 2016, arXiv:1603.08023), with human evaluations still considered the gold
standard. Unfortunately, how to perform human evaluations is also an open
problem: differing data collection methods have varying levels of human
agreement and statistical sensitivity, resulting in differing amounts of human
annotation hours and labor costs. In this work we compare five different
crowdworker-based human evaluation methods and find that different methods are
best depending on the types of models compared, with no clear winner across the
board. While this highlights the open problems in the area, our analysis leads
to advice of when to use which one, and possible future directions."
ImFace: A Nonlinear 3D Morphable Face Model with Implicit Neural Representations,0.864665,"Precise representations of 3D faces are beneficial to various computer vision
and graphics applications. Due to the data discretization and model linearity,
however, it remains challenging to capture accurate identity and expression
clues in current studies. This paper presents a novel 3D morphable face model,
namely ImFace, to learn a nonlinear and continuous space with implicit neural
representations. It builds two explicitly disentangled deformation fields to
model complex shapes associated with identities and expressions, respectively,
and designs an improved learning strategy to extend embeddings of expressions
to allow more diverse changes. We further introduce a Neural Blend-Field to
learn sophisticated details by adaptively blending a series of local fields. In
addition to ImFace, an effective preprocessing pipeline is proposed to address
the issue of watertight input requirement in implicit representations, enabling
them to work with common facial surfaces for the first time. Extensive
experiments are performed to demonstrate the superiority of ImFace."
Zero-Shot Retrieval with Search Agents and Hybrid Environments,0.0405104,"Learning to search is the task of building artificial agents that learn to
autonomously use a search box to find information. So far, it has been shown
that current language models can learn symbolic query reformulation policies,
in combination with traditional term-based retrieval, but fall short of
outperforming neural retrievers. We extend the previous learning to search
setup to a hybrid environment, which accepts discrete query refinement
operations, after a first-pass retrieval step via a dual encoder. Experiments
on the BEIR task show that search agents, trained via behavioral cloning,
outperform the underlying search system based on a combined dual encoder
retriever and cross encoder reranker. Furthermore, we find that simple
heuristic Hybrid Retrieval Environments (HRE) can improve baseline performance
by several nDCG points. The search agent based on HRE (HARE) matches
state-of-the-art performance, balanced in both zero-shot and in-domain
evaluations, via interpretable actions, and at twice the speed."
Transfer Learning based Search Space Design for Hyperparameter Tuning,0.0676497,"The tuning of hyperparameters becomes increasingly important as machine
learning (ML) models have been extensively applied in data mining applications.
Among various approaches, Bayesian optimization (BO) is a successful
methodology to tune hyper-parameters automatically. While traditional methods
optimize each tuning task in isolation, there has been recent interest in
speeding up BO by transferring knowledge across previous tasks. In this work,
we introduce an automatic method to design the BO search space with the aid of
tuning history from past tasks. This simple yet effective approach can be used
to endow many existing BO methods with transfer learning capabilities. In
addition, it enjoys the three advantages: universality, generality, and
safeness. The extensive experiments show that our approach considerably boosts
BO by designing a promising and compact search space instead of using the
entire space, and outperforms the state-of-the-arts on a wide range of
benchmarks, including machine learning and deep learning tuning tasks, and
neural architecture search."
Summarizing Patients Problems from Hospital Progress Notes Using Pre-trained Sequence-to-Sequence Models,0.343444,"Automatically summarizing patients' main problems from daily progress notes
using natural language processing methods helps to battle against information
and cognitive overload in hospital settings and potentially assists providers
with computerized diagnostic decision support. Problem list summarization
requires a model to understand, abstract, and generate clinical documentation.
In this work, we propose a new NLP task that aims to generate a list of
problems in a patient's daily care plan using input from the provider's
progress notes during hospitalization. We investigate the performance of T5 and
BART, two state-of-the-art seq2seq transformer architectures, in solving this
problem. We provide a corpus built on top of progress notes from publicly
available electronic health record progress notes in the Medical Information
Mart for Intensive Care (MIMIC)-III. T5 and BART are trained on general domain
text, and we experiment with a data augmentation method and a domain adaptation
pre-training method to increase exposure to medical vocabulary and knowledge.
Evaluation methods include ROUGE, BERTScore, cosine similarity on sentence
embedding, and F-score on medical concepts. Results show that T5 with domain
adaptive pre-training achieves significant performance gains compared to a
rule-based system and general domain pre-trained language models, indicating a
promising direction for tackling the problem summarization task."
Uncertainty-aware Panoptic Segmentation,0.551462,"Reliable scene understanding is indispensable for modern autonomous systems.
Current learning-based methods typically try to maximize their performance
based on segmentation metrics that only consider the quality of the
segmentation. However, for the safe operation of a system in the real world it
is crucial to consider the uncertainty in the prediction as well. In this work,
we introduce the novel task of uncertainty-aware panoptic segmentation, which
aims to predict per-pixel semantic and instance segmentations, together with
per-pixel uncertainty estimates. We define two novel metrics to facilitate its
quantitative analysis, the uncertainty-aware Panoptic Quality (uPQ) and the
panoptic Expected Calibration Error (pECE). We further propose the novel
top-down Evidential Panoptic Segmentation Network (EvPSNet) to solve this task.
Our architecture employs a simple yet effective panoptic fusion module that
leverages the predicted uncertainties. Furthermore, we provide several strong
baselines combining state-of-the-art panoptic segmentation networks with
sampling-free uncertainty estimation techniques. Extensive evaluations show
that our EvPSNet achieves the new state-of-the-art for the standard Panoptic
Quality (PQ), as well as for our uncertainty-aware panoptic metrics. We make
the code available at: \url{https://github.com/kshitij3112/EvPSNet}"
Multi-task Learning for Cross-Lingual Sentiment Analysis,0.132072,"This paper presents a cross-lingual sentiment analysis of news articles using
zero-shot and few-shot learning. The study aims to classify the Croatian news
articles with positive, negative, and neutral sentiments using the Slovene
dataset. The system is based on a trilingual BERT-based model trained in three
languages: English, Slovene, Croatian. The paper analyses different setups
using datasets in two languages and proposes a simple multi-task model to
perform sentiment classification. The evaluation is performed using the
few-shot and zero-shot scenarios in single-task and multi-task experiments for
Croatian and Slovene."
Imputing Out-of-Vocabulary Embeddings with LOVE Makes Language Models Robust with Little Cost,0.0755199,"State-of-the-art NLP systems represent inputs with word embeddings, but these
are brittle when faced with Out-of-Vocabulary (OOV) words. To address this
issue, we follow the principle of mimick-like models to generate vectors for
unseen words, by learning the behavior of pre-trained embeddings using only the
surface form of words. We present a simple contrastive learning framework,
LOVE, which extends the word representation of an existing pre-trained language
model (such as BERT), and makes it robust to OOV with few additional
parameters. Extensive evaluations demonstrate that our lightweight model
achieves similar or even better performances than prior competitors, both on
original datasets and on corrupted variants. Moreover, it can be used in a
plug-and-play fashion with FastText and BERT, where it significantly improves
their robustness."
A context-aware knowledge transferring strategy for CTC-based ASR,0.130547,"Non-autoregressive automatic speech recognition (ASR) modeling has received
increasing attention recently because of its fast decoding speed and superior
performance. Among representatives, methods based on the connectionist temporal
classification (CTC) are still a dominating stream. However, the theoretically
inherent flaw, the assumption of independence between tokens, creates a
performance barrier for the school of works. To mitigate the challenge, we
propose a context-aware knowledge transferring strategy, consisting of a
knowledge transferring module and a context-aware training strategy, for
CTC-based ASR. The former is designed to distill linguistic information from a
pre-trained language model, and the latter is framed to modulate the
limitations caused by the conditional independence assumption. As a result, a
knowledge-injected context-aware CTC-based ASR built upon the wav2vec2.0 is
presented in this paper. A series of experiments on the AISHELL-1 and AISHELL-2
datasets demonstrate the effectiveness of the proposed method."
Does BERT really agree ? Fine-grained Analysis of Lexical Dependence on a Syntactic Task,0.094437,"Although transformer-based Neural Language Models demonstrate impressive
performance on a variety of tasks, their generalization abilities are not well
understood. They have been shown to perform strongly on subject-verb number
agreement in a wide array of settings, suggesting that they learned to track
syntactic dependencies during their training even without explicit supervision.
In this paper, we examine the extent to which BERT is able to perform
lexically-independent subject-verb number agreement (NA) on targeted syntactic
templates. To do so, we disrupt the lexical patterns found in naturally
occurring stimuli for each targeted structure in a novel fine-grained analysis
of BERT's behavior. Our results on nonce sentences suggest that the model
generalizes well for simple templates, but fails to perform
lexically-independent syntactic generalization when as little as one attractor
is present."
Panoramic Human Activity Recognition,0.111816,"To obtain a more comprehensive activity understanding for a crowded scene, in
this paper, we propose a new problem of panoramic human activity recognition
(PAR), which aims to simultaneous achieve the individual action, social group
activity, and global activity recognition. This is a challenging yet practical
problem in real-world applications. For this problem, we develop a novel
hierarchical graph neural network to progressively represent and model the
multi-granularity human activities and mutual social relations for a crowd of
people. We further build a benchmark to evaluate the proposed method and other
existing related methods. Experimental results verify the rationality of the
proposed PAR problem, the effectiveness of our method and the usefulness of the
benchmark. We will release the source code and benchmark to the public for
promoting the study on this problem."
Point-Level Region Contrast for Object Detection Pre-Training,0.264829,"In this work we present point-level region contrast, a self-supervised
pre-training approach for the task of object detection. This approach is
motivated by the two key factors in detection: localization and recognition.
While accurate localization favors models that operate at the pixel- or
point-level, correct recognition typically relies on a more holistic,
region-level view of objects. Incorporating this perspective in pre-training,
our approach performs contrastive learning by directly sampling individual
point pairs from different regions. Compared to an aggregated representation
per region, our approach is more robust to the change in input region quality,
and further enables us to implicitly improve initial region assignments via
online knowledge distillation during training. Both advantages are important
when dealing with imperfect regions encountered in the unsupervised setting.
Experiments show point-level region contrast improves on state-of-the-art
pre-training methods for object detection and segmentation across multiple
tasks and datasets, and we provide extensive ablation studies and
visualizations to aid understanding. Code will be made available."
Medical Image Captioning via Generative Pretrained Transformers,0.097783,"The automatic clinical caption generation problem is referred to as proposed
model combining the analysis of frontal chest X-Ray scans with structured
patient information from the radiology records. We combine two language models,
the Show-Attend-Tell and the GPT-3, to generate comprehensive and descriptive
radiology records. The proposed combination of these models generates a textual
summary with the essential information about pathologies found, their location,
and the 2D heatmaps localizing each pathology on the original X-Ray scans. The
proposed model is tested on two medical datasets, the Open-I, MIMIC-CXR, and
the general-purpose MS-COCO. The results measured with the natural language
assessment metrics prove their efficient applicability to the chest X-Ray image
captioning."
PseudoClick: Interactive Image Segmentation with Click Imitation,-1.0,"The goal of click-based interactive image segmentation is to obtain precise
object segmentation masks with limited user interaction, i.e., by a minimal
number of user clicks. Existing methods require users to provide all the
clicks: by first inspecting the segmentation mask and then providing points on
mislabeled regions, iteratively. We ask the question: can our model directly
predict where to click, so as to further reduce the user interaction cost? To
this end, we propose {\PseudoClick}, a generic framework that enables existing
segmentation networks to propose candidate next clicks. These automatically
generated clicks, termed pseudo clicks in this work, serve as an imitation of
human clicks to refine the segmentation mask."
Ray3D: ray-based 3D human pose estimation for monocular absolute 3D localization,0.159083,"In this paper, we propose a novel monocular ray-based 3D (Ray3D) absolute
human pose estimation with calibrated camera. Accurate and generalizable
absolute 3D human pose estimation from monocular 2D pose input is an ill-posed
problem. To address this challenge, we convert the input from pixel space to 3D
normalized rays. This conversion makes our approach robust to camera intrinsic
parameter changes. To deal with the in-the-wild camera extrinsic parameter
variations, Ray3D explicitly takes the camera extrinsic parameters as an input
and jointly models the distribution between the 3D pose rays and camera
extrinsic parameters. This novel network design is the key to the outstanding
generalizability of Ray3D approach. To have a comprehensive understanding of
how the camera intrinsic and extrinsic parameter variations affect the accuracy
of absolute 3D key-point localization, we conduct in-depth systematic
experiments on three single person 3D benchmarks as well as one synthetic
benchmark. These experiments demonstrate that our method significantly
outperforms existing state-of-the-art models. Our code and the synthetic
dataset are available at https://github.com/YxZhxn/Ray3D ."
Attention Based Neural Networks for Wireless Channel Estimation,0.0682463,"In this paper, we deploy the self-attention mechanism to achieve improved
channel estimation for orthogonal frequency-division multiplexing waveforms in
the downlink. Specifically, we propose a new hybrid encoder-decoder structure
(called HA02) for the first time which exploits the attention mechanism to
focus on the most important input information. In particular, we implement a
transformer encoder block as the encoder to achieve the sparsity in the input
features and a residual neural network as the decoder respectively, inspired by
the success of the attention mechanism. Using 3GPP channel models, our
simulations show superior estimation performance compared with other candidate
neural network methods for channel estimation."
Semantic Enhanced Text-to-SQL Parsing via Iteratively Learning Schema Linking Graph,0.147112,"The generalizability to new databases is of vital importance to Text-to-SQL
systems which aim to parse human utterances into SQL statements. Existing works
achieve this goal by leveraging the exact matching method to identify the
lexical matching between the question words and the schema items. However,
these methods fail in other challenging scenarios, such as the synonym
substitution in which the surface form differs between the corresponding
question words and schema items. In this paper, we propose a framework named
ISESL-SQL to iteratively build a semantic enhanced schema-linking graph between
question tokens and database schemas. First, we extract a schema linking graph
from PLMs through a probing procedure in an unsupervised manner. Then the
schema linking graph is further optimized during the training process through a
deep graph learning method. Meanwhile, we also design an auxiliary task called
graph regularization to improve the schema information mentioned in the
schema-linking graph. Extensive experiments on three benchmarks demonstrate
that ISESL-SQL could consistently outperform the baselines and further
investigations show its generalizability and robustness."
Hand Avatar: Free-Pose Hand Animation and Rendering from Monocular Video,0.864665,"We present HandAvatar, a novel representation for hand animation and
rendering, which can generate smoothly compositional geometry and
self-occlusion-aware texture. Specifically, we first develop a MANO-HD model as
a high-resolution mesh topology to fit personalized hand shapes. Sequentially,
we decompose hand geometry into per-bone rigid parts, and then re-compose
paired geometry encodings to derive an across-part consistent occupancy field.
As for texture modeling, we propose a self-occlusion-aware shading field
(SelF). In SelF, drivable anchors are paved on the MANO-HD surface to record
albedo information under a wide variety of hand poses. Moreover, directed soft
occupancy is designed to describe the ray-to-surface relation, which is
leveraged to generate an illumination field for the disentanglement of
pose-independent albedo and pose-dependent illumination. Trained from monocular
video data, our HandAvatar can perform free-pose hand animation and rendering
while at the same time achieving superior appearance fidelity. We also
demonstrate that HandAvatar provides a route for hand appearance editing.
Project website: https://seanchenxy.github.io/HandAvatarWeb."
"When classifying grammatical role, BERT doesn't care about word order... except when it matters",0.0917404,"Because meaning can often be inferred from lexical semantics alone, word
order is often a redundant cue in natural language. For example, the words
chopped, chef, and onion are more likely used to convey ""The chef chopped the
onion,"" not ""The onion chopped the chef."" Recent work has shown large language
models to be surprisingly word order invariant, but crucially has largely
considered natural prototypical inputs, where compositional meaning mostly
matches lexical expectations. To overcome this confound, we probe grammatical
role representation in English BERT and GPT-2, on instances where lexical
expectations are not sufficient, and word order knowledge is necessary for
correct classification. Such non-prototypical instances are naturally occurring
English sentences with inanimate subjects or animate objects, or sentences
where we systematically swap the arguments to make sentences like ""The onion
chopped the chef"". We find that, while early layer embeddings are largely
lexical, word order is in fact crucial in defining the later-layer
representations of words in semantically non-prototypical positions. Our
experiments isolate the effect of word order on the contextualization process,
and highlight how models use context in the uncommon, but critical, instances
where it matters."
Recognising the importance of preference change: A call for a coordinated multidisciplinary research effort in the age of AI,0.124548,"As artificial intelligence becomes more powerful and a ubiquitous presence in
daily life, it is imperative to understand and manage the impact of AI systems
on our lives and decisions. Modern ML systems often change user behavior (e.g.
personalized recommender systems learn user preferences to deliver
recommendations that change online behavior). An externality of behavior change
is preference change. This article argues for the establishment of a
multidisciplinary endeavor focused on understanding how AI systems change
preference: Preference Science. We operationalize preference to incorporate
concepts from various disciplines, outlining the importance of meta-preferences
and preference-change preferences, and proposing a preliminary framework for
how preferences change. We draw a distinction between preference change,
permissible preference change, and outright preference manipulation. A
diversity of disciplines contribute unique insights to this framework."
Learning to Revise References for Faithful Summarization,0.220904,"In real-world scenarios with naturally occurring datasets, reference
summaries are noisy and may contain information that cannot be inferred from
the source text. On large news corpora, removing low quality samples has been
shown to reduce model hallucinations. Yet, for smaller, and/or noisier corpora,
filtering is detrimental to performance. To improve reference quality while
retaining all data, we propose a new approach: to selectively re-write
unsupported reference sentences to better reflect source data. We automatically
generate a synthetic dataset of positive and negative revisions by corrupting
supported sentences and learn to revise reference sentences with contrastive
learning. The intensity of revisions is treated as a controllable attribute so
that, at inference, diverse candidates can be over-generated-then-rescored to
balance faithfulness and abstraction. To test our methods, we extract noisy
references from publicly available MIMIC-III discharge summaries for the task
of hospital-course summarization, and vary the data on which models are
trained. According to metrics and human evaluation, models trained on revised
clinical references are much more faithful, informative, and fluent than models
trained on original or filtered data."
A Slot Is Not Built in One Utterance: Spoken Language Dialogs with Sub-Slots,0.452555,"A slot value might be provided segment by segment over multiple-turn
interactions in a dialog, especially for some important information such as
phone numbers and names. It is a common phenomenon in daily life, but little
attention has been paid to it in previous work. To fill the gap, this paper
defines a new task named Sub-Slot based Task-Oriented Dialog (SSTOD) and builds
a Chinese dialog dataset SSD for boosting research on SSTOD. The dataset
includes a total of 40K dialogs and 500K utterances from four different
domains: Chinese names, phone numbers, ID numbers and license plate numbers.
The data is well annotated with sub-slot values, slot values, dialog states and
actions. We find some new linguistic phenomena and interactive manners in SSTOD
which raise critical challenges of building dialog agents for the task. We test
three state-of-the-art dialog models on SSTOD and find they cannot handle the
task well on any of the four domains. We also investigate an improved model by
involving slot knowledge in a plug-in manner. More work should be done to meet
the new challenges raised from SSTOD which widely exists in real-life
applications. The dataset and code are publicly available via
https://github.com/shunjiu/SSTOD."
"CVM-Cervix: A Hybrid Cervical Pap-Smear Image Classification Framework Using CNN, Visual Transformer and Multilayer Perceptron",0.912505,"Cervical cancer is the seventh most common cancer among all the cancers
worldwide and the fourth most common cancer among women. Cervical cytopathology
image classification is an important method to diagnose cervical cancer. Manual
screening of cytopathology images is time-consuming and error-prone. The
emergence of the automatic computer-aided diagnosis system solves this problem.
This paper proposes a framework called CVM-Cervix based on deep learning to
perform cervical cell classification tasks. It can analyze pap slides quickly
and accurately. CVM-Cervix first proposes a Convolutional Neural Network module
and a Visual Transformer module for local and global feature extraction
respectively, then a Multilayer Perceptron module is designed to fuse the local
and global features for the final classification. Experimental results show the
effectiveness and potential of the proposed CVM-Cervix in the field of cervical
Pap smear image classification. In addition, according to the practical needs
of clinical work, we perform a lightweight post-processing to compress the
model."
Rethinking the Role of Scale for In-Context Learning: An Interpretability-based Case Study at 66 Billion Scale,0.0411115,"Language models have been shown to perform better with an increase in scale
on a wide variety of tasks via the in-context learning paradigm. In this paper,
we investigate the hypothesis that the ability of a large language model to
in-context learn-perform a task is not uniformly spread across all of its
underlying components. Using a 66 billion parameter language model (OPT-66B)
across a diverse set of 14 downstream tasks, we find this is indeed the case:
$\sim$70% of attention heads and $\sim$20% of feed forward networks can be
removed with minimal decline in task performance. We find substantial overlap
in the set of attention heads (un)important for in-context learning across
tasks and number of in-context examples. We also address our hypothesis through
a task-agnostic lens, finding that a small set of attention heads in OPT-66B
score highly on their ability to perform primitive induction operations
associated with in-context learning, namely, prefix matching and copying. These
induction heads overlap with task-specific important heads, reinforcing
arguments by Olsson et al. (arXiv:2209.11895) regarding induction head
generality to more sophisticated behaviors associated with in-context learning.
Overall, our study provides several insights that indicate large language
models may be under-trained for in-context learning and opens up questions on
how to pre-train language models to more effectively perform in-context
learning."
SciNLI: A Corpus for Natural Language Inference on Scientific Text,0.101996,"Existing Natural Language Inference (NLI) datasets, while being instrumental
in the advancement of Natural Language Understanding (NLU) research, are not
related to scientific text. In this paper, we introduce SciNLI, a large dataset
for NLI that captures the formality in scientific text and contains 107,412
sentence pairs extracted from scholarly papers on NLP and computational
linguistics. Given that the text used in scientific literature differs vastly
from the text used in everyday language both in terms of vocabulary and
sentence structure, our dataset is well suited to serve as a benchmark for the
evaluation of scientific NLU models. Our experiments show that SciNLI is harder
to classify than the existing NLI datasets. Our best performing model with
XLNet achieves a Macro F1 score of only 78.18% and an accuracy of 78.23%
showing that there is substantial room for improvement."
Cross-Spectral Neural Radiance Fields,0.628712,"We propose X-NeRF, a novel method to learn a Cross-Spectral scene
representation given images captured from cameras with different light spectrum
sensitivity, based on the Neural Radiance Fields formulation. X-NeRF optimizes
camera poses across spectra during training and exploits Normalized
Cross-Device Coordinates (NXDC) to render images of different modalities from
arbitrary viewpoints, which are aligned and at the same resolution. Experiments
on 16 forward-facing scenes, featuring color, multi-spectral and infrared
images, confirm the effectiveness of X-NeRF at modeling Cross-Spectral scene
representations."
Continuous Prompt Tuning Based Textual Entailment Model for E-commerce Entity Typing,0.0281878,"The explosion of e-commerce has caused the need for processing and analysis
of product titles, like entity typing in product titles. However, the rapid
activity in e-commerce has led to the rapid emergence of new entities, which is
difficult to be solved by general entity typing. Besides, product titles in
e-commerce have very different language styles from text data in general
domain. In order to handle new entities in product titles and address the
special language styles problem of product titles in e-commerce domain, we
propose our textual entailment model with continuous prompt tuning based
hypotheses and fusion embeddings for e-commerce entity typing. First, we
reformulate the entity typing task into a textual entailment problem to handle
new entities that are not present during training. Second, we design a model to
automatically generate textual entailment hypotheses using a continuous prompt
tuning method, which can generate better textual entailment hypotheses without
manual design. Third, we utilize the fusion embeddings of BERT embedding and
CharacterBERT embedding with a two-layer MLP classifier to solve the problem
that the language styles of product titles in e-commerce are different from
that of general domain. To analyze the effect of each contribution, we compare
the performance of entity typing and textual entailment model, and conduct
ablation studies on continuous prompt tuning and fusion embeddings. We also
evaluate the impact of different prompt template initialization for the
continuous prompt tuning. We show our proposed model improves the average F1
score by around 2% compared to the baseline BERT entity typing model."
Other Roles Matter! Enhancing Role-Oriented Dialogue Summarization via Role Interactions,0.0505034,"Role-oriented dialogue summarization is to generate summaries for different
roles in the dialogue, e.g., merchants and consumers. Existing methods handle
this task by summarizing each role's content separately and thus are prone to
ignore the information from other roles. However, we believe that other roles'
content could benefit the quality of summaries, such as the omitted information
mentioned by other roles. Therefore, we propose a novel role interaction
enhanced method for role-oriented dialogue summarization. It adopts cross
attention and decoder self-attention interactions to interactively acquire
other roles' critical information. The cross attention interaction aims to
select other roles' critical dialogue utterances, while the decoder
self-attention interaction aims to obtain key information from other roles'
summaries. Experimental results have shown that our proposed method
significantly outperforms strong baselines on two public role-oriented dialogue
summarization datasets. Extensive analyses have demonstrated that other roles'
content could help generate summaries with more complete semantics and correct
topic structures."
Smoothing Entailment Graphs with Language Models,0.20607,"The diversity and Zipfian frequency distribution of natural language
predicates in corpora leads to sparsity in Entailment Graphs (EGs) built by
Open Relation Extraction (ORE). EGs are computationally efficient and
explainable models of natural language inference, but as symbolic models, they
fail if a novel premise or hypothesis vertex is missing at test-time. We
present theory and methodology for overcoming such sparsity in symbolic models.
First, we introduce a theory of optimal smoothing of EGs by constructing
transitive chains. We then demonstrate an efficient, open-domain, and
unsupervised smoothing method using an off-the-shelf Language Model to find
approximations of missing premise predicates. This improves recall by 25.1 and
16.3 percentage points on two difficult directional entailment datasets, while
raising average precision and maintaining model explainability. Further, in a
QA task we show that EG smoothing is most useful for answering questions with
lesser supporting text, where missing premise predicates are more costly.
Finally, controlled experiments with WordNet confirm our theory and show that
hypothesis smoothing is difficult, but possible in principle."
Semantic Similarity Computing Model Based on Multi Model Fine-Grained Nonlinear Fusion,0.147768,"Natural language processing (NLP) task has achieved excellent performance in
many fields, including semantic understanding, automatic summarization, image
recognition and so on. However, most of the neural network models for NLP
extract the text in a fine-grained way, which is not conducive to grasp the
meaning of the text from a global perspective. To alleviate the problem, the
combination of the traditional statistical method and deep learning model as
well as a novel model based on multi model nonlinear fusion are proposed in
this paper. The model uses the Jaccard coefficient based on part of speech,
Term Frequency-Inverse Document Frequency (TF-IDF) and word2vec-CNN algorithm
to measure the similarity of sentences respectively. According to the
calculation accuracy of each model, the normalized weight coefficient is
obtained and the calculation results are compared. The weighted vector is input
into the fully connected neural network to give the final classification
results. As a result, the statistical sentence similarity evaluation algorithm
reduces the granularity of feature extraction, so it can grasp the sentence
features globally. Experimental results show that the matching of sentence
similarity calculation method based on multi model nonlinear fusion is 84%, and
the F1 value of the model is 75%."
Consent as a Foundation for Responsible Autonomy,0.390681,"This paper focuses on a dynamic aspect of responsible autonomy, namely, to
make intelligent agents be responsible at run time. That is, it considers
settings where decision making by agents impinges upon the outcomes perceived
by other agents. For an agent to act responsibly, it must accommodate the
desires and other attitudes of its users and, through other agents, of their
users.
  The contribution of this paper is twofold. First, it provides a conceptual
analysis of consent, its benefits and misuses, and how understanding consent
can help achieve responsible autonomy. Second, it outlines challenges for AI
(in particular, for agents and multiagent systems) that merit investigation to
form as a basis for modeling consent in multiagent systems and applying consent
to achieve responsible autonomy."
Region-Aware Face Swapping,0.395715,"This paper presents a novel Region-Aware Face Swapping (RAFSwap) network to
achieve identity-consistent harmonious high-resolution face generation in a
local-global manner: \textbf{1)} Local Facial Region-Aware (FRA) branch
augments local identity-relevant features by introducing the Transformer to
effectively model misaligned cross-scale semantic interaction. \textbf{2)}
Global Source Feature-Adaptive (SFA) branch further complements global
identity-relevant cues for generating identity-consistent swapped faces.
Besides, we propose a \textit{Face Mask Predictor} (FMP) module incorporated
with StyleGAN2 to predict identity-relevant soft facial masks in an
unsupervised manner that is more practical for generating harmonious
high-resolution faces. Abundant experiments qualitatively and quantitatively
demonstrate the superiority of our method for generating more
identity-consistent high-resolution swapped faces over SOTA methods, \eg,
obtaining 96.70 ID retrieval that outperforms SOTA MegaFS by 5.87$\uparrow$."
A new Hyper-heuristic based on Adaptive Simulated Annealing and Reinforcement Learning for the Capacitated Electric Vehicle Routing Problem,0.213073,"Electric vehicles (EVs) have been adopted in urban areas to reduce
environmental pollution and global warming as a result of the increasing number
of freight vehicles. However, there are still deficiencies in routing the
trajectories of last-mile logistics that continue to impact social and economic
sustainability. For that reason, in this paper, a hyper-heuristic (HH) approach
called Hyper-heuristic Adaptive Simulated Annealing with Reinforcement Learning
(HHASA$_{RL}$) is proposed. It is composed of a multi-armed bandit method and
the self-adaptive Simulated Annealing (SA) metaheuristic algorithm for solving
the problem called Capacitated Electric Vehicle Routing Problem (CEVRP). Due to
the limited number of charging stations and the travel range of EVs, the EVs
must require battery recharging moments in advance and reduce travel times and
costs. The HH implemented improves multiple minimum best-known solutions and
obtains the best mean values for some high-dimensional instances for the
proposed benchmark for the IEEE WCCI2020 competition."
Don't Say What You Don't Know: Improving the Consistency of Abstractive Summarization by Constraining Beam Search,0.141384,"Abstractive summarization systems today produce fluent and relevant output,
but often ""hallucinate"" statements not supported by the source text. We analyze
the connection between hallucinations and training data, and find evidence that
models hallucinate because they train on target summaries that are unsupported
by the source. Based on our findings, we present PINOCCHIO, a new decoding
method that improves the consistency of a transformer-based abstractive
summarizer by constraining beam search to avoid hallucinations. Given the model
states and outputs at a given step, PINOCCHIO detects likely model
hallucinations based on various measures of attribution to the source text.
PINOCCHIO backtracks to find more consistent output, and can opt to produce no
summary at all when no consistent generation can be found. In experiments, we
find that PINOCCHIO improves the consistency of generation (in terms of F1) by
an average of~67% on two abstractive summarization datasets."
Visually-Augmented Language Modeling,0.209329,"Human language is grounded on multimodal knowledge including visual knowledge
like colors, sizes, and shapes. However, current large-scale pre-trained
language models rely on text-only self-supervised training with massive text
data, which precludes them from utilizing relevant visual information when
necessary. To address this, we propose a novel pre-training framework, named
VaLM, to Visually-augment text tokens with retrieved relevant images for
Language Modeling. Specifically, VaLM builds on a novel latent text-image
alignment method via an image retrieval module to fetch corresponding images
given a textual context. With the visually-augmented context, VaLM uses a
visual knowledge fusion layer to enable multimodal grounded language modeling
by attending to both text context and visual knowledge in images. We evaluate
VaLM on various visual knowledge-intensive commonsense reasoning tasks, which
require visual information to excel. The experimental results illustrate that
VaLM outperforms all strong language-only and vision-language baselines with
substantial gains in reasoning object commonsense including color, size, and
shape. Our code is available at https://github.com/Victorwz/VaLM."
Thermodynamics-informed neural networks for physically realistic mixed reality,0.0159536,"The imminent impact of immersive technologies in society urges for active
research in real-time and interactive physics simulation for virtual worlds to
be realistic. In this context, realistic means to be compliant to the laws of
physics. In this paper we present a method for computing the dynamic response
of (possibly non-linear and dissipative) deformable objects induced by
real-time user interactions in mixed reality using deep learning. The
graph-based architecture of the method ensures the thermodynamic consistency of
the predictions, whereas the visualization pipeline allows a natural and
realistic user experience. Two examples of virtual solids interacting with
virtual or physical solids in mixed reality scenarios are provided to prove the
performance of the method."
Better plain ViT baselines for ImageNet-1k,0.0544374,"It is commonly accepted that the Vision Transformer model requires
sophisticated regularization techniques to excel at ImageNet-1k scale data.
Surprisingly, we find this is not the case and standard data augmentation is
sufficient. This note presents a few minor modifications to the original Vision
Transformer (ViT) vanilla training setting that dramatically improve the
performance of plain ViT models. Notably, 90 epochs of training surpass 76%
top-1 accuracy in under seven hours on a TPUv3-8, similar to the classic
ResNet50 baseline, and 300 epochs of training reach 80% in less than one day."
Whodunit? Learning to Contrast for Authorship Attribution,0.233312,"Authorship attribution is the task of identifying the author of a given text.
The key is finding representations that can differentiate between authors.
Existing approaches typically use manually designed features that capture a
dataset's content and style, but these approaches are dataset-dependent and
yield inconsistent performance across corpora. In this work, we propose
\textit{learning} author-specific representations by fine-tuning pre-trained
generic language representations with a contrastive objective (Contra-X). We
show that Contra-X learns representations that form highly separable clusters
for different authors. It advances the state-of-the-art on multiple human and
machine authorship attribution benchmarks, enabling improvements of up to 6.8%
over cross-entropy fine-tuning. However, we find that Contra-X improves overall
accuracy at the cost of sacrificing performance for some authors. Resolving
this tension will be an important direction for future work. To the best of our
knowledge, we are the first to integrate contrastive learning with pre-trained
language model fine-tuning for authorship attribution."
Motion Policy Networks,0.278777,"Collision-free motion generation in unknown environments is a core building
block for robot manipulation. Generating such motions is challenging due to
multiple objectives; not only should the solutions be optimal, the motion
generator itself must be fast enough for real-time performance and reliable
enough for practical deployment. A wide variety of methods have been proposed
ranging from local controllers to global planners, often being combined to
offset their shortcomings. We present an end-to-end neural model called Motion
Policy Networks (M$\pi$Nets) to generate collision-free, smooth motion from
just a single depth camera observation. M$\pi$Nets are trained on over 3
million motion planning problems in over 500,000 environments. Our experiments
show that M$\pi$Nets are significantly faster than global planners while
exhibiting the reactivity needed to deal with dynamic scenes. They are 46%
better than prior neural planners and more robust than local control policies.
Despite being only trained in simulation, M$\pi$Nets transfer well to the real
robot with noisy partial point clouds. Code and data are publicly available at
https://mpinets.github.io."
Unifying and Boosting Gradient-Based Training-Free Neural Architecture Search,0.0880127,"Neural architecture search (NAS) has gained immense popularity owing to its
ability to automate neural architecture design. A number of training-free
metrics are recently proposed to realize NAS without training, hence making NAS
more scalable. Despite their competitive empirical performances, a unified
theoretical understanding of these training-free metrics is lacking. As a
consequence, (a) the relationships among these metrics are unclear, (b) there
is no theoretical interpretation for their empirical performances, and (c)
there may exist untapped potential in existing training-free NAS, which
probably can be unveiled through a unified theoretical understanding. To this
end, this paper presents a unified theoretical analysis of gradient-based
training-free NAS, which allows us to (a) theoretically study their
relationships, (b) theoretically guarantee their generalization performances,
and (c) exploit our unified theoretical understanding to develop a novel
framework named hybrid NAS (HNAS) which consistently boosts training-free NAS
in a principled way. Remarkably, HNAS can enjoy the advantages of both
training-free (i.e., the superior search efficiency) and training-based (i.e.,
the remarkable search effectiveness) NAS, which we have demonstrated through
extensive experiments."
Procedural Image Programs for Representation Learning,0.22317,"Learning image representations using synthetic data allows training neural
networks without some of the concerns associated with real images, such as
privacy and bias. Existing work focuses on a handful of curated generative
processes which require expert knowledge to design, making it hard to scale up.
To overcome this, we propose training with a large dataset of twenty-one
thousand programs, each one generating a diverse set of synthetic images. These
programs are short code snippets, which are easy to modify and fast to execute
using OpenGL. The proposed dataset can be used for both supervised and
unsupervised representation learning, and reduces the gap between pre-training
with real and procedurally generated images by 38%."
BERT-Deep CNN: State-of-the-Art for Sentiment Analysis of COVID-19 Tweets,0.0525518,"The free flow of information has been accelerated by the rapid development of
social media technology. There has been a significant social and psychological
impact on the population due to the outbreak of Coronavirus disease (COVID-19).
The COVID-19 pandemic is one of the current events being discussed on social
media platforms. In order to safeguard societies from this pandemic, studying
people's emotions on social media is crucial. As a result of their particular
characteristics, sentiment analysis of texts like tweets remains challenging.
Sentiment analysis is a powerful text analysis tool. It automatically detects
and analyzes opinions and emotions from unstructured data. Texts from a wide
range of sources are examined by a sentiment analysis tool, which extracts
meaning from them, including emails, surveys, reviews, social media posts, and
web articles. To evaluate sentiments, natural language processing (NLP) and
machine learning techniques are used, which assign weights to entities, topics,
themes, and categories in sentences or phrases. Machine learning tools learn
how to detect sentiment without human intervention by examining examples of
emotions in text. In a pandemic situation, analyzing social media texts to
uncover sentimental trends can be very helpful in gaining a better
understanding of society's needs and predicting future trends. We intend to
study society's perception of the COVID-19 pandemic through social media using
state-of-the-art BERT and Deep CNN models. The superiority of BERT models over
other deep models in sentiment analysis is evident and can be concluded from
the comparison of the various research studies mentioned in this article."
Transfer Learning with Synthetic Corpora for Spatial Role Labeling and Reasoning,0.361327,"Recent research shows synthetic data as a source of supervision helps
pretrained language models (PLM) transfer learning to new target tasks/domains.
However, this idea is less explored for spatial language. We provide two new
data resources on multiple spatial language processing tasks. The first dataset
is synthesized for transfer learning on spatial question answering (SQA) and
spatial role labeling (SpRL). Compared to previous SQA datasets, we include a
larger variety of spatial relation types and spatial expressions. Our data
generation process is easily extendable with new spatial expression lexicons.
The second one is a real-world SQA dataset with human-generated questions built
on an existing corpus with SPRL annotations. This dataset can be used to
evaluate spatial language processing models in realistic situations. We show
pretraining with automatically generated data significantly improves the SOTA
results on several SQA and SPRL benchmarks, particularly when the training data
in the target domain is small."
Not always about you: Prioritizing community needs when developing endangered language technology,0.22662,"Languages are classified as low-resource when they lack the quantity of data
necessary for training statistical and machine learning tools and models.
Causes of resource scarcity vary but can include poor access to technology for
developing these resources, a relatively small population of speakers, or a
lack of urgency for collecting such resources in bilingual populations where
the second language is high-resource. As a result, the languages described as
low-resource in the literature are as different as Finnish on the one hand,
with millions of speakers using it in every imaginable domain, and Seneca, with
only a small-handful of fluent speakers using the language primarily in a
restricted domain. While issues stemming from the lack of resources necessary
to train models unite this disparate group of languages, many other issues cut
across the divide between widely-spoken low resource languages and endangered
languages. In this position paper, we discuss the unique technological,
cultural, practical, and ethical challenges that researchers and indigenous
speech community members face when working together to develop language
technology to support endangered language documentation and revitalization. We
report the perspectives of language teachers, Master Speakers and elders from
indigenous communities, as well as the point of view of academics. We describe
an ongoing fruitful collaboration and make recommendations for future
partnerships between academic researchers and language community stakeholders."
rPPG-Toolbox: Deep Remote PPG Toolbox,0.0509952,"Camera-based physiological measurement is a fast growing field of computer
vision. Remote photoplethysmography (rPPG) utilizes imaging devices (e.g.,
cameras) to measure the peripheral blood volume pulse (BVP) via
photoplethysmography, and enables cardiac measurement via webcams and
smartphones. However, the task is non-trivial with important pre-processing,
modeling, and post-processing steps required to obtain state-of-the-art
results. Replication of results and benchmarking of new models is critical for
scientific progress; however, as with many other applications of deep learning,
reliable codebases are not easy to find or use. We present a comprehensive
toolbox, rPPG-Toolbox, that contains unsupervised and supervised rPPG models
with support for public benchmark datasets, data augmentation, and systematic
evaluation: \url{https://github.com/ubicomplab/rPPG-Toolbox}"
Siamese Contrastive Embedding Network for Compositional Zero-Shot Learning,0.480341,"Compositional Zero-Shot Learning (CZSL) aims to recognize unseen compositions
formed from seen state and object during training. Since the same state may be
various in the visual appearance while entangled with different objects, CZSL
is still a challenging task. Some methods recognize state and object with two
trained classifiers, ignoring the impact of the interaction between object and
state; the other methods try to learn the joint representation of the
state-object compositions, leading to the domain gap between seen and unseen
composition sets. In this paper, we propose a novel Siamese Contrastive
Embedding Network (SCEN) (Code: https://github.com/XDUxyLi/SCEN-master) for
unseen composition recognition. Considering the entanglement between state and
object, we embed the visual feature into a Siamese Contrastive Space to capture
prototypes of them separately, alleviating the interaction between state and
object. In addition, we design a State Transition Module (STM) to increase the
diversity of training compositions, improving the robustness of the recognition
model. Extensive experiments indicate that our method significantly outperforms
the state-of-the-art approaches on three challenging benchmark datasets,
including the recent proposed C-QGA dataset."
ComMU: Dataset for Combinatorial Music Generation,0.0820048,"Commercial adoption of automatic music composition requires the capability of
generating diverse and high-quality music suitable for the desired context
(e.g., music for romantic movies, action games, restaurants, etc.). In this
paper, we introduce combinatorial music generation, a new task to create
varying background music based on given conditions. Combinatorial music
generation creates short samples of music with rich musical metadata, and
combines them to produce a complete music. In addition, we introduce ComMU, the
first symbolic music dataset consisting of short music samples and their
corresponding 12 musical metadata for combinatorial music generation. Notable
properties of ComMU are that (1) dataset is manually constructed by
professional composers with an objective guideline that induces regularity, and
(2) it has 12 musical metadata that embraces composers' intentions. Our results
show that we can generate diverse high-quality music only with metadata, and
that our unique metadata such as track-role and extended chord quality improves
the capacity of the automatic composition. We highly recommend watching our
video before reading the paper (https://pozalabs.github.io/ComMU)."
CCPT: Automatic Gameplay Testing and Validation with Curiosity-Conditioned Proximal Trajectories,0.117466,"This paper proposes a novel deep reinforcement learning algorithm to perform
automatic analysis and detection of gameplay issues in complex 3D navigation
environments. The Curiosity-Conditioned Proximal Trajectories (CCPT) method
combines curiosity and imitation learning to train agents to methodically
explore in the proximity of known trajectories derived from expert
demonstrations. We show how CCPT can explore complex environments, discover
gameplay issues and design oversights in the process, and recognize and
highlight them directly to game designers. We further demonstrate the
effectiveness of the algorithm in a novel 3D navigation environment which
reflects the complexity of modern AAA video games. Our results show a higher
level of coverage and bug discovery than baselines methods, and it hence can
provide a valuable tool for game designers to identify issues in game design
automatically."
Camera-Conditioned Stable Feature Generation for Isolated Camera Supervised Person Re-IDentification,0.0524352,"To learn camera-view invariant features for person Re-IDentification (Re-ID),
the cross-camera image pairs of each person play an important role. However,
such cross-view training samples could be unavailable under the ISolated Camera
Supervised (ISCS) setting, e.g., a surveillance system deployed across distant
scenes. To handle this challenging problem, a new pipeline is introduced by
synthesizing the cross-camera samples in the feature space for model training.
Specifically, the feature encoder and generator are end-to-end optimized under
a novel method, Camera-Conditioned Stable Feature Generation (CCSFG). Its joint
learning procedure raises concern on the stability of generative model
training. Therefore, a new feature generator, $\sigma$-Regularized Conditional
Variational Autoencoder ($\sigma$-Reg.~CVAE), is proposed with theoretical and
experimental analysis on its robustness. Extensive experiments on two ISCS
person Re-ID datasets demonstrate the superiority of our CCSFG to the
competitors."
Sentiment-Aware Automatic Speech Recognition pre-training for enhanced Speech Emotion Recognition,0.182329,"We propose a novel multi-task pre-training method for Speech Emotion
Recognition (SER). We pre-train SER model simultaneously on Automatic Speech
Recognition (ASR) and sentiment classification tasks to make the acoustic ASR
model more ``emotion aware''. We generate targets for the sentiment
classification using text-to-sentiment model trained on publicly available
data. Finally, we fine-tune the acoustic ASR on emotion annotated speech data.
We evaluated the proposed approach on the MSP-Podcast dataset, where we
achieved the best reported concordance correlation coefficient (CCC) of 0.41
for valence prediction."
End-to-End Image-Based Fashion Recommendation,0.259308,"In fashion-based recommendation settings, incorporating the item image
features is considered a crucial factor, and it has shown significant
improvements to many traditional models, including but not limited to matrix
factorization, auto-encoders, and nearest neighbor models. While there are
numerous image-based recommender approaches that utilize dedicated deep neural
networks, comparisons to attribute-aware models are often disregarded despite
their ability to be easily extended to leverage items' image features. In this
paper, we propose a simple yet effective attribute-aware model that
incorporates image features for better item representation learning in item
recommendation tasks. The proposed model utilizes items' image features
extracted by a calibrated ResNet50 component. We present an ablation study to
compare incorporating the image features using three different techniques into
the recommender system component that can seamlessly leverage any available
items' attributes. Experiments on two image-based real-world recommender
systems datasets show that the proposed model significantly outperforms all
state-of-the-art image-based models."
Open- and Closed-Loop Neural Network Verification using Polynomial Zonotopes,0.0908746,"We present a novel approach to efficiently compute tight non-convex
enclosures of the image through neural networks with ReLU, sigmoid, or
hyperbolic tangent activation functions. In particular, we abstract the
input-output relation of each neuron by a polynomial approximation, which is
evaluated in a set-based manner using polynomial zonotopes. While our approach
can also can be beneficial for open-loop neural network verification, our main
application is reachability analysis of neural network controlled systems,
where polynomial zonotopes are able to capture the non-convexity caused by the
neural network as well as the system dynamics. This results in a superior
performance compared to other methods, as we demonstrate on various benchmarks."
Deep versus Wide: An Analysis of Student Architectures for Task-Agnostic Knowledge Distillation of Self-Supervised Speech Models,0.187229,"Self-supervised learning (SSL) is seen as a very promising approach with high
performance for several speech downstream tasks. Since the parameters of SSL
models are generally so large that training and inference require a lot of
memory and computational cost, it is desirable to produce compact SSL models
without a significant performance degradation by applying compression methods
such as knowledge distillation (KD). Although the KD approach is able to shrink
the depth and/or width of SSL model structures, there has been little research
on how varying the depth and width impacts the internal representation of the
small-footprint model. This paper provides an empirical study that addresses
the question. We investigate the performance on SUPERB while varying the
structure and KD methods so as to keep the number of parameters constant; this
allows us to analyze the contribution of the representation introduced by
varying the model architecture. Experiments demonstrate that a certain depth is
essential for solving content-oriented tasks (e.g. automatic speech
recognition) accurately, whereas a certain width is necessary for achieving
high performance on several speaker-oriented tasks (e.g. speaker
identification). Based on these observations, we identify, for SUPERB, a more
compressed model with better performance than previous studies."
Towards Involving End-users in Interactive Human-in-the-loop AI Fairness,0.202484,"Ensuring fairness in artificial intelligence (AI) is important to counteract
bias and discrimination in far-reaching applications. Recent work has started
to investigate how humans judge fairness and how to support machine learning
(ML) experts in making their AI models fairer. Drawing inspiration from an
Explainable AI (XAI) approach called \emph{explanatory debugging} used in
interactive machine learning, our work explores designing interpretable and
interactive human-in-the-loop interfaces that allow ordinary end-users without
any technical or domain background to identify potential fairness issues and
possibly fix them in the context of loan decisions. Through workshops with
end-users, we co-designed and implemented a prototype system that allowed
end-users to see why predictions were made, and then to change weights on
features to ""debug"" fairness issues. We evaluated the use of this prototype
system through an online study. To investigate the implications of diverse
human values about fairness around the globe, we also explored how cultural
dimensions might play a role in using this prototype. Our results contribute to
the design of interfaces to allow end-users to be involved in judging and
addressing AI fairness through a human-in-the-loop approach."
To Answer or Not to Answer? Improving Machine Reading Comprehension Model with Span-based Contrastive Learning,-1.0,"Machine Reading Comprehension with Unanswerable Questions is a difficult NLP
task, challenged by the questions which can not be answered from passages. It
is observed that subtle literal changes often make an answerable question
unanswerable, however, most MRC models fail to recognize such changes. To
address this problem, in this paper, we propose a span-based method of
Contrastive Learning (spanCL) which explicitly contrast answerable questions
with their answerable and unanswerable counterparts at the answer span level.
With spanCL, MRC models are forced to perceive crucial semantic changes from
slight literal differences. Experiments on SQuAD 2.0 dataset show that spanCL
can improve baselines significantly, yielding 0.86-2.14 absolute EM
improvements. Additional experiments also show that spanCL is an effective way
to utilize generated questions."
Controllable Radiance Fields for Dynamic Face Synthesis,0.093731,"Recent work on 3D-aware image synthesis has achieved compelling results using
advances in neural rendering. However, 3D-aware synthesis of face dynamics
hasn't received much attention. Here, we study how to explicitly control
generative model synthesis of face dynamics exhibiting non-rigid motion (e.g.,
facial expression change), while simultaneously ensuring 3D-awareness. For this
we propose a Controllable Radiance Field (CoRF): 1) Motion control is achieved
by embedding motion features within the layered latent motion space of a
style-based generator; 2) To ensure consistency of background, motion features
and subject-specific attributes such as lighting, texture, shapes, albedo, and
identity, a face parsing net, a head regressor and an identity encoder are
incorporated. On head image/video data we show that CoRFs are 3D-aware while
enabling editing of identity, viewing directions, and motion."
RAILD: Towards Leveraging Relation Features for Inductive Link Prediction In Knowledge Graphs,0.0520463,"Due to the open world assumption, Knowledge Graphs (KGs) are never complete.
In order to address this issue, various Link Prediction (LP) methods are
proposed so far. Some of these methods are inductive LP models which are
capable of learning representations for entities not seen during training.
However, to the best of our knowledge, none of the existing inductive LP models
focus on learning representations for unseen relations. In this work, a novel
Relation Aware Inductive Link preDiction (RAILD) is proposed for KG completion
which learns representations for both unseen entities and unseen relations. In
addition to leveraging textual literals associated with both entities and
relations by employing language models, RAILD also introduces a novel
graph-based approach to generate features for relations. Experiments are
conducted with different existing and newly created challenging benchmark
datasets and the results indicate that RAILD leads to performance improvement
over the state-of-the-art models. Moreover, since there are no existing
inductive LP models which learn representations for unseen relations, we have
created our own baselines and the results obtained with RAILD also outperform
these baselines."
Long-tailed Instance Segmentation using Gumbel Optimized Loss,0.429659,"Major advancements have been made in the field of object detection and
segmentation recently. However, when it comes to rare categories, the
state-of-the-art methods fail to detect them, resulting in a significant
performance gap between rare and frequent categories. In this paper, we
identify that Sigmoid or Softmax functions used in deep detectors are a major
reason for low performance and are sub-optimal for long-tailed detection and
segmentation. To address this, we develop a Gumbel Optimized Loss (GOL), for
long-tailed detection and segmentation. It aligns with the Gumbel distribution
of rare classes in imbalanced datasets, considering the fact that most classes
in long-tailed detection have low expected probability. The proposed GOL
significantly outperforms the best state-of-the-art method by 1.1% on AP , and
boosts the overall segmentation by 9.0% and detection by 8.0%, particularly
improving detection of rare classes by 20.3%, compared to Mask-RCNN, on LVIS
dataset. Code available at: https://github.com/kostas1515/GOL"
Identifying Moments of Change from Longitudinal User Text,0.295369,"Identifying changes in individuals' behaviour and mood, as observed via
content shared on online platforms, is increasingly gaining importance. Most
research to-date on this topic focuses on either: (a) identifying individuals
at risk or with a certain mental health condition given a batch of posts or (b)
providing equivalent labels at the post level. A disadvantage of such work is
the lack of a strong temporal component and the inability to make longitudinal
assessments following an individual's trajectory and allowing timely
interventions. Here we define a new task, that of identifying moments of change
in individuals on the basis of their shared content online. The changes we
consider are sudden shifts in mood (switches) or gradual mood progression
(escalations). We have created detailed guidelines for capturing moments of
change and a corpus of 500 manually annotated user timelines (18.7K posts). We
have developed a variety of baseline models drawing inspiration from related
tasks and show that the best performance is obtained through context aware
sequential modelling. We also introduce new metrics for capturing rare events
in temporal windows."
Efficient Remote Photoplethysmography with Temporal Derivative Modules and Time-Shift Invariant Loss,0.336553,"We present a lightweight neural model for remote heart rate estimation
focused on the efficient spatio-temporal learning of facial
photoplethysmography (PPG) based on i) modelling of PPG dynamics by
combinations of multiple convolutional derivatives, and ii) increased
flexibility of the model to learn possible offsets between the facial video PPG
and the ground truth. PPG dynamics are modelled by a Temporal Derivative Module
(TDM) constructed by the incremental aggregation of multiple convolutional
derivatives, emulating a Taylor series expansion up to the desired order.
Robustness to ground truth offsets is handled by the introduction of TALOS
(Temporal Adaptive LOcation Shift), a new temporal loss to train learning-based
models. We verify the effectiveness of our model by reporting accuracy and
efficiency metrics on the public PURE and UBFC-rPPG datasets. Compared to
existing models, our approach shows competitive heart rate estimation accuracy
with a much lower number of parameters and lower computational cost."
Scribble-Supervised LiDAR Semantic Segmentation,0.166655,"Densely annotating LiDAR point clouds remains too expensive and
time-consuming to keep up with the ever growing volume of data. While current
literature focuses on fully-supervised performance, developing efficient
methods that take advantage of realistic weak supervision have yet to be
explored. In this paper, we propose using scribbles to annotate LiDAR point
clouds and release ScribbleKITTI, the first scribble-annotated dataset for
LiDAR semantic segmentation. Furthermore, we present a pipeline to reduce the
performance gap that arises when using such weak annotations. Our pipeline
comprises of three stand-alone contributions that can be combined with any
LiDAR semantic segmentation model to achieve up to 95.7% of the
fully-supervised performance while using only 8% labeled points. Our scribble
annotations and code are available at github.com/ouenal/scribblekitti."
HPT: Hierarchy-aware Prompt Tuning for Hierarchical Text Classification,0.827891,"Hierarchical text classification (HTC) is a challenging subtask of
multi-label classification due to its complex label hierarchy. Recently, the
pretrained language models (PLM)have been widely adopted in HTC through a
fine-tuning paradigm. However, in this paradigm, there exists a huge gap
between the classification tasks with sophisticated label hierarchy and the
masked language model (MLM) pretraining tasks of PLMs and thus the potentials
of PLMs can not be fully tapped. To bridge the gap, in this paper, we propose
HPT, a Hierarchy-aware Prompt Tuning method to handle HTC from a multi-label
MLM perspective. Specifically, we construct a dynamic virtual template and
label words that take the form of soft prompts to fuse the label hierarchy
knowledge and introduce a zero-bounded multi-label cross entropy loss to
harmonize the objectives of HTC and MLM. Extensive experiments show HPT
achieves state-of-the-art performances on 3 popular HTC datasets and is adept
at handling the imbalance and low resource situations. Our code is available at
https://github.com/wzh9969/HPT."
Depth Estimation with Simplified Transformer,0.0695427,"Transformer and its variants have shown state-of-the-art results in many
vision tasks recently, ranging from image classification to dense prediction.
Despite of their success, limited work has been reported on improving the model
efficiency for deployment in latency-critical applications, such as autonomous
driving and robotic navigation. In this paper, we aim at improving upon the
existing transformers in vision, and propose a method for self-supervised
monocular Depth Estimation with Simplified Transformer (DEST), which is
efficient and particularly suitable for deployment on GPU-based platforms.
Through strategic design choices, our model leads to significant reduction in
model size, complexity, as well as inference latency, while achieving superior
accuracy as compared to state-of-the-art. We also show that our design
generalize well to other dense prediction task without bells and whistles."
Towards Climate Awareness in NLP Research,0.270496,"The climate impact of AI, and NLP research in particular, has become a
serious issue given the enormous amount of energy that is increasingly being
used for training and running computational models. Consequently, increasing
focus is placed on efficient NLP. However, this important initiative lacks
simple guidelines that would allow for systematic climate reporting of NLP
research. We argue that this deficiency is one of the reasons why very few
publications in NLP report key figures that would allow a more thorough
examination of environmental impact. As a remedy, we propose a climate
performance model card with the primary purpose of being practically usable
with only limited information about experiments and the underlying computer
hardware. We describe why this step is essential to increase awareness about
the environmental impact of NLP research and, thereby, paving the way for more
thorough discussions."
GCS-Q: Quantum Graph Coalition Structure Generation,0.0752265,"The problem of generating an optimal coalition structure for a given
coalition game of rational agents is to find a partition that maximizes their
social welfare and is known to be NP-hard. This paper proposes GCS-Q, a novel
quantum-supported solution for Induced Subgraph Games (ISGs) in coalition
structure generation. GCS-Q starts by considering the grand coalition as
initial coalition structure and proceeds by iteratively splitting the
coalitions into two nonempty subsets to obtain a coalition structure with a
higher coalition value. In particular, given an $n$-agent ISG, the GCS-Q solves
the optimal split problem $\mathcal{O} (n)$ times using a quantum annealing
device, exploring $\mathcal{O}(2^n)$ partitions at each step. We show that
GCS-Q outperforms the currently best classical solvers with its runtime in the
order of $n^2$ and an expected worst-case approximation ratio of $93\%$ on
standard benchmark datasets."
PromptBoosting: Black-Box Text Classification with Ten Forward Passes,-1.0,"We describe PromptBoosting, a query-efficient procedure for building a text
classifier from a neural language model (LM) without access to the LM's
parameters, gradients, or hidden representations. This form of ""black-box""
classifier training has become increasingly important as the cost of training
and inference in large-scale LMs grows. But existing black-box LM classifier
learning approaches are themselves computationally inefficient, typically
specializing LMs to the target task by searching in a large space of (discrete
or continuous) prompts using zeroth-order optimization methods. Instead of
directly optimizing in prompt space, PromptBoosting obtains a small pool of
prompts via a gradient-free approach and then constructs a large pool of weak
learners by pairing these prompts with different elements of the LM's output
distribution. These weak learners are then ensembled using the AdaBoost
algorithm. The entire learning process requires only a small number of forward
passes and no backward pass. Experiments show that PromptBoosting achieves
state-of-the-art performance in multiple black-box few-shot classification
tasks, and matches or outperforms full fine-tuning in both few-shot and
standard learning paradigms, while training 10x faster than existing black-box
methods."
Retrieval of surgical phase transitions using reinforcement learning,0.0471553,"In minimally invasive surgery, surgical workflow segmentation from video
analysis is a well studied topic. The conventional approach defines it as a
multi-class classification problem, where individual video frames are
attributed a surgical phase label.
  We introduce a novel reinforcement learning formulation for offline phase
transition retrieval. Instead of attempting to classify every video frame, we
identify the timestamp of each phase transition. By construction, our model
does not produce spurious and noisy phase transitions, but contiguous phase
blocks. We investigate two different configurations of this model. The first
does not require processing all frames in a video (only <60% and <20% of frames
in 2 different applications), while producing results slightly under the
state-of-the-art accuracy. The second configuration processes all video frames,
and outperforms the state-of-the art at a comparable computational cost.
  We compare our method against the recent top-performing frame-based
approaches TeCNO and Trans-SVNet on the public dataset Cholec80 and also on an
in-house dataset of laparoscopic sacrocolpopexy. We perform both a frame-based
(accuracy, precision, recall and F1-score) and an event-based (event ratio)
evaluation of our algorithms."
Admissible Policy Teaching through Reward Design,0.151813,"We study reward design strategies for incentivizing a reinforcement learning
agent to adopt a policy from a set of admissible policies. The goal of the
reward designer is to modify the underlying reward function cost-efficiently
while ensuring that any approximately optimal deterministic policy under the
new reward function is admissible and performs well under the original reward
function. This problem can be viewed as a dual to the problem of optimal reward
poisoning attacks: instead of forcing an agent to adopt a specific policy, the
reward designer incentivizes an agent to avoid taking actions that are
inadmissible in certain states. Perhaps surprisingly, and in contrast to the
problem of optimal reward poisoning attacks, we first show that the reward
design problem for admissible policy teaching is computationally challenging,
and it is NP-hard to find an approximately optimal reward modification. We then
proceed by formulating a surrogate problem whose optimal solution approximates
the optimal solution to the reward design problem in our setting, but is more
amenable to optimization techniques and analysis. For this surrogate problem,
we present characterization results that provide bounds on the value of the
optimal solution. Finally, we design a local search algorithm to solve the
surrogate problem and showcase its utility using simulation-based experiments."
Rank-N-Contrast: Learning Continuous Representations for Regression,0.108341,"Deep regression models typically learn in an end-to-end fashion without
explicitly emphasizing a regression-aware representation. Consequently, the
learned representations exhibit fragmentation and fail to capture the
continuous nature of sample orders, inducing suboptimal results across a wide
range of regression tasks. To fill the gap, we propose Rank-N-Contrast (RNC), a
framework that learns continuous representations for regression by contrasting
samples against each other based on their rankings in the target space. We
demonstrate, theoretically and empirically, that RNC guarantees the desired
order of learned representations in accordance with the target orders, enjoying
not only better performance but also significantly improved robustness,
efficiency, and generalization. Extensive experiments using five real-world
regression datasets that span computer vision, human-computer interaction, and
healthcare verify that RNC achieves state-of-the-art performance, highlighting
its intriguing properties including better data efficiency, robustness to
spurious targets and data corruptions, and generalization to distribution
shifts. Code is available at: https://github.com/kaiwenzha/Rank-N-Contrast."
SALTED: A Framework for SAlient Long-Tail Translation Error Detection,0.568988,"Traditional machine translation (MT) metrics provide an average measure of
translation quality that is insensitive to the long tail of behavioral problems
in MT. Examples include translation of numbers, physical units, dropped content
and hallucinations. These errors, which occur rarely and unpredictably in
Neural Machine Translation (NMT), greatly undermine the reliability of
state-of-the-art MT systems. Consequently, it is important to have visibility
into these problems during model development. Towards this direction, we
introduce SALTED, a specifications-based framework for behavioral testing of MT
models that provides fine-grained views of salient long-tail errors, permitting
trustworthy visibility into previously invisible problems. At the core of our
approach is the development of high-precision detectors that flag errors (or
alternatively, verify output correctness) between a source sentence and a
system output. We demonstrate that such detectors could be used not just to
identify salient long-tail errors in MT systems, but also for higher-recall
filtering of the training data, fixing targeted errors with model fine-tuning
in NMT and generating novel data for metamorphic testing to elicit further bugs
in models."
Biometric Signature Verification Using Recurrent Neural Networks,0.612743,"Architectures based on Recurrent Neural Networks (RNNs) have been
successfully applied to many different tasks such as speech or handwriting
recognition with state-of-the-art results. The main contribution of this work
is to analyse the feasibility of RNNs for on-line signature verification in
real practical scenarios. We have considered a system based on Long Short-Term
Memory (LSTM) with a Siamese architecture whose goal is to learn a similarity
metric from pairs of signatures. For the experimental work, the BiosecurID
database comprised of 400 users and 4 separated acquisition sessions are
considered. Our proposed LSTM RNN system has outperformed the results of recent
published works on the BiosecurID benchmark in figures ranging from 17.76% to
28.00% relative verification performance improvement for skilled forgeries."
Input-Tuning: Adapting Unfamiliar Inputs to Frozen Pretrained Models,0.0975974,"Recently the prompt-tuning paradigm has attracted significant attention. By
only tuning continuous prompts with a frozen pre-trained language model (PLM),
prompt-tuning takes a step towards deploying a shared frozen PLM to serve
numerous downstream tasks. Although prompt-tuning shows good performance on
certain natural language understanding (NLU) tasks, its effectiveness on
natural language generation (NLG) tasks is still under-explored. In this paper,
we argue that one of the factors hindering the development of prompt-tuning on
NLG tasks is the unfamiliar inputs (i.e., inputs are linguistically different
from the pretraining corpus). For example, our preliminary exploration reveals
a large performance gap between prompt-tuning and fine-tuning when unfamiliar
inputs occur frequently in NLG tasks. This motivates us to propose
input-tuning, which fine-tunes both the continuous prompts and the input
representations, leading to a more effective way to adapt unfamiliar inputs to
frozen PLMs. Our proposed input-tuning is conceptually simple and empirically
powerful. Experimental results on seven NLG tasks demonstrate that input-tuning
is significantly and consistently better than prompt-tuning. Furthermore, on
three of these tasks, input-tuning can achieve a comparable or even better
performance than fine-tuning."
From Easy to Hard: Two-stage Selector and Reader for Multi-hop Question Answering,0.224685,"Multi-hop question answering (QA) is a challenging task requiring QA systems
to perform complex reasoning over multiple documents and provide supporting
facts together with the exact answer. Existing works tend to utilize
graph-based reasoning and question decomposition to obtain the reasoning chain,
which inevitably introduces additional complexity and cumulative error to the
system. To address the above issue, we propose a simple yet effective novel
framework, From Easy to Hard (FE2H), to remove distracting information and
obtain better contextual representations for the multi-hop QA task. Inspired by
the iterative document selection process and the progressive learning custom of
humans, FE2H divides both the document selector and reader into two stages
following an easy-to-hard manner. Specifically, we first select the document
most relevant to the question and then utilize the question together with this
document to select other pertinent documents. As for the QA phase, our reader
is first trained on a single-hop QA dataset and then transferred into the
multi-hop QA task. We comprehensively evaluate our model on the popular
multi-hop QA benchmark HotpotQA. Experimental results demonstrate that our
method ourperforms all other methods in the leaderboard of HotpotQA (distractor
setting)."
Eliciting Best Practices for Collaboration with Computational Notebooks,0.0658785,"Despite the widespread adoption of computational notebooks, little is known
about best practices for their usage in collaborative contexts. In this paper,
we fill this gap by eliciting a catalog of best practices for collaborative
data science with computational notebooks. With this aim, we first look for
best practices through a multivocal literature review. Then, we conduct
interviews with professional data scientists to assess their awareness of these
best practices. Finally, we assess the adoption of best practices through the
analysis of 1,380 Jupyter notebooks retrieved from the Kaggle platform.
Findings reveal that experts are mostly aware of the best practices and tend to
adopt them in their daily work. Nonetheless, they do not consistently follow
all the recommendations as, depending on specific contexts, some are deemed
unfeasible or counterproductive due to the lack of proper tool support. As
such, we envision the design of notebook solutions that allow data scientists
not to have to prioritize exploration and rapid prototyping over writing code
of quality."
Mix and Localize: Localizing Sound Sources in Mixtures,0.454825,"We present a method for simultaneously localizing multiple sound sources
within a visual scene. This task requires a model to both group a sound mixture
into individual sources, and to associate them with a visual signal. Our method
jointly solves both tasks at once, using a formulation inspired by the
contrastive random walk of Jabri et al. We create a graph in which images and
separated sounds correspond to nodes, and train a random walker to transition
between nodes from different modalities with high return probability. The
transition probabilities for this walk are determined by an audio-visual
similarity metric that is learned by our model. We show through experiments
with musical instruments and human speech that our model can successfully
localize multiple sounds, outperforming other self-supervised methods. Project
site: https://hxixixh.github.io/mix-and-localize"
Normalizing Flows for Human Pose Anomaly Detection,0.19621,"Video anomaly detection is an ill-posed problem because it relies on many
parameters such as appearance, pose, camera angle, background, and more. We
distill the problem to anomaly detection of human pose, thus decreasing the
risk of nuisance parameters such as appearance affecting the result. Focusing
on pose alone also has the side benefit of reducing bias against distinct
minority groups. Our model works directly on human pose graph sequences and is
exceptionally lightweight (~1K parameters), capable of running on any machine
able to run the pose estimation with negligible additional resources. We
leverage the highly compact pose representation in a normalizing flows
framework, which we extend to tackle the unique characteristics of
spatio-temporal pose data and show its advantages in this use case. The
algorithm is quite general and can handle training data of only normal examples
as well as a supervised setting that consists of labeled normal and abnormal
examples. We report state-of-the-art results on two anomaly detection
benchmarks - the unsupervised ShanghaiTech dataset and the recent supervised
UBnormal dataset."
YOLO and Mask R-CNN for Vehicle Number Plate Identification,0.209749,"License plate scanners have grown in popularity in parking lots during the
past few years. In order to quickly identify license plates, traditional plate
recognition devices used in parking lots employ a fixed source of light and
shooting angles. For skewed angles, such as license plate images taken with
ultra-wide angle or fisheye lenses, deformation of the license plate
recognition plate can also be quite severe, impairing the ability of standard
license plate recognition systems to identify the plate. Mask RCNN gadget that
may be utilised for oblique pictures and various shooting angles. The results
of the experiments show that the suggested design will be capable of
classifying license plates with bevel angles larger than 0/60. Character
recognition using the suggested Mask R-CNN approach has advanced significantly
as well. The proposed Mask R-CNN method has also achieved significant progress
in character recognition, which is tilted more than 45 degrees as compared to
the strategy of employing the YOLOv2 model. Experiment results also suggest
that the methodology presented in the open data plate collecting is better than
other techniques (known as the AOLP dataset)."
Large-Field Contextual Feature Learning for Glass Detection,0.078477,"Glass is very common in our daily life. Existing computer vision systems
neglect it and thus may have severe consequences, e.g., a robot may crash into
a glass wall. However, sensing the presence of glass is not straightforward.
The key challenge is that arbitrary objects/scenes can appear behind the glass.
In this paper, we propose an important problem of detecting glass surfaces from
a single RGB image. To address this problem, we construct the first large-scale
glass detection dataset (GDD) and propose a novel glass detection network,
called GDNet-B, which explores abundant contextual cues in a large
field-of-view via a novel large-field contextual feature integration (LCFI)
module and integrates both high-level and low-level boundary features with a
boundary feature enhancement (BFE) module. Extensive experiments demonstrate
that our GDNet-B achieves satisfying glass detection results on the images
within and beyond the GDD testing set. We further validate the effectiveness
and generalization capability of our proposed GDNet-B by applying it to other
vision tasks, including mirror segmentation and salient object detection.
Finally, we show the potential applications of glass detection and discuss
possible future research directions."
Annotating Norwegian Language Varieties on Twitter for Part-of-Speech,0.111534,"Norwegian Twitter data poses an interesting challenge for Natural Language
Processing (NLP) tasks. These texts are difficult for models trained on
standardized text in one of the two Norwegian written forms (Bokm{\aa}l and
Nynorsk), as they contain both the typical variation of social media text, as
well as a large amount of dialectal variety. In this paper we present a novel
Norwegian Twitter dataset annotated with POS-tags. We show that models trained
on Universal Dependency (UD) data perform worse when evaluated against this
dataset, and that models trained on Bokm{\aa}l generally perform better than
those trained on Nynorsk. We also see that performance on dialectal tweets is
comparable to the written standards for some models. Finally we perform a
detailed analysis of the errors that models commonly make on this data."
MMNet: Muscle motion-guided network for micro-expression recognition,0.232883,"Facial micro-expressions (MEs) are involuntary facial motions revealing
peoples real feelings and play an important role in the early intervention of
mental illness, the national security, and many human-computer interaction
systems. However, existing micro-expression datasets are limited and usually
pose some challenges for training good classifiers. To model the subtle facial
muscle motions, we propose a robust micro-expression recognition (MER)
framework, namely muscle motion-guided network (MMNet). Specifically, a
continuous attention (CA) block is introduced to focus on modeling local subtle
muscle motion patterns with little identity information, which is different
from most previous methods that directly extract features from complete video
frames with much identity information. Besides, we design a position
calibration (PC) module based on the vision transformer. By adding the position
embeddings of the face generated by PC module at the end of the two branches,
the PC module can help to add position information to facial muscle motion
pattern features for the MER. Extensive experiments on three public
micro-expression datasets demonstrate that our approach outperforms
state-of-the-art methods by a large margin."
Revisiting DocRED -- Addressing the False Negative Problem in Relation Extraction,0.185315,"The DocRED dataset is one of the most popular and widely used benchmarks for
document-level relation extraction (RE). It adopts a recommend-revise
annotation scheme so as to have a large-scale annotated dataset. However, we
find that the annotation of DocRED is incomplete, i.e., false negative samples
are prevalent. We analyze the causes and effects of the overwhelming false
negative problem in the DocRED dataset. To address the shortcoming, we
re-annotate 4,053 documents in the DocRED dataset by adding the missed relation
triples back to the original DocRED. We name our revised DocRED dataset
Re-DocRED. We conduct extensive experiments with state-of-the-art neural models
on both datasets, and the experimental results show that the models trained and
evaluated on our Re-DocRED achieve performance improvements of around 13 F1
points. Moreover, we conduct a comprehensive analysis to identify the potential
areas for further improvement. Our dataset is publicly available at
https://github.com/tonytan48/Re-DocRED."
A Distributional Lens for Multi-Aspect Controllable Text Generation,0.498208,"Multi-aspect controllable text generation is a more challenging and practical
task than single-aspect control. Existing methods achieve complex multi-aspect
control by fusing multiple controllers learned from single-aspect, but suffer
from attribute degeneration caused by the mutual interference of these
controllers. To address this, we provide observations on attribute fusion from
a distributional perspective and propose to directly search for the
intersection areas of multiple attribute distributions as their combination for
generation. Our method first estimates the attribute space with an autoencoder
structure. Afterward, we iteratively approach the intersections by jointly
minimizing distances to points representing different attributes. Finally, we
map them to attribute-relevant sentences with a prefix-tuning-based decoder.
Experiments on the three-aspect control task, including sentiment, topic, and
detoxification aspects, reveal that our method outperforms several strong
baselines on attribute relevance and text quality and achieves the SOTA.
Further analysis also supplies some explanatory support for the effectiveness
of our approach."
MIRROR: Differentiable Deep Social Projection for Assistive Human-Robot Communication,0.231766,"Communication is a hallmark of intelligence. In this work, we present MIRROR,
an approach to (i) quickly learn human models from human demonstrations, and
(ii) use the models for subsequent communication planning in assistive
shared-control settings. MIRROR is inspired by social projection theory, which
hypothesizes that humans use self-models to understand others. Likewise, MIRROR
leverages self-models learned using reinforcement learning to bootstrap human
modeling. Experiments with simulated humans show that this approach leads to
rapid learning and more robust models compared to existing behavioral cloning
and state-of-the-art imitation learning methods. We also present a
human-subject study using the CARLA simulator which shows that (i) MIRROR is
able to scale to complex domains with high-dimensional observations and
complicated world physics and (ii) provides effective assistive communication
that enabled participants to drive more safely in adverse weather conditions."
Massively Digitized Power Grid: Opportunities and Challenges of Use-inspired AI,0.0474731,"This article presents a use-inspired perspective of the opportunities and
challenges in a massively digitized power grid. It argues that the intricate
interplay of data availability, computing capability, and artificial
intelligence (AI) algorithm development are the three key factors driving the
adoption of digitized solutions in the power grid. The impact of these three
factors on critical functions of power system operation and planning practices
are reviewed and illustrated with industrial practice case studies. Open
challenges and research opportunities for data, computing, and AI algorithms
are articulated within the context of the power industry's tremendous
decarbonization efforts."
Boundary-Guided Camouflaged Object Detection,0.356937,"Camouflaged object detection (COD), segmenting objects that are elegantly
blended into their surroundings, is a valuable yet challenging task. Existing
deep-learning methods often fall into the difficulty of accurately identifying
the camouflaged object with complete and fine object structure. To this end, in
this paper, we propose a novel boundary-guided network (BGNet) for camouflaged
object detection. Our method explores valuable and extra object-related edge
semantics to guide representation learning of COD, which forces the model to
generate features that highlight object structure, thereby promoting
camouflaged object detection of accurate boundary localization. Extensive
experiments on three challenging benchmark datasets demonstrate that our BGNet
significantly outperforms the existing 18 state-of-the-art methods under four
widely-used evaluation metrics. Our code is publicly available at:
https://github.com/thograce/BGNet."
Hero-Gang Neural Model For Named Entity Recognition,0.0435158,"Named entity recognition (NER) is a fundamental and important task in NLP,
aiming at identifying named entities (NEs) from free text. Recently, since the
multi-head attention mechanism applied in the Transformer model can effectively
capture longer contextual information, Transformer-based models have become the
mainstream methods and have achieved significant performance in this task.
Unfortunately, although these models can capture effective global context
information, they are still limited in the local feature and position
information extraction, which is critical in NER. In this paper, to address
this limitation, we propose a novel Hero-Gang Neural structure (HGN), including
the Hero and Gang module, to leverage both global and local information to
promote NER. Specifically, the Hero module is composed of a Transformer-based
encoder to maintain the advantage of the self-attention mechanism, and the Gang
module utilizes a multi-window recurrent module to extract local features and
position information under the guidance of the Hero module. Afterward, the
proposed multi-window attention effectively combines global information and
multiple local features for predicting entity labels. Experimental results on
several benchmark datasets demonstrate the effectiveness of our proposed model."
The Alberta Plan for AI Research,0.159051,"Herein we describe our approach to artificial intelligence research, which we
call the Alberta Plan. The Alberta Plan is pursued within our research groups
in Alberta and by others who are like minded throughout the world. We welcome
all who would join us in this pursuit."
Predicting Future Occupancy Grids in Dynamic Environment with Spatio-Temporal Learning,0.0917861,"Reliably predicting future occupancy of highly dynamic urban environments is
an important precursor for safe autonomous navigation. Common challenges in the
prediction include forecasting the relative position of other vehicles,
modelling the dynamics of vehicles subjected to different traffic conditions,
and vanishing surrounding objects. To tackle these challenges, we propose a
spatio-temporal prediction network pipeline that takes the past information
from the environment and semantic labels separately for generating future
occupancy predictions. Compared to the current SOTA, our approach predicts
occupancy for a longer horizon of 3 seconds and in a relatively complex
environment from the nuScenes dataset. Our experimental results demonstrate the
ability of spatio-temporal networks to understand scene dynamics without the
need for HD-Maps and explicit modeling dynamic objects. We publicly release our
occupancy grid dataset based on nuScenes to support further research."
Prompt-Based Metric Learning for Few-Shot NER,0.130367,"Few-shot named entity recognition (NER) targets generalizing to unseen labels
and/or domains with few labeled examples. Existing metric learning methods
compute token-level similarities between query and support sets, but are not
able to fully incorporate label semantics into modeling. To address this issue,
we propose a simple method to largely improve metric learning for NER: 1)
multiple prompt schemas are designed to enhance label semantics; 2) we propose
a novel architecture to effectively combine multiple prompt-based
representations. Empirically, our method achieves new state-of-the-art (SOTA)
results under 16 of the 18 considered settings, substantially outperforming the
previous SOTA by an average of 8.84% and a maximum of 34.51% in relative gains
of micro F1. Our code is available at https://github.com/AChen-qaq/ProML."
Object Level Depth Reconstruction for Category Level 6D Object Pose Estimation From Monocular RGB Image,0.113915,"Recently, RGBD-based category-level 6D object pose estimation has achieved
promising improvement in performance, however, the requirement of depth
information prohibits broader applications. In order to relieve this problem,
this paper proposes a novel approach named Object Level Depth reconstruction
Network (OLD-Net) taking only RGB images as input for category-level 6D object
pose estimation. We propose to directly predict object-level depth from a
monocular RGB image by deforming the category-level shape prior into
object-level depth and the canonical NOCS representation. Two novel modules
named Normalized Global Position Hints (NGPH) and Shape-aware Decoupled Depth
Reconstruction (SDDR) module are introduced to learn high fidelity object-level
depth and delicate shape representations. At last, the 6D object pose is solved
by aligning the predicted canonical representation with the back-projected
object-level depth. Extensive experiments on the challenging CAMERA25 and
REAL275 datasets indicate that our model, though simple, achieves
state-of-the-art performance."
MicroBERT: Effective Training of Low-resource Monolingual BERTs through Parameter Reduction and Multitask Learning,0.0541301,"Transformer language models (TLMs) are critical for most NLP tasks, but they
are difficult to create for low-resource languages because of how much
pretraining data they require. In this work, we investigate two techniques for
training monolingual TLMs in a low-resource setting: greatly reducing TLM size,
and complementing the masked language modeling objective with two
linguistically rich supervised tasks (part-of-speech tagging and dependency
parsing). Results from 7 diverse languages indicate that our model, MicroBERT,
is able to produce marked improvements in downstream task evaluations relative
to a typical monolingual TLM pretraining approach. Specifically, we find that
monolingual MicroBERT models achieve gains of up to 18% for parser LAS and 11%
for NER F1 compared to a multilingual baseline, mBERT, while having less than
1% of its parameter count. We conclude reducing TLM parameter count and using
labeled data for pretraining low-resource TLMs can yield large quality benefits
and in some cases produce models that outperform multilingual approaches."
Unsupervised Face Morphing Attack Detection via Self-paced Anomaly Detection,0.366079,"The supervised-learning-based morphing attack detection (MAD) solutions
achieve outstanding success in dealing with attacks from known morphing
techniques and known data sources. However, given variations in the morphing
attacks, the performance of supervised MAD solutions drops significantly due to
the insufficient diversity and quantity of the existing MAD datasets. To
address this concern, we propose a completely unsupervised MAD solution via
self-paced anomaly detection (SPL-MAD) by leveraging the existing large-scale
face recognition (FR) datasets and the unsupervised nature of convolutional
autoencoders. Using general FR datasets that might contain unintentionally and
unlabeled manipulated samples to train an autoencoder can lead to a diverse
reconstruction behavior of attack and bona fide samples. We analyze this
behavior empirically to provide a solid theoretical ground for designing our
unsupervised MAD solution. This also results in proposing to integrate our
adapted modified self-paced learning paradigm to enhance the reconstruction
error separability between the bona fide and attack samples in a completely
unsupervised manner. Our experimental results on a diverse set of MAD
evaluation datasets show that the proposed unsupervised SPL-MAD solution
outperforms the overall performance of a wide range of supervised MAD solutions
and provides higher generalizability on unknown attacks."
Type-aware Embeddings for Multi-Hop Reasoning over Knowledge Graphs,0.659135,"Multi-hop reasoning over real-life knowledge graphs (KGs) is a highly
challenging problem as traditional subgraph matching methods are not capable to
deal with noise and missing information. To address this problem, it has been
recently introduced a promising approach based on jointly embedding logical
queries and KGs into a low-dimensional space to identify answer entities.
However, existing proposals ignore critical semantic knowledge inherently
available in KGs, such as type information. To leverage type information, we
propose a novel TypE-aware Message Passing (TEMP) model, which enhances the
entity and relation representations in queries, and simultaneously improves
generalization, deductive and inductive reasoning. Remarkably, TEMP is a
plug-and-play model that can be easily incorporated into existing
embedding-based models to improve their performance. Extensive experiments on
three real-world datasets demonstrate TEMP's effectiveness."
CLIP-Art: Contrastive Pre-training for Fine-Grained Art Classification,0.532568,"Existing computer vision research in artwork struggles with artwork's
fine-grained attributes recognition and lack of curated annotated datasets due
to their costly creation. To the best of our knowledge, we are one of the first
methods to use CLIP (Contrastive Language-Image Pre-Training) to train a neural
network on a variety of artwork images and text descriptions pairs. CLIP is
able to learn directly from free-form art descriptions, or, if available,
curated fine-grained labels. Model's zero-shot capability allows predicting
accurate natural language description for a given image, without directly
optimizing for the task. Our approach aims to solve 2 challenges: instance
retrieval and fine-grained artwork attribute recognition. We use the iMet
Dataset, which we consider the largest annotated artwork dataset. In this
benchmark we achieved competitive results using only self-supervision."
Hyperbolic Image Segmentation,0.127573,"For image segmentation, the current standard is to perform pixel-level
optimization and inference in Euclidean output embedding spaces through linear
hyperplanes. In this work, we show that hyperbolic manifolds provide a valuable
alternative for image segmentation and propose a tractable formulation of
hierarchical pixel-level classification in hyperbolic space. Hyperbolic Image
Segmentation opens up new possibilities and practical benefits for
segmentation, such as uncertainty estimation and boundary information for free,
zero-label generalization, and increased performance in low-dimensional output
embeddings."
Local Sliced-Wasserstein Feature Sets for Illumination-invariant Face Recognition,0.120969,"We present a new method for face recognition from digital images acquired
under varying illumination conditions. The method is based on mathematical
modeling of local gradient distributions using the Radon Cumulative
Distribution Transform (R-CDT). We demonstrate that lighting variations cause
certain types of deformations of local image gradient distributions which, when
expressed in R-CDT domain, can be modeled as a subspace. Face recognition is
then performed using a nearest subspace in R-CDT domain of local gradient
distributions. Experiment results demonstrate the proposed method outperforms
other alternatives in several face recognition tasks with challenging
illumination conditions. Python code implementing the proposed method is
available, which is integrated as a part of the software package PyTransKit."
Dynamic Dialogue Policy for Continual Reinforcement Learning,0.0255129,"Continual learning is one of the key components of human learning and a
necessary requirement of artificial intelligence. As dialogue can potentially
span infinitely many topics and tasks, a task-oriented dialogue system must
have the capability to continually learn, dynamically adapting to new
challenges while preserving the knowledge it already acquired. Despite the
importance, continual reinforcement learning of the dialogue policy has
remained largely unaddressed. The lack of a framework with training protocols,
baseline models and suitable metrics, has so far hindered research in this
direction. In this work we fill precisely this gap, enabling research in
dialogue policy optimisation to go from static to dynamic learning. We provide
a continual learning algorithm, baseline architectures and metrics for
assessing continual learning models. Moreover, we propose the dynamic dialogue
policy transformer (DDPT), a novel dynamic architecture that can integrate new
knowledge seamlessly, is capable of handling large state spaces and obtains
significant zero-shot performance when being exposed to unseen domains, without
any growth in network parameter size."
Heterogeneous-Agent Mirror Learning: A Continuum of Solutions to Cooperative MARL,0.314076,"The necessity for cooperation among intelligent machines has popularised
cooperative multi-agent reinforcement learning (MARL) in the artificial
intelligence (AI) research community. However, many research endeavors have
been focused on developing practical MARL algorithms whose effectiveness has
been studied only empirically, thereby lacking theoretical guarantees. As
recent studies have revealed, MARL methods often achieve performance that is
unstable in terms of reward monotonicity or suboptimal at convergence. To
resolve these issues, in this paper, we introduce a novel framework named
Heterogeneous-Agent Mirror Learning (HAML) that provides a general template for
MARL algorithmic designs. We prove that algorithms derived from the HAML
template satisfy the desired properties of the monotonic improvement of the
joint reward and the convergence to Nash equilibrium. We verify the
practicality of HAML by proving that the current state-of-the-art cooperative
MARL algorithms, HATRPO and HAPPO, are in fact HAML instances. Next, as a
natural outcome of our theory, we propose HAML extensions of two well-known RL
algorithms, HAA2C (for A2C) and HADDPG (for DDPG), and demonstrate their
effectiveness against strong baselines on StarCraftII and Multi-Agent MuJoCo
tasks."
Crosslingual Generalization through Multitask Finetuning,0.772832,"Multitask prompted finetuning (MTF) has been shown to help large language
models generalize to new tasks in a zero-shot setting, but so far explorations
of MTF have focused on English data and models. We apply MTF to the pretrained
multilingual BLOOM and mT5 model families to produce finetuned variants called
BLOOMZ and mT0. We find finetuning large multilingual language models on
English tasks with English prompts allows for task generalization to
non-English languages that appear only in the pretraining corpus. Finetuning on
multilingual tasks with English prompts further improves performance on English
and non-English tasks leading to various state-of-the-art zero-shot results. We
also investigate finetuning on multilingual tasks with prompts that have been
machine-translated from English to match the language of each dataset. We find
training on these machine-translated prompts leads to better performance on
human-written prompts in the respective languages. Surprisingly, we find models
are capable of zero-shot generalization to tasks in languages they have never
intentionally seen. We conjecture that the models are learning higher-level
capabilities that are both task- and language-agnostic. In addition, we
introduce xP3, a composite of supervised datasets in 46 languages with English
and machine-translated prompts. Our code, datasets and models are freely
available at https://github.com/bigscience-workshop/xmtf."
ContraReg: Contrastive Learning of Multi-modality Unsupervised Deformable Image Registration,0.137185,"Establishing voxelwise semantic correspondence across distinct imaging
modalities is a foundational yet formidable computer vision task. Current
multi-modality registration techniques maximize hand-crafted inter-domain
similarity functions, are limited in modeling nonlinear intensity-relationships
and deformations, and may require significant re-engineering or underperform on
new tasks, datasets, and domain pairs. This work presents ContraReg, an
unsupervised contrastive representation learning approach to multi-modality
deformable registration. By projecting learned multi-scale local patch features
onto a jointly learned inter-domain embedding space, ContraReg obtains
representations useful for non-rigid multi-modality alignment. Experimentally,
ContraReg achieves accurate and robust results with smooth and invertible
deformations across a series of baselines and ablations on a neonatal T1-T2
brain MRI registration task with all methods validated over a wide range of
deformation regularization strengths."
Motron: Multimodal Probabilistic Human Motion Forecasting,0.625971,"Autonomous systems and humans are increasingly sharing the same space. Robots
work side by side or even hand in hand with humans to balance each other's
limitations. Such cooperative interactions are ever more sophisticated. Thus,
the ability to reason not just about a human's center of gravity position, but
also its granular motion is an important prerequisite for human-robot
interaction. Though, many algorithms ignore the multimodal nature of humans or
neglect uncertainty in their motion forecasts. We present Motron, a multimodal,
probabilistic, graph-structured model, that captures human's multimodality
using probabilistic methods while being able to output deterministic
maximum-likelihood motions and corresponding confidence values for each mode.
Our model aims to be tightly integrated with the robotic
planning-control-interaction loop; outputting physically feasible human motions
and being computationally efficient. We demonstrate the performance of our
model on several challenging real-world motion forecasting datasets,
outperforming a wide array of generative/variational methods while providing
state-of-the-art single-output motions if required. Both using significantly
less computational power than state-of-the art algorithms."
Beyond English-Centric Bitexts for Better Multilingual Language Representation Learning,0.133165,"In this paper, we elaborate upon recipes for building multilingual
representation models that are not only competitive with existing
state-of-the-art models but are also more parameter efficient, thereby
promoting better adoption in resource-constrained scenarios and practical
applications. We show that going beyond English-centric bitexts, coupled with a
novel sampling strategy aimed at reducing under-utilization of training data,
substantially boosts performance across model sizes for both Electra and MLM
pre-training objectives. We introduce XY-LENT: X-Y bitext enhanced Language
ENcodings using Transformers which not only achieves state-of-the-art
performance over 5 cross-lingual tasks within all model size bands, is also
competitive across bands. Our XY-LENT XL variant outperforms XLM-RXXL and
exhibits competitive performance with mT5 XXL while being 5x and 6x smaller
respectively. We then show that our proposed method helps ameliorate the curse
of multilinguality, with the XY-LENT XL achieving 99.3% GLUE performance and
98.5% SQuAD 2.0 performance compared to a SoTA English only model in the same
size band. We then analyze our models performance on extremely low resource
languages and posit that scaling alone may not be sufficient for improving the
performance in this scenario"
YOLO-FaceV2: A Scale and Occlusion Aware Face Detector,0.153585,"In recent years, face detection algorithms based on deep learning have made
great progress. These algorithms can be generally divided into two categories,
i.e. two-stage detector like Faster R-CNN and one-stage detector like YOLO.
Because of the better balance between accuracy and speed, one-stage detectors
have been widely used in many applications. In this paper, we propose a
real-time face detector based on the one-stage detector YOLOv5, named
YOLO-FaceV2. We design a Receptive Field Enhancement module called RFE to
enhance receptive field of small face, and use NWD Loss to make up for the
sensitivity of IoU to the location deviation of tiny objects. For face
occlusion, we present an attention module named SEAM and introduce Repulsion
Loss to solve it. Moreover, we use a weight function Slide to solve the
imbalance between easy and hard samples and use the information of the
effective receptive field to design the anchor. The experimental results on
WiderFace dataset show that our face detector outperforms YOLO and its variants
can be find in all easy, medium and hard subsets. Source code in
https://github.com/Krasjet-Yu/YOLO-FaceV2"
Keys to Better Image Inpainting: Structure and Texture Go Hand in Hand,0.131838,"Deep image inpainting has made impressive progress with recent advances in
image generation and processing algorithms. We claim that the performance of
inpainting algorithms can be better judged by the generated structures and
textures. Structures refer to the generated object boundary or novel geometric
structures within the hole, while texture refers to high-frequency details,
especially man-made repeating patterns filled inside the structural regions. We
believe that better structures are usually obtained from a coarse-to-fine
GAN-based generator network while repeating patterns nowadays can be better
modeled using state-of-the-art high-frequency fast fourier convolutional
layers. In this paper, we propose a novel inpainting network combining the
advantages of the two designs. Therefore, our model achieves a remarkable
visual quality to match state-of-the-art performance in both structure
generation and repeating texture synthesis using a single network. Extensive
experiments demonstrate the effectiveness of the method, and our conclusions
further highlight the two critical factors of image inpainting quality,
structures, and textures, as the future design directions of inpainting
networks."
The Topological BERT: Transforming Attention into Topology for Natural Language Processing,0.086162,"In recent years, the introduction of the Transformer models sparked a
revolution in natural language processing (NLP). BERT was one of the first text
encoders using only the attention mechanism without any recurrent parts to
achieve state-of-the-art results on many NLP tasks.
  This paper introduces a text classifier using topological data analysis. We
use BERT's attention maps transformed into attention graphs as the only input
to that classifier. The model can solve tasks such as distinguishing spam from
ham messages, recognizing whether a sentence is grammatically correct, or
evaluating a movie review as negative or positive. It performs comparably to
the BERT baseline and outperforms it on some tasks.
  Additionally, we propose a new method to reduce the number of BERT's
attention heads considered by the topological classifier, which allows us to
prune the number of heads from 144 down to as few as ten with no reduction in
performance. Our work also shows that the topological model displays higher
robustness against adversarial attacks than the original BERT model, which is
maintained during the pruning process. To the best of our knowledge, this work
is the first to confront topological-based models with adversarial attacks in
the context of NLP."
Effective and Efficient Training for Sequential Recommendation using Recency Sampling,0.0318045,"Many modern sequential recommender systems use deep neural networks, which
can effectively estimate the relevance of items but require a lot of time to
train. Slow training increases expenses, hinders product development timescales
and prevents the model from being regularly updated to adapt to changing user
preferences. Training such sequential models involves appropriately sampling
past user interactions to create a realistic training objective. The existing
training objectives have limitations. For instance, next item prediction never
uses the beginning of the sequence as a learning target, thereby potentially
discarding valuable data. On the other hand, the item masking used by BERT4Rec
is only weakly related to the goal of the sequential recommendation; therefore,
it requires much more time to obtain an effective model. Hence, we propose a
novel Recency-based Sampling of Sequences training objective that addresses
both limitations. We apply our method to various recent and state-of-the-art
model architectures - such as GRU4Rec, Caser, and SASRec. We show that the
models enhanced with our method can achieve performances exceeding or very
close to stateof-the-art BERT4Rec, but with much less training time."
Gold Doesn't Always Glitter: Spectral Removal of Linear and Nonlinear Guarded Attribute Information,0.158954,"We describe a simple and effective method (Spectral Attribute removaL; SAL)
to remove private or guarded information from neural representations. Our
method uses matrix decomposition to project the input representations into
directions with reduced covariance with the guarded information rather than
maximal covariance as factorization methods normally use. We begin with linear
information removal and proceed to generalize our algorithm to the case of
nonlinear information removal using kernels. Our experiments demonstrate that
our algorithm retains better main task performance after removing the guarded
information compared to previous work. In addition, our experiments demonstrate
that we need a relatively small amount of guarded attribute data to remove
information about these attributes, which lowers the exposure to sensitive data
and is more suitable for low-resource scenarios. Code is available at
https://github.com/jasonshaoshun/SAL."
A Multimodal Corpus for Emotion Recognition in Sarcasm,0.0951924,"While sentiment and emotion analysis have been studied extensively, the
relationship between sarcasm and emotion has largely remained unexplored. A
sarcastic expression may have a variety of underlying emotions. For example, ""I
love being ignored"" belies sadness, while ""my mobile is fabulous with a battery
backup of only 15 minutes!"" expresses frustration. Detecting the emotion behind
a sarcastic expression is non-trivial yet an important task. We undertake the
task of detecting the emotion in a sarcastic statement, which to the best of
our knowledge, is hitherto unexplored. We start with the recently released
multimodal sarcasm detection dataset (MUStARD) pre-annotated with 9 emotions.
We identify and correct 343 incorrect emotion labels (out of 690). We double
the size of the dataset, label it with emotions along with valence and arousal
which are important indicators of emotional intensity. Finally, we label each
sarcastic utterance with one of the four sarcasm types-Propositional, Embedded,
Likeprefixed and Illocutionary, with the goal of advancing sarcasm detection
research. Exhaustive experimentation with multimodal (text, audio, and video)
fusion models establishes a benchmark for exact emotion recognition in sarcasm
and outperforms the state-of-art sarcasm detection. We release the dataset
enriched with various annotations and the code for research purposes:
https://github.com/apoorva-nunna/MUStARD_Plus_Plus"
Learning to Walk by Steering: Perceptive Quadrupedal Locomotion in Dynamic Environments,0.142304,"We tackle the problem of perceptive locomotion in dynamic environments. In
this problem, a quadrupedal robot must exhibit robust and agile walking
behaviors in response to environmental clutter and moving obstacles. We present
a hierarchical learning framework, named PRELUDE, which decomposes the problem
of perceptive locomotion into high-level decision-making to predict navigation
commands and low-level gait generation to realize the target commands. In this
framework, we train the high-level navigation controller with imitation
learning on human demonstrations collected on a steerable cart and the
low-level gait controller with reinforcement learning (RL). Therefore, our
method can acquire complex navigation behaviors from human supervision and
discover versatile gaits from trial and error. We demonstrate the effectiveness
of our approach in simulation and with hardware experiments. Videos and code
can be found at the project page: https://ut-austin-rpl.github.io/PRELUDE."
AI-based Malware and Ransomware Detection Models,0.183894,"Cybercrime is one of the major digital threats of this century. In
particular, ransomware attacks have significantly increased, resulting in
global damage costs of tens of billion dollars. In this paper, we train and
test different Machine Learning and Deep Learning models for malware detection,
malware classification and ransomware detection. We introduce a novel and
flexible solution that combines two optimized models for malware and ransomware
detection. Our results demonstrate some improvements both in terms of detection
performances and flexibility. In particular, our combined models pave the way
for easier future enhancements using specialized and thus interchangeable
detection modules."
Nonparametric Masked Language Modeling,0.351153,"Existing language models (LMs) predict tokens with a softmax over a finite
vocabulary, which can make it difficult to predict rare tokens or phrases. We
introduce NPM, the first nonparametric masked language model that replaces this
softmax with a nonparametric distribution over every phrase in a reference
corpus. NPM fills in the [MASK] solely from retrieving a token from a text
corpus. We show that NPM can be efficiently trained with a contrastive
objective and an in-batch approximation to full corpus retrieval. Zero-shot
evaluation on 16 tasks including classification, fact probing and question
answering demonstrates that NPM outperforms significantly larger parametric
models, either with or without a retrieve-and-generate approach. It is
particularly better at dealing with rare patterns (word senses or facts) and
predicting rare or nearly unseen words (e.g., non-Latin script). We release the
model and code at github.com/facebookresearch/NPM."
Creativity in translation: machine translation as a constraint for literary texts,0.374209,"This article presents the results of a study involving the translation of a
short story by Kurt Vonnegut from English to Catalan and Dutch using three
modalities: machine-translation (MT), post-editing (PE) and translation without
aid (HT). Our aim is to explore creativity, understood to involve novelty and
acceptability, from a quantitative perspective. The results show that HT has
the highest creativity score, followed by PE, and lastly, MT, and this is
unanimous from all reviewers. A neural MT system trained on literary data does
not currently have the necessary capabilities for a creative translation; it
renders literal solutions to translation problems. More importantly, using MT
to post-edit raw output constrains the creativity of translators, resulting in
a poorer translation often not fit for publication, according to experts."
Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models,0.282364,"Pre-trained language models (LMs) are shown to easily generate toxic
language. In this work, we systematically explore domain-adaptive training to
reduce the toxicity of language models. We conduct this study on three
dimensions: training corpus, model size, and parameter efficiency. For the
training corpus, we propose to leverage the generative power of LMs and
generate nontoxic datasets for domain-adaptive training, which mitigates the
exposure bias and is shown to be more data-efficient than using a curated
pre-training corpus. We demonstrate that the self-generation method
consistently outperforms the existing baselines across various model sizes on
both automatic and human evaluations, even when it uses a 1/3 smaller training
corpus. We then comprehensively study detoxifying LMs with parameter sizes
ranging from 126M up to 530B (3x larger than GPT-3), a scale that has never
been studied before. We find that i) large LMs have similar toxicity levels as
smaller ones given the same pre-training corpus, and ii) large LMs require more
endeavor to detoxify. We also explore parameter-efficient training methods for
detoxification. We demonstrate that adding and training adapter-only layers in
LMs not only saves a lot of parameters but also achieves a better trade-off
between toxicity and perplexity than whole model adaptation for the large-scale
models."
TAPE: Task-Agnostic Prior Embedding for Image Restoration,0.234432,"Learning a generalized prior for natural image restoration is an important
yet challenging task. Early methods mostly involved handcrafted priors
including normalized sparsity, l_0 gradients, dark channel priors, etc.
Recently, deep neural networks have been used to learn various image priors but
do not guarantee to generalize. In this paper, we propose a novel approach that
embeds a task-agnostic prior into a transformer. Our approach, named
Task-Agnostic Prior Embedding (TAPE), consists of two stages, namely,
task-agnostic pre-training and task-specific fine-tuning, where the first stage
embeds prior knowledge about natural images into the transformer and the second
stage extracts the knowledge to assist downstream image restoration.
Experiments on various types of degradation validate the effectiveness of TAPE.
The image restoration performance in terms of PSNR is improved by as much as
1.45dB and even outperforms task-specific algorithms. More importantly, TAPE
shows the ability of disentangling generalized image priors from degraded
images, which enjoys favorable transfer ability to unknown downstream tasks."
BSRT: Improving Burst Super-Resolution with Swin Transformer and Flow-Guided Deformable Alignment,0.778042,"This work addresses the Burst Super-Resolution (BurstSR) task using a new
architecture, which requires restoring a high-quality image from a sequence of
noisy, misaligned, and low-resolution RAW bursts. To overcome the challenges in
BurstSR, we propose a Burst Super-Resolution Transformer (BSRT), which can
significantly improve the capability of extracting inter-frame information and
reconstruction. To achieve this goal, we propose a Pyramid Flow-Guided
Deformable Convolution Network (Pyramid FG-DCN) and incorporate Swin
Transformer Blocks and Groups as our main backbone. More specifically, we
combine optical flows and deformable convolutions, hence our BSRT can handle
misalignment and aggregate the potential texture information in multi-frames
more efficiently. In addition, our Transformer-based structure can capture
long-range dependency to further improve the performance. The evaluation on
both synthetic and real-world tracks demonstrates that our approach achieves a
new state-of-the-art in BurstSR task. Further, our BSRT wins the championship
in the NTIRE2022 Burst Super-Resolution Challenge."
Penalized Proximal Policy Optimization for Safe Reinforcement Learning,0.628747,"Safe reinforcement learning aims to learn the optimal policy while satisfying
safety constraints, which is essential in real-world applications. However,
current algorithms still struggle for efficient policy updates with hard
constraint satisfaction. In this paper, we propose Penalized Proximal Policy
Optimization (P3O), which solves the cumbersome constrained policy iteration
via a single minimization of an equivalent unconstrained problem. Specifically,
P3O utilizes a simple-yet-effective penalty function to eliminate cost
constraints and removes the trust-region constraint by the clipped surrogate
objective. We theoretically prove the exactness of the proposed method with a
finite penalty factor and provide a worst-case analysis for approximate error
when evaluated on sample trajectories. Moreover, we extend P3O to more
challenging multi-constraint and multi-agent scenarios which are less studied
in previous work. Extensive experiments show that P3O outperforms
state-of-the-art algorithms with respect to both reward improvement and
constraint satisfaction on a set of constrained locomotive tasks."
Token-level Sequence Labeling for Spoken Language Understanding using Compositional End-to-End Models,0.0705356,"End-to-end spoken language understanding (SLU) systems are gaining popularity
over cascaded approaches due to their simplicity and ability to avoid error
propagation. However, these systems model sequence labeling as a sequence
prediction task causing a divergence from its well-established token-level
tagging formulation. We build compositional end-to-end SLU systems that
explicitly separate the added complexity of recognizing spoken mentions in SLU
from the NLU task of sequence labeling. By relying on intermediate decoders
trained for ASR, our end-to-end systems transform the input modality from
speech to token-level representations that can be used in the traditional
sequence labeling framework. This composition of ASR and NLU formulations in
our end-to-end SLU system offers direct compatibility with pre-trained ASR and
NLU systems, allows performance monitoring of individual components and enables
the use of globally normalized losses like CRF, making them attractive in
practical scenarios. Our models outperform both cascaded and direct end-to-end
models on a labeling task of named entity recognition across SLU benchmarks."
Biological Robots: Perspectives on an Emerging Interdisciplinary Field,0.0708454,"Advances in science and engineering often reveal the limitations of classical
approaches initially used to understand, predict, and control phenomena. With
progress, conceptual categories must often be re-evaluated to better track
recently discovered invariants across disciplines. It is essential to refine
frameworks and resolve conflicting boundaries between disciplines such that
they better facilitate, not restrict, experimental approaches and capabilities.
In this essay, we discuss issues at the intersection of developmental biology,
computer science, and robotics. In the context of biological robots, we explore
changes across concepts and previously distinct fields that are driven by
recent advances in materials, information, and life sciences. Herein, each
author provides their own perspective on the subject, framed by their own
disciplinary training. We argue that as with computation, certain aspects of
developmental biology and robotics are not tied to specific materials; rather,
the consilience of these fields can help to shed light on issues of multi-scale
control, self-assembly, and relationships between form and function. We hope
new fields can emerge as boundaries arising from technological limitations are
overcome, furthering practical applications from regenerative medicine to
useful synthetic living machines."
Realistic Blur Synthesis for Learning Image Deblurring,0.490688,"Training learning-based deblurring methods demands a tremendous amount of
blurred and sharp image pairs. Unfortunately, existing synthetic datasets are
not realistic enough, and deblurring models trained on them cannot handle real
blurred images effectively. While real datasets have recently been proposed,
they provide limited diversity of scenes and camera settings, and capturing
real datasets for diverse settings is still challenging. To resolve this, this
paper analyzes various factors that introduce differences between real and
synthetic blurred images. To this end, we present RSBlur, a novel dataset with
real blurred images and the corresponding sharp image sequences to enable a
detailed analysis of the difference between real and synthetic blur. With the
dataset, we reveal the effects of different factors in the blur generation
process. Based on the analysis, we also present a novel blur synthesis pipeline
to synthesize more realistic blur. We show that our synthesis pipeline can
improve the deblurring performance on real blurred images."
Learning a General Clause-to-Clause Relationships for Enhancing Emotion-Cause Pair Extraction,0.39477,"Emotion-cause pair extraction (ECPE) is an emerging task aiming to extract
potential pairs of emotions and corresponding causes from documents. Previous
approaches have focused on modeling the pair-to-pair relationship and achieved
promising results. However, the clause-to-clause relationship, which
fundamentally symbolizes the underlying structure of a document, has still been
in its research infancy. In this paper, we define a novel clause-to-clause
relationship. To learn it applicably, we propose a general clause-level
encoding model named EA-GAT comprising E-GAT and Activation Sort. E-GAT is
designed to aggregate information from different types of clauses; Activation
Sort leverages the individual emotion/cause prediction and the sort-based
mapping to propel the clause to a more favorable representation. Since EA-GAT
is a clause-level encoding model, it can be broadly integrated with any
previous approach. Experimental results show that our approach has a
significant advantage over all current approaches on the Chinese and English
benchmark corpus, with an average of $2.1\%$ and $1.03\%$."
DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides,0.115666,"In the clinic, resected tissue samples are stained with Hematoxylin-and-Eosin
(H&E) and/or Immunhistochemistry (IHC) stains and presented to the pathologists
on glass slides or as digital scans for diagnosis and assessment of disease
progression. Cell-level quantification, e.g. in IHC protein expression scoring,
can be extremely inefficient and subjective. We present DeepLIIF
(https://deepliif.org), a first free online platform for efficient and
reproducible IHC scoring. DeepLIIF outperforms current state-of-the-art
approaches (relying on manual error-prone annotations) by virtually restaining
clinical IHC slides with more informative multiplex immunofluorescence
staining. Our DeepLIIF cloud-native platform supports (1) more than 150
proprietary/non-proprietary input formats via the Bio-Formats standard, (2)
interactive adjustment, visualization, and downloading of the IHC
quantification results and the accompanying restained images, (3) consumption
of an exposed workflow API programmatically or through interactive plugins for
open source whole slide image viewers such as QuPath/ImageJ, and (4) auto
scaling to efficiently scale GPU resources based on user demand."
Towards automatic generation of Piping and Instrumentation Diagrams (P&IDs) with Artificial Intelligence,0.367751,"Developing Piping and Instrumentation Diagrams (P&IDs) is a crucial step
during the development of chemical processes. Currently, this is a tedious,
manual, and time-consuming task. We propose a novel, completely data-driven
method for the prediction of control structures. Our methodology is inspired by
end-to-end transformer-based human language translation models. We cast the
control structure prediction as a translation task where Process Flow Diagrams
(PFDs) are translated to P&IDs. To use established transformer-based language
translation models, we represent the P&IDs and PFDs as strings using our
recently proposed SFILES 2.0 notation. Model training is performed in a
transfer learning approach. Firstly, we pre-train our model using generated
P&IDs to learn the grammatical structure of the process diagrams. Thereafter,
the model is fine-tuned leveraging transfer learning on real P&IDs. The model
achieved a top-5 accuracy of 74.8% on 10,000 generated P&IDs and 89.2% on
100,000 generated P&IDs. These promising results show great potential for
AI-assisted process engineering. The tests on a dataset of 312 real P&IDs
indicate the need of a larger P&IDs dataset for industry applications."
Streaming Adaptive Submodular Maximization,0.0679227,"Many sequential decision making problems can be formulated as an adaptive
submodular maximization problem. However, most of existing studies in this
field focus on pool-based setting, where one can pick items in any order, and
there have been few studies for the stream-based setting where items arrive in
an arbitrary order and one must immediately decide whether to select an item or
not upon its arrival. In this paper, we introduce a new class of utility
functions, semi-policywise submodular functions. We develop a series of
effective algorithms to maximize a semi-policywise submodular function under
the stream-based setting."
Reconstructed Student-Teacher and Discriminative Networks for Anomaly Detection,0.0633162,"Anomaly detection is an important problem in computer vision; however, the
scarcity of anomalous samples makes this task difficult. Thus, recent anomaly
detection methods have used only normal images with no abnormal areas for
training. In this work, a powerful anomaly detection method is proposed based
on student-teacher feature pyramid matching (STPM), which consists of a student
and teacher network. Generative models are another approach to anomaly
detection. They reconstruct normal images from an input and compute the
difference between the predicted normal and the input. Unfortunately, STPM does
not have the ability to generate normal images. To improve the accuracy of
STPM, this work uses a student network, as in generative models, to reconstruct
normal features. This improves the accuracy; however, the anomaly maps for
normal images are not clean because STPM does not use anomaly images for
training, which decreases the accuracy of the image-level anomaly detection. To
further improve accuracy, a discriminative network trained with
pseudo-anomalies from anomaly maps is used in our method, which consists of two
pairs of student-teacher networks and a discriminative network. The method
displayed high accuracy on the MVTec anomaly detection dataset."
Integrating Human-in-the-loop into Swarm Learning for Decentralized Fake News Detection,0.306214,"Social media has become an effective platform to generate and spread fake
news that can mislead people and even distort public opinion. Centralized
methods for fake news detection, however, cannot effectively protect user
privacy during the process of centralized data collection for training models.
Moreover, it cannot fully involve user feedback in the loop of learning
detection models for further enhancing fake news detection. To overcome these
challenges, this paper proposed a novel decentralized method, Human-in-the-loop
Based Swarm Learning (HBSL), to integrate user feedback into the loop of
learning and inference for recognizing fake news without violating user privacy
in a decentralized manner. It consists of distributed nodes that are able to
independently learn and detect fake news on local data. Furthermore, detection
models trained on these nodes can be enhanced through decentralized model
merging. Experimental results demonstrate that the proposed method outperforms
the state-of-the-art decentralized method in regard of detecting fake news on a
benchmark dataset."
TEMPERA: Test-Time Prompting via Reinforcement Learning,0.83425,"Careful prompt design is critical to the use of large language models in
zero-shot or few-shot learning. As a consequence, there is a growing interest
in automated methods to design optimal prompts. In this work, we propose
Test-time Prompt Editing using Reinforcement learning (TEMPERA). In contrast to
prior prompt generation methods, TEMPERA can efficiently leverage prior
knowledge, is adaptive to different queries and provides an interpretable
prompt for every query. To achieve this, we design a novel action space that
allows flexible editing of the initial prompts covering a wide set of
commonly-used components like instructions, few-shot exemplars, and
verbalizers. The proposed method achieves significant gains compared with
recent SoTA approaches like prompt tuning, AutoPrompt, and RLPrompt, across a
variety of tasks including sentiment analysis, topic classification, natural
language inference, and reading comprehension. Our method achieves 5.33x on
average improvement in sample efficiency when compared to the traditional
fine-tuning methods."
Omnifont Persian OCR System Using Primitives,0.0962347,"In this paper, we introduce a model-based omnifont Persian OCR system. The
system uses a set of 8 primitive elements as structural features for
recognition. First, the scanned document is preprocessed. After normalizing the
preprocessed image, text rows and sub-words are separated and then thinned.
After recognition of dots in sub-words, strokes are extracted and primitive
elements of each sub-word are recognized using the strokes. Finally, the
primitives are compared with a predefined set of character identification
vectors in order to identify sub-word characters. The separation and
recognition steps of the system are concurrent, eliminating unavoidable errors
of independent separation of letters. The system has been tested on documents
with 14 standard Persian fonts in 6 sizes. The achieved precision is 97.06%."
Formal Algorithms for Transformers,0.28929,"This document aims to be a self-contained, mathematically precise overview of
transformer architectures and algorithms (*not* results). It covers what
transformers are, how they are trained, what they are used for, their key
architectural components, and a preview of the most prominent models. The
reader is assumed to be familiar with basic ML terminology and simpler neural
network architectures such as MLPs."
Towards Inter-character Relationship-driven Story Generation,0.0649849,"In this paper, we introduce the task of modeling interpersonal relationships
for story generation. For addressing this task, we propose Relationships as
Latent Variables for Story Generation, (ReLiSt). ReLiSt generates stories
sentence by sentence and has two major components - a relationship selector and
a story continuer. The relationship selector specifies a latent variable to
pick the relationship to exhibit in the next sentence and the story continuer
generates the next sentence while expressing the selected relationship in a
coherent way. Our automatic and human evaluations demonstrate that ReLiSt is
able to generate stories with relationships that are more faithful to desired
relationships while maintaining the content quality. The relationship
assignments to sentences during inference bring interpretability to ReLiSt."
Sample-Efficient Reinforcement Learning of Partially Observable Markov Games,0.159042,"This paper considers the challenging tasks of Multi-Agent Reinforcement
Learning (MARL) under partial observability, where each agent only sees her own
individual observations and actions that reveal incomplete information about
the underlying state of system. This paper studies these tasks under the
general model of multiplayer general-sum Partially Observable Markov Games
(POMGs), which is significantly larger than the standard model of Imperfect
Information Extensive-Form Games (IIEFGs). We identify a rich subclass of POMGs
-- weakly revealing POMGs -- in which sample-efficient learning is tractable.
In the self-play setting, we prove that a simple algorithm combining optimism
and Maximum Likelihood Estimation (MLE) is sufficient to find approximate Nash
equilibria, correlated equilibria, as well as coarse correlated equilibria of
weakly revealing POMGs, in a polynomial number of samples when the number of
agents is small. In the setting of playing against adversarial opponents, we
show that a variant of our optimistic MLE algorithm is capable of achieving
sublinear regret when being compared against the optimal maximin policies. To
our best knowledge, this work provides the first line of sample-efficient
results for learning POMGs."
ConvFinQA: Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering,0.533581,"With the recent advance in large pre-trained language models, researchers
have achieved record performances in NLP tasks that mostly focus on language
pattern matching. The community is experiencing the shift of the challenge from
how to model language to the imitation of complex reasoning abilities like
human beings. In this work, we investigate the application domain of finance
that involves real-world, complex numerical reasoning. We propose a new
large-scale dataset, ConvFinQA, aiming to study the chain of numerical
reasoning in conversational question answering. Our dataset poses great
challenge in modeling long-range, complex numerical reasoning paths in
real-world conversations. We conduct comprehensive experiments and analyses
with both the neural symbolic methods and the prompting-based methods, to
provide insights into the reasoning mechanisms of these two divisions. We
believe our new dataset should serve as a valuable resource to push forward the
exploration of real-world, complex reasoning tasks as the next research focus.
Our dataset and code is publicly available at
https://github.com/czyssrs/ConvFinQA."
CMT-DeepLab: Clustering Mask Transformers for Panoptic Segmentation,0.52123,"We propose Clustering Mask Transformer (CMT-DeepLab), a transformer-based
framework for panoptic segmentation designed around clustering. It rethinks the
existing transformer architectures used in segmentation and detection;
CMT-DeepLab considers the object queries as cluster centers, which fill the
role of grouping the pixels when applied to segmentation. The clustering is
computed with an alternating procedure, by first assigning pixels to the
clusters by their feature affinity, and then updating the cluster centers and
pixel features. Together, these operations comprise the Clustering Mask
Transformer (CMT) layer, which produces cross-attention that is denser and more
consistent with the final segmentation task. CMT-DeepLab improves the
performance over prior art significantly by 4.4% PQ, achieving a new
state-of-the-art of 55.7% PQ on the COCO test-dev set."
A Double-Graph Based Framework for Frame Semantic Parsing,0.082765,"Frame semantic parsing is a fundamental NLP task, which consists of three
subtasks: frame identification, argument identification and role
classification. Most previous studies tend to neglect relations between
different subtasks and arguments and pay little attention to ontological frame
knowledge defined in FrameNet. In this paper, we propose a Knowledge-guided
Incremental semantic parser with Double-graph (KID). We first introduce Frame
Knowledge Graph (FKG), a heterogeneous graph containing both frames and FEs
(Frame Elements) built on the frame knowledge so that we can derive
knowledge-enhanced representations for frames and FEs. Besides, we propose
Frame Semantic Graph (FSG) to represent frame semantic structures extracted
from the text with graph structures. In this way, we can transform frame
semantic parsing into an incremental graph construction problem to strengthen
interactions between subtasks and relations between arguments. Our experiments
show that KID outperforms the previous state-of-the-art method by up to 1.7
F1-score on two FrameNet datasets. Our code is availavle at
https://github.com/PKUnlp-icler/KID."
TENET: Transformer Encoding Network for Effective Temporal Flow on Motion Prediction,0.0,"This technical report presents an effective method for motion prediction in
autonomous driving. We develop a Transformer-based method for input encoding
and trajectory prediction. Besides, we propose the Temporal Flow Header to
enhance the trajectory encoding. In the end, an efficient K-means ensemble
method is used. Using our Transformer network and ensemble method, we win the
first place of Argoverse 2 Motion Forecasting Challenge with the
state-of-the-art brier-minFDE score of 1.90."
Densely Constrained Depth Estimator for Monocular 3D Object Detection,0.0885086,"Estimating accurate 3D locations of objects from monocular images is a
challenging problem because of lacking depth. Previous work shows that
utilizing the object's keypoint projection constraints to estimate multiple
depth candidates boosts the detection performance. However, the existing
methods can only utilize vertical edges as projection constraints for depth
estimation. So these methods only use a small number of projection constraints
and produce insufficient depth candidates, leading to inaccurate depth
estimation. In this paper, we propose a method that utilizes dense projection
constraints from edges of any direction. In this way, we employ much more
projection constraints and produce considerable depth candidates. Besides, we
present a graph matching weighting module to merge the depth candidates. The
proposed method DCD (Densely Constrained Detector) achieves state-of-the-art
performance on the KITTI and WOD benchmarks. Code is released at
https://github.com/BraveGroup/DCD."
Patterns of near-crash events in a naturalistic driving dataset: applying rules mining,0.13531,"This study aims to explore the associations between near-crash events and
road geometry and trip features by investigating a naturalistic driving dataset
and a corresponding roadway inventory dataset using an association rule mining
method."
Code-DKT: A Code-based Knowledge Tracing Model for Programming Tasks,0.0170901,"Knowledge tracing (KT) models are a popular approach for predicting students'
future performance at practice problems using their prior attempts. Though many
innovations have been made in KT, most models including the state-of-the-art
Deep KT (DKT) mainly leverage each student's response either as correct or
incorrect, ignoring its content. In this work, we propose Code-based Deep
Knowledge Tracing (Code-DKT), a model that uses an attention mechanism to
automatically extract and select domain-specific code features to extend DKT.
We compared the effectiveness of Code-DKT against Bayesian and Deep Knowledge
Tracing (BKT and DKT) on a dataset from a class of 50 students attempting to
solve 5 introductory programming assignments. Our results show that Code-DKT
consistently outperforms DKT by 3.07-4.00% AUC across the 5 assignments, a
comparable improvement to other state-of-the-art domain-general KT models over
DKT. Finally, we analyze problem-specific performance through a set of case
studies for one assignment to demonstrate when and how code features improve
Code-DKT's predictions."
Synthetic Distracted Driving (SynDD2) dataset for analyzing distracted behaviors and various gaze zones of a driver,0.207391,"This article presents a synthetic distracted driving (SynDD2 - a continuum of
SynDD1) dataset for machine learning models to detect and analyze drivers'
various distracted behavior and different gaze zones. We collected the data in
a stationary vehicle using three in-vehicle cameras positioned at locations: on
the dashboard, near the rearview mirror, and on the top right-side window
corner. The dataset contains two activity types: distracted activities and gaze
zones for each participant, and each activity type has two sets: without
appearance blocks and with appearance blocks such as wearing a hat or
sunglasses. The order and duration of each activity for each participant are
random. In addition, the dataset contains manual annotations for each activity,
having its start and end time annotated. Researchers could use this dataset to
evaluate the performance of machine learning algorithms to classify various
distracting activities and gaze zones of drivers."
Multi-Agent Chance-Constrained Stochastic Shortest Path with Application to Risk-Aware Intelligent Intersection,0.205748,"In transportation networks, where traffic lights have traditionally been used
for vehicle coordination, intersections act as natural bottlenecks. A
formidable challenge for existing automated intersections lies in detecting and
reasoning about uncertainty from the operating environment and human-driven
vehicles. In this paper, we propose a risk-aware intelligent intersection
system for autonomous vehicles (AVs) as well as human-driven vehicles (HVs). We
cast the problem as a novel class of Multi-agent Chance-Constrained Stochastic
Shortest Path (MCC-SSP) problems and devise an exact Integer Linear Programming
(ILP) formulation that is scalable in the number of agents' interaction points
(e.g., potential collision points at the intersection). In particular, when the
number of agents within an interaction point is small, which is often the case
in intersections, the ILP has a polynomial number of variables and constraints.
To further improve the running time performance, we show that the collision
risk computation can be performed offline. Additionally, a trajectory
optimization workflow is provided to generate risk-aware trajectories for any
given intersection. The proposed framework is implemented in CARLA simulator
and evaluated under a fully autonomous intersection with AVs only as well as in
a hybrid setup with a signalized intersection for HVs and an intelligent scheme
for AVs. As verified via simulations, the featured approach improves
intersection's efficiency by up to $200\%$ while also conforming to the
specified tunable risk threshold."
Items from Psychometric Tests as Training Data for Personality Profiling Models of Twitter Users,0.111883,"Machine-learned models for author profiling in social media often rely on
data acquired via self-reporting-based psychometric tests (questionnaires)
filled out by social media users. This is an expensive but accurate data
collection strategy. Another, less costly alternative, which leads to
potentially more noisy and biased data, is to rely on labels inferred from
publicly available information in the profiles of the users, for instance
self-reported diagnoses or test results. In this paper, we explore a third
strategy, namely to directly use a corpus of items from validated psychometric
tests as training data. Items from psychometric tests often consist of
sentences from an I-perspective (e.g., ""I make friends easily.""). Such corpora
of test items constitute 'small data', but their availability for many concepts
is a rich resource. We investigate this approach for personality profiling, and
evaluate BERT classifiers fine-tuned on such psychometric test items for the
big five personality traits (openness, conscientiousness, extraversion,
agreeableness, neuroticism) and analyze various augmentation strategies
regarding their potential to address the challenges coming with such a small
corpus. Our evaluation on a publicly available Twitter corpus shows a
comparable performance to in-domain training for 4/5 personality traits with
T5-based data augmentation."
Real-time Online Video Detection with Temporal Smoothing Transformers,0.202654,"Streaming video recognition reasons about objects and their actions in every
frame of a video. A good streaming recognition model captures both long-term
dynamics and short-term changes of video. Unfortunately, in most existing
methods, the computational complexity grows linearly or quadratically with the
length of the considered dynamics. This issue is particularly pronounced in
transformer-based architectures. To address this issue, we reformulate the
cross-attention in a video transformer through the lens of kernel and apply two
kinds of temporal smoothing kernel: A box kernel or a Laplace kernel. The
resulting streaming attention reuses much of the computation from frame to
frame, and only requires a constant time update each frame. Based on this idea,
we build TeSTra, a Temporal Smoothing Transformer, that takes in arbitrarily
long inputs with constant caching and computing overhead. Specifically, it runs
$6\times$ faster than equivalent sliding-window based transformers with 2,048
frames in a streaming setting. Furthermore, thanks to the increased temporal
span, TeSTra achieves state-of-the-art results on THUMOS'14 and
EPIC-Kitchen-100, two standard online action detection and action anticipation
datasets. A real-time version of TeSTra outperforms all but one prior
approaches on the THUMOS'14 dataset."
LISA: Learning Implicit Shape and Appearance of Hands,0.734463,"This paper proposes a do-it-all neural model of human hands, named LISA. The
model can capture accurate hand shape and appearance, generalize to arbitrary
hand subjects, provide dense surface correspondences, be reconstructed from
images in the wild and easily animated. We train LISA by minimizing the shape
and appearance losses on a large set of multi-view RGB image sequences
annotated with coarse 3D poses of the hand skeleton. For a 3D point in the hand
local coordinate, our model predicts the color and the signed distance with
respect to each hand bone independently, and then combines the per-bone
predictions using predicted skinning weights. The shape, color and pose
representations are disentangled by design, allowing to estimate or animate
only selected parameters. We experimentally demonstrate that LISA can
accurately reconstruct a dynamic hand from monocular or multi-view sequences,
achieving a noticeably higher quality of reconstructed hand shapes compared to
baseline approaches. Project page:
https://www.iri.upc.edu/people/ecorona/lisa/."
DIMBA: Discretely Masked Black-Box Attack in Single Object Tracking,0.0924791,"The adversarial attack can force a CNN-based model to produce an incorrect
output by craftily manipulating human-imperceptible input. Exploring such
perturbations can help us gain a deeper understanding of the vulnerability of
neural networks, and provide robustness to deep learning against miscellaneous
adversaries. Despite extensive studies focusing on the robustness of image,
audio, and NLP, works on adversarial examples of visual object tracking --
especially in a black-box manner -- are quite lacking. In this paper, we
propose a novel adversarial attack method to generate noises for single object
tracking under black-box settings, where perturbations are merely added on
initial frames of tracking sequences, which is difficult to be noticed from the
perspective of a whole video clip. Specifically, we divide our algorithm into
three components and exploit reinforcement learning for localizing important
frame patches precisely while reducing unnecessary computational queries
overhead. Compared to existing techniques, our method requires fewer queries on
initialized frames of a video to manipulate competitive or even better attack
performance. We test our algorithm in both long-term and short-term datasets,
including OTB100, VOT2018, UAV123, and LaSOT. Extensive experiments demonstrate
the effectiveness of our method on three mainstream types of trackers:
discrimination, Siamese-based, and reinforcement learning-based trackers."
Self-Supervised Vision Transformers Learn Visual Concepts in Histopathology,0.591406,"Tissue phenotyping is a fundamental task in learning objective
characterizations of histopathologic biomarkers within the tumor-immune
microenvironment in cancer pathology. However, whole-slide imaging (WSI) is a
complex computer vision in which: 1) WSIs have enormous image resolutions with
precludes large-scale pixel-level efforts in data curation, and 2) diversity of
morphological phenotypes results in inter- and intra-observer variability in
tissue labeling. To address these limitations, current efforts have proposed
using pretrained image encoders (transfer learning from ImageNet,
self-supervised pretraining) in extracting morphological features from
pathology, but have not been extensively validated. In this work, we conduct a
search for good representations in pathology by training a variety of
self-supervised models with validation on a variety of weakly-supervised and
patch-level tasks. Our key finding is in discovering that Vision Transformers
using DINO-based knowledge distillation are able to learn data-efficient and
interpretable features in histology images wherein the different attention
heads learn distinct morphological phenotypes. We make evaluation code and
pretrained weights publicly-available at:
https://github.com/Richarizardd/Self-Supervised-ViT-Path."
Bootstrapped Transformer for Offline Reinforcement Learning,0.0526886,"Offline reinforcement learning (RL) aims at learning policies from previously
collected static trajectory data without interacting with the real environment.
Recent works provide a novel perspective by viewing offline RL as a generic
sequence generation problem, adopting sequence models such as Transformer
architecture to model distributions over trajectories, and repurposing beam
search as a planning algorithm. However, the training datasets utilized in
general offline RL tasks are quite limited and often suffer from insufficient
distribution coverage, which could be harmful to training sequence generation
models yet has not drawn enough attention in the previous works. In this paper,
we propose a novel algorithm named Bootstrapped Transformer, which incorporates
the idea of bootstrapping and leverages the learned model to self-generate more
offline data to further boost the sequence model training. We conduct extensive
experiments on two offline RL benchmarks and demonstrate that our model can
largely remedy the existing offline RL training limitations and beat other
strong baseline methods. We also analyze the generated pseudo data and the
revealed characteristics may shed some light on offline RL training. The codes
are available at https://seqml.github.io/bootorl."
Beyond the Return: Off-policy Function Estimation under User-specified Error-measuring Distributions,0.0586005,"Off-policy evaluation often refers to two related tasks: estimating the
expected return of a policy and estimating its value function (or other
functions of interest, such as density ratios). While recent works on
marginalized importance sampling (MIS) show that the former can enjoy provable
guarantees under realizable function approximation, the latter is only known to
be feasible under much stronger assumptions such as prohibitively expressive
discriminators. In this work, we provide guarantees for off-policy function
estimation under only realizability, by imposing proper regularization on the
MIS objectives. Compared to commonly used regularization in MIS, our
regularizer is much more flexible and can account for an arbitrary
user-specified distribution, under which the learned function will be close to
the groundtruth. We provide exact characterization of the optimal dual solution
that needs to be realized by the discriminator class, which determines the
data-coverage assumption in the case of value-function learning. As another
surprising observation, the regularizer can be altered to relax the
data-coverage requirement, and completely eliminate it in the ideal case with
strong side information."
More Interpretable Graph Similarity Computation via Maximum Common Subgraph Inference,0.134577,"Graph similarity measurement, which computes the distance/similarity between
two graphs, arises in various graph-related tasks. Recent learning-based
methods lack interpretability, as they directly transform interaction
information between two graphs into one hidden vector and then map it to
similarity. To cope with this problem, this study proposes a more interpretable
end-to-end paradigm for graph similarity learning, named Similarity Computation
via Maximum Common Subgraph Inference (INFMCS). Our critical insight into
INFMCS is the strong correlation between similarity score and Maximum Common
Subgraph (MCS). We implicitly infer MCS to obtain the normalized MCS size, with
the supervision information being only the similarity score during training. To
capture more global information, we also stack some vanilla transformer encoder
layers with graph convolution layers and propose a novel permutation-invariant
node Positional Encoding. The entire model is quite simple yet effective.
Comprehensive experiments demonstrate that INFMCS consistently outperforms
state-of-the-art baselines for graph-graph classification and regression tasks.
Ablation experiments verify the effectiveness of the proposed computation
paradigm and other components. Also, visualization and statistics of results
reveal the interpretability of INFMCS."
MonoGround: Detecting Monocular 3D Objects from the Ground,0.149293,"Monocular 3D object detection has attracted great attention for its
advantages in simplicity and cost. Due to the ill-posed 2D to 3D mapping
essence from the monocular imaging process, monocular 3D object detection
suffers from inaccurate depth estimation and thus has poor 3D detection
results. To alleviate this problem, we propose to introduce the ground plane as
a prior in the monocular 3d object detection. The ground plane prior serves as
an additional geometric condition to the ill-posed mapping and an extra source
in depth estimation. In this way, we can get a more accurate depth estimation
from the ground. Meanwhile, to take full advantage of the ground plane prior,
we propose a depth-align training strategy and a precise two-stage depth
inference method tailored for the ground plane prior. It is worth noting that
the introduced ground plane prior requires no extra data sources like LiDAR,
stereo images, and depth information. Extensive experiments on the KITTI
benchmark show that our method could achieve state-of-the-art results compared
with other methods while maintaining a very fast speed. Our code and models are
available at https://github.com/cfzd/MonoGround."
Entropy- and Distance-Based Predictors From GPT-2 Attention Patterns Predict Reading Times Over and Above GPT-2 Surprisal,0.103173,"Transformer-based large language models are trained to make predictions about
the next word by aggregating representations of previous tokens through their
self-attention mechanism. In the field of cognitive modeling, such attention
patterns have recently been interpreted as embodying the process of cue-based
retrieval, in which attention over multiple targets is taken to generate
interference and latency during retrieval. Under this framework, this work
first defines an entropy-based predictor that quantifies the diffuseness of
self-attention, as well as distance-based predictors that capture the
incremental change in attention patterns across timesteps. Moreover, following
recent studies that question the informativeness of attention weights, we also
experiment with alternative methods for incorporating vector norms into
attention weights. Regression experiments using predictors calculated from the
GPT-2 language model show that these predictors deliver a substantially better
fit to held-out self-paced reading and eye-tracking data over a rigorous
baseline including GPT-2 surprisal. Additionally, the distance-based predictors
generally demonstrated higher predictive power, with effect sizes of up to 6.59
ms per standard deviation on self-paced reading times (compared to 2.82 ms for
surprisal) and 1.05 ms per standard deviation on eye-gaze durations (compared
to 3.81 ms for surprisal)."
Uncertainty-aware deep learning methods for robust diabetic retinopathy classification,0.407944,"Automatic classification of diabetic retinopathy from retinal images has been
widely studied using deep neural networks with impressive results. However,
there is a clinical need for estimation of the uncertainty in the
classifications, a shortcoming of modern neural networks. Recently, approximate
Bayesian deep learning methods have been proposed for the task but the studies
have only considered the binary referable/non-referable diabetic retinopathy
classification applied to benchmark datasets. We present novel results by
systematically investigating a clinical dataset and a clinically relevant
5-class classification scheme, in addition to benchmark datasets and the binary
classification scheme. Moreover, we derive a connection between uncertainty
measures and classifier risk, from which we develop a new uncertainty measure.
We observe that the previously proposed entropy-based uncertainty measure
generalizes to the clinical dataset on the binary classification scheme but not
on the 5-class scheme, whereas our new uncertainty measure generalizes to the
latter case."
"Text and Patterns: For Effective Chain of Thought, It Takes Two to Tango",0.741303,"The past decade has witnessed dramatic gains in natural language processing
and an unprecedented scaling of large language models. These developments have
been accelerated by the advent of few-shot techniques such as chain of thought
(CoT) prompting. Specifically, CoT pushes the performance of large language
models in a few-shot setup by augmenting the prompts with intermediate steps.
Despite impressive results across various tasks, the reasons behind their
success have not been explored. This work uses counterfactual prompting to
develop a deeper understanding of CoT-based few-shot prompting mechanisms in
large language models. We first systematically identify and define the key
components of a prompt: symbols, patterns, and text. Then, we devise and
conduct an exhaustive set of experiments across four different tasks, by
querying the model with counterfactual prompts where only one of these
components is altered. Our experiments across three models (PaLM, GPT-3, and
CODEX) reveal several surprising findings and brings into question the
conventional wisdom around few-shot prompting. First, the presence of factual
patterns in a prompt is practically immaterial to the success of CoT. Second,
our results conclude that the primary role of intermediate steps may not be to
facilitate learning how to solve a task. The intermediate steps are rather a
beacon for the model to realize what symbols to replicate in the output to form
a factual answer. Further, text imbues patterns with commonsense knowledge and
meaning. Our empirical and qualitative analysis reveals that a symbiotic
relationship between text and patterns explains the success of few-shot
prompting: text helps extract commonsense from the question to help patterns,
and patterns enforce task understanding and direct text generation."
RuCoLA: Russian Corpus of Linguistic Acceptability,0.456741,"Linguistic acceptability (LA) attracts the attention of the research
community due to its many uses, such as testing the grammatical knowledge of
language models and filtering implausible texts with acceptability classifiers.
However, the application scope of LA in languages other than English is limited
due to the lack of high-quality resources. To this end, we introduce the
Russian Corpus of Linguistic Acceptability (RuCoLA), built from the ground up
under the well-established binary LA approach. RuCoLA consists of $9.8$k
in-domain sentences from linguistic publications and $3.6$k out-of-domain
sentences produced by generative models. The out-of-domain set is created to
facilitate the practical use of acceptability for improving language
generation. Our paper describes the data collection protocol and presents a
fine-grained analysis of acceptability classification experiments with a range
of baseline approaches. In particular, we demonstrate that the most widely used
language models still fall behind humans by a large margin, especially when
detecting morphological and semantic errors. We release RuCoLA, the code of
experiments, and a public leaderboard (rucola-benchmark.com) to assess the
linguistic competence of language models for Russian."
DialoKG: Knowledge-Structure Aware Task-Oriented Dialogue Generation,0.347625,"Task-oriented dialogue generation is challenging since the underlying
knowledge is often dynamic and effectively incorporating knowledge into the
learning process is hard. It is particularly challenging to generate both
human-like and informative responses in this setting. Recent research primarily
focused on various knowledge distillation methods where the underlying
relationship between the facts in a knowledge base is not effectively captured.
In this paper, we go one step further and demonstrate how the structural
information of a knowledge graph can improve the system's inference
capabilities. Specifically, we propose DialoKG, a novel task-oriented dialogue
system that effectively incorporates knowledge into a language model. Our
proposed system views relational knowledge as a knowledge graph and introduces
(1) a structure-aware knowledge embedding technique, and (2) a knowledge
graph-weighted attention masking strategy to facilitate the system selecting
relevant information during the dialogue generation. An empirical evaluation
demonstrates the effectiveness of DialoKG over state-of-the-art methods on
several standard benchmark datasets."
RF-Next: Efficient Receptive Field Search for Convolutional Neural Networks,0.095892,"Temporal/spatial receptive fields of models play an important role in
sequential/spatial tasks. Large receptive fields facilitate long-term
relations, while small receptive fields help to capture the local details.
Existing methods construct models with hand-designed receptive fields in
layers. Can we effectively search for receptive field combinations to replace
hand-designed patterns? To answer this question, we propose to find better
receptive field combinations through a global-to-local search scheme. Our
search scheme exploits both global search to find the coarse combinations and
local search to get the refined receptive field combinations further. The
global search finds possible coarse combinations other than human-designed
patterns. On top of the global search, we propose an expectation-guided
iterative local search scheme to refine combinations effectively. Our RF-Next
models, plugging receptive field search to various models, boost the
performance on many tasks, e.g., temporal action segmentation, object
detection, instance segmentation, and speech synthesis. The source code is
publicly available on http://mmcheng.net/rfnext."
BOAT: Bilateral Local Attention Vision Transformer,0.111653,"Vision Transformers achieved outstanding performance in many computer vision
tasks. Early Vision Transformers such as ViT and DeiT adopt global
self-attention, which is computationally expensive when the number of patches
is large. To improve efficiency, recent Vision Transformers adopt local
self-attention mechanisms, where self-attention is computed within local
windows. Despite the fact that window-based local self-attention significantly
boosts efficiency, it fails to capture the relationships between distant but
similar patches in the image plane. To overcome this limitation of image-space
local attention, in this paper, we further exploit the locality of patches in
the feature space. We group the patches into multiple clusters using their
features, and self-attention is computed within every cluster. Such
feature-space local attention effectively captures the connections between
patches across different local windows but still relevant. We propose a
Bilateral lOcal Attention vision Transformer (BOAT), which integrates
feature-space local attention with image-space local attention. We further
integrate BOAT with both Swin and CSWin models, and extensive experiments on
several benchmark datasets demonstrate that our BOAT-CSWin model clearly and
consistently outperforms existing state-of-the-art CNN models and vision
Transformers."
Transforming Gait: Video-Based Spatiotemporal Gait Analysis,0.111685,"Human pose estimation from monocular video is a rapidly advancing field that
offers great promise to human movement science and rehabilitation. This
potential is tempered by the smaller body of work ensuring the outputs are
clinically meaningful and properly calibrated. Gait analysis, typically
performed in a dedicated lab, produces precise measurements including
kinematics and step timing. Using over 7000 monocular video from an
instrumented gait analysis lab, we trained a neural network to map 3D joint
trajectories and the height of individuals onto interpretable biomechanical
outputs including gait cycle timing and sagittal plane joint kinematics and
spatiotemporal trajectories. This task specific layer produces accurate
estimates of the timing of foot contact and foot off events. After parsing the
kinematic outputs into individual gait cycles, it also enables accurate
cycle-by-cycle estimates of cadence, step time, double and single support time,
walking speed and step length."
Multi-Granularity Prediction for Scene Text Recognition,0.341716,"Scene text recognition (STR) has been an active research topic in computer
vision for years. To tackle this challenging problem, numerous innovative
methods have been successively proposed and incorporating linguistic knowledge
into STR models has recently become a prominent trend. In this work, we first
draw inspiration from the recent progress in Vision Transformer (ViT) to
construct a conceptually simple yet powerful vision STR model, which is built
upon ViT and outperforms previous state-of-the-art models for scene text
recognition, including both pure vision models and language-augmented methods.
To integrate linguistic knowledge, we further propose a Multi-Granularity
Prediction strategy to inject information from the language modality into the
model in an implicit way, i.e. , subword representations (BPE and WordPiece)
widely-used in NLP are introduced into the output space, in addition to the
conventional character level representation, while no independent language
model (LM) is adopted. The resultant algorithm (termed MGP-STR) is able to push
the performance envelop of STR to an even higher level. Specifically, it
achieves an average recognition accuracy of 93.35% on standard benchmarks. Code
is available at
https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/MGP-STR."
Low-rank lottery tickets: finding efficient low-rank neural networks via matrix differential equations,0.394693,"Neural networks have achieved tremendous success in a large variety of
applications. However, their memory footprint and computational demand can
render them impractical in application settings with limited hardware or energy
resources. In this work, we propose a novel algorithm to find efficient
low-rank subnetworks. Remarkably, these subnetworks are determined and adapted
already during the training phase and the overall time and memory resources
required by both training and evaluating them are significantly reduced. The
main idea is to restrict the weight matrices to a low-rank manifold and to
update the low-rank factors rather than the full matrix during training. To
derive training updates that are restricted to the prescribed manifold, we
employ techniques from dynamic model order reduction for matrix differential
equations. This allows us to provide approximation, stability, and descent
guarantees. Moreover, our method automatically and dynamically adapts the ranks
during training to achieve the desired approximation accuracy. The efficiency
of the proposed method is demonstrated through a variety of numerical
experiments on fully-connected and convolutional networks."
Hitchhiker's Guide to Super-Resolution: Introduction and Recent Advances,0.0477389,"With the advent of Deep Learning (DL), Super-Resolution (SR) has also become
a thriving research area. However, despite promising results, the field still
faces challenges that require further research e.g., allowing flexible
upsampling, more effective loss functions, and better evaluation metrics. We
review the domain of SR in light of recent advances, and examine
state-of-the-art models such as diffusion (DDPM) and transformer-based SR
models. We present a critical discussion on contemporary strategies used in SR,
and identify promising yet unexplored research directions. We complement
previous surveys by incorporating the latest developments in the field such as
uncertainty-driven losses, wavelet networks, neural architecture search, novel
normalization methods, and the latests evaluation techniques. We also include
several visualizations for the models and methods throughout each chapter in
order to facilitate a global understanding of the trends in the field. This
review is ultimately aimed at helping researchers to push the boundaries of DL
applied to SR."
Unbiased Heterogeneous Scene Graph Generation with Relation-aware Message Passing Neural Network,0.122307,"Recent scene graph generation (SGG) frameworks have focused on learning
complex relationships among multiple objects in an image. Thanks to the nature
of the message passing neural network (MPNN) that models high-order
interactions between objects and their neighboring objects, they are dominant
representation learning modules for SGG. However, existing MPNN-based
frameworks assume the scene graph as a homogeneous graph, which restricts the
context-awareness of visual relations between objects. That is, they overlook
the fact that the relations tend to be highly dependent on the objects with
which the relations are associated. In this paper, we propose an unbiased
heterogeneous scene graph generation (HetSGG) framework that captures
relation-aware context using message passing neural networks. We devise a novel
message passing layer, called relation-aware message passing neural network
(RMP), that aggregates the contextual information of an image considering the
predicate type between objects. Our extensive evaluations demonstrate that
HetSGG outperforms state-of-the-art methods, especially outperforming on tail
predicate classes."
Iterative Patch Selection for High-Resolution Image Recognition,0.0275361,"High-resolution images are prevalent in various applications, such as
autonomous driving and computer-aided diagnosis. However, training neural
networks on such images is computationally challenging and easily leads to
out-of-memory errors even on modern GPUs. We propose a simple method, Iterative
Patch Selection (IPS), which decouples the memory usage from the input size and
thus enables the processing of arbitrarily large images under tight hardware
constraints. IPS achieves this by selecting only the most salient patches,
which are then aggregated into a global representation for image recognition.
For both patch selection and aggregation, a cross-attention based transformer
is introduced, which exhibits a close connection to Multiple Instance Learning.
Our method demonstrates strong performance and has wide applicability across
different domains, training regimes and image sizes while using minimal
accelerator memory. For example, we are able to finetune our model on
whole-slide images consisting of up to 250k patches (>16 gigapixels) with only
5 GB of GPU VRAM at a batch size of 16."
On the Explainability of Natural Language Processing Deep Models,0.0347693,"While there has been a recent explosion of work on ExplainableAI ExAI on deep
models that operate on imagery and tabular data, textual datasets present new
challenges to the ExAI community. Such challenges can be attributed to the lack
of input structure in textual data, the use of word embeddings that add to the
opacity of the models and the difficulty of the visualization of the inner
workings of deep models when they are trained on textual data.
  Lately, methods have been developed to address the aforementioned challenges
and present satisfactory explanations on Natural Language Processing (NLP)
models. However, such methods are yet to be studied in a comprehensive
framework where common challenges are properly stated and rigorous evaluation
practices and metrics are proposed. Motivated to democratize ExAI methods in
the NLP field, we present in this work a survey that studies model-agnostic as
well as model-specific explainability methods on NLP models. Such methods can
either develop inherently interpretable NLP models or operate on pre-trained
models in a post-hoc manner. We make this distinction and we further decompose
the methods into three categories according to what they explain: (1) word
embeddings (input-level), (2) inner workings of NLP models (processing-level)
and (3) models' decisions (output-level). We also detail the different
evaluation approaches interpretability methods in the NLP field. Finally, we
present a case-study on the well-known neural machine translation in an
appendix and we propose promising future research directions for ExAI in the
NLP field."
PointInst3D: Segmenting 3D Instances by Points,0.123626,"The current state-of-the-art methods in 3D instance segmentation typically
involve a clustering step, despite the tendency towards heuristics, greedy
algorithms, and a lack of robustness to the changes in data statistics. In
contrast, we propose a fully-convolutional 3D point cloud instance segmentation
method that works in a per-point prediction fashion. In doing so it avoids the
challenges that clustering-based methods face: introducing dependencies among
different tasks of the model. We find the key to its success is assigning a
suitable target to each sampled point. Instead of the commonly used static or
distance-based assignment strategies, we propose to use an Optimal Transport
approach to optimally assign target masks to the sampled points according to
the dynamic matching costs. Our approach achieves promising results on both
ScanNet and S3DIS benchmarks. The proposed approach removes intertask
dependencies and thus represents a simpler and more flexible 3D instance
segmentation framework than other competing methods, while achieving improved
segmentation accuracy."
Pruning-as-Search: Efficient Neural Architecture Search via Channel Pruning and Structural Reparameterization,0.115058,"Neural architecture search (NAS) and network pruning are widely studied
efficient AI techniques, but not yet perfect. NAS performs exhaustive candidate
architecture search, incurring tremendous search cost. Though (structured)
pruning can simply shrink model dimension, it remains unclear how to decide the
per-layer sparsity automatically and optimally. In this work, we revisit the
problem of layer-width optimization and propose Pruning-as-Search (PaS), an
end-to-end channel pruning method to search out desired sub-network
automatically and efficiently. Specifically, we add a depth-wise binary
convolution to learn pruning policies directly through gradient descent. By
combining the structural reparameterization and PaS, we successfully searched
out a new family of VGG-like and lightweight networks, which enable the
flexibility of arbitrary width with respect to each layer instead of each
stage. Experimental results show that our proposed architecture outperforms
prior arts by around $1.0\%$ top-1 accuracy under similar inference speed on
ImageNet-1000 classification task. Furthermore, we demonstrate the
effectiveness of our width search on complex tasks including instance
segmentation and image translation. Code and models are released."
LingYi: Medical Conversational Question Answering System based on Multi-modal Knowledge Graphs,0.221048,"The medical conversational system can relieve the burden of doctors and
improve the efficiency of healthcare, especially during the pandemic. This
paper presents a medical conversational question answering (CQA) system based
on the multi-modal knowledge graph, namely ""LingYi"", which is designed as a
pipeline framework to maintain high flexibility. Our system utilizes automated
medical procedures including medical triage, consultation, image-text drug
recommendation and record. To conduct knowledge-grounded dialogues with
patients, we first construct a Chinese Medical Multi-Modal Knowledge Graph
(CM3KG) and collect a large-scale Chinese Medical CQA (CMCQA) dataset. Compared
with the other existing medical question-answering systems, our system adopts
several state-of-the-art technologies including medical entity disambiguation
and medical dialogue generation, which is more friendly to provide medical
services to patients. In addition, we have open-sourced our codes which contain
back-end models and front-end web pages at https://github.com/WENGSYX/LingYi.
The datasets including CM3KG at https://github.com/WENGSYX/CM3KG and CMCQA at
https://github.com/WENGSYX/CMCQA are also released to further promote future
research."
Semi-Supervised Formality Style Transfer with Consistency Training,0.115217,"Formality style transfer (FST) is a task that involves paraphrasing an
informal sentence into a formal one without altering its meaning. To address
the data-scarcity problem of existing parallel datasets, previous studies tend
to adopt a cycle-reconstruction scheme to utilize additional unlabeled data,
where the FST model mainly benefits from target-side unlabeled sentences. In
this work, we propose a simple yet effective semi-supervised framework to
better utilize source-side unlabeled sentences based on consistency training.
Specifically, our approach augments pseudo-parallel data obtained from a
source-side informal sentence by enforcing the model to generate similar
outputs for its perturbed version. Moreover, we empirically examined the
effects of various data perturbation methods and propose effective data
filtering strategies to improve our framework. Experimental results on the
GYAFC benchmark demonstrate that our approach can achieve state-of-the-art
results, even with less than 40% of the parallel data."
MMFN: Multi-Modal-Fusion-Net for End-to-End Driving,0.226933,"Inspired by the fact that humans use diverse sensory organs to perceive the
world, sensors with different modalities are deployed in end-to-end driving to
obtain the global context of the 3D scene. In previous works, camera and LiDAR
inputs are fused through transformers for better driving performance. These
inputs are normally further interpreted as high-level map information to assist
navigation tasks. Nevertheless, extracting useful information from the complex
map input is challenging, for redundant information may mislead the agent and
negatively affect driving performance. We propose a novel approach to
efficiently extract features from vectorized High-Definition (HD) maps and
utilize them in the end-to-end driving tasks. In addition, we design a new
expert to further enhance the model performance by considering multi-road
rules. Experimental results prove that both of the proposed improvements enable
our agent to achieve superior performance compared with other methods."
Space-based gravitational wave signal detection and extraction with deep neural network,0.120935,"Space-based gravitational wave (GW) detectors will be able to observe signals
from sources that are otherwise nearly impossible from current ground-based
detection. Consequently, the well established signal detection method, matched
filtering, will require a complex template bank, leading to a computational
cost that is too expensive in practice. Here, we develop a high-accuracy GW
signal detection and extraction method for all space-based GW sources. As a
proof of concept, we show that a science-driven and uniform multi-stage
self-attention-based deep neural network can identify synthetic signals that
are submerged in Gaussian noise. Our method exhibits a detection rate exceeding
99% in identifying signals from various sources, with the signal-to-noise ratio
at 50, at a false alarm rate of 1%. while obtaining at least 95% similarity
compared with target signals. We further demonstrate the interpretability and
strong generalization behavior for several extended scenarios."
Real or Fake Text?: Investigating Human Ability to Detect Boundaries Between Human-Written and Machine-Generated Text,0.0643997,"As text generated by large language models proliferates, it becomes vital to
understand how humans engage with such text, and whether or not they are able
to detect when the text they are reading did not originate with a human writer.
Prior work on human detection of generated text focuses on the case where an
entire passage is either human-written or machine-generated. In this paper, we
study a more realistic setting where text begins as human-written and
transitions to being generated by state-of-the-art neural language models. We
show that, while annotators often struggle at this task, there is substantial
variance in annotator skill and that given proper incentives, annotators can
improve at this task over time. Furthermore, we conduct a detailed comparison
study and analyze how a variety of variables (model size, decoding strategy,
fine-tuning, prompt genre, etc.) affect human detection performance. Finally,
we collect error annotations from our participants and use them to show that
certain textual genres influence models to make different types of errors and
that certain sentence-level features correlate highly with annotator selection.
We release the RoFT dataset: a collection of over 21,000 human annotations
paired with error classifications to encourage future work in human detection
and evaluation of generated text."
EA$^2$E: Improving Consistency with Event Awareness for Document-Level Argument Extraction,0.165339,"Events are inter-related in documents. Motivated by the
one-sense-per-discourse theory, we hypothesize that a participant tends to play
consistent roles across multiple events in the same document. However recent
work on document-level event argument extraction models each individual event
in isolation and therefore causes inconsistency among extracted arguments
across events, which will further cause discrepancy for downstream applications
such as event knowledge base population, question answering, and hypothesis
generation. In this work, we formulate event argument consistency as the
constraints from event-event relations under the document-level setting. To
improve consistency we introduce the Event-Aware Argument Extraction (EA$^2$E)
model with augmented context for training and inference. Experiment results on
WIKIEVENTS and ACE2005 datasets demonstrate the effectiveness of EA$^2$E
compared to baseline methods."
Bayesian Optimization under Stochastic Delayed Feedback,0.270697,"Bayesian optimization (BO) is a widely-used sequential method for
zeroth-order optimization of complex and expensive-to-compute black-box
functions. The existing BO methods assume that the function evaluation
(feedback) is available to the learner immediately or after a fixed delay. Such
assumptions may not be practical in many real-life problems like online
recommendations, clinical trials, and hyperparameter tuning where feedback is
available after a random delay. To benefit from the experimental
parallelization in these problems, the learner needs to start new function
evaluations without waiting for delayed feedback. In this paper, we consider
the BO under stochastic delayed feedback problem. We propose algorithms with
sub-linear regret guarantees that efficiently address the dilemma of selecting
new function queries while waiting for randomly delayed feedback. Building on
our results, we also make novel contributions to batch BO and contextual
Gaussian process bandits. Experiments on synthetic and real-life datasets
verify the performance of our algorithms."
Re-Examining Calibration: The Case of Question Answering,0.0333021,"For users to trust model predictions, they need to understand model outputs,
particularly their confidence - calibration aims to adjust (calibrate) models'
confidence to match expected accuracy. We argue that the traditional
calibration evaluation does not promote effective calibrations: for example, it
can encourage always assigning a mediocre confidence score to all predictions,
which does not help users distinguish correct predictions from wrong ones.
Building on those observations, we propose a new calibration metric, MacroCE,
that better captures whether the model assigns low confidence to wrong
predictions and high confidence to correct predictions. Focusing on the
practical application of open-domain question answering, we examine
conventional calibration methods applied on the widely-used retriever-reader
pipeline, all of which do not bring significant gains under our new MacroCE
metric. Toward better calibration, we propose a new calibration method
(ConsCal) that uses not just final model predictions but whether multiple model
checkpoints make consistent predictions. Altogether, we provide an alternative
view of calibration along with a new metric, re-evaluation of existing
calibration methods on our metric, and proposal of a more effective calibration
method."
Quantitative AI Risk Assessments: Opportunities and Challenges,0.371023,"Although AI-based systems are increasingly being leveraged to provide value
to organizations, individuals, and society, significant attendant risks have
been identified. These risks have led to proposed regulations, litigation, and
general societal concerns.
  As with any promising technology, organizations want to benefit from the
positive capabilities of AI technology while reducing the risks. The best way
to reduce risks is to implement comprehensive AI lifecycle governance where
policies and procedures are described and enforced during the design,
development, deployment, and monitoring of an AI system. While support for
comprehensive governance is beginning to emerge, organizations often need to
identify the risks of deploying an already-built model without knowledge of how
it was constructed or access to its original developers.
  Such an assessment will quantitatively assess the risks of an existing model
in a manner analogous to how a home inspector might assess the energy
efficiency of an already-built home or a physician might assess overall patient
health based on a battery of tests. This paper explores the concept of a
quantitative AI Risk Assessment, exploring the opportunities, challenges, and
potential impacts of such an approach, and discussing how it might improve AI
regulations."
MHMS: Multimodal Hierarchical Multimedia Summarization,0.531967,"Multimedia summarization with multimodal output can play an essential role in
real-world applications, i.e., automatically generating cover images and titles
for news articles or providing introductions to online videos. In this work, we
propose a multimodal hierarchical multimedia summarization (MHMS) framework by
interacting visual and language domains to generate both video and textual
summaries. Our MHMS method contains video and textual segmentation and
summarization module, respectively. It formulates a cross-domain alignment
objective with optimal transport distance which leverages cross-domain
interaction to generate the representative keyframe and textual summary. We
evaluated MHMS on three recent multimodal datasets and demonstrated the
effectiveness of our method in producing high-quality multimodal summaries."
Modeling Dual Read/Write Paths for Simultaneous Machine Translation,0.210929,"Simultaneous machine translation (SiMT) outputs translation while reading
source sentence and hence requires a policy to decide whether to wait for the
next source word (READ) or generate a target word (WRITE), the actions of which
form a read/write path. Although the read/write path is essential to SiMT
performance, no direct supervision is given to the path in the existing
methods. In this paper, we propose a method of dual-path SiMT which introduces
duality constraints to direct the read/write path. According to duality
constraints, the read/write path in source-to-target and target-to-source SiMT
models can be mapped to each other. As a result, the two SiMT models can be
optimized jointly by forcing their read/write paths to satisfy the mapping.
Experiments on En-Vi and De-En tasks show that our method can outperform strong
baselines under all latency."
PSP-HDRI$+$: A Synthetic Dataset Generator for Pre-Training of Human-Centric Computer Vision Models,0.265571,"We introduce a new synthetic data generator PSP-HDRI$+$ that proves to be a
superior pre-training alternative to ImageNet and other large-scale synthetic
data counterparts. We demonstrate that pre-training with our synthetic data
will yield a more general model that performs better than alternatives even
when tested on out-of-distribution (OOD) sets. Furthermore, using ablation
studies guided by person keypoint estimation metrics with an off-the-shelf
model architecture, we show how to manipulate our synthetic data generator to
further improve model performance."
Uncertainty-aware Personal Assistant for Making Personalized Privacy Decisions,0.430717,"Many software systems, such as online social networks enable users to share
information about themselves. While the action of sharing is simple, it
requires an elaborate thought process on privacy: what to share, with whom to
share, and for what purposes. Thinking about these for each piece of content to
be shared is tedious. Recent approaches to tackle this problem build personal
assistants that can help users by learning what is private over time and
recommending privacy labels such as private or public to individual content
that a user considers sharing. However, privacy is inherently ambiguous and
highly personal. Existing approaches to recommend privacy decisions do not
address these aspects of privacy sufficiently. Ideally, a personal assistant
should be able to adjust its recommendation based on a given user, considering
that user's privacy understanding. Moreover, the personal assistant should be
able to assess when its recommendation would be uncertain and let the user make
the decision on her own. Accordingly, this paper proposes a personal assistant
that uses evidential deep learning to classify content based on its privacy
label. An important characteristic of the personal assistant is that it can
model its uncertainty in its decisions explicitly, determine that it does not
know the answer, and delegate from making a recommendation when its uncertainty
is high. By factoring in the user's own understanding of privacy, such as risk
factors or own labels, the personal assistant can personalize its
recommendations per user. We evaluate our proposed personal assistant using a
well-known data set. Our results show that our personal assistant can
accurately identify uncertain cases, personalize them to its user's needs, and
thus helps users preserve their privacy well."
OakInk: A Large-scale Knowledge Repository for Understanding Hand-Object Interaction,0.322264,"Learning how humans manipulate objects requires machines to acquire knowledge
from two perspectives: one for understanding object affordances and the other
for learning human's interactions based on the affordances. Even though these
two knowledge bases are crucial, we find that current databases lack a
comprehensive awareness of them. In this work, we propose a multi-modal and
rich-annotated knowledge repository, OakInk, for visual and cognitive
understanding of hand-object interactions. We start to collect 1,800 common
household objects and annotate their affordances to construct the first
knowledge base: Oak. Given the affordance, we record rich human interactions
with 100 selected objects in Oak. Finally, we transfer the interactions on the
100 recorded objects to their virtual counterparts through a novel method:
Tink. The recorded and transferred hand-object interactions constitute the
second knowledge base: Ink. As a result, OakInk contains 50,000 distinct
affordance-aware and intent-oriented hand-object interactions. We benchmark
OakInk on pose estimation and grasp generation tasks. Moreover, we propose two
practical applications of OakInk: intent-based interaction generation and
handover generation. Our datasets and source code are publicly available at
https://github.com/lixiny/OakInk."
Code-Switching without Switching: Language Agnostic End-to-End Speech Translation,0.0542562,"We propose a) a Language Agnostic end-to-end Speech Translation model (LAST),
and b) a data augmentation strategy to increase code-switching (CS)
performance. With increasing globalization, multiple languages are increasingly
used interchangeably during fluent speech. Such CS complicates traditional
speech recognition and translation, as we must recognize which language was
spoken first and then apply a language-dependent recognizer and subsequent
translation component to generate the desired target language output. Such a
pipeline introduces latency and errors. In this paper, we eliminate the need
for that, by treating speech recognition and translation as one unified
end-to-end speech translation problem. By training LAST with both input
languages, we decode speech into one target language, regardless of the input
language. LAST delivers comparable recognition and speech translation accuracy
in monolingual usage, while reducing latency and error rate considerably when
CS is observed."
Hybrid Multimodal Fusion for Humor Detection,0.0982724,"In this paper, we present our solution to the MuSe-Humor sub-challenge of the
Multimodal Emotional Challenge (MuSe) 2022. The goal of the MuSe-Humor
sub-challenge is to detect humor and calculate AUC from audiovisual recordings
of German football Bundesliga press conferences. It is annotated for humor
displayed by the coaches. For this sub-challenge, we first build a discriminant
model using the transformer module and BiLSTM module, and then propose a hybrid
fusion strategy to use the prediction results of each modality to improve the
performance of the model. Our experiments demonstrate the effectiveness of our
proposed model and hybrid fusion strategy on multimodal fusion, and the AUC of
our proposed model on the test set is 0.8972."
Semantic properties of English nominal pluralization: Insights from word embeddings,0.120653,"Semantic differentiation of nominal pluralization is grammaticalized in many
languages. For example, plural markers may only be relevant for human nouns.
English does not appear to make such distinctions. Using distributional
semantics, we show that English nominal pluralization exhibits semantic
clusters. For instance, pluralization of fruit words is more similar to one
another and less similar to pluralization of other semantic classes. Therefore,
reduction of the meaning shift in plural formation to the addition of an
abstract plural meaning is too simplistic. A semantically informed method,
called CosClassAvg, is introduced that outperforms pluralization methods in
distributional semantics which assume plural formation amounts to the addition
of a fixed plural vector. In comparison with our approach, a method from
compositional distributional semantics, called FRACSS, predicted plural vectors
that were more similar to the corpus-extracted plural vectors in terms of
direction but not vector length. A modeling study reveals that the observed
difference between the two predicted semantic spaces by CosClassAvg and FRACSS
carries over to how well a computational model of the listener can understand
previously unencountered plural forms. Mappings from word forms, represented
with triphone vectors, to predicted semantic vectors are more productive when
CosClassAvg-generated semantic vectors are employed as gold standard vectors
instead of FRACSS-generated vectors."
Instance-specific and Model-adaptive Supervision for Semi-supervised Semantic Segmentation,0.150523,"Recently, semi-supervised semantic segmentation has achieved promising
performance with a small fraction of labeled data. However, most existing
studies treat all unlabeled data equally and barely consider the differences
and training difficulties among unlabeled instances. Differentiating unlabeled
instances can promote instance-specific supervision to adapt to the model's
evolution dynamically. In this paper, we emphasize the cruciality of instance
differences and propose an instance-specific and model-adaptive supervision for
semi-supervised semantic segmentation, named iMAS. Relying on the model's
performance, iMAS employs a class-weighted symmetric intersection-over-union to
evaluate quantitative hardness of each unlabeled instance and supervises the
training on unlabeled data in a model-adaptive manner. Specifically, iMAS
learns from unlabeled instances progressively by weighing their corresponding
consistency losses based on the evaluated hardness. Besides, iMAS dynamically
adjusts the augmentation for each instance such that the distortion degree of
augmented instances is adapted to the model's generalization capability across
the training course. Not integrating additional losses and training procedures,
iMAS can obtain remarkable performance gains against current state-of-the-art
approaches on segmentation benchmarks under different semi-supervised partition
protocols."
Temporal Attention for Language Models,0.148747,"Pretrained language models based on the transformer architecture have shown
great success in NLP. Textual training data often comes from the web and is
thus tagged with time-specific information, but most language models ignore
this information. They are trained on the textual data alone, limiting their
ability to generalize temporally. In this work, we extend the key component of
the transformer architecture, i.e., the self-attention mechanism, and propose
temporal attention - a time-aware self-attention mechanism. Temporal attention
can be applied to any transformer model and requires the input texts to be
accompanied with their relevant time points. It allows the transformer to
capture this temporal information and create time-specific contextualized word
representations. We leverage these representations for the task of semantic
change detection; we apply our proposed mechanism to BERT and experiment on
three datasets in different languages (English, German, and Latin) that also
vary in time, size, and genre. Our proposed model achieves state-of-the-art
results on all the datasets."
Memory-free Online Change-point Detection: A Novel Neural Network Approach,0.0794887,"Change-point detection (CPD), which detects abrupt changes in the data
distribution, is recognized as one of the most significant tasks in time series
analysis. Despite the extensive literature on offline CPD, unsupervised online
CPD still suffers from major challenges, including scalability, hyperparameter
tuning, and learning constraints. To mitigate some of these challenges, in this
paper, we propose a novel deep learning approach for unsupervised online CPD
from multi-dimensional time series, named Adaptive LSTM-Autoencoder
Change-Point Detection (ALACPD). ALACPD exploits an LSTM-autoencoder-based
neural network to perform unsupervised online CPD. It continuously adapts to
the incoming samples without keeping the previously received input, thus being
memory-free. We perform an extensive evaluation on several real-world time
series CPD benchmarks. We show that ALACPD, on average, ranks first among
state-of-the-art CPD algorithms in terms of quality of the time series
segmentation, and it is on par with the best performer in terms of the accuracy
of the estimated change-points. The implementation of ALACPD is available
online on Github\footnote{\url{https://github.com/zahraatashgahi/ALACPD}}."
Tractable Boolean and Arithmetic Circuits,0.0596396,"Tractable Boolean and arithmetic circuits have been studied extensively in AI
for over two decades now. These circuits were initially proposed as ""compiled
objects,"" meant to facilitate logical and probabilistic reasoning, as they
permit various types of inference to be performed in linear-time and a
feed-forward fashion like neural networks. In more recent years, the role of
tractable circuits has significantly expanded as they became a computational
and semantical backbone for some approaches that aim to integrate knowledge,
reasoning and learning. In this article, we review the foundations of tractable
circuits and some associated milestones, while focusing on their core
properties and techniques that make them particularly useful for the broad aims
of neuro-symbolic AI."
Deformable Butterfly: A Highly Structured and Sparse Linear Transform,0.093142,"We introduce a new kind of linear transform named Deformable Butterfly
(DeBut) that generalizes the conventional butterfly matrices and can be adapted
to various input-output dimensions. It inherits the fine-to-coarse-grained
learnable hierarchy of traditional butterflies and when deployed to neural
networks, the prominent structures and sparsity in a DeBut layer constitutes a
new way for network compression. We apply DeBut as a drop-in replacement of
standard fully connected and convolutional layers, and demonstrate its
superiority in homogenizing a neural network and rendering it favorable
properties such as light weight and low inference complexity, without
compromising accuracy. The natural complexity-accuracy tradeoff arising from
the myriad deformations of a DeBut layer also opens up new rooms for analytical
and practical research. The codes and Appendix are publicly available at:
https://github.com/ruilin0212/DeBut."
Dual-Geometric Space Embedding Model for Two-View Knowledge Graphs,0.21976,"Two-view knowledge graphs (KGs) jointly represent two components: an ontology
view for abstract and commonsense concepts, and an instance view for specific
entities that are instantiated from ontological concepts. As such, these KGs
contain heterogeneous structures that are hierarchical, from the ontology-view,
and cyclical, from the instance-view. Despite these various structures in KGs,
most recent works on embedding KGs assume that the entire KG belongs to only
one of the two views but not both simultaneously. For works that seek to put
both views of the KG together, the instance and ontology views are assumed to
belong to the same geometric space, such as all nodes embedded in the same
Euclidean space or non-Euclidean product space, an assumption no longer
reasonable for two-view KGs where different portions of the graph exhibit
different structures. To address this issue, we define and construct a
dual-geometric space embedding model (DGS) that models two-view KGs using a
complex non-Euclidean geometric space, by embedding different portions of the
KG in different geometric spaces. DGS utilizes the spherical space, hyperbolic
space, and their intersecting space in a unified framework for learning
embeddings. Furthermore, for the spherical space, we propose novel closed
spherical space operators that directly operate in the spherical space without
the need for mapping to an approximate tangent space. Experiments on public
datasets show that DGS significantly outperforms previous state-of-the-art
baseline models on KG completion tasks, demonstrating its ability to better
model heterogeneous structures in KGs."
Acquiring and Modelling Abstract Commonsense Knowledge via Conceptualization,0.0358678,"Conceptualization, or viewing entities and situations as instances of
abstract concepts in mind and making inferences based on that, is a vital
component in human intelligence for commonsense reasoning. Although recent
artificial intelligence has made progress in acquiring and modelling
commonsense, attributed to large neural language models and commonsense
knowledge graphs (CKGs), conceptualization is yet to thoroughly be introduced,
making current approaches ineffective to cover knowledge about countless
diverse entities and situations in the real world. To address the problem, we
thoroughly study the possible role of conceptualization in commonsense
reasoning, and formulate a framework to replicate human conceptual induction
from acquiring abstract knowledge about abstract concepts. Aided by the
taxonomy Probase, we develop tools for contextualized conceptualization on
ATOMIC, a large-scale human annotated CKG. We annotate a dataset for the
validity of conceptualizations for ATOMIC on both event and triple level,
develop a series of heuristic rules based on linguistic features, and train a
set of neural models, so as to generate and verify abstract knowledge. Based on
these components, a pipeline to acquire abstract knowledge is built. A large
abstract CKG upon ATOMIC is then induced, ready to be instantiated to infer
about unseen entities or situations. Furthermore, experiments find directly
augmenting data with abstract triples to be helpful in commonsense modelling."
Combining Lipschitz and RBF Surrogate Models for High-dimensional Computationally Expensive Problems,0.116432,"Standard evolutionary optimization algorithms assume that the evaluation of
the objective and constraint functions is straightforward and computationally
cheap. However, in many real-world optimization problems, these evaluations
involve computationally expensive numerical simulations or physical
experiments. Surrogate-assisted evolutionary algorithms (SAEAs) have recently
gained increased attention for their performance in solving these types of
problems. The main idea of SAEAs is the integration of an evolutionary
algorithm with a selected surrogate model that approximates the computationally
expensive function. In this paper, we propose a surrogate model based on a
Lipschitz underestimation and use it to develop a differential evolution-based
algorithm. The algorithm, called Lipschitz Surrogate-assisted Differential
Evolution (LSADE), utilizes the Lipschitz-based surrogate model, along with a
standard radial basis function surrogate model and a local search procedure.
The experimental results on seven benchmark functions of dimensions 30, 50,
100, and 200 show that the proposed LSADE algorithm is competitive compared
with the state-of-the-art algorithms under a limited computational budget,
being especially effective for the very complicated benchmark functions in high
dimensions."
Detecting Methane Plumes using PRISMA: Deep Learning Model and Data Augmentation,0.367364,"The new generation of hyperspectral imagers, such as PRISMA, has improved
significantly our detection capability of methane (CH4) plumes from space at
high spatial resolution (30m). We present here a complete framework to identify
CH4 plumes using images from the PRISMA satellite mission and a deep learning
model able to detect plumes over large areas. To compensate for the relative
scarcity of PRISMA images, we trained our model by transposing high resolution
plumes from Sentinel-2 to PRISMA. Our methodology thus avoids computationally
expensive synthetic plume generation from Large Eddy Simulations by generating
a broad and realistic training database, and paves the way for large-scale
detection of methane plumes using future hyperspectral sensors (EnMAP, EMIT,
CarbonMapper)."
Semi-Supervised Single-View 3D Reconstruction via Prototype Shape Priors,0.116221,"The performance of existing single-view 3D reconstruction methods heavily
relies on large-scale 3D annotations. However, such annotations are tedious and
expensive to collect. Semi-supervised learning serves as an alternative way to
mitigate the need for manual labels, but remains unexplored in 3D
reconstruction. Inspired by the recent success of semi-supervised image
classification tasks, we propose SSP3D, a semi-supervised framework for 3D
reconstruction. In particular, we introduce an attention-guided prototype shape
prior module for guiding realistic object reconstruction. We further introduce
a discriminator-guided module to incentivize better shape generation, as well
as a regularizer to tolerate noisy training samples. On the ShapeNet benchmark,
the proposed approach outperforms previous supervised methods by clear margins
under various labeling ratios, (i.e., 1%, 5% , 10% and 20%). Moreover, our
approach also performs well when transferring to real-world Pix3D datasets
under labeling ratios of 10%. We also demonstrate our method could transfer to
novel categories with few novel supervised data. Experiments on the popular
ShapeNet dataset show that our method outperforms the zero-shot baseline by
over 12% and we also perform rigorous ablations and analysis to validate our
approach."
Physics-aware Differentiable Discrete Codesign for Diffractive Optical Neural Networks,0.228352,"Diffractive optical neural networks (DONNs) have attracted lots of attention
as they bring significant advantages in terms of power efficiency, parallelism,
and computational speed compared with conventional deep neural networks (DNNs),
which have intrinsic limitations when implemented on digital platforms.
However, inversely mapping algorithm-trained physical model parameters onto
real-world optical devices with discrete values is a non-trivial task as
existing optical devices have non-unified discrete levels and non-monotonic
properties. This work proposes a novel device-to-system hardware-software
codesign framework, which enables efficient physics-aware training of DONNs
w.r.t arbitrary experimental measured optical devices across layers.
Specifically, Gumbel-Softmax is employed to enable differentiable discrete
mapping from real-world device parameters into the forward function of DONNs,
where the physical parameters in DONNs can be trained by simply minimizing the
loss function of the ML task. The results have demonstrated that our proposed
framework offers significant advantages over conventional quantization-based
methods, especially with low-precision optical devices. Finally, the proposed
algorithm is fully verified with physical experimental optical systems in
low-precision settings."
Constrained Dynamic Movement Primitives for Safe Learning of Motor Skills,0.147097,"Dynamic movement primitives are widely used for learning skills which can be
demonstrated to a robot by a skilled human or controller. While their
generalization capabilities and simple formulation make them very appealing to
use, they possess no strong guarantees to satisfy operational safety
constraints for a task. In this paper, we present constrained dynamic movement
primitives (CDMP) which can allow for constraint satisfaction in the robot
workspace. We present a formulation of a non-linear optimization to perturb the
DMP forcing weights regressed by locally-weighted regression to admit a Zeroing
Barrier Function (ZBF), which certifies workspace constraint satisfaction. We
demonstrate the proposed CDMP under different constraints on the end-effector
movement such as obstacle avoidance and workspace constraints on a physical
robot. A video showing the implementation of the proposed algorithm using
different manipulators in different environments could be found here
https://youtu.be/hJegJJkJfys."
g2pW: A Conditional Weighted Softmax BERT for Polyphone Disambiguation in Mandarin,0.0553972,"Polyphone disambiguation is the most crucial task in Mandarin
grapheme-to-phoneme (g2p) conversion. Previous studies have approached this
problem using pre-trained language models, restricted output, and extra
information from Part-Of-Speech (POS) tagging. Inspired by these strategies, we
propose a novel approach, called g2pW, which adapts learnable softmax-weights
to condition the outputs of BERT with the polyphonic character of interest and
its POS tagging. Rather than using the hard mask as in previous works, our
experiments show that learning a soft-weighting function for the candidate
phonemes benefits performance. In addition, our proposed g2pW does not require
extra pre-trained POS tagging models while using POS tags as auxiliary features
since we train the POS tagging model simultaneously with the unified encoder.
Experimental results show that our g2pW outperforms existing methods on the
public CPP dataset. All codes, model weights, and a user-friendly package are
publicly available."
Hierarchical Multi-Label Classification of Scientific Documents,0.208434,"Automatic topic classification has been studied extensively to assist
managing and indexing scientific documents in a digital collection. With the
large number of topics being available in recent years, it has become necessary
to arrange them in a hierarchy. Therefore, the automatic classification systems
need to be able to classify the documents hierarchically. In addition, each
paper is often assigned to more than one relevant topic. For example, a paper
can be assigned to several topics in a hierarchy tree. In this paper, we
introduce a new dataset for hierarchical multi-label text classification
(HMLTC) of scientific papers called SciHTC, which contains 186,160 papers and
1,233 categories from the ACM CCS tree. We establish strong baselines for HMLTC
and propose a multi-task learning approach for topic classification with
keyword labeling as an auxiliary task. Our best model achieves a Macro-F1 score
of 34.57% which shows that this dataset provides significant research
opportunities on hierarchical scientific topic classification. We make our
dataset and code available on Github."
BLASER: A Text-Free Speech-to-Speech Translation Evaluation Metric,0.0503552,"End-to-End speech-to-speech translation (S2ST) is generally evaluated with
text-based metrics. This means that generated speech has to be automatically
transcribed, making the evaluation dependent on the availability and quality of
automatic speech recognition (ASR) systems. In this paper, we propose a
text-free evaluation metric for end-to-end S2ST, named BLASER, to avoid the
dependency on ASR systems. BLASER leverages a multilingual multimodal encoder
to directly encode the speech segments for source input, translation output and
reference into a shared embedding space and computes a score of the translation
quality that can be used as a proxy to human evaluation. To evaluate our
approach, we construct training and evaluation sets from more than 40k human
annotations covering seven language directions. The best results of BLASER are
achieved by training with supervision from human rating scores. We show that
when evaluated at the sentence level, BLASER correlates significantly better
with human judgment compared to ASR-dependent metrics including ASR-SENTBLEU in
all translation directions and ASR-COMET in five of them. Our analysis shows
combining speech and text as inputs to BLASER does not increase the correlation
with human scores, but best correlations are achieved when using speech, which
motivates the goal of our research. Moreover, we show that using ASR for
references is detrimental for text-based metrics."
Discovering Transferable Forensic Features for CNN-generated Images Detection,0.23843,"Visual counterfeits are increasingly causing an existential conundrum in
mainstream media with rapid evolution in neural image synthesis methods. Though
detection of such counterfeits has been a taxing problem in the image forensics
community, a recent class of forensic detectors -- universal detectors -- are
able to surprisingly spot counterfeit images regardless of generator
architectures, loss functions, training datasets, and resolutions. This
intriguing property suggests the possible existence of transferable forensic
features (T-FF) in universal detectors. In this work, we conduct the first
analytical study to discover and understand T-FF in universal detectors. Our
contributions are 2-fold: 1) We propose a novel forensic feature relevance
statistic (FF-RS) to quantify and discover T-FF in universal detectors and, 2)
Our qualitative and quantitative investigations uncover an unexpected finding:
color is a critical T-FF in universal detectors. Code and models are available
at https://keshik6.github.io/transferable-forensic-features/"
TIE: Topological Information Enhanced Structural Reading Comprehension on Web Pages,0.105113,"Recently, the structural reading comprehension (SRC) task on web pages has
attracted increasing research interests. Although previous SRC work has
leveraged extra information such as HTML tags or XPaths, the informative
topology of web pages is not effectively exploited. In this work, we propose a
Topological Information Enhanced model (TIE), which transforms the token-level
task into a tag-level task by introducing a two-stage process (i.e. node
locating and answer refining). Based on that, TIE integrates Graph Attention
Network (GAT) and Pre-trained Language Model (PLM) to leverage the topological
information of both logical structures and spatial structures. Experimental
results demonstrate that our model outperforms strong baselines and achieves
state-of-the-art performances on the web-based SRC benchmark WebSRC at the time
of writing. The code of TIE will be publicly available at
https://github.com/X-LANCE/TIE."
A Simple and Powerful Global Optimization for Unsupervised Video Object Segmentation,0.124055,"We propose a simple, yet powerful approach for unsupervised object
segmentation in videos. We introduce an objective function whose minimum
represents the mask of the main salient object over the input sequence. It only
relies on independent image features and optical flows, which can be obtained
using off-the-shelf self-supervised methods. It scales with the length of the
sequence with no need for superpixels or sparsification, and it generalizes to
different datasets without any specific training. This objective function can
actually be derived from a form of spectral clustering applied to the entire
video. Our method achieves on-par performance with the state of the art on
standard benchmarks (DAVIS2016, SegTrack-v2, FBMS59), while being conceptually
and practically much simpler. Code is available at
https://ponimatkin.github.io/ssl-vos."
What Do Compressed Multilingual Machine Translation Models Forget?,0.131039,"Recently, very large pre-trained models achieve state-of-the-art results in
various natural language processing (NLP) tasks, but their size makes it more
challenging to apply them in resource-constrained environments. Compression
techniques allow to drastically reduce the size of the models and therefore
their inference time with negligible impact on top-tier metrics. However, the
general performance averaged across multiple tasks and/or languages may hide a
drastic performance drop on under-represented features, which could result in
the amplification of biases encoded by the models. In this work, we assess the
impact of compression methods on Multilingual Neural Machine Translation models
(MNMT) for various language groups, gender, and semantic biases by extensive
analysis of compressed models on different machine translation benchmarks, i.e.
FLORES-101, MT-Gender, and DiBiMT. We show that the performance of
under-represented languages drops significantly, while the average BLEU metric
only slightly decreases. Interestingly, the removal of noisy memorization with
compression leads to a significant improvement for some medium-resource
languages. Finally, we demonstrate that compression amplifies intrinsic gender
and semantic biases, even in high-resource languages. Code:
https://github.com/alirezamshi/bias-compressedMT"
RMGN: A Regional Mask Guided Network for Parser-free Virtual Try-on,-1.0,"Virtual try-on(VTON) aims at fitting target clothes to reference person
images, which is widely adopted in e-commerce.Existing VTON approaches can be
narrowly categorized into Parser-Based(PB) and Parser-Free(PF) by whether
relying on the parser information to mask the persons' clothes and synthesize
try-on images. Although abandoning parser information has improved the
applicability of PF methods, the ability of detail synthesizing has also been
sacrificed. As a result, the distraction from original cloth may persistin
synthesized images, especially in complicated postures and high resolution
applications. To address the aforementioned issue, we propose a novel PF method
named Regional Mask Guided Network(RMGN). More specifically, a regional mask is
proposed to explicitly fuse the features of target clothes and reference
persons so that the persisted distraction can be eliminated. A posture
awareness loss and a multi-level feature extractor are further proposed to
handle the complicated postures and synthesize high resolution images.
Extensive experiments demonstrate that our proposed RMGN outperforms both
state-of-the-art PB and PF methods.Ablation studies further verify the
effectiveness ofmodules in RMGN."
Structured Local Radiance Fields for Human Avatar Modeling,0.38099,"It is extremely challenging to create an animatable clothed human avatar from
RGB videos, especially for loose clothes due to the difficulties in motion
modeling. To address this problem, we introduce a novel representation on the
basis of recent neural scene rendering techniques. The core of our
representation is a set of structured local radiance fields, which are anchored
to the pre-defined nodes sampled on a statistical human body template. These
local radiance fields not only leverage the flexibility of implicit
representation in shape and appearance modeling, but also factorize cloth
deformations into skeleton motions, node residual translations and the dynamic
detail variations inside each individual radiance field. To learn our
representation from RGB data and facilitate pose generalization, we propose to
learn the node translations and the detail variations in a conditional
generative latent space. Overall, our method enables automatic construction of
animatable human avatars for various types of clothes without the need for
scanning subject-specific templates, and can generate realistic images with
dynamic details for novel poses. Experiment show that our method outperforms
state-of-the-art methods both qualitatively and quantitatively."
"Mapping the Multilingual Margins: Intersectional Biases of Sentiment Analysis Systems in English, Spanish, and Arabic",0.0759378,"As natural language processing systems become more widespread, it is
necessary to address fairness issues in their implementation and deployment to
ensure that their negative impacts on society are understood and minimized.
However, there is limited work that studies fairness using a multilingual and
intersectional framework or on downstream tasks. In this paper, we introduce
four multilingual Equity Evaluation Corpora, supplementary test sets designed
to measure social biases, and a novel statistical framework for studying
unisectional and intersectional social biases in natural language processing.
We use these tools to measure gender, racial, ethnic, and intersectional social
biases across five models trained on emotion regression tasks in English,
Spanish, and Arabic. We find that many systems demonstrate statistically
significant unisectional and intersectional social biases."
CrowdMLP: Weakly-Supervised Crowd Counting via Multi-Granularity MLP,0.497148,"Existing state-of-the-art crowd counting algorithms rely excessively on
location-level annotations, which are burdensome to acquire. When only
count-level (weak) supervisory signals are available, it is arduous and
error-prone to regress total counts due to the lack of explicit spatial
constraints. To address this issue, a novel and efficient counter (referred to
as CrowdMLP) is presented, which probes into modelling global dependencies of
embeddings and regressing total counts by devising a multi-granularity MLP
regressor. In specific, a locally-focused pre-trained frontend is cascaded to
extract crude feature maps with intrinsic spatial cues, which prevent the model
from collapsing into trivial outcomes. The crude embeddings, along with raw
crowd scenes, are tokenized at different granularity levels. The
multi-granularity MLP then proceeds to mix tokens at the dimensions of
cardinality, channel, and spatial for mining global information. An effective
proxy task, namely Split-Counting, is also proposed to evade the barrier of
limited samples and the shortage of spatial hints in a self-supervised manner.
Extensive experiments demonstrate that CrowdMLP significantly outperforms
existing weakly-supervised counting algorithms and performs on par with
state-of-the-art location-level supervised approaches."
Learning Disentangled Textual Representations via Statistical Measures of Similarity,0.136846,"When working with textual data, a natural application of disentangled
representations is fair classification where the goal is to make predictions
without being biased (or influenced) by sensitive attributes that may be
present in the data (e.g., age, gender or race). Dominant approaches to
disentangle a sensitive attribute from textual representations rely on learning
simultaneously a penalization term that involves either an adversarial loss
(e.g., a discriminator) or an information measure (e.g., mutual information).
However, these methods require the training of a deep neural network with
several parameter updates for each update of the representation model. As a
matter of fact, the resulting nested optimization loop is both time consuming,
adding complexity to the optimization dynamic, and requires a fine
hyperparameter selection (e.g., learning rates, architecture). In this work, we
introduce a family of regularizers for learning disentangled representations
that do not require training. These regularizers are based on statistical
measures of similarity between the conditional probability distributions with
respect to the sensitive attributes. Our novel regularizers do not require
additional training, are faster and do not involve additional tuning while
achieving better results both when combined with pretrained and randomly
initialized text encoders."
BERT on a Data Diet: Finding Important Examples by Gradient-Based Pruning,0.0283117,"Current pre-trained language models rely on large datasets for achieving
state-of-the-art performance. However, past research has shown that not all
examples in a dataset are equally important during training. In fact, it is
sometimes possible to prune a considerable fraction of the training set while
maintaining the test performance. Established on standard vision benchmarks,
two gradient-based scoring metrics for finding important examples are GraNd and
its estimated version, EL2N. In this work, we employ these two metrics for the
first time in NLP. We demonstrate that these metrics need to be computed after
at least one epoch of fine-tuning and they are not reliable in early steps.
Furthermore, we show that by pruning a small portion of the examples with the
highest GraNd/EL2N scores, we can not only preserve the test accuracy, but also
surpass it. This paper details adjustments and implementation choices which
enable GraNd and EL2N to be applied to NLP."
SimANS: Simple Ambiguous Negatives Sampling for Dense Text Retrieval,0.440908,"Sampling proper negatives from a large document pool is vital to effectively
train a dense retrieval model. However, existing negative sampling strategies
suffer from the uninformative or false negative problem. In this work, we
empirically show that according to the measured relevance scores, the negatives
ranked around the positives are generally more informative and less likely to
be false negatives. Intuitively, these negatives are not too hard (\emph{may be
false negatives}) or too easy (\emph{uninformative}). They are the ambiguous
negatives and need more attention during training. Thus, we propose a simple
ambiguous negatives sampling method, SimANS, which incorporates a new sampling
probability distribution to sample more ambiguous negatives. Extensive
experiments on four public and one industry datasets show the effectiveness of
our approach. We made the code and models publicly available in
\url{https://github.com/microsoft/SimXNS}."
End-to-end model for named entity recognition from speech without paired training data,0.0616857,"Recent works showed that end-to-end neural approaches tend to become very
popular for spoken language understanding (SLU). Through the term end-to-end,
one considers the use of a single model optimized to extract semantic
information directly from the speech signal. A major issue for such models is
the lack of paired audio and textual data with semantic annotation. In this
paper, we propose an approach to build an end-to-end neural model to extract
semantic information in a scenario in which zero paired audio data is
available. Our approach is based on the use of an external model trained to
generate a sequence of vectorial representations from text. These
representations mimic the hidden representations that could be generated inside
an end-to-end automatic speech recognition (ASR) model by processing a speech
signal. An SLU neural module is then trained using these representations as
input and the annotated text as output. Last, the SLU module replaces the top
layers of the ASR model to achieve the construction of the end-to-end model.
Our experiments on named entity recognition, carried out on the QUAERO corpus,
show that this approach is very promising, getting better results than a
comparable cascade approach or than the use of synthetic voices."
ATP: AMRize Then Parse! Enhancing AMR Parsing with PseudoAMRs,0.076371,"As Abstract Meaning Representation (AMR) implicitly involves compound
semantic annotations, we hypothesize auxiliary tasks which are semantically or
formally related can better enhance AMR parsing. We find that 1) Semantic role
labeling (SRL) and dependency parsing (DP), would bring more performance gain
than other tasks e.g. MT and summarization in the text-to-AMR transition even
with much less data. 2) To make a better fit for AMR, data from auxiliary tasks
should be properly ""AMRized"" to PseudoAMR before training. Knowledge from
shallow level parsing tasks can be better transferred to AMR Parsing with
structure transform. 3) Intermediate-task learning is a better paradigm to
introduce auxiliary tasks to AMR parsing, compared to multitask learning. From
an empirical perspective, we propose a principled method to involve auxiliary
tasks to boost AMR parsing. Extensive experiments show that our method achieves
new state-of-the-art performance on different benchmarks especially in
topology-related scores."
Generalizing to the Future: Mitigating Entity Bias in Fake News Detection,0.203824,"The wide dissemination of fake news is increasingly threatening both
individuals and society. Fake news detection aims to train a model on the past
news and detect fake news of the future. Though great efforts have been made,
existing fake news detection methods overlooked the unintended entity bias in
the real-world data, which seriously influences models' generalization ability
to future data. For example, 97\% of news pieces in 2010-2017 containing the
entity `Donald Trump' are real in our data, but the percentage falls down to
merely 33\% in 2018. This would lead the model trained on the former set to
hardly generalize to the latter, as it tends to predict news pieces about
`Donald Trump' as real for lower training loss. In this paper, we propose an
entity debiasing framework (\textbf{ENDEF}) which generalizes fake news
detection models to the future data by mitigating entity bias from a
cause-effect perspective. Based on the causal graph among entities, news
contents, and news veracity, we separately model the contribution of each cause
(entities and contents) during training. In the inference stage, we remove the
direct effect of the entities to mitigate entity bias. Extensive offline
experiments on the English and Chinese datasets demonstrate that the proposed
framework can largely improve the performance of base fake news detectors, and
online tests verify its superiority in practice. To the best of our knowledge,
this is the first work to explicitly improve the generalization ability of fake
news detection models to the future data. The code has been released at
https://github.com/ICTMCG/ENDEF-SIGIR2022."
A Framework for Multi-stage Bonus Allocation in meal delivery Platform,0.241812,"Online meal delivery is undergoing explosive growth, as this service is
becoming increasingly popular. A meal delivery platform aims to provide
excellent and stable services for customers and restaurants. However, in
reality, several hundred thousand orders are canceled per day in the Meituan
meal delivery platform since they are not accepted by the crowd soucing
drivers. The cancellation of the orders is incredibly detrimental to the
customer's repurchase rate and the reputation of the Meituan meal delivery
platform. To solve this problem, a certain amount of specific funds is provided
by Meituan's business managers to encourage the crowdsourcing drivers to accept
more orders. To make better use of the funds, in this work, we propose a
framework to deal with the multi-stage bonus allocation problem for a meal
delivery platform. The objective of this framework is to maximize the number of
accepted orders within a limited bonus budget. This framework consists of a
semi-black-box acceptance probability model, a Lagrangian dual-based dynamic
programming algorithm, and an online allocation algorithm. The semi-black-box
acceptance probability model is employed to forecast the relationship between
the bonus allocated to order and its acceptance probability, the Lagrangian
dual-based dynamic programming algorithm aims to calculate the empirical
Lagrangian multiplier for each allocation stage offline based on the historical
data set, and the online allocation algorithm uses the results attained in the
offline part to calculate a proper delivery bonus for each order. To verify the
effectiveness and efficiency of our framework, both offline experiments on a
real-world data set and online A/B tests on the Meituan meal delivery platform
are conducted. Our results show that using the proposed framework, the total
order cancellations can be decreased by more than 25\% in reality."
Ultrahyperbolic Knowledge Graph Embeddings,0.250377,"Recent knowledge graph (KG) embeddings have been advanced by hyperbolic
geometry due to its superior capability for representing hierarchies. The
topological structures of real-world KGs, however, are rather heterogeneous,
i.e., a KG is composed of multiple distinct hierarchies and non-hierarchical
graph structures. Therefore, a homogeneous (either Euclidean or hyperbolic)
geometry is not sufficient for fairly representing such heterogeneous
structures. To capture the topological heterogeneity of KGs, we present an
ultrahyperbolic KG embedding (UltraE) in an ultrahyperbolic (or
pseudo-Riemannian) manifold that seamlessly interleaves hyperbolic and
spherical manifolds. In particular, we model each relation as a
pseudo-orthogonal transformation that preserves the pseudo-Riemannian bilinear
form. The pseudo-orthogonal transformation is decomposed into various operators
(i.e., circular rotations, reflections and hyperbolic rotations), allowing for
simultaneously modeling heterogeneous structures as well as complex relational
patterns. Experimental results on three standard KGs show that UltraE
outperforms previous Euclidean- and hyperbolic-based approaches."
Adversarial Contrastive Learning for Evidence-aware Fake News Detection with Graph Neural Networks,0.171328,"The prevalence and perniciousness of fake news have been a critical issue on
the Internet, which stimulates the development of automatic fake news detection
in turn. In this paper, we focus on evidence-based fake news detection, where
several evidences are utilized to probe the veracity of news (i.e., a claim).
Most previous methods first employ sequential models to embed the semantic
information and then capture the claim-evidence interaction based on attention
mechanisms. Despite their effectiveness, they still suffer from three
weaknesses. Firstly, sequential models fail to integrate the relevant
information that is scattered far apart in evidences. Secondly, they
underestimate much redundant information in evidences may be useless or
harmful. Thirdly, insufficient data utilization limits the separability and
reliability of representations captured by the model. To solve these problems,
we propose a unified Graph-based sEmantic structure mining framework with
ConTRAstive Learning, namely GETRAL in short. Specifically, we first model
claims and evidences as graph-structured data to capture the long-distance
semantic dependency. Consequently, we reduce information redundancy by
performing graph structure learning. Then the fine-grained semantic
representations are fed into the claim-evidence interaction module for
predictions. Finally, an adversarial contrastive learning module is applied to
make full use of data and strengthen representation learning. Comprehensive
experiments have demonstrated the superiority of GETRAL over the
state-of-the-arts and validated the efficacy of semantic mining with graph
structure and contrastive learning."
"Fewer Errors, but More Stereotypes? The Effect of Model Size on Gender Bias",0.233482,"The size of pretrained models is increasing, and so is their performance on a
variety of NLP tasks. However, as their memorization capacity grows, they might
pick up more social biases. In this work, we examine the connection between
model size and its gender bias (specifically, occupational gender bias). We
measure bias in three masked language model families (RoBERTa, DeBERTa, and T5)
in two setups: directly using prompt based method, and using a downstream task
(Winogender). We find on the one hand that larger models receive higher bias
scores on the former task, but when evaluated on the latter, they make fewer
gender errors. To examine these potentially conflicting results, we carefully
investigate the behavior of the different models on Winogender. We find that
while larger models outperform smaller ones, the probability that their
mistakes are caused by gender bias is higher. Moreover, we find that the
proportion of stereotypical errors compared to anti-stereotypical ones grows
with the model size. Our findings highlight the potential risks that can arise
from increasing model size."
Interpretable Hidden Markov Model-Based Deep Reinforcement Learning Hierarchical Framework for Predictive Maintenance of Turbofan Engines,0.0707783,"An open research question in deep reinforcement learning is how to focus the
policy learning of key decisions within a sparse domain. This paper emphasizes
combining the advantages of inputoutput hidden Markov models and reinforcement
learning towards interpretable maintenance decisions. We propose a novel
hierarchical-modeling methodology that, at a high level, detects and interprets
the root cause of a failure as well as the health degradation of the turbofan
engine, while, at a low level, it provides the optimal replacement policy. It
outperforms the baseline performance of deep reinforcement learning methods
applied directly to the raw data or when using a hidden Markov model without
such a specialized hierarchy. It also provides comparable performance to prior
work, however, with the additional benefit of interpretability."
py-irt: A Scalable Item Response Theory Library for Python,0.0713391,"py-irt is a Python library for fitting Bayesian Item Response Theory (IRT)
models. py-irt estimates latent traits of subjects and items, making it
appropriate for use in IRT tasks as well as ideal-point models. py-irt is built
on top of the Pyro and PyTorch frameworks and uses GPU-accelerated training to
scale to large data sets. Code, documentation, and examples can be found at
https://github.com/nd-ball/py-irt. py-irt can be installed from the GitHub page
or the Python Package Index (PyPI)."
When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment,0.709601,"AI systems are becoming increasingly intertwined with human life. In order to
effectively collaborate with humans and ensure safety, AI systems need to be
able to understand, interpret and predict human moral judgments and decisions.
Human moral judgments are often guided by rules, but not always. A central
challenge for AI safety is capturing the flexibility of the human moral mind --
the ability to determine when a rule should be broken, especially in novel or
unusual situations. In this paper, we present a novel challenge set consisting
of rule-breaking question answering (RBQA) of cases that involve potentially
permissible rule-breaking -- inspired by recent moral psychology studies. Using
a state-of-the-art large language model (LLM) as a basis, we propose a novel
moral chain of thought (MORALCOT) prompting strategy that combines the
strengths of LLMs with theories of moral reasoning developed in cognitive
science to predict human moral judgments. MORALCOT outperforms seven existing
LLMs by 6.2% F1, suggesting that modeling human reasoning might be necessary to
capture the flexibility of the human moral mind. We also conduct a detailed
error analysis to suggest directions for future work to improve AI safety using
RBQA. Our data is open-sourced at
https://huggingface.co/datasets/feradauto/MoralExceptQA and code at
https://github.com/feradauto/MoralCoT"
Exemplar-free Online Continual Learning,0.212164,"Targeted for real world scenarios, online continual learning aims to learn
new tasks from sequentially available data under the condition that each data
is observed only once by the learner. Though recent works have made remarkable
achievements by storing part of learned task data as exemplars for knowledge
replay, the performance is greatly relied on the size of stored exemplars while
the storage consumption is a significant constraint in continual learning. In
addition, storing exemplars may not always be feasible for certain applications
due to privacy concerns. In this work, we propose a novel exemplar-free method
by leveraging nearest-class-mean (NCM) classifier where the class mean is
estimated during training phase on all data seen so far through online mean
update criteria. We focus on image classification task and conduct extensive
experiments on benchmark datasets including CIFAR-100 and Food-1k. The results
demonstrate that our method without using any exemplar outperforms
state-of-the-art exemplar-based approaches with large margins under standard
protocol (20 exemplars per class) and is able to achieve competitive
performance even with larger exemplar size (100 exemplars per class)."
Learning to Imitate Object Interactions from Internet Videos,0.0413538,"We study the problem of imitating object interactions from Internet videos.
This requires understanding the hand-object interactions in 4D, spatially in 3D
and over time, which is challenging due to mutual hand-object occlusions. In
this paper we make two main contributions: (1) a novel reconstruction technique
RHOV (Reconstructing Hands and Objects from Videos), which reconstructs 4D
trajectories of both the hand and the object using 2D image cues and temporal
smoothness constraints; (2) a system for imitating object interactions in a
physics simulator with reinforcement learning. We apply our reconstruction
technique to 100 challenging Internet videos. We further show that we can
successfully imitate a range of different object interactions in a physics
simulator. Our object-centric approach is not limited to human-like
end-effectors and can learn to imitate object interactions using different
embodiments, like a robotic arm with a parallel jaw gripper."
RePFormer: Refinement Pyramid Transformer for Robust Facial Landmark Detection,0.0,"This paper presents a Refinement Pyramid Transformer (RePFormer) for robust
facial landmark detection. Most facial landmark detectors focus on learning
representative image features. However, these CNN-based feature representations
are not robust enough to handle complex real-world scenarios due to ignoring
the internal structure of landmarks, as well as the relations between landmarks
and context. In this work, we formulate the facial landmark detection task as
refining landmark queries along pyramid memories. Specifically, a pyramid
transformer head (PTH) is introduced to build both homologous relations among
landmarks and heterologous relations between landmarks and cross-scale
contexts. Besides, a dynamic landmark refinement (DLR) module is designed to
decompose the landmark regression into an end-to-end refinement procedure,
where the dynamically aggregated queries are transformed to residual
coordinates predictions. Extensive experimental results on four facial landmark
detection benchmarks and their various subsets demonstrate the superior
performance and high robustness of our framework."
Questions Are All You Need to Train a Dense Passage Retriever,0.706879,"We introduce ART, a new corpus-level autoencoding approach for training dense
retrieval models that does not require any labeled training data. Dense
retrieval is a central challenge for open-domain tasks, such as Open QA, where
state-of-the-art methods typically require large supervised datasets with
custom hard-negative mining and denoising of positive examples. ART, in
contrast, only requires access to unpaired inputs and outputs (e.g. questions
and potential answer documents). It uses a new document-retrieval autoencoding
scheme, where (1) an input question is used to retrieve a set of evidence
documents, and (2) the documents are then used to compute the probability of
reconstructing the original question. Training for retrieval based on question
reconstruction enables effective unsupervised learning of both document and
question encoders, which can be later incorporated into complete Open QA
systems without any further finetuning. Extensive experiments demonstrate that
ART obtains state-of-the-art results on multiple QA retrieval benchmarks with
only generic initialization from a pre-trained language model, removing the
need for labeled data and task-specific losses."
A Deep-Discrete Learning Framework for Spherical Surface Registration,0.0584814,"Cortical surface registration is a fundamental tool for neuroimaging analysis
that has been shown to improve the alignment of functional regions relative to
volumetric approaches. Classically, image registration is performed by
optimizing a complex objective similarity function, leading to long run times.
This contributes to a convention for aligning all data to a global average
reference frame that poorly reflects the underlying cortical heterogeneity. In
this paper, we propose a novel unsupervised learning-based framework that
converts registration to a multi-label classification problem, where each point
in a low-resolution control grid deforms to one of fixed, finite number of
endpoints. This is learned using a spherical geometric deep learning
architecture, in an end-to-end unsupervised way, with regularization imposed
using a deep Conditional Random Field (CRF). Experiments show that our proposed
framework performs competitively, in terms of similarity and areal distortion,
relative to the most popular classical surface registration algorithms and
generates smoother deformations than other learning-based surface registration
methods, even in subjects with atypical cortical morphology."
Hyperspherical Consistency Regularization,0.224419,"Recent advances in contrastive learning have enlightened diverse applications
across various semi-supervised fields. Jointly training supervised learning and
unsupervised learning with a shared feature encoder becomes a common scheme.
Though it benefits from taking advantage of both feature-dependent information
from self-supervised learning and label-dependent information from supervised
learning, this scheme remains suffering from bias of the classifier. In this
work, we systematically explore the relationship between self-supervised
learning and supervised learning, and study how self-supervised learning helps
robust data-efficient deep learning. We propose hyperspherical consistency
regularization (HCR), a simple yet effective plug-and-play method, to
regularize the classifier using feature-dependent information and thus avoid
bias from labels. Specifically, HCR first projects logits from the classifier
and feature projections from the projection head on the respective hypersphere,
then it enforces data points on hyperspheres to have similar structures by
minimizing binary cross entropy of pairwise distances' similarity metrics.
Extensive experiments on semi-supervised and weakly-supervised learning
demonstrate the effectiveness of our method, by showing superior performance
with HCR."
Unsupervised Human Action Recognition with Skeletal Graph Laplacian and Self-Supervised Viewpoints Invariance,0.0812181,"This paper presents a novel end-to-end method for the problem of
skeleton-based unsupervised human action recognition. We propose a new
architecture with a convolutional autoencoder that uses graph Laplacian
regularization to model the skeletal geometry across the temporal dynamics of
actions. Our approach is robust towards viewpoint variations by including a
self-supervised gradient reverse layer that ensures generalization across
camera views. The proposed method is validated on NTU-60 and NTU-120
large-scale datasets in which it outperforms all prior unsupervised
skeleton-based approaches on the cross-subject, cross-view, and cross-setup
protocols. Although unsupervised, our learnable representation allows our
method even to surpass a few supervised skeleton-based action recognition
methods. The code is available in:
www.github.com/IIT-PAVIS/UHAR_Skeletal_Laplacian"
Non-Autoregressive Machine Translation: It's Not as Fast as it Seems,0.140265,"Efficient machine translation models are commercially important as they can
increase inference speeds, and reduce costs and carbon emissions. Recently,
there has been much interest in non-autoregressive (NAR) models, which promise
faster translation. In parallel to the research on NAR models, there have been
successful attempts to create optimized autoregressive models as part of the
WMT shared task on efficient translation. In this paper, we point out flaws in
the evaluation methodology present in the literature on NAR models and we
provide a fair comparison between a state-of-the-art NAR model and the
autoregressive submissions to the shared task. We make the case for consistent
evaluation of NAR models, and also for the importance of comparing NAR models
with other widely used methods for improving efficiency. We run experiments
with a connectionist-temporal-classification-based (CTC) NAR model implemented
in C++ and compare it with AR models using wall clock times. Our results show
that, although NAR models are faster on GPUs, with small batch sizes, they are
almost always slower under more realistic usage conditions. We call for more
realistic and extensive evaluation of NAR models in future work."
On the Paradox of Learning to Reason from Data,0.0416266,"Logical reasoning is needed in a wide range of NLP tasks. Can a BERT model be
trained end-to-end to solve logical reasoning problems presented in natural
language? We attempt to answer this question in a confined problem space where
there exists a set of parameters that perfectly simulates logical reasoning. We
make observations that seem to contradict each other: BERT attains near-perfect
accuracy on in-distribution test examples while failing to generalize to other
data distributions over the exact same problem space. Our study provides an
explanation for this paradox: instead of learning to emulate the correct
reasoning function, BERT has in fact learned statistical features that
inherently exist in logical reasoning problems. We also show that it is
infeasible to jointly remove statistical features from data, illustrating the
difficulty of learning to reason in general. Our result naturally extends to
other neural models and unveils the fundamental difference between learning to
reason and learning to achieve high performance on NLP benchmarks using
statistical features."
UC-OWOD: Unknown-Classified Open World Object Detection,0.601024,"Open World Object Detection (OWOD) is a challenging computer vision problem
that requires detecting unknown objects and gradually learning the identified
unknown classes. However, it cannot distinguish unknown instances as multiple
unknown classes. In this work, we propose a novel OWOD problem called
Unknown-Classified Open World Object Detection (UC-OWOD). UC-OWOD aims to
detect unknown instances and classify them into different unknown classes.
Besides, we formulate the problem and devise a two-stage object detector to
solve UC-OWOD. First, unknown label-aware proposal and unknown-discriminative
classification head are used to detect known and unknown objects. Then,
similarity-based unknown classification and unknown clustering refinement
modules are constructed to distinguish multiple unknown classes. Moreover, two
novel evaluation protocols are designed to evaluate unknown-class detection.
Abundant experiments and visualizations prove the effectiveness of the proposed
method. Code is available at https://github.com/JohnWuzh/UC-OWOD."
Controlling Bias Exposure for Fair Interpretable Predictions,0.101849,"Recent work on reducing bias in NLP models usually focuses on protecting or
isolating information related to a sensitive attribute (like gender or race).
However, when sensitive information is semantically entangled with the task
information of the input, e.g., gender information is predictive for a
profession, a fair trade-off between task performance and bias mitigation is
difficult to achieve. Existing approaches perform this trade-off by eliminating
bias information from the latent space, lacking control over how much bias is
necessarily required to be removed. We argue that a favorable debiasing method
should use sensitive information 'fairly', rather than blindly eliminating it
(Caliskan et al., 2017; Sun et al., 2019; Bogen et al., 2020). In this work, we
provide a novel debiasing algorithm by adjusting the predictive model's belief
to (1) ignore the sensitive information if it is not useful for the task; (2)
use sensitive information minimally as necessary for the prediction (while also
incurring a penalty). Experimental results on two text classification tasks
(influenced by gender) and an open-ended generation task (influenced by race)
indicate that our model achieves a desirable trade-off between debiasing and
task performance along with producing debiased rationales as evidence."
Fine-Grained Object Classification via Self-Supervised Pose Alignment,0.418873,"Semantic patterns of fine-grained objects are determined by subtle appearance
difference of local parts, which thus inspires a number of part-based methods.
However, due to uncontrollable object poses in images, distinctive details
carried by local regions can be spatially distributed or even self-occluded,
leading to a large variation on object representation. For discounting pose
variations, this paper proposes to learn a novel graph based object
representation to reveal a global configuration of local parts for
self-supervised pose alignment across classes, which is employed as an
auxiliary feature regularization on a deep representation learning
network.Moreover, a coarse-to-fine supervision together with the proposed
pose-insensitive constraint on shallow-to-deep sub-networks encourages
discriminative features in a curriculum learning manner. We evaluate our method
on three popular fine-grained object classification benchmarks, consistently
achieving the state-of-the-art performance. Source codes are available at
https://github.com/yangxh11/P2P-Net."
Agile Maneuvers in Legged Robots: a Predictive Control Approach,0.0954752,"Planning and execution of agile locomotion maneuvers have been a longstanding
challenge in legged robotics. It requires to derive motion plans and local
feedback policies in real-time to handle the nonholonomy of the kinetic
momenta. To achieve so, we propose a hybrid predictive controller that
considers the robot's actuation limits and full-body dynamics. It combines the
feedback policies with tactile information to locally predict future actions.
It converges within a few milliseconds thanks to a feasibility-driven approach.
Our predictive controller enables ANYmal robots to generate agile maneuvers in
realistic scenarios. A crucial element is to track the local feedback policies
as, in contrast to whole-body control, they achieve the desired angular
momentum. To the best of our knowledge, our predictive controller is the first
to handle actuation limits, generate agile locomotion maneuvers, and execute
optimal feedback policies for low level torque control without the use of a
separate whole-body controller."
Does Simultaneous Speech Translation need Simultaneous Models?,0.03624,"In simultaneous speech translation (SimulST), finding the best trade-off
between high translation quality and low latency is a challenging task. To meet
the latency constraints posed by the different application scenarios, multiple
dedicated SimulST models are usually trained and maintained, generating high
computational costs. In this paper, motivated by the increased social and
environmental impact caused by these costs, we investigate whether a single
model trained offline can serve not only the offline but also the simultaneous
task without the need for any additional training or adaptation. Experiments on
en->{de, es} indicate that, aside from facilitating the adoption of
well-established offline techniques and architectures without affecting
latency, the offline solution achieves similar or better translation quality
compared to the same model trained in simultaneous settings, as well as being
competitive with the SimulST state of the art."
How would Stance Detection Techniques Evolve after the Launch of ChatGPT?,0.854876,"Stance detection refers to the task of extracting the standpoint (Favor,
Against or Neither) towards a target in given texts. Such research gains
increasing attention with the proliferation of social media contents. The
conventional framework of handling stance detection is converting it into text
classification tasks. Deep learning models have already replaced rule-based
models and traditional machine learning models in solving such problems.
Current deep neural networks are facing two main challenges which are
insufficient labeled data and information in social media posts and the
unexplainable nature of deep learning models. A new pre-trained language model
chatGPT was launched on Nov 30, 2022. For the stance detection tasks, our
experiments show that ChatGPT can achieve SOTA or similar performance for
commonly used datasets including SemEval-2016 and P-Stance. At the same time,
ChatGPT can provide explanation for its own prediction, which is beyond the
capability of any existing model. The explanations for the cases it cannot
provide classification results are especially useful. ChatGPT has the potential
to be the best AI model for stance detection tasks in NLP, or at least change
the research paradigm of this field. ChatGPT also opens up the possibility of
building explanatory AI for stance detection."
SQuId: Measuring Speech Naturalness in Many Languages,0.196008,"Much of text-to-speech research relies on human evaluation, which incurs
heavy costs and slows down the development process. The problem is particularly
acute in heavily multilingual applications, where recruiting and polling judges
can take weeks. We introduce SQuId (Speech Quality Identification), a
multilingual naturalness prediction model trained on over a million ratings and
tested in 65 locales-the largest effort of this type to date. The main insight
is that training one model on many locales consistently outperforms mono-locale
baselines. We present our task, the model, and show that it outperforms a
competitive baseline based on w2v-BERT and VoiceMOS by 50.0%. We then
demonstrate the effectiveness of cross-locale transfer during fine-tuning and
highlight its effect on zero-shot locales, i.e., locales for which there is no
fine-tuning data. Through a series of analyses, we highlight the role of
non-linguistic effects such as sound artifacts in cross-locale transfer.
Finally, we present the effect of our design decision, e.g., model size,
pre-training diversity, and language rebalancing with several ablation
experiments."
PSMNet: Position-aware Stereo Merging Network for Room Layout Estimation,0.160137,"In this paper, we propose a new deep learning-based method for estimating
room layout given a pair of 360 panoramas. Our system, called Position-aware
Stereo Merging Network or PSMNet, is an end-to-end joint layout-pose estimator.
PSMNet consists of a Stereo Pano Pose (SP2) transformer and a novel
Cross-Perspective Projection (CP2) layer. The stereo-view SP2 transformer is
used to implicitly infer correspondences between views, and can handle noisy
poses. The pose-aware CP2 layer is designed to render features from the
adjacent view to the anchor (reference) view, in order to perform view fusion
and estimate the visible layout. Our experiments and analysis validate our
method, which significantly outperforms the state-of-the-art layout estimators,
especially for large and complex room spaces."
Rethinking Graph Convolutional Networks in Knowledge Graph Completion,0.0802254,"Graph convolutional networks (GCNs) -- which are effective in modeling graph
structures -- have been increasingly popular in knowledge graph completion
(KGC). GCN-based KGC models first use GCNs to generate expressive entity
representations and then use knowledge graph embedding (KGE) models to capture
the interactions among entities and relations. However, many GCN-based KGC
models fail to outperform state-of-the-art KGE models though introducing
additional computational complexity. This phenomenon motivates us to explore
the real effect of GCNs in KGC. Therefore, in this paper, we build upon
representative GCN-based KGC models and introduce variants to find which factor
of GCNs is critical in KGC. Surprisingly, we observe from experiments that the
graph structure modeling in GCNs does not have a significant impact on the
performance of KGC models, which is in contrast to the common belief. Instead,
the transformations for entity representations are responsible for the
performance improvements. Based on the observation, we propose a simple yet
effective framework named LTE-KGE, which equips existing KGE models with
linearly transformed entity embeddings. Experiments demonstrate that LTE-KGE
models lead to similar performance improvements with GCN-based KGC methods,
while being more computationally efficient. These results suggest that existing
GCNs are unnecessary for KGC, and novel GCN-based KGC models should count on
more ablation studies to validate their effectiveness. The code of all the
experiments is available on GitHub at https://github.com/MIRALab-USTC/GCN4KGC."
TINYCD: A (Not So) Deep Learning Model For Change Detection,-1.0,"In this paper, we present a lightweight and effective change detection model,
called TinyCD. This model has been designed to be faster and smaller than
current state-of-the-art change detection models due to industrial needs.
Despite being from 13 to 140 times smaller than the compared change detection
models, and exposing at least a third of the computational complexity, our
model outperforms the current state-of-the-art models by at least $1\%$ on both
F1 score and IoU on the LEVIR-CD dataset, and more than $8\%$ on the WHU-CD
dataset. To reach these results, TinyCD uses a Siamese U-Net architecture
exploiting low-level features in a globally temporal and locally spatial way.
In addition, it adopts a new strategy to mix features in the space-time domain
both to merge the embeddings obtained from the Siamese backbones, and, coupled
with an MLP block, it forms a novel space-semantic attention mechanism, the Mix
and Attention Mask Block (MAMB). Source code, models and results are available
here: https://github.com/AndreaCodegoni/Tiny_model_4_CD"
4D-StOP: Panoptic Segmentation of 4D LiDAR using Spatio-temporal Object Proposal Generation and Aggregation,0.638811,"In this work, we present a new paradigm, called 4D-StOP, to tackle the task
of 4D Panoptic LiDAR Segmentation. 4D-StOP first generates spatio-temporal
proposals using voting-based center predictions, where each point in the 4D
volume votes for a corresponding center. These tracklet proposals are further
aggregated using learned geometric features. The tracklet aggregation method
effectively generates a video-level 4D scene representation over the entire
space-time volume. This is in contrast to existing end-to-end trainable
state-of-the-art approaches which use spatio-temporal embeddings that are
represented by Gaussian probability distributions. Our voting-based tracklet
generation method followed by geometric feature-based aggregation generates
significantly improved panoptic LiDAR segmentation quality when compared to
modeling the entire 4D volume using Gaussian probability distributions. 4D-StOP
achieves a new state-of-the-art when applied to the SemanticKITTI test dataset
with a score of 63.9 LSTQ, which is a large (+7%) improvement compared to
current best-performing end-to-end trainable methods. The code and pre-trained
models are available at: https://github.com/LarsKreuzberg/4D-StOP."
Rethinking Performance Gains in Image Dehazing Networks,0.344541,"Image dehazing is an active topic in low-level vision, and many image
dehazing networks have been proposed with the rapid development of deep
learning. Although these networks' pipelines work fine, the key mechanism to
improving image dehazing performance remains unclear. For this reason, we do
not target to propose a dehazing network with fancy modules; rather, we make
minimal modifications to popular U-Net to obtain a compact dehazing network.
Specifically, we swap out the convolutional blocks in U-Net for residual blocks
with the gating mechanism, fuse the feature maps of main paths and skip
connections using the selective kernel, and call the resulting U-Net variant
gUNet. As a result, with a significantly reduced overhead, gUNet is superior to
state-of-the-art methods on multiple image dehazing datasets. Finally, we
verify these key designs to the performance gain of image dehazing networks
through extensive ablation studies."
Strategy Synthesis for Zero-Sum Neuro-Symbolic Concurrent Stochastic Games,0.424889,"Neuro-symbolic approaches to artificial intelligence, which combine neural
networks with classical symbolic techniques, are growing in prominence,
necessitating formal approaches to reason about their correctness. We propose a
novel modelling formalism called neuro-symbolic concurrent stochastic games
(NS-CSGs), which comprise two probabilistic finite-state agents interacting in
a shared continuous-state environment. Each agent observes the environment
using a neural perception mechanism, which converts inputs such as images into
symbolic percepts, and makes decisions symbolically. We focus on the class of
NS-CSGs with Borel state spaces and prove the existence and measurability of
the value function for zero-sum discounted cumulative rewards under
piecewise-constant restrictions on the components of this class of models. To
compute values and synthesise strategies, we present, for the first time,
practical value iteration (VI) and policy iteration (PI) algorithms to solve
this new subclass of continuous-state CSGs. These require a finite
decomposition of the environment induced by the neural perception mechanisms of
the agents and rely on finite abstract representations of value functions and
strategies closed under VI or PI. First, we introduce a Borel measurable
piecewise-constant (B-PWC) representation of value functions, extend minimax
backups to this representation and propose a value iteration algorithm called
B-PWC VI. Second, we introduce two novel representations for the value
functions and strategies, constant-piecewise-linear (CON-PWL) and
constant-piecewise-constant (CON-PWC) respectively, and propose
Minimax-action-free PI by extending a recent PI method based on alternating
player choices for finite state spaces to Borel state spaces, which does not
require normal-form games to be solved."
VoLux-GAN: A Generative Model for 3D Face Synthesis with HDRI Relighting,0.0928042,"We propose VoLux-GAN, a generative framework to synthesize 3D-aware faces
with convincing relighting. Our main contribution is a volumetric HDRI
relighting method that can efficiently accumulate albedo, diffuse and specular
lighting contributions along each 3D ray for any desired HDR environmental map.
Additionally, we show the importance of supervising the image decomposition
process using multiple discriminators. In particular, we propose a data
augmentation technique that leverages recent advances in single image portrait
relighting to enforce consistent geometry, albedo, diffuse and specular
components. Multiple experiments and comparisons with other generative
frameworks show how our model is a step forward towards photorealistic
relightable 3D generative models."
Anticipative Feature Fusion Transformer for Multi-Modal Action Anticipation,0.448647,"Although human action anticipation is a task which is inherently multi-modal,
state-of-the-art methods on well known action anticipation datasets leverage
this data by applying ensemble methods and averaging scores of unimodal
anticipation networks. In this work we introduce transformer based modality
fusion techniques, which unify multi-modal data at an early stage. Our
Anticipative Feature Fusion Transformer (AFFT) proves to be superior to popular
score fusion approaches and presents state-of-the-art results outperforming
previous methods on EpicKitchens-100 and EGTEA Gaze+. Our model is easily
extensible and allows for adding new modalities without architectural changes.
Consequently, we extracted audio features on EpicKitchens-100 which we add to
the set of commonly used features in the community."
"Event Causality Identification with Causal News Corpus -- Shared Task 3, CASE 2022",0.230731,"The Event Causality Identification Shared Task of CASE 2022 involved two
subtasks working on the Causal News Corpus. Subtask 1 required participants to
predict if a sentence contains a causal relation or not. This is a supervised
binary classification task. Subtask 2 required participants to identify the
Cause, Effect and Signal spans per causal sentence. This could be seen as a
supervised sequence labeling task. For both subtasks, participants uploaded
their predictions for a held-out test set, and ranking was done based on binary
F1 and macro F1 scores for Subtask 1 and 2, respectively. This paper summarizes
the work of the 17 teams that submitted their results to our competition and 12
system description papers that were received. The best F1 scores achieved for
Subtask 1 and 2 were 86.19% and 54.15%, respectively. All the top-performing
approaches involved pre-trained language models fine-tuned to the targeted
task. We further discuss these approaches and analyze errors across
participants' systems in this paper."
GIFS: Neural Implicit Function for General Shape Representation,0.473087,"Recent development of neural implicit function has shown tremendous success
on high-quality 3D shape reconstruction. However, most works divide the space
into inside and outside of the shape, which limits their representing power to
single-layer and watertight shapes. This limitation leads to tedious data
processing (converting non-watertight raw data to watertight) as well as the
incapability of representing general object shapes in the real world. In this
work, we propose a novel method to represent general shapes including
non-watertight shapes and shapes with multi-layer surfaces. We introduce
General Implicit Function for 3D Shape (GIFS), which models the relationships
between every two points instead of the relationships between points and
surfaces. Instead of dividing 3D space into predefined inside-outside regions,
GIFS encodes whether two points are separated by any surface. Experiments on
ShapeNet show that GIFS outperforms previous state-of-the-art methods in terms
of reconstruction quality, rendering efficiency, and visual fidelity. Project
page is available at https://jianglongye.com/gifs ."
On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model,0.192512,"Many recent studies on large-scale language models have reported successful
in-context zero- and few-shot learning ability. However, the in-depth analysis
of when in-context learning occurs is still lacking. For example, it is unknown
how in-context learning performance changes as the training corpus varies.
Here, we investigate the effects of the source and size of the pretraining
corpus on in-context learning in HyperCLOVA, a Korean-centric GPT-3 model. From
our in-depth investigation, we introduce the following observations: (1)
in-context learning performance heavily depends on the corpus domain source,
and the size of the pretraining corpus does not necessarily determine the
emergence of in-context learning, (2) in-context learning ability can emerge
when a language model is trained on a combination of multiple corpora, even
when each corpus does not result in in-context learning on its own, (3)
pretraining with a corpus related to a downstream task does not always
guarantee the competitive in-context learning performance of the downstream
task, especially in the few-shot setting, and (4) the relationship between
language modeling (measured in perplexity) and in-context learning does not
always correlate: e.g., low perplexity does not always imply high in-context
few-shot learning performance."
MorisienMT: A Dataset for Mauritian Creole Machine Translation,-1.0,"In this paper, we describe MorisienMT, a dataset for benchmarking machine
translation quality of Mauritian Creole. Mauritian Creole (Morisien) is the
lingua franca of the Republic of Mauritius and is a French-based creole
language. MorisienMT consists of a parallel corpus between English and
Morisien, French and Morisien and a monolingual corpus for Morisien. We first
give an overview of Morisien and then describe the steps taken to create the
corpora and, from it, the training and evaluation splits. Thereafter, we
establish a variety of baseline models using the created parallel corpora as
well as large French--English corpora for transfer learning. We release our
datasets publicly for research purposes and hope that this spurs research for
Morisien machine translation."
Atari-5: Distilling the Arcade Learning Environment down to Five Games,0.0160244,"The Arcade Learning Environment (ALE) has become an essential benchmark for
assessing the performance of reinforcement learning algorithms. However, the
computational cost of generating results on the entire 57-game dataset limits
ALE's use and makes the reproducibility of many results infeasible. We propose
a novel solution to this problem in the form of a principled methodology for
selecting small but representative subsets of environments within a benchmark
suite. We applied our method to identify a subset of five ALE games, called
Atari-5, which produces 57-game median score estimates within 10% of their true
values. Extending the subset to 10-games recovers 80% of the variance for
log-scores for all games within the 57-game set. We show this level of
compression is possible due to a high degree of correlation between many of the
games in ALE."
Deep Surrogate Assisted Generation of Environments,0.0741055,"Recent progress in reinforcement learning (RL) has started producing
generally capable agents that can solve a distribution of complex environments.
These agents are typically tested on fixed, human-authored environments. On the
other hand, quality diversity (QD) optimization has been proven to be an
effective component of environment generation algorithms, which can generate
collections of high-quality environments that are diverse in the resulting
agent behaviors. However, these algorithms require potentially expensive
simulations of agents on newly generated environments. We propose Deep
Surrogate Assisted Generation of Environments (DSAGE), a sample-efficient QD
environment generation algorithm that maintains a deep surrogate model for
predicting agent behaviors in new environments. Results in two benchmark
domains show that DSAGE significantly outperforms existing QD environment
generation algorithms in discovering collections of environments that elicit
diverse behaviors of a state-of-the-art RL agent and a planning agent. Our
source code and videos are available at https://dsagepaper.github.io/."
Neural Cloth Simulation,0.190283,"We present a general framework for the garment animation problem through
unsupervised deep learning inspired in physically based simulation. Existing
trends in the literature already explore this possibility. Nonetheless, these
approaches do not handle cloth dynamics. Here, we propose the first methodology
able to learn realistic cloth dynamics unsupervisedly, and henceforth, a
general formulation for neural cloth simulation. The key to achieve this is to
adapt an existing optimization scheme for motion from simulation based
methodologies to deep learning. Then, analyzing the nature of the problem, we
devise an architecture able to automatically disentangle static and dynamic
cloth subspaces by design. We will show how this improves model performance.
Additionally, this opens the possibility of a novel motion augmentation
technique that greatly improves generalization. Finally, we show it also allows
to control the level of motion in the predictions. This is a useful, never seen
before, tool for artists. We provide of detailed analysis of the problem to
establish the bases of neural cloth simulation and guide future research into
the specifics of this domain."
Entropy-based Active Learning for Object Detection with Progressive Diversity Constraint,0.344497,"Active learning is a promising alternative to alleviate the issue of high
annotation cost in the computer vision tasks by consciously selecting more
informative samples to label. Active learning for object detection is more
challenging and existing efforts on it are relatively rare. In this paper, we
propose a novel hybrid approach to address this problem, where the
instance-level uncertainty and diversity are jointly considered in a bottom-up
manner. To balance the computational complexity, the proposed approach is
designed as a two-stage procedure. At the first stage, an Entropy-based
Non-Maximum Suppression (ENMS) is presented to estimate the uncertainty of
every image, which performs NMS according to the entropy in the feature space
to remove predictions with redundant information gains. At the second stage, a
diverse prototype (DivProto) strategy is explored to ensure the diversity
across images by progressively converting it into the intra-class and
inter-class diversities of the entropy-based class-specific prototypes.
Extensive experiments are conducted on MS COCO and Pascal VOC, and the proposed
approach achieves state of the art results and significantly outperforms the
other counterparts, highlighting its superiority."
CrowdFormer: Weakly-supervised Crowd counting with Improved Generalizability,0.297121,"Convolutional neural networks (CNNs) have dominated the field of computer
vision for nearly a decade due to their strong ability to learn local features.
However, due to their limited receptive field, CNNs fail to model the global
context. On the other hand, transformer, an attention-based architecture can
model the global context easily. Despite this, there are limited studies that
investigate the effectiveness of transformers in crowd counting. In addition,
the majority of the existing crowd counting methods are based on the regression
of density maps which requires point-level annotation of each person present in
the scene. This annotation task is laborious and also error-prone. This has led
to increased focus on weakly-supervised crowd counting methods which require
only the count-level annotations. In this paper, we propose a weakly-supervised
method for crowd counting using a pyramid vision transformer. We have conducted
extensive evaluations to validate the effectiveness of the proposed method. Our
method is comparable to the state-of-the-art on the benchmark crowd datasets.
More importantly, it shows remarkable generalizability."
Redwood: Using Collision Detection to Grow a Large-Scale Intent Classification Dataset,0.0944497,"Dialog systems must be capable of incorporating new skills via updates over
time in order to reflect new use cases or deployment scenarios. Similarly,
developers of such ML-driven systems need to be able to add new training data
to an already-existing dataset to support these new skills. In intent
classification systems, problems can arise if training data for a new skill's
intent overlaps semantically with an already-existing intent. We call such
cases collisions. This paper introduces the task of intent collision detection
between multiple datasets for the purposes of growing a system's skillset. We
introduce several methods for detecting collisions, and evaluate our methods on
real datasets that exhibit collisions. To highlight the need for intent
collision detection, we show that model performance suffers if new data is
added in such a way that does not arbitrate colliding intents. Finally, we use
collision detection to construct and benchmark a new dataset, Redwood, which is
composed of 451 ntent categories from 13 original intent classification
datasets, making it the largest publicly available intent classification
benchmark."
Self-supervised models of audio effectively explain human cortical responses to speech,0.215203,"Self-supervised language models are very effective at predicting high-level
cortical responses during language comprehension. However, the best current
models of lower-level auditory processing in the human brain rely on either
hand-constructed acoustic filters or representations from supervised audio
neural networks. In this work, we capitalize on the progress of self-supervised
speech representation learning (SSL) to create new state-of-the-art models of
the human auditory system. Compared against acoustic baselines, phonemic
features, and supervised models, representations from the middle layers of
self-supervised models (APC, wav2vec, wav2vec 2.0, and HuBERT) consistently
yield the best prediction performance for fMRI recordings within the auditory
cortex (AC). Brain areas involved in low-level auditory processing exhibit a
preference for earlier SSL model layers, whereas higher-level semantic areas
prefer later layers. We show that these trends are due to the models' ability
to encode information at multiple linguistic levels (acoustic, phonetic, and
lexical) along their representation depth. Overall, these results show that
self-supervised models effectively capture the hierarchy of information
relevant to different stages of speech processing in human cortex."
DiGamma: Domain-aware Genetic Algorithm for HW-Mapping Co-optimization for DNN Accelerators,0.73134,"The design of DNN accelerators includes two key parts: HW resource
configuration and mapping strategy. Intensive research has been conducted to
optimize each of them independently. Unfortunately, optimizing for both
together is extremely challenging due to the extremely large cross-coupled
search space. To address this, in this paper, we propose a HW-Mapping
co-optimization framework, an efficient encoding of the immense design space
constructed by HW and Mapping, and a domain-aware genetic algorithm, named
DiGamma, with specialized operators for improving search efficiency. We
evaluate DiGamma with seven popular DNNs models with different properties. Our
evaluations show DiGamma can achieve (geomean) 3.0x and 10.0x speedup,
comparing to the best-performing baseline optimization algorithms, in edge and
cloud settings."
mGPT: Few-Shot Learners Go Multilingual,0.286719,"Recent studies report that autoregressive language models can successfully
solve many NLP tasks via zero- and few-shot learning paradigms, which opens up
new possibilities for using the pre-trained language models. This paper
introduces two autoregressive GPT-like models with 1.3 billion and 13 billion
parameters trained on 60 languages from 25 language families using Wikipedia
and Colossal Clean Crawled Corpus. We reproduce the GPT-3 architecture using
GPT-2 sources and the sparse attention mechanism; Deepspeed and Megatron
frameworks allow us to parallelize the training and inference steps
effectively. The resulting models show performance on par with the recently
released XGLM models by Facebook, covering more languages and enhancing NLP
possibilities for low resource languages of CIS countries and Russian small
nations. We detail the motivation for the choices of the architecture design,
thoroughly describe the data preparation pipeline, and train five small
versions of the model to choose the most optimal multilingual tokenization
strategy. We measure the model perplexity in all covered languages and evaluate
it on the wide spectre of multilingual tasks, including classification,
generative, sequence labeling and knowledge probing. The models were evaluated
with the zero-shot and few-shot methods. Furthermore, we compared the
classification tasks with the state-of-the-art multilingual model XGLM. source
code and the mGPT XL model are publicly released."
"M-SpeechCLIP: Leveraging Large-Scale, Pre-Trained Models for Multilingual Speech to Image Retrieval",0.0117991,"This work investigates the use of large-scale, English-only pre-trained
models (CLIP and HuBERT) for multilingual image-speech retrieval. For
non-English image-speech retrieval, we outperform the current state-of-the-art
performance by a wide margin both when training separate models for each
language, and with a single model which processes speech in all three
languages. We identify key differences in model behavior and performance
between English and non-English settings, attributable to the English-only
pre-training of CLIP and HuBERT, and investigate how fine-tuning the
pre-trained models impacts these differences. Finally, we show that our models
can be used for mono- and cross-lingual speech-text retrieval and cross-lingual
speech-speech retrieval, despite never having seen any parallel speech-text or
speech-speech data during training."
Spatial Transformer Network on Skeleton-based Gait Recognition,0.198598,"Skeleton-based gait recognition models usually suffer from the robustness
problem, as the Rank-1 accuracy varies from 90\% in normal walking cases to
70\% in walking with coats cases. In this work, we propose a state-of-the-art
robust skeleton-based gait recognition model called Gait-TR, which is based on
the combination of spatial transformer frameworks and temporal convolutional
networks. Gait-TR achieves substantial improvements over other skeleton-based
gait models with higher accuracy and better robustness on the well-known gait
dataset CASIA-B. Particularly in walking with coats cases, Gait-TR get a 90\%
Rank-1 gait recognition accuracy rate, which is higher than the best result of
silhouette-based models, which usually have higher accuracy than the
silhouette-based gait recognition models. Moreover, our experiment on CASIA-B
shows that the spatial transformer can extract gait features from the human
skeleton better than the widely used graph convolutional network."
Table-based Fact Verification with Self-adaptive Mixture of Experts,0.103312,"The table-based fact verification task has recently gained widespread
attention and yet remains to be a very challenging problem. It inherently
requires informative reasoning over natural language together with different
numerical and logical reasoning on tables (e.g., count, superlative,
comparative). Considering that, we exploit mixture-of-experts and present in
this paper a new method: Self-adaptive Mixture-of-Experts Network (SaMoE).
Specifically, we have developed a mixture-of-experts neural network to
recognize and execute different types of reasoning -- the network is composed
of multiple experts, each handling a specific part of the semantics for
reasoning, whereas a management module is applied to decide the contribution of
each expert network to the verification result. A self-adaptive method is
developed to teach the management module combining results of different experts
more efficiently without external knowledge. The experimental results
illustrate that our framework achieves 85.1% accuracy on the benchmark dataset
TabFact, comparable with the previous state-of-the-art models. We hope our
framework can serve as a new baseline for table-based verification. Our code is
available at https://github.com/THUMLP/SaMoE."
DraftRec: Personalized Draft Recommendation for Winning in Multi-Player Online Battle Arena Games,0.214734,"This paper presents a personalized character recommendation system for
Multiplayer Online Battle Arena (MOBA) games which are considered as one of the
most popular online video game genres around the world. When playing MOBA
games, players go through a draft stage, where they alternately select a
virtual character to play. When drafting, players select characters by not only
considering their character preferences, but also the synergy and competence of
their team's character combination. However, the complexity of drafting induces
difficulties for beginners to choose the appropriate characters based on the
characters of their team while considering their own champion preferences. To
alleviate this problem, we propose DraftRec, a novel hierarchical model which
recommends characters by considering each player's champion preferences and the
interaction between the players. DraftRec consists of two networks: the player
network and the match network. The player network captures the individual
player's champion preference, and the match network integrates the complex
relationship between the players and their respective champions. We train and
evaluate our model from a manually collected 280,000 matches of League of
Legends and a publicly available 50,000 matches of Dota2. Empirically, our
method achieved state-of-the-art performance in character recommendation and
match outcome prediction task. Furthermore, a comprehensive user survey
confirms that DraftRec provides convincing and satisfying recommendations. Our
code and dataset are available at https://github.com/dojeon-ai/DraftRec."
Formal Language Recognition by Hard Attention Transformers: Perspectives from Circuit Complexity,0.117484,"This paper analyzes three formal models of Transformer encoders that differ
in the form of their self-attention mechanism: unique hard attention (UHAT);
generalized unique hard attention (GUHAT), which generalizes UHAT; and
averaging hard attention (AHAT). We show that UHAT and GUHAT Transformers,
viewed as string acceptors, can only recognize formal languages in the
complexity class AC$^0$, the class of languages recognizable by families of
Boolean circuits of constant depth and polynomial size. This upper bound
subsumes Hahn's (2020) results that GUHAT cannot recognize the DYCK languages
or the PARITY language, since those languages are outside AC$^0$ (Furst et al.,
1984). In contrast, the non-AC$^0$ languages MAJORITY and DYCK-1 are
recognizable by AHAT networks, implying that AHAT can recognize languages that
UHAT and GUHAT cannot."
Sufficient Statistic Memory Approximate Message Passing,0.0458069,"Approximate message passing (AMP) type algorithms have been widely used in
the signal reconstruction of certain large random linear systems. A key feature
of the AMP-type algorithms is that their dynamics can be correctly described by
state evolution. However, state evolution does not necessarily guarantee the
convergence of iterative algorithms. To solve the convergence problem of
AMP-type algorithms in principle, this paper proposes a memory AMP (MAMP) under
a sufficient statistic condition, named sufficient statistic MAMP (SS-MAMP). We
show that the covariance matrices of SS-MAMP are L-banded and convergent. Given
an arbitrary MAMP, we can construct the SS-MAMP by damping, which not only
ensures the convergence, but also preserves the orthogonality, i.e., its
dynamics can be correctly described by state evolution."
ES6D: A Computation Efficient and Symmetry-Aware 6D Pose Regression Framework,0.511731,"In this paper, a computation efficient regression framework is presented for
estimating the 6D pose of rigid objects from a single RGB-D image, which is
applicable to handling symmetric objects. This framework is designed in a
simple architecture that efficiently extracts point-wise features from RGB-D
data using a fully convolutional network, called XYZNet, and directly regresses
the 6D pose without any post refinement. In the case of symmetric object, one
object has multiple ground-truth poses, and this one-to-many relationship may
lead to estimation ambiguity. In order to solve this ambiguity problem, we
design a symmetry-invariant pose distance metric, called average (maximum)
grouped primitives distance or A(M)GPD. The proposed A(M)GPD loss can make the
regression network converge to the correct state, i.e., all minima in the
A(M)GPD loss surface are mapped to the correct poses. Extensive experiments on
YCB-Video and T-LESS datasets demonstrate the proposed framework's
substantially superior performance in top accuracy and low computational cost."
BioTABQA: Instruction Learning for Biomedical Table Question Answering,-1.0,"Table Question Answering (TQA) is an important but under-explored task. Most
of the existing QA datasets are in unstructured text format and only few of
them use tables as the context. To the best of our knowledge, none of TQA
datasets exist in the biomedical domain where tables are frequently used to
present information. In this paper, we first curate a table question answering
dataset, BioTABQA, using 22 templates and the context from a biomedical
textbook on differential diagnosis. BioTABQA can not only be used to teach a
model how to answer questions from tables but also evaluate how a model
generalizes to unseen questions, an important scenario for biomedical
applications. To achieve the generalization evaluation, we divide the templates
into 17 training and 5 cross-task evaluations. Then, we develop two baselines
using single and multi-tasks learning on BioTABQA. Furthermore, we explore
instructional learning, a recent technique showing impressive generalizing
performance. Experimental results show that our instruction-tuned model
outperforms single and multi-task baselines on an average by ~23% and ~6%
across various evaluation settings, and more importantly, instruction-tuned
model outperforms baselines by ~5% on cross-tasks."
Using Context-to-Vector with Graph Retrofitting to Improve Word Embeddings,0.145973,"Although contextualized embeddings generated from large-scale pre-trained
models perform well in many tasks, traditional static embeddings (e.g.,
Skip-gram, Word2Vec) still play an important role in low-resource and
lightweight settings due to their low computational cost, ease of deployment,
and stability. In this paper, we aim to improve word embeddings by 1)
incorporating more contextual information from existing pre-trained models into
the Skip-gram framework, which we call Context-to-Vec; 2) proposing a
post-processing retrofitting method for static embeddings independent of
training by employing priori synonym knowledge and weighted vector
distribution. Through extrinsic and intrinsic tasks, our methods are well
proven to outperform the baselines by a large margin."
PIC4rl-gym: a ROS2 modular framework for Robots Autonomous Navigation with Deep Reinforcement Learning,0.240054,"Learning agents can optimize standard autonomous navigation improving
flexibility, efficiency, and computational cost of the system by adopting a
wide variety of approaches. This work introduces the \textit{PIC4rl-gym}, a
fundamental modular framework to enhance navigation and learning research by
mixing ROS2 and Gazebo, the standard tools of the robotics community, with Deep
Reinforcement Learning (DRL). The paper describes the whole structure of the
PIC4rl-gym, which fully integrates DRL agent's training and testing in several
indoor and outdoor navigation scenarios and tasks. A modular approach is
adopted to easily customize the simulation by selecting new platforms, sensors,
or models. We demonstrate the potential of our novel gym by benchmarking the
resulting policies, trained for different navigation tasks, with a complete set
of metrics."
Few Shot Generative Model Adaption via Relaxed Spatial Structural Alignment,0.614641,"Training a generative adversarial network (GAN) with limited data has been a
challenging task. A feasible solution is to start with a GAN well-trained on a
large scale source domain and adapt it to the target domain with a few samples,
termed as few shot generative model adaption. However, existing methods are
prone to model overfitting and collapse in extremely few shot setting (less
than 10). To solve this problem, we propose a relaxed spatial structural
alignment method to calibrate the target generative models during the adaption.
We design a cross-domain spatial structural consistency loss comprising the
self-correlation and disturbance correlation consistency loss. It helps align
the spatial structural information between the synthesis image pairs of the
source and target domains. To relax the cross-domain alignment, we compress the
original latent space of generative models to a subspace. Image pairs generated
from the subspace are pulled closer. Qualitative and quantitative experiments
show that our method consistently surpasses the state-of-the-art methods in few
shot setting."
Visual Context-driven Audio Feature Enhancement for Robust End-to-End Audio-Visual Speech Recognition,0.351796,"This paper focuses on designing a noise-robust end-to-end Audio-Visual Speech
Recognition (AVSR) system. To this end, we propose Visual Context-driven Audio
Feature Enhancement module (V-CAFE) to enhance the input noisy audio speech
with a help of audio-visual correspondence. The proposed V-CAFE is designed to
capture the transition of lip movements, namely visual context and to generate
a noise reduction mask by considering the obtained visual context. Through
context-dependent modeling, the ambiguity in viseme-to-phoneme mapping can be
refined for mask generation. The noisy representations are masked out with the
noise reduction mask resulting in enhanced audio features. The enhanced audio
features are fused with the visual features and taken to an encoder-decoder
model composed of Conformer and Transformer for speech recognition. We show the
proposed end-to-end AVSR with the V-CAFE can further improve the
noise-robustness of AVSR. The effectiveness of the proposed method is evaluated
in noisy speech recognition and overlapped speech recognition experiments using
the two largest audio-visual datasets, LRS2 and LRS3."
Efficient Long Sequence Modeling via State Space Augmented Transformer,0.230885,"Transformer models have achieved superior performance in various natural
language processing tasks. However, the quadratic computational cost of the
attention mechanism limits its practicality for long sequences. There are
existing attention variants that improve the computational efficiency, but they
have limited ability to effectively compute global information. In parallel to
Transformer models, state space models (SSMs) are tailored for long sequences,
but they are not flexible enough to capture complicated local information. We
propose SPADE, short for $\underline{\textbf{S}}$tate
s$\underline{\textbf{P}}$ace
$\underline{\textbf{A}}$ugmente$\underline{\textbf{D}}$
Transform$\underline{\textbf{E}}$r. Specifically, we augment a SSM into the
bottom layer of SPADE, and we employ efficient local attention methods for the
other layers. The SSM augments global information, which complements the lack
of long-range dependency issue in local attention methods. Experimental results
on the Long Range Arena benchmark and language modeling tasks demonstrate the
effectiveness of the proposed method. To further demonstrate the scalability of
SPADE, we pre-train large encoder-decoder models and present fine-tuning
results on natural language understanding and natural language generation
tasks."
Do Bayesian Neural Networks Need To Be Fully Stochastic?,0.0784904,"We investigate the benefit of treating all the parameters in a Bayesian
neural network stochastically and find compelling theoretical and empirical
evidence that this standard construction may be unnecessary. To this end, we
prove that expressive predictive distributions require only small amounts of
stochasticity. In particular, partially stochastic networks with only $n$
stochastic biases are universal probabilistic predictors for $n$-dimensional
predictive problems. In empirical investigations, we find no systematic benefit
of full stochasticity across four different inference modalities and eight
datasets; partially stochastic networks can match and sometimes even outperform
fully stochastic networks, despite their reduced memory costs."
On the Super-exponential Quantum Speedup of Equivariant Quantum Machine Learning Algorithms with SU($d$) Symmetry,0.257,"We introduce a framework of the equivariant convolutional algorithms which is
tailored for a number of machine-learning tasks on physical systems with
arbitrary SU($d$) symmetries. It allows us to enhance a natural model of
quantum computation--permutational quantum computing (PQC) [Quantum Inf.
Comput., 10, 470-497 (2010)] --and defines a more powerful model: PQC+. While
PQC was shown to be effectively classically simulatable, we exhibit a problem
which can be efficiently solved on PQC+ machine, whereas the best known
classical algorithms runs in $O(n!n^2)$ time, thus providing strong evidence
against PQC+ being classically simulatable. We further discuss practical
quantum machine learning algorithms which can be carried out in the paradigm of
PQC+."
Data-Efficient Backdoor Attacks,0.0790679,"Recent studies have proven that deep neural networks are vulnerable to
backdoor attacks. Specifically, by mixing a small number of poisoned samples
into the training set, the behavior of the trained model can be maliciously
controlled. Existing attack methods construct such adversaries by randomly
selecting some clean data from the benign set and then embedding a trigger into
them. However, this selection strategy ignores the fact that each poisoned
sample contributes inequally to the backdoor injection, which reduces the
efficiency of poisoning. In this paper, we formulate improving the poisoned
data efficiency by the selection as an optimization problem and propose a
Filtering-and-Updating Strategy (FUS) to solve it. The experimental results on
CIFAR-10 and ImageNet-10 indicate that the proposed method is effective: the
same attack success rate can be achieved with only 47% to 75% of the poisoned
sample volume compared to the random selection strategy. More importantly, the
adversaries selected according to one setting can generalize well to other
settings, exhibiting strong transferability. The prototype code of our method
is now available at https://github.com/xpf/Data-Efficient-Backdoor-Attacks."
Quark: Controllable Text Generation with Reinforced Unlearning,0.382432,"Large-scale language models often learn behaviors that are misaligned with
user expectations. Generated text may contain offensive or toxic language,
contain significant repetition, or be of a different sentiment than desired by
the user. We consider the task of unlearning these misalignments by fine-tuning
the language model on signals of what not to do. We introduce Quantized Reward
Konditioning (Quark), an algorithm for optimizing a reward function that
quantifies an (un)wanted property, while not straying too far from the original
model. Quark alternates between (i) collecting samples with the current
language model, (ii) sorting them into quantiles based on reward, with each
quantile identified by a reward token prepended to the language model's input,
and (iii) using a standard language modeling loss on samples from each quantile
conditioned on its reward token, while remaining nearby the original language
model via a KL-divergence penalty. By conditioning on a high-reward token at
generation time, the model generates text that exhibits less of the unwanted
property. For unlearning toxicity, negative sentiment, and repetition, our
experiments show that Quark outperforms both strong baselines and
state-of-the-art reinforcement learning methods like PPO (Schulman et al.
2017), while relying only on standard language modeling primitives."
CHQ-Summ: A Dataset for Consumer Healthcare Question Summarization,0.230085,"The quest for seeking health information has swamped the web with consumers'
health-related questions. Generally, consumers use overly descriptive and
peripheral information to express their medical condition or other healthcare
needs, contributing to the challenges of natural language understanding. One
way to address this challenge is to summarize the questions and distill the key
information of the original question. To address this issue, we introduce a new
dataset, CHQ-Summ that contains 1507 domain-expert annotated consumer health
questions and corresponding summaries. The dataset is derived from the
community question-answering forum and therefore provides a valuable resource
for understanding consumer health-related posts on social media. We benchmark
the dataset on multiple state-of-the-art summarization models to show the
effectiveness of the dataset."
Learning to Adapt Domain Shifts of Moral Values via Instance Weighting,0.148904,"Classifying moral values in user-generated text from social media is critical
in understanding community cultures and interpreting user behaviors of social
movements. Moral values and language usage can change across the social
movements; however, text classifiers are usually trained in source domains of
existing social movements and tested in target domains of new social issues
without considering the variations. In this study, we examine domain shifts of
moral values and language usage, quantify the effects of domain shifts on the
morality classification task, and propose a neural adaptation framework via
instance weighting to improve cross-domain classification tasks. The
quantification analysis suggests a strong correlation between morality shifts,
language usage, and classification performance. We evaluate the neural
adaptation framework on a public Twitter data across 7 social movements and
gain classification improvements up to 12.1\%. Finally, we release a new data
of the COVID-19 vaccine labeled with moral values and evaluate our approach on
the new target domain. For the case study of the COVID-19 vaccine, our
adaptation framework achieves up to 5.26\% improvements over neural baselines."
Efficient Visual Tracking via Hierarchical Cross-Attention Transformer,0.261071,"In recent years, target tracking has made great progress in accuracy. This
development is mainly attributed to powerful networks (such as transformers)
and additional modules (such as online update and refinement modules). However,
less attention has been paid to tracking speed. Most state-of-the-art trackers
are satisfied with the real-time speed on powerful GPUs. However, practical
applications necessitate higher requirements for tracking speed, especially
when edge platforms with limited resources are used. In this work, we present
an efficient tracking method via a hierarchical cross-attention transformer
named HCAT. Our model runs about 195 fps on GPU, 45 fps on CPU, and 55 fps on
the edge AI platform of NVidia Jetson AGX Xavier. Experiments show that our
HCAT achieves promising results on LaSOT, GOT-10k, TrackingNet, NFS, OTB100,
UAV123, and VOT2020. Code and models are available at
https://github.com/chenxin-dlut/HCAT."
RestoreFormer: High-Quality Blind Face Restoration from Undegraded Key-Value Pairs,0.762052,"Blind face restoration is to recover a high-quality face image from unknown
degradations. As face image contains abundant contextual information, we
propose a method, RestoreFormer, which explores fully-spatial attentions to
model contextual information and surpasses existing works that use local
operators. RestoreFormer has several benefits compared to prior arts. First,
unlike the conventional multi-head self-attention in previous Vision
Transformers (ViTs), RestoreFormer incorporates a multi-head cross-attention
layer to learn fully-spatial interactions between corrupted queries and
high-quality key-value pairs. Second, the key-value pairs in ResotreFormer are
sampled from a reconstruction-oriented high-quality dictionary, whose elements
are rich in high-quality facial features specifically aimed for face
reconstruction, leading to superior restoration results. Third, RestoreFormer
outperforms advanced state-of-the-art methods on one synthetic dataset and
three real-world datasets, as well as produces images with better visual
quality."
TripleRE: Knowledge Graph Embeddings via Tripled Relation Vectors,0.864665,"Translation-based knowledge graph embedding has been one of the most
important branches for knowledge representation learning since TransE came out.
Although many translation-based approaches have achieved some progress in
recent years, the performance was still unsatisfactory. This paper proposes a
novel knowledge graph embedding method named TripleRE with two versions. The
first version of TripleRE creatively divide the relationship vector into three
parts. The second version takes advantage of the concept of residual and
achieves better performance. In addition, attempts on using NodePiece to encode
entities achieved promising results in reducing the parametric size, and solved
the problems of scalability. Experiments show that our approach achieved
state-of-the-art performance on the large-scale knowledge graph dataset, and
competitive performance on other datasets."
PatchZero: Defending against Adversarial Patch Attacks by Detecting and Zeroing the Patch,0.864665,"Adversarial patch attacks mislead neural networks by injecting adversarial
pixels within a local region. Patch attacks can be highly effective in a
variety of tasks and physically realizable via attachment (e.g. a sticker) to
the real-world objects. Despite the diversity in attack patterns, adversarial
patches tend to be highly textured and different in appearance from natural
images. We exploit this property and present PatchZero, a general defense
pipeline against white-box adversarial patches without retraining the
downstream classifier or detector. Specifically, our defense detects
adversaries at the pixel-level and ""zeros out"" the patch region by repainting
with mean pixel values. We further design a two-stage adversarial training
scheme to defend against the stronger adaptive attacks. PatchZero achieves SOTA
defense performance on the image classification (ImageNet, RESISC45), object
detection (PASCAL VOC), and video classification (UCF101) tasks with little
degradation in benign performance. In addition, PatchZero transfers to
different patch shapes and attack types."
LargeKernel3D: Scaling up Kernels in 3D Sparse CNNs,0.268584,"Recent advance in 2D CNNs has revealed that large kernels are important.
However, when directly applying large convolutional kernels in 3D CNNs, severe
difficulties are met, where those successful module designs in 2D become
surprisingly ineffective on 3D networks, including the popular depth-wise
convolution. To address this vital challenge, we instead propose the
spatial-wise partition convolution and its large-kernel module. As a result, it
avoids the optimization and efficiency issues of naive 3D large kernels. Our
large-kernel 3D CNN network, LargeKernel3D, yields notable improvement in 3D
tasks of semantic segmentation and object detection. It achieves 73.9% mIoU on
the ScanNetv2 semantic segmentation and 72.8% NDS nuScenes object detection
benchmarks, ranking 1st on the nuScenes LIDAR leaderboard. The performance
further boosts to 74.2% NDS with a simple multi-modal fusion. In addition,
LargeKernel3D can be scaled to 17x17x17 kernel size on Waymo 3D object
detection. For the first time, we show that large kernels are feasible and
essential for 3D visual tasks."
An attention mechanism based convolutional network for satellite precipitation downscaling over China,0.267941,"Precipitation is a key part of hydrological circulation and is a sensitive
indicator of climate change. The Integrated Multi-satellitE Retrievals for the
Global Precipitation Measurement (GPM) mission (IMERG) datasets are widely used
for global and regional precipitation investigations. However, their local
application is limited by the relatively coarse spatial resolution. Therefore,
in this paper, an attention mechanism based convolutional network (AMCN) is
proposed to downscale GPM IMERG monthly precipitation data. The proposed method
is an end-to-end network, which consists of a global cross-attention module, a
multi-factor cross-attention module, and a residual convolutional module,
comprehensively considering the potential relationships between precipitation
and complicated surface characteristics. In addition, a degradation loss
function based on low-resolution precipitation is designed to physically
constrain the network training, to improve the robustness of the proposed
network under different time and scale variations. The experiments demonstrate
that the proposed network significantly outperforms three baseline methods.
Finally, a geographic difference analysis method is introduced to further
improve the downscaled results by incorporating in-situ measurements for
high-quality and fine-scale precipitation estimation."
Computational historical linguistics and language diversity in South Asia,0.0912411,"South Asia is home to a plethora of languages, many of which severely lack
access to new language technologies. This linguistic diversity also results in
a research environment conducive to the study of comparative, contact, and
historical linguistics -- fields which necessitate the gathering of extensive
data from many languages. We claim that data scatteredness (rather than
scarcity) is the primary obstacle in the development of South Asian language
technology, and suggest that the study of language history is uniquely aligned
with surmounting this obstacle. We review recent developments in and at the
intersection of South Asian NLP and historical-comparative linguistics,
describing our and others' current efforts in this area. We also offer new
strategies towards breaking the data barrier."
"Towards Automated Document Revision: Grammatical Error Correction, Fluency Edits, and Beyond",0.133078,"Natural language processing technology has rapidly improved automated
grammatical error correction tasks, and the community begins to explore
document-level revision as one of the next challenges. To go beyond
sentence-level automated grammatical error correction to NLP-based
document-level revision assistant, there are two major obstacles: (1) there are
few public corpora with document-level revisions being annotated by
professional editors, and (2) it is not feasible to elicit all possible
references and evaluate the quality of revision with such references because
there are infinite possibilities of revision. This paper tackles these
challenges. First, we introduce a new document-revision corpus, TETRA, where
professional editors revised academic papers sampled from the ACL anthology
which contain few trivial grammatical errors that enable us to focus more on
document- and paragraph-level edits such as coherence and consistency. Second,
we explore reference-less and interpretable methods for meta-evaluation that
can detect quality improvements by document revision. We show the uniqueness of
TETRA compared with existing document revision corpora and demonstrate that a
fine-tuned pre-trained language model can discriminate the quality of documents
after revision even when the difference is subtle. This promising result will
encourage the community to further explore automated document revision models
and metrics in future."
Model Cascading: Towards Jointly Improving Efficiency and Accuracy of NLP Systems,0.0631089,"Do all instances need inference through the big models for a correct
prediction? Perhaps not; some instances are easy and can be answered correctly
by even small capacity models. This provides opportunities for improving the
computational efficiency of systems. In this work, we present an explorative
study on 'model cascading', a simple technique that utilizes a collection of
models of varying capacities to accurately yet efficiently output predictions.
Through comprehensive experiments in multiple task settings that differ in the
number of models available for cascading (K value), we show that cascading
improves both the computational efficiency and the prediction accuracy. For
instance, in K=3 setting, cascading saves up to 88.93% computation cost and
consistently achieves superior prediction accuracy with an improvement of up to
2.18%. We also study the impact of introducing additional models in the cascade
and show that it further increases the efficiency improvements. Finally, we
hope that our work will facilitate development of efficient NLP systems making
their widespread adoption in real-world applications possible."
Scalable Planning and Learning Framework Development for Swarm-to-Swarm Engagement Problems,0.129981,"Development of guidance, navigation and control frameworks/algorithms for
swarms attracted significant attention in recent years. That being said,
algorithms for planning swarm allocations/trajectories for engaging with enemy
swarms is largely an understudied problem. Although small-scale scenarios can
be addressed with tools from differential game theory, existing approaches fail
to scale for large-scale multi-agent pursuit evasion (PE) scenarios. In this
work, we propose a reinforcement learning (RL) based framework to decompose to
large-scale swarm engagement problems into a number of independent multi-agent
pursuit-evasion games. We simulate a variety of multi-agent PE scenarios, where
finite time capture is guaranteed under certain conditions. The calculated PE
statistics are provided as a reward signal to the high level allocation layer,
which uses an RL algorithm to allocate controlled swarm units to eliminate
enemy swarm units with maximum efficiency. We verify our approach in
large-scale swarm-to-swarm engagement simulations."
Improving Chinese Story Generation via Awareness of Syntactic Dependencies and Semantics,0.153284,"Story generation aims to generate a long narrative conditioned on a given
input. In spite of the success of prior works with the application of
pre-trained models, current neural models for Chinese stories still struggle to
generate high-quality long text narratives. We hypothesise that this stems from
ambiguity in syntactically parsing the Chinese language, which does not have
explicit delimiters for word segmentation. Consequently, neural models suffer
from the inefficient capturing of features in Chinese narratives. In this
paper, we present a new generation framework that enhances the feature
capturing mechanism by informing the generation model of dependencies between
words and additionally augmenting the semantic representation learning through
synonym denoising training. We conduct a range of experiments, and the results
demonstrate that our framework outperforms the state-of-the-art Chinese
generation models on all evaluation metrics, demonstrating the benefits of
enhanced dependency and semantic representation learning."
When Adversarial Training Meets Vision Transformers: Recipes from Training to Architecture,0.0524453,"Vision Transformers (ViTs) have recently achieved competitive performance in
broad vision tasks. Unfortunately, on popular threat models, naturally trained
ViTs are shown to provide no more adversarial robustness than convolutional
neural networks (CNNs). Adversarial training is still required for ViTs to
defend against such adversarial attacks. In this paper, we provide the first
and comprehensive study on the adversarial training recipe of ViTs via
extensive evaluation of various training techniques across benchmark datasets.
We find that pre-training and SGD optimizer are necessary for ViTs' adversarial
training. Further considering ViT as a new type of model architecture, we
investigate its adversarial robustness from the perspective of its unique
architectural components. We find, when randomly masking gradients from some
attention blocks or masking perturbations on some patches during adversarial
training, the adversarial robustness of ViTs can be remarkably improved, which
may potentially open up a line of work to explore the architectural information
inside the newly designed models like ViTs. Our code is available at
https://github.com/mo666666/When-Adversarial-Training-Meets-Vision-Transformers."
PP-YOLOE: An evolved version of YOLO,0.62568,"In this report, we present PP-YOLOE, an industrial state-of-the-art object
detector with high performance and friendly deployment. We optimize on the
basis of the previous PP-YOLOv2, using anchor-free paradigm, more powerful
backbone and neck equipped with CSPRepResStage, ET-head and dynamic label
assignment algorithm TAL. We provide s/m/l/x models for different practice
scenarios. As a result, PP-YOLOE-l achieves 51.4 mAP on COCO test-dev and 78.1
FPS on Tesla V100, yielding a remarkable improvement of (+1.9 AP, +13.35% speed
up) and (+1.3 AP, +24.96% speed up), compared to the previous state-of-the-art
industrial models PP-YOLOv2 and YOLOX respectively. Further, PP-YOLOE inference
speed achieves 149.2 FPS with TensorRT and FP16-precision. We also conduct
extensive experiments to verify the effectiveness of our designs. Source code
and pre-trained models are available at
https://github.com/PaddlePaddle/PaddleDetection."
DeciWatch: A Simple Baseline for 10x Efficient 2D and 3D Pose Estimation,0.0886643,"This paper proposes a simple baseline framework for video-based 2D/3D human
pose estimation that can achieve 10 times efficiency improvement over existing
works without any performance degradation, named DeciWatch. Unlike current
solutions that estimate each frame in a video, DeciWatch introduces a simple
yet effective sample-denoise-recover framework that only watches sparsely
sampled frames, taking advantage of the continuity of human motions and the
lightweight pose representation. Specifically, DeciWatch uniformly samples less
than 10% video frames for detailed estimation, denoises the estimated 2D/3D
poses with an efficient Transformer architecture, and then accurately recovers
the rest of the frames using another Transformer-based network. Comprehensive
experimental results on three video-based human pose estimation and body mesh
recovery tasks with four datasets validate the efficiency and effectiveness of
DeciWatch. Code is available at https://github.com/cure-lab/DeciWatch."
"Perceive, Interact, Predict: Learning Dynamic and Static Clues for End-to-End Motion Prediction",0.418725,"Motion prediction is highly relevant to the perception of dynamic objects and
static map elements in the scenarios of autonomous driving. In this work, we
propose PIP, the first end-to-end Transformer-based framework which jointly and
interactively performs online mapping, object detection and motion prediction.
PIP leverages map queries, agent queries and mode queries to encode the
instance-wise information of map elements, agents and motion intentions,
respectively. Based on the unified query representation, a differentiable
multi-task interaction scheme is proposed to exploit the correlation between
perception and prediction. Even without human-annotated HD map or agent's
historical tracking trajectory as guidance information, PIP realizes end-to-end
multi-agent motion prediction and achieves better performance than
tracking-based and HD-map-based methods. PIP provides comprehensive high-level
information of the driving scene (vectorized static map and dynamic objects
with motion information), and contributes to the downstream planning and
control. Code and models will be released for facilitating further research."
What do we Really Know about State of the Art NER?,0.16738,"Named Entity Recognition (NER) is a well researched NLP task and is widely
used in real world NLP scenarios. NER research typically focuses on the
creation of new ways of training NER, with relatively less emphasis on
resources and evaluation. Further, state of the art (SOTA) NER models, trained
on standard datasets, typically report only a single performance measure
(F-score) and we don't really know how well they do for different entity types
and genres of text, or how robust are they to new, unseen entities. In this
paper, we perform a broad evaluation of NER using a popular dataset, that takes
into consideration various text genres and sources constituting the dataset at
hand. Additionally, we generate six new adversarial test sets through small
perturbations in the original test set, replacing select entities while
retaining the context. We also train and test our models on randomly generated
train/dev/test splits followed by an experiment where the models are trained on
a select set of genres but tested genres not seen in training. These
comprehensive evaluation strategies were performed using three SOTA NER models.
Based on our results, we recommend some useful reporting practices for NER
researchers, that could help in providing a better understanding of a SOTA
model's performance in future."
Comparative layer-wise analysis of self-supervised speech models,0.678831,"Many self-supervised speech models, varying in their pre-training objective,
input modality, and pre-training data, have been proposed in the last few
years. Despite impressive successes on downstream tasks, we still have a
limited understanding of the properties encoded by the models and the
differences across models. In this work, we examine the intermediate
representations for a variety of recent models. Specifically, we measure
acoustic, phonetic, and word-level properties encoded in individual layers,
using a lightweight analysis tool based on canonical correlation analysis
(CCA). We find that these properties evolve across layers differently depending
on the model, and the variations relate to the choice of pre-training
objective. We further investigate the utility of our analyses for downstream
tasks by comparing the property trends with performance on speech recognition
and spoken language understanding tasks. We discover that CCA trends provide
reliable guidance to choose layers of interest for downstream tasks and that
single-layer performance often matches or improves upon using all layers,
suggesting implications for more efficient use of pre-trained models."
PhoCaL: A Multi-Modal Dataset for Category-Level Object Pose Estimation with Photometrically Challenging Objects,0.440829,"Object pose estimation is crucial for robotic applications and augmented
reality. Beyond instance level 6D object pose estimation methods, estimating
category-level pose and shape has become a promising trend. As such, a new
research field needs to be supported by well-designed datasets. To provide a
benchmark with high-quality ground truth annotations to the community, we
introduce a multimodal dataset for category-level object pose estimation with
photometrically challenging objects termed PhoCaL. PhoCaL comprises 60 high
quality 3D models of household objects over 8 categories including highly
reflective, transparent and symmetric objects. We developed a novel
robot-supported multi-modal (RGB, depth, polarisation) data acquisition and
annotation process. It ensures sub-millimeter accuracy of the pose for opaque
textured, shiny and transparent objects, no motion blur and perfect camera
synchronisation. To set a benchmark for our dataset, state-of-the-art RGB-D and
monocular RGB methods are evaluated on the challenging scenes of PhoCaL."
Generating natural images with direct Patch Distributions Matching,0.180484,"Many traditional computer vision algorithms generate realistic images by
requiring that each patch in the generated image be similar to a patch in a
training image and vice versa. Recently, this classical approach has been
replaced by adversarial training with a patch discriminator. The adversarial
approach avoids the computational burden of finding nearest neighbors of
patches but often requires very long training times and may fail to match the
distribution of patches. In this paper we leverage the recently developed
Sliced Wasserstein Distance and develop an algorithm that explicitly and
efficiently minimizes the distance between patch distributions in two images.
Our method is conceptually simple, requires no training and can be implemented
in a few lines of codes. On a number of image generation tasks we show that our
results are often superior to single-image-GANs, require no training, and can
generate high quality images in a few seconds. Our implementation is available
at https://github.com/ariel415el/GPDM"
A Systematic Evaluation of Response Selection for Open Domain Dialogue,0.025251,"Recent progress on neural approaches for language processing has triggered a
resurgence of interest on building intelligent open-domain chatbots. However,
even the state-of-the-art neural chatbots cannot produce satisfying responses
for every turn in a dialog. A practical solution is to generate multiple
response candidates for the same context, and then perform response
ranking/selection to determine which candidate is the best. Previous work in
response selection typically trains response rankers using synthetic data that
is formed from existing dialogs by using a ground truth response as the single
appropriate response and constructing inappropriate responses via random
selection or using adversarial methods. In this work, we curated a dataset
where responses from multiple response generators produced for the same dialog
context are manually annotated as appropriate (positive) and inappropriate
(negative). We argue that such training data better matches the actual use case
examples, enabling the models to learn to rank responses effectively. With this
new dataset, we conduct a systematic evaluation of state-of-the-art methods for
response selection, and demonstrate that both strategies of using multiple
positive candidates and using manually verified hard negative candidates can
bring in significant performance improvement in comparison to using the
adversarial training data, e.g., increase of 3% and 13% in Recall@1 score,
respectively."
DARER: Dual-task Temporal Relational Recurrent Reasoning Network for Joint Dialog Sentiment Classification and Act Recognition,0.069665,"The task of joint dialog sentiment classification (DSC) and act recognition
(DAR) aims to simultaneously predict the sentiment label and act label for each
utterance in a dialog. In this paper, we put forward a new framework which
models the explicit dependencies via integrating \textit{prediction-level
interactions} other than semantics-level interactions, more consistent with
human intuition. Besides, we propose a speaker-aware temporal graph (SATG) and
a dual-task relational temporal graph (DRTG) to introduce \textit{temporal
relations} into dialog understanding and dual-task reasoning. To implement our
framework, we propose a novel model dubbed DARER, which first generates the
context-, speaker- and temporal-sensitive utterance representations via
modeling SATG, then conducts recurrent dual-task relational reasoning on DRTG,
in which process the estimated label distributions act as key clues in
prediction-level interactions. Experiment results show that DARER outperforms
existing models by large margins while requiring much less computation resource
and costing less training time. Remarkably, on DSC task in Mastodon, DARER
gains a relative improvement of about 25% over previous best model in terms of
F1, with less than 50% parameters and about only 60% required GPU memory."
ALTO: A Large-Scale Dataset for UAV Visual Place Recognition and Localization,0.0296726,"We present the ALTO dataset, a vision-focused dataset for the development and
benchmarking of Visual Place Recognition and Localization methods for Unmanned
Aerial Vehicles. The dataset is composed of two long (approximately 150km and
260km) trajectories flown by a helicopter over Ohio and Pennsylvania, and it
includes high precision GPS-INS ground truth location data, high precision
accelerometer readings, laser altimeter readings, and RGB downward facing
camera imagery. In addition, we provide reference imagery over the flight
paths, which makes this dataset suitable for VPR benchmarking and other tasks
common in Localization, such as image registration and visual odometry. To the
author's knowledge, this is the largest real-world aerial-vehicle dataset of
this kind. Our dataset is available at https://github.com/MetaSLAM/ALTO."
Generative Aspect-Based Sentiment Analysis with Contrastive Learning and Expressive Structure,0.0323173,"Generative models have demonstrated impressive results on Aspect-based
Sentiment Analysis (ABSA) tasks, particularly for the emerging task of
extracting Aspect-Category-Opinion-Sentiment (ACOS) quadruples. However, these
models struggle with implicit sentiment expressions, which are commonly
observed in opinionated content such as online reviews. In this work, we
introduce GEN-SCL-NAT, which consists of two techniques for improved structured
generation for ACOS quadruple extraction. First, we propose GEN-SCL, a
supervised contrastive learning objective that aids quadruple prediction by
encouraging the model to produce input representations that are discriminable
across key input attributes, such as sentiment polarity and the existence of
implicit opinions and aspects. Second, we introduce GEN-NAT, a new structured
generation format that better adapts autoregressive encoder-decoder models to
extract quadruples in a generative fashion. Experimental results show that
GEN-SCL-NAT achieves top performance across three ACOS datasets, averaging
1.48% F1 improvement, with a maximum 1.73% increase on the LAPTOP-L1 dataset.
Additionally, we see significant gains on implicit aspect and opinion splits
that have been shown as challenging for existing ACOS approaches."
Sequential Manipulation Planning on Scene Graph,0.124577,"We devise a 3D scene graph representation, contact graph+ (cg+), for
efficient sequential task planning. Augmented with predicate-like attributes,
this contact graph-based representation abstracts scene layouts with succinct
geometric information and valid robot-scene interactions. Goal configurations,
naturally specified on contact graphs, can be produced by a genetic algorithm
with a stochastic optimization method. A task plan is then initialized by
computing the Graph Editing Distance (GED) between the initial contact graphs
and the goal configurations, which generates graph edit operations
corresponding to possible robot actions. We finalize the task plan by imposing
constraints to regulate the temporal feasibility of graph edit operations,
ensuring valid task and motion correspondences. In a series of simulations and
experiments, robots successfully complete complex sequential object
rearrangement tasks that are difficult to specify using conventional planning
language like Planning Domain Definition Language (PDDL), demonstrating the
high feasibility and potential of robot sequential task planning on contact
graph."
PermutoSDF: Fast Multi-View Reconstruction with Implicit Surfaces using Permutohedral Lattices,0.551371,"Neural radiance-density field methods have become increasingly popular for
the task of novel-view rendering. Their recent extension to hash-based
positional encoding ensures fast training and inference with visually pleasing
results. However, density-based methods struggle with recovering accurate
surface geometry. Hybrid methods alleviate this issue by optimizing the density
based on an underlying SDF. However, current SDF methods are overly smooth and
miss fine geometric details. In this work, we combine the strengths of these
two lines of work in a novel hash-based implicit surface representation. We
propose improvements to the two areas by replacing the voxel hash encoding with
a permutohedral lattice which optimizes faster, especially for higher
dimensions. We additionally propose a regularization scheme which is crucial
for recovering high-frequency geometric detail. We evaluate our method on
multiple datasets and show that we can recover geometric detail at the level of
pores and wrinkles while using only RGB images for supervision. Furthermore,
using sphere tracing we can render novel views at 30 fps on an RTX 3090. Code
is publicly available at: https://radualexandru.github.io/permuto_sdf"
Probing Speech Emotion Recognition Transformers for Linguistic Knowledge,0.0725412,"Large, pre-trained neural networks consisting of self-attention layers
(transformers) have recently achieved state-of-the-art results on several
speech emotion recognition (SER) datasets. These models are typically
pre-trained in self-supervised manner with the goal to improve automatic speech
recognition performance -- and thus, to understand linguistic information. In
this work, we investigate the extent in which this information is exploited
during SER fine-tuning. Using a reproducible methodology based on open-source
tools, we synthesise prosodically neutral speech utterances while varying the
sentiment of the text. Valence predictions of the transformer model are very
reactive to positive and negative sentiment content, as well as negations, but
not to intensifiers or reducers, while none of those linguistic features impact
arousal or dominance. These findings show that transformers can successfully
leverage linguistic information to improve their valence predictions, and that
linguistic analysis should be included in their testing."
Towards Textual Out-of-Domain Detection without In-Domain Labels,0.133314,"In many real-world settings, machine learning models need to identify user
inputs that are out-of-domain (OOD) so as to avoid performing wrong actions.
This work focuses on a challenging case of OOD detection, where no labels for
in-domain data are accessible (e.g., no intent labels for the intent
classification task). To this end, we first evaluate different language model
based approaches that predict likelihood for a sequence of tokens. Furthermore,
we propose a novel representation learning based method by combining
unsupervised clustering and contrastive learning so that better data
representations for OOD detection can be learned. Through extensive
experiments, we demonstrate that this method can significantly outperform
likelihood-based methods and can be even competitive to the state-of-the-art
supervised approaches with label information."
Detector-Free Weakly Supervised Group Activity Recognition,0.345982,"Group activity recognition is the task of understanding the activity
conducted by a group of people as a whole in a multi-person video. Existing
models for this task are often impractical in that they demand ground-truth
bounding box labels of actors even in testing or rely on off-the-shelf object
detectors. Motivated by this, we propose a novel model for group activity
recognition that depends neither on bounding box labels nor on object detector.
Our model based on Transformer localizes and encodes partial contexts of a
group activity by leveraging the attention mechanism, and represents a video
clip as a set of partial context embeddings. The embedding vectors are then
aggregated to form a single group representation that reflects the entire
context of an activity while capturing temporal evolution of each partial
context. Our method achieves outstanding performance on two benchmarks,
Volleyball and NBA datasets, surpassing not only the state of the art trained
with the same level of supervision, but also some of existing models relying on
stronger supervision."
Towards Summary Candidates Fusion,0.230277,"Sequence-to-sequence deep neural models fine-tuned for abstractive
summarization can achieve great performance on datasets with enough human
annotations. Yet, it has been shown that they have not reached their full
potential, with a wide gap between the top beam search output and the oracle
beam. Recently, re-ranking methods have been proposed, to learn to select a
better summary candidate. However, such methods are limited by the summary
quality aspects captured by the first-stage candidates. To bypass this
limitation, we propose a new paradigm in second-stage abstractive summarization
called SummaFusion that fuses several summary candidates to produce a novel
abstractive second-stage summary. Our method works well on several
summarization datasets, improving both the ROUGE scores and qualitative
properties of fused summaries. It is especially good when the candidates to
fuse are worse, such as in the few-shot setup where we set a new
state-of-the-art. We will make our code and checkpoints available at
https://github.com/ntunlp/SummaFusion/."
Fast Event-based Optical Flow Estimation by Triplet Matching,0.0934411,"Event cameras are novel bio-inspired sensors that offer advantages over
traditional cameras (low latency, high dynamic range, low power, etc.). Optical
flow estimation methods that work on packets of events trade off speed for
accuracy, while event-by-event (incremental) methods have strong assumptions
and have not been tested on common benchmarks that quantify progress in the
field. Towards applications on resource-constrained devices, it is important to
develop optical flow algorithms that are fast, light-weight and accurate. This
work leverages insights from neuroscience, and proposes a novel optical flow
estimation scheme based on triplet matching. The experiments on publicly
available benchmarks demonstrate its capability to handle complex scenes with
comparable results as prior packet-based algorithms. In addition, the proposed
method achieves the fastest execution time (> 10 kHz) on standard CPUs as it
requires only three events in estimation. We hope that our research opens the
door to real-time, incremental motion estimation methods and applications in
real-world scenarios."
Knowledge Is Flat: A Seq2Seq Generative Framework for Various Knowledge Graph Completion,0.347329,"Knowledge Graph Completion (KGC) has been recently extended to multiple
knowledge graph (KG) structures, initiating new research directions, e.g.
static KGC, temporal KGC and few-shot KGC. Previous works often design KGC
models closely coupled with specific graph structures, which inevitably results
in two drawbacks: 1) structure-specific KGC models are mutually incompatible;
2) existing KGC methods are not adaptable to emerging KGs. In this paper, we
propose KG-S2S, a Seq2Seq generative framework that could tackle different
verbalizable graph structures by unifying the representation of KG facts into
""flat"" text, regardless of their original form. To remedy the KG structure
information loss from the ""flat"" text, we further improve the input
representations of entities and relations, and the inference algorithm in
KG-S2S. Experiments on five benchmarks show that KG-S2S outperforms many
competitive baselines, setting new state-of-the-art performance. Finally, we
analyze KG-S2S's ability on the different relations and the Non-entity
Generations."
Open Vocabulary Semantic Segmentation with Patch Aligned Contrastive Learning,0.461305,"We introduce Patch Aligned Contrastive Learning (PACL), a modified
compatibility function for CLIP's contrastive loss, intending to train an
alignment between the patch tokens of the vision encoder and the CLS token of
the text encoder. With such an alignment, a model can identify regions of an
image corresponding to a given text input, and therefore transfer seamlessly to
the task of open vocabulary semantic segmentation without requiring any
segmentation annotations during training. Using pre-trained CLIP encoders with
PACL, we are able to set the state-of-the-art on the task of open vocabulary
zero-shot segmentation on 4 different segmentation benchmarks: Pascal VOC,
Pascal Context, COCO Stuff and ADE20K. Furthermore, we show that PACL is also
applicable to image-level predictions and when used with a CLIP backbone,
provides a general improvement in zero-shot classification accuracy compared to
CLIP, across a suite of 12 image classification datasets."
High-resolution Face Swapping via Latent Semantics Disentanglement,0.42671,"We present a novel high-resolution face swapping method using the inherent
prior knowledge of a pre-trained GAN model. Although previous research can
leverage generative priors to produce high-resolution results, their quality
can suffer from the entangled semantics of the latent space. We explicitly
disentangle the latent semantics by utilizing the progressive nature of the
generator, deriving structure attributes from the shallow layers and appearance
attributes from the deeper ones. Identity and pose information within the
structure attributes are further separated by introducing a landmark-driven
structure transfer latent direction. The disentangled latent code produces rich
generative features that incorporate feature blending to produce a plausible
swapping result. We further extend our method to video face swapping by
enforcing two spatio-temporal constraints on the latent space and the image
space. Extensive experiments demonstrate that the proposed method outperforms
state-of-the-art image/video face swapping methods in terms of hallucination
quality and consistency. Code can be found at:
https://github.com/cnnlstm/FSLSD_HiRes."
JParaCrawl v3.0: A Large-scale English-Japanese Parallel Corpus,0.222885,"Most current machine translation models are mainly trained with parallel
corpora, and their translation accuracy largely depends on the quality and
quantity of the corpora. Although there are billions of parallel sentences for
a few language pairs, effectively dealing with most language pairs is difficult
due to a lack of publicly available parallel corpora. This paper creates a
large parallel corpus for English-Japanese, a language pair for which only
limited resources are available, compared to such resource-rich languages as
English-German. It introduces a new web-based English-Japanese parallel corpus
named JParaCrawl v3.0. Our new corpus contains more than 21 million unique
parallel sentence pairs, which is more than twice as many as the previous
JParaCrawl v2.0 corpus. Through experiments, we empirically show how our new
corpus boosts the accuracy of machine translation models on various domains.
The JParaCrawl v3.0 corpus will eventually be publicly available online for
research purposes."
MoDem: Accelerating Visual Model-Based Reinforcement Learning with Demonstrations,-1.0,"Poor sample efficiency continues to be the primary challenge for deployment
of deep Reinforcement Learning (RL) algorithms for real-world applications, and
in particular for visuo-motor control. Model-based RL has the potential to be
highly sample efficient by concurrently learning a world model and using
synthetic rollouts for planning and policy improvement. However, in practice,
sample-efficient learning with model-based RL is bottlenecked by the
exploration challenge. In this work, we find that leveraging just a handful of
demonstrations can dramatically improve the sample-efficiency of model-based
RL. Simply appending demonstrations to the interaction dataset, however, does
not suffice. We identify key ingredients for leveraging demonstrations in model
learning -- policy pretraining, targeted exploration, and oversampling of
demonstration data -- which forms the three phases of our model-based RL
framework. We empirically study three complex visuo-motor control domains and
find that our method is 150%-250% more successful in completing sparse reward
tasks compared to prior approaches in the low data regime (100K interaction
steps, 5 demonstrations). Code and videos are available at:
https://nicklashansen.github.io/modemrl"
COIN: Co-Cluster Infomax for Bipartite Graphs,0.0815848,"Bipartite graphs are powerful data structures to model interactions between
two types of nodes, which have been used in a variety of applications, such as
recommender systems, information retrieval, and drug discovery. A fundamental
challenge for bipartite graphs is how to learn informative node embeddings.
Despite the success of recent self-supervised learning methods on bipartite
graphs, their objectives are discriminating instance-wise positive and negative
node pairs, which could contain cluster-level errors. In this paper, we
introduce a novel co-cluster infomax (COIN) framework, which captures the
cluster-level information by maximizing the mutual information of co-clusters.
Different from previous infomax methods which estimate mutual information by
neural networks, COIN could easily calculate mutual information. Besides, COIN
is an end-to-end coclustering method which can be trained jointly with other
objective functions and optimized via back-propagation. Furthermore, we also
provide theoretical analysis for COIN. We theoretically prove that COIN is able
to effectively increase the mutual information of node embeddings and COIN is
upper-bounded by the prior distributions of nodes. We extensively evaluate the
proposed COIN framework on various benchmark datasets and tasks to demonstrate
the effectiveness of COIN."
Improving Multi-Document Summarization through Referenced Flexible Extraction with Credit-Awareness,0.488539,"A notable challenge in Multi-Document Summarization (MDS) is the
extremely-long length of the input. In this paper, we present an
extract-then-abstract Transformer framework to overcome the problem.
Specifically, we leverage pre-trained language models to construct a
hierarchical extractor for salient sentence selection across documents and an
abstractor for rewriting the selected contents as summaries. However, learning
such a framework is challenging since the optimal contents for the abstractor
are generally unknown. Previous works typically create pseudo extraction oracle
to enable the supervised learning for both the extractor and the abstractor.
Nevertheless, we argue that the performance of such methods could be restricted
due to the insufficient information for prediction and inconsistent objectives
between training and testing. To this end, we propose a loss weighting
mechanism that makes the model aware of the unequal importance for the
sentences not in the pseudo extraction oracle, and leverage the fine-tuned
abstractor to generate summary references as auxiliary signals for learning the
extractor. Moreover, we propose a reinforcement learning method that can
efficiently apply to the extractor for harmonizing the optimization between
training and testing. Experiment results show that our framework substantially
outperforms strong baselines with comparable model sizes and achieves the best
results on the Multi-News, Multi-XScience, and WikiCatSum corpora."
Constrained Optimization with Dynamic Bound-scaling for Effective NLPBackdoor Defense,0.605026,"We develop a novel optimization method for NLPbackdoor inversion. We leverage
a dynamically reducing temperature coefficient in the softmax function to
provide changing loss landscapes to the optimizer such that the process
gradually focuses on the ground truth trigger, which is denoted as a one-hot
value in a convex hull. Our method also features a temperature rollback
mechanism to step away from local optimals, exploiting the observation that
local optimals can be easily deter-mined in NLP trigger inversion (while not in
general optimization). We evaluate the technique on over 1600 models (with
roughly half of them having injected backdoors) on 3 prevailing NLP tasks, with
4 different backdoor attacks and 7 architectures. Our results show that the
technique is able to effectively and efficiently detect and remove backdoors,
outperforming 4 baseline methods."
Convolutional Neural Networks for Image Spam Detection,0.153383,"Spam can be defined as unsolicited bulk email. In an effort to evade
text-based filters, spammers sometimes embed spam text in an image, which is
referred to as image spam. In this research, we consider the problem of image
spam detection, based on image analysis. We apply convolutional neural networks
(CNN) to this problem, we compare the results obtained using CNNs to other
machine learning techniques, and we compare our results to previous related
work. We consider both real-world image spam and challenging image spam-like
datasets. Our results improve on previous work by employing CNNs based on a
novel feature set consisting of a combination of the raw image and Canny edges."
A Close Look into the Calibration of Pre-trained Language Models,0.169751,"Pre-trained language models (PLMs) may fail in giving reliable estimates of
their predictive uncertainty. We take a close look into this problem, aiming to
answer two questions: (1) Do PLMs learn to become calibrated in the training
process? (2) How effective are existing calibration methods? For the first
question, we conduct fine-grained control experiments to study the dynamic
change in PLMs' calibration performance in training. We consider six factors as
control variables, including dataset difficulty, available training samples,
training steps, the number of tunable parameters, model scale, and pretraining.
We observe a consistent change in calibration performance across six factors.
We find that PLMs don't learn to become calibrated in training, evidenced by
the continual increase in confidence, no matter whether the predictions are
correct or not. We highlight that our finding somewhat contradicts two
established conclusions: (a) Larger PLMs are more calibrated; (b) Pretraining
improves model calibration. Next, we study the effectiveness of existing
calibration methods in mitigating the overconfidence issue. Besides unlearnable
calibration methods (e.g., label smoothing), we adapt and extend two recently
proposed learnable methods that directly collect data to train models to have
reasonable confidence estimations. Experimental results show that learnable
methods significantly reduce PLMs' confidence in wrong predictions. The code is
available at \url{https://github.com/lifan-yuan/PLMCalibration}."
Zero-Shot Voice Conditioning for Denoising Diffusion TTS Models,0.317428,"We present a novel way of conditioning a pretrained denoising diffusion
speech model to produce speech in the voice of a novel person unseen during
training. The method requires a short (~3 seconds) sample from the target
person, and generation is steered at inference time, without any training
steps. At the heart of the method lies a sampling process that combines the
estimation of the denoising model with a low-pass version of the new speaker's
sample. The objective and subjective evaluations show that our sampling method
can generate a voice similar to that of the target speaker in terms of
frequency, with an accuracy comparable to state-of-the-art methods, and without
training."
Auto-ViT-Acc: An FPGA-Aware Automatic Acceleration Framework for Vision Transformer with Mixed-Scheme Quantization,0.889543,"Vision transformers (ViTs) are emerging with significantly improved accuracy
in computer vision tasks. However, their complex architecture and enormous
computation/storage demand impose urgent needs for new hardware accelerator
design methodology. This work proposes an FPGA-aware automatic ViT acceleration
framework based on the proposed mixed-scheme quantization. To the best of our
knowledge, this is the first FPGA-based ViT acceleration framework exploring
model quantization. Compared with state-of-the-art ViT quantization work
(algorithmic approach only without hardware acceleration), our quantization
achieves 0.47% to 1.36% higher Top-1 accuracy under the same bit-width.
Compared with the 32-bit floating-point baseline FPGA accelerator, our
accelerator achieves around 5.6x improvement on the frame rate (i.e., 56.8 FPS
vs. 10.0 FPS) with 0.71% accuracy drop on ImageNet dataset for DeiT-base."
Exploring Document-Level Literary Machine Translation with Parallel Paragraphs from World Literature,0.465856,"Literary translation is a culturally significant task, but it is bottlenecked
by the small number of qualified literary translators relative to the many
untranslated works published around the world. Machine translation (MT) holds
potential to complement the work of human translators by improving both
training procedures and their overall efficiency. Literary translation is less
constrained than more traditional MT settings since translators must balance
meaning equivalence, readability, and critical interpretability in the target
language. This property, along with the complex discourse-level context present
in literary texts, also makes literary MT more challenging to computationally
model and evaluate. To explore this task, we collect a dataset (Par3) of
non-English language novels in the public domain, each aligned at the paragraph
level to both human and automatic English translations. Using Par3, we discover
that expert literary translators prefer reference human translations over
machine-translated paragraphs at a rate of 84%, while state-of-the-art
automatic MT metrics do not correlate with those preferences. The experts note
that MT outputs contain not only mistranslations, but also discourse-disrupting
errors and stylistic inconsistencies. To address these problems, we train a
post-editing model whose output is preferred over normal MT output at a rate of
69% by experts. We publicly release Par3 at
https://github.com/katherinethai/par3/ to spur future research into literary
MT."
Spatio-Temporal Dynamic Graph Relation Learning for Urban Metro Flow Prediction,0.164875,"Urban metro flow prediction is of great value for metro operation scheduling,
passenger flow management and personal travel planning. However, it faces two
main challenges. First, different metro stations, e.g. transfer stations and
non-transfer stations, have unique traffic patterns. Second, it is challenging
to model complex spatio-temporal dynamic relation of metro stations. To address
these challenges, we develop a spatio-temporal dynamic graph relational
learning model (STDGRL) to predict urban metro station flow. First, we propose
a spatio-temporal node embedding representation module to capture the traffic
patterns of different stations. Second, we employ a dynamic graph relationship
learning module to learn dynamic spatial relationships between metro stations
without a predefined graph adjacency matrix. Finally, we provide a
transformer-based long-term relationship prediction module for long-term metro
flow prediction. Extensive experiments are conducted based on metro data in
Beijing, Shanghai, Chongqing and Hangzhou. Experimental results show the
advantages of our method beyond 11 baselines for urban metro flow prediction."
Learning Audio-Text Agreement for Open-vocabulary Keyword Spotting,0.694871,"In this paper, we propose a novel end-to-end user-defined keyword spotting
method that utilizes linguistically corresponding patterns between speech and
text sequences. Unlike previous approaches requiring speech keyword enrollment,
our method compares input queries with an enrolled text keyword sequence. To
place the audio and text representations within a common latent space, we adopt
an attention-based cross-modal matching approach that is trained in an
end-to-end manner with monotonic matching loss and keyword classification loss.
We also utilize a de-noising loss for the acoustic embedding network to improve
robustness in noisy environments. Additionally, we introduce the LibriPhrase
dataset, a new short-phrase dataset based on LibriSpeech for efficiently
training keyword spotting models. Our proposed method achieves competitive
results on various evaluation sets compared to other single-modal and
cross-modal baselines."
Interactive Multi-Class Tiny-Object Detection,0.0681559,"Annotating tens or hundreds of tiny objects in a given image is laborious yet
crucial for a multitude of Computer Vision tasks. Such imagery typically
contains objects from various categories, yet the multi-class interactive
annotation setting for the detection task has thus far been unexplored. To
address these needs, we propose a novel interactive annotation method for
multiple instances of tiny objects from multiple classes, based on a few
point-based user inputs. Our approach, C3Det, relates the full image context
with annotator inputs in a local and global manner via late-fusion and
feature-correlation, respectively. We perform experiments on the Tiny-DOTA and
LCell datasets using both two-stage and one-stage object detection
architectures to verify the efficacy of our approach. Our approach outperforms
existing approaches in interactive annotation, achieving higher mAP with fewer
clicks. Furthermore, we validate the annotation efficiency of our approach in a
user study where it is shown to be 2.85x faster and yield only 0.36x task load
(NASA-TLX, lower is better) compared to manual annotation. The code is
available at
https://github.com/ChungYi347/Interactive-Multi-Class-Tiny-Object-Detection."
DocEnTr: An End-to-End Document Image Enhancement Transformer,0.621617,"Document images can be affected by many degradation scenarios, which cause
recognition and processing difficulties. In this age of digitization, it is
important to denoise them for proper usage. To address this challenge, we
present a new encoder-decoder architecture based on vision transformers to
enhance both machine-printed and handwritten document images, in an end-to-end
fashion. The encoder operates directly on the pixel patches with their
positional information without the use of any convolutional layers, while the
decoder reconstructs a clean image from the encoded patches. Conducted
experiments show a superiority of the proposed model compared to the state-of
the-art methods on several DIBCO benchmarks. Code and models will be publicly
available at: \url{https://github.com/dali92002/DocEnTR}."
Meta Spatio-Temporal Debiasing for Video Scene Graph Generation,0.694763,"Video scene graph generation (VidSGG) aims to parse the video content into
scene graphs, which involves modeling the spatio-temporal contextual
information in the video. However, due to the long-tailed training data in
datasets, the generalization performance of existing VidSGG models can be
affected by the spatio-temporal conditional bias problem. In this work, from
the perspective of meta-learning, we propose a novel Meta Video Scene Graph
Generation (MVSGG) framework to address such a bias problem. Specifically, to
handle various types of spatio-temporal conditional biases, our framework first
constructs a support set and a group of query sets from the training data,
where the data distribution of each query set is different from that of the
support set w.r.t. a type of conditional bias. Then, by performing a novel meta
training and testing process to optimize the model to obtain good testing
performance on these query sets after training on the support set, our
framework can effectively guide the model to learn to well generalize against
biases. Extensive experiments demonstrate the efficacy of our proposed
framework."
VolRecon: Volume Rendering of Signed Ray Distance Functions for Generalizable Multi-View Reconstruction,0.337467,"The success of the Neural Radiance Fields (NeRF) in novel view synthesis has
inspired researchers to propose neural implicit scene reconstruction. However,
most existing neural implicit reconstruction methods optimize per-scene
parameters and therefore lack generalizability to new scenes. We introduce
VolRecon, a novel generalizable implicit reconstruction method with Signed Ray
Distance Function (SRDF). To reconstruct the scene with fine details and little
noise, VolRecon combines projection features aggregated from multi-view
features, and volume features interpolated from a coarse global feature volume.
Using a ray transformer, we compute SRDF values of sampled points on a ray and
then render color and depth. On DTU dataset, VolRecon outperforms SparseNeuS by
about 30% in sparse view reconstruction and achieves comparable accuracy as
MVSNet in full view reconstruction. Furthermore, our approach exhibits good
generalization performance on the large-scale ETH3D benchmark."
PSP: Pre-trained Soft Prompts for Few-Shot Abstractive Summarization,0.3437,"Few-shot abstractive summarization has become a challenging task in natural
language generation. To support it, we designed a novel soft prompts
architecture coupled with a prompt pre-training plus fine-tuning paradigm that
is effective and tunes only extremely light parameters. The soft prompts
include continuous input embeddings across an encoder and a decoder to fit the
structure of the generation models. Importantly, a novel inner-prompt placed in
the text is introduced to capture document-level information. The aim is to
devote attention to understanding the document that better prompts the model to
generate document-related content. The first step in the summarization
procedure is to conduct prompt pre-training with self-supervised pseudo-data.
This teaches the model basic summarizing capabilities. The model is then
fine-tuned with few-shot examples. Experimental results on the CNN/DailyMail
and XSum datasets show that our method, with only 0.1% of the parameters,
outperforms full-model tuning where all model parameters are tuned. It also
surpasses Prompt Tuning by a large margin and delivers competitive results
against Prefix-Tuning with 3% of the parameters."
HULC: 3D Human Motion Capture with Pose Manifold Sampling and Dense Contact Guidance,0.240826,"Marker-less monocular 3D human motion capture (MoCap) with scene interactions
is a challenging research topic relevant for extended reality, robotics and
virtual avatar generation. Due to the inherent depth ambiguity of monocular
settings, 3D motions captured with existing methods often contain severe
artefacts such as incorrect body-scene inter-penetrations, jitter and body
floating. To tackle these issues, we propose HULC, a new approach for 3D human
MoCap which is aware of the scene geometry. HULC estimates 3D poses and dense
body-environment surface contacts for improved 3D localisations, as well as the
absolute scale of the subject. Furthermore, we introduce a 3D pose trajectory
optimisation based on a novel pose manifold sampling that resolves erroneous
body-environment inter-penetrations. Although the proposed method requires less
structured inputs compared to existing scene-aware monocular MoCap algorithms,
it produces more physically-plausible poses: HULC significantly and
consistently outperforms the existing approaches in various experiments and on
different metrics. Project page: https://vcai.mpi-inf.mpg.de/projects/HULC/."
Dialog Acts for Task-Driven Embodied Agents,0.109679,"Embodied agents need to be able to interact in natural language understanding
task descriptions and asking appropriate follow up questions to obtain
necessary information to be effective at successfully accomplishing tasks for a
wide range of users. In this work, we propose a set of dialog acts for
modelling such dialogs and annotate the TEACh dataset that includes over 3,000
situated, task oriented conversations (consisting of 39.5k utterances in total)
with dialog acts. TEACh-DA is one of the first large scale dataset of dialog
act annotations for embodied task completion. Furthermore, we demonstrate the
use of this annotated dataset in training models for tagging the dialog acts of
a given utterance, predicting the dialog act of the next response given a
dialog history, and use the dialog acts to guide agent's non-dialog behaviour.
In particular, our experiments on the TEACh Execution from Dialog History task
where the model predicts the sequence of low level actions to be executed in
the environment for embodied task completion, demonstrate that dialog acts can
improve end task success rate by up to 2 points compared to the system without
dialog acts."
Causal Fairness Analysis,0.156036,"Decision-making systems based on AI and machine learning have been used
throughout a wide range of real-world scenarios, including healthcare, law
enforcement, education, and finance. It is no longer far-fetched to envision a
future where autonomous systems will be driving entire business decisions and,
more broadly, supporting large-scale decision-making infrastructure to solve
society's most challenging problems. Issues of unfairness and discrimination
are pervasive when decisions are being made by humans, and remain (or are
potentially amplified) when decisions are made using machines with little
transparency, accountability, and fairness. In this paper, we introduce a
framework for \textit{causal fairness analysis} with the intent of filling in
this gap, i.e., understanding, modeling, and possibly solving issues of
fairness in decision-making settings. The main insight of our approach will be
to link the quantification of the disparities present on the observed data with
the underlying, and often unobserved, collection of causal mechanisms that
generate the disparity in the first place, challenge we call the Fundamental
Problem of Causal Fairness Analysis (FPCFA). In order to solve the FPCFA, we
study the problem of decomposing variations and empirical measures of fairness
that attribute such variations to structural mechanisms and different units of
the population. Our effort culminates in the Fairness Map, which is the first
systematic attempt to organize and explain the relationship between different
criteria found in the literature. Finally, we study which causal assumptions
are minimally needed for performing causal fairness analysis and propose a
Fairness Cookbook, which allows data scientists to assess the existence of
disparate impact and disparate treatment."
SC-wLS: Towards Interpretable Feed-forward Camera Re-localization,0.0723039,"Visual re-localization aims to recover camera poses in a known environment,
which is vital for applications like robotics or augmented reality.
Feed-forward absolute camera pose regression methods directly output poses by a
network, but suffer from low accuracy. Meanwhile, scene coordinate based
methods are accurate, but need iterative RANSAC post-processing, which brings
challenges to efficient end-to-end training and inference. In order to have the
best of both worlds, we propose a feed-forward method termed SC-wLS that
exploits all scene coordinate estimates for weighted least squares pose
regression. This differentiable formulation exploits a weight network imposed
on 2D-3D correspondences, and requires pose supervision only. Qualitative
results demonstrate the interpretability of learned weights. Evaluations on
7Scenes and Cambridge datasets show significantly promoted performance when
compared with former feed-forward counterparts. Moreover, our SC-wLS method
enables a new capability: self-supervised test-time adaptation on the weight
network. Codes and models are publicly available."
Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries,0.218136,"Learning under a continuously changing data distribution with incorrect
labels is a desirable real-world problem yet challenging. A large body of
continual learning (CL) methods, however, assumes data streams with clean
labels, and online learning scenarios under noisy data streams are yet
underexplored. We consider a more practical CL task setup of an online learning
from blurry data stream with corrupted labels, where existing CL methods
struggle. To address the task, we first argue the importance of both diversity
and purity of examples in the episodic memory of continual learning models. To
balance diversity and purity in the episodic memory, we propose a novel
strategy to manage and use the memory by a unified approach of label noise
aware diverse sampling and robust learning with semi-supervised learning. Our
empirical validations on four real-world or synthetic noise datasets (CIFAR10
and 100, mini-WebVision, and Food-101N) exhibit that our method significantly
outperforms prior arts in this realistic and challenging continual learning
scenario. Code and data splits are available in
https://github.com/clovaai/puridiver."
PolyHope: Two-Level Hope Speech Detection from Tweets,0.243655,"Hope is characterized as openness of spirit toward the future, a desire,
expectation, and wish for something to happen or to be true that remarkably
affects human's state of mind, emotions, behaviors, and decisions. Hope is
usually associated with concepts of desired expectations and
possibility/probability concerning the future. Despite its importance, hope has
rarely been studied as a social media analysis task. This paper presents a hope
speech dataset that classifies each tweet first into ""Hope"" and ""Not Hope"",
then into three fine-grained hope categories: ""Generalized Hope"", ""Realistic
Hope"", and ""Unrealistic Hope"" (along with ""Not Hope""). English tweets in the
first half of 2022 were collected to build this dataset. Furthermore, we
describe our annotation process and guidelines in detail and discuss the
challenges of classifying hope and the limitations of the existing hope speech
detection corpora. In addition, we reported several baselines based on
different learning approaches, such as traditional machine learning, deep
learning, and transformers, to benchmark our dataset. We evaluated our
baselines using weighted-averaged and macro-averaged F1-scores. Observations
show that a strict process for annotator selection and detailed annotation
guidelines enhanced the dataset's quality. This strict annotation process
resulted in promising performance for simple machine learning classifiers with
only bi-grams; however, binary and multiclass hope speech detection results
reveal that contextual embedding models have higher performance in this
dataset."
GazeNeRF: 3D-Aware Gaze Redirection with Neural Radiance Fields,0.0662565,"We propose GazeNeRF, a 3D-aware method for the task of gaze redirection.
Existing gaze redirection methods operate on 2D images and struggle to generate
3D consistent results. Instead, we build on the intuition that the face region
and eyeballs are separate 3D structures that move in a coordinated yet
independent fashion. Our method leverages recent advancements in conditional
image-based neural radiance fields and proposes a two-stream architecture that
predicts volumetric features for the face and eye regions separately. Rigidly
transforming the eye features via a 3D rotation matrix provides fine-grained
control over the desired gaze angle. The final, redirected image is then
attained via differentiable volume compositing. Our experiments show that this
architecture outperforms naively conditioned NeRF baselines as well as previous
state-of-the-art 2D gaze redirection methods in terms of redirection accuracy
and identity preservation."
NFLAT: Non-Flat-Lattice Transformer for Chinese Named Entity Recognition,-1.0,"Recently, Flat-LAttice Transformer (FLAT) has achieved great success in
Chinese Named Entity Recognition (NER). FLAT performs lexical enhancement by
constructing flat lattices, which mitigates the difficulties posed by blurred
word boundaries and the lack of word semantics. In FLAT, the positions of
starting and ending characters are used to connect a matching word. However,
this method is likely to match more words when dealing with long texts,
resulting in long input sequences. Therefore, it significantly increases the
memory and computational costs of the self-attention module. To deal with this
issue, we advocate a novel lexical enhancement method, InterFormer, that
effectively reduces the amount of computational and memory costs by
constructing non-flat lattices. Furthermore, with InterFormer as the backbone,
we implement NFLAT for Chinese NER. NFLAT decouples lexicon fusion and context
feature encoding. Compared with FLAT, it reduces unnecessary attention
calculations in ""word-character"" and ""word-word"". This reduces the memory usage
by about 50% and can use more extensive lexicons or higher batches for network
training. The experimental results obtained on several well-known benchmarks
demonstrate the superiority of the proposed method over the state-of-the-art
hybrid (character-word) models."
Towards Better Chinese-centric Neural Machine Translation for Low-resource Languages,0.267489,"The last decade has witnessed enormous improvements in science and
technology, stimulating the growing demand for economic and cultural exchanges
in various countries. Building a neural machine translation (NMT) system has
become an urgent trend, especially in the low-resource setting. However, recent
work tends to study NMT systems for low-resource languages centered on English,
while few works focus on low-resource NMT systems centered on other languages
such as Chinese. To achieve this, the low-resource multilingual translation
challenge of the 2021 iFLYTEK AI Developer Competition provides the
Chinese-centric multilingual low-resource NMT tasks, where participants are
required to build NMT systems based on the provided low-resource samples. In
this paper, we present the winner competition system that leverages monolingual
word embeddings data enhancement, bilingual curriculum learning, and
contrastive re-ranking. In addition, a new Incomplete-Trust (In-trust) loss
function is proposed to replace the traditional cross-entropy loss when
training. The experimental results demonstrate that the implementation of these
ideas leads better performance than other state-of-the-art methods. All the
experimental codes are released at:
https://github.com/WENGSYX/Low-resource-text-translation."
Human Activity Recognition from Wi-Fi CSI Data Using Principal Component-Based Wavelet CNN,0.106452,"Human Activity Recognition (HAR) is an emerging technology with several
applications in surveillance, security, and healthcare sectors. Noninvasive HAR
systems based on Wi-Fi Channel State Information (CSI) signals can be developed
leveraging the quick growth of ubiquitous Wi-Fi technologies, and the
correlation between CSI dynamics and body motions. In this paper, we propose
Principal Component-based Wavelet Convolutional Neural Network (or PCWCNN) -- a
novel approach that offers robustness and efficiency for practical real-time
applications. Our proposed method incorporates two efficient preprocessing
algorithms -- the Principal Component Analysis (PCA) and the Discrete Wavelet
Transform (DWT). We employ an adaptive activity segmentation algorithm that is
accurate and computationally light. Additionally, we used the Wavelet CNN for
classification, which is a deep convolutional network analogous to the
well-studied ResNet and DenseNet networks. We empirically show that our
proposed PCWCNN model performs very well on a real dataset, outperforming
existing approaches."
Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer,0.926157,"Videos are created to express emotion, exchange information, and share
experiences. Video synthesis has intrigued researchers for a long time. Despite
the rapid progress driven by advances in visual synthesis, most existing
studies focus on improving the frames' quality and the transitions between
them, while little progress has been made in generating longer videos. In this
paper, we present a method that builds on 3D-VQGAN and transformers to generate
videos with thousands of frames. Our evaluation shows that our model trained on
16-frame video clips from standard benchmarks such as UCF-101, Sky Time-lapse,
and Taichi-HD datasets can generate diverse, coherent, and high-quality long
videos. We also showcase conditional extensions of our approach for generating
meaningful long videos by incorporating temporal information with text and
audio. Videos and code can be found at
https://songweige.github.io/projects/tats/index.html."
Describing Differences between Text Distributions with Natural Language,0.39926,"How do two distributions of texts differ? Humans are slow at answering this,
since discovering patterns might require tediously reading through hundreds of
samples. We propose to automatically summarize the differences by ""learning a
natural language hypothesis"": given two distributions $D_{0}$ and $D_{1}$, we
search for a description that is more often true for $D_{1}$, e.g., ""is
military-related."" To tackle this problem, we fine-tune GPT-3 to propose
descriptions with the prompt: ""[samples of $D_{0}$] + [samples of $D_{1}$] +
the difference between them is_____."" We then re-rank the descriptions by
checking how often they hold on a larger set of samples with a learned
verifier. On a benchmark of 54 real-world binary classification tasks, while
GPT-3 Curie (13B) only generates a description similar to human annotation 7%
of the time, the performance reaches 61% with fine-tuning and re-ranking, and
our best system using GPT-3 Davinci (175B) reaches 76%. We apply our system to
describe distribution shifts, debug dataset shortcuts, summarize unknown tasks,
and label text clusters, and present analyses based on automatically generated
descriptions."
Generate rather than Retrieve: Large Language Models are Strong Context Generators,0.282701,"Knowledge-intensive tasks, such as open-domain question answering (QA),
require access to a large amount of world or domain knowledge. A common
approach for knowledge-intensive tasks is to employ a retrieve-then-read
pipeline that first retrieves a handful of relevant contextual documents from
an external corpus such as Wikipedia and then predicts an answer conditioned on
the retrieved documents. In this paper, we present a novel perspective for
solving knowledge-intensive tasks by replacing document retrievers with large
language model generators. We call our method generate-then-read (GenRead),
which first prompts a large language model to generate contextutal documents
based on a given question, and then reads the generated documents to produce
the final answer. Furthermore, we propose a novel clustering-based prompting
method that selects distinct prompts, resulting in the generated documents that
cover different perspectives, leading to better recall over acceptable answers.
We conduct extensive experiments on three different knowledge-intensive tasks,
including open-domain QA, fact checking, and dialogue system. Notably, GenRead
achieves 71.6 and 54.4 exact match scores on TriviaQA and WebQ, significantly
outperforming the state-of-the-art retrieve-then-read pipeline DPR-FiD by +4.0
and +3.9, without retrieving any documents from any external knowledge source.
Lastly, we demonstrate the model performance can be further improved by
combining retrieval and generation. Our code and generated documents can be
found at https://github.com/wyu97/GenRead."
SUPERB @ SLT 2022: Challenge on Generalization and Efficiency of Self-Supervised Speech Representation Learning,0.19128,"We present the SUPERB challenge at SLT 2022, which aims at learning
self-supervised speech representation for better performance, generalization,
and efficiency. The challenge builds upon the SUPERB benchmark and implements
metrics to measure the computation requirements of self-supervised learning
(SSL) representation and to evaluate its generalizability and performance
across the diverse SUPERB tasks. The SUPERB benchmark provides comprehensive
coverage of popular speech processing tasks, from speech and speaker
recognition to audio generation and semantic understanding. As SSL has gained
interest in the speech community and showed promising outcomes, we envision the
challenge to uplevel the impact of SSL techniques by motivating more practical
designs of techniques beyond task performance. We summarize the results of 14
submitted models in this paper. We also discuss the main findings from those
submissions and the future directions of SSL research."
A method for ethical AI in Defence: A case study on developing trustworthy autonomous systems,0.207215,"What does it mean to be responsible and responsive when developing and
deploying trusted autonomous systems in Defence? In this short reflective
article, we describe a case study of building a trusted autonomous system -
Athena AI - within an industry-led, government-funded project with diverse
collaborators and stakeholders. Using this case study, we draw out lessons on
the value and impact of embedding responsible research and innovation-aligned,
ethics-by-design approaches and principles throughout the development of
technology at high translation readiness levels."
Emergent Communication through Metropolis-Hastings Naming Game with Deep Generative Models,0.326028,"Constructive studies on symbol emergence systems seek to investigate
computational models that can better explain human language evolution, the
creation of symbol systems, and the construction of internal representations.
This study provides a new model for emergent communication, which is based on a
probabilistic generative model (PGM) instead of a discriminative model based on
deep reinforcement learning. We define the Metropolis-Hastings (MH) naming game
by generalizing previously proposed models. It is not a referential game with
explicit feedback, as assumed by many emergent communication studies. Instead,
it is a game based on joint attention without explicit feedback.
Mathematically, the MH naming game is proved to be a type of MH algorithm for
an integrative PGM that combines two agents that play the naming game. From
this viewpoint, symbol emergence is regarded as decentralized Bayesian
inference, and semiotic communication is regarded as inter-personal cross-modal
inference. This notion leads to the collective predictive coding hypothesis}
regarding language evolution and, in general, the emergence of symbols. We also
propose the inter-Gaussian mixture model (GMM)+ variational autoencoder (VAE),
a deep generative model for emergent communication based on the MH naming game.
The model has been validated on MNIST and Fruits 360 datasets. Experimental
findings demonstrate that categories are formed from real images observed by
agents, and signs are correctly shared across agents by successfully utilizing
both of the observations of agents via the MH naming game. Furthermore,
scholars verified that visual images were recalled from signs uttered by
agents. Notably, emergent communication without supervision and reward feedback
improved the performance of the unsupervised representation learning of agents."
Multimodal learning with graphs,0.210374,"Artificial intelligence for graphs has achieved remarkable success in
modeling complex systems, ranging from dynamic networks in biology to
interacting particle systems in physics. However, the increasingly
heterogeneous graph datasets call for multimodal methods that can combine
different inductive biases: the set of assumptions that algorithms use to make
predictions for inputs they have not encountered during training. Learning on
multimodal datasets presents fundamental challenges because the inductive
biases can vary by data modality and graphs might not be explicitly given in
the input. To address these challenges, multimodal graph AI methods combine
different modalities while leveraging cross-modal dependencies using graphs.
Diverse datasets are combined using graphs and fed into sophisticated
multimodal architectures, specified as image-intensive, knowledge-grounded and
language-intensive models. Using this categorization, we introduce a blueprint
for multimodal graph learning, use it to study existing methods and provide
guidelines to design new models."
Imagination-Augmented Natural Language Understanding,0.486221,"Human brains integrate linguistic and perceptual information simultaneously
to understand natural language, and hold the critical ability to render
imaginations. Such abilities enable us to construct new abstract concepts or
concrete objects, and are essential in involving practical knowledge to solve
problems in low-resource scenarios. However, most existing methods for Natural
Language Understanding (NLU) are mainly focused on textual signals. They do not
simulate human visual imagination ability, which hinders models from inferring
and learning efficiently from limited data samples. Therefore, we introduce an
Imagination-Augmented Cross-modal Encoder (iACE) to solve natural language
understanding tasks from a novel learning perspective -- imagination-augmented
cross-modal understanding. iACE enables visual imagination with external
knowledge transferred from the powerful generative and pre-trained
vision-and-language models. Extensive experiments on GLUE and SWAG show that
iACE achieves consistent improvement over visually-supervised pre-trained
models. More importantly, results in extreme and normal few-shot settings
validate the effectiveness of iACE in low-resource natural language
understanding circumstances."
Stubborn: A Strong Baseline for Indoor Object Navigation,0.552096,"We present a strong baseline that surpasses the performance of previously
published methods on the Habitat Challenge task of navigating to a target
object in indoor environments. Our method is motivated from primary failure
modes of prior state-of-the-art: poor exploration, inaccurate object
identification, and agent getting trapped due to imprecise map construction. We
make three contributions to mitigate these issues: (i) First, we show that
existing map-based methods fail to effectively use semantic clues for
exploration. We present a semantic-agnostic exploration strategy (called
Stubborn) without any learning that surprisingly outperforms prior work. (ii)
We propose a strategy for integrating temporal information to improve object
identification. (iii) Lastly, due to inaccurate depth observation the agent
often gets trapped in small regions. We develop a multi-scale collision map for
obstacle identification that mitigates this issue."
Ontology-enhanced Prompt-tuning for Few-shot Learning,0.99755,"Few-shot Learning (FSL) is aimed to make predictions based on a limited
number of samples. Structured data such as knowledge graphs and ontology
libraries has been leveraged to benefit the few-shot setting in various tasks.
However, the priors adopted by the existing methods suffer from challenging
knowledge missing, knowledge noise, and knowledge heterogeneity, which hinder
the performance for few-shot learning. In this study, we explore knowledge
injection for FSL with pre-trained language models and propose
ontology-enhanced prompt-tuning (OntoPrompt). Specifically, we develop the
ontology transformation based on the external knowledge graph to address the
knowledge missing issue, which fulfills and converts structure knowledge to
text. We further introduce span-sensitive knowledge injection via a visible
matrix to select informative knowledge to handle the knowledge noise issue. To
bridge the gap between knowledge and text, we propose a collective training
algorithm to optimize representations jointly. We evaluate our proposed
OntoPrompt in three tasks, including relation extraction, event extraction, and
knowledge graph completion, with eight datasets. Experimental results
demonstrate that our approach can obtain better few-shot performance than
baselines."
Unsupervised Learning of Efficient Geometry-Aware Neural Articulated Representations,0.58123,"We propose an unsupervised method for 3D geometry-aware representation
learning of articulated objects, in which no image-pose pairs or foreground
masks are used for training. Though photorealistic images of articulated
objects can be rendered with explicit pose control through existing 3D neural
representations, these methods require ground truth 3D pose and foreground
masks for training, which are expensive to obtain. We obviate this need by
learning the representations with GAN training. The generator is trained to
produce realistic images of articulated objects from random poses and latent
vectors by adversarial training. To avoid a high computational cost for GAN
training, we propose an efficient neural representation for articulated objects
based on tri-planes and then present a GAN-based framework for its unsupervised
training. Experiments demonstrate the efficiency of our method and show that
GAN-based training enables the learning of controllable 3D representations
without paired supervision."
DialFRED: Dialogue-Enabled Agents for Embodied Instruction Following,0.793902,"Language-guided Embodied AI benchmarks requiring an agent to navigate an
environment and manipulate objects typically allow one-way communication: the
human user gives a natural language command to the agent, and the agent can
only follow the command passively. We present DialFRED, a dialogue-enabled
embodied instruction following benchmark based on the ALFRED benchmark.
DialFRED allows an agent to actively ask questions to the human user; the
additional information in the user's response is used by the agent to better
complete its task. We release a human-annotated dataset with 53K task-relevant
questions and answers and an oracle to answer questions. To solve DialFRED, we
propose a questioner-performer framework wherein the questioner is pre-trained
with the human-annotated data and fine-tuned with reinforcement learning. We
make DialFRED publicly available and encourage researchers to propose and
evaluate their solutions to building dialog-enabled embodied agents."
ViT-DD: Multi-Task Vision Transformer for Semi-Supervised Driver Distraction Detection,0.214594,"Ensuring traffic safety and mitigating accidents in modern driving is of
paramount importance, and computer vision technologies have the potential to
significantly contribute to this goal. This paper presents a multi-modal Vision
Transformer for Driver Distraction Detection (termed ViT-DD), which
incorporates inductive information from training signals related to both
distraction detection and driver emotion recognition. Additionally, a
self-learning algorithm is developed, allowing for the seamless integration of
driver data without emotion labels into the multi-task training process of
ViT-DD. Experimental results reveal that the proposed ViT-DD surpasses existing
state-of-the-art methods for driver distraction detection by 6.5% and 0.9% on
the SFDDD and AUCDD datasets, respectively."
Leveraging Off-the-shelf Diffusion Model for Multi-attribute Fashion Image Manipulation,0.565497,"Fashion attribute editing is a task that aims to convert the semantic
attributes of a given fashion image while preserving the irrelevant regions.
Previous works typically employ conditional GANs where the generator explicitly
learns the target attributes and directly execute the conversion. These
approaches, however, are neither scalable nor generic as they operate only with
few limited attributes and a separate generator is required for each dataset or
attribute set. Inspired by the recent advancement of diffusion models, we
explore the classifier-guided diffusion that leverages the off-the-shelf
diffusion model pretrained on general visual semantics such as Imagenet. In
order to achieve a generic editing pipeline, we pose this as multi-attribute
image manipulation task, where the attribute ranges from item category, fabric,
pattern to collar and neckline. We empirically show that conventional methods
fail in our challenging setting, and study efficient adaptation scheme that
involves recently introduced attention-pooling technique to obtain a
multi-attribute classifier guidance. Based on this, we present a mask-free
fashion attribute editing framework that leverages the classifier logits and
the cross-attention map for manipulation. We empirically demonstrate that our
framework achieves convincing sample quality and attribute alignments."
Robust Trajectory Prediction against Adversarial Attacks,0.060549,"Trajectory prediction using deep neural networks (DNNs) is an essential
component of autonomous driving (AD) systems. However, these methods are
vulnerable to adversarial attacks, leading to serious consequences such as
collisions. In this work, we identify two key ingredients to defend trajectory
prediction models against adversarial attacks including (1) designing effective
adversarial training methods and (2) adding domain-specific data augmentation
to mitigate the performance degradation on clean data. We demonstrate that our
method is able to improve the performance by 46% on adversarial data and at the
cost of only 3% performance degradation on clean data, compared to the model
trained with clean data. Additionally, compared to existing robust methods, our
method can improve performance by 21% on adversarial examples and 9% on clean
data. Our robust model is evaluated with a planner to study its downstream
impacts. We demonstrate that our model can significantly reduce the severe
accident rates (e.g., collisions and off-road driving)."
A simple language-agnostic yet very strong baseline system for hate speech and offensive content identification,0.11415,"For automatically identifying hate speech and offensive content in tweets, a
system based on a classical supervised algorithm only fed with character
n-grams, and thus completely language-agnostic, is proposed by the SATLab team.
After its optimization in terms of the feature weighting and the classifier
parameters, it reached, in the multilingual HASOC 2021 challenge, a medium
performance level in English, the language for which it is easy to develop deep
learning approaches relying on many external linguistic resources, but a far
better level for the two less resourced language, Hindi and Marathi. It ends
even first when performances are averaged over the three tasks in these
languages, outperforming many deep learning approaches. These performances
suggest that it is an interesting reference level to evaluate the benefits of
using more complex approaches such as deep learning or taking into account
complementary resources."
FJMP: Factorized Joint Multi-Agent Motion Prediction over Learned Directed Acyclic Interaction Graphs,0.195239,"Predicting the future motion of road agents is a critical task in an
autonomous driving pipeline. In this work, we address the problem of generating
a set of scene-level, or joint, future trajectory predictions in multi-agent
driving scenarios. To this end, we propose FJMP, a Factorized Joint Motion
Prediction framework for multi-agent interactive driving scenarios. FJMP models
the future scene interaction dynamics as a sparse directed interaction graph,
where edges denote explicit interactions between agents. We then prune the
graph into a directed acyclic graph (DAG) and decompose the joint prediction
task into a sequence of marginal and conditional predictions according to the
partial ordering of the DAG, where joint future trajectories are decoded using
a directed acyclic graph neural network (DAGNN). We conduct experiments on the
INTERACTION and Argoverse 2 datasets and demonstrate that FJMP produces more
accurate and scene-consistent joint trajectory predictions than non-factorized
approaches, especially on the most interactive and kinematically interesting
agents. FJMP ranks 1st on the multi-agent test leaderboard of the INTERACTION
dataset."
Video Prediction by Efficient Transformers,0.0,"Video prediction is a challenging computer vision task that has a wide range
of applications. In this work, we present a new family of Transformer-based
models for video prediction. Firstly, an efficient local spatial-temporal
separation attention mechanism is proposed to reduce the complexity of standard
Transformers. Then, a full autoregressive model, a partial autoregressive model
and a non-autoregressive model are developed based on the new efficient
Transformer. The partial autoregressive model has a similar performance with
the full autoregressive model but a faster inference speed. The
non-autoregressive model not only achieves a faster inference speed but also
mitigates the quality degradation problem of the autoregressive counterparts,
but it requires additional parameters and loss function for learning. Given the
same attention mechanism, we conducted a comprehensive study to compare the
proposed three video prediction variants. Experiments show that the proposed
video prediction models are competitive with more complex state-of-the-art
convolutional-LSTM based models. The source code is available at
https://github.com/XiYe20/VPTR."
CITRIS: Causal Identifiability from Temporal Intervened Sequences,0.400436,"Understanding the latent causal factors of a dynamical system from visual
observations is considered a crucial step towards agents reasoning in complex
environments. In this paper, we propose CITRIS, a variational autoencoder
framework that learns causal representations from temporal sequences of images
in which underlying causal factors have possibly been intervened upon. In
contrast to the recent literature, CITRIS exploits temporality and observing
intervention targets to identify scalar and multidimensional causal factors,
such as 3D rotation angles. Furthermore, by introducing a normalizing flow,
CITRIS can be easily extended to leverage and disentangle representations
obtained by already pretrained autoencoders. Extending previous results on
scalar causal factors, we prove identifiability in a more general setting, in
which only some components of a causal factor are affected by interventions. In
experiments on 3D rendered image sequences, CITRIS outperforms previous methods
on recovering the underlying causal variables. Moreover, using pretrained
autoencoders, CITRIS can even generalize to unseen instantiations of causal
factors, opening future research areas in sim-to-real generalization for causal
representation learning."
Human-to-Robot Imitation in the Wild,0.712292,"We approach the problem of learning by watching humans in the wild. While
traditional approaches in Imitation and Reinforcement Learning are promising
for learning in the real world, they are either sample inefficient or are
constrained to lab settings. Meanwhile, there has been a lot of success in
processing passive, unstructured human data. We propose tackling this problem
via an efficient one-shot robot learning algorithm, centered around learning
from a third-person perspective. We call our method WHIRL: In-the-Wild Human
Imitating Robot Learning. WHIRL extracts a prior over the intent of the human
demonstrator, using it to initialize our agent's policy. We introduce an
efficient real-world policy learning scheme that improves using interactions.
Our key contributions are a simple sampling-based policy optimization approach,
a novel objective function for aligning human and robot videos as well as an
exploration method to boost sample efficiency. We show one-shot generalization
and success in real-world settings, including 20 different manipulation tasks
in the wild. Videos and talk at https://human2robot.github.io"
Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning,0.686992,"Prompt learning approaches have made waves in natural language processing by
inducing better few-shot performance while they still follow a parametric-based
learning paradigm; the oblivion and rote memorization problems in learning may
encounter unstable generalization issues. Specifically, vanilla prompt learning
may struggle to utilize atypical instances by rote during fully-supervised
training or overfit shallow patterns with low-shot data. To alleviate such
limitations, we develop RetroPrompt with the motivation of decoupling knowledge
from memorization to help the model strike a balance between generalization and
memorization. In contrast with vanilla prompt learning, RetroPrompt constructs
an open-book knowledge-store from training instances and implements a retrieval
mechanism during the process of input, training and inference, thus equipping
the model with the ability to retrieve related contexts from the training
corpus as cues for enhancement. Extensive experiments demonstrate that
RetroPrompt can obtain better performance in both few-shot and zero-shot
settings. Besides, we further illustrate that our proposed RetroPrompt can
yield better generalization abilities with new datasets. Detailed analysis of
memorization indeed reveals RetroPrompt can reduce the reliance of language
models on memorization; thus, improving generalization for downstream tasks.
Code is available in
https://github.com/zjunlp/PromptKG/tree/main/research/RetroPrompt."
Towards High-Fidelity Single-view Holistic Reconstruction of Indoor Scenes,0.448684,"We present a new framework to reconstruct holistic 3D indoor scenes including
both room background and indoor objects from single-view images. Existing
methods can only produce 3D shapes of indoor objects with limited geometry
quality because of the heavy occlusion of indoor scenes. To solve this, we
propose an instance-aligned implicit function (InstPIFu) for detailed object
reconstruction. Combining with instance-aligned attention module, our method is
empowered to decouple mixed local features toward the occluded instances.
Additionally, unlike previous methods that simply represents the room
background as a 3D bounding box, depth map or a set of planes, we recover the
fine geometry of the background via implicit representation. Extensive
experiments on the SUN RGB-D, Pix3D, 3D-FUTURE, and 3D-FRONT datasets
demonstrate that our method outperforms existing approaches in both background
and foreground object reconstruction. Our code and model will be made publicly
available."
Q-ViT: Fully Differentiable Quantization for Vision Transformer,0.0,"In this paper, we propose a fully differentiable quantization method for
vision transformer (ViT) named as Q-ViT, in which both of the quantization
scales and bit-widths are learnable parameters. Specifically, based on our
observation that heads in ViT display different quantization robustness, we
leverage head-wise bit-width to squeeze the size of Q-ViT while preserving
performance. In addition, we propose a novel technique named switchable scale
to resolve the convergence problem in the joint training of quantization scales
and bit-widths. In this way, Q-ViT pushes the limits of ViT quantization to
3-bit without heavy performance drop. Moreover, we analyze the quantization
robustness of every architecture component of ViT and show that the Multi-head
Self-Attention (MSA) and the Gaussian Error Linear Units (GELU) are the key
aspects for ViT quantization. This study provides some insights for further
research about ViT quantization. Extensive experiments on different ViT models,
such as DeiT and Swin Transformer show the effectiveness of our quantization
method. In particular, our method outperforms the state-of-the-art uniform
quantization method by 1.5% on DeiT-Tiny."
Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models,0.817992,"Motivations for methods in explainable artificial intelligence (XAI) often
include detecting, quantifying and mitigating bias, and contributing to making
machine learning models fairer. However, exactly how an XAI method can help in
combating biases is often left unspecified. In this paper, we briefly review
trends in explainability and fairness in NLP research, identify the current
practices in which explainability methods are applied to detect and mitigate
bias, and investigate the barriers preventing XAI methods from being used more
widely in tackling fairness issues."
CenterFormer: Center-based Transformer for 3D Object Detection,-1.0,"Query-based transformer has shown great potential in constructing long-range
attention in many image-domain tasks, but has rarely been considered in
LiDAR-based 3D object detection due to the overwhelming size of the point cloud
data. In this paper, we propose CenterFormer, a center-based transformer
network for 3D object detection. CenterFormer first uses a center heatmap to
select center candidates on top of a standard voxel-based point cloud encoder.
It then uses the feature of the center candidate as the query embedding in the
transformer. To further aggregate features from multiple frames, we design an
approach to fuse features through cross-attention. Lastly, regression heads are
added to predict the bounding box on the output center feature representation.
Our design reduces the convergence difficulty and computational complexity of
the transformer structure. The results show significant improvements over the
strong baseline of anchor-free object detection networks. CenterFormer achieves
state-of-the-art performance for a single model on the Waymo Open Dataset, with
73.7% mAPH on the validation set and 75.6% mAPH on the test set, significantly
outperforming all previously published CNN and transformer-based methods. Our
code is publicly available at https://github.com/TuSimple/centerformer"
Understanding Stereotypes in Language Models: Towards Robust Measurement and Zero-Shot Debiasing,0.110103,"Generated texts from large pretrained language models have been shown to
exhibit a variety of harmful, human-like biases about various demographics.
These findings prompted large efforts aiming to understand and measure such
effects, with the goal of providing benchmarks that can guide the development
of techniques mitigating these stereotypical associations. However, as recent
research has pointed out, the current benchmarks lack a robust experimental
setup, consequently hindering the inference of meaningful conclusions from
their evaluation metrics. In this paper, we extend these arguments and
demonstrate that existing techniques and benchmarks aiming to measure
stereotypes tend to be inaccurate and consist of a high degree of experimental
noise that severely limits the knowledge we can gain from benchmarking language
models based on them. Accordingly, we propose a new framework for robustly
measuring and quantifying biases exhibited by generative language models.
Finally, we use this framework to investigate GPT-3's occupational gender bias
and propose prompting techniques for mitigating these biases without the need
for fine-tuning."
Multimodal Hate Speech Detection from Bengali Memes and Texts,0.367947,"Numerous machine learning (ML) and deep learning (DL)-based approaches have
been proposed to utilize textual data from social media for anti-social
behavior analysis like cyberbullying, fake news detection, and identification
of hate speech mainly for highly-resourced languages such as English. However,
despite having a lot of diversity and millions of native speakers, some
languages like Bengali are under-resourced, which is due to a lack of
computational resources for natural language processing (NLP). Similar to other
languages, Bengali social media contents also include images along with texts
(e.g., multimodal memes are posted by embedding short texts into images on
Facebook). Therefore, only the textual data is not enough to judge them since
images might give extra context to make a proper judgement. This paper is about
hate speech detection from multimodal Bengali memes and texts. We prepared the
only multimodal hate speech dataset for-a-kind of problem for Bengali, which we
use to train state-of-the-art neural architectures (e.g., Bi-LSTM/Conv-LSTM
with word embeddings, ConvNets + pre-trained language models, e.g., monolingual
Bangla BERT, multilingual BERT-cased/uncased, and XLM-RoBERTa) to jointly
analyze textual and visual information for hate speech detection. Conv-LSTM and
XLM-RoBERTa models performed best for texts, yielding F1 scores of 0.78 and
0.82, respectively. As of memes, ResNet-152 and DenseNet-161 models yield F1
scores of 0.78 and 0.79, respectively. As for multimodal fusion, XLM-RoBERTa +
DenseNet-161 performed the best, yielding an F1 score of 0.83. Our study
suggests that text modality is most useful for hate speech detection, while
memes are moderately useful."
Generalized Differentiable RANSAC,0.0890393,"We propose $\nabla$-RANSAC, a generalized differentiable RANSAC that allows
learning the entire randomized robust estimation pipeline. The proposed
approach enables the use of relaxation techniques for estimating the gradients
in the sampling distribution, which are then propagated through a
differentiable solver. The trainable quality function marginalizes over the
scores from all the models estimated within $\nabla$-RANSAC to guide the
network learning accurate and useful inlier probabilities or to train feature
detection and matching networks. Our method directly maximizes the probability
of drawing a good hypothesis, allowing us to learn better sampling
distributions. We test $\nabla$-RANSAC on various real-world scenarios on
fundamental and essential matrix estimation, and 3D point cloud registration,
outdoors and indoors, with handcrafted and learning-based features. It is
superior to the state-of-the-art in terms of accuracy while running at a
similar speed to its less accurate alternatives. The code and trained models
are available at https://github.com/weitong8591/differentiable_ransac."
Learning Appearance-motion Normality for Video Anomaly Detection,0.470494,"Video anomaly detection is a challenging task in the computer vision
community. Most single task-based methods do not consider the independence of
unique spatial and temporal patterns, while two-stream structures lack the
exploration of the correlations. In this paper, we propose spatial-temporal
memories augmented two-stream auto-encoder framework, which learns the
appearance normality and motion normality independently and explores the
correlations via adversarial learning. Specifically, we first design two proxy
tasks to train the two-stream structure to extract appearance and motion
features in isolation. Then, the prototypical features are recorded in the
corresponding spatial and temporal memory pools. Finally, the encoding-decoding
network performs adversarial learning with the discriminator to explore the
correlations between spatial and temporal patterns. Experimental results show
that our framework outperforms the state-of-the-art methods, achieving AUCs of
98.1% and 89.8% on UCSD Ped2 and CUHK Avenue datasets."
Exploring Visual Prompts for Adapting Large-Scale Models,0.982586,"We investigate the efficacy of visual prompting to adapt large-scale models
in vision. Following the recent approach from prompt tuning and adversarial
reprogramming, we learn a single image perturbation such that a frozen model
prompted with this perturbation performs a new task. Through comprehensive
experiments, we demonstrate that visual prompting is particularly effective for
CLIP and robust to distribution shift, achieving performance competitive with
standard linear probes. We further analyze properties of the downstream
dataset, prompt design, and output transformation in regard to adaptation
performance. The surprising effectiveness of visual prompting provides a new
perspective on adapting pre-trained models in vision. Code is available at
http://hjbahng.github.io/visual_prompting ."
Teaching Where to Look: Attention Similarity Knowledge Distillation for Low Resolution Face Recognition,0.314045,"Deep learning has achieved outstanding performance for face recognition
benchmarks, but performance reduces significantly for low resolution (LR)
images. We propose an attention similarity knowledge distillation approach,
which transfers attention maps obtained from a high resolution (HR) network as
a teacher into an LR network as a student to boost LR recognition performance.
Inspired by humans being able to approximate an object's region from an LR
image based on prior knowledge obtained from HR images, we designed the
knowledge distillation loss using the cosine similarity to make the student
network's attention resemble the teacher network's attention. Experiments on
various LR face related benchmarks confirmed the proposed method generally
improved recognition performances on LR settings, outperforming
state-of-the-art results by simply transferring well-constructed attention
maps. The code and pretrained models are publicly available in the
https://github.com/gist-ailab/teaching-where-to-look."
Should We Rely on Entity Mentions for Relation Extraction? Debiasing Relation Extraction with Counterfactual Analysis,0.598595,"Recent literature focuses on utilizing the entity information in the
sentence-level relation extraction (RE), but this risks leaking superficial and
spurious clues of relations. As a result, RE still suffers from unintended
entity bias, i.e., the spurious correlation between entity mentions (names) and
relations. Entity bias can mislead the RE models to extract the relations that
do not exist in the text. To combat this issue, some previous work masks the
entity mentions to prevent the RE models from overfitting entity mentions.
However, this strategy degrades the RE performance because it loses the
semantic information of entities. In this paper, we propose the CORE
(Counterfactual Analysis based Relation Extraction) debiasing method that
guides the RE models to focus on the main effects of textual context without
losing the entity information. We first construct a causal graph for RE, which
models the dependencies between variables in RE models. Then, we propose to
conduct counterfactual analysis on our causal graph to distill and mitigate the
entity bias, that captures the causal effects of specific entity mentions in
each instance. Note that our CORE method is model-agnostic to debias existing
RE systems during inference without changing their training processes.
Extensive experimental results demonstrate that our CORE yields significant
gains on both effectiveness and generalization for RE. The source code is
provided at: https://github.com/vanoracai/CoRE."
On Vision Features in Multimodal Machine Translation,0.25307,"Previous work on multimodal machine translation (MMT) has focused on the way
of incorporating vision features into translation but little attention is on
the quality of vision models. In this work, we investigate the impact of vision
models on MMT. Given the fact that Transformer is becoming popular in computer
vision, we experiment with various strong models (such as Vision Transformer)
and enhanced features (such as object-detection and image captioning). We
develop a selective attention model to study the patch-level contribution of an
image in MMT. On detailed probing tasks, we find that stronger vision models
are helpful for learning translation from the visual modality. Our results also
suggest the need of carefully examining MMT models, especially when current
benchmarks are small-scale and biased. Our code could be found at
\url{https://github.com/libeineu/fairseq_mmt}."
SmartBrush: Text and Shape Guided Object Inpainting with Diffusion Model,0.981684,"Generic image inpainting aims to complete a corrupted image by borrowing
surrounding information, which barely generates novel content. By contrast,
multi-modal inpainting provides more flexible and useful controls on the
inpainted content, \eg, a text prompt can be used to describe an object with
richer attributes, and a mask can be used to constrain the shape of the
inpainted object rather than being only considered as a missing area. We
propose a new diffusion-based model named SmartBrush for completing a missing
region with an object using both text and shape-guidance. While previous work
such as DALLE-2 and Stable Diffusion can do text-guided inapinting they do not
support shape guidance and tend to modify background texture surrounding the
generated object. Our model incorporates both text and shape guidance with
precision control. To preserve the background better, we propose a novel
training and sampling strategy by augmenting the diffusion U-net with
object-mask prediction. Lastly, we introduce a multi-task training strategy by
jointly training inpainting with text-to-image generation to leverage more
training data. We conduct extensive experiments showing that our model
outperforms all baselines in terms of visual quality, mask controllability, and
background preservation."
A Generalist Framework for Panoptic Segmentation of Images and Videos,0.758526,"Panoptic segmentation assigns semantic and instance ID labels to every pixel
of an image. As permutations of instance IDs are also valid solutions, the task
requires learning of high-dimensional one-to-many mapping. As a result,
state-of-the-art approaches use customized architectures and task-specific loss
functions. We formulate panoptic segmentation as a discrete data generation
problem, without relying on inductive bias of the task. A diffusion model is
proposed to model panoptic masks, with a simple architecture and generic loss
function. By simply adding past predictions as a conditioning signal, our
method is capable of modeling video (in a streaming setting) and thereby learns
to track object instances automatically. With extensive experiments, we
demonstrate that our simple approach can perform competitively to
state-of-the-art specialist methods in similar settings."
Reducing the Vision and Language Bias for Temporal Sentence Grounding,0.349208,"Temporal sentence grounding (TSG) is an important yet challenging task in
multimedia information retrieval. Although previous TSG methods have achieved
decent performance, they tend to capture the selection biases of frequently
appeared video-query pairs in the dataset rather than present robust multimodal
reasoning abilities, especially for the rarely appeared pairs. In this paper,
we study the above issue of selection biases and accordingly propose a
Debiasing-TSG (D-TSG) model to filter and remove the negative biases in both
vision and language modalities for enhancing the model generalization ability.
Specifically, we propose to alleviate the issue from two perspectives: 1)
Feature distillation. We built a multi-modal debiasing branch to firstly
capture the vision and language biases, and then apply a bias identification
module to explicitly recognize the true negative biases and remove them from
the benign multi-modal representations. 2) Contrastive sample generation. We
construct two types of negative samples to enforce the model to accurately
learn the aligned multi-modal semantics and make complete semantic reasoning.
We apply the proposed model to both commonly and rarely appeared TSG cases, and
demonstrate its effectiveness by achieving the state-of-the-art performance on
three benchmark datasets (ActivityNet Caption, TACoS, and Charades-STA)."
ARST: Auto-Regressive Surgical Transformer for Phase Recognition from Laparoscopic Videos,0.262701,"Phase recognition plays an essential role for surgical workflow analysis in
computer assisted intervention. Transformer, originally proposed for sequential
data modeling in natural language processing, has been successfully applied to
surgical phase recognition. Existing works based on transformer mainly focus on
modeling attention dependency, without introducing auto-regression. In this
work, an Auto-Regressive Surgical Transformer, referred as ARST, is first
proposed for on-line surgical phase recognition from laparoscopic videos,
modeling the inter-phase correlation implicitly by conditional probability
distribution. To reduce inference bias and to enhance phase consistency, we
further develop a consistency constraint inference strategy based on
auto-regression. We conduct comprehensive validations on a well-known public
dataset Cholec80. Experimental results show that our method outperforms the
state-of-the-art methods both quantitatively and qualitatively, and achieves an
inference rate of 66 frames per second (fps)."
Scaling Up Probabilistic Circuits by Latent Variable Distillation,0.0418309,"Probabilistic Circuits (PCs) are a unified framework for tractable
probabilistic models that support efficient computation of various
probabilistic queries (e.g., marginal probabilities). One key challenge is to
scale PCs to model large and high-dimensional real-world datasets: we observe
that as the number of parameters in PCs increases, their performance
immediately plateaus. This phenomenon suggests that the existing optimizers
fail to exploit the full expressive power of large PCs. We propose to overcome
such bottleneck by latent variable distillation: we leverage the less tractable
but more expressive deep generative models to provide extra supervision over
the latent variables of PCs. Specifically, we extract information from
Transformer-based generative models to assign values to latent variables of
PCs, providing guidance to PC optimizers. Experiments on both image and
language modeling benchmarks (e.g., ImageNet and WikiText-2) show that latent
variable distillation substantially boosts the performance of large PCs
compared to their counterparts without latent variable distillation. In
particular, on the image modeling benchmarks, PCs achieve competitive
performance against some of the widely-used deep generative models, including
variational autoencoders and flow-based models, opening up new avenues for
tractable generative modeling."
Hierarchical Temporal Transformer for 3D Hand Pose Estimation and Action Recognition from Egocentric RGB Videos,0.125714,"Understanding dynamic hand motions and actions from egocentric RGB videos is
a fundamental yet challenging task due to self-occlusion and ambiguity. To
address occlusion and ambiguity, we develop a transformer-based framework to
exploit temporal information for robust estimation. Noticing the different
temporal granularity of and the semantic correlation between hand pose
estimation and action recognition, we build a network hierarchy with two
cascaded transformer encoders, where the first one exploits the short-term
temporal cue for hand pose estimation, and the latter aggregates per-frame pose
and object information over a longer time span to recognize the action. Our
approach achieves competitive results on two first-person hand action
benchmarks, namely FPHA and H2O. Extensive ablation studies verify our design
choices."
Transformers are Sample-Efficient World Models,0.0742307,"Deep reinforcement learning agents are notoriously sample inefficient, which
considerably limits their application to real-world problems. Recently, many
model-based methods have been designed to address this issue, with learning in
the imagination of a world model being one of the most prominent approaches.
However, while virtually unlimited interaction with a simulated environment
sounds appealing, the world model has to be accurate over extended periods of
time. Motivated by the success of Transformers in sequence modeling tasks, we
introduce IRIS, a data-efficient agent that learns in a world model composed of
a discrete autoencoder and an autoregressive Transformer. With the equivalent
of only two hours of gameplay in the Atari 100k benchmark, IRIS achieves a mean
human normalized score of 1.046, and outperforms humans on 10 out of 26 games,
setting a new state of the art for methods without lookahead search. To foster
future research on Transformers and world models for sample-efficient
reinforcement learning, we release our code and models at
https://github.com/eloialonso/iris."
UniGDD: A Unified Generative Framework for Goal-Oriented Document-Grounded Dialogue,-1.0,"The goal-oriented document-grounded dialogue aims at responding to the user
query based on the dialogue context and supporting document. Existing studies
tackle this problem by decomposing it into two sub-tasks: knowledge
identification and response generation. However, such pipeline methods would
unavoidably suffer from the error propagation issue. This paper proposes to
unify these two sub-tasks via sequentially generating the grounding knowledge
and the response. We further develop a prompt-connected multi-task learning
strategy to model the characteristics and connections of different tasks and
introduce linear temperature scheduling to reduce the negative effect of
irrelevant document information. Experimental results demonstrate the
effectiveness of our framework."
Interactive Grounded Language Understanding in a Collaborative Environment: IGLU 2021,0.217865,"Human intelligence has the remarkable ability to quickly adapt to new tasks
and environments. Starting from a very young age, humans acquire new skills and
learn how to solve new tasks either by imitating the behavior of others or by
following provided natural language instructions. To facilitate research in
this direction, we propose \emph{IGLU: Interactive Grounded Language
Understanding in a Collaborative Environment}.
  The primary goal of the competition is to approach the problem of how to
build interactive agents that learn to solve a task while provided with
grounded natural language instructions in a collaborative environment.
Understanding the complexity of the challenge, we split it into sub-tasks to
make it feasible for participants."
Revisiting Discrete Soft Actor-Critic,0.22748,"We study the adaption of soft actor-critic (SAC) from continuous action space
to discrete action space. We revisit vanilla SAC and provide an in-depth
understanding of its Q value underestimation and performance instability issues
when applied to discrete settings. We thereby propose entropy-penalty and
double average Q-learning with Q-clip to address these issues. Extensive
experiments on typical benchmarks with discrete action space, including Atari
games and a large-scale MOBA game, show the efficacy of our proposed method.
Our code is at:https://github.com/coldsummerday/Revisiting-Discrete-SAC."
MoSE: Modality Split and Ensemble for Multimodal Knowledge Graph Completion,0.232213,"Multimodal knowledge graph completion (MKGC) aims to predict missing entities
in MKGs. Previous works usually share relation representation across
modalities. This results in mutual interference between modalities during
training, since for a pair of entities, the relation from one modality probably
contradicts that from another modality. Furthermore, making a unified
prediction based on the shared relation representation treats the input in
different modalities equally, while their importance to the MKGC task should be
different. In this paper, we propose MoSE, a Modality Split representation
learning and Ensemble inference framework for MKGC. Specifically, in the
training phase, we learn modality-split relation embeddings for each modality
instead of a single modality-shared one, which alleviates the modality
interference. Based on these embeddings, in the inference phase, we first make
modality-split predictions and then exploit various ensemble methods to combine
the predictions with different weights, which models the modality importance
dynamically. Experimental results on three KG datasets show that MoSE
outperforms state-of-the-art MKGC methods. Codes are available at
https://github.com/OreOZhao/MoSE4MKGC."
iCaps: Iterative Category-level Object Pose and Shape Estimation,0.697521,"This paper proposes a category-level 6D object pose and shape estimation
approach iCaps, which allows tracking 6D poses of unseen objects in a category
and estimating their 3D shapes. We develop a category-level auto-encoder
network using depth images as input, where feature embeddings from the
auto-encoder encode poses of objects in a category. The auto-encoder can be
used in a particle filter framework to estimate and track 6D poses of objects
in a category. By exploiting an implicit shape representation based on signed
distance functions, we build a LatentNet to estimate a latent representation of
the 3D shape given the estimated pose of an object. Then the estimated pose and
shape can be used to update each other in an iterative way. Our category-level
6D object pose and shape estimation pipeline only requires 2D detection and
segmentation for initialization. We evaluate our approach on a publicly
available dataset and demonstrate its effectiveness. In particular, our method
achieves comparably high accuracy on shape estimation."
Large region targets observation scheduling by multiple satellites using resampling particle swarm optimization,0.148467,"The last decades have witnessed a rapid increase of Earth observation
satellites (EOSs), leading to the increasing complexity of EOSs scheduling. On
account of the widespread applications of large region observation, this paper
aims to address the EOSs observation scheduling problem for large region
targets. A rapid coverage calculation method employing a projection reference
plane and a polygon clipping technique is first developed. We then formulate a
nonlinear integer programming model for the scheduling problem, where the
objective function is calculated based on the developed coverage calculation
method. A greedy initialization-based resampling particle swarm optimization
(GI-RPSO) algorithm is proposed to solve the model. The adopted greedy
initialization strategy and particle resampling method contribute to generating
efficient and effective solutions during the evolution process. In the end,
extensive experiments are conducted to illustrate the effectiveness and
reliability of the proposed method. Compared to the traditional particle swarm
optimization and the widely used greedy algorithm, the proposed GI-RPSO can
improve the scheduling result by 5.42% and 15.86%, respectively."
A general-purpose material property data extraction pipeline from large polymer corpora using Natural Language Processing,0.391596,"The ever-increasing number of materials science articles makes it hard to
infer chemistry-structure-property relations from published literature. We used
natural language processing (NLP) methods to automatically extract material
property data from the abstracts of polymer literature. As a component of our
pipeline, we trained MaterialsBERT, a language model, using 2.4 million
materials science abstracts, which outperforms other baseline models in three
out of five named entity recognition datasets when used as the encoder for
text. Using this pipeline, we obtained ~300,000 material property records from
~130,000 abstracts in 60 hours. The extracted data was analyzed for a diverse
range of applications such as fuel cells, supercapacitors, and polymer solar
cells to recover non-trivial insights. The data extracted through our pipeline
is made available through a web platform at https://polymerscholar.org which
can be used to locate material property data recorded in abstracts
conveniently. This work demonstrates the feasibility of an automatic pipeline
that starts from published literature and ends with a complete set of extracted
material property information."
Does Your Model Classify Entities Reasonably? Diagnosing and Mitigating Spurious Correlations in Entity Typing,0.0609663,"Entity typing aims at predicting one or more words that describe the type(s)
of a specific mention in a sentence. Due to shortcuts from surface patterns to
annotated entity labels and biased training, existing entity typing models are
subject to the problem of spurious correlations. To comprehensively investigate
the faithfulness and reliability of entity typing methods, we first
systematically define distinct kinds of model biases that are reflected mainly
from spurious correlations. Particularly, we identify six types of existing
model biases, including mention-context bias, lexical overlapping bias, named
entity bias, pronoun bias, dependency bias, and overgeneralization bias. To
mitigate model biases, we then introduce a counterfactual data augmentation
method. By augmenting the original training set with their debiased
counterparts, models are forced to fully comprehend sentences and discover the
fundamental cues for entity typing, rather than relying on spurious
correlations for shortcuts. Experimental results on the UFET dataset show our
counterfactual data augmentation approach helps improve generalization of
different entity typing models with consistently better performance on both the
original and debiased test sets."
Evaluating and Inducing Personality in Pre-trained Language Models,0.156256,"Standardized and quantified evaluation of machine behaviors is a crux of
understanding LLMs. In this study, we draw inspiration from psychometric
studies by leveraging human personality theory as a tool for studying machine
behaviors. Originating as a philosophical quest for human behaviors, the study
of personality delves into how individuals differ in thinking, feeling, and
behaving. Toward building and understanding human-like social machines, we are
motivated to ask: Can we assess machine behaviors by leveraging human
psychometric tests in a principled and quantitative manner? If so, can we
induce a specific personality in LLMs? To answer these questions, we introduce
the Machine Personality Inventory (MPI) tool for studying machine behaviors;
MPI follows standardized personality tests, built upon the Big Five Personality
Factors (Big Five) theory and personality assessment inventories. By
systematically evaluating LLMs with MPI, we provide the first piece of evidence
demonstrating the efficacy of MPI in studying LLMs behaviors. We further devise
a Personality Prompting (P^2) method to induce LLMs with specific personalities
in a controllable way, capable of producing diverse and verifiable behaviors.
We hope this work sheds light on future studies by adopting personality as the
essential indicator for various downstream tasks, and could further motivate
research into equally intriguing human-like machine behaviors."
Automated Isovist Computation for Minecraft,0.142191,"Procedural content generation for games is a growing trend in both research
and industry, even though there is no consensus of how good content looks, nor
how to automatically evaluate it. A number of metrics have been developed in
the past, usually focused on the artifact as a whole, and mostly lacking
grounding in human experience. In this study we develop a new set of automated
metrics, motivated by ideas from architecture, namely isovists and space
syntax, which have a track record of capturing human experience of space. These
metrics can be computed for a specific game state, from the player's
perspective, and take into account their embodiment in the game world. We show
how to apply those metrics to the 3d blockworld of Minecraft. We use a dataset
of generated settlements from the GDMC Settlement Generation Challenge in
Minecraft and establish several rank-based correlations between the isovist
properties and the rating human judges gave those settelements. We also produce
a range of heat maps that demonstrate the location based applicability of the
approach, which allows for development of those metrics as measures for a game
experience at a specific time and space."
Learning Probabilities of Causation from Finite Population Data,0.238181,"This paper deals with the problem of learning the probabilities of causation
of subpopulations given finite population data. The tight bounds of three basic
probabilities of causation, the probability of necessity and sufficiency (PNS),
the probability of sufficiency (PS), and the probability of necessity (PN),
were derived by Tian and Pearl. However, obtaining the bounds for each
subpopulation requires experimental and observational distributions of each
subpopulation, which is usually impractical to estimate given finite population
data. We propose a machine learning model that helps to learn the bounds of the
probabilities of causation for subpopulations given finite population data. We
further show by a simulated study that the machine learning model is able to
learn the bounds of PNS for 32768 subpopulations with only knowing roughly 500
of them from the finite population data."
JuryGCN: Quantifying Jackknife Uncertainty on Graph Convolutional Networks,0.0893711,"Graph Convolutional Network (GCN) has exhibited strong empirical performance
in many real-world applications. The vast majority of existing works on GCN
primarily focus on the accuracy while ignoring how confident or uncertain a GCN
is with respect to its predictions. Despite being a cornerstone of trustworthy
graph mining, uncertainty quantification on GCN has not been well studied and
the scarce existing efforts either fail to provide deterministic quantification
or have to change the training procedure of GCN by introducing additional
parameters or architectures. In this paper, we propose the first
frequentist-based approach named JuryGCN in quantifying the uncertainty of GCN,
where the key idea is to quantify the uncertainty of a node as the width of
confidence interval by a jackknife estimator. Moreover, we leverage the
influence functions to estimate the change in GCN parameters without
re-training to scale up the computation. The proposed JuryGCN is capable of
quantifying uncertainty deterministically without modifying the GCN
architecture or introducing additional parameters. We perform extensive
experimental evaluation on real-world datasets in the tasks of both active
learning and semi-supervised node classification, which demonstrate the
efficacy of the proposed method."
Monte Carlo Tree Search based Variable Selection for High Dimensional Bayesian Optimization,0.216425,"Bayesian optimization (BO) is a class of popular methods for expensive
black-box optimization, and has been widely applied to many scenarios. However,
BO suffers from the curse of dimensionality, and scaling it to high-dimensional
problems is still a challenge. In this paper, we propose a variable selection
method MCTS-VS based on Monte Carlo tree search (MCTS), to iteratively select
and optimize a subset of variables. That is, MCTS-VS constructs a
low-dimensional subspace via MCTS and optimizes in the subspace with any BO
algorithm. We give a theoretical analysis of the general variable selection
method to reveal how it can work. Experiments on high-dimensional synthetic
functions and real-world problems (i.e., NAS-bench problems and MuJoCo
locomotion tasks) show that MCTS-VS equipped with a proper BO optimizer can
achieve state-of-the-art performance."
"""This is Fake! Shared it by Mistake"": Assessing the Intent of Fake News Spreaders",0.390708,"Individuals can be misled by fake news and spread it unintentionally without
knowing it is false. This phenomenon has been frequently observed but has not
been investigated. Our aim in this work is to assess the intent of fake news
spreaders. To distinguish between intentional versus unintentional spreading,
we study the psychological explanations of unintentional spreading. With this
foundation, we then propose an influence graph, using which we assess the
intent of fake news spreaders. Our extensive experiments show that the assessed
intent can help significantly differentiate between intentional and
unintentional fake news spreaders. Furthermore, the estimated intent can
significantly improve the current techniques that detect fake news. To our best
knowledge, this is the first work to model individuals' intent in fake news
spreading."
Algorithms for Weighted Pushdown Automata,0.069249,"Weighted pushdown automata (WPDAs) are at the core of many natural language
processing tasks, like syntax-based statistical machine translation and
transition-based dependency parsing. As most existing dynamic programming
algorithms are designed for context-free grammars (CFGs), algorithms for PDAs
often resort to a PDA-to-CFG conversion. In this paper, we develop novel
algorithms that operate directly on WPDAs. Our algorithms are inspired by
Lang's algorithm, but use a more general definition of pushdown automaton and
either reduce the space requirements by a factor of $|\Gamma|$ (the size of the
stack alphabet) or reduce the runtime by a factor of more than $|Q|$ (the
number of states). When run on the same class of PDAs as Lang's algorithm, our
algorithm is both more space-efficient by a factor of $|\Gamma|$ and more
time-efficient by a factor of $|Q| \cdot |\Gamma|$."
Watermark Vaccine: Adversarial Attacks to Prevent Watermark Removal,0.0921845,"As a common security tool, visible watermarking has been widely applied to
protect copyrights of digital images. However, recent works have shown that
visible watermarks can be removed by DNNs without damaging their host images.
Such watermark-removal techniques pose a great threat to the ownership of
images. Inspired by the vulnerability of DNNs on adversarial perturbations, we
propose a novel defence mechanism by adversarial machine learning for good.
From the perspective of the adversary, blind watermark-removal networks can be
posed as our target models; then we actually optimize an imperceptible
adversarial perturbation on the host images to proactively attack against
watermark-removal networks, dubbed Watermark Vaccine. Specifically, two types
of vaccines are proposed. Disrupting Watermark Vaccine (DWV) induces to ruin
the host image along with watermark after passing through watermark-removal
networks. In contrast, Inerasable Watermark Vaccine (IWV) works in another
fashion of trying to keep the watermark not removed and still noticeable.
Extensive experiments demonstrate the effectiveness of our DWV/IWV in
preventing watermark removal, especially on various watermark removal networks."
Patch-wise Contrastive Style Learning for Instagram Filter Removal,0.0603154,"Image-level corruptions and perturbations degrade the performance of CNNs on
different downstream vision tasks. Social media filters are one of the most
common resources of various corruptions and perturbations for real-world visual
analysis applications. The negative effects of these distractive factors can be
alleviated by recovering the original images with their pure style for the
inference of the downstream vision tasks. Assuming these filters substantially
inject a piece of additional style information to the social media images, we
can formulate the problem of recovering the original versions as a reverse
style transfer problem. We introduce Contrastive Instagram Filter Removal
Network (CIFR), which enhances this idea for Instagram filter removal by
employing a novel multi-layer patch-wise contrastive style learning mechanism.
Experiments show our proposed strategy produces better qualitative and
quantitative results than the previous studies. Moreover, we present the
results of our additional experiments for proposed architecture within
different settings. Finally, we present the inference outputs and quantitative
comparison of filtered and recovered images on localization and segmentation
tasks to encourage the main motivation for this problem."
Instance-Specific Image Goal Navigation: Training Embodied Agents to Find Object Instances,0.242267,"We consider the problem of embodied visual navigation given an image-goal
(ImageNav) where an agent is initialized in an unfamiliar environment and
tasked with navigating to a location 'described' by an image. Unlike related
navigation tasks, ImageNav does not have a standardized task definition which
makes comparison across methods difficult. Further, existing formulations have
two problematic properties; (1) image-goals are sampled from random locations
which can lead to ambiguity (e.g., looking at walls), and (2) image-goals match
the camera specification and embodiment of the agent; this rigidity is limiting
when considering user-driven downstream applications. We present the
Instance-specific ImageNav task (InstanceImageNav) to address these
limitations. Specifically, the goal image is 'focused' on some particular
object instance in the scene and is taken with camera parameters independent of
the agent. We instantiate InstanceImageNav in the Habitat Simulator using
scenes from the Habitat-Matterport3D dataset (HM3D) and release a standardized
benchmark to measure community progress."
Disentangling Identity and Pose for Facial Expression Recognition,0.0501211,"Facial expression recognition (FER) is a challenging problem because the
expression component is always entangled with other irrelevant factors, such as
identity and head pose. In this work, we propose an identity and pose
disentangled facial expression recognition (IPD-FER) model to learn more
discriminative feature representation. We regard the holistic facial
representation as the combination of identity, pose and expression. These three
components are encoded with different encoders. For identity encoder, a well
pre-trained face recognition model is utilized and fixed during training, which
alleviates the restriction on specific expression training data in previous
works and makes the disentanglement practicable on in-the-wild datasets. At the
same time, the pose and expression encoder are optimized with corresponding
labels. Combining identity and pose feature, a neutral face of input individual
should be generated by the decoder. When expression feature is added, the input
image should be reconstructed. By comparing the difference between synthesized
neutral and expressional images of the same individual, the expression
component is further disentangled from identity and pose. Experimental results
verify the effectiveness of our method on both lab-controlled and in-the-wild
databases and we achieve state-of-the-art recognition performance."
BigColor: Colorization using a Generative Color Prior for Natural Images,0.0442489,"For realistic and vivid colorization, generative priors have recently been
exploited. However, such generative priors often fail for in-the-wild complex
images due to their limited representation space. In this paper, we propose
BigColor, a novel colorization approach that provides vivid colorization for
diverse in-the-wild images with complex structures. While previous generative
priors are trained to synthesize both image structures and colors, we learn a
generative color prior to focus on color synthesis given the spatial structure
of an image. In this way, we reduce the burden of synthesizing image structures
from the generative prior and expand its representation space to cover diverse
images. To this end, we propose a BigGAN-inspired encoder-generator network
that uses a spatial feature map instead of a spatially-flattened BigGAN latent
code, resulting in an enlarged representation space. Our method enables robust
colorization for diverse inputs in a single forward pass, supports arbitrary
input resolutions, and provides multi-modal colorization results. We
demonstrate that BigColor significantly outperforms existing methods especially
on in-the-wild images with complex structures."
TimeLMs: Diachronic Language Models from Twitter,0.99188,"Despite its importance, the time variable has been largely neglected in the
NLP and language model literature. In this paper, we present TimeLMs, a set of
language models specialized on diachronic Twitter data. We show that a
continual learning strategy contributes to enhancing Twitter-based language
models' capacity to deal with future and out-of-distribution tweets, while
making them competitive with standardized and more monolithic benchmarks. We
also perform a number of qualitative analyses showing how they cope with trends
and peaks in activity involving specific named entities or concept drift."
Deep Learning on a Healthy Data Diet: Finding Important Examples for Fairness,0.0507472,"Data-driven predictive solutions predominant in commercial applications tend
to suffer from biases and stereotypes, which raises equity concerns. Prediction
models may discover, use, or amplify spurious correlations based on gender or
other protected personal characteristics, thus discriminating against
marginalized groups. Mitigating gender bias has become an important research
focus in natural language processing (NLP) and is an area where annotated
corpora are available. Data augmentation reduces gender bias by adding
counterfactual examples to the training dataset. In this work, we show that
some of the examples in the augmented dataset can be not important or even
harmful for fairness. We hence propose a general method for pruning both the
factual and counterfactual examples to maximize the model's fairness as
measured by the demographic parity, equality of opportunity, and equality of
odds. The fairness achieved by our method surpasses that of data augmentation
on three text classification datasets, using no more than half of the examples
in the augmented dataset. Our experiments are conducted using models of varying
sizes and pre-training settings."
Multi-View Document Representation Learning for Open-Domain Dense Retrieval,0.496007,"Dense retrieval has achieved impressive advances in first-stage retrieval
from a large-scale document collection, which is built on bi-encoder
architecture to produce single vector representation of query and document.
However, a document can usually answer multiple potential queries from
different views. So the single vector representation of a document is hard to
match with multi-view queries, and faces a semantic mismatch problem. This
paper proposes a multi-view document representation learning framework, aiming
to produce multi-view embeddings to represent documents and enforce them to
align with different queries. First, we propose a simple yet effective method
of generating multiple embeddings through viewers. Second, to prevent
multi-view embeddings from collapsing to the same one, we further propose a
global-local loss with annealed temperature to encourage the multiple viewers
to better align with different potential queries. Experiments show our method
outperforms recent works and achieves state-of-the-art results."
The Internet of Senses: Building on Semantic Communications and Edge Intelligence,0.127002,"The Internet of Senses (IoS) holds the promise of flawless telepresence-style
communication for all human `receptors' and therefore blurs the difference of
virtual and real environments. We commence by highlighting the compelling use
cases empowered by the IoS and also the key network requirements. We then
elaborate on how the emerging semantic communications and Artificial
Intelligence (AI)/Machine Learning (ML) paradigms along with 6G technologies
may satisfy the requirements of IoS use cases. On one hand, semantic
communications can be applied for extracting meaningful and significant
information and hence efficiently exploit the resources and for harnessing a
priori information at the receiver to satisfy IoS requirements. On the other
hand, AI/ML facilitates frugal network resource management by making use of the
enormous amount of data generated in IoS edge nodes and devices, as well as by
optimizing the IoS performance via intelligent agents. However, the intelligent
agents deployed at the edge are not completely aware of each others' decisions
and the environments of each other, hence they operate in a partially rather
than fully observable environment. Therefore, we present a case study of
Partially Observable Markov Decision Processes (POMDP) for improving the User
Equipment (UE) throughput and energy consumption, as they are imperative for
IoS use cases, using Reinforcement Learning for astutely activating and
deactivating the component carriers in carrier aggregation. Finally, we outline
the challenges and open issues of IoS implementations and employing semantic
communications, edge intelligence as well as learning under partial
observability in the IoS context."
Hyperbolic Vision Transformers: Combining Improvements in Metric Learning,0.370638,"Metric learning aims to learn a highly discriminative model encouraging the
embeddings of similar classes to be close in the chosen metrics and pushed
apart for dissimilar ones. The common recipe is to use an encoder to extract
embeddings and a distance-based loss function to match the representations --
usually, the Euclidean distance is utilized. An emerging interest in learning
hyperbolic data embeddings suggests that hyperbolic geometry can be beneficial
for natural data. Following this line of work, we propose a new
hyperbolic-based model for metric learning. At the core of our method is a
vision transformer with output embeddings mapped to hyperbolic space. These
embeddings are directly optimized using modified pairwise cross-entropy loss.
We evaluate the proposed model with six different formulations on four datasets
achieving the new state-of-the-art performance. The source code is available at
https://github.com/htdt/hyp_metric."
A Second Wave of UD Hebrew Treebanking and Cross-Domain Parsing,0.284874,"Foundational Hebrew NLP tasks such as segmentation, tagging and parsing, have
relied to date on various versions of the Hebrew Treebank (HTB, Sima'an et al.
2001). However, the data in HTB, a single-source newswire corpus, is now over
30 years old, and does not cover many aspects of contemporary Hebrew on the
web. This paper presents a new, freely available UD treebank of Hebrew
stratified from a range of topics selected from Hebrew Wikipedia. In addition
to introducing the corpus and evaluating the quality of its annotations, we
deploy automatic validation tools based on grew (Guillaume, 2021), and conduct
the first cross domain parsing experiments in Hebrew. We obtain new
state-of-the-art (SOTA) results on UD NLP tasks, using a combination of the
latest language modelling and some incremental improvements to existing
transformer based approaches. We also release a new version of the UD HTB
matching annotation scheme updates from our new corpus."
Truth Set Algebra: A New Way to Prove Undefinability,0.19379,"The article proposes a new technique for proving the undefinability of
logical connectives through each other and illustrates the technique with
several examples. Some of the obtained results are new proofs of the existing
theorems, others are original to this work."
Is a Modular Architecture Enough?,0.0992929,"Inspired from human cognition, machine learning systems are gradually
revealing advantages of sparser and more modular architectures. Recent work
demonstrates that not only do some modular architectures generalize well, but
they also lead to better out-of-distribution generalization, scaling
properties, learning speed, and interpretability. A key intuition behind the
success of such systems is that the data generating system for most real-world
settings is considered to consist of sparsely interacting parts, and endowing
models with similar inductive biases will be helpful. However, the field has
been lacking in a rigorous quantitative assessment of such systems because
these real-world data distributions are complex and unknown. In this work, we
provide a thorough assessment of common modular architectures, through the lens
of simple and known modular data distributions. We highlight the benefits of
modularity and sparsity and reveal insights on the challenges faced while
optimizing modular systems. In doing so, we propose evaluation metrics that
highlight the benefits of modularity, the regimes in which these benefits are
substantial, as well as the sub-optimality of current end-to-end learned
modular systems as opposed to their claimed potential."
Evaluating Explainability for Graph Neural Networks,0.0557395,"As post hoc explanations are increasingly used to understand the behavior of
graph neural networks (GNNs), it becomes crucial to evaluate the quality and
reliability of GNN explanations. However, assessing the quality of GNN
explanations is challenging as existing graph datasets have no or unreliable
ground-truth explanations for a given task. Here, we introduce a synthetic
graph data generator, ShapeGGen, which can generate a variety of benchmark
datasets (e.g., varying graph sizes, degree distributions, homophilic vs.
heterophilic graphs) accompanied by ground-truth explanations. Further, the
flexibility to generate diverse synthetic datasets and corresponding
ground-truth explanations allows us to mimic the data generated by various
real-world applications. We include ShapeGGen and several real-world graph
datasets into an open-source graph explainability library, GraphXAI. In
addition to synthetic and real-world graph datasets with ground-truth
explanations, GraphXAI provides data loaders, data processing functions,
visualizers, GNN model implementations, and evaluation metrics to benchmark the
performance of GNN explainability methods."
Bayes risk CTC: Controllable CTC alignment in Sequence-to-Sequence tasks,0.116065,"Sequence-to-Sequence (seq2seq) tasks transcribe the input sequence to a
target sequence. The Connectionist Temporal Classification (CTC) criterion is
widely used in multiple seq2seq tasks. Besides predicting the target sequence,
a side product of CTC is to predict the alignment, which is the most probable
input-long sequence that specifies a hard aligning relationship between the
input and target units. As there are multiple potential aligning sequences
(called paths) that are equally considered in CTC formulation, the choice of
which path will be most probable and become the predicted alignment is always
uncertain. In addition, it is usually observed that the alignment predicted by
vanilla CTC will drift compared with its reference and rarely provides
practical functionalities. Thus, the motivation of this work is to make the CTC
alignment prediction controllable and thus equip CTC with extra
functionalities. The Bayes risk CTC (BRCTC) criterion is then proposed in this
work, in which a customizable Bayes risk function is adopted to enforce the
desired characteristics of the predicted alignment. With the risk function, the
BRCTC is a general framework to adopt some customizable preference over the
paths in order to concentrate the posterior into a particular subset of the
paths. In applications, we explore one particular preference which yields
models with the down-sampling ability and reduced inference costs. By using
BRCTC with another preference for early emissions, we obtain an improved
performance-latency trade-off for online models. Experimentally, the proposed
BRCTC reduces the inference cost of offline models by up to 47% without
performance degradation and cuts down the overall latency of online systems to
an unseen level."
Understanding Translationese in Cross-Lingual Summarization,0.476648,"Given a document in a source language, cross-lingual summarization (CLS) aims
at generating a concise summary in a different target language. Unlike
monolingual summarization (MS), naturally occurring source-language documents
paired with target-language summaries are rare. To collect large-scale CLS
data, existing datasets typically involve translation in their creation.
However, the translated text is distinguished from the text originally written
in that language, i.e., translationese. In this paper, we first confirm that
different approaches of constructing CLS datasets will lead to different
degrees of translationese. Then we systematically investigate how
translationese affects CLS model evaluation and performance when it appears in
source documents or target summaries. In detail, we find that (1) the
translationese in documents or summaries of test sets might lead to the
discrepancy between human judgment and automatic evaluation; (2) the
translationese in training sets would harm model performance in real-world
applications; (3) though machine-translated documents involve translationese,
they are very useful for building CLS systems on low-resource languages under
specific training strategies. Lastly, we give suggestions for future CLS
research including dataset and model developments. We hope that our work could
let researchers notice the phenomenon of translationese in CLS and take it into
account in the future."
The Third International Verification of Neural Networks Competition (VNN-COMP 2022): Summary and Results,0.0949897,"This report summarizes the 3rd International Verification of Neural Networks
Competition (VNN-COMP 2022), held as a part of the 5th Workshop on Formal
Methods for ML-Enabled Autonomous Systems (FoMLAS), which was collocated with
the 34th International Conference on Computer-Aided Verification (CAV).
VNN-COMP is held annually to facilitate the fair and objective comparison of
state-of-the-art neural network verification tools, encourage the
standardization of tool interfaces, and bring together the neural network
verification community. To this end, standardized formats for networks (ONNX)
and specification (VNN-LIB) were defined, tools were evaluated on equal-cost
hardware (using an automatic evaluation pipeline based on AWS instances), and
tool parameters were chosen by the participants before the final test sets were
made public. In the 2022 iteration, 11 teams participated on a diverse set of
12 scored benchmarks. This report summarizes the rules, benchmarks,
participating tools, results, and lessons learned from this iteration of this
competition."
Label-enhanced Prototypical Network with Contrastive Learning for Multi-label Few-shot Aspect Category Detection,0.575907,"Multi-label aspect category detection allows a given review sentence to
contain multiple aspect categories, which is shown to be more practical in
sentiment analysis and attracting increasing attention. As annotating large
amounts of data is time-consuming and labor-intensive, data scarcity occurs
frequently in real-world scenarios, which motivates multi-label few-shot aspect
category detection. However, research on this problem is still in infancy and
few methods are available. In this paper, we propose a novel label-enhanced
prototypical network (LPN) for multi-label few-shot aspect category detection.
The highlights of LPN can be summarized as follows. First, it leverages label
description as auxiliary knowledge to learn more discriminative prototypes,
which can retain aspect-relevant information while eliminating the harmful
effect caused by irrelevant aspects. Second, it integrates with contrastive
learning, which encourages that the sentences with the same aspect label are
pulled together in embedding space while simultaneously pushing apart the
sentences with different aspect labels. In addition, it introduces an adaptive
multi-label inference module to predict the aspect count in the sentence, which
is simple yet effective. Extensive experimental results on three datasets
demonstrate that our proposed model LPN can consistently achieve
state-of-the-art performance."
DuAT: Dual-Aggregation Transformer Network for Medical Image Segmentation,0.0635764,"Transformer-based models have been widely demonstrated to be successful in
computer vision tasks by modelling long-range dependencies and capturing global
representations. However, they are often dominated by features of large
patterns leading to the loss of local details (e.g., boundaries and small
objects), which are critical in medical image segmentation. To alleviate this
problem, we propose a Dual-Aggregation Transformer Network called DuAT, which
is characterized by two innovative designs, namely, the Global-to-Local Spatial
Aggregation (GLSA) and Selective Boundary Aggregation (SBA) modules. The GLSA
has the ability to aggregate and represent both global and local spatial
features, which are beneficial for locating large and small objects,
respectively. The SBA module is used to aggregate the boundary characteristic
from low-level features and semantic information from high-level features for
better preserving boundary details and locating the re-calibration objects.
Extensive experiments in six benchmark datasets demonstrate that our proposed
model outperforms state-of-the-art methods in the segmentation of skin lesion
images, and polyps in colonoscopy images. In addition, our approach is more
robust than existing methods in various challenging situations such as small
object segmentation and ambiguous object boundaries."
Draw Your Art Dream: Diverse Digital Art Synthesis with Multimodal Guided Diffusion,0.851609,"Digital art synthesis is receiving increasing attention in the multimedia
community because of engaging the public with art effectively. Current digital
art synthesis methods usually use single-modality inputs as guidance, thereby
limiting the expressiveness of the model and the diversity of generated
results. To solve this problem, we propose the multimodal guided artwork
diffusion (MGAD) model, which is a diffusion-based digital artwork generation
approach that utilizes multimodal prompts as guidance to control the
classifier-free diffusion model. Additionally, the contrastive language-image
pretraining (CLIP) model is used to unify text and image modalities. Extensive
experimental results on the quality and quantity of the generated digital art
paintings confirm the effectiveness of the combination of the diffusion model
and multimodal guidance. Code is available at
https://github.com/haha-lisa/MGAD-multimodal-guided-artwork-diffusion."
HiSMatch: Historical Structure Matching based Temporal Knowledge Graph Reasoning,0.0558385,"A Temporal Knowledge Graph (TKG) is a sequence of KGs with respective
timestamps, which adopts quadruples in the form of (\emph{subject},
\emph{relation}, \emph{object}, \emph{timestamp}) to describe dynamic facts.
TKG reasoning has facilitated many real-world applications via answering such
queries as (\emph{query entity}, \emph{query relation}, \emph{?}, \emph{future
timestamp}) about future. This is actually a matching task between a query and
candidate entities based on their historical structures, which reflect
behavioral trends of the entities at different timestamps. In addition, recent
KGs provide background knowledge of all the entities, which is also helpful for
the matching. Thus, in this paper, we propose the \textbf{Hi}storical
\textbf{S}tructure \textbf{Match}ing (\textbf{HiSMatch}) model. It applies two
structure encoders to capture the semantic information contained in the
historical structures of the query and candidate entities. Besides, it adopts
another encoder to integrate the background knowledge into the model. TKG
reasoning experiments on six benchmark datasets demonstrate the significant
improvement of the proposed HiSMatch model, with up to 5.6\% performance
improvement in MRR, compared to the state-of-the-art baselines."
DQ-BART: Efficient Sequence-to-Sequence Model via Joint Distillation and Quantization,0.837716,"Large-scale pre-trained sequence-to-sequence models like BART and T5 achieve
state-of-the-art performance on many generative NLP tasks. However, such models
pose a great challenge in resource-constrained scenarios owing to their large
memory requirements and high latency. To alleviate this issue, we propose to
jointly distill and quantize the model, where knowledge is transferred from the
full-precision teacher model to the quantized and distilled low-precision
student model. Empirical analyses show that, despite the challenging nature of
generative tasks, we were able to achieve a 16.5x model footprint compression
ratio with little performance drop relative to the full-precision counterparts
on multiple summarization and QA datasets. We further pushed the limit of
compression ratio to 27.7x and presented the performance-efficiency trade-off
for generative tasks using pre-trained models. To the best of our knowledge,
this is the first work aiming to effectively distill and quantize
sequence-to-sequence pre-trained models for language generation tasks."
Robust Lottery Tickets for Pre-trained Language Models,0.203663,"Recent works on Lottery Ticket Hypothesis have shown that pre-trained
language models (PLMs) contain smaller matching subnetworks(winning tickets)
which are capable of reaching accuracy comparable to the original models.
However, these tickets are proved to be notrobust to adversarial examples, and
even worse than their PLM counterparts. To address this problem, we propose a
novel method based on learning binary weight masks to identify robust tickets
hidden in the original PLMs. Since the loss is not differentiable for the
binary mask, we assign the hard concrete distribution to the masks and
encourage their sparsity using a smoothing approximation of L0
regularization.Furthermore, we design an adversarial loss objective to guide
the search for robust tickets and ensure that the tickets perform well bothin
accuracy and robustness. Experimental results show the significant improvement
of the proposed method over previous work on adversarial robustness evaluation."
Gradient-based Uncertainty for Monocular Depth Estimation,0.0,"In monocular depth estimation, disturbances in the image context, like moving
objects or reflecting materials, can easily lead to erroneous predictions. For
that reason, uncertainty estimates for each pixel are necessary, in particular
for safety-critical applications such as automated driving. We propose a post
hoc uncertainty estimation approach for an already trained and thus fixed depth
estimation model, represented by a deep neural network. The uncertainty is
estimated with the gradients which are extracted with an auxiliary loss
function. To avoid relying on ground-truth information for the loss definition,
we present an auxiliary loss function based on the correspondence of the depth
prediction for an image and its horizontally flipped counterpart. Our approach
achieves state-of-the-art uncertainty estimation results on the KITTI and NYU
Depth V2 benchmarks without the need to retrain the neural network. Models and
code are publicly available at https://github.com/jhornauer/GrUMoDepth."
Spiking Neural Networks for Frame-based and Event-based Single Object Localization,0.104314,"Spiking neural networks have shown much promise as an energy-efficient
alternative to artificial neural networks. However, understanding the impacts
of sensor noises and input encodings on the network activity and performance
remains difficult with common neuromorphic vision baselines like
classification. Therefore, we propose a spiking neural network approach for
single object localization trained using surrogate gradient descent, for frame-
and event-based sensors. We compare our method with similar artificial neural
networks and show that our model has competitive/better performance in
accuracy, robustness against various corruptions, and has lower energy
consumption. Moreover, we study the impact of neural coding schemes for static
images in accuracy, robustness, and energy efficiency. Our observations differ
importantly from previous studies on bio-plausible learning rules, which helps
in the design of surrogate gradient trained architectures, and offers insight
to design priorities in future neuromorphic technologies in terms of noise
characteristics and data encoding methods."
Instruction Tuning for Few-Shot Aspect-Based Sentiment Analysis,0.180688,"Aspect-based Sentiment Analysis (ABSA) is a fine-grained sentiment analysis
task which involves four elements from user-generated texts: aspect term,
aspect category, opinion term, and sentiment polarity. Most computational
approaches focus on some of the ABSA sub-tasks such as tuple (aspect term,
sentiment polarity) or triplet (aspect term, opinion term, sentiment polarity)
extraction using either pipeline or joint modeling approaches. Recently,
generative approaches have been proposed to extract all four elements as (one
or more) quadruplets from text as a single task. In this work, we take a step
further and propose a unified framework for solving ABSA, and the associated
sub-tasks to improve the performance in few-shot scenarios. To this end, we
fine-tune a T5 model with instructional prompts in a multi-task learning
fashion covering all the sub-tasks, as well as the entire quadruple prediction
task. In experiments with multiple benchmark datasets, we show that the
proposed multi-task prompting approach brings performance boost (by absolute
8.29 F1) in the few-shot learning setting."
Continuous Scene Representations for Embodied AI,0.11896,"We propose Continuous Scene Representations (CSR), a scene representation
constructed by an embodied agent navigating within a space, where objects and
their relationships are modeled by continuous valued embeddings. Our method
captures feature relationships between objects, composes them into a graph
structure on-the-fly, and situates an embodied agent within the representation.
Our key insight is to embed pair-wise relationships between objects in a latent
space. This allows for a richer representation compared to discrete relations
(e.g., [support], [next-to]) commonly used for building scene representations.
CSR can track objects as the agent moves in a scene, update the representation
accordingly, and detect changes in room configurations. Using CSR, we
outperform state-of-the-art approaches for the challenging downstream task of
visual room rearrangement, without any task specific training. Moreover, we
show the learned embeddings capture salient spatial details of the scene and
show applicability to real world data. A summery video and code is available at
https://prior.allenai.org/projects/csr."
PTSEFormer: Progressive Temporal-Spatial Enhanced TransFormer Towards Video Object Detection,-1.0,"Recent years have witnessed a trend of applying context frames to boost the
performance of object detection as video object detection. Existing methods
usually aggregate features at one stroke to enhance the feature. These methods,
however, usually lack spatial information from neighboring frames and suffer
from insufficient feature aggregation. To address the issues, we perform a
progressive way to introduce both temporal information and spatial information
for an integrated enhancement. The temporal information is introduced by the
temporal feature aggregation model (TFAM), by conducting an attention mechanism
between the context frames and the target frame (i.e., the frame to be
detected). Meanwhile, we employ a Spatial Transition Awareness Model (STAM) to
convey the location transition information between each context frame and
target frame. Built upon a transformer-based detector DETR, our PTSEFormer also
follows an end-to-end fashion to avoid heavy post-processing procedures while
achieving 88.1% mAP on the ImageNet VID dataset. Codes are available at
https://github.com/Hon-Wong/PTSEFormer."
One-Shot Adaptation of GAN in Just One CLIP,0.12596,"There are many recent research efforts to fine-tune a pre-trained generator
with a few target images to generate images of a novel domain. Unfortunately,
these methods often suffer from overfitting or under-fitting when fine-tuned
with a single target image. To address this, here we present a novel
single-shot GAN adaptation method through unified CLIP space manipulations.
Specifically, our model employs a two-step training strategy: reference image
search in the source generator using a CLIP-guided latent optimization,
followed by generator fine-tuning with a novel loss function that imposes CLIP
space consistency between the source and adapted generators. To further improve
the adapted model to produce spatially consistent samples with respect to the
source generator, we also propose contrastive regularization for patchwise
relationships in the CLIP space. Experimental results show that our model
generates diverse outputs with the target texture and outperforms the baseline
models both qualitatively and quantitatively. Furthermore, we show that our
CLIP space manipulation strategy allows more effective attribute editing."
FreGAN: Exploiting Frequency Components for Training GANs under Limited Data,0.202105,"Training GANs under limited data often leads to discriminator overfitting and
memorization issues, causing divergent training. Existing approaches mitigate
the overfitting by employing data augmentations, model regularization, or
attention mechanisms. However, they ignore the frequency bias of GANs and take
poor consideration towards frequency information, especially high-frequency
signals that contain rich details. To fully utilize the frequency information
of limited data, this paper proposes FreGAN, which raises the model's frequency
awareness and draws more attention to producing high-frequency signals,
facilitating high-quality generation. In addition to exploiting both real and
generated images' frequency information, we also involve the frequency signals
of real images as a self-supervised constraint, which alleviates the GAN
disequilibrium and encourages the generator to synthesize adequate rather than
arbitrary frequency signals. Extensive results demonstrate the superiority and
effectiveness of our FreGAN in ameliorating generation quality in the low-data
regime (especially when training data is less than 100). Besides, FreGAN can be
seamlessly applied to existing regularization and attention mechanism models to
further boost the performance."
Transformation-Equivariant 3D Object Detection for Autonomous Driving,0.228777,"3D object detection received increasing attention in autonomous driving
recently. Objects in 3D scenes are distributed with diverse orientations.
Ordinary detectors do not explicitly model the variations of rotation and
reflection transformations. Consequently, large networks and extensive data
augmentation are required for robust detection. Recent equivariant networks
explicitly model the transformation variations by applying shared networks on
multiple transformed point clouds, showing great potential in object geometry
modeling. However, it is difficult to apply such networks to 3D object
detection in autonomous driving due to its large computation cost and slow
reasoning speed. In this work, we present TED, an efficient
Transformation-Equivariant 3D Detector to overcome the computation cost and
speed issues. TED first applies a sparse convolution backbone to extract
multi-channel transformation-equivariant voxel features; and then aligns and
aggregates these equivariant features into lightweight and compact
representations for high-performance 3D object detection. On the highly
competitive KITTI 3D car detection leaderboard, TED ranked 1st among all
submissions with competitive efficiency."
Identifying Weaknesses in Machine Translation Metrics Through Minimum Bayes Risk Decoding: A Case Study for COMET,0.718922,"Neural metrics have achieved impressive correlation with human judgements in
the evaluation of machine translation systems, but before we can safely
optimise towards such metrics, we should be aware of (and ideally eliminate)
biases toward bad translations that receive high scores. Our experiments show
that sample-based Minimum Bayes Risk decoding can be used to explore and
quantify such weaknesses. When applying this strategy to COMET for en-de and
de-en, we find that COMET models are not sensitive enough to discrepancies in
numbers and named entities. We further show that these biases are hard to fully
remove by simply training on additional synthetic data and release our code and
data for facilitating further experiments."
"Generated Faces in the Wild: Quantitative Comparison of Stable Diffusion, Midjourney and DALL-E 2",0.20827,"The field of image synthesis has made great strides in the last couple of
years. Recent models are capable of generating images with astonishing quality.
Fine-grained evaluation of these models on some interesting categories such as
faces is still missing. Here, we conduct a quantitative comparison of three
popular systems including Stable Diffusion, Midjourney, and DALL-E 2 in their
ability to generate photorealistic faces in the wild. We find that Stable
Diffusion generates better faces than the other systems, according to the FID
score. We also introduce a dataset of generated faces in the wild dubbed GFW,
including a total of 15,076 faces. Furthermore, we hope that our study spurs
follow-up research in assessing the generative models and improving them. Data
and code are available at data and code, respectively."
WiCV 2021: The Eighth Women In Computer Vision Workshop,0.108673,"In this paper, we present the details of Women in Computer Vision Workshop -
WiCV 2021, organized alongside the virtual CVPR 2021. It provides a voice to a
minority (female) group in the computer vision community and focuses on
increasing the visibility of these researchers, both in academia and industry.
WiCV believes that such an event can play an important role in lowering the
gender imbalance in the field of computer vision. WiCV is organized each year
where it provides a)~opportunity for collaboration between researchers from
minority groups, b)~mentorship to female junior researchers, c)~financial
support to presenters to overcome monetary burden and d)~large and diverse
choice of role models, who can serve as examples to younger researchers at the
beginning of their careers. In this paper, we present a report on the workshop
program, trends over the past years, a summary of statistics regarding
presenters, attendees, and sponsorship for the WiCV 2021 workshop."
Using Ontologies for the Formalization and Recognition of Criticality for Automated Driving,0.0,"Knowledge representation and reasoning has a long history of examining how
knowledge can be formalized, interpreted, and semantically analyzed by
machines. In the area of automated vehicles, recent advances suggest the
ability to formalize and leverage relevant knowledge as a key enabler in
handling the inherently open and complex context of the traffic world. This
paper demonstrates ontologies to be a powerful tool for a) modeling and
formalization of and b) reasoning about factors associated with criticality in
the environment of automated vehicles. For this, we leverage the well-known
6-Layer Model to create a formal representation of the environmental context.
Within this representation, an ontology models domain knowledge as logical
axioms, enabling deduction on the presence of critical factors within traffic
scenes and scenarios. For executing automated analyses, a joint description
logic and rule reasoner is used in combination with an a-priori predicate
augmentation. We elaborate on the modular approach, present a publicly
available implementation, and evaluate the method by means of a large-scale
drone data set of urban traffic scenarios."
SATr: Slice Attention with Transformer for Universal Lesion Detection,0.165258,"Universal Lesion Detection (ULD) in computed tomography plays an essential
role in computer-aided diagnosis. Promising ULD results have been reported by
multi-slice-input detection approaches which model 3D context from multiple
adjacent CT slices, but such methods still experience difficulty in obtaining a
global representation among different slices and within each individual slice
since they only use convolution-based fusion operations. In this paper, we
propose a novel Slice Attention Transformer (SATr) block which can be easily
plugged into convolution-based ULD backbones to form hybrid network structures.
Such newly formed hybrid backbones can better model long-distance feature
dependency via the cascaded self-attention modules in the Transformer block
while still holding a strong power of modeling local features with the
convolutional operations in the original backbone. Experiments with five
state-of-the-art methods show that the proposed SATr block can provide an
almost free boost to lesion detection accuracy without extra hyperparameters or
special network designs."
Privacy-Preserving Image Classification Using Vision Transformer,0.27198,"In this paper, we propose a privacy-preserving image classification method
that is based on the combined use of encrypted images and the vision
transformer (ViT). The proposed method allows us not only to apply images
without visual information to ViT models for both training and testing but to
also maintain a high classification accuracy. ViT utilizes patch embedding and
position embedding for image patches, so this architecture is shown to reduce
the influence of block-wise image transformation. In an experiment, the
proposed method for privacy-preserving image classification is demonstrated to
outperform state-of-the-art methods in terms of classification accuracy and
robustness against various attacks."
Attribute-based Representations for Accurate and Interpretable Video Anomaly Detection,0.178238,"Video anomaly detection (VAD) is a challenging computer vision task with many
practical applications. As anomalies are inherently ambiguous, it is essential
for users to understand the reasoning behind a system's decision in order to
determine if the rationale is sound. In this paper, we propose a simple but
highly effective method that pushes the boundaries of VAD accuracy and
interpretability using attribute-based representations. Our method represents
every object by its velocity and pose. The anomaly scores are computed using a
density-based approach. Surprisingly, we find that this simple representation
is sufficient to achieve state-of-the-art performance in ShanghaiTech, the
largest and most complex VAD dataset. Combining our interpretable
attribute-based representations with implicit, deep representation yields
state-of-the-art performance with a $99.1\%, 93.3\%$, and $85.9\%$ AUROC on
Ped2, Avenue, and ShanghaiTech, respectively. Our method is accurate,
interpretable, and easy to implement."
Overview of the Shared Task on Fake News Detection in Urdu at FIRE 2021,0.245648,"Automatic detection of fake news is a highly important task in the
contemporary world. This study reports the 2nd shared task called
UrduFake@FIRE2021 on identifying fake news detection in Urdu. The goal of the
shared task is to motivate the community to come up with efficient methods for
solving this vital problem, particularly for the Urdu language. The task is
posed as a binary classification problem to label a given news article as a
real or a fake news article. The organizers provide a dataset comprising news
in five domains: (i) Health, (ii) Sports, (iii) Showbiz, (iv) Technology, and
(v) Business, split into training and testing sets. The training set contains
1300 annotated news articles -- 750 real news, 550 fake news, while the testing
set contains 300 news articles -- 200 real, 100 fake news. 34 teams from 7
different countries (China, Egypt, Israel, India, Mexico, Pakistan, and UAE)
registered to participate in the UrduFake@FIRE2021 shared task. Out of those,
18 teams submitted their experimental results, and 11 of those submitted their
technical reports, which is substantially higher compared to the UrduFake
shared task in 2020 when only 6 teams submitted their technical reports. The
technical reports submitted by the participants demonstrated different data
representation techniques ranging from count-based BoW features to word vector
embeddings as well as the use of numerous machine learning algorithms ranging
from traditional SVM to various neural network architectures including
Transformers such as BERT and RoBERTa. In this year's competition, the best
performing system obtained an F1-macro score of 0.679, which is lower than the
past year's best result of 0.907 F1-macro. Admittedly, while training sets from
the past and the current years overlap to a large extent, the testing set
provided this year is completely different."
Fine-grained Category Discovery under Coarse-grained supervision with Hierarchical Weighted Self-contrastive Learning,0.0985062,"Novel category discovery aims at adapting models trained on known categories
to novel categories. Previous works only focus on the scenario where known and
novel categories are of the same granularity. In this paper, we investigate a
new practical scenario called Fine-grained Category Discovery under
Coarse-grained supervision (FCDC). FCDC aims at discovering fine-grained
categories with only coarse-grained labeled data, which can adapt models to
categories of different granularity from known ones and reduce significant
labeling cost. It is also a challenging task since supervised training on
coarse-grained categories tends to focus on inter-class distance (distance
between coarse-grained classes) but ignore intra-class distance (distance
between fine-grained sub-classes) which is essential for separating
fine-grained categories. Considering most current methods cannot transfer
knowledge from coarse-grained level to fine-grained level, we propose a
hierarchical weighted self-contrastive network by building a novel weighted
self-contrastive module and combining it with supervised learning in a
hierarchical manner. Extensive experiments on public datasets show both
effectiveness and efficiency of our model over compared methods. Code and data
are available at https://github.com/Lackel/Hierarchical_Weighted_SCL."
Sar Ship Detection based on Swin Transformer and Feature Enhancement Feature Pyramid Network,0.291995,"With the booming of Convolutional Neural Networks (CNNs), CNNs such as VGG-16
and ResNet-50 widely serve as backbone in SAR ship detection. However, CNN
based backbone is hard to model long-range dependencies, and causes the lack of
enough high-quality semantic information in feature maps of shallow layers,
which leads to poor detection performance in complicated background and
small-sized ships cases. To address these problems, we propose a SAR ship
detection method based on Swin Transformer and Feature Enhancement Feature
Pyramid Network (FEFPN). Swin Transformer serves as backbone to model
long-range dependencies and generates hierarchical features maps. FEFPN is
proposed to further improve the quality of feature maps by gradually enhancing
the semantic information of feature maps at all levels, especially feature maps
in shallow layers. Experiments conducted on SAR ship detection dataset (SSDD)
reveal the advantage of our proposed methods."
Communication Beyond Transmitting Bits: Semantics-Guided Source and Channel Coding,0.557329,"Classical communication paradigms focus on accurately transmitting bits over
a noisy channel, and Shannon theory provides a fundamental theoretical limit on
the rate of reliable communications. In this approach, bits are treated
equally, and the communication system is oblivious to what meaning these bits
convey or how they would be used. Future communications towards intelligence
and conciseness will predictably play a dominant role, and the proliferation of
connected intelligent agents requires a radical rethinking of coded
transmission paradigm to support the new communication morphology on the
horizon. The recent concept of ""semantic communications"" offers a promising
research direction. Injecting semantic guidance into the coded transmission
design to achieve semantics-aware communications shows great potential for
further breakthrough in effectiveness and reliability. This article sheds light
on semantics-guided source and channel coding as a transmission paradigm of
semantic communications, which exploits both data semantics diversity and
wireless channel diversity together to boost the whole system performance. We
present the general system architecture and key techniques, and indicate some
open issues on this topic."
Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection,0.322179,"In some scenarios, classifier requires detecting out-of-distribution samples
far from its training data. With desirable characteristics, reconstruction
autoencoder-based methods deal with this problem by using input reconstruction
error as a metric of novelty vs. normality. We formulate the essence of such
approach as a quadruplet domain translation with an intrinsic bias to only
query for a proxy of conditional data uncertainty. Accordingly, an improvement
direction is formalized as maximumly compressing the autoencoder's latent space
while ensuring its reconstructive power for acting as a described domain
translator. From it, strategies are introduced including semantic
reconstruction, data certainty decomposition and normalized L2 distance to
substantially improve original methods, which together establish
state-of-the-art performance on various benchmarks, e.g., the FPR@95%TPR of
CIFAR-100 vs. TinyImagenet-crop on Wide-ResNet is 0.2%. Importantly, our method
works without any additional data, hard-to-implement structure, time-consuming
pipeline, and even harming the classification accuracy of known classes."
NumGLUE: A Suite of Fundamental yet Challenging Mathematical Reasoning Tasks,0.335746,"Given the ubiquitous nature of numbers in text, reasoning with numbers to
perform simple calculations is an important skill of AI systems. While many
datasets and models have been developed to this end, state-of-the-art AI
systems are brittle; failing to perform the underlying mathematical reasoning
when they appear in a slightly different scenario. Drawing inspiration from
GLUE that was proposed in the context of natural language understanding, we
propose NumGLUE, a multi-task benchmark that evaluates the performance of AI
systems on eight different tasks, that at their core require simple arithmetic
understanding. We show that this benchmark is far from being solved with neural
models including state-of-the-art large-scale language models performing
significantly worse than humans (lower by 46.4%). Further, NumGLUE promotes
sharing knowledge across tasks, especially those with limited training data as
evidenced by the superior performance (average gain of 3.4% on each task) when
a model is jointly trained on all the tasks as opposed to task-specific
modeling. Finally, we hope that NumGLUE will encourage systems that perform
robust and general arithmetic reasoning within language, a first step towards
being able to perform more complex mathematical reasoning."
Zero-Shot On-the-Fly Event Schema Induction,0.18885,"What are the events involved in a pandemic outbreak? What steps should be
taken when planning a wedding? The answers to these questions can be found by
collecting many documents on the complex event of interest, extracting relevant
information, and analyzing it. We present a new approach in which large
language models are utilized to generate source documents that allow
predicting, given a high-level event definition, the specific events,
arguments, and relations between them to construct a schema that describes the
complex event in its entirety. Using our model, complete schemas on any topic
can be generated on-the-fly without any manual data collection, i.e., in a
zero-shot manner. Moreover, we develop efficient methods to extract pertinent
information from texts and demonstrate in a series of experiments that these
schemas are considered to be more complete than human-curated ones in the
majority of examined scenarios. Finally, we show that this framework is
comparable in performance with previous supervised schema induction methods
that rely on collecting real texts while being more general and flexible
without the need for a predefined ontology."
The Inverse of Exact Renormalization Group Flows as Statistical Inference,0.352224,"We build on the view of the Exact Renormalization Group (ERG) as an
instantiation of Optimal Transport described by a functional
convection-diffusion equation. We provide a new information theoretic
perspective for understanding the ERG through the intermediary of Bayesian
Statistical Inference. This connection is facilitated by the Dynamical Bayesian
Inference scheme, which encodes Bayesian inference in the form of a one
parameter family of probability distributions solving an integro-differential
equation derived from Bayes' law. In this note, we demonstrate how the
Dynamical Bayesian Inference equation is, itself, equivalent to a diffusion
equation which we dub Bayesian Diffusion. Identifying the features that define
Bayesian Diffusion, and mapping them onto the features that define the ERG, we
obtain a dictionary outlining how renormalization can be understood as the
inverse of statistical inference."
"GigaST: A 10,000-hour Pseudo Speech Translation Corpus",0.410083,"This paper introduces GigaST, a large-scale pseudo speech translation (ST)
corpus. We create the corpus by translating the text in GigaSpeech, an English
ASR corpus, into German and Chinese. The training set is translated by a strong
machine translation system and the test set is translated by human. ST models
trained with an addition of our corpus obtain new state-of-the-art results on
the MuST-C English-German benchmark test set. We provide a detailed description
of the translation process and verify its quality. We make the translated text
data public and hope to facilitate research in speech translation.
Additionally, we also release the training scripts on NeurST to make it easy to
replicate our systems. GigaST dataset is available at
https://st-benchmark.github.io/resources/GigaST."
Learning Smooth Neural Functions via Lipschitz Regularization,0.243965,"Neural implicit fields have recently emerged as a useful representation for
3D shapes. These fields are commonly represented as neural networks which map
latent descriptors and 3D coordinates to implicit function values. The latent
descriptor of a neural field acts as a deformation handle for the 3D shape it
represents. Thus, smoothness with respect to this descriptor is paramount for
performing shape-editing operations. In this work, we introduce a novel
regularization designed to encourage smooth latent spaces in neural fields by
penalizing the upper bound on the field's Lipschitz constant. Compared with
prior Lipschitz regularized networks, ours is computationally fast, can be
implemented in four lines of code, and requires minimal hyperparameter tuning
for geometric applications. We demonstrate the effectiveness of our approach on
shape interpolation and extrapolation as well as partial shape reconstruction
from 3D point clouds, showing both qualitative and quantitative improvements
over existing state-of-the-art and non-regularized baselines."
NICGSlowDown: Evaluating the Efficiency Robustness of Neural Image Caption Generation Models,0.0778631,"Neural image caption generation (NICG) models have received massive attention
from the research community due to their excellent performance in visual
understanding. Existing work focuses on improving NICG model accuracy while
efficiency is less explored. However, many real-world applications require
real-time feedback, which highly relies on the efficiency of NICG models.
Recent research observed that the efficiency of NICG models could vary for
different inputs. This observation brings in a new attack surface of NICG
models, i.e., An adversary might be able to slightly change inputs to cause the
NICG models to consume more computational resources. To further understand such
efficiency-oriented threats, we propose a new attack approach, NICGSlowDown, to
evaluate the efficiency robustness of NICG models. Our experimental results
show that NICGSlowDown can generate images with human-unnoticeable
perturbations that will increase the NICG model latency up to 483.86%. We hope
this research could raise the community's concern about the efficiency
robustness of NICG models."
MAESTRO: Matched Speech Text Representations through Modality Matching,0.99355,"We present Maestro, a self-supervised training method to unify
representations learnt from speech and text modalities. Self-supervised
learning from speech signals aims to learn the latent structure inherent in the
signal, while self-supervised learning from text attempts to capture lexical
information. Learning aligned representations from unpaired speech and text
sequences is a challenging task. Previous work either implicitly enforced the
representations learnt from these two modalities to be aligned in the latent
space through multitasking and parameter sharing or explicitly through
conversion of modalities via speech synthesis. While the former suffers from
interference between the two modalities, the latter introduces additional
complexity. In this paper, we propose Maestro, a novel algorithm to learn
unified representations from both these modalities simultaneously that can
transfer to diverse downstream tasks such as Automated Speech Recognition (ASR)
and Speech Translation (ST). Maestro learns unified representations through
sequence alignment, duration prediction and matching embeddings in the learned
space through an aligned masked-language model loss. We establish a new
state-of-the-art (SOTA) on VoxPopuli multilingual ASR with a 8% relative
reduction in Word Error Rate (WER), multidomain SpeechStew ASR (3.7% relative)
and 21 languages to English multilingual ST on CoVoST 2 with an improvement of
2.8 BLEU averaged over 21 languages."
Improving Rare Word Recognition with LM-aware MWER Training,0.326143,"Language models (LMs) significantly improve the recognition accuracy of
end-to-end (E2E) models on words rarely seen during training, when used in
either the shallow fusion or the rescoring setups. In this work, we introduce
LMs in the learning of hybrid autoregressive transducer (HAT) models in the
discriminative training framework, to mitigate the training versus inference
gap regarding the use of LMs. For the shallow fusion setup, we use LMs during
both hypotheses generation and loss computation, and the LM-aware MWER-trained
model achieves 10\% relative improvement over the model trained with standard
MWER on voice search test sets containing rare words. For the rescoring setup,
we learn a small neural module to generate per-token fusion weights in a
data-dependent manner. This model achieves the same rescoring WER as regular
MWER-trained model, but without the need for sweeping fusion weights."
MonoJSG: Joint Semantic and Geometric Cost Volume for Monocular 3D Object Detection,-1.0,"Due to the inherent ill-posed nature of 2D-3D projection, monocular 3D object
detection lacks accurate depth recovery ability. Although the deep neural
network (DNN) enables monocular depth-sensing from high-level learned features,
the pixel-level cues are usually omitted due to the deep convolution mechanism.
To benefit from both the powerful feature representation in DNN and pixel-level
geometric constraints, we reformulate the monocular object depth estimation as
a progressive refinement problem and propose a joint semantic and geometric
cost volume to model the depth error. Specifically, we first leverage neural
networks to learn the object position, dimension, and dense normalized 3D
object coordinates. Based on the object depth, the dense coordinates patch
together with the corresponding object features is reprojected to the image
space to build a cost volume in a joint semantic and geometric error manner.
The final depth is obtained by feeding the cost volume to a refinement network,
where the distribution of semantic and geometric error is regularized by direct
depth supervision. Through effectively mitigating depth error by the refinement
framework, we achieve state-of-the-art results on both the KITTI and Waymo
datasets."
Provable Defense against Backdoor Policies in Reinforcement Learning,0.176077,"We propose a provable defense mechanism against backdoor policies in
reinforcement learning under subspace trigger assumption. A backdoor policy is
a security threat where an adversary publishes a seemingly well-behaved policy
which in fact allows hidden triggers. During deployment, the adversary can
modify observed states in a particular way to trigger unexpected actions and
harm the agent. We assume the agent does not have the resources to re-train a
good policy. Instead, our defense mechanism sanitizes the backdoor policy by
projecting observed states to a 'safe subspace', estimated from a small number
of interactions with a clean (non-triggered) environment. Our sanitized policy
achieves $\epsilon$ approximate optimality in the presence of triggers,
provided the number of clean interactions is $O\left(\frac{D}{(1-\gamma)^4
\epsilon^2}\right)$ where $\gamma$ is the discounting factor and $D$ is the
dimension of state space. Empirically, we show that our sanitization defense
performs well on two Atari game environments."
MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering,0.468576,"Visual language data such as plots, charts, and infographics are ubiquitous
in the human world. However, state-of-the-art vision-language models do not
perform well on these data. We propose MatCha (Math reasoning and Chart
derendering pretraining) to enhance visual language models' capabilities in
jointly modeling charts/plots and language data. Specifically, we propose
several pretraining tasks that cover plot deconstruction and numerical
reasoning which are the key capabilities in visual language modeling.
  We perform the MatCha pretraining starting from Pix2Struct, a recently
proposed image-to-text visual language model. On standard benchmarks such as
PlotQA and ChartQA, the MatCha model outperforms state-of-the-art methods by as
much as nearly 20%. We also examine how well MatCha pretraining transfers to
domains such as screenshots, textbook diagrams, and document figures and
observe overall improvement, verifying the usefulness of MatCha pretraining on
broader visual language tasks."
Improving End-to-End Contextual Speech Recognition with Fine-Grained Contextual Knowledge Selection,0.909282,"Nowadays, most methods in end-to-end contextual speech recognition bias the
recognition process towards contextual knowledge. Since all-neural contextual
biasing methods rely on phrase-level contextual modeling and attention-based
relevance modeling, they may encounter confusion between similar
context-specific phrases, which hurts predictions at the token level. In this
work, we focus on mitigating confusion problems with fine-grained contextual
knowledge selection (FineCoS). In FineCoS, we introduce fine-grained knowledge
to reduce the uncertainty of token predictions. Specifically, we first apply
phrase selection to narrow the range of phrase candidates, and then conduct
token attention on the tokens in the selected phrase candidates. Moreover, we
re-normalize the attention weights of most relevant phrases in inference to
obtain more focused phrase-level contextual representations, and inject
position information to better discriminate phrases or tokens. On LibriSpeech
and an in-house 160,000-hour dataset, we explore the proposed methods based on
a controllable all-neural biasing method, collaborative decoding (ColDec). The
proposed methods provide at most 6.1% relative word error rate reduction on
LibriSpeech and 16.4% relative character error rate reduction on the in-house
dataset over ColDec."
RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust Correspondence Field Estimation and Pose Optimization,0.817124,"6-DoF object pose estimation from a monocular image is challenging, and a
post-refinement procedure is generally needed for high-precision estimation. In
this paper, we propose a framework based on a recurrent neural network (RNN)
for object pose refinement, which is robust to erroneous initial poses and
occlusions. During the recurrent iterations, object pose refinement is
formulated as a non-linear least squares problem based on the estimated
correspondence field (between a rendered image and the observed image). The
problem is then solved by a differentiable Levenberg-Marquardt (LM) algorithm
enabling end-to-end training. The correspondence field estimation and pose
refinement are conducted alternatively in each iteration to recover the object
poses. Furthermore, to improve the robustness to occlusion, we introduce a
consistency-check mechanism based on the learned descriptors of the 3D model
and observed 2D images, which downweights the unreliable correspondences during
pose optimization. Extensive experiments on LINEMOD, Occlusion-LINEMOD, and
YCB-Video datasets validate the effectiveness of our method and demonstrate
state-of-the-art performance."
Holistic Interaction Transformer Network for Action Detection,0.262206,"Actions are about how we interact with the environment, including other
people, objects, and ourselves. In this paper, we propose a novel multi-modal
Holistic Interaction Transformer Network (HIT) that leverages the largely
ignored, but critical hand and pose information essential to most human
actions. The proposed ""HIT"" network is a comprehensive bi-modal framework that
comprises an RGB stream and a pose stream. Each of them separately models
person, object, and hand interactions. Within each sub-network, an
Intra-Modality Aggregation module (IMA) is introduced that selectively merges
individual interaction units. The resulting features from each modality are
then glued using an Attentive Fusion Mechanism (AFM). Finally, we extract cues
from the temporal context to better classify the occurring actions using cached
memory. Our method significantly outperforms previous approaches on the J-HMDB,
UCF101-24, and MultiSports datasets. We also achieve competitive results on
AVA. The code will be available at https://github.com/joslefaure/HIT."
Mixing Up Contrastive Learning: Self-Supervised Representation Learning for Time Series,0.113482,"The lack of labeled data is a key challenge for learning useful
representation from time series data. However, an unsupervised representation
framework that is capable of producing high quality representations could be of
great value. It is key to enabling transfer learning, which is especially
beneficial for medical applications, where there is an abundance of data but
labeling is costly and time consuming. We propose an unsupervised contrastive
learning framework that is motivated from the perspective of label smoothing.
The proposed approach uses a novel contrastive loss that naturally exploits a
data augmentation scheme in which new samples are generated by mixing two data
samples with a mixing component. The task in the proposed framework is to
predict the mixing component, which is utilized as soft targets in the loss
function. Experiments demonstrate the framework's superior performance compared
to other representation learning approaches on both univariate and multivariate
time series and illustrate its benefits for transfer learning for clinical time
series."
On the Relation between Sensitivity and Accuracy in In-context Learning,0.0371692,"In-context learning (ICL) suffers from oversensitivity to the prompt, making
it unreliable in real-world scenarios. We study the sensitivity of ICL with
respect to multiple perturbation types. First, we find that label bias obscures
the true sensitivity, and therefore prior work may have significantly
underestimated ICL sensitivity. Second, we observe a strong negative
correlation between ICL sensitivity and accuracy: predictions sensitive to
perturbations are less likely to be correct. Motivated by these findings, we
propose \textsc{SenSel}, a few-shot selective prediction method that abstains
from sensitive predictions. Experiments on ten classification datasets show
that \textsc{SenSel} consistently outperforms two commonly used
confidence-based and entropy-based baselines on abstention decisions."
Understanding Influence Functions and Datamodels via Harmonic Analysis,0.0422594,"Influence functions estimate effect of individual data points on predictions
of the model on test data and were adapted to deep learning in Koh and Liang
[2017]. They have been used for detecting data poisoning, detecting helpful and
harmful examples, influence of groups of datapoints, etc. Recently, Ilyas et
al. [2022] introduced a linear regression method they termed datamodels to
predict the effect of training points on outputs on test data. The current
paper seeks to provide a better theoretical understanding of such interesting
empirical phenomena. The primary tool is harmonic analysis and the idea of
noise stability. Contributions include: (a) Exact characterization of the
learnt datamodel in terms of Fourier coefficients. (b) An efficient method to
estimate the residual error and quality of the optimum linear datamodel without
having to train the datamodel. (c) New insights into when influences of groups
of datapoints may or may not add up linearly."
Class-Incremental Learning for Action Recognition in Videos,0.278574,"We tackle catastrophic forgetting problem in the context of class-incremental
learning for video recognition, which has not been explored actively despite
the popularity of continual learning. Our framework addresses this challenging
task by introducing time-channel importance maps and exploiting the importance
maps for learning the representations of incoming examples via knowledge
distillation. We also incorporate a regularization scheme in our objective
function, which encourages individual features obtained from different time
steps in a video to be uncorrelated and eventually improves accuracy by
alleviating catastrophic forgetting. We evaluate the proposed approach on
brand-new splits of class-incremental action recognition benchmarks constructed
upon the UCF101, HMDB51, and Something-Something V2 datasets, and demonstrate
the effectiveness of our algorithm in comparison to the existing continual
learning methods that are originally designed for image data."
GMF: General Multimodal Fusion Framework for Correspondence Outlier Rejection,0.112098,"Rejecting correspondence outliers enables to boost the correspondence
quality, which is a critical step in achieving high point cloud registration
accuracy. The current state-of-the-art correspondence outlier rejection methods
only utilize the structure features of the correspondences. However, texture
information is critical to reject the correspondence outliers in our human
vision system. In this paper, we propose General Multimodal Fusion (GMF) to
learn to reject the correspondence outliers by leveraging both the structure
and texture information. Specifically, two cross-attention-based fusion layers
are proposed to fuse the texture information from paired images and structure
information from point correspondences. Moreover, we propose a convolutional
position encoding layer to enhance the difference between Tokens and enable the
encoding feature pay attention to neighbor information. Our position encoding
layer will make the cross-attention operation integrate both local and global
information. Experiments on multiple datasets(3DMatch, 3DLoMatch, KITTI) and
recent state-of-the-art models (3DRegNet, DGR, PointDSC) prove that our GMF
achieves wide generalization ability and consistently improves the point cloud
registration accuracy. Furthermore, several ablation studies demonstrate the
robustness of the proposed GMF on different loss functions, lighting conditions
and noises.The code is available at https://github.com/XiaoshuiHuang/GMF."
Spatiality-guided Transformer for 3D Dense Captioning on Point Clouds,0.209027,"Dense captioning in 3D point clouds is an emerging vision-and-language task
involving object-level 3D scene understanding. Apart from coarse semantic class
prediction and bounding box regression as in traditional 3D object detection,
3D dense captioning aims at producing a further and finer instance-level label
of natural language description on visual appearance and spatial relations for
each scene object of interest. To detect and describe objects in a scene,
following the spirit of neural machine translation, we propose a
transformer-based encoder-decoder architecture, namely SpaCap3D, to transform
objects into descriptions, where we especially investigate the relative
spatiality of objects in 3D scenes and design a spatiality-guided encoder via a
token-to-token spatial relation learning objective and an object-centric
decoder for precise and spatiality-enhanced object caption generation.
Evaluated on two benchmark datasets, ScanRefer and ReferIt3D, our proposed
SpaCap3D outperforms the baseline method Scan2Cap by 4.94% and 9.61% in
CIDEr@0.5IoU, respectively. Our project page with source code and supplementary
files is available at https://SpaCap3D.github.io/ ."
Benchmarking Self-Supervised Learning on Diverse Pathology Datasets,0.269813,"Computational pathology can lead to saving human lives, but models are
annotation hungry and pathology images are notoriously expensive to annotate.
Self-supervised learning has shown to be an effective method for utilizing
unlabeled data, and its application to pathology could greatly benefit its
downstream tasks. Yet, there are no principled studies that compare SSL methods
and discuss how to adapt them for pathology. To address this need, we execute
the largest-scale study of SSL pre-training on pathology image data, to date.
Our study is conducted using 4 representative SSL methods on diverse downstream
tasks. We establish that large-scale domain-aligned pre-training in pathology
consistently out-performs ImageNet pre-training in standard SSL settings such
as linear and fine-tuning evaluations, as well as in low-label regimes.
Moreover, we propose a set of domain-specific techniques that we experimentally
show leads to a performance boost. Lastly, for the first time, we apply SSL to
the challenging task of nuclei instance segmentation and show large and
consistent performance improvements under diverse settings."
On the State of the Art in Authorship Attribution and Authorship Verification,0.277266,"Despite decades of research on authorship attribution (AA) and authorship
verification (AV), inconsistent dataset splits/filtering and mismatched
evaluation methods make it difficult to assess the state of the art. In this
paper, we present a survey of the fields, resolve points of confusion,
introduce Valla that standardizes and benchmarks AA/AV datasets and metrics,
provide a large-scale empirical evaluation, and provide apples-to-apples
comparisons between existing methods. We evaluate eight promising methods on
fifteen datasets (including distribution-shifted challenge sets) and introduce
a new large-scale dataset based on texts archived by Project Gutenberg.
Surprisingly, we find that a traditional Ngram-based model performs best on 5
(of 7) AA tasks, achieving an average macro-accuracy of $76.50\%$ (compared to
$66.71\%$ for a BERT-based model). However, on the two AA datasets with the
greatest number of words per author, as well as on the AV datasets, BERT-based
models perform best. While AV methods are easily applied to AA, they are seldom
included as baselines in AA papers. We show that through the application of
hard-negative mining, AV methods are competitive alternatives to AA methods.
Valla and all experiment code can be found here:
https://github.com/JacobTyo/Valla"
Occluded Person Re-Identification via Relational Adaptive Feature Correction Learning,0.081925,"Occluded person re-identification (Re-ID) in images captured by multiple
cameras is challenging because the target person is occluded by pedestrians or
objects, especially in crowded scenes. In addition to the processes performed
during holistic person Re-ID, occluded person Re-ID involves the removal of
obstacles and the detection of partially visible body parts. Most existing
methods utilize the off-the-shelf pose or parsing networks as pseudo labels,
which are prone to error. To address these issues, we propose a novel Occlusion
Correction Network (OCNet) that corrects features through relational-weight
learning and obtains diverse and representative features without using external
networks. In addition, we present a simple concept of a center feature in order
to provide an intuitive solution to pedestrian occlusion scenarios.
Furthermore, we suggest the idea of Separation Loss (SL) for focusing on
different parts between global features and part features. We conduct extensive
experiments on five challenging benchmark datasets for occluded and holistic
Re-ID tasks to demonstrate that our method achieves superior performance to
state-of-the-art methods especially on occluded scene."
Robust $Q$-learning Algorithm for Markov Decision Processes under Wasserstein Uncertainty,0.170716,"We present a novel $Q$-learning algorithm to solve distributionally robust
Markov decision problems, where the corresponding ambiguity set of transition
probabilities for the underlying Markov decision process is a Wasserstein ball
around a (possibly estimated) reference measure. We prove convergence of the
presented algorithm and provide several examples also using real data to
illustrate both the tractability of our algorithm as well as the benefits of
considering distributional robustness when solving stochastic optimal control
problems, in particular when the estimated distributions turn out to be
misspecified in practice."
A Walk in the Park: Learning to Walk in 20 Minutes With Model-Free Reinforcement Learning,0.0811393,"Deep reinforcement learning is a promising approach to learning policies in
uncontrolled environments that do not require domain knowledge. Unfortunately,
due to sample inefficiency, deep RL applications have primarily focused on
simulated environments. In this work, we demonstrate that the recent
advancements in machine learning algorithms and libraries combined with a
carefully tuned robot controller lead to learning quadruped locomotion in only
20 minutes in the real world. We evaluate our approach on several indoor and
outdoor terrains which are known to be challenging for classical model-based
controllers. We observe the robot to be able to learn walking gait consistently
on all of these terrains. Finally, we evaluate our design decisions in a
simulated environment."
A Proposal for Foley Sound Synthesis Challenge,0.113389,"""Foley"" refers to sound effects that are added to multimedia during
post-production to enhance its perceived acoustic properties, e.g., by
simulating the sounds of footsteps, ambient environmental sounds, or visible
objects on the screen. While foley is traditionally produced by foley artists,
there is increasing interest in automatic or machine-assisted techniques
building upon recent advances in sound synthesis and generative models. To
foster more participation in this growing research area, we propose a challenge
for automatic foley synthesis. Through case studies on successful previous
challenges in audio and machine learning, we set the goals of the proposed
challenge: rigorous, unified, and efficient evaluation of different foley
synthesis systems, with an overarching goal of drawing active participation
from the research community. We outline the details and design considerations
of a foley sound synthesis challenge, including task definition, dataset
requirements, and evaluation criteria."
"Learning Fast, Learning Slow: A General Continual Learning Method based on Complementary Learning System",0.684501,"Humans excel at continually learning from an ever-changing environment
whereas it remains a challenge for deep neural networks which exhibit
catastrophic forgetting. The complementary learning system (CLS) theory
suggests that the interplay between rapid instance-based learning and slow
structured learning in the brain is crucial for accumulating and retaining
knowledge. Here, we propose CLS-ER, a novel dual memory experience replay (ER)
method which maintains short-term and long-term semantic memories that interact
with the episodic memory. Our method employs an effective replay mechanism
whereby new knowledge is acquired while aligning the decision boundaries with
the semantic memories. CLS-ER does not utilize the task boundaries or make any
assumption about the distribution of the data which makes it versatile and
suited for ""general continual learning"". Our approach achieves state-of-the-art
performance on standard benchmarks as well as more realistic general continual
learning settings."
Structural Bias for Aspect Sentiment Triplet Extraction,0.0748588,"Structural bias has recently been exploited for aspect sentiment triplet
extraction (ASTE) and led to improved performance. On the other hand, it is
recognized that explicitly incorporating structural bias would have a negative
impact on efficiency, whereas pretrained language models (PLMs) can already
capture implicit structures. Thus, a natural question arises: Is structural
bias still a necessity in the context of PLMs? To answer the question, we
propose to address the efficiency issues by using an adapter to integrate
structural bias in the PLM and using a cheap-to-compute relative position
structure in place of the syntactic dependency structure. Benchmarking
evaluation is conducted on the SemEval datasets. The results show that our
proposed structural adapter is beneficial to PLMs and achieves state-of-the-art
performance over a range of strong baselines, yet with a light parameter demand
and low latency. Meanwhile, we give rise to the concern that the current
evaluation default with data of small scale is under-confident. Consequently,
we release a large-scale dataset for ASTE. The results on the new dataset hint
that the structural adapter is confidently effective and efficient to a large
scale. Overall, we draw the conclusion that structural bias shall still be a
necessity even with PLMs."
Multimodal Transformer for Nursing Activity Recognition,0.252385,"In an aging population, elderly patient safety is a primary concern at
hospitals and nursing homes, which demands for increased nurse care. By
performing nurse activity recognition, we can not only make sure that all
patients get an equal desired care, but it can also free nurses from manual
documentation of activities they perform, leading to a fair and safe place of
care for the elderly. In this work, we present a multimodal transformer-based
network, which extracts features from skeletal joints and acceleration data,
and fuses them to perform nurse activity recognition. Our method achieves
state-of-the-art performance of 81.8% accuracy on the benchmark dataset
available for nurse activity recognition from the Nurse Care Activity
Recognition Challenge. We perform ablation studies to show that our fusion
model is better than single modality transformer variants (using only
acceleration or skeleton joints data). Our solution also outperforms
state-of-the-art ST-GCN, GRU and other classical hand-crafted-feature-based
classifier solutions by a margin of 1.6%, on the NCRC dataset. Code is
available at \url{https://github.com/Momilijaz96/MMT_for_NCRC}."
Leveraging unsupervised and weakly-supervised data to improve direct speech-to-speech translation,0.704122,"End-to-end speech-to-speech translation (S2ST) without relying on
intermediate text representations is a rapidly emerging frontier of research.
Recent works have demonstrated that the performance of such direct S2ST systems
is approaching that of conventional cascade S2ST when trained on comparable
datasets. However, in practice, the performance of direct S2ST is bounded by
the availability of paired S2ST training data. In this work, we explore
multiple approaches for leveraging much more widely available unsupervised and
weakly-supervised speech and text data to improve the performance of direct
S2ST based on Translatotron 2. With our most effective approaches, the average
translation quality of direct S2ST on 21 language pairs on the CVSS-C corpus is
improved by +13.6 BLEU (or +113% relatively), as compared to the previous
state-of-the-art trained without additional data. The improvements on
low-resource language are even more significant (+398% relatively on average).
Our comparative studies suggest future research directions for S2ST and speech
representation learning."
Exemplar Free Class Agnostic Counting,0.190636,"We tackle the task of Class Agnostic Counting, which aims to count objects in
a novel object category at test time without any access to labeled training
data for that category. All previous class agnostic counting methods cannot
work in a fully automated setting, and require computationally expensive test
time adaptation. To address these challenges, we propose a visual counter which
operates in a fully automated setting and does not require any test time
adaptation. Our proposed approach first identifies exemplars from repeating
objects in an image, and then counts the repeating objects. We propose a novel
region proposal network for identifying the exemplars. After identifying the
exemplars, we obtain the corresponding count by using a density estimation
based Visual Counter. We evaluate our proposed approach on FSC-147 dataset, and
show that it achieves superior performance compared to the existing approaches."
Transfer Language Selection for Zero-Shot Cross-Lingual Abusive Language Detection,0.240239,"We study the selection of transfer languages for automatic abusive language
detection. Instead of preparing a dataset for every language, we demonstrate
the effectiveness of cross-lingual transfer learning for zero-shot abusive
language detection. This way we can use existing data from higher-resource
languages to build better detection systems for low-resource languages. Our
datasets are from seven different languages from three language families. We
measure the distance between the languages using several language similarity
measures, especially by quantifying the World Atlas of Language Structures. We
show that there is a correlation between linguistic similarity and classifier
performance. This discovery allows us to choose an optimal transfer language
for zero shot abusive language detection."
Optimizing Data Collection for Machine Learning,0.0909035,"Modern deep learning systems require huge data sets to achieve impressive
performance, but there is little guidance on how much or what kind of data to
collect. Over-collecting data incurs unnecessary present costs, while
under-collecting may incur future costs and delay workflows. We propose a new
paradigm for modeling the data collection workflow as a formal optimal data
collection problem that allows designers to specify performance targets,
collection costs, a time horizon, and penalties for failing to meet the
targets. Additionally, this formulation generalizes to tasks requiring multiple
data sources, such as labeled and unlabeled data used in semi-supervised
learning. To solve our problem, we develop Learn-Optimize-Collect (LOC), which
minimizes expected future collection costs. Finally, we numerically compare our
framework to the conventional baseline of estimating data requirements by
extrapolating from neural scaling laws. We significantly reduce the risks of
failing to meet desired performance targets on several classification,
segmentation, and detection tasks, while maintaining low total collection
costs."
BITE: Textual Backdoor Attacks with Iterative Trigger Injection,0.16467,"Backdoor attacks have become an emerging threat to NLP systems. By providing
poisoned training data, the adversary can embed a ""backdoor"" into the victim
model, which allows input instances satisfying certain textual patterns (e.g.,
containing a keyword) to be predicted as a target label of the adversary's
choice. In this paper, we demonstrate that it is possible to design a backdoor
attack that is both stealthy (i.e., hard to notice) and effective (i.e., has a
high attack success rate). We propose BITE, a backdoor attack that poisons the
training data to establish strong correlations between the target label and a
set of ""trigger words"". These trigger words are iteratively identified and
injected into the target-label instances through natural word-level
perturbations. The poisoned training data instruct the victim model to predict
the target label on inputs containing trigger words, forming the backdoor.
Experiments on four text classification datasets show that our proposed attack
is significantly more effective than baseline methods while maintaining decent
stealthiness, raising alarm on the usage of untrusted training data. We further
propose a defense method named DeBITE based on potential trigger word removal,
which outperforms existing methods in defending against BITE and generalizes
well to handling other backdoor attacks."
Transformer Quality in Linear Time,0.233874,"We revisit the design choices in Transformers, and propose methods to address
their weaknesses in handling long sequences. First, we propose a simple layer
named gated attention unit, which allows the use of a weaker single-head
attention with minimal quality loss. We then propose a linear approximation
method complementary to this new layer, which is accelerator-friendly and
highly competitive in quality. The resulting model, named FLASH, matches the
perplexity of improved Transformers over both short (512) and long (8K) context
lengths, achieving training speedups of up to 4.9$\times$ on Wiki-40B and
12.1$\times$ on PG-19 for auto-regressive language modeling, and 4.8$\times$ on
C4 for masked language modeling."
Machine Translation between Spoken Languages and Signed Languages Represented in SignWriting,0.100494,"This paper presents work on novel machine translation (MT) systems between
spoken and signed languages, where signed languages are represented in
SignWriting, a sign language writing system. Our work seeks to address the lack
of out-of-the-box support for signed languages in current MT systems and is
based on the SignBank dataset, which contains pairs of spoken language text and
SignWriting content. We introduce novel methods to parse, factorize, decode,
and evaluate SignWriting, leveraging ideas from neural factored MT. In a
bilingual setup--translating from American Sign Language to (American)
English--our method achieves over 30 BLEU, while in two multilingual
setups--translating in both directions between spoken languages and signed
languages--we achieve over 20 BLEU. We find that common MT techniques used to
improve spoken language translation similarly affect the performance of sign
language translation. These findings validate our use of an intermediate text
representation for signed languages to include them in natural language
processing research."
Soft Diffusion: Score Matching for General Corruptions,0.392099,"We define a broader family of corruption processes that generalizes
previously known diffusion models. To reverse these general diffusions, we
propose a new objective called Soft Score Matching that provably learns the
score function for any linear corruption process and yields state of the art
results for CelebA. Soft Score Matching incorporates the degradation process in
the network. Our new loss trains the model to predict a clean image,
\textit{that after corruption}, matches the diffused observation. We show that
our objective learns the gradient of the likelihood under suitable regularity
conditions for a family of corruption processes. We further develop a
principled way to select the corruption levels for general diffusion processes
and a novel sampling method that we call Momentum Sampler. We show
experimentally that our framework works for general linear corruption
processes, such as Gaussian blur and masking. We achieve state-of-the-art FID
score $1.85$ on CelebA-64, outperforming all previous linear diffusion models.
We also show significant computational benefits compared to vanilla denoising
diffusion."
cosFormer: Rethinking Softmax in Attention,0.998054,"Transformer has shown great successes in natural language processing,
computer vision, and audio processing. As one of its core components, the
softmax attention helps to capture long-range dependencies yet prohibits its
scale-up due to the quadratic space and time complexity to the sequence length.
Kernel methods are often adopted to reduce the complexity by approximating the
softmax operator. Nevertheless, due to the approximation errors, their
performances vary in different tasks/corpus and suffer crucial performance
drops when compared with the vanilla softmax attention. In this paper, we
propose a linear transformer called cosFormer that can achieve comparable or
better accuracy to the vanilla transformer in both casual and cross attentions.
cosFormer is based on two key properties of softmax attention: i).
non-negativeness of the attention matrix; ii). a non-linear re-weighting scheme
that can concentrate the distribution of the attention matrix. As its linear
substitute, cosFormer fulfills these properties with a linear operator and a
cosine-based distance re-weighting mechanism. Extensive experiments on language
modeling and text understanding tasks demonstrate the effectiveness of our
method. We further examine our method on long sequences and achieve
state-of-the-art performance on the Long-Range Arena benchmark. The source code
is available at https://github.com/OpenNLPLab/cosFormer."
Exploring Target Representations for Masked Autoencoders,0.166271,"Masked autoencoders have become popular training paradigms for
self-supervised visual representation learning. These models randomly mask a
portion of the input and reconstruct the masked portion according to the target
representations. In this paper, we first show that a careful choice of the
target representation is unnecessary for learning good representations, since
different targets tend to derive similarly behaved models. Driven by this
observation, we propose a multi-stage masked distillation pipeline and use a
randomly initialized model as the teacher, enabling us to effectively train
high-capacity models without any efforts to carefully design target
representations. Interestingly, we further explore using teachers of larger
capacity, obtaining distilled students with remarkable transferring ability. On
different tasks of classification, transfer learning, object detection, and
semantic segmentation, the proposed method to perform masked knowledge
distillation with bootstrapped teachers (dBOT) outperforms previous
self-supervised methods by nontrivial margins. We hope our findings, as well as
the proposed method, could motivate people to rethink the roles of target
representations in pre-training masked autoencoders.The code and pre-trained
models are publicly available at https://github.com/liuxingbin/dbot."
Intelligent problem-solving as integrated hierarchical reinforcement learning,0.348196,"According to cognitive psychology and related disciplines, the development of
complex problem-solving behaviour in biological agents depends on hierarchical
cognitive mechanisms. Hierarchical reinforcement learning is a promising
computational approach that may eventually yield comparable problem-solving
behaviour in artificial agents and robots. However, to date the problem-solving
abilities of many human and non-human animals are clearly superior to those of
artificial systems. Here, we propose steps to integrate biologically inspired
hierarchical mechanisms to enable advanced problem-solving skills in artificial
agents. Therefore, we first review the literature in cognitive psychology to
highlight the importance of compositional abstraction and predictive
processing. Then we relate the gained insights with contemporary hierarchical
reinforcement learning methods. Interestingly, our results suggest that all
identified cognitive mechanisms have been implemented individually in isolated
computational architectures, raising the question of why there exists no single
unifying architecture that integrates them. As our final contribution, we
address this question by providing an integrative perspective on the
computational challenges to develop such a unifying architecture. We expect our
results to guide the development of more sophisticated cognitively inspired
hierarchical machine learning architectures."
Video Anomaly Detection by Solving Decoupled Spatio-Temporal Jigsaw Puzzles,0.791707,"Video Anomaly Detection (VAD) is an important topic in computer vision.
Motivated by the recent advances in self-supervised learning, this paper
addresses VAD by solving an intuitive yet challenging pretext task, i.e.,
spatio-temporal jigsaw puzzles, which is cast as a multi-label fine-grained
classification problem. Our method exhibits several advantages over existing
works: 1) the spatio-temporal jigsaw puzzles are decoupled in terms of spatial
and temporal dimensions, responsible for capturing highly discriminative
appearance and motion features, respectively; 2) full permutations are used to
provide abundant jigsaw puzzles covering various difficulty levels, allowing
the network to distinguish subtle spatio-temporal differences between normal
and abnormal events; and 3) the pretext task is tackled in an end-to-end manner
without relying on any pre-trained models. Our method outperforms
state-of-the-art counterparts on three public benchmarks. Especially on
ShanghaiTech Campus, the result is superior to reconstruction and
prediction-based methods by a large margin."
The Role of ImageNet Classes in Fréchet Inception Distance,0.964328,"Fr\'echet Inception Distance (FID) is the primary metric for ranking models
in data-driven generative modeling. While remarkably successful, the metric is
known to sometimes disagree with human judgement. We investigate a root cause
of these discrepancies, and visualize what FID ""looks at"" in generated images.
We show that the feature space that FID is (typically) computed in is so close
to the ImageNet classifications that aligning the histograms of Top-$N$
classifications between sets of generated and real images can reduce FID
substantially -- without actually improving the quality of results. Thus, we
conclude that FID is prone to intentional or accidental distortions. As a
practical example of an accidental distortion, we discuss a case where an
ImageNet pre-trained FastGAN achieves a FID comparable to StyleGAN2, while
being worse in terms of human evaluation."
BiSyn-GAT+: Bi-Syntax Aware Graph Attention Network for Aspect-based Sentiment Analysis,0.527198,"Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis
task that aims to align aspects and corresponding sentiments for
aspect-specific sentiment polarity inference. It is challenging because a
sentence may contain multiple aspects or complicated (e.g., conditional,
coordinating, or adversative) relations. Recently, exploiting dependency syntax
information with graph neural networks has been the most popular trend. Despite
its success, methods that heavily rely on the dependency tree pose challenges
in accurately modeling the alignment of the aspects and their words indicative
of sentiment, since the dependency tree may provide noisy signals of unrelated
associations (e.g., the ""conj"" relation between ""great"" and ""dreadful"" in
Figure 2). In this paper, to alleviate this problem, we propose a Bi-Syntax
aware Graph Attention Network (BiSyn-GAT+). Specifically, BiSyn-GAT+ fully
exploits the syntax information (e.g., phrase segmentation and hierarchical
structure) of the constituent tree of a sentence to model the sentiment-aware
context of every single aspect (called intra-context) and the sentiment
relations across aspects (called inter-context) for learning. Experiments on
four benchmark datasets demonstrate that BiSyn-GAT+ outperforms the
state-of-the-art methods consistently."
mSLAM: Massively multilingual joint pre-training for speech and text,0.955329,"We present mSLAM, a multilingual Speech and LAnguage Model that learns
cross-lingual cross-modal representations of speech and text by pre-training
jointly on large amounts of unlabeled speech and text in multiple languages.
mSLAM combines w2v-BERT pre-training on speech with SpanBERT pre-training on
character-level text, along with Connectionist Temporal Classification (CTC)
losses on paired speech and transcript data, to learn a single model capable of
learning from and representing both speech and text signals in a shared
representation space. We evaluate mSLAM on several downstream speech
understanding tasks and find that joint pre-training with text improves quality
on speech translation, speech intent classification and speech language-ID
while being competitive on multilingual ASR, when compared against speech-only
pre-training. Our speech translation model demonstrates zero-shot text
translation without seeing any text translation data, providing evidence for
cross-modal alignment of representations. mSLAM also benefits from multi-modal
fine-tuning, further improving the quality of speech translation by directly
leveraging text translation data during the fine-tuning process. Our empirical
analysis highlights several opportunities and challenges arising from
large-scale multimodal pre-training, suggesting directions for future research."
Visual Programming: Compositional visual reasoning without training,0.999999,"We present VISPROG, a neuro-symbolic approach to solving complex and
compositional visual tasks given natural language instructions. VISPROG avoids
the need for any task-specific training. Instead, it uses the in-context
learning ability of large language models to generate python-like modular
programs, which are then executed to get both the solution and a comprehensive
and interpretable rationale. Each line of the generated program may invoke one
of several off-the-shelf computer vision models, image processing routines, or
python functions to produce intermediate outputs that may be consumed by
subsequent parts of the program. We demonstrate the flexibility of VISPROG on 4
diverse tasks - compositional visual question answering, zero-shot reasoning on
image pairs, factual knowledge object tagging, and language-guided image
editing. We believe neuro-symbolic approaches like VISPROG are an exciting
avenue to easily and effectively expand the scope of AI systems to serve the
long tail of complex tasks that people may wish to perform."
Offline RL Policies Should be Trained to be Adaptive,0.395708,"Offline RL algorithms must account for the fact that the dataset they are
provided may leave many facets of the environment unknown. The most common way
to approach this challenge is to employ pessimistic or conservative methods,
which avoid behaviors that are too dissimilar from those in the training
dataset. However, relying exclusively on conservatism has drawbacks:
performance is sensitive to the exact degree of conservatism, and conservative
objectives can recover highly suboptimal policies. In this work, we propose
that offline RL methods should instead be adaptive in the presence of
uncertainty. We show that acting optimally in offline RL in a Bayesian sense
involves solving an implicit POMDP. As a result, optimal policies for offline
RL must be adaptive, depending not just on the current state but rather all the
transitions seen so far during evaluation.We present a model-free algorithm for
approximating this optimal adaptive policy, and demonstrate the efficacy of
learning such adaptive policies in offline RL benchmarks."
Revisiting the Gold Standard: Grounding Summarization Evaluation with Robust Human Evaluation,0.221344,"Human evaluation is the foundation upon which the evaluation of both
summarization systems and automatic metrics rests. However, existing human
evaluation studies for summarization either exhibit a low inter-annotator
agreement or have insufficient scale, and an in-depth analysis of human
evaluation is lacking. Therefore, we address the shortcomings of existing
summarization evaluation along the following axes: (1) We propose a modified
summarization salience protocol, Atomic Content Units (ACUs), which is based on
fine-grained semantic units and allows for a high inter-annotator agreement.
(2) We curate the Robust Summarization Evaluation (RoSE) benchmark, a large
human evaluation dataset consisting of 22,000 summary-level annotations over 28
top-performing systems on three datasets. (3) We conduct a comparative study of
four human evaluation protocols, underscoring potential confounding factors in
evaluation setups. (4) We evaluate 50 automatic metrics and their variants
using the collected human annotations across evaluation protocols and
demonstrate how our benchmark leads to more statistically stable and
significant results. The metrics we benchmarked include recent methods based on
large language models (LLMs), GPTScore and G-Eval. Furthermore, our findings
have important implications for evaluating LLMs, as we show that LLMs adjusted
by human feedback (e.g., GPT-3.5) may overfit unconstrained human evaluation,
which is affected by the annotators' prior, input-agnostic preferences, calling
for more robust, targeted evaluation methods."
TweetNLP: Cutting-Edge Natural Language Processing for Social Media,0.267422,"In this paper we present TweetNLP, an integrated platform for Natural
Language Processing (NLP) in social media. TweetNLP supports a diverse set of
NLP tasks, including generic focus areas such as sentiment analysis and named
entity recognition, as well as social media-specific tasks such as emoji
prediction and offensive language identification. Task-specific systems are
powered by reasonably-sized Transformer-based language models specialized on
social media text (in particular, Twitter) which can be run without the need
for dedicated hardware or cloud services. The main contributions of TweetNLP
are: (1) an integrated Python library for a modern toolkit supporting social
media analysis using our various task-specific models adapted to the social
domain; (2) an interactive online demo for codeless experimentation using our
models; and (3) a tutorial covering a wide variety of typical social media
applications."
Causal Intervention for Subject-Deconfounded Facial Action Unit Recognition,0.180669,"Subject-invariant facial action unit (AU) recognition remains challenging for
the reason that the data distribution varies among subjects. In this paper, we
propose a causal inference framework for subject-invariant facial action unit
recognition. To illustrate the causal effect existing in AU recognition task,
we formulate the causalities among facial images, subjects, latent AU semantic
relations, and estimated AU occurrence probabilities via a structural causal
model. By constructing such a causal diagram, we clarify the causal effect
among variables and propose a plug-in causal intervention module, CIS, to
deconfound the confounder \emph{Subject} in the causal diagram. Extensive
experiments conducted on two commonly used AU benchmark datasets, BP4D and
DISFA, show the effectiveness of our CIS, and the model with CIS inserted,
CISNet, has achieved state-of-the-art performance."
Cross-modal Contrastive Learning for Speech Translation,0.669684,"How can we learn unified representations for spoken utterances and their
written text? Learning similar representations for semantically similar speech
and text is important for speech translation. To this end, we propose ConST, a
cross-modal contrastive learning method for end-to-end speech-to-text
translation. We evaluate ConST and a variety of previous baselines on a popular
benchmark MuST-C. Experiments show that the proposed ConST consistently
outperforms the previous methods on, and achieves an average BLEU of 29.4. The
analysis further verifies that ConST indeed closes the representation gap of
different modalities -- its learned representation improves the accuracy of
cross-modal speech-text retrieval from 4% to 88%. Code and models are available
at https://github.com/ReneeYe/ConST."
RBP-Pose: Residual Bounding Box Projection for Category-Level Pose Estimation,0.297934,"Category-level object pose estimation aims to predict the 6D pose as well as
the 3D metric size of arbitrary objects from a known set of categories. Recent
methods harness shape prior adaptation to map the observed point cloud into the
canonical space and apply Umeyama algorithm to recover the pose and size.
However, their shape prior integration strategy boosts pose estimation
indirectly, which leads to insufficient pose-sensitive feature extraction and
slow inference speed. To tackle this problem, in this paper, we propose a novel
geometry-guided Residual Object Bounding Box Projection network RBP-Pose that
jointly predicts object pose and residual vectors describing the displacements
from the shape-prior-indicated object surface projections on the bounding box
towards the real surface projections. Such definition of residual vectors is
inherently zero-mean and relatively small, and explicitly encapsulates spatial
cues of the 3D object for robust and accurate pose regression. We enforce
geometry-aware consistency terms to align the predicted pose and residual
vectors to further boost performance."
MagicPony: Learning Articulated 3D Animals in the Wild,0.406881,"We consider the problem of predicting the 3D shape, articulation, viewpoint,
texture, and lighting of an articulated animal like a horse given a single test
image as input. We present a new method, dubbed MagicPony, that learns this
predictor purely from in-the-wild single-view images of the object category,
with minimal assumptions about the topology of deformation. At its core is an
implicit-explicit representation of articulated shape and appearance, combining
the strengths of neural fields and meshes. In order to help the model
understand an object's shape and pose, we distil the knowledge captured by an
off-the-shelf self-supervised vision transformer and fuse it into the 3D model.
To overcome local optima in viewpoint estimation, we further introduce a new
viewpoint sampling scheme that comes at no additional training cost. MagicPony
outperforms prior work on this challenging task and demonstrates excellent
generalisation in reconstructing art, despite the fact that it is only trained
on real images."
Robust Preference Learning for Storytelling via Contrastive Reinforcement Learning,0.0929713,"Controlled automated story generation seeks to generate natural language
stories satisfying constraints from natural language critiques or preferences.
Existing methods to control for story preference utilize prompt engineering
which is labor intensive and often inconsistent. They may also use
logit-manipulation methods which require annotated datasets to exist for the
desired attributes. To address these issues, we first train a contrastive
bi-encoder model to align stories with corresponding human critiques, named
CARP, building a general purpose preference model. This is subsequently used as
a reward function to fine-tune a generative language model via reinforcement
learning. However, simply fine-tuning a generative language model with a
contrastive reward model does not always reliably result in a story generation
system capable of generating stories that meet user preferences. To increase
story generation robustness we further fine-tune the contrastive reward model
using a prompt-learning technique. A human participant study is then conducted
comparing generations from our full system, ablations, and two baselines. We
show that the full fine-tuning pipeline results in a story generator preferred
over a LLM 20x as large as well as logit-based methods. This motivates the use
of contrastive learning for general purpose human preference modeling."
C-VTON: Context-Driven Image-Based Virtual Try-On Network,0.468031,"Image-based virtual try-on techniques have shown great promise for enhancing
the user-experience and improving customer satisfaction on fashion-oriented
e-commerce platforms. However, existing techniques are currently still limited
in the quality of the try-on results they are able to produce from input images
of diverse characteristics. In this work, we propose a Context-Driven Virtual
Try-On Network (C-VTON) that addresses these limitations and convincingly
transfers selected clothing items to the target subjects even under challenging
pose configurations and in the presence of self-occlusions. At the core of the
C-VTON pipeline are: (i) a geometric matching procedure that efficiently aligns
the target clothing with the pose of the person in the input images, and (ii) a
powerful image generator that utilizes various types of contextual information
when synthesizing the final try-on result. C-VTON is evaluated in rigorous
experiments on the VITON and MPV datasets and in comparison to state-of-the-art
techniques from the literature. Experimental results show that the proposed
approach is able to produce photo-realistic and visually convincing results and
significantly improves on the existing state-of-the-art."
Understanding Iterative Revision from Human-Written Text,0.267414,"Writing is, by nature, a strategic, adaptive, and more importantly, an
iterative process. A crucial part of writing is editing and revising the text.
Previous works on text revision have focused on defining edit intention
taxonomies within a single domain or developing computational models with a
single level of edit granularity, such as sentence-level edits, which differ
from human's revision cycles. This work describes IteraTeR: the first
large-scale, multi-domain, edit-intention annotated corpus of iteratively
revised text. In particular, IteraTeR is collected based on a new framework to
comprehensively model the iterative text revisions that generalize to various
domains of formal writing, edit intentions, revision depths, and granularities.
When we incorporate our annotated edit intentions, both generative and
edit-based text revision models significantly improve automatic evaluations.
Through our work, we better understand the text revision process, making vital
connections between edit intentions and writing quality, enabling the creation
of diverse corpora to support computational modeling of iterative text
revisions."
Models and Datasets for Cross-Lingual Summarisation,0.388606,"We present a cross-lingual summarisation corpus with long documents in a
source language associated with multi-sentence summaries in a target language.
The corpus covers twelve language pairs and directions for four European
languages, namely Czech, English, French and German, and the methodology for
its creation can be applied to several other languages. We derive cross-lingual
document-summary instances from Wikipedia by combining lead paragraphs and
articles' bodies from language aligned Wikipedia titles. We analyse the
proposed cross-lingual summarisation task with automatic metrics and validate
it with a human study. To illustrate the utility of our dataset we report
experiments with multi-lingual pre-trained models in supervised, zero- and
few-shot, and out-of-domain scenarios."
From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer,0.671794,"Knowledge graph completion aims to address the problem of extending a KG with
missing triples. In this paper, we provide an approach GenKGC, which converts
knowledge graph completion to sequence-to-sequence generation task with the
pre-trained language model. We further introduce relation-guided demonstration
and entity-aware hierarchical decoding for better representation learning and
fast inference. Experimental results on three datasets show that our approach
can obtain better or comparable performance than baselines and achieve faster
inference speed compared with previous methods with pre-trained language
models. We also release a new large-scale Chinese knowledge graph dataset
AliopenKG500 for research purpose. Code and datasets are available in
https://github.com/zjunlp/PromptKG/tree/main/GenKGC."
OSFormer: One-Stage Camouflaged Instance Segmentation with Transformers,0.160982,"We present OSFormer, the first one-stage transformer framework for
camouflaged instance segmentation (CIS). OSFormer is based on two key designs.
First, we design a location-sensing transformer (LST) to obtain the location
label and instance-aware parameters by introducing the location-guided queries
and the blend-convolution feedforward network. Second, we develop a
coarse-to-fine fusion (CFF) to merge diverse context information from the LST
encoder and CNN backbone. Coupling these two components enables OSFormer to
efficiently blend local features and long-range context dependencies for
predicting camouflaged instances. Compared with two-stage frameworks, our
OSFormer reaches 41% AP and achieves good convergence efficiency without
requiring enormous training data, i.e., only 3,040 samples under 60 epochs.
Code link: https://github.com/PJLallen/OSFormer."
TensorIR: An Abstraction for Automatic Tensorized Program Optimization,0.192128,"Deploying deep learning models on various devices has become an important
topic. The wave of hardware specialization brings a diverse set of acceleration
primitives for multi-dimensional tensor computations. These new acceleration
primitives, along with the emerging machine learning models, bring tremendous
engineering challenges. In this paper, we present TensorIR, a compiler
abstraction for optimizing programs with these tensor computation primitives.
TensorIR generalizes the loop nest representation used in existing machine
learning compilers to bring tensor computation as the first-class citizen.
Finally, we build an end-to-end framework on top of our abstraction to
automatically optimize deep learning models for given tensor computation
primitives. Experimental results show that TensorIR compilation automatically
uses the tensor computation primitives for given hardware backends and delivers
performance that is competitive to state-of-art hand-optimized systems across
platforms."
Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality,0.974503,"We present a novel task and dataset for evaluating the ability of vision and
language models to conduct visio-linguistic compositional reasoning, which we
call Winoground. Given two images and two captions, the goal is to match them
correctly - but crucially, both captions contain a completely identical set of
words, only in a different order. The dataset was carefully hand-curated by
expert annotators and is labeled with a rich set of fine-grained tags to assist
in analyzing model performance. We probe a diverse range of state-of-the-art
vision and language models and find that, surprisingly, none of them do much
better than chance. Evidently, these models are not as skilled at
visio-linguistic compositional reasoning as we might have hoped. We perform an
extensive analysis to obtain insights into how future work might try to
mitigate these models' shortcomings. We aim for Winoground to serve as a useful
evaluation set for advancing the state of the art and driving further progress
in the field. The dataset is available at
https://huggingface.co/datasets/facebook/winoground."
VLSP 2021 - ViMRC Challenge: Vietnamese Machine Reading Comprehension,0.183473,"One of the emerging research trends in natural language understanding is
machine reading comprehension (MRC) which is the task to find answers to human
questions based on textual data. Existing Vietnamese datasets for MRC research
concentrate solely on answerable questions. However, in reality, questions can
be unanswerable for which the correct answer is not stated in the given textual
data. To address the weakness, we provide the research community with a
benchmark dataset named UIT-ViQuAD 2.0 for evaluating the MRC task and question
answering systems for the Vietnamese language. We use UIT-ViQuAD 2.0 as a
benchmark dataset for the challenge on Vietnamese MRC at the Eighth Workshop on
Vietnamese Language and Speech Processing (VLSP 2021). This task attracted 77
participant teams from 34 universities and other organizations. In this
article, we present details of the organization of the challenge, an overview
of the methods employed by shared-task participants, and the results. The
highest performances are 77.24% in F1-score and 67.43% in Exact Match on the
private test set. The Vietnamese MRC systems proposed by the top 3 teams use
XLM-RoBERTa, a powerful pre-trained language model based on the transformer
architecture. The UIT-ViQuAD 2.0 dataset motivates researchers to further
explore the Vietnamese machine reading comprehension task and related tasks
such as question answering, question generation, and natural language
inference."
"A Benchmark for Automatic Medical Consultation System: Frameworks, Tasks and Datasets",0.542205,"In recent years, interest has arisen in using machine learning to improve the
efficiency of automatic medical consultation and enhance patient experience. In
this article, we propose two frameworks to support automatic medical
consultation, namely doctor-patient dialogue understanding and task-oriented
interaction. We create a new large medical dialogue dataset with multi-level
finegrained annotations and establish five independent tasks, including named
entity recognition, dialogue act classification, symptom label inference,
medical report generation and diagnosis-oriented dialogue policy. We report a
set of benchmark results for each task, which shows the usability of the
dataset and sets a baseline for future studies. Both code and data is available
from https://github.com/lemuria-wchen/imcs21."
Few-shot Named Entity Recognition with Self-describing Networks,0.149295,"Few-shot NER needs to effectively capture information from limited instances
and transfer useful knowledge from external resources. In this paper, we
propose a self-describing mechanism for few-shot NER, which can effectively
leverage illustrative instances and precisely transfer knowledge from external
resources by describing both entity types and mentions using a universal
concept set. Specifically, we design Self-describing Networks (SDNet), a
Seq2Seq generation model which can universally describe mentions using
concepts, automatically map novel entity types to concepts, and adaptively
recognize entities on-demand. We pre-train SDNet with large-scale corpus, and
conduct experiments on 8 benchmarks from different domains. Experiments show
that SDNet achieves competitive performances on all benchmarks and achieves the
new state-of-the-art on 6 benchmarks, which demonstrates its effectiveness and
robustness."
QuestSim: Human Motion Tracking from Sparse Sensors with Simulated Avatars,0.401363,"Real-time tracking of human body motion is crucial for interactive and
immersive experiences in AR/VR. However, very limited sensor data about the
body is available from standalone wearable devices such as HMDs (Head Mounted
Devices) or AR glasses. In this work, we present a reinforcement learning
framework that takes in sparse signals from an HMD and two controllers, and
simulates plausible and physically valid full body motions. Using high quality
full body motion as dense supervision during training, a simple policy network
can learn to output appropriate torques for the character to balance, walk, and
jog, while closely following the input signals. Our results demonstrate
surprisingly similar leg motions to ground truth without any observations of
the lower body, even when the input is only the 6D transformations of the HMD.
We also show that a single policy can be robust to diverse locomotion styles,
different body sizes, and novel environments."
CommonsenseQA 2.0: Exposing the Limits of AI through Gamification,0.764101,"Constructing benchmarks that test the abilities of modern natural language
understanding models is difficult - pre-trained language models exploit
artifacts in benchmarks to achieve human parity, but still fail on adversarial
examples and make errors that demonstrate a lack of common sense. In this work,
we propose gamification as a framework for data construction. The goal of
players in the game is to compose questions that mislead a rival AI while using
specific phrases for extra points. The game environment leads to enhanced user
engagement and simultaneously gives the game designer control over the
collected data, allowing us to collect high-quality data at scale. Using our
method we create CommonsenseQA 2.0, which includes 14,343 yes/no questions, and
demonstrate its difficulty for models that are orders-of-magnitude larger than
the AI used in the game itself. Our best baseline, the T5-based Unicorn with
11B parameters achieves an accuracy of 70.2%, substantially higher than GPT-3
(52.9%) in a few-shot inference setup. Both score well below human performance
which is at 94.1%."
ERNIE-Search: Bridging Cross-Encoder with Dual-Encoder via Self On-the-fly Distillation for Dense Passage Retrieval,0.589126,"Neural retrievers based on pre-trained language models (PLMs), such as
dual-encoders, have achieved promising performance on the task of open-domain
question answering (QA). Their effectiveness can further reach new
state-of-the-arts by incorporating cross-architecture knowledge distillation.
However, most of the existing studies just directly apply conventional
distillation methods. They fail to consider the particular situation where the
teacher and student have different structures. In this paper, we propose a
novel distillation method that significantly advances cross-architecture
distillation for dual-encoders. Our method 1) introduces a self on-the-fly
distillation method that can effectively distill late interaction (i.e.,
ColBERT) to vanilla dual-encoder, and 2) incorporates a cascade distillation
process to further improve the performance with a cross-encoder teacher.
Extensive experiments are conducted to validate that our proposed solution
outperforms strong baselines and establish a new state-of-the-art on
open-domain QA benchmarks."
Least-to-Most Prompting Enables Complex Reasoning in Large Language Models,1.0,"Chain-of-thought prompting has demonstrated remarkable performance on various
natural language reasoning tasks. However, it tends to perform poorly on tasks
which requires solving problems harder than the exemplars shown in the prompts.
To overcome this challenge of easy-to-hard generalization, we propose a novel
prompting strategy, least-to-most prompting. The key idea in this strategy is
to break down a complex problem into a series of simpler subproblems and then
solve them in sequence. Solving each subproblem is facilitated by the answers
to previously solved subproblems. Our experimental results on tasks related to
symbolic manipulation, compositional generalization, and math reasoning reveal
that least-to-most prompting is capable of generalizing to more difficult
problems than those seen in the prompts. A notable finding is that when the
GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve
the compositional generalization benchmark SCAN in any split (including length
split) with an accuracy of at least 99% using just 14 exemplars, compared to
only 16% accuracy with chain-of-thought prompting. This is particularly
noteworthy because neural-symbolic models in the literature that specialize in
solving SCAN are trained on the entire training set containing over 15,000
examples. We have included prompts for all the tasks in the Appendix."
Towards a Cleaner Document-Oriented Multilingual Crawled Corpus,0.69908,"The need for raw large raw corpora has dramatically increased in recent years
with the introduction of transfer learning and semi-supervised learning methods
to Natural Language Processing. And while there have been some recent attempts
to manually curate the amount of data necessary to train large language models,
the main way to obtain this data is still through automatic web crawling. In
this paper we take the existing multilingual web corpus OSCAR and its pipeline
Ungoliant that extracts and classifies data from Common Crawl at the line
level, and propose a set of improvements and automatic annotations in order to
produce a new document-oriented version of OSCAR that could prove more suitable
to pre-train large generative language models as well as hopefully other
applications in Natural Language Processing and Digital Humanities."
CM3: A Causal Masked Multimodal Model of the Internet,0.988314,"We introduce CM3, a family of causally masked generative models trained over
a large corpus of structured multi-modal documents that can contain both text
and image tokens. Our new causally masked approach generates tokens left to
right while also masking out a small number of long token spans that are
generated at the end of the string, instead of their original positions. The
casual masking object provides a type of hybrid of the more common causal and
masked language models, by enabling full generative modeling while also
providing bidirectional context when generating the masked spans. We train
causally masked language-image models on large-scale web and Wikipedia
articles, where each document contains all of the text, hypertext markup,
hyperlinks, and image tokens (from a VQVAE-GAN), provided in the order they
appear in the original HTML source (before masking). The resulting CM3 models
can generate rich structured, multi-modal outputs while conditioning on
arbitrary masked document contexts, and thereby implicitly learn a wide range
of text, image, and cross modal tasks. They can be prompted to recover, in a
zero-shot fashion, the functionality of models such as DALL-E, GENRE, and HTLM.
We set the new state-of-the-art in zero-shot summarization, entity linking, and
entity disambiguation while maintaining competitive performance in the
fine-tuning setting. We can generate images unconditionally, conditioned on
text (like DALL-E) and do captioning all in a zero-shot setting with a single
model."
"GO-Surf: Neural Feature Grid Optimization for Fast, High-Fidelity RGB-D Surface Reconstruction",0.863321,"We present GO-Surf, a direct feature grid optimization method for accurate
and fast surface reconstruction from RGB-D sequences. We model the underlying
scene with a learned hierarchical feature voxel grid that encapsulates
multi-level geometric and appearance local information. Feature vectors are
directly optimized such that after being tri-linearly interpolated, decoded by
two shallow MLPs into signed distance and radiance values, and rendered via
surface volume rendering, the discrepancy between synthesized and observed
RGB/depth values is minimized. Our supervision signals -- RGB, depth and
approximate SDF -- can be obtained directly from input images without any need
for fusion or post-processing. We formulate a novel SDF gradient regularization
term that encourages surface smoothness and hole filling while maintaining high
frequency details. GO-Surf can optimize sequences of $1$-$2$K frames in
$15$-$45$ minutes, a speedup of $\times60$ over NeuralRGB-D, the most related
approach based on an MLP representation, while maintaining on par performance
on standard benchmarks. Project page: https://jingwenwang95.github.io/go_surf/"
Third Time's the Charm? Image and Video Editing with StyleGAN3,0.99293,"StyleGAN is arguably one of the most intriguing and well-studied generative
models, demonstrating impressive performance in image generation, inversion,
and manipulation. In this work, we explore the recent StyleGAN3 architecture,
compare it to its predecessor, and investigate its unique advantages, as well
as drawbacks. In particular, we demonstrate that while StyleGAN3 can be trained
on unaligned data, one can still use aligned data for training, without
hindering the ability to generate unaligned imagery. Next, our analysis of the
disentanglement of the different latent spaces of StyleGAN3 indicates that the
commonly used W/W+ spaces are more entangled than their StyleGAN2 counterparts,
underscoring the benefits of using the StyleSpace for fine-grained editing.
Considering image inversion, we observe that existing encoder-based techniques
struggle when trained on unaligned data. We therefore propose an encoding
scheme trained solely on aligned data, yet can still invert unaligned images.
Finally, we introduce a novel video inversion and editing workflow that
leverages the capabilities of a fine-tuned StyleGAN3 generator to reduce
texture sticking and expand the field of view of the edited video."
Revisiting End-to-End Speech-to-Text Translation From Scratch,0.259694,"End-to-end (E2E) speech-to-text translation (ST) often depends on pretraining
its encoder and/or decoder using source transcripts via speech recognition or
text translation tasks, without which translation performance drops
substantially. However, transcripts are not always available, and how
significant such pretraining is for E2E ST has rarely been studied in the
literature. In this paper, we revisit this question and explore the extent to
which the quality of E2E ST trained on speech-translation pairs alone can be
improved. We reexamine several techniques proven beneficial to ST previously,
and offer a set of best practices that biases a Transformer-based E2E ST system
toward training from scratch. Besides, we propose parameterized distance
penalty to facilitate the modeling of locality in the self-attention model for
speech. On four benchmarks covering 23 languages, our experiments show that,
without using any transcripts or pretraining, the proposed system reaches and
even outperforms previous studies adopting pretraining, although the gap
remains in (extremely) low-resource settings. Finally, we discuss neural
acoustic feature modeling, where a neural model is designed to extract acoustic
features from raw speech signals directly, with the goal to simplify inductive
biases and add freedom to the model in describing speech. For the first time,
we demonstrate its feasibility and show encouraging results on ST tasks."
UnrealEgo: A New Dataset for Robust Egocentric 3D Human Motion Capture,0.297793,"We present UnrealEgo, i.e., a new large-scale naturalistic dataset for
egocentric 3D human pose estimation. UnrealEgo is based on an advanced concept
of eyeglasses equipped with two fisheye cameras that can be used in
unconstrained environments. We design their virtual prototype and attach them
to 3D human models for stereo view capture. We next generate a large corpus of
human motions. As a consequence, UnrealEgo is the first dataset to provide
in-the-wild stereo images with the largest variety of motions among existing
egocentric datasets. Furthermore, we propose a new benchmark method with a
simple but effective idea of devising a 2D keypoint estimation module for
stereo inputs to improve 3D human pose estimation. The extensive experiments
show that our approach outperforms the previous state-of-the-art methods
qualitatively and quantitatively. UnrealEgo and our source codes are available
on our project web page."
The Stack: 3 TB of permissively licensed source code,0.877409,"Large Language Models (LLMs) play an ever-increasing role in the field of
Artificial Intelligence (AI)--not only for natural language processing but also
for code understanding and generation. To stimulate open and responsible
research on LLMs for code, we introduce The Stack, a 3.1 TB dataset consisting
of permissively licensed source code in 30 programming languages. We describe
how we collect the full dataset, construct a permissively licensed subset,
present a data governance plan, discuss limitations, and show promising results
on text2code benchmarks by training 350M-parameter decoders on different Python
subsets. We find that (1) near-deduplicating the data significantly boosts
performance across all experiments, and (2) it is possible to match previously
reported HumanEval and MBPP performance using only permissively licensed data.
We make the dataset available at https://hf.co/BigCode, provide a tool called
""Am I in The Stack"" (https://hf.co/spaces/bigcode/in-the-stack) for developers
to search The Stack for copies of their code, and provide a process for code to
be removed from the dataset by following the instructions at
https://www.bigcode-project.org/docs/about/the-stack/."
Neural Feature Fusion Fields: 3D Distillation of Self-Supervised 2D Image Representations,0.5027,"We present Neural Feature Fusion Fields (N3F), a method that improves dense
2D image feature extractors when the latter are applied to the analysis of
multiple images reconstructible as a 3D scene. Given an image feature
extractor, for example pre-trained using self-supervision, N3F uses it as a
teacher to learn a student network defined in 3D space. The 3D student network
is similar to a neural radiance field that distills said features and can be
trained with the usual differentiable rendering machinery. As a consequence,
N3F is readily applicable to most neural rendering formulations, including
vanilla NeRF and its extensions to complex dynamic scenes. We show that our
method not only enables semantic understanding in the context of scene-specific
neural fields without the use of manual labels, but also consistently improves
over the self-supervised 2D baselines. This is demonstrated by considering
various tasks, such as 2D object retrieval, 3D segmentation, and scene editing,
in diverse sequences, including long egocentric videos in the EPIC-KITCHENS
benchmark."
Adversarial Laser Spot: Robust and Covert Physical-World Attack to DNNs,0.132687,"Most existing deep neural networks (DNNs) are easily disturbed by slight
noise. However, there are few researches on physical attacks by deploying
lighting equipment. The light-based physical attacks has excellent covertness,
which brings great security risks to many vision-based applications (such as
self-driving). Therefore, we propose a light-based physical attack, called
adversarial laser spot (AdvLS), which optimizes the physical parameters of
laser spots through genetic algorithm to perform physical attacks. It realizes
robust and covert physical attack by using low-cost laser equipment. As far as
we know, AdvLS is the first light-based physical attack that perform physical
attacks in the daytime. A large number of experiments in the digital and
physical environments show that AdvLS has excellent robustness and covertness.
In addition, through in-depth analysis of the experimental data, we find that
the adversarial perturbations generated by AdvLS have superior adversarial
attack migration. The experimental results show that AdvLS impose serious
interference to advanced DNNs, we call for the attention of the proposed AdvLS.
The code of AdvLS is available at: https://github.com/ChengYinHu/AdvLS"
Multilingual Machine Translation with Hyper-Adapters,0.0549896,"Multilingual machine translation suffers from negative interference across
languages. A common solution is to relax parameter sharing with
language-specific modules like adapters. However, adapters of related languages
are unable to transfer information, and their total number of parameters
becomes prohibitively expensive as the number of languages grows. In this work,
we overcome these drawbacks using hyper-adapters -- hyper-networks that
generate adapters from language and layer embeddings. While past work had poor
results when scaling hyper-networks, we propose a rescaling fix that
significantly improves convergence and enables training larger hyper-networks.
We find that hyper-adapters are more parameter efficient than regular adapters,
reaching the same performance with up to 12 times less parameters. When using
the same number of parameters and FLOPS, our approach consistently outperforms
regular adapters. Also, hyper-adapters converge faster than alternative
approaches and scale better than regular dense networks. Our analysis shows
that hyper-adapters learn to encode language relatedness, enabling positive
transfer across languages."
"""I think this is the most disruptive technology"": Exploring Sentiments of ChatGPT Early Adopters using Twitter Data",0.968952,"Large language models have recently attracted significant attention due to
their impressive performance on a variety of tasks. ChatGPT developed by OpenAI
is one such implementation of a large, pre-trained language model that has
gained immense popularity among early adopters, where certain users go to the
extent of characterizing it as a disruptive technology in many domains.
Understanding such early adopters' sentiments is important because it can
provide insights into the potential success or failure of the technology, as
well as its strengths and weaknesses. In this paper, we conduct a mixed-method
study using 10,732 tweets from early ChatGPT users. We first use topic
modelling to identify the main topics and then perform an in-depth qualitative
sentiment analysis of each topic. Our results show that the majority of the
early adopters have expressed overwhelmingly positive sentiments related to
topics such as Disruptions to software development, Entertainment and
exercising creativity. Only a limited percentage of users expressed concerns
about issues such as the potential for misuse of ChatGPT, especially regarding
topics such as Impact on educational aspects. We discuss these findings by
providing specific examples for each topic and then detail implications related
to addressing these concerns for both researchers and users."
MOTRv2: Bootstrapping End-to-End Multi-Object Tracking by Pretrained Object Detectors,0.296033,"In this paper, we propose MOTRv2, a simple yet effective pipeline to
bootstrap end-to-end multi-object tracking with a pretrained object detector.
Existing end-to-end methods, MOTR and TrackFormer are inferior to their
tracking-by-detection counterparts mainly due to their poor detection
performance. We aim to improve MOTR by elegantly incorporating an extra object
detector. We first adopt the anchor formulation of queries and then use an
extra object detector to generate proposals as anchors, providing detection
prior to MOTR. The simple modification greatly eases the conflict between joint
learning detection and association tasks in MOTR. MOTRv2 keeps the query
propogation feature and scales well on large-scale benchmarks. MOTRv2 ranks the
1st place (73.4% HOTA on DanceTrack) in the 1st Multiple People Tracking in
Group Dance Challenge. Moreover, MOTRv2 reaches state-of-the-art performance on
the BDD100K dataset. We hope this simple and effective pipeline can provide
some new insights to the end-to-end MOT community. Code is available at
\url{https://github.com/megvii-research/MOTRv2}."
Rationale-Augmented Ensembles in Language Models,0.868289,"Recent research has shown that rationales, or step-by-step chains of thought,
can be used to improve performance in multi-step reasoning tasks. We reconsider
rationale-augmented prompting for few-shot in-context learning, where (input ->
output) prompts are expanded to (input, rationale -> output) prompts. For
rationale-augmented prompting we demonstrate how existing approaches, which
rely on manual prompt engineering, are subject to sub-optimal rationales that
may harm performance. To mitigate this brittleness, we propose a unified
framework of rationale-augmented ensembles, where we identify rationale
sampling in the output space as the key component to robustly improve
performance. This framework is general and can easily be extended to common
natural language processing tasks, even those that do not traditionally
leverage intermediate steps, such as question answering, word sense
disambiguation, and sentiment analysis. We demonstrate that rationale-augmented
ensembles achieve more accurate and interpretable results than existing
prompting approaches--including standard prompting without rationales and
rationale-based chain-of-thought prompting--while simultaneously improving
interpretability of model predictions through the associated rationales."
Hidden Poison: Machine Unlearning Enables Camouflaged Poisoning Attacks,0.271236,"We introduce camouflaged data poisoning attacks, a new attack vector that
arises in the context of machine unlearning and other settings when model
retraining may be induced. An adversary first adds a few carefully crafted
points to the training dataset such that the impact on the model's predictions
is minimal. The adversary subsequently triggers a request to remove a subset of
the introduced points at which point the attack is unleashed and the model's
predictions are negatively affected. In particular, we consider clean-label
targeted attacks (in which the goal is to cause the model to misclassify a
specific test point) on datasets including CIFAR-10, Imagenette, and Imagewoof.
This attack is realized by constructing camouflage datapoints that mask the
effect of a poisoned dataset."
A case for using rotation invariant features in state of the art feature matchers,0.0886065,"The aim of this paper is to demonstrate that a state of the art feature
matcher (LoFTR) can be made more robust to rotations by simply replacing the
backbone CNN with a steerable CNN which is equivariant to translations and
image rotations. It is experimentally shown that this boost is obtained without
reducing performance on ordinary illumination and viewpoint matching sequences."
Demystifying Prompts in Language Models via Perplexity Estimation,0.978255,"Language models can be prompted to perform a wide variety of zero- and
few-shot learning problems. However, performance varies significantly with the
choice of prompt, and we do not yet understand why this happens or how to pick
the best prompts. In this work, we analyze the factors that contribute to this
variance and establish a new empirical hypothesis: the performance of a prompt
is coupled with the extent to which the model is familiar with the language it
contains. Over a wide range of tasks, we show that the lower the perplexity of
the prompt is, the better the prompt is able to perform the task. As a result,
we devise a method for creating prompts: (1) automatically extend a small seed
set of manually written prompts by paraphrasing using GPT3 and backtranslation
and (2) choose the lowest perplexity prompts to get significant gains in
performance."
CSL: A Large-scale Chinese Scientific Literature Dataset,0.851738,"Scientific literature serves as a high-quality corpus, supporting a lot of
Natural Language Processing (NLP) research. However, existing datasets are
centered around the English language, which restricts the development of
Chinese scientific NLP. In this work, we present CSL, a large-scale Chinese
Scientific Literature dataset, which contains the titles, abstracts, keywords
and academic fields of 396k papers. To our knowledge, CSL is the first
scientific document dataset in Chinese. The CSL can serve as a Chinese corpus.
Also, this semi-structured data is a natural annotation that can constitute
many supervised NLP tasks. Based on CSL, we present a benchmark to evaluate the
performance of models across scientific domain tasks, i.e., summarization,
keyword generation and text classification. We analyze the behavior of existing
text-to-text models on the evaluation tasks and reveal the challenges for
Chinese scientific NLP tasks, which provides a valuable reference for future
research. Data and code are available at https://github.com/ydli-ai/CSL"
Ditto: Building Digital Twins of Articulated Objects from Interaction,0.431631,"Digitizing physical objects into the virtual world has the potential to
unlock new research and applications in embodied AI and mixed reality. This
work focuses on recreating interactive digital twins of real-world articulated
objects, which can be directly imported into virtual environments. We introduce
Ditto to learn articulation model estimation and 3D geometry reconstruction of
an articulated object through interactive perception. Given a pair of visual
observations of an articulated object before and after interaction, Ditto
reconstructs part-level geometry and estimates the articulation model of the
object. We employ implicit neural representations for joint geometry and
articulation modeling. Our experiments show that Ditto effectively builds
digital twins of articulated objects in a category-agnostic way. We also apply
Ditto to real-world objects and deploy the recreated digital twins in physical
simulation. Code and additional results are available at
https://ut-austin-rpl.github.io/Ditto"
KappaFace: Adaptive Additive Angular Margin Loss for Deep Face Recognition,-1.0,"Feature learning is a widely used method employed for large-scale face
recognition. Recently, large-margin softmax loss methods have demonstrated
significant enhancements on deep face recognition. These methods propose fixed
positive margins in order to enforce intra-class compactness and inter-class
diversity. However, the majority of the proposed methods do not consider the
class imbalance issue, which is a major challenge in practice for developing
deep face recognition models. We hypothesize that it significantly affects the
generalization ability of the deep face models. Inspired by this observation,
we introduce a novel adaptive strategy, called KappaFace, to modulate the
relative importance based on class difficultness and imbalance. With the
support of the von Mises-Fisher distribution, our proposed KappaFace loss can
intensify the margin's magnitude for hard learning or low concentration classes
while relaxing it for counter classes. Experiments conducted on popular facial
benchmarks demonstrate that our proposed method achieves superior performance
to the state-of-the-art."
Selective Annotation Makes Language Models Better Few-Shot Learners,0.20881,"Many recent approaches to natural language tasks are built on the remarkable
abilities of large language models. Large language models can perform
in-context learning, where they learn a new task from a few task
demonstrations, without any parameter updates. This work examines the
implications of in-context learning for the creation of datasets for new
natural language tasks. Departing from recent in-context learning methods, we
formulate an annotation-efficient, two-step framework: selective annotation
that chooses a pool of examples to annotate from unlabeled data in advance,
followed by prompt retrieval that retrieves task examples from the annotated
pool at test time. Based on this framework, we propose an unsupervised,
graph-based selective annotation method, voke-k, to select diverse,
representative examples to annotate. Extensive experiments on 10 datasets
(covering classification, commonsense reasoning, dialogue, and text/code
generation) demonstrate that our selective annotation method improves the task
performance by a large margin. On average, vote-k achieves a 12.9%/11.4%
relative gain under an annotation budget of 18/100, as compared to randomly
selecting examples to annotate. Compared to state-of-the-art supervised
finetuning approaches, it yields similar performance with 10-100x less
annotation cost across 10 tasks. We further analyze the effectiveness of our
framework in various scenarios: language models with varying sizes, alternative
selective annotation methods, and cases where there is a test data domain
shift. We hope that our studies will serve as a basis for data annotations as
large language models are increasingly applied to new tasks. Our code is
available at https://github.com/HKUNLP/icl-selective-annotation."
Inference and dynamic decision-making for deteriorating systems with probabilistic dependencies through Bayesian networks and deep reinforcement learning,0.0351326,"In the context of modern environmental and societal concerns, there is an
increasing demand for methods able to identify management strategies for civil
engineering systems, minimizing structural failure risks while optimally
planning inspection and maintenance (I&M) processes. Most available methods
simplify the I&M decision problem to the component level due to the
computational complexity associated with global optimization methodologies
under joint system-level state descriptions. In this paper, we propose an
efficient algorithmic framework for inference and decision-making under
uncertainty for engineering systems exposed to deteriorating environments,
providing optimal management strategies directly at the system level. In our
approach, the decision problem is formulated as a factored partially observable
Markov decision process, whose dynamics are encoded in Bayesian network
conditional structures. The methodology can handle environments under equal or
general, unequal deterioration correlations among components, through Gaussian
hierarchical structures and dynamic Bayesian networks. In terms of policy
optimization, we adopt a deep decentralized multi-agent actor-critic (DDMAC)
reinforcement learning approach, in which the policies are approximated by
actor neural networks guided by a critic network. By including deterioration
dependence in the simulated environment, and by formulating the cost model at
the system level, DDMAC policies intrinsically consider the underlying
system-effects. This is demonstrated through numerical experiments conducted
for both a 9-out-of-10 system and a steel frame under fatigue deterioration.
Results demonstrate that DDMAC policies offer substantial benefits when
compared to state-of-the-art heuristic approaches. The inherent consideration
of system-effects by DDMAC strategies is also interpreted based on the learned
policies."
Learning Robust Representations for Continual Relation Extraction via Adversarial Class Augmentation,0.149114,"Continual relation extraction (CRE) aims to continually learn new relations
from a class-incremental data stream. CRE model usually suffers from
catastrophic forgetting problem, i.e., the performance of old relations
seriously degrades when the model learns new relations. Most previous work
attributes catastrophic forgetting to the corruption of the learned
representations as new relations come, with an implicit assumption that the CRE
models have adequately learned the old relations. In this paper, through
empirical studies we argue that this assumption may not hold, and an important
reason for catastrophic forgetting is that the learned representations do not
have good robustness against the appearance of analogous relations in the
subsequent learning process. To address this issue, we encourage the model to
learn more precise and robust representations through a simple yet effective
adversarial class augmentation mechanism (ACA), which is easy to implement and
model-agnostic. Experimental results show that ACA can consistently improve the
performance of state-of-the-art CRE models on two popular benchmarks."
Real-time Online Multi-Object Tracking in Compressed Domain,0.271508,"Recent online Multi-Object Tracking (MOT) methods have achieved desirable
tracking performance. However, the tracking speed of most existing methods is
rather slow. Inspired from the fact that the adjacent frames are highly
relevant and redundant, we divide the frames into key and non-key frames
respectively and track objects in the compressed domain. For the key frames,
the RGB images are restored for detection and data association. To make data
association more reliable, an appearance Convolutional Neural Network (CNN)
which can be jointly trained with the detector is proposed. For the non-key
frames, the objects are directly propagated by a tracking CNN based on the
motion information provided in the compressed domain. Compared with the
state-of-the-art online MOT methods,our tracker is about 6x faster while
maintaining a comparable tracking performance."
"Intelligent Computing: The Latest Advances, Challenges and Future",0.143315,"Computing is a critical driving force in the development of human
civilization. In recent years, we have witnessed the emergence of intelligent
computing, a new computing paradigm that is reshaping traditional computing and
promoting digital revolution in the era of big data, artificial intelligence
and internet-of-things with new computing theories, architectures, methods,
systems, and applications. Intelligent computing has greatly broadened the
scope of computing, extending it from traditional computing on data to
increasingly diverse computing paradigms such as perceptual intelligence,
cognitive intelligence, autonomous intelligence, and human-computer fusion
intelligence. Intelligence and computing have undergone paths of different
evolution and development for a long time but have become increasingly
intertwined in recent years: intelligent computing is not only
intelligence-oriented but also intelligence-driven. Such cross-fertilization
has prompted the emergence and rapid advancement of intelligent computing.
Intelligent computing is still in its infancy and an abundance of innovations
in the theories, systems, and applications of intelligent computing are
expected to occur soon. We present the first comprehensive survey of literature
on intelligent computing, covering its theory fundamentals, the technological
fusion of intelligence and computing, important applications, challenges, and
future perspectives. We believe that this survey is highly timely and will
provide a comprehensive reference and cast valuable insights into intelligent
computing for academic and industrial researchers and practitioners."
Document-Level Relation Extraction with Adaptive Focal Loss and Knowledge Distillation,0.366949,"Document-level Relation Extraction (DocRE) is a more challenging task
compared to its sentence-level counterpart. It aims to extract relations from
multiple sentences at once. In this paper, we propose a semi-supervised
framework for DocRE with three novel components. Firstly, we use an axial
attention module for learning the interdependency among entity-pairs, which
improves the performance on two-hop relations. Secondly, we propose an adaptive
focal loss to tackle the class imbalance problem of DocRE. Lastly, we use
knowledge distillation to overcome the differences between human annotated data
and distantly supervised data. We conducted experiments on two DocRE datasets.
Our model consistently outperforms strong baselines and its performance exceeds
the previous SOTA by 1.36 F1 and 1.46 Ign_F1 score on the DocRED leaderboard.
Our code and data will be released at https://github.com/tonytan48/KD-DocRE."
CORE: Simple and Effective Session-based Recommendation within Consistent Representation Space,0.786109,"Session-based Recommendation (SBR) refers to the task of predicting the next
item based on short-term user behaviors within an anonymous session. However,
session embedding learned by a non-linear encoder is usually not in the same
representation space as item embeddings, resulting in the inconsistent
prediction issue while recommending items. To address this issue, we propose a
simple and effective framework named CORE, which can unify the representation
space for both the encoding and decoding processes. Firstly, we design a
representation-consistent encoder that takes the linear combination of input
item embeddings as session embedding, guaranteeing that sessions and items are
in the same representation space. Besides, we propose a robust distance
measuring method to prevent overfitting of embeddings in the consistent
representation space. Extensive experiments conducted on five public real-world
datasets demonstrate the effectiveness and efficiency of the proposed method.
The code is available at: https://github.com/RUCAIBox/CORE."
POEM: Out-of-Distribution Detection with Posterior Sampling,-1.0,"Out-of-distribution (OOD) detection is indispensable for machine learning
models deployed in the open world. Recently, the use of an auxiliary outlier
dataset during training (also known as outlier exposure) has shown promising
performance. As the sample space for potential OOD data can be prohibitively
large, sampling informative outliers is essential. In this work, we propose a
novel posterior sampling-based outlier mining framework, POEM, which
facilitates efficient use of outlier data and promotes learning a compact
decision boundary between ID and OOD data for improved detection. We show that
POEM establishes state-of-the-art performance on common benchmarks. Compared to
the current best method that uses a greedy sampling strategy, POEM improves the
relative performance by 42.0% and 24.2% (FPR95) on CIFAR-10 and CIFAR-100,
respectively. We further provide theoretical insights on the effectiveness of
POEM for OOD detection."
Offline RL for Natural Language Generation with Implicit Language Q Learning,0.586294,"Large language models distill broad knowledge from text corpora. However,
they can be inconsistent when it comes to completing user specified tasks. This
issue can be addressed by finetuning such models via supervised learning on
curated datasets, or via reinforcement learning. In this work, we propose a
novel offline RL method, implicit language Q-learning (ILQL), designed for use
on language models, that combines both the flexible utility maximization
framework of RL algorithms with the ability of supervised learning to leverage
previously collected data, as well as its simplicity and stability. Our method
employs a combination of value conservatism alongside an implicit dataset
support constraint in learning value functions, which are then used to guide
language model generations towards maximizing user-specified utility functions.
In addition to empirically validating ILQL, we present a detailed empirical
analysis of situations where offline RL can be useful in natural language
generation settings, demonstrating how it can be a more effective utility
optimizer than prior approaches for end-to-end dialogue, and how it can
effectively optimize high variance reward functions based on subjective
judgement, such as whether to label a comment as toxic or not."
Faithful Reasoning Using Large Language Models,0.86867,"Although contemporary large language models (LMs) demonstrate impressive
question-answering capabilities, their answers are typically the product of a
single call to the model. This entails an unwelcome degree of opacity and
compromises performance, especially on problems that are inherently multi-step.
To address these limitations, we show how LMs can be made to perform faithful
multi-step reasoning via a process whose causal structure mirrors the
underlying logical structure of the problem. Our approach works by chaining
together reasoning steps, where each step results from calls to two fine-tuned
LMs, one for selection and one for inference, to produce a valid reasoning
trace. Our method carries out a beam search through the space of reasoning
traces to improve reasoning quality. We demonstrate the effectiveness of our
model on multi-step logical deduction and scientific question-answering,
showing that it outperforms baselines on final answer accuracy, and generates
humanly interpretable reasoning traces whose validity can be checked by the
user."
Semiconductor Defect Detection by Hybrid Classical-Quantum Deep Learning,0.532493,"With the rapid development of artificial intelligence and autonomous driving
technology, the demand for semiconductors is projected to rise substantially.
However, the massive expansion of semiconductor manufacturing and the
development of new technology will bring many defect wafers. If these defect
wafers have not been correctly inspected, the ineffective semiconductor
processing on these defect wafers will cause additional impact to our
environment, such as excessive carbon dioxide emission and energy consumption.
In this paper, we utilize the information processing advantages of quantum
computing to promote the defect learning defect review (DLDR). We propose a
classical-quantum hybrid algorithm for deep learning on near-term quantum
processors. By tuning parameters implemented on it, quantum circuit driven by
our framework learns a given DLDR task, include of wafer defect map
classification, defect pattern classification, and hotspot detection. In
addition, we explore parametrized quantum circuits with different
expressibility and entangling capacities. These results can be used to build a
future roadmap to develop circuit-based quantum deep learning for semiconductor
defect detection."
SeqOT: A Spatial-Temporal Transformer Network for Place Recognition Using Sequential LiDAR Data,0.552902,"Place recognition is an important component for autonomous vehicles to
achieve loop closing or global localization. In this paper, we tackle the
problem of place recognition based on sequential 3D LiDAR scans obtained by an
onboard LiDAR sensor. We propose a transformer-based network named SeqOT to
exploit the temporal and spatial information provided by sequential range
images generated from the LiDAR data. It uses multi-scale transformers to
generate a global descriptor for each sequence of LiDAR range images in an
end-to-end fashion. During online operation, our SeqOT finds similar places by
matching such descriptors between the current query sequence and those stored
in the map. We evaluate our approach on four datasets collected with different
types of LiDAR sensors in different environments. The experimental results show
that our method outperforms the state-of-the-art LiDAR-based place recognition
methods and generalizes well across different environments. Furthermore, our
method operates online faster than the frame rate of the sensor. The
implementation of our method is released as open source at:
https://github.com/BIT-MJY/SeqOT."
M2I: From Factored Marginal Trajectory Prediction to Interactive Prediction,0.774122,"Predicting future motions of road participants is an important task for
driving autonomously in urban scenes. Existing models excel at predicting
marginal trajectories for single agents, yet it remains an open question to
jointly predict scene compliant trajectories over multiple agents. The
challenge is due to exponentially increasing prediction space as a function of
the number of agents. In this work, we exploit the underlying relations between
interacting agents and decouple the joint prediction problem into marginal
prediction problems. Our proposed approach M2I first classifies interacting
agents as pairs of influencers and reactors, and then leverages a marginal
prediction model and a conditional prediction model to predict trajectories for
the influencers and reactors, respectively. The predictions from interacting
agents are combined and selected according to their joint likelihoods.
Experiments show that our simple but effective approach achieves
state-of-the-art performance on the Waymo Open Motion Dataset interactive
prediction benchmark."
TAFNet: A Three-Stream Adaptive Fusion Network for RGB-T Crowd Counting,0.843613,"In this paper, we propose a three-stream adaptive fusion network named
TAFNet, which uses paired RGB and thermal images for crowd counting.
Specifically, TAFNet is divided into one main stream and two auxiliary streams.
We combine a pair of RGB and thermal images to constitute the input of main
stream. Two auxiliary streams respectively exploit RGB image and thermal image
to extract modality-specific features. Besides, we propose an Information
Improvement Module (IIM) to fuse the modality-specific features into the main
stream adaptively. Experiment results on RGBT-CC dataset show that our method
achieves more than 20% improvement on mean average error and root mean squared
error compared with state-of-the-art method. The source code will be publicly
available at https://github.com/TANGHAIHAN/TAFNet."
Anomaly Detection via Reverse Distillation from One-Class Embedding,0.559367,"Knowledge distillation (KD) achieves promising results on the challenging
problem of unsupervised anomaly detection (AD).The representation discrepancy
of anomalies in the teacher-student (T-S) model provides essential evidence for
AD. However, using similar or identical architectures to build the teacher and
student models in previous studies hinders the diversity of anomalous
representations. To tackle this problem, we propose a novel T-S model
consisting of a teacher encoder and a student decoder and introduce a simple
yet effective ""reverse distillation"" paradigm accordingly. Instead of receiving
raw images directly, the student network takes teacher model's one-class
embedding as input and targets to restore the teacher's multiscale
representations. Inherently, knowledge distillation in this study starts from
abstract, high-level presentations to low-level features. In addition, we
introduce a trainable one-class bottleneck embedding (OCBE) module in our T-S
model. The obtained compact embedding effectively preserves essential
information on normal patterns, but abandons anomaly perturbations. Extensive
experimentation on AD and one-class novelty detection benchmarks shows that our
method surpasses SOTA performance, demonstrating our proposed approach's
effectiveness and generalizability."
Deep Transformer Q-Networks for Partially Observable Reinforcement Learning,0.0,"Real-world reinforcement learning tasks often involve some form of partial
observability where the observations only give a partial or noisy view of the
true state of the world. Such tasks typically require some form of memory,
where the agent has access to multiple past observations, in order to perform
well. One popular way to incorporate memory is by using a recurrent neural
network to access the agent's history. However, recurrent neural networks in
reinforcement learning are often fragile and difficult to train, susceptible to
catastrophic forgetting and sometimes fail completely as a result. In this
work, we propose Deep Transformer Q-Networks (DTQN), a novel architecture
utilizing transformers and self-attention to encode an agent's history. DTQN is
designed modularly, and we compare results against several modifications to our
base model. Our experiments demonstrate the transformer can solve partially
observable tasks faster and more stably than previous recurrent approaches."
Learning Progressive Modality-shared Transformers for Effective Visible-Infrared Person Re-identification,0.708943,"Visible-Infrared Person Re-Identification (VI-ReID) is a challenging
retrieval task under complex modality changes. Existing methods usually focus
on extracting discriminative visual features while ignoring the reliability and
commonality of visual features between different modalities. In this paper, we
propose a novel deep learning framework named Progressive Modality-shared
Transformer (PMT) for effective VI-ReID. To reduce the negative effect of
modality gaps, we first take the gray-scale images as an auxiliary modality and
propose a progressive learning strategy. Then, we propose a Modality-Shared
Enhancement Loss (MSEL) to guide the model to explore more reliable identity
information from modality-shared features. Finally, to cope with the problem of
large intra-class differences and small inter-class differences, we propose a
Discriminative Center Loss (DCL) combined with the MSEL to further improve the
discrimination of reliable features. Extensive experiments on SYSU-MM01 and
RegDB datasets show that our proposed framework performs better than most
state-of-the-art methods. For model reproduction, we release the source code at
https://github.com/hulu88/PMT."
Spatio-Temporal Transformer for Dynamic Facial Expression Recognition in the Wild,0.158744,"Previous methods for dynamic facial expression in the wild are mainly based
on Convolutional Neural Networks (CNNs), whose local operations ignore the
long-range dependencies in videos. To solve this problem, we propose the
spatio-temporal Transformer (STT) to capture discriminative features within
each frame and model contextual relationships among frames. Spatio-temporal
dependencies are captured and integrated by our unified Transformer.
Specifically, given an image sequence consisting of multiple frames as input,
we utilize the CNN backbone to translate each frame into a visual feature
sequence. Subsequently, the spatial attention and the temporal attention within
each block are jointly applied for learning spatio-temporal representations at
the sequence level. In addition, we propose the compact softmax cross entropy
loss to further encourage the learned features have the minimum intra-class
distance and the maximum inter-class distance. Experiments on two in-the-wild
dynamic facial expression datasets (i.e., DFEW and AFEW) indicate that our
method provides an effective way to make use of the spatial and temporal
dependencies for dynamic facial expression recognition. The source code and the
training logs will be made publicly available."
DDG-DA: Data Distribution Generation for Predictable Concept Drift Adaptation,0.288338,"In many real-world scenarios, we often deal with streaming data that is
sequentially collected over time. Due to the non-stationary nature of the
environment, the streaming data distribution may change in unpredictable ways,
which is known as concept drift. To handle concept drift, previous methods
first detect when/where the concept drift happens and then adapt models to fit
the distribution of the latest data. However, there are still many cases that
some underlying factors of environment evolution are predictable, making it
possible to model the future concept drift trend of the streaming data, while
such cases are not fully explored in previous work.
  In this paper, we propose a novel method DDG-DA, that can effectively
forecast the evolution of data distribution and improve the performance of
models. Specifically, we first train a predictor to estimate the future data
distribution, then leverage it to generate training samples, and finally train
models on the generated data. We conduct experiments on three real-world tasks
(forecasting on stock price trend, electricity load and solar irradiance) and
obtain significant improvement on multiple widely-used models."
Monotonic Differentiable Sorting Networks,0.141674,"Differentiable sorting algorithms allow training with sorting and ranking
supervision, where only the ordering or ranking of samples is known. Various
methods have been proposed to address this challenge, ranging from optimal
transport-based differentiable Sinkhorn sorting algorithms to making classic
sorting networks differentiable. One problem of current differentiable sorting
methods is that they are non-monotonic. To address this issue, we propose a
novel relaxation of conditional swap operations that guarantees monotonicity in
differentiable sorting networks. We introduce a family of sigmoid functions and
prove that they produce differentiable sorting networks that are monotonic.
Monotonicity ensures that the gradients always have the correct sign, which is
an advantage in gradient-based optimization. We demonstrate that monotonic
differentiable sorting networks improve upon previous differentiable sorting
methods."
Multi-Game Decision Transformers,0.967645,"A longstanding goal of the field of AI is a method for learning a highly
capable, generalist agent from diverse experience. In the subfields of vision
and language, this was largely achieved by scaling up transformer-based models
and training them on large, diverse datasets. Motivated by this progress, we
investigate whether the same strategy can be used to produce generalist
reinforcement learning agents. Specifically, we show that a single
transformer-based model - with a single set of weights - trained purely offline
can play a suite of up to 46 Atari games simultaneously at close-to-human
performance. When trained and evaluated appropriately, we find that the same
trends observed in language and vision hold, including scaling of performance
with model size and rapid adaptation to new games via fine-tuning. We compare
several approaches in this multi-game setting, such as online and offline RL
methods and behavioral cloning, and find that our Multi-Game Decision
Transformer models offer the best scalability and performance. We release the
pre-trained models and code to encourage further research in this direction."
Privacy-friendly Synthetic Data for the Development of Face Morphing Attack Detectors,0.848092,"The main question this work aims at answering is: ""can morphing attack
detection (MAD) solutions be successfully developed based on synthetic data?"".
Towards that, this work introduces the first synthetic-based MAD development
dataset, namely the Synthetic Morphing Attack Detection Development dataset
(SMDD). This dataset is utilized successfully to train three MAD backbones
where it proved to lead to high MAD performance, even on completely unknown
attack types. Additionally, an essential aspect of this work is the detailed
legal analyses of the challenges of using and sharing real biometric data,
rendering our proposed SMDD dataset extremely essential. The SMDD dataset,
consisting of 30,000 attack and 50,000 bona fide samples, is publicly available
for research purposes."
Physical Attack on Monocular Depth Estimation with Optimal Adversarial Patches,0.251237,"Deep learning has substantially boosted the performance of Monocular Depth
Estimation (MDE), a critical component in fully vision-based autonomous driving
(AD) systems (e.g., Tesla and Toyota). In this work, we develop an attack
against learning-based MDE. In particular, we use an optimization-based method
to systematically generate stealthy physical-object-oriented adversarial
patches to attack depth estimation. We balance the stealth and effectiveness of
our attack with object-oriented adversarial design, sensitive region
localization, and natural style camouflage. Using real-world driving scenarios,
we evaluate our attack on concurrent MDE models and a representative downstream
task for AD (i.e., 3D object detection). Experimental results show that our
method can generate stealthy, effective, and robust adversarial patches for
different target objects and models and achieves more than 6 meters mean depth
estimation error and 93% attack success rate (ASR) in object detection with a
patch of 1/9 of the vehicle's rear area. Field tests on three different driving
routes with a real vehicle indicate that we cause over 6 meters mean depth
estimation error and reduce the object detection rate from 90.70% to 5.16% in
continuous video frames."
Leveraging Social Influence based on Users Activity Centers for Point-of-Interest Recommendation,0.0528053,"Recommender Systems (RSs) aim to model and predict the user preference while
interacting with items, such as Points of Interest (POIs). These systems face
several challenges, such as data sparsity, limiting their effectiveness. In
this paper, we address this problem by incorporating social, geographical, and
temporal information into the Matrix Factorization (MF) technique. To this end,
we model social influence based on two factors: similarities between users in
terms of common check-ins and the friendships between them. We introduce two
levels of friendship based on explicit friendship networks and high check-in
overlap between users. We base our friendship algorithm on users' geographical
activity centers. The results show that our proposed model outperforms the
state-of-the-art on two real-world datasets. More specifically, our ablation
study shows that the social model improves the performance of our proposed POI
recommendation system by 31% and 14% on the Gowalla and Yelp datasets in terms
of Precision@10, respectively."
BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation,0.999976,"Vision-Language Pre-training (VLP) has advanced the performance for many
vision-language tasks. However, most existing pre-trained models only excel in
either understanding-based tasks or generation-based tasks. Furthermore,
performance improvement has been largely achieved by scaling up the dataset
with noisy image-text pairs collected from the web, which is a suboptimal
source of supervision. In this paper, we propose BLIP, a new VLP framework
which transfers flexibly to both vision-language understanding and generation
tasks. BLIP effectively utilizes the noisy web data by bootstrapping the
captions, where a captioner generates synthetic captions and a filter removes
the noisy ones. We achieve state-of-the-art results on a wide range of
vision-language tasks, such as image-text retrieval (+2.7% in average
recall@1), image captioning (+2.8% in CIDEr), and VQA (+1.6% in VQA score).
BLIP also demonstrates strong generalization ability when directly transferred
to video-language tasks in a zero-shot manner. Code, models, and datasets are
released at https://github.com/salesforce/BLIP."
Few-shot Learning with Noisy Labels,0.149947,"Few-shot learning (FSL) methods typically assume clean support sets with
accurately labeled samples when training on novel classes. This assumption can
often be unrealistic: support sets, no matter how small, can still include
mislabeled samples. Robustness to label noise is therefore essential for FSL
methods to be practical, but this problem surprisingly remains largely
unexplored. To address mislabeled samples in FSL settings, we make several
technical contributions. (1) We offer simple, yet effective, feature
aggregation methods, improving the prototypes used by ProtoNet, a popular FSL
technique. (2) We describe a novel Transformer model for Noisy Few-Shot
Learning (TraNFS). TraNFS leverages a transformer's attention mechanism to
weigh mislabeled versus correct samples. (3) Finally, we extensively test these
methods on noisy versions of MiniImageNet and TieredImageNet. Our results show
that TraNFS is on-par with leading FSL methods on clean support sets, yet
outperforms them, by far, in the presence of label noise."
Simple Open-Vocabulary Object Detection with Vision Transformers,0.824939,"Combining simple architectures with large-scale pre-training has led to
massive improvements in image classification. For object detection,
pre-training and scaling approaches are less well established, especially in
the long-tailed and open-vocabulary setting, where training data is relatively
scarce. In this paper, we propose a strong recipe for transferring image-text
models to open-vocabulary object detection. We use a standard Vision
Transformer architecture with minimal modifications, contrastive image-text
pre-training, and end-to-end detection fine-tuning. Our analysis of the scaling
properties of this setup shows that increasing image-level pre-training and
model size yield consistent improvements on the downstream detection task. We
provide the adaptation strategies and regularizations needed to attain very
strong performance on zero-shot text-conditioned and one-shot image-conditioned
object detection. Code and models are available on GitHub."
Event Transformer. A sparse-aware solution for efficient event data processing,0.696371,"Event cameras are sensors of great interest for many applications that run in
low-resource and challenging environments. They log sparse illumination changes
with high temporal resolution and high dynamic range, while they present
minimal power consumption. However, top-performing methods often ignore
specific event-data properties, leading to the development of generic but
computationally expensive algorithms. Efforts toward efficient solutions
usually do not achieve top-accuracy results for complex tasks. This work
proposes a novel framework, Event Transformer (EvT), that effectively takes
advantage of event-data properties to be highly efficient and accurate. We
introduce a new patch-based event representation and a compact transformer-like
architecture to process it. EvT is evaluated on different event-based
benchmarks for action and gesture recognition. Evaluation results show better
or comparable accuracy to the state-of-the-art while requiring significantly
less computation resources, which makes EvT able to work with minimal latency
both on GPU and CPU."
CIRCLe: Color Invariant Representation Learning for Unbiased Classification of Skin Lesions,0.159289,"While deep learning based approaches have demonstrated expert-level
performance in dermatological diagnosis tasks, they have also been shown to
exhibit biases toward certain demographic attributes, particularly skin types
(e.g., light versus dark), a fairness concern that must be addressed. We
propose CIRCLe, a skin color invariant deep representation learning method for
improving fairness in skin lesion classification. CIRCLe is trained to classify
images by utilizing a regularization loss that encourages images with the same
diagnosis but different skin types to have similar latent representations.
Through extensive evaluation and ablation studies, we demonstrate CIRCLe's
superior performance over the state-of-the-art when evaluated on 16k+ images
spanning 6 Fitzpatrick skin types and 114 diseases, using classification
accuracy, equal opportunity difference (for light versus dark groups), and
normalized accuracy range, a new measure we propose to assess fairness on
multiple skin type groups."
GazeOnce: Real-Time Multi-Person Gaze Estimation,0.290627,"Appearance-based gaze estimation aims to predict the 3D eye gaze direction
from a single image. While recent deep learning-based approaches have
demonstrated excellent performance, they usually assume one calibrated face in
each input image and cannot output multi-person gaze in real time. However,
simultaneous gaze estimation for multiple people in the wild is necessary for
real-world applications. In this paper, we propose the first one-stage
end-to-end gaze estimation method, GazeOnce, which is capable of simultaneously
predicting gaze directions for multiple faces (>10) in an image. In addition,
we design a sophisticated data generation pipeline and propose a new dataset,
MPSGaze, which contains full images of multiple people with 3D gaze ground
truth. Experimental results demonstrate that our unified framework not only
offers a faster speed, but also provides a lower gaze estimation error compared
with state-of-the-art methods. This technique can be useful in real-time
applications with multiple users."
News Summarization and Evaluation in the Era of GPT-3,0.991461,"The recent success of prompting large language models like GPT-3 has led to a
paradigm shift in NLP research. In this paper, we study its impact on text
summarization, focusing on the classic benchmark domain of news summarization.
First, we investigate how GPT-3 compares against fine-tuned models trained on
large summarization datasets. We show that not only do humans overwhelmingly
prefer GPT-3 summaries, prompted using only a task description, but these also
do not suffer from common dataset-specific issues such as poor factuality.
Next, we study what this means for evaluation, particularly the role of gold
standard test sets. Our experiments show that both reference-based and
reference-free automatic metrics cannot reliably evaluate GPT-3 summaries.
Finally, we evaluate models on a setting beyond generic summarization,
specifically keyword-based summarization, and show how dominant fine-tuning
approaches compare to prompting.
  To support further research, we release: (a) a corpus of 10K generated
summaries from fine-tuned and prompt-based models across 4 standard
summarization benchmarks, (b) 1K human preference judgments comparing different
systems for generic- and keyword-based summarization."
NICO++: Towards Better Benchmarking for Domain Generalization,0.189952,"Despite the remarkable performance that modern deep neural networks have
achieved on independent and identically distributed (I.I.D.) data, they can
crash under distribution shifts. Most current evaluation methods for domain
generalization (DG) adopt the leave-one-out strategy as a compromise on the
limited number of domains. We propose a large-scale benchmark with extensive
labeled domains named NICO++ along with more rational evaluation methods for
comprehensively evaluating DG algorithms. To evaluate DG datasets, we propose
two metrics to quantify covariate shift and concept shift, respectively. Two
novel generalization bounds from the perspective of data construction are
proposed to prove that limited concept shift and significant covariate shift
favor the evaluation capability for generalization. Through extensive
experiments, NICO++ shows its superior evaluation capability compared with
current DG datasets and its contribution in alleviating unfairness caused by
the leak of oracle knowledge in model selection."
Learning Equivariant Segmentation with Instance-Unique Querying,0.157033,"Prevalent state-of-the-art instance segmentation methods fall into a
query-based scheme, in which instance masks are derived by querying the image
feature using a set of instance-aware embeddings. In this work, we devise a new
training framework that boosts query-based models through discriminative query
embedding learning. It explores two essential properties, namely dataset-level
uniqueness and transformation equivariance, of the relation between queries and
instances. First, our algorithm uses the queries to retrieve the corresponding
instances from the whole training dataset, instead of only searching within
individual scenes. As querying instances across scenes is more challenging, the
segmenters are forced to learn more discriminative queries for effective
instance separation. Second, our algorithm encourages both image (instance)
representations and queries to be equivariant against geometric
transformations, leading to more robust, instance-query matching. On top of
four famous, query-based models ($i.e.,$ CondInst, SOLOv2, SOTR, and
Mask2Former), our training algorithm provides significant performance gains
($e.g.,$ +1.6 - 3.2 AP) on COCO dataset. In addition, our algorithm promotes
the performance of SOLOv2 by 2.7 AP, on LVISv1 dataset."
ClarET: Pre-training a Correlation-Aware Context-To-Event Transformer for Event-Centric Generation and Classification,0.230164,"Generating new events given context with correlated ones plays a crucial role
in many event-centric reasoning tasks. Existing works either limit their scope
to specific scenarios or overlook event-level correlations. In this paper, we
propose to pre-train a general Correlation-aware context-to-Event Transformer
(ClarET) for event-centric reasoning. To achieve this, we propose three novel
event-centric objectives, i.e., whole event recovering, contrastive
event-correlation encoding and prompt-based event locating, which highlight
event-level correlations with effective training. The proposed ClarET is
applicable to a wide range of event-centric reasoning scenarios, considering
its versatility of (i) event-correlation types (e.g., causal, temporal,
contrast), (ii) application formulations (i.e., generation and classification),
and (iii) reasoning types (e.g., abductive, counterfactual and ending
reasoning). Empirical fine-tuning results, as well as zero- and few-shot
learning, on 9 benchmarks (5 generation and 4 classification tasks covering 4
reasoning types with diverse event correlations), verify its effectiveness and
generalization ability."
Omnivore: A Single Model for Many Visual Modalities,0.999928,"Prior work has studied different visual modalities in isolation and developed
separate architectures for recognition of images, videos, and 3D data. Instead,
in this paper, we propose a single model which excels at classifying images,
videos, and single-view 3D data using exactly the same model parameters. Our
'Omnivore' model leverages the flexibility of transformer-based architectures
and is trained jointly on classification tasks from different modalities.
Omnivore is simple to train, uses off-the-shelf standard datasets, and performs
at-par or better than modality-specific models of the same size. A single
Omnivore model obtains 86.0% on ImageNet, 84.1% on Kinetics, and 67.1% on SUN
RGB-D. After finetuning, our models outperform prior work on a variety of
vision tasks and generalize across modalities. Omnivore's shared visual
representation naturally enables cross-modal recognition without access to
correspondences between modalities. We hope our results motivate researchers to
model visual modalities together."
$\mathcal{X}$-Metric: An N-Dimensional Information-Theoretic Framework for Groupwise Registration and Deep Combined Computing,0.140208,"This paper presents a generic probabilistic framework for estimating the
statistical dependency and finding the anatomical correspondences among an
arbitrary number of medical images. The method builds on a novel formulation of
the $N$-dimensional joint intensity distribution by representing the common
anatomy as latent variables and estimating the appearance model with
nonparametric estimators. Through connection to maximum likelihood and the
expectation-maximization algorithm, an information\hyp{}theoretic metric called
$\mathcal{X}$-metric and a co-registration algorithm named $\mathcal{X}$-CoReg
are induced, allowing groupwise registration of the $N$ observed images with
computational complexity of $\mathcal{O}(N)$. Moreover, the method naturally
extends for a weakly-supervised scenario where anatomical labels of certain
images are provided. This leads to a combined\hyp{}computing framework
implemented with deep learning, which performs registration and segmentation
simultaneously and collaboratively in an end-to-end fashion. Extensive
experiments were conducted to demonstrate the versatility and applicability of
our model, including multimodal groupwise registration, motion correction for
dynamic contrast enhanced magnetic resonance images, and deep combined
computing for multimodal medical images. Results show the superiority of our
method in various applications in terms of both accuracy and efficiency,
highlighting the advantage of the proposed representation of the imaging
process."
Voxel Field Fusion for 3D Object Detection,0.370128,"In this work, we present a conceptually simple yet effective framework for
cross-modality 3D object detection, named voxel field fusion. The proposed
approach aims to maintain cross-modality consistency by representing and fusing
augmented image features as a ray in the voxel field. To this end, the
learnable sampler is first designed to sample vital features from the image
plane that are projected to the voxel grid in a point-to-ray manner, which
maintains the consistency in feature representation with spatial context. In
addition, ray-wise fusion is conducted to fuse features with the supplemental
context in the constructed voxel field. We further develop mixed augmentor to
align feature-variant transformations, which bridges the modality gap in data
augmentation. The proposed framework is demonstrated to achieve consistent
gains in various benchmarks and outperforms previous fusion-based methods on
KITTI and nuScenes datasets. Code is made available at
https://github.com/dvlab-research/VFF."
Towards Human-Agent Communication via the Information Bottleneck Principle,0.0895413,"Emergent communication research often focuses on optimizing task-specific
utility as a driver for communication. However, human languages appear to
evolve under pressure to efficiently compress meanings into communication
signals by optimizing the Information Bottleneck tradeoff between
informativeness and complexity. In this work, we study how trading off these
three factors -- utility, informativeness, and complexity -- shapes emergent
communication, including compared to human communication. To this end, we
propose Vector-Quantized Variational Information Bottleneck (VQ-VIB), a method
for training neural agents to compress inputs into discrete signals embedded in
a continuous space. We train agents via VQ-VIB and compare their performance to
previously proposed neural architectures in grounded environments and in a
Lewis reference game. Across all neural architectures and settings, taking into
account communicative informativeness benefits communication convergence rates,
and penalizing communicative complexity leads to human-like lexicon sizes while
maintaining high utility. Additionally, we find that VQ-VIB outperforms other
discrete communication methods. This work demonstrates how fundamental
principles that are believed to characterize human language evolution may
inform emergent communication in artificial agents."
SwinNet: Swin Transformer drives edge-aware RGB-D and RGB-T salient object detection,0.981684,"Convolutional neural networks (CNNs) are good at extracting contexture
features within certain receptive fields, while transformers can model the
global long-range dependency features. By absorbing the advantage of
transformer and the merit of CNN, Swin Transformer shows strong feature
representation ability. Based on it, we propose a cross-modality fusion model
SwinNet for RGB-D and RGB-T salient object detection. It is driven by Swin
Transformer to extract the hierarchical features, boosted by attention
mechanism to bridge the gap between two modalities, and guided by edge
information to sharp the contour of salient object. To be specific, two-stream
Swin Transformer encoder first extracts multi-modality features, and then
spatial alignment and channel re-calibration module is presented to optimize
intra-level cross-modality features. To clarify the fuzzy boundary, edge-guided
decoder achieves inter-level cross-modality fusion under the guidance of edge
features. The proposed model outperforms the state-of-the-art models on RGB-D
and RGB-T datasets, showing that it provides more insight into the
cross-modality complementarity task."
Why Does Surprisal From Larger Transformer-Based Language Models Provide a Poorer Fit to Human Reading Times?,0.184984,"This work presents a detailed linguistic analysis into why larger
Transformer-based pre-trained language models with more parameters and lower
perplexity nonetheless yield surprisal estimates that are less predictive of
human reading times. First, regression analyses show a strictly monotonic,
positive log-linear relationship between perplexity and fit to reading times
for the more recently released five GPT-Neo variants and eight OPT variants on
two separate datasets, replicating earlier results limited to just GPT-2 (Oh et
al., 2022). Subsequently, analysis of residual errors reveals a systematic
deviation of the larger variants, such as underpredicting reading times of
named entities and making compensatory overpredictions for reading times of
function words such as modals and conjunctions. These results suggest that the
propensity of larger Transformer-based models to 'memorize' sequences during
training makes their surprisal estimates diverge from humanlike expectations,
which warrants caution in using pre-trained language models to study human
language processing."
3D Common Corruptions and Data Augmentation,0.610361,"We introduce a set of image transformations that can be used as corruptions
to evaluate the robustness of models as well as data augmentation mechanisms
for training neural networks. The primary distinction of the proposed
transformations is that, unlike existing approaches such as Common Corruptions,
the geometry of the scene is incorporated in the transformations -- thus
leading to corruptions that are more likely to occur in the real world. We also
introduce a set of semantic corruptions (e.g. natural object occlusions). We
show these transformations are `efficient' (can be computed on-the-fly),
`extendable' (can be applied on most image datasets), expose vulnerability of
existing models, and can effectively make models more robust when employed as
`3D data augmentation' mechanisms. The evaluations on several tasks and
datasets suggest incorporating 3D information into benchmarking and training
opens up a promising direction for robustness research."
EmoDiff: Intensity Controllable Emotional Text-to-Speech with Soft-Label Guidance,0.401518,"Although current neural text-to-speech (TTS) models are able to generate
high-quality speech, intensity controllable emotional TTS is still a
challenging task. Most existing methods need external optimizations for
intensity calculation, leading to suboptimal results or degraded quality. In
this paper, we propose EmoDiff, a diffusion-based TTS model where emotion
intensity can be manipulated by a proposed soft-label guidance technique
derived from classifier guidance. Specifically, instead of being guided with a
one-hot vector for the specified emotion, EmoDiff is guided with a soft label
where the value of the specified emotion and \textit{Neutral} is set to
$\alpha$ and $1-\alpha$ respectively. The $\alpha$ here represents the emotion
intensity and can be chosen from 0 to 1. Our experiments show that EmoDiff can
precisely control the emotion intensity while maintaining high voice quality.
Moreover, diverse speech with specified emotion intensity can be generated by
sampling in the reverse denoising process."
Ham2Pose: Animating Sign Language Notation into Pose Sequences,0.467542,"Translating spoken languages into Sign languages is necessary for open
communication between the hearing and hearing-impaired communities. To achieve
this goal, we propose the first method for animating a text written in
HamNoSys, a lexical Sign language notation, into signed pose sequences. As
HamNoSys is universal by design, our proposed method offers a generic solution
invariant to the target Sign language. Our method gradually generates pose
predictions using transformer encoders that create meaningful representations
of the text and poses while considering their spatial and temporal information.
We use weak supervision for the training process and show that our method
succeeds in learning from partial and inaccurate data. Additionally, we offer a
new distance measurement that considers missing keypoints, to measure the
distance between pose sequences using DTW-MJE. We validate its correctness
using AUTSL, a large-scale Sign language dataset, show that it measures the
distance between pose sequences more accurately than existing measurements, and
use it to assess the quality of our generated pose sequences. Code for the data
pre-processing, the model, and the distance measurement is publicly released
for future research."
Dataset Distillation by Matching Training Trajectories,0.964366,"Dataset distillation is the task of synthesizing a small dataset such that a
model trained on the synthetic set will match the test accuracy of the model
trained on the full dataset. In this paper, we propose a new formulation that
optimizes our distilled data to guide networks to a similar state as those
trained on real data across many training steps. Given a network, we train it
for several iterations on our distilled data and optimize the distilled data
with respect to the distance between the synthetically trained parameters and
the parameters trained on real data. To efficiently obtain the initial and
target network parameters for large-scale datasets, we pre-compute and store
training trajectories of expert networks trained on the real dataset. Our
method handily outperforms existing methods and also allows us to distill
higher-resolution visual data."
Equivariant Self-Supervision for Musical Tempo Estimation,0.0590595,"Self-supervised methods have emerged as a promising avenue for representation
learning in the recent years since they alleviate the need for labeled
datasets, which are scarce and expensive to acquire. Contrastive methods are a
popular choice for self-supervision in the audio domain, and typically provide
a learning signal by forcing the model to be invariant to some transformations
of the input. These methods, however, require measures such as negative
sampling or some form of regularisation to be taken to prevent the model from
collapsing on trivial solutions. In this work, instead of invariance, we
propose to use equivariance as a self-supervision signal to learn audio tempo
representations from unlabelled data. We derive a simple loss function that
prevents the network from collapsing on a trivial solution during training,
without requiring any form of regularisation or negative sampling. Our
experiments show that it is possible to learn meaningful representations for
tempo estimation by solely relying on equivariant self-supervision, achieving
performance comparable with supervised methods on several benchmarks. As an
added benefit, our method only requires moderate compute resources and
therefore remains accessible to a wide research community."
LocalBins: Improving Depth Estimation by Learning Local Distributions,-1.0,"We propose a novel architecture for depth estimation from a single image. The
architecture itself is based on the popular encoder-decoder architecture that
is frequently used as a starting point for all dense regression tasks. We build
on AdaBins which estimates a global distribution of depth values for the input
image and evolve the architecture in two ways. First, instead of predicting
global depth distributions, we predict depth distributions of local
neighborhoods at every pixel. Second, instead of predicting depth distributions
only towards the end of the decoder, we involve all layers of the decoder. We
call this new architecture LocalBins. Our results demonstrate a clear
improvement over the state-of-the-art in all metrics on the NYU-Depth V2
dataset. Code and pretrained models will be made publicly available."
SGPT: GPT Sentence Embeddings for Semantic Search,0.508077,"Decoder transformers have continued increasing in scale reaching hundreds of
billions of parameters. Due to their scale the same decoder sets
state-of-the-art results on various language tasks via prompting or
fine-tuning. Yet, these large foundation models remain unusable for the related
fields of semantic search and sentence embeddings. This prevents possibly new
state-of-the-art results and forces organizations to train and maintain
separate models. To this end, we propose SGPT to use decoders for sentence
embeddings and semantic search via prompting or fine-tuning. At 5.8 billion
parameters SGPT improves on the previously best sentence embeddings by a margin
of 7% and outperforms a concurrent method with 175 billion parameters as
measured on the BEIR search benchmark. Code, models and result files are freely
available at https://github.com/Muennighoff/sgpt."
TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations at Twitter,0.178343,"Pre-trained language models (PLMs) are fundamental for natural language
processing applications. Most existing PLMs are not tailored to the noisy
user-generated text on social media, and the pre-training does not factor in
the valuable social engagement logs available in a social network. We present
TwHIN-BERT, a multilingual language model productionized at Twitter, trained on
in-domain data from the popular social network. TwHIN-BERT differs from prior
pre-trained language models as it is trained with not only text-based
self-supervision, but also with a social objective based on the rich social
engagements within a Twitter heterogeneous information network (TwHIN). Our
model is trained on 7 billion tweets covering over 100 distinct languages,
providing a valuable representation to model short, noisy, user-generated text.
We evaluate our model on various multilingual social recommendation and
semantic understanding tasks and demonstrate significant metric improvement
over established pre-trained language models. We open-source TwHIN-BERT and our
curated hashtag prediction and social engagement benchmark datasets to the
research community."
"Less Data, More Knowledge: Building Next Generation Semantic Communication Networks",0.443997,"Semantic communication is viewed as a revolutionary paradigm that can
potentially transform how we design and operate wireless communication systems.
However, despite a recent surge of research activities in this area, the
research landscape remains limited. In this tutorial, we present the first
rigorous vision of a scalable end-to-end semantic communication network that is
founded on novel concepts from artificial intelligence (AI), causal reasoning,
and communication theory. We first discuss how the design of semantic
communication networks requires a move from data-driven networks towards
knowledge-driven ones. Subsequently, we highlight the necessity of creating
semantic representations of data that satisfy the key properties of minimalism,
generalizability, and efficiency so as to do more with less. We then explain
how those representations can form the basis a so-called semantic language. By
using semantic representation and languages, we show that the traditional
transmitter and receiver now become a teacher and apprentice. Then, we define
the concept of reasoning by investigating the fundamentals of causal
representation learning and their role in designing semantic communication
networks. We demonstrate that reasoning faculties are majorly characterized by
the ability to capture causal and associational relationships in datastreams.
For such reasoning-driven networks, we propose novel and essential semantic
communication metrics that include new ""reasoning capacity"" measures that could
go beyond Shannon's bound to capture the convergence of computing and
communication. Finally, we explain how semantic communications can be scaled to
large-scale networks (6G and beyond). In a nutshell, we expect this tutorial to
provide a comprehensive reference on how to properly build, analyze, and deploy
future semantic communication networks."
Stop Wasting My Time! Saving Days of ImageNet and BERT Training with Latest Weight Averaging,0.0982916,"Training vision or language models on large datasets can take days, if not
weeks. We show that averaging the weights of the k latest checkpoints, each
collected at the end of an epoch, can speed up the training progression in
terms of loss and accuracy by dozens of epochs, corresponding to time savings
up to ~68 and ~30 GPU hours when training a ResNet50 on ImageNet and
RoBERTa-Base model on WikiText-103, respectively. We also provide the code and
model checkpoint trajectory to reproduce the results and facilitate research on
reusing historical weights for faster convergence."
"The Better Your Syntax, the Better Your Semantics? Probing Pretrained Language Models for the English Comparative Correlative",0.111428,"Construction Grammar (CxG) is a paradigm from cognitive linguistics
emphasising the connection between syntax and semantics. Rather than rules that
operate on lexical items, it posits constructions as the central building
blocks of language, i.e., linguistic units of different granularity that
combine syntax and semantics. As a first step towards assessing the
compatibility of CxG with the syntactic and semantic knowledge demonstrated by
state-of-the-art pretrained language models (PLMs), we present an investigation
of their capability to classify and understand one of the most commonly studied
constructions, the English comparative correlative (CC). We conduct experiments
examining the classification accuracy of a syntactic probe on the one hand and
the models' behaviour in a semantic application task on the other, with BERT,
RoBERTa, and DeBERTa as the example PLMs. Our results show that all three
investigated PLMs are able to recognise the structure of the CC but fail to use
its meaning. While human-like performance of PLMs on many NLP tasks has been
alleged, this indicates that PLMs still suffer from substantial shortcomings in
central domains of linguistic knowledge."
Restoring Vision in Adverse Weather Conditions with Patch-Based Denoising Diffusion Models,0.566874,"Image restoration under adverse weather conditions has been of significant
interest for various computer vision applications. Recent successful methods
rely on the current progress in deep neural network architectural designs
(e.g., with vision transformers). Motivated by the recent progress achieved
with state-of-the-art conditional generative models, we present a novel
patch-based image restoration algorithm based on denoising diffusion
probabilistic models. Our patch-based diffusion modeling approach enables
size-agnostic image restoration by using a guided denoising process with
smoothed noise estimates across overlapping patches during inference. We
empirically evaluate our model on benchmark datasets for image desnowing,
combined deraining and dehazing, and raindrop removal. We demonstrate our
approach to achieve state-of-the-art performances on both weather-specific and
multi-weather image restoration, and experimentally show strong generalization
to real-world test images."
Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought,0.902191,"Large language models (LLMs) have shown remarkable reasoning capabilities
given chain-of-thought prompts (examples with intermediate reasoning steps).
Existing benchmarks measure reasoning ability indirectly, by evaluating
accuracy on downstream tasks such as mathematical reasoning. However, it is
unclear how these models obtain the answers and whether they rely on simple
heuristics rather than the generated chain-of-thought. To enable systematic
exploration of the reasoning ability of LLMs, we present a new synthetic
question-answering dataset called PrOntoQA, where each example is generated
from a synthetic world model represented in first-order logic. This allows us
to parse the generated chain-of-thought into symbolic proofs for formal
analysis. Our analysis on InstructGPT and GPT-3 shows that LLMs are quite
capable of making correct individual deduction steps, and so are generally
capable of reasoning, even in fictional contexts. However, they have difficulty
with proof planning: When multiple valid deduction steps are available, they
are not able to systematically explore the different options."
Masked Generative Distillation,0.989691,"Knowledge distillation has been applied to various tasks successfully. The
current distillation algorithm usually improves students' performance by
imitating the output of the teacher. This paper shows that teachers can also
improve students' representation power by guiding students' feature recovery.
From this point of view, we propose Masked Generative Distillation (MGD), which
is simple: we mask random pixels of the student's feature and force it to
generate the teacher's full feature through a simple block. MGD is a truly
general feature-based distillation method, which can be utilized on various
tasks, including image classification, object detection, semantic segmentation
and instance segmentation. We experiment on different models with extensive
datasets and the results show that all the students achieve excellent
improvements. Notably, we boost ResNet-18 from 69.90% to 71.69% ImageNet top-1
accuracy, RetinaNet with ResNet-50 backbone from 37.4 to 41.0 Boundingbox mAP,
SOLO based on ResNet-50 from 33.1 to 36.2 Mask mAP and DeepLabV3 based on
ResNet-18 from 73.20 to 76.02 mIoU. Our codes are available at
https://github.com/yzd-v/MGD."
Distantly Supervised Named Entity Recognition via Confidence-Based Multi-Class Positive and Unlabeled Learning,0.119566,"In this paper, we study the named entity recognition (NER) problem under
distant supervision. Due to the incompleteness of the external dictionaries
and/or knowledge bases, such distantly annotated training data usually suffer
from a high false negative rate. To this end, we formulate the Distantly
Supervised NER (DS-NER) problem via Multi-class Positive and Unlabeled (MPU)
learning and propose a theoretically and practically novel CONFidence-based MPU
(Conf-MPU) approach. To handle the incomplete annotations, Conf-MPU consists of
two steps. First, a confidence score is estimated for each token of being an
entity token. Then, the proposed Conf-MPU risk estimation is applied to train a
multi-class classifier for the NER task. Thorough experiments on two benchmark
datasets labeled by various external knowledge demonstrate the superiority of
the proposed Conf-MPU over existing DS-NER methods."
Bi-PointFlowNet: Bidirectional Learning for Point Cloud Based Scene Flow Estimation,0.52901,"Scene flow estimation, which extracts point-wise motion between scenes, is
becoming a crucial task in many computer vision tasks. However, all of the
existing estimation methods utilize only the unidirectional features,
restricting the accuracy and generality. This paper presents a novel scene flow
estimation architecture using bidirectional flow embedding layers. The proposed
bidirectional layer learns features along both forward and backward directions,
enhancing the estimation performance. In addition, hierarchical feature
extraction and warping improve the performance and reduce computational
overhead. Experimental results show that the proposed architecture achieved a
new state-of-the-art record by outperforming other approaches with large margin
in both FlyingThings3D and KITTI benchmarks. Codes are available at
https://github.com/cwc1260/BiFlow."
Balancing Discriminability and Transferability for Source-Free Domain Adaptation,0.18218,"Conventional domain adaptation (DA) techniques aim to improve domain
transferability by learning domain-invariant representations; while
concurrently preserving the task-discriminability knowledge gathered from the
labeled source data. However, the requirement of simultaneous access to labeled
source and unlabeled target renders them unsuitable for the challenging
source-free DA setting. The trivial solution of realizing an effective original
to generic domain mapping improves transferability but degrades task
discriminability. Upon analyzing the hurdles from both theoretical and
empirical standpoints, we derive novel insights to show that a mixup between
original and corresponding translated generic samples enhances the
discriminability-transferability trade-off while duly respecting the
privacy-oriented source-free setting. A simple but effective realization of the
proposed insights on top of the existing source-free DA approaches yields
state-of-the-art performance with faster convergence. Beyond single-source, we
also outperform multi-source prior-arts across both classification and semantic
segmentation benchmarks."
NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages,0.323579,"Natural language processing (NLP) has a significant impact on society via
technologies such as machine translation and search engines. Despite its
success, NLP technology is only widely available for high-resource languages
such as English and Chinese, while it remains inaccessible to many languages
due to the unavailability of data resources and benchmarks. In this work, we
focus on developing resources for languages in Indonesia. Despite being the
second most linguistically diverse country, most languages in Indonesia are
categorized as endangered and some are even extinct. We develop the first-ever
parallel resource for 10 low-resource languages in Indonesia. Our resource
includes datasets, a multi-task benchmark, and lexicons, as well as a parallel
Indonesian-English dataset. We provide extensive analyses and describe the
challenges when creating such resources. We hope that our work can spark NLP
research on Indonesian and other underrepresented languages."
TRUST XAI: Model-Agnostic Explanations for AI With a Case Study on IIoT Security,0.62827,"Despite AI's significant growth, its ""black box"" nature creates challenges in
generating adequate trust. Thus, it is seldom utilized as a standalone unit in
IoT high-risk applications, such as critical industrial infrastructures,
medical systems, and financial applications, etc. Explainable AI (XAI) has
emerged to help with this problem. However, designing appropriately fast and
accurate XAI is still challenging, especially in numerical applications. Here,
we propose a universal XAI model named Transparency Relying Upon Statistical
Theory (TRUST), which is model-agnostic, high-performing, and suitable for
numerical applications. Simply put, TRUST XAI models the statistical behavior
of the AI's outputs in an AI-based system. Factor analysis is used to transform
the input features into a new set of latent variables. We use mutual
information to rank these variables and pick only the most influential ones on
the AI's outputs and call them ""representatives"" of the classes. Then we use
multi-modal Gaussian distributions to determine the likelihood of any new
sample belonging to each class. We demonstrate the effectiveness of TRUST in a
case study on cybersecurity of the industrial Internet of things (IIoT) using
three different cybersecurity datasets. As IIoT is a prominent application that
deals with numerical data. The results show that TRUST XAI provides
explanations for new random samples with an average success rate of 98%.
Compared with LIME, a popular XAI model, TRUST is shown to be superior in the
context of performance, speed, and the method of explainability. In the end, we
also show how TRUST is explained to the user."
Training Language Models with Memory Augmentation,0.757998,"Recent work has improved language models (LMs) remarkably by equipping them
with a non-parametric memory component. However, most existing approaches only
introduce mem-ories at testing time or represent them using a separately
trained encoder, resulting in suboptimal training of the language model. In
this work, we present TRIME, a novel yet simple training approach designed for
training LMs with memory augmentation. Our approach uses a training objective
that directly takes in-batch examples as accessible memory. We also present new
methods for memory construction and data batching, which are used for adapting
to different sets of memories--local, long-term, and external memory--at
testing time. We evaluate TRIME on multiple language modeling and machine
translation benchmarks and show that it is able to achieve significant
improvements across all the settings. Concretely, TRIME reduces the perplexity
from 18.70 to 15.37 on WIKITEXT-103, by effectively leveraging a large memory
set from the training corpus. Compared to standard LM training, TRIME adds
negligible computational overhead and is compatible with different neural
architectures, making it a versatile solution for training memory-augmented
LMs."
Quantifying Privacy Risks of Masked Language Models Using Membership Inference Attacks,0.619979,"The wide adoption and application of Masked language models~(MLMs) on
sensitive data (from legal to medical) necessitates a thorough quantitative
investigation into their privacy vulnerabilities -- to what extent do MLMs leak
information about their training data? Prior attempts at measuring leakage of
MLMs via membership inference attacks have been inconclusive, implying the
potential robustness of MLMs to privacy attacks. In this work, we posit that
prior attempts were inconclusive because they based their attack solely on the
MLM's model score. We devise a stronger membership inference attack based on
likelihood ratio hypothesis testing that involves an additional reference MLM
to more accurately quantify the privacy risks of memorization in MLMs. We show
that masked language models are extremely susceptible to likelihood ratio
membership inference attacks: Our empirical results, on models trained on
medical notes, show that our attack improves the AUC of prior membership
inference attacks from 0.66 to an alarmingly high 0.90 level, with a
significant improvement in the low-error region: at 1% false positive rate, our
attack is 51X more powerful than prior work."
Shadow-Background-Noise 3D Spatial Decomposition Using Sparse Low-Rank Gaussian Properties for Video-SAR Moving Target Shadow Enhancement,0.483617,"Moving target shadows among video synthetic aperture radar (Video-SAR) images
are always interfered by low scattering backgrounds and cluttered noises,
causing poor detec-tion-tracking accuracy. Thus, a shadow-background-noise 3D
spatial decomposition (SBN-3D-SD) model is proposed to enhance shadows for
higher detection-tracking accuracy. It leverages the sparse property of
shadows, the low-rank property of back-grounds, and the Gaussian property of
noises to perform 3D spatial three-decomposition. It separates shadows from
back-grounds and noises by the alternating direction method of multi-pliers
(ADMM). Results on the Sandia National Laboratories (SNL) data verify its
effectiveness. It boosts the shadow saliency from the qualitative and
quantitative evaluation. It boosts the shadow detection accuracy of Faster
R-CNN, RetinaNet and YOLOv3. It also boosts the shadow tracking accuracy of
TransTrack, FairMOT and ByteTrack."
LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding,0.78243,"Structured document understanding has attracted considerable attention and
made significant progress recently, owing to its crucial role in intelligent
document processing. However, most existing related models can only deal with
the document data of specific language(s) (typically English) included in the
pre-training collection, which is extremely limited. To address this issue, we
propose a simple yet effective Language-independent Layout Transformer (LiLT)
for structured document understanding. LiLT can be pre-trained on the
structured documents of a single language and then directly fine-tuned on other
languages with the corresponding off-the-shelf monolingual/multilingual
pre-trained textual models. Experimental results on eight languages have shown
that LiLT can achieve competitive or even superior performance on diverse
widely-used downstream benchmarks, which enables language-independent benefit
from the pre-training of document layout structure. Code and model are publicly
available at https://github.com/jpWang/LiLT."
Human Evaluation and Correlation with Automatic Metrics in Consultation Note Generation,0.205546,"In recent years, machine learning models have rapidly become better at
generating clinical consultation notes; yet, there is little work on how to
properly evaluate the generated consultation notes to understand the impact
they may have on both the clinician using them and the patient's clinical
safety. To address this we present an extensive human evaluation study of
consultation notes where 5 clinicians (i) listen to 57 mock consultations, (ii)
write their own notes, (iii) post-edit a number of automatically generated
notes, and (iv) extract all the errors, both quantitative and qualitative. We
then carry out a correlation study with 18 automatic quality metrics and the
human judgements. We find that a simple, character-based Levenshtein distance
metric performs on par if not better than common model-based metrics like
BertScore. All our findings and annotations are open-sourced."
Towards Unified Conversational Recommender Systems via Knowledge-Enhanced Prompt Learning,0.474729,"Conversational recommender systems (CRS) aim to proactively elicit user
preference and recommend high-quality items through natural language
conversations. Typically, a CRS consists of a recommendation module to predict
preferred items for users and a conversation module to generate appropriate
responses. To develop an effective CRS, it is essential to seamlessly integrate
the two modules. Existing works either design semantic alignment strategies, or
share knowledge resources and representations between the two modules. However,
these approaches still rely on different architectures or techniques to develop
the two modules, making it difficult for effective module integration.
  To address this problem, we propose a unified CRS model named UniCRS based on
knowledge-enhanced prompt learning. Our approach unifies the recommendation and
conversation subtasks into the prompt learning paradigm, and utilizes
knowledge-enhanced prompts based on a fixed pre-trained language model (PLM) to
fulfill both subtasks in a unified approach. In the prompt design, we include
fused knowledge representations, task-specific soft tokens, and the dialogue
context, which can provide sufficient contextual information to adapt the PLM
for the CRS task. Besides, for the recommendation subtask, we also incorporate
the generated response template as an important part of the prompt, to enhance
the information interaction between the two subtasks. Extensive experiments on
two public CRS datasets have demonstrated the effectiveness of our approach."
Event knowledge in large language models: the gap between the impossible and the unlikely,0.1312,"Word co-occurrence patterns in language corpora contain a surprising amount
of conceptual knowledge. Large language models (LLMs), trained to predict words
in context, leverage these patterns to achieve impressive performance on
diverse semantic tasks requiring world knowledge. An important but understudied
question about LLMs' semantic abilities is whether they acquire generalized
knowledge of common events. Here, we test whether five pre-trained LLMs (from
2018's BERT to 2023's MPT) assign higher likelihood to plausible descriptions
of agent-patient interactions than to minimally different implausible versions
of the same event. Using three curated sets of minimal sentence pairs (total
n=1,215), we found that pre-trained LLMs possess substantial event knowledge,
outperforming other distributional language models. In particular, they almost
always assign higher likelihood to possible vs. impossible events (The teacher
bought the laptop vs. The laptop bought the teacher). However, LLMs show less
consistent preferences for likely vs. unlikely events (The nanny tutored the
boy vs. The boy tutored the nanny). In follow-up analyses, we show that (i) LLM
scores are driven by both plausibility and surface-level sentence features,
(ii) LLM scores generalize well across syntactic variants (active vs. passive
constructions) but less well across semantic variants (synonymous sentences),
(iii) some LLM errors mirror human judgment ambiguity, and (iv) sentence
plausibility serves as an organizing dimension in internal LLM representations.
Overall, our results show that important aspects of event knowledge naturally
emerge from distributional linguistic patterns, but also highlight a gap
between representations of possible/impossible and likely/unlikely events."
Repairing Bugs in Python Assignments Using Large Language Models,0.642346,"Students often make mistakes on their introductory programming assignments as
part of their learning process. Unfortunately, providing custom repairs for
these mistakes can require a substantial amount of time and effort from class
instructors. Automated program repair (APR) techniques can be used to
synthesize such fixes. Prior work has explored the use of symbolic and neural
techniques for APR in the education domain. Both types of approaches require
either substantial engineering efforts or large amounts of data and training.
We propose to use a large language model trained on code, such as Codex, to
build an APR system -- MMAPR -- for introductory Python programming
assignments. Our system can fix both syntactic and semantic mistakes by
combining multi-modal prompts, iterative querying, test-case-based selection of
few-shots, and program chunking. We evaluate MMAPR on 286 real student programs
and compare to a baseline built by combining a state-of-the-art Python syntax
repair engine, BIFI, and state-of-the-art Python semantic repair engine for
student assignments, Refactory. We find that MMAPR can fix more programs and
produce smaller patches on average."
Perceiver-Actor: A Multi-Task Transformer for Robotic Manipulation,0.739853,"Transformers have revolutionized vision and natural language processing with
their ability to scale with large datasets. But in robotic manipulation, data
is both limited and expensive. Can manipulation still benefit from Transformers
with the right problem formulation? We investigate this question with PerAct, a
language-conditioned behavior-cloning agent for multi-task 6-DoF manipulation.
PerAct encodes language goals and RGB-D voxel observations with a Perceiver
Transformer, and outputs discretized actions by ``detecting the next best voxel
action''. Unlike frameworks that operate on 2D images, the voxelized 3D
observation and action space provides a strong structural prior for efficiently
learning 6-DoF actions. With this formulation, we train a single multi-task
Transformer for 18 RLBench tasks (with 249 variations) and 7 real-world tasks
(with 18 variations) from just a few demonstrations per task. Our results show
that PerAct significantly outperforms unstructured image-to-action agents and
3D ConvNet baselines for a wide range of tabletop tasks."
MISC: A MIxed Strategy-Aware Model Integrating COMET for Emotional Support Conversation,0.480304,"Applying existing methods to emotional support conversation -- which provides
valuable assistance to people who are in need -- has two major limitations: (a)
they generally employ a conversation-level emotion label, which is too
coarse-grained to capture user's instant mental state; (b) most of them focus
on expressing empathy in the response(s) rather than gradually reducing user's
distress. To address the problems, we propose a novel model \textbf{MISC},
which firstly infers the user's fine-grained emotional status, and then
responds skillfully using a mixture of strategy. Experimental results on the
benchmark dataset demonstrate the effectiveness of our method and reveal the
benefits of fine-grained emotion understanding as well as mixed-up strategy
modeling. Our code and data could be found in
\url{https://github.com/morecry/MISC}."
Transformer-based SAR Image Despeckling,0.424057,"Synthetic Aperture Radar (SAR) images are usually degraded by a
multiplicative noise known as speckle which makes processing and interpretation
of SAR images difficult. In this paper, we introduce a transformer-based
network for SAR image despeckling. The proposed despeckling network comprises
of a transformer-based encoder which allows the network to learn global
dependencies between different image regions - aiding in better despeckling.
The network is trained end-to-end with synthetically generated speckled images
using a composite loss function. Experiments show that the proposed method
achieves significant improvements over traditional and convolutional neural
network-based despeckling methods on both synthetic and real SAR images."
Grammar-Based Grounded Lexicon Learning,0.156944,"We present Grammar-Based Grounded Lexicon Learning (G2L2), a lexicalist
approach toward learning a compositional and grounded meaning representation of
language from grounded data, such as paired images and texts. At the core of
G2L2 is a collection of lexicon entries, which map each word to a tuple of a
syntactic type and a neuro-symbolic semantic program. For example, the word
shiny has a syntactic type of adjective; its neuro-symbolic semantic program
has the symbolic form {\lambda}x. filter(x, SHINY), where the concept SHINY is
associated with a neural network embedding, which will be used to classify
shiny objects. Given an input sentence, G2L2 first looks up the lexicon entries
associated with each token. It then derives the meaning of the sentence as an
executable neuro-symbolic program by composing lexical meanings based on
syntax. The recovered meaning programs can be executed on grounded inputs. To
facilitate learning in an exponentially-growing compositional space, we
introduce a joint parsing and expected execution algorithm, which does local
marginalization over derivations to reduce the training time. We evaluate G2L2
on two domains: visual reasoning and language-driven navigation. Results show
that G2L2 can generalize from small amounts of data to novel compositions of
words."
LineCap: Line Charts for Data Visualization Captioning Models,-1.0,"Data visualization captions help readers understand the purpose of a
visualization and are crucial for individuals with visual impairments. The
prevalence of poor figure captions and the successful application of deep
learning approaches to image captioning motivate the use of similar techniques
for automated figure captioning. However, research in this field has been
stunted by the lack of suitable datasets. We introduce LineCap, a novel figure
captioning dataset of 3,528 figures, and we provide insights from curating this
dataset and using end-to-end deep learning models for automated figure
captioning."
SeedFormer: Patch Seeds based Point Cloud Completion with Upsample Transformer,0.346647,"Point cloud completion has become increasingly popular among generation tasks
of 3D point clouds, as it is a challenging yet indispensable problem to recover
the complete shape of a 3D object from its partial observation. In this paper,
we propose a novel SeedFormer to improve the ability of detail preservation and
recovery in point cloud completion. Unlike previous methods based on a global
feature vector, we introduce a new shape representation, namely Patch Seeds,
which not only captures general structures from partial inputs but also
preserves regional information of local patterns. Then, by integrating seed
features into the generation process, we can recover faithful details for
complete point clouds in a coarse-to-fine manner. Moreover, we devise an
Upsample Transformer by extending the transformer structure into basic
operations of point generators, which effectively incorporates spatial and
semantic relationships between neighboring points. Qualitative and quantitative
evaluations demonstrate that our method outperforms state-of-the-art completion
networks on several benchmark datasets. Our code is available at
https://github.com/hrzhou2/seedformer."
PropSegmEnt: A Large-Scale Corpus for Proposition-Level Segmentation and Entailment Recognition,0.0424101,"The widely studied task of Natural Language Inference (NLI) requires a system
to recognize whether one piece of text is textually entailed by another, i.e.
whether the entirety of its meaning can be inferred from the other. In current
NLI datasets and models, textual entailment relations are typically defined on
the sentence- or paragraph-level. However, even a simple sentence often
contains multiple propositions, i.e. distinct units of meaning conveyed by the
sentence. As these propositions can carry different truth values in the context
of a given premise, we argue for the need to recognize the textual entailment
relation of each proposition in a sentence individually.
  We propose PropSegmEnt, a corpus of over 45K propositions annotated by expert
human raters. Our dataset structure resembles the tasks of (1) segmenting
sentences within a document to the set of propositions, and (2) classifying the
entailment relation of each proposition with respect to a different yet
topically-aligned document, i.e. documents describing the same event or entity.
We establish strong baselines for the segmentation and entailment tasks.
Through case studies on summary hallucination detection and document-level NLI,
we demonstrate that our conceptual framework is potentially useful for
understanding and explaining the compositionality of NLI labels."
SDF-StyleGAN: Implicit SDF-Based StyleGAN for 3D Shape Generation,0.970239,"We present a StyleGAN2-based deep learning approach for 3D shape generation,
called SDF-StyleGAN, with the aim of reducing visual and geometric
dissimilarity between generated shapes and a shape collection. We extend
StyleGAN2 to 3D generation and utilize the implicit signed distance function
(SDF) as the 3D shape representation, and introduce two novel global and local
shape discriminators that distinguish real and fake SDF values and gradients to
significantly improve shape geometry and visual quality. We further complement
the evaluation metrics of 3D generative models with the shading-image-based
Fr\'echet inception distance (FID) scores to better assess visual quality and
shape distribution of the generated shapes. Experiments on shape generation
demonstrate the superior performance of SDF-StyleGAN over the state-of-the-art.
We further demonstrate the efficacy of SDF-StyleGAN in various tasks based on
GAN inversion, including shape reconstruction, shape completion from partial
point clouds, single-view image-based shape generation, and shape style
editing. Extensive ablation studies justify the efficacy of our framework
design. Our code and trained models are available at
https://github.com/Zhengxinyang/SDF-StyleGAN."
VALHALLA: Visual Hallucination for Machine Translation,0.251167,"Designing better machine translation systems by considering auxiliary inputs
such as images has attracted much attention in recent years. While existing
methods show promising performance over the conventional text-only translation
systems, they typically require paired text and image as input during
inference, which limits their applicability to real-world scenarios. In this
paper, we introduce a visual hallucination framework, called VALHALLA, which
requires only source sentences at inference time and instead uses hallucinated
visual representations for multimodal machine translation. In particular, given
a source sentence an autoregressive hallucination transformer is used to
predict a discrete visual representation from the input text, and the combined
text and hallucinated representations are utilized to obtain the target
translation. We train the hallucination transformer jointly with the
translation transformer using standard backpropagation with cross-entropy
losses while being guided by an additional loss that encourages consistency
between predictions using either ground-truth or hallucinated visual
representations. Extensive experiments on three standard translation datasets
with a diverse set of language pairs demonstrate the effectiveness of our
approach over both text-only baselines and state-of-the-art methods. Project
page: http://www.svcl.ucsd.edu/projects/valhalla."
CtlGAN: Few-shot Artistic Portraits Generation with Contrastive Transfer Learning,0.107396,"Generating artistic portraits is a challenging problem in computer vision.
Existing portrait stylization models that generate good quality results are
based on Image-to-Image Translation and require abundant data from both source
and target domains. However, without enough data, these methods would result in
overfitting. In this work, we propose CtlGAN, a new few-shot artistic portraits
generation model with a novel contrastive transfer learning strategy. We adapt
a pretrained StyleGAN in the source domain to a target artistic domain with no
more than 10 artistic faces. To reduce overfitting to the few training
examples, we introduce a novel Cross-Domain Triplet loss which explicitly
encourages the target instances generated from different latent codes to be
distinguishable. We propose a new encoder which embeds real faces into Z+ space
and proposes a dual-path training strategy to better cope with the adapted
decoder and eliminate the artifacts. Extensive qualitative, quantitative
comparisons and a user study show our method significantly outperforms
state-of-the-arts under 10-shot and 1-shot settings and generates high quality
artistic portraits. The code will be made publicly available."
A Span-level Bidirectional Network for Aspect Sentiment Triplet Extraction,0.499575,"Aspect Sentiment Triplet Extraction (ASTE) is a new fine-grained sentiment
analysis task that aims to extract triplets of aspect terms, sentiments, and
opinion terms from review sentences. Recently, span-level models achieve
gratifying results on ASTE task by taking advantage of the predictions of all
possible spans. Since all possible spans significantly increases the number of
potential aspect and opinion candidates, it is crucial and challenging to
efficiently extract the triplet elements among them. In this paper, we present
a span-level bidirectional network which utilizes all possible spans as input
and extracts triplets from spans bidirectionally. Specifically, we devise both
the aspect decoder and opinion decoder to decode the span representations and
extract triples from aspect-to-opinion and opinion-to-aspect directions. With
these two decoders complementing with each other, the whole network can extract
triplets from spans more comprehensively. Moreover, considering that mutual
exclusion cannot be guaranteed between the spans, we design a similar span
separation loss to facilitate the downstream task of distinguishing the correct
span by expanding the KL divergence of similar spans during the training
process; in the inference process, we adopt an inference strategy to remove
conflicting triplets from the results base on their confidence scores.
Experimental results show that our framework not only significantly outperforms
state-of-the-art methods, but achieves better performance in predicting
triplets with multi-token entities and extracting triplets in sentences contain
multi-triplets."
Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind,0.0561353,"When reading a story, humans can quickly understand new fictional characters
with a few observations, mainly by drawing analogies to fictional and real
people they already know. This reflects the few-shot and meta-learning essence
of humans' inference of characters' mental states, i.e., theory-of-mind (ToM),
which is largely ignored in existing research. We fill this gap with a novel
NLP dataset, ToM-in-AMC, the first assessment of machines' meta-learning of ToM
in a realistic narrative understanding scenario. Our dataset consists of ~1,000
parsed movie scripts, each corresponding to a few-shot character understanding
task that requires models to mimic humans' ability of fast digesting characters
with a few starting scenes in a new movie.
  We propose a novel ToM prompting approach designed to explicitly assess the
influence of multiple ToM dimensions. It surpasses existing baseline models,
underscoring the significance of modeling multiple ToM dimensions for our task.
Our extensive human study verifies that humans are capable of solving our
problem by inferring characters' mental states based on their previously seen
movies. In comparison, our systems based on either state-of-the-art large
language models (GPT-4) or meta-learning algorithms lags >20% behind,
highlighting a notable limitation in existing approaches' ToM capabilities."
ProsocialDialog: A Prosocial Backbone for Conversational Agents,0.521271,"Most existing dialogue systems fail to respond properly to potentially unsafe
user utterances by either ignoring or passively agreeing with them. To address
this issue, we introduce ProsocialDialog, the first large-scale multi-turn
dialogue dataset to teach conversational agents to respond to problematic
content following social norms. Covering diverse unethical, problematic,
biased, and toxic situations, ProsocialDialog contains responses that encourage
prosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb,
RoTs). Created via a human-AI collaborative framework, ProsocialDialog consists
of 58K dialogues, with 331K utterances, 160K unique RoTs, and 497K dialogue
safety labels accompanied by free-form rationales.
  With this dataset, we introduce a dialogue safety detection module, Canary,
capable of generating RoTs given conversational context, and a
socially-informed dialogue agent, Prost. Empirical results show that Prost
generates more socially acceptable dialogues compared to other state-of-the-art
language and dialogue models in both in-domain and out-of-domain settings.
Additionally, Canary effectively guides conversational agents and off-the-shelf
language models to generate significantly more prosocial responses. Our work
highlights the promise and importance of creating and steering conversational
AI to be socially responsible."
Variable Bitrate Neural Fields,0.68203,"Neural approximations of scalar and vector fields, such as signed distance
functions and radiance fields, have emerged as accurate, high-quality
representations. State-of-the-art results are obtained by conditioning a neural
approximation with a lookup from trainable feature grids that take on part of
the learning task and allow for smaller, more efficient neural networks.
Unfortunately, these feature grids usually come at the cost of significantly
increased memory consumption compared to stand-alone neural network models. We
present a dictionary method for compressing such feature grids, reducing their
memory consumption by up to 100x and permitting a multiresolution
representation which can be useful for out-of-core streaming. We formulate the
dictionary optimization as a vector-quantized auto-decoder problem which lets
us learn end-to-end discrete neural representations in a space where no direct
supervision is available and with dynamic topology and structure. Our source
code will be available at https://github.com/nv-tlabs/vqad."
Can language models handle recursively nested grammatical structures? A case study on comparing models and humans,0.258604,"How should we compare the capabilities of language models (LMs) and humans? I
draw inspiration from comparative psychology to highlight some challenges. In
particular, I consider a case study: processing of recursively nested
grammatical structures. Prior work suggests that LMs cannot handle these
structures as reliably as humans can. However, the humans were provided with
instructions and training, while the LMs were evaluated zero-shot. I therefore
match the evaluation more closely. Providing large LMs with a simple prompt --
substantially less content than the human training -- allows the LMs to
consistently outperform the human results, and even to extrapolate to more
deeply nested conditions than were tested with humans. Further, reanalyzing the
prior human data suggests that the humans may not perform above chance at the
difficult structures initially. Thus, large LMs may indeed process recursively
nested grammatical structures as reliably as humans. This case study highlights
how discrepancies in the evaluation can confound comparisons of language models
and humans. I therefore reflect on the broader challenge of comparing human and
model capabilities, and highlight an important difference between evaluating
cognitive models and foundation models."
E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text,0.10811,"Identifying named entities such as a person, location or organization, in
documents can highlight key information to readers. Training Named Entity
Recognition (NER) models requires an annotated data set, which can be a
time-consuming labour-intensive task. Nevertheless, there are publicly
available NER data sets for general English. Recently there has been interest
in developing NER for legal text. However, prior work and experimental results
reported here indicate that there is a significant degradation in performance
when NER methods trained on a general English data set are applied to legal
text. We describe a publicly available legal NER data set, called E-NER, based
on legal company filings available from the US Securities and Exchange
Commission's EDGAR data set. Training a number of different NER algorithms on
the general English CoNLL-2003 corpus but testing on our test collection
confirmed significant degradations in accuracy, as measured by the F1-score, of
between 29.4\% and 60.4\%, compared to training and testing on the E-NER
collection."
polyBERT: A chemical language model to enable fully machine-driven ultrafast polymer informatics,0.202677,"Polymers are a vital part of everyday life. Their chemical universe is so
large that it presents unprecedented opportunities as well as significant
challenges to identify suitable application-specific candidates. We present a
complete end-to-end machine-driven polymer informatics pipeline that can search
this space for suitable candidates at unprecedented speed and accuracy. This
pipeline includes a polymer chemical fingerprinting capability called polyBERT
(inspired by Natural Language Processing concepts), and a multitask learning
approach that maps the polyBERT fingerprints to a host of properties. polyBERT
is a chemical linguist that treats the chemical structure of polymers as a
chemical language. The present approach outstrips the best presently available
concepts for polymer property prediction based on handcrafted fingerprint
schemes in speed by two orders of magnitude while preserving accuracy, thus
making it a strong candidate for deployment in scalable architectures including
cloud infrastructures."
Multimodal Token Fusion for Vision Transformers,0.589839,"Many adaptations of transformers have emerged to address the single-modal
vision tasks, where self-attention modules are stacked to handle input sources
like images. Intuitively, feeding multiple modalities of data to vision
transformers could improve the performance, yet the inner-modal attentive
weights may also be diluted, which could thus undermine the final performance.
In this paper, we propose a multimodal token fusion method (TokenFusion),
tailored for transformer-based vision tasks. To effectively fuse multiple
modalities, TokenFusion dynamically detects uninformative tokens and
substitutes these tokens with projected and aggregated inter-modal features.
Residual positional alignment is also adopted to enable explicit utilization of
the inter-modal alignments after fusion. The design of TokenFusion allows the
transformer to learn correlations among multimodal features, while the
single-modal transformer architecture remains largely intact. Extensive
experiments are conducted on a variety of homogeneous and heterogeneous
modalities and demonstrate that TokenFusion surpasses state-of-the-art methods
in three typical vision tasks: multimodal image-to-image translation, RGB-depth
semantic segmentation, and 3D object detection with point cloud and images. Our
code is available at https://github.com/yikaiw/TokenFusion."
Pointillism: Accurate 3D bounding box estimation with multi-radars,0.50552,"Autonomous perception requires high-quality environment sensing in the form
of 3D bounding boxes of dynamic objects. The primary sensors used in automotive
systems are light-based cameras and LiDARs. However, they are known to fail in
adverse weather conditions. Radars can potentially solve this problem as they
are barely affected by adverse weather conditions. However, specular
reflections of wireless signals cause poor performance of radar point clouds.
We introduce Pointillism, a system that combines data from multiple spatially
separated radars with an optimal separation to mitigate these problems. We
introduce a novel concept of Cross Potential Point Clouds, which uses the
spatial diversity induced by multiple radars and solves the problem of noise
and sparsity in radar point clouds. Furthermore, we present the design of
RP-net, a novel deep learning architecture, designed explicitly for radar's
sparse data distribution, to enable accurate 3D bounding box estimation. The
spatial techniques designed and proposed in this paper are fundamental to
radars point cloud distribution and would benefit other radar sensing
applications."
Online Continual Learning for Embedded Devices,0.396486,"Real-time on-device continual learning is needed for new applications such as
home robots, user personalization on smartphones, and augmented/virtual reality
headsets. However, this setting poses unique challenges: embedded devices have
limited memory and compute capacity and conventional machine learning models
suffer from catastrophic forgetting when updated on non-stationary data
streams. While several online continual learning models have been developed,
their effectiveness for embedded applications has not been rigorously studied.
In this paper, we first identify criteria that online continual learners must
meet to effectively perform real-time, on-device learning. We then study the
efficacy of several online continual learning methods when used with mobile
neural networks. We measure their performance, memory usage, compute
requirements, and ability to generalize to out-of-domain inputs."
Perception Prioritized Training of Diffusion Models,0.616106,"Diffusion models learn to restore noisy data, which is corrupted with
different levels of noise, by optimizing the weighted sum of the corresponding
loss terms, i.e., denoising score matching loss. In this paper, we show that
restoring data corrupted with certain noise levels offers a proper pretext task
for the model to learn rich visual concepts. We propose to prioritize such
noise levels over other levels during training, by redesigning the weighting
scheme of the objective function. We show that our simple redesign of the
weighting scheme significantly improves the performance of diffusion models
regardless of the datasets, architectures, and sampling strategies."
Decoupling Makes Weakly Supervised Local Feature Better,0.459884,"Weakly supervised learning can help local feature methods to overcome the
obstacle of acquiring a large-scale dataset with densely labeled
correspondences. However, since weak supervision cannot distinguish the losses
caused by the detection and description steps, directly conducting weakly
supervised learning within a joint describe-then-detect pipeline suffers
limited performance. In this paper, we propose a decoupled describe-then-detect
pipeline tailored for weakly supervised local feature learning. Within our
pipeline, the detection step is decoupled from the description step and
postponed until discriminative and robust descriptors are learned. In addition,
we introduce a line-to-window search strategy to explicitly use the camera pose
information for better descriptor learning. Extensive experiments show that our
method, namely PoSFeat (Camera Pose Supervised Feature), outperforms previous
fully and weakly supervised methods and achieves state-of-the-art performance
on a wide range of downstream tasks."
NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis,-1.0,"Sentiment analysis is one of the most widely studied applications in NLP, but
most work focuses on languages with large amounts of data. We introduce the
first large-scale human-annotated Twitter sentiment dataset for the four most
widely spoken languages in Nigeria (Hausa, Igbo, Nigerian-Pidgin, and
Yor\`ub\'a ) consisting of around 30,000 annotated tweets per language (and
14,000 for Nigerian-Pidgin), including a significant fraction of code-mixed
tweets. We propose text collection, filtering, processing and labeling methods
that enable us to create datasets for these low-resource languages. We evaluate
a rangeof pre-trained models and transfer strategies on the dataset. We find
that language-specific models and language-adaptivefine-tuning generally
perform best. We release the datasets, trained models, sentiment lexicons, and
code to incentivizeresearch on sentiment analysis in under-represented
languages."
Readability Controllable Biomedical Document Summarization,0.2999,"Different from general documents, it is recognised that the ease with which
people can understand a biomedical text is eminently varied, owing to the
highly technical nature of biomedical documents and the variance of readers'
domain knowledge. However, existing biomedical document summarization systems
have paid little attention to readability control, leaving users with summaries
that are incompatible with their levels of expertise. In recognition of this
urgent demand, we introduce a new task of readability controllable
summarization for biomedical documents, which aims to recognise users'
readability demands and generate summaries that better suit their needs:
technical summaries for experts and plain language summaries (PLS) for laymen.
To establish this task, we construct a corpus consisting of biomedical papers
with technical summaries and PLSs written by the authors, and benchmark
multiple advanced controllable abstractive and extractive summarization models
based on pre-trained language models (PLMs) with prevalent controlling and
generation techniques. Moreover, we propose a novel masked language model (MLM)
based metric and its variant to effectively evaluate the readability
discrepancy between lay and technical summaries. Experimental results from
automated and human evaluations show that though current control techniques
allow for a certain degree of readability adjustment during generation, the
performance of existing controllable summarization methods is far from
desirable in this task."
Generative Cooperative Learning for Unsupervised Video Anomaly Detection,0.504041,"Video anomaly detection is well investigated in weakly-supervised and
one-class classification (OCC) settings. However, unsupervised video anomaly
detection methods are quite sparse, likely because anomalies are less frequent
in occurrence and usually not well-defined, which when coupled with the absence
of ground truth supervision, could adversely affect the performance of the
learning algorithms. This problem is challenging yet rewarding as it can
completely eradicate the costs of obtaining laborious annotations and enable
such systems to be deployed without human intervention. To this end, we propose
a novel unsupervised Generative Cooperative Learning (GCL) approach for video
anomaly detection that exploits the low frequency of anomalies towards building
a cross-supervision between a generator and a discriminator. In essence, both
networks get trained in a cooperative fashion, thereby allowing unsupervised
learning. We conduct extensive experiments on two large-scale video anomaly
detection datasets, UCF crime, and ShanghaiTech. Consistent improvement over
the existing state-of-the-art unsupervised and OCC methods corroborate the
effectiveness of our approach."
Learning from the Dictionary: Heterogeneous Knowledge Guided Fine-tuning for Chinese Spell Checking,0.485456,"Chinese Spell Checking (CSC) aims to detect and correct Chinese spelling
errors. Recent researches start from the pretrained knowledge of language
models and take multimodal information into CSC models to improve the
performance. However, they overlook the rich knowledge in the dictionary, the
reference book where one can learn how one character should be pronounced,
written, and used. In this paper, we propose the LEAD framework, which renders
the CSC model to learn heterogeneous knowledge from the dictionary in terms of
phonetics, vision, and meaning. LEAD first constructs positive and negative
samples according to the knowledge of character phonetics, glyphs, and
definitions in the dictionary. Then a unified contrastive learning-based
training scheme is employed to refine the representations of the CSC models.
Extensive experiments and detailed analyses on the SIGHAN benchmark datasets
demonstrate the effectiveness of our proposed methods."
SpeechMatrix: A Large-Scale Mined Corpus of Multilingual Speech-to-Speech Translations,0.69777,"We present SpeechMatrix, a large-scale multilingual corpus of
speech-to-speech translations mined from real speech of European Parliament
recordings. It contains speech alignments in 136 language pairs with a total of
418 thousand hours of speech. To evaluate the quality of this parallel speech,
we train bilingual speech-to-speech translation models on mined data only and
establish extensive baseline results on EuroParl-ST, VoxPopuli and FLEURS test
sets. Enabled by the multilinguality of SpeechMatrix, we also explore
multilingual speech-to-speech translation, a topic which was addressed by few
other works. We also demonstrate that model pre-training and sparse scaling
using Mixture-of-Experts bring large gains to translation performance. The
mined data and models are freely available."
On the Use of BERT for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation,0.787022,"In recent years, pre-trained models have become dominant in most natural
language processing (NLP) tasks. However, in the area of Automated Essay
Scoring (AES), pre-trained models such as BERT have not been properly used to
outperform other deep learning models such as LSTM. In this paper, we introduce
a novel multi-scale essay representation for BERT that can be jointly learned.
We also employ multiple losses and transfer learning from out-of-domain essays
to further improve the performance. Experiment results show that our approach
derives much benefit from joint learning of multi-scale essay representation
and obtains almost the state-of-the-art result among all deep learning models
in the ASAP task. Our multi-scale essay representation also generalizes well to
CommonLit Readability Prize data set, which suggests that the novel text
representation proposed in this paper may be a new and effective choice for
long-text tasks."
DialogVED: A Pre-trained Latent Variable Encoder-Decoder Model for Dialog Response Generation,0.0849768,"Dialog response generation in open domain is an important research topic
where the main challenge is to generate relevant and diverse responses. In this
paper, we propose a new dialog pre-training framework called DialogVED, which
introduces continuous latent variables into the enhanced encoder-decoder
pre-training framework to increase the relevance and diversity of responses.
With the help of a large dialog corpus (Reddit), we pre-train the model using
the following 4 tasks adopted in language models (LMs) and variational
autoencoders (VAEs): 1) masked language model; 2) response generation; 3)
bag-of-words prediction; and 4) KL divergence reduction. We also add additional
parameters to model the turn structure in dialogs to improve the performance of
the pre-trained model. We conduct experiments on PersonaChat, DailyDialog, and
DSTC7-AVSD benchmarks for response generation. Experimental results show that
our model achieves the new state-of-the-art results on all these datasets."
CoMER: Modeling Coverage for Transformer-based Handwritten Mathematical Expression Recognition,0.0,"The Transformer-based encoder-decoder architecture has recently made
significant advances in recognizing handwritten mathematical expressions.
However, the transformer model still suffers from the lack of coverage problem,
making its expression recognition rate (ExpRate) inferior to its RNN
counterpart. Coverage information, which records the alignment information of
the past steps, has proven effective in the RNN models. In this paper, we
propose CoMER, a model that adopts the coverage information in the transformer
decoder. Specifically, we propose a novel Attention Refinement Module (ARM) to
refine the attention weights with past alignment information without hurting
its parallelism. Furthermore, we take coverage information to the extreme by
proposing self-coverage and cross-coverage, which utilize the past alignment
information from the current and previous layers. Experiments show that CoMER
improves the ExpRate by 0.61%/2.09%/1.59% compared to the current
state-of-the-art model, and reaches 59.33%/59.81%/62.97% on the CROHME
2014/2016/2019 test sets."
Breaking the Representation Bottleneck of Chinese Characters: Neural Machine Translation with Stroke Sequence Modeling,0.501251,"Existing research generally treats Chinese character as a minimum unit for
representation. However, such Chinese character representation will suffer two
bottlenecks: 1) Learning bottleneck, the learning cannot benefit from its rich
internal features (e.g., radicals and strokes); and 2) Parameter bottleneck,
each individual character has to be represented by a unique vector. In this
paper, we introduce a novel representation method for Chinese characters to
break the bottlenecks, namely StrokeNet, which represents a Chinese character
by a Latinized stroke sequence (e.g., ""ao1 (concave)"" to ""ajaie"" and ""tu1
(convex)"" to ""aeaqe""). Specifically, StrokeNet maps each stroke to a specific
Latin character, thus allowing similar Chinese characters to have similar Latin
representations. With the introduction of StrokeNet to neural machine
translation (NMT), many powerful but not applicable techniques to non-Latin
languages (e.g., shared subword vocabulary learning and ciphertext-based data
augmentation) can now be perfectly implemented. Experiments on the widely-used
NIST Chinese-English, WMT17 Chinese-English and IWSLT17 Japanese-English NMT
tasks show that StrokeNet can provide a significant performance boost over the
strong baselines with fewer model parameters, achieving 26.5 BLEU on the WMT17
Chinese-English task which is better than any previously reported results
without using monolingual data. Code and scripts are freely available at
https://github.com/zjwang21/StrokeNet."
NAFSSR: Stereo Image Super-Resolution Using NAFNet,0.242941,"Stereo image super-resolution aims at enhancing the quality of
super-resolution results by utilizing the complementary information provided by
binocular systems. To obtain reasonable performance, most methods focus on
finely designing modules, loss functions, and etc. to exploit information from
another viewpoint. This has the side effect of increasing system complexity,
making it difficult for researchers to evaluate new ideas and compare methods.
This paper inherits a strong and simple image restoration model, NAFNet, for
single-view feature extraction and extends it by adding cross attention modules
to fuse features between views to adapt to binocular scenarios. The proposed
baseline for stereo image super-resolution is noted as NAFSSR. Furthermore,
training/testing strategies are proposed to fully exploit the performance of
NAFSSR. Extensive experiments demonstrate the effectiveness of our method. In
particular, NAFSSR outperforms the state-of-the-art methods on the KITTI 2012,
KITTI 2015, Middlebury, and Flickr1024 datasets. With NAFSSR, we won 1st place
in the NTIRE 2022 Stereo Image Super-resolution Challenge. Codes and models
will be released at https://github.com/megvii-research/NAFNet."
SimVP: Simpler yet Better Video Prediction,0.422232,"From CNN, RNN, to ViT, we have witnessed remarkable advancements in video
prediction, incorporating auxiliary inputs, elaborate neural architectures, and
sophisticated training strategies. We admire these progresses but are confused
about the necessity: is there a simple method that can perform comparably well?
This paper proposes SimVP, a simple video prediction model that is completely
built upon CNN and trained by MSE loss in an end-to-end fashion. Without
introducing any additional tricks and complicated strategies, we can achieve
state-of-the-art performance on five benchmark datasets. Through extended
experiments, we demonstrate that SimVP has strong generalization and
extensibility on real-world datasets. The significant reduction of training
cost makes it easier to scale to complex scenarios. We believe SimVP can serve
as a solid baseline to stimulate the further development of video prediction.
The code is available at
\href{https://github.com/gaozhangyang/SimVP-Simpler-yet-Better-Video-Prediction}{Github}."
PartSLIP: Low-Shot Part Segmentation for 3D Point Clouds via Pretrained Image-Language Models,0.864665,"Generalizable 3D part segmentation is important but challenging in vision and
robotics. Training deep models via conventional supervised methods requires
large-scale 3D datasets with fine-grained part annotations, which are costly to
collect. This paper explores an alternative way for low-shot part segmentation
of 3D point clouds by leveraging a pretrained image-language model, GLIP, which
achieves superior performance on open-vocabulary 2D detection. We transfer the
rich knowledge from 2D to 3D through GLIP-based part detection on point cloud
rendering and a novel 2D-to-3D label lifting algorithm. We also utilize
multi-view 3D priors and few-shot prompt tuning to boost performance
significantly. Extensive evaluation on PartNet and PartNet-Mobility datasets
shows that our method enables excellent zero-shot 3D part segmentation. Our
few-shot version not only outperforms existing few-shot approaches by a large
margin but also achieves highly competitive results compared to the fully
supervised counterpart. Furthermore, we demonstrate that our method can be
directly applied to iPhone-scanned point clouds without significant domain
gaps."
Evaluating Human-Language Model Interaction,0.499323,"Many real-world applications of language models (LMs), such as writing
assistance and code autocomplete, involve human-LM interaction. However, most
benchmarks are non-interactive in that a model produces output without human
involvement. To evaluate human-LM interaction, we develop a new framework,
Human-AI Language-based Interaction Evaluation (HALIE), that defines the
components of interactive systems and dimensions to consider when designing
evaluation metrics. Compared to standard, non-interactive evaluation, HALIE
captures (i) the interactive process, not only the final output; (ii) the
first-person subjective experience, not just a third-party assessment; and
(iii) notions of preference beyond quality (e.g., enjoyment and ownership). We
then design five tasks to cover different forms of interaction: social
dialogue, question answering, crossword puzzles, summarization, and metaphor
generation. With four state-of-the-art LMs (three variants of OpenAI's GPT-3
and AI21 Labs' Jurassic-1), we find that better non-interactive performance
does not always translate to better human-LM interaction. In particular, we
highlight three cases where the results from non-interactive and interactive
metrics diverge and underscore the importance of human-LM interaction for LM
evaluation."
"The Carbon Footprint of Machine Learning Training Will Plateau, Then Shrink",0.862472,"Machine Learning (ML) workloads have rapidly grown in importance, but raised
concerns about their carbon footprint. Four best practices can reduce ML
training energy by up to 100x and CO2 emissions up to 1000x. By following best
practices, overall ML energy use (across research, development, and production)
held steady at <15% of Google's total energy use for the past three years. If
the whole ML field were to adopt best practices, total carbon emissions from
training would reduce. Hence, we recommend that ML papers include emissions
explicitly to foster competition on more than just model quality. Estimates of
emissions in papers that omitted them have been off 100x-100,000x, so
publishing emissions has the added benefit of ensuring accurate accounting.
Given the importance of climate change, we must get the numbers right to make
certain that we work on its biggest challenges."
End-to-end Document Recognition and Understanding with Dessurt,-1.0,"We introduce Dessurt, a relatively simple document understanding transformer
capable of being fine-tuned on a greater variety of document tasks than prior
methods. It receives a document image and task string as input and generates
arbitrary text autoregressively as output. Because Dessurt is an end-to-end
architecture that performs text recognition in addition to the document
understanding, it does not require an external recognition model as prior
methods do. Dessurt is a more flexible model than prior methods and is able to
handle a variety of document domains and tasks. We show that this model is
effective at 9 different dataset-task combinations."
HouseDiffusion: Vector Floorplan Generation via a Diffusion Model with Discrete and Continuous Denoising,0.162413,"The paper presents a novel approach for vector-floorplan generation via a
diffusion model, which denoises 2D coordinates of room/door corners with two
inference objectives: 1) a single-step noise as the continuous quantity to
precisely invert the continuous forward process; and 2) the final 2D coordinate
as the discrete quantity to establish geometric incident relationships such as
parallelism, orthogonality, and corner-sharing. Our task is graph-conditioned
floorplan generation, a common workflow in floorplan design. We represent a
floorplan as 1D polygonal loops, each of which corresponds to a room or a door.
Our diffusion model employs a Transformer architecture at the core, which
controls the attention masks based on the input graph-constraint and directly
generates vector-graphics floorplans via a discrete and continuous denoising
process. We have evaluated our approach on RPLAN dataset. The proposed approach
makes significant improvements in all the metrics against the state-of-the-art
with significant margins, while being capable of generating non-Manhattan
structures and controlling the exact number of corners per room. A project
website with supplementary video and document is here
https://aminshabani.github.io/housediffusion."
Building a Role Specified Open-Domain Dialogue System Leveraging Large-Scale Language Models,0.343467,"Recent open-domain dialogue models have brought numerous breakthroughs.
However, building a chat system is not scalable since it often requires a
considerable volume of human-human dialogue data, especially when enforcing
features such as persona, style, or safety. In this work, we study the
challenge of imposing roles on open-domain dialogue systems, with the goal of
making the systems maintain consistent roles while conversing naturally with
humans. To accomplish this, the system must satisfy a role specification that
includes certain conditions on the stated features as well as a system policy
on whether or not certain types of utterances are allowed. For this, we propose
an efficient data collection framework leveraging in-context few-shot learning
of large-scale language models for building role-satisfying dialogue dataset
from scratch. We then compare various architectures for open-domain dialogue
systems in terms of meeting role specifications while maintaining
conversational abilities. Automatic and human evaluations show that our models
return few out-of-bounds utterances, keeping competitive performance on general
metrics. We release a Korean dialogue dataset we built for further research."
A Graph Neural Network Approach to Automated Model Building in Cryo-EM Maps,0.579403,"Electron cryo-microscopy (cryo-EM) produces three-dimensional (3D) maps of
the electrostatic potential of biological macromolecules, including proteins.
Along with knowledge about the imaged molecules, cryo-EM maps allow de novo
atomic modelling, which is typically done through a laborious manual process.
Taking inspiration from recent advances in machine learning applications to
protein structure prediction, we propose a graph neural network (GNN) approach
for automated model building of proteins in cryo-EM maps. The GNN acts on a
graph with nodes assigned to individual amino acids and edges representing the
protein chain. Combining information from the voxel-based cryo-EM data, the
amino acid sequence data and prior knowledge about protein geometries, the GNN
refines the geometry of the protein chain and classifies the amino acids for
each of its nodes. Application to 28 test cases shows that our approach
outperforms the state-of-the-art and approximates manual building for cryo-EM
maps with resolutions better than 3.5 \r{A}."
Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models,0.663112,"Despite the success, the process of fine-tuning large-scale PLMs brings
prohibitive adaptation costs. In fact, fine-tuning all the parameters of a
colossal model and retaining separate instances for different tasks are
practically infeasible. This necessitates a new branch of research focusing on
the parameter-efficient adaptation of PLMs, dubbed as delta tuning in this
paper. In contrast with the standard fine-tuning, delta tuning only fine-tunes
a small portion of the model parameters while keeping the rest untouched,
largely reducing both the computation and storage costs. Recent studies have
demonstrated that a series of delta tuning methods with distinct tuned
parameter selection could achieve performance on a par with full-parameter
fine-tuning, suggesting a new promising way of stimulating large-scale PLMs. In
this paper, we first formally describe the problem of delta tuning and then
comprehensively review recent delta tuning approaches. We also propose a
unified categorization criterion that divide existing delta tuning methods into
three groups: addition-based, specification-based, and reparameterization-based
methods. Though initially proposed as an efficient method to steer large
models, we believe that some of the fascinating evidence discovered along with
delta tuning could help further reveal the mechanisms of PLMs and even deep
neural networks. To this end, we discuss the theoretical principles underlying
the effectiveness of delta tuning and propose frameworks to interpret delta
tuning from the perspective of optimization and optimal control, respectively.
Furthermore, we provide a holistic empirical study of representative methods,
where results on over 100 NLP tasks demonstrate a comprehensive performance
comparison of different approaches. The experimental results also cover the
analysis of combinatorial, scaling and transferable properties of delta tuning."
"Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model",0.841303,"Pretrained general-purpose language models can achieve state-of-the-art
accuracies in various natural language processing domains by adapting to
downstream tasks via zero-shot, few-shot and fine-tuning techniques. Because of
their success, the size of these models has increased rapidly, requiring
high-performance hardware, software, and algorithmic techniques to enable
training such large models. As the result of a joint effort between Microsoft
and NVIDIA, we present details on the training of the largest monolithic
transformer based language model, Megatron-Turing NLG 530B (MT-NLG), with 530
billion parameters. In this paper, we first focus on the infrastructure as well
as the 3D parallelism methodology used to train this model using DeepSpeed and
Megatron. Next, we detail the training process, the design of our training
corpus, and our data curation techniques, which we believe is a key ingredient
to the success of the model. Finally, we discuss various evaluation results, as
well as other interesting observations and new properties exhibited by MT-NLG.
We demonstrate that MT-NLG achieves superior zero-, one-, and few-shot learning
accuracies on several NLP benchmarks and establishes new state-of-the-art
results. We believe that our contributions will help further the development of
large-scale training infrastructures, large-scale language models, and natural
language generations."
PromptBERT: Improving BERT Sentence Embeddings with Prompts,0.624511,"We propose PromptBERT, a novel contrastive learning method for learning
better sentence representation. We firstly analyze the drawback of current
sentence embedding from original BERT and find that it is mainly due to the
static token embedding bias and ineffective BERT layers. Then we propose the
first prompt-based sentence embeddings method and discuss two prompt
representing methods and three prompt searching methods to make BERT achieve
better sentence embeddings. Moreover, we propose a novel unsupervised training
objective by the technology of template denoising, which substantially shortens
the performance gap between the supervised and unsupervised settings. Extensive
experiments show the effectiveness of our method. Compared to SimCSE,
PromptBert achieves 2.29 and 2.58 points of improvement based on BERT and
RoBERTa in the unsupervised setting."
Submodularity In Machine Learning and Artificial Intelligence,0.239109,"In this manuscript, we offer a gentle review of submodularity and
supermodularity and their properties. We offer a plethora of submodular
definitions; a full description of a number of example submodular functions and
their generalizations; example discrete constraints; a discussion of basic
algorithms for maximization, minimization, and other operations; a brief
overview of continuous submodular extensions; and some historical applications.
We then turn to how submodularity is useful in machine learning and artificial
intelligence. This includes summarization, and we offer a complete account of
the differences between and commonalities amongst sketching, coresets,
extractive and abstractive summarization in NLP, data distillation and
condensation, and data subset selection and feature selection. We discuss a
variety of ways to produce a submodular function useful for machine learning,
including heuristic hand-crafting, learning or approximately learning a
submodular function or aspects thereof, and some advantages of the use of a
submodular function as a coreset producer. We discuss submodular combinatorial
information functions, and how submodularity is useful for clustering, data
partitioning, parallel machine learning, active and semi-supervised learning,
probabilistic modeling, and structured norms and loss functions."
REGTR: End-to-end Point Cloud Correspondences with Transformers,0.79298,"Despite recent success in incorporating learning into point cloud
registration, many works focus on learning feature descriptors and continue to
rely on nearest-neighbor feature matching and outlier filtering through RANSAC
to obtain the final set of correspondences for pose estimation. In this work,
we conjecture that attention mechanisms can replace the role of explicit
feature matching and RANSAC, and thus propose an end-to-end framework to
directly predict the final set of correspondences. We use a network
architecture consisting primarily of transformer layers containing self and
cross attentions, and train it to predict the probability each point lies in
the overlapping region and its corresponding position in the other point cloud.
The required rigid transformation can then be estimated directly from the
predicted correspondences without further post-processing. Despite its
simplicity, our approach achieves state-of-the-art performance on 3DMatch and
ModelNet benchmarks. Our source code can be found at
https://github.com/yewzijian/RegTR ."
On the Effects of Image Quality Degradation on Minutiae- and Ridge-Based Automatic Fingerprint Recognition,0.398929,"The effect of image quality degradation on the verification performance of
automatic fingerprint recognition is investigated. We study the performance of
two fingerprint matchers based on minutiae and ridge information under varying
fingerprint image quality. The ridge-based system is found to be more robust to
image quality degradation than the minutiae-based system for a number of
different image quality criteria."
Estimating Soft Labels for Out-of-Domain Intent Detection,0.113667,"Out-of-Domain (OOD) intent detection is important for practical dialog
systems. To alleviate the issue of lacking OOD training samples, some works
propose synthesizing pseudo OOD samples and directly assigning one-hot OOD
labels to these pseudo samples. However, these one-hot labels introduce noises
to the training process because some hard pseudo OOD samples may coincide with
In-Domain (IND) intents. In this paper, we propose an adaptive soft pseudo
labeling (ASoul) method that can estimate soft labels for pseudo OOD samples
when training OOD detectors. Semantic connections between pseudo OOD samples
and IND intents are captured using an embedding graph. A co-training framework
is further introduced to produce resulting soft labels following the smoothness
assumption, i.e., close samples are likely to have similar labels. Extensive
experiments on three benchmark datasets show that ASoul consistently improves
the OOD detection performance and outperforms various competitive baselines."
Surgical Fine-Tuning Improves Adaptation to Distribution Shifts,0.243894,"A common approach to transfer learning under distribution shift is to
fine-tune the last few layers of a pre-trained model, preserving learned
features while also adapting to the new task. This paper shows that in such
settings, selectively fine-tuning a subset of layers (which we term surgical
fine-tuning) matches or outperforms commonly used fine-tuning approaches.
Moreover, the type of distribution shift influences which subset is more
effective to tune: for example, for image corruptions, fine-tuning only the
first few layers works best. We validate our findings systematically across
seven real-world data tasks spanning three types of distribution shifts.
Theoretically, we prove that for two-layer neural networks in an idealized
setting, first-layer tuning can outperform fine-tuning all layers. Intuitively,
fine-tuning more parameters on a small target dataset can cause information
learned during pre-training to be forgotten, and the relevant information
depends on the type of shift."
Adapting Pre-trained Language Models to African Languages via Multilingual Adaptive Fine-Tuning,0.497836,"Multilingual pre-trained language models (PLMs) have demonstrated impressive
performance on several downstream tasks for both high-resourced and
low-resourced languages. However, there is still a large performance drop for
languages unseen during pre-training, especially African languages. One of the
most effective approaches to adapt to a new language is \textit{language
adaptive fine-tuning} (LAFT) -- fine-tuning a multilingual PLM on monolingual
texts of a language using the pre-training objective. However, adapting to a
target language individually takes a large disk space and limits the
cross-lingual transfer abilities of the resulting models because they have been
specialized for a single language. In this paper, we perform
\textit{multilingual adaptive fine-tuning} on 17 most-resourced African
languages and three other high-resource languages widely spoken on the African
continent to encourage cross-lingual transfer learning. To further specialize
the multilingual PLM, we removed vocabulary tokens from the embedding layer
that corresponds to non-African writing scripts before MAFT, thus reducing the
model size by around 50%. Our evaluation on two multilingual PLMs (AfriBERTa
and XLM-R) and three NLP tasks (NER, news topic classification, and sentiment
classification) shows that our approach is competitive to applying LAFT on
individual languages while requiring significantly less disk space.
Additionally, we show that our adapted PLM also improves the zero-shot
cross-lingual transfer abilities of parameter efficient fine-tuning methods."
PAL: Persona-Augmented Emotional Support Conversation Generation,0.154377,"Due to the lack of human resources for mental health support, there is an
increasing demand for employing conversational agents for support. Recent work
has demonstrated the effectiveness of dialogue models in providing emotional
support. As previous studies have demonstrated that seekers' persona is an
important factor for effective support, we investigate whether there are
benefits to modeling such information in dialogue models for support. In this
paper, our empirical analysis verifies that persona has an important impact on
emotional support. Therefore, we propose a framework for dynamically inferring
and modeling seekers' persona. We first train a model for inferring the
seeker's persona from the conversation history. Accordingly, we propose PAL, a
model that leverages persona information and, in conjunction with our
strategy-based controllable generation method, provides personalized emotional
support. Automatic and manual evaluations demonstrate that PAL achieves
state-of-the-art results, outperforming the baselines on the studied benchmark.
Our code and data are publicly available at https://github.com/chengjl19/PAL."
Exploring Plain Vision Transformer Backbones for Object Detection,0.994474,"We explore the plain, non-hierarchical Vision Transformer (ViT) as a backbone
network for object detection. This design enables the original ViT architecture
to be fine-tuned for object detection without needing to redesign a
hierarchical backbone for pre-training. With minimal adaptations for
fine-tuning, our plain-backbone detector can achieve competitive results.
Surprisingly, we observe: (i) it is sufficient to build a simple feature
pyramid from a single-scale feature map (without the common FPN design) and
(ii) it is sufficient to use window attention (without shifting) aided with
very few cross-window propagation blocks. With plain ViT backbones pre-trained
as Masked Autoencoders (MAE), our detector, named ViTDet, can compete with the
previous leading methods that were all based on hierarchical backbones,
reaching up to 61.3 AP_box on the COCO dataset using only ImageNet-1K
pre-training. We hope our study will draw attention to research on
plain-backbone detectors. Code for ViTDet is available in Detectron2."
SparseNeuS: Fast Generalizable Neural Surface Reconstruction from Sparse Views,0.922119,"We introduce SparseNeuS, a novel neural rendering based method for the task
of surface reconstruction from multi-view images. This task becomes more
difficult when only sparse images are provided as input, a scenario where
existing neural reconstruction approaches usually produce incomplete or
distorted results. Moreover, their inability of generalizing to unseen new
scenes impedes their application in practice. Contrarily, SparseNeuS can
generalize to new scenes and work well with sparse images (as few as 2 or 3).
SparseNeuS adopts signed distance function (SDF) as the surface representation,
and learns generalizable priors from image features by introducing geometry
encoding volumes for generic surface prediction. Moreover, several strategies
are introduced to effectively leverage sparse views for high-quality
reconstruction, including 1) a multi-level geometry reasoning framework to
recover the surfaces in a coarse-to-fine manner; 2) a multi-scale color
blending scheme for more reliable color prediction; 3) a consistency-aware
fine-tuning scheme to control the inconsistent regions caused by occlusion and
noise. Extensive experiments demonstrate that our approach not only outperforms
the state-of-the-art methods, but also exhibits good efficiency,
generalizability, and flexibility."
IRON: Inverse Rendering by Optimizing Neural SDFs and Materials from Photometric Images,0.767944,"We propose a neural inverse rendering pipeline called IRON that operates on
photometric images and outputs high-quality 3D content in the format of
triangle meshes and material textures readily deployable in existing graphics
pipelines. Our method adopts neural representations for geometry as signed
distance fields (SDFs) and materials during optimization to enjoy their
flexibility and compactness, and features a hybrid optimization scheme for
neural SDFs: first, optimize using a volumetric radiance field approach to
recover correct topology, then optimize further using edgeaware physics-based
surface rendering for geometry refinement and disentanglement of materials and
lighting. In the second stage, we also draw inspiration from mesh-based
differentiable rendering, and design a novel edge sampling algorithm for neural
SDFs to further improve performance. We show that our IRON achieves
significantly better inverse rendering quality compared to prior works. Our
project page is here: https://kai-46.github.io/IRON-website/"
Conditional Generation with a Question-Answering Blueprint,0.143715,"The ability to convey relevant and faithful information is critical for many
tasks in conditional generation and yet remains elusive for neural seq-to-seq
models whose outputs often reveal hallucinations and fail to correctly cover
important details. In this work, we advocate planning as a useful intermediate
representation for rendering conditional generation less opaque and more
grounded. Our work proposes a new conceptualization of text plans as a sequence
of question-answer (QA) pairs. We enhance existing datasets (e.g., for
summarization) with a QA blueprint operating as a proxy for both content
selection (i.e.,~what to say) and planning (i.e.,~in what order). We obtain
blueprints automatically by exploiting state-of-the-art question generation
technology and convert input-output pairs into input-blueprint-output tuples.
We develop Transformer-based models, each varying in how they incorporate the
blueprint in the generated output (e.g., as a global plan or iteratively).
Evaluation across metrics and datasets demonstrates that blueprint models are
more factual than alternatives which do not resort to planning and allow
tighter control of the generation output."
Multi-modal Contrastive Representation Learning for Entity Alignment,0.522093,"Multi-modal entity alignment aims to identify equivalent entities between two
different multi-modal knowledge graphs, which consist of structural triples and
images associated with entities. Most previous works focus on how to utilize
and encode information from different modalities, while it is not trivial to
leverage multi-modal knowledge in entity alignment because of the modality
heterogeneity. In this paper, we propose MCLEA, a Multi-modal Contrastive
Learning based Entity Alignment model, to obtain effective joint
representations for multi-modal entity alignment. Different from previous
works, MCLEA considers task-oriented modality and models the inter-modal
relationships for each entity representation. In particular, MCLEA firstly
learns multiple individual representations from multiple modalities, and then
performs contrastive learning to jointly model intra-modal and inter-modal
interactions. Extensive experimental results show that MCLEA outperforms
state-of-the-art baselines on public datasets under both supervised and
unsupervised settings."
Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models,0.661245,"Pre-trained vision-language models (e.g., CLIP) have shown promising
zero-shot generalization in many downstream tasks with properly designed text
prompts. Instead of relying on hand-engineered prompts, recent works learn
prompts using the training data from downstream tasks. While effective,
training on domain-specific data reduces a model's generalization capability to
unseen new domains. In this work, we propose test-time prompt tuning (TPT), a
method that can learn adaptive prompts on the fly with a single test sample.
For image classification, TPT optimizes the prompt by minimizing the entropy
with confidence selection so that the model has consistent predictions across
different augmented views of each test sample. In evaluating generalization to
natural distribution shifts, TPT improves the zero-shot top-1 accuracy of CLIP
by 3.6% on average, surpassing previous prompt tuning approaches that require
additional task-specific training data. In evaluating cross-dataset
generalization with unseen categories, TPT performs on par with the
state-of-the-art approaches that use additional training data. Project page:
https://azshue.github.io/TPT."
Semantic Image Synthesis via Diffusion Models,0.490584,"Denoising Diffusion Probabilistic Models (DDPMs) have achieved remarkable
success in various image generation tasks compared with Generative Adversarial
Nets (GANs). Recent work on semantic image synthesis mainly follows the
\emph{de facto} GAN-based approaches, which may lead to unsatisfactory quality
or diversity of generated images. In this paper, we propose a novel framework
based on DDPM for semantic image synthesis. Unlike previous conditional
diffusion model directly feeds the semantic layout and noisy image as input to
a U-Net structure, which may not fully leverage the information in the input
semantic mask, our framework processes semantic layout and noisy image
differently. It feeds noisy image to the encoder of the U-Net structure while
the semantic layout to the decoder by multi-layer spatially-adaptive
normalization operators. To further improve the generation quality and semantic
interpretability in semantic image synthesis, we introduce the classifier-free
guidance sampling strategy, which acknowledge the scores of an unconditional
model for sampling process. Extensive experiments on three benchmark datasets
demonstrate the effectiveness of our proposed method, achieving
state-of-the-art performance in terms of fidelity (FID) and diversity (LPIPS)."
Unifying Motion Deblurring and Frame Interpolation with Events,0.0547979,"Slow shutter speed and long exposure time of frame-based cameras often cause
visual blur and loss of inter-frame information, degenerating the overall
quality of captured videos. To this end, we present a unified framework of
event-based motion deblurring and frame interpolation for blurry video
enhancement, where the extremely low latency of events is leveraged to
alleviate motion blur and facilitate intermediate frame prediction.
Specifically, the mapping relation between blurry frames and sharp latent
images is first predicted by a learnable double integral network, and a fusion
network is then proposed to refine the coarse results via utilizing the
information from consecutive blurry inputs and the concurrent events. By
exploring the mutual constraints among blurry frames, latent images, and event
streams, we further propose a self-supervised learning framework to enable
network training with real-world blurry videos and events. Extensive
experiments demonstrate that our method compares favorably against the
state-of-the-art approaches and achieves remarkable performance on both
synthetic and real-world datasets."
Deep Learning in Business Analytics: A Clash of Expectations and Reality,0.182016,"Our fast-paced digital economy shaped by global competition requires
increased data-driven decision-making based on artificial intelligence (AI) and
machine learning (ML). The benefits of deep learning (DL) are manifold, but it
comes with limitations that have - so far - interfered with widespread industry
adoption. This paper explains why DL - despite its popularity - has
difficulties speeding up its adoption within business analytics. It is shown -
by a mixture of content analysis and empirical study - that the adoption of
deep learning is not only affected by computational complexity, lacking big
data architecture, lack of transparency (black-box), and skill shortage, but
also by the fact that DL does not outperform traditional ML models in the case
of structured datasets with fixed-length feature vectors. Deep learning should
be regarded as a powerful addition to the existing body of ML models instead of
a one size fits all solution."
Real-time Full-stack Traffic Scene Perception for Autonomous Driving with Roadside Cameras,0.423898,"We propose a novel and pragmatic framework for traffic scene perception with
roadside cameras. The proposed framework covers a full-stack of roadside
perception pipeline for infrastructure-assisted autonomous driving, including
object detection, object localization, object tracking, and multi-camera
information fusion. Unlike previous vision-based perception frameworks rely
upon depth offset or 3D annotation at training, we adopt a modular decoupling
design and introduce a landmark-based 3D localization method, where the
detection and localization can be well decoupled so that the model can be
easily trained based on only 2D annotations. The proposed framework applies to
either optical or thermal cameras with pinhole or fish-eye lenses. Our
framework is deployed at a two-lane roundabout located at Ellsworth Rd. and
State St., Ann Arbor, MI, USA, providing 7x24 real-time traffic flow monitoring
and high-precision vehicle trajectory extraction. The whole system runs
efficiently on a low-power edge computing device with all-component end-to-end
delay of less than 20ms."
A sequence-to-sequence approach for document-level relation extraction,0.441497,"Motivated by the fact that many relations cross the sentence boundary, there
has been increasing interest in document-level relation extraction (DocRE).
DocRE requires integrating information within and across sentences, capturing
complex interactions between mentions of entities. Most existing methods are
pipeline-based, requiring entities as input. However, jointly learning to
extract entities and relations can improve performance and be more efficient
due to shared parameters and training steps. In this paper, we develop a
sequence-to-sequence approach, seq2rel, that can learn the subtasks of DocRE
(entity extraction, coreference resolution and relation extraction) end-to-end,
replacing a pipeline of task-specific components. Using a simple strategy we
call entity hinting, we compare our approach to existing pipeline-based methods
on several popular biomedical datasets, in some cases exceeding their
performance. We also report the first end-to-end results on these datasets for
future comparison. Finally, we demonstrate that, under our model, an end-to-end
approach outperforms a pipeline-based approach. Our code, data and trained
models are available at {\url{https://github.com/johngiorgi/seq2rel}}. An
online demo is available at
{\url{https://share.streamlit.io/johngiorgi/seq2rel/main/demo.py}}."
Connection-minimal Abduction in EL via Translation to FOL -- Technical Report,0.0818234,"Abduction in description logics finds extensions of a knowledge base to make
it entail an observation. As such, it can be used to explain why the
observation does not follow, to repair incomplete knowledge bases, and to
provide possible explanations for unexpected observations. We consider TBox
abduction in the lightweight description logic EL, where the observation is a
concept inclusion and the background knowledge is a TBox, i.e., a set of
concept inclusions. To avoid useless answers, such problems usually come with
further restrictions on the solution space and/or minimality criteria that help
sort the chaff from the grain. We argue that existing minimality notions are
insufficient, and introduce connection minimality. This criterion follows
Occam's razor by rejecting hypotheses that use concept inclusions unrelated to
the problem at hand. We show how to compute a special class of
connection-minimal hypotheses in a sound and complete way. Our technique is
based on a translation to first-order logic, and constructs hypotheses based on
prime implicates. We evaluate a prototype implementation of our approach on
ontologies from the medical domain."
Generative Modelling With Inverse Heat Dissipation,0.713086,"While diffusion models have shown great success in image generation, their
noise-inverting generative process does not explicitly consider the structure
of images, such as their inherent multi-scale nature. Inspired by diffusion
models and the empirical success of coarse-to-fine modelling, we propose a new
diffusion-like model that generates images through stochastically reversing the
heat equation, a PDE that locally erases fine-scale information when run over
the 2D plane of the image. We interpret the solution of the forward heat
equation with constant additive noise as a variational approximation in the
diffusion latent variable model. Our new model shows emergent qualitative
properties not seen in standard diffusion models, such as disentanglement of
overall colour and shape in images. Spectral analysis on natural images
highlights connections to diffusion models and reveals an implicit
coarse-to-fine inductive bias in them."
Dataless Knowledge Fusion by Merging Weights of Language Models,0.528632,"Fine-tuning pre-trained language models has become the prevalent paradigm for
building downstream NLP models. Oftentimes fine-tuned models are readily
available but their training data is not, due to data privacy or intellectual
property concerns. This creates a barrier to fusing knowledge across individual
models to yield a better single model. In this paper, we study the problem of
merging individual models built on different training data sets to obtain a
single model that performs well both across all data set domains and can
generalize on out-of-domain data. We propose a dataless knowledge fusion method
that merges models in their parameter space, guided by weights that minimize
prediction differences between the merged model and the individual models. Over
a battery of evaluation settings, we show that the proposed method
significantly outperforms baselines such as Fisher-weighted averaging or model
ensembling. Further, we find that our method is a promising alternative to
multi-task learning that can preserve or sometimes improve over the individual
models without access to the training data. Finally, model merging is more
efficient than training a multi-task model, thus making it applicable to a
wider set of scenarios."
RelTR: Relation Transformer for Scene Graph Generation,0.821438,"Different objects in the same scene are more or less related to each other,
but only a limited number of these relationships are noteworthy. Inspired by
DETR, which excels in object detection, we view scene graph generation as a set
prediction problem and propose an end-to-end scene graph generation model RelTR
which has an encoder-decoder architecture. The encoder reasons about the visual
feature context while the decoder infers a fixed-size set of triplets
subject-predicate-object using different types of attention mechanisms with
coupled subject and object queries. We design a set prediction loss performing
the matching between the ground truth and predicted triplets for the end-to-end
training. In contrast to most existing scene graph generation methods, RelTR is
a one-stage method that predicts a set of relationships directly only using
visual appearance without combining entities and labeling all possible
predicates. Extensive experiments on the Visual Genome and Open Images V6
datasets demonstrate the superior performance and fast inference of our model."
An Initial Investigation for Detecting Vocoder Fingerprints of Fake Audio,0.0492075,"Many effective attempts have been made for fake audio detection. However,
they can only provide detection results but no countermeasures to curb this
harm. For many related practical applications, what model or algorithm
generated the fake audio also is needed. Therefore, We propose a new problem
for detecting vocoder fingerprints of fake audio. Experiments are conducted on
the datasets synthesized by eight state-of-the-art vocoders. We have
preliminarily explored the features and model architectures. The t-SNE
visualization shows that different vocoders generate distinct vocoder
fingerprints."
MM-DFN: Multimodal Dynamic Fusion Network for Emotion Recognition in Conversations,0.68078,"Emotion Recognition in Conversations (ERC) has considerable prospects for
developing empathetic machines. For multimodal ERC, it is vital to understand
context and fuse modality information in conversations. Recent graph-based
fusion methods generally aggregate multimodal information by exploring unimodal
and cross-modal interactions in a graph. However, they accumulate redundant
information at each layer, limiting the context understanding between
modalities. In this paper, we propose a novel Multimodal Dynamic Fusion Network
(MM-DFN) to recognize emotions by fully understanding multimodal conversational
context. Specifically, we design a new graph-based dynamic fusion module to
fuse multimodal contextual features in a conversation. The module reduces
redundancy and enhances complementarity between modalities by capturing the
dynamics of contextual information in different semantic spaces. Extensive
experiments on two public benchmark datasets demonstrate the effectiveness and
superiority of MM-DFN."
TCTrack: Temporal Contexts for Aerial Tracking,0.567683,"Temporal contexts among consecutive frames are far from being fully utilized
in existing visual trackers. In this work, we present TCTrack, a comprehensive
framework to fully exploit temporal contexts for aerial tracking. The temporal
contexts are incorporated at \textbf{two levels}: the extraction of
\textbf{features} and the refinement of \textbf{similarity maps}. Specifically,
for feature extraction, an online temporally adaptive convolution is proposed
to enhance the spatial features using temporal information, which is achieved
by dynamically calibrating the convolution weights according to the previous
frames. For similarity map refinement, we propose an adaptive temporal
transformer, which first effectively encodes temporal knowledge in a
memory-efficient way, before the temporal knowledge is decoded for accurate
adjustment of the similarity map. TCTrack is effective and efficient:
evaluation on four aerial tracking benchmarks shows its impressive performance;
real-world UAV tests show its high speed of over 27 FPS on NVIDIA Jetson AGX
Xavier."
Walk These Ways: Tuning Robot Control for Generalization with Multiplicity of Behavior,0.942709,"Learned locomotion policies can rapidly adapt to diverse environments similar
to those experienced during training but lack a mechanism for fast tuning when
they fail in an out-of-distribution test environment. This necessitates a slow
and iterative cycle of reward and environment redesign to achieve good
performance on a new task. As an alternative, we propose learning a single
policy that encodes a structured family of locomotion strategies that solve
training tasks in different ways, resulting in Multiplicity of Behavior (MoB).
Different strategies generalize differently and can be chosen in real-time for
new tasks or environments, bypassing the need for time-consuming retraining. We
release a fast, robust open-source MoB locomotion controller, Walk These Ways,
that can execute diverse gaits with variable footswing, posture, and speed,
unlocking diverse downstream tasks: crouching, hopping, high-speed running,
stair traversal, bracing against shoves, rhythmic dance, and more. Video and
code release: https://gmargo11.github.io/walk-these-ways/"
"Frame-level Prediction of Facial Expressions, Valence, Arousal and Action Units for Mobile Devices",0.325607,"In this paper, we consider the problem of real-time video-based facial
emotion analytics, namely, facial expression recognition, prediction of valence
and arousal and detection of action unit points. We propose the novel
frame-level emotion recognition algorithm by extracting facial features with
the single EfficientNet model pre-trained on AffectNet. As a result, our
approach may be implemented even for video analytics on mobile devices.
Experimental results for the large scale Aff-Wild2 database from the third
Affective Behavior Analysis in-the-wild (ABAW) Competition demonstrate that our
simple model is significantly better when compared to the VggFace baseline. In
particular, our method is characterized by 0.15-0.2 higher performance measures
for validation sets in uni-task Expression Classification, Valence-Arousal
Estimation and Expression Classification. Due to simplicity, our approach may
be considered as a new baseline for all four sub-challenges."
EfficientNeRF: Efficient Neural Radiance Fields,0.864665,"Neural Radiance Fields (NeRF) has been wildly applied to various tasks for
its high-quality representation of 3D scenes. It takes long per-scene training
time and per-image testing time. In this paper, we present EfficientNeRF as an
efficient NeRF-based method to represent 3D scene and synthesize novel-view
images. Although several ways exist to accelerate the training or testing
process, it is still difficult to much reduce time for both phases
simultaneously. We analyze the density and weight distribution of the sampled
points then propose valid and pivotal sampling at the coarse and fine stage,
respectively, to significantly improve sampling efficiency. In addition, we
design a novel data structure to cache the whole scene during testing to
accelerate the rendering speed. Overall, our method can reduce over 88\% of
training time, reach rendering speed of over 200 FPS, while still achieving
competitive accuracy. Experiments prove that our method promotes the
practicality of NeRF in the real world and enables many applications."
Metaphors in Pre-Trained Language Models: Probing and Generalization Across Datasets and Languages,0.449836,"Human languages are full of metaphorical expressions. Metaphors help people
understand the world by connecting new concepts and domains to more familiar
ones. Large pre-trained language models (PLMs) are therefore assumed to encode
metaphorical knowledge useful for NLP systems. In this paper, we investigate
this hypothesis for PLMs, by probing metaphoricity information in their
encodings, and by measuring the cross-lingual and cross-dataset generalization
of this information. We present studies in multiple metaphor detection datasets
and in four languages (i.e., English, Spanish, Russian, and Farsi). Our
extensive experiments suggest that contextual representations in PLMs do encode
metaphorical knowledge, and mostly in their middle layers. The knowledge is
transferable between languages and datasets, especially when the annotation is
consistent across training and testing sets. Our findings give helpful insights
for both cognitive and NLP scientists."
MultiCoNER: A Large-scale Multilingual dataset for Complex Named Entity Recognition,0.999854,"We present MultiCoNER, a large multilingual dataset for Named Entity
Recognition that covers 3 domains (Wiki sentences, questions, and search
queries) across 11 languages, as well as multilingual and code-mixing subsets.
This dataset is designed to represent contemporary challenges in NER, including
low-context scenarios (short and uncased text), syntactically complex entities
like movie titles, and long-tail entity distributions. The 26M token dataset is
compiled from public resources using techniques such as heuristic-based
sentence sampling, template extraction and slotting, and machine translation.
We applied two NER models on our dataset: a baseline XLM-RoBERTa model, and a
state-of-the-art GEMNET model that leverages gazetteers. The baseline achieves
moderate performance (macro-F1=54%), highlighting the difficulty of our data.
GEMNET, which uses gazetteers, improvement significantly (average improvement
of macro-F1=+30%). MultiCoNER poses challenges even for large pre-trained
language models, and we believe that it can help further research in building
robust NER systems. MultiCoNER is publicly available at
https://registry.opendata.aws/multiconer/ and we hope that this resource will
help advance research in various aspects of NER."
"Alexa, Let's Work Together: Introducing the First Alexa Prize TaskBot Challenge on Conversational Task Assistance",0.993697,"Since its inception in 2016, the Alexa Prize program has enabled hundreds of
university students to explore and compete to develop conversational agents
through the SocialBot Grand Challenge. The goal of the challenge is to build
agents capable of conversing coherently and engagingly with humans on popular
topics for 20 minutes, while achieving an average rating of at least 4.0/5.0.
However, as conversational agents attempt to assist users with increasingly
complex tasks, new conversational AI techniques and evaluation platforms are
needed. The Alexa Prize TaskBot challenge, established in 2021, builds on the
success of the SocialBot challenge by introducing the requirements of
interactively assisting humans with real-world Cooking and Do-It-Yourself
tasks, while making use of both voice and visual modalities. This challenge
requires the TaskBots to identify and understand the user's need, identify and
integrate task and domain knowledge into the interaction, and develop new ways
of engaging the user without distracting them from the task at hand, among
other challenges. This paper provides an overview of the TaskBot challenge,
describes the infrastructure support provided to the teams with the CoBot
Toolkit, and summarizes the approaches the participating teams took to overcome
the research challenges. Finally, it analyzes the performance of the competing
TaskBots during the first year of the competition."
Bangla hate speech detection on social media using attention-based recurrent neural network,0.75001,"Hate speech has spread more rapidly through the daily use of technology and,
most notably, by sharing your opinions or feelings on social media in a
negative aspect. Although numerous works have been carried out in detecting
hate speeches in English, German, and other languages, very few works have been
carried out in the context of the Bengali language. In contrast, millions of
people communicate on social media in Bengali. The few existing works that have
been carried out need improvements in both accuracy and interpretability. This
article proposed encoder decoder based machine learning model, a popular tool
in NLP, to classify user's Bengali comments on Facebook pages. A dataset of
7,425 Bengali comments, consisting of seven distinct categories of hate
speeches, was used to train and evaluate our model. For extracting and encoding
local features from the comments, 1D convolutional layers were used. Finally,
the attention mechanism, LSTM, and GRU based decoders have been used for
predicting hate speech categories. Among the three encoder decoder algorithms,
the attention-based decoder obtained the best accuracy (77%)."
Relation-Specific Attentions over Entity Mentions for Enhanced Document-Level Relation Extraction,0.419326,"Compared with traditional sentence-level relation extraction, document-level
relation extraction is a more challenging task where an entity in a document
may be mentioned multiple times and associated with multiple relations.
However, most methods of document-level relation extraction do not distinguish
between mention-level features and entity-level features, and just apply simple
pooling operation for aggregating mention-level features into entity-level
features. As a result, the distinct semantics between the different mentions of
an entity are overlooked. To address this problem, we propose RSMAN in this
paper which performs selective attentions over different entity mentions with
respect to candidate relations. In this manner, the flexible and
relation-specific representations of entities are obtained which indeed benefit
relation classification. Our extensive experiments upon two benchmark datasets
show that our RSMAN can bring significant improvements for some backbone models
to achieve state-of-the-art performance, especially when an entity have
multiple mentions in the document."
A Variational Hierarchical Model for Neural Cross-Lingual Summarization,0.29947,"The goal of the cross-lingual summarization (CLS) is to convert a document in
one language (e.g., English) to a summary in another one (e.g., Chinese).
Essentially, the CLS task is the combination of machine translation (MT) and
monolingual summarization (MS), and thus there exists the hierarchical
relationship between MT\&MS and CLS. Existing studies on CLS mainly focus on
utilizing pipeline methods or jointly training an end-to-end model through an
auxiliary MT or MS objective. However, it is very challenging for the model to
directly conduct CLS as it requires both the abilities to translate and
summarize. To address this issue, we propose a hierarchical model for the CLS
task, based on the conditional variational auto-encoder. The hierarchical model
contains two kinds of latent variables at the local and global levels,
respectively. At the local level, there are two latent variables, one for
translation and the other for summarization. As for the global level, there is
another latent variable for cross-lingual summarization conditioned on the two
local-level variables. Experiments on two language directions (English-Chinese)
verify the effectiveness and superiority of the proposed approach. In addition,
we show that our model is able to generate better cross-lingual summaries than
comparison models in the few-shot setting."
Seeing Like a Toolkit: How Toolkits Envision the Work of AI Ethics,0.171851,"Numerous toolkits have been developed to support ethical AI development.
However, toolkits, like all tools, encode assumptions in their design about
what work should be done and how. In this paper, we conduct a qualitative
analysis of 27 AI ethics toolkits to critically examine how the work of ethics
is imagined and how it is supported by these toolkits. Specifically, we examine
the discourses toolkits rely on when talking about ethical issues, who they
imagine should do the work of ethics, and how they envision the work practices
involved in addressing ethics. Among the toolkits, we identify a mismatch
between the imagined work of ethics and the support the toolkits provide for
doing that work. In particular, we identify a lack of guidance around how to
navigate labor, organizational, and institutional power dynamics as they relate
to performing ethical work. We use these omissions to chart future work for
researchers and designers of AI ethics toolkits."
Delving into Out-of-Distribution Detection with Vision-Language Representations,0.693359,"Recognizing out-of-distribution (OOD) samples is critical for machine
learning systems deployed in the open world. The vast majority of OOD detection
methods are driven by a single modality (e.g., either vision or language),
leaving the rich information in multi-modal representations untapped. Inspired
by the recent success of vision-language pre-training, this paper enriches the
landscape of OOD detection from a single-modal to a multi-modal regime.
Particularly, we propose Maximum Concept Matching (MCM), a simple yet effective
zero-shot OOD detection method based on aligning visual features with textual
concepts. We contribute in-depth analysis and theoretical insights to
understand the effectiveness of MCM. Extensive experiments demonstrate that MCM
achieves superior performance on a wide variety of real-world tasks. MCM with
vision-language features outperforms a common baseline with pure visual
features on a hard OOD task with semantically similar classes by 13.1% (AUROC).
Code is available at https://github.com/deeplearning-wisc/MCM."
Unified Pretraining Framework for Document Understanding,0.299123,"Document intelligence automates the extraction of information from documents
and supports many business applications. Recent self-supervised learning
methods on large-scale unlabeled document datasets have opened up promising
directions towards reducing annotation efforts by training models with
self-supervised objectives. However, most of the existing document pretraining
methods are still language-dominated. We present UDoc, a new unified
pretraining framework for document understanding. UDoc is designed to support
most document understanding tasks, extending the Transformer to take multimodal
embeddings as input. Each input element is composed of words and visual
features from a semantic region of the input document image. An important
feature of UDoc is that it learns a generic representation by making use of
three self-supervised losses, encouraging the representation to model
sentences, learn similarities, and align modalities. Extensive empirical
analysis demonstrates that the pretraining procedure learns better joint
representations and leads to improvements in downstream tasks."
Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation,0.517115,"A diffusion model learns to predict a vector field of gradients. We propose
to apply chain rule on the learned gradients, and back-propagate the score of a
diffusion model through the Jacobian of a differentiable renderer, which we
instantiate to be a voxel radiance field. This setup aggregates 2D scores at
multiple camera viewpoints into a 3D score, and repurposes a pretrained 2D
model for 3D data generation. We identify a technical challenge of distribution
mismatch that arises in this application, and propose a novel estimation
mechanism to resolve it. We run our algorithm on several off-the-shelf
diffusion image generative models, including the recently released Stable
Diffusion trained on the large-scale LAION dataset."
Empowering Graph Representation Learning with Test-Time Graph Transformation,0.283025,"As powerful tools for representation learning on graphs, graph neural
networks (GNNs) have facilitated various applications from drug discovery to
recommender systems. Nevertheless, the effectiveness of GNNs is immensely
challenged by issues related to data quality, such as distribution shift,
abnormal features and adversarial attacks. Recent efforts have been made on
tackling these issues from a modeling perspective which requires additional
cost of changing model architectures or re-training model parameters. In this
work, we provide a data-centric view to tackle these issues and propose a graph
transformation framework named GTrans which adapts and refines graph data at
test time to achieve better performance. We provide theoretical analysis on the
design of the framework and discuss why adapting graph data works better than
adapting the model. Extensive experiments have demonstrated the effectiveness
of GTrans on three distinct scenarios for eight benchmark datasets where
suboptimal data is presented. Remarkably, GTrans performs the best in most
cases with improvements up to 2.8%, 8.2% and 3.8% over the best baselines on
three experimental settings. Code is released at
https://github.com/ChandlerBang/GTrans."
Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small,0.76108,"Research in mechanistic interpretability seeks to explain behaviors of
machine learning models in terms of their internal components. However, most
previous work either focuses on simple behaviors in small models, or describes
complicated behaviors in larger models with broad strokes. In this work, we
bridge this gap by presenting an explanation for how GPT-2 small performs a
natural language task called indirect object identification (IOI). Our
explanation encompasses 26 attention heads grouped into 7 main classes, which
we discovered using a combination of interpretability approaches relying on
causal interventions. To our knowledge, this investigation is the largest
end-to-end attempt at reverse-engineering a natural behavior ""in the wild"" in a
language model. We evaluate the reliability of our explanation using three
quantitative criteria--faithfulness, completeness and minimality. Though these
criteria support our explanation, they also point to remaining gaps in our
understanding. Our work provides evidence that a mechanistic understanding of
large ML models is feasible, opening opportunities to scale our understanding
to both larger models and more complex tasks."
Legal Case Document Summarization: Extractive and Abstractive Methods and their Evaluation,0.437349,"Summarization of legal case judgement documents is a challenging problem in
Legal NLP. However, not much analyses exist on how different families of
summarization models (e.g., extractive vs. abstractive) perform when applied to
legal case documents. This question is particularly important since many recent
transformer-based abstractive summarization models have restrictions on the
number of input tokens, and legal documents are known to be very long. Also, it
is an open question on how best to evaluate legal case document summarization
systems. In this paper, we carry out extensive experiments with several
extractive and abstractive summarization methods (both supervised and
unsupervised) over three legal summarization datasets that we have developed.
Our analyses, that includes evaluation by law practitioners, lead to several
interesting insights on legal summarization in specific and long document
summarization in general."
Online Continual Learning with Contrastive Vision Transformer,0.145869,"Online continual learning (online CL) studies the problem of learning
sequential tasks from an online data stream without task boundaries, aiming to
adapt to new data while alleviating catastrophic forgetting on the past tasks.
This paper proposes a framework Contrastive Vision Transformer (CVT), which
designs a focal contrastive learning strategy based on a transformer
architecture, to achieve a better stability-plasticity trade-off for online CL.
Specifically, we design a new external attention mechanism for online CL that
implicitly captures previous tasks' information. Besides, CVT contains
learnable focuses for each class, which could accumulate the knowledge of
previous classes to alleviate forgetting. Based on the learnable focuses, we
design a focal contrastive loss to rebalance contrastive learning between new
and past classes and consolidate previously learned representations. Moreover,
CVT contains a dual-classifier structure for decoupling learning current
classes and balancing all observed classes. The extensive experimental results
show that our approach achieves state-of-the-art performance with even fewer
parameters on online CL benchmarks and effectively alleviates the catastrophic
forgetting."
Problems with Cosine as a Measure of Embedding Similarity for High Frequency Words,0.282368,"Cosine similarity of contextual embeddings is used in many NLP tasks (e.g.,
QA, IR, MT) and metrics (e.g., BERTScore). Here, we uncover systematic ways in
which word similarities estimated by cosine over BERT embeddings are
understated and trace this effect to training data frequency. We find that
relative to human judgements, cosine similarity underestimates the similarity
of frequent words with other instances of the same word or other words across
contexts, even after controlling for polysemy and other factors. We conjecture
that this underestimation of similarity for high frequency words is due to
differences in the representational geometry of high and low frequency words
and provide a formal argument for the two-dimensional case."
Active Learning by Feature Mixing,0.57656,"The promise of active learning (AL) is to reduce labelling costs by selecting
the most valuable examples to annotate from a pool of unlabelled data.
Identifying these examples is especially challenging with high-dimensional data
(e.g. images, videos) and in low-data regimes. In this paper, we propose a
novel method for batch AL called ALFA-Mix. We identify unlabelled instances
with sufficiently-distinct features by seeking inconsistencies in predictions
resulting from interventions on their representations. We construct
interpolations between representations of labelled and unlabelled instances
then examine the predicted labels. We show that inconsistencies in these
predictions help discovering features that the model is unable to recognise in
the unlabelled instances. We derive an efficient implementation based on a
closed-form solution to the optimal interpolation causing changes in
predictions. Our method outperforms all recent AL approaches in 30 different
settings on 12 benchmarks of images, videos, and non-visual data. The
improvements are especially significant in low-data regimes and on self-trained
vision transformers, where ALFA-Mix outperforms the state-of-the-art in 59% and
43% of the experiments respectively."
Dynamic Global Memory for Document-level Argument Extraction,0.650797,"Extracting informative arguments of events from news articles is a
challenging problem in information extraction, which requires a global
contextual understanding of each document. While recent work on document-level
extraction has gone beyond single-sentence and increased the cross-sentence
inference capability of end-to-end models, they are still restricted by certain
input sequence length constraints and usually ignore the global context between
events. To tackle this issue, we introduce a new global neural generation-based
framework for document-level event argument extraction by constructing a
document memory store to record the contextual event information and leveraging
it to implicitly and explicitly help with decoding of arguments for later
events. Empirical results show that our framework outperforms prior methods
substantially and it is more robust to adversarially annotated examples with
our constrained decoding design. (Our code and resources are available at
https://github.com/xinyadu/memory_docie for research purpose.)"
"DiRA: Discriminative, Restorative, and Adversarial Learning for Self-supervised Medical Image Analysis",0.647909,"Discriminative learning, restorative learning, and adversarial learning have
proven beneficial for self-supervised learning schemes in computer vision and
medical imaging. Existing efforts, however, omit their synergistic effects on
each other in a ternary setup, which, we envision, can significantly benefit
deep semantic representation learning. To realize this vision, we have
developed DiRA, the first framework that unites discriminative, restorative,
and adversarial learning in a unified manner to collaboratively glean
complementary visual information from unlabeled medical images for fine-grained
semantic representation learning. Our extensive experiments demonstrate that
DiRA (1) encourages collaborative learning among three learning ingredients,
resulting in more generalizable representation across organs, diseases, and
modalities; (2) outperforms fully supervised ImageNet models and increases
robustness in small data regimes, reducing annotation cost across multiple
medical imaging applications; (3) learns fine-grained semantic representation,
facilitating accurate lesion localization with only image-level annotation; and
(4) enhances state-of-the-art restorative approaches, revealing that DiRA is a
general mechanism for united representation learning. All code and pre-trained
models are available at https: //github.com/JLiangLab/DiRA."
SafeText: A Benchmark for Exploring Physical Safety in Language Models,0.864665,"Understanding what constitutes safe text is an important issue in natural
language processing and can often prevent the deployment of models deemed
harmful and unsafe. One such type of safety that has been scarcely studied is
commonsense physical safety, i.e. text that is not explicitly violent and
requires additional commonsense knowledge to comprehend that it leads to
physical harm. We create the first benchmark dataset, SafeText, comprising
real-life scenarios with paired safe and physically unsafe pieces of advice. We
utilize SafeText to empirically study commonsense physical safety across
various models designed for text generation and commonsense reasoning tasks. We
find that state-of-the-art large language models are susceptible to the
generation of unsafe text and have difficulty rejecting unsafe advice. As a
result, we argue for further studies of safety and the assessment of
commonsense physical safety in models before release."
DyLoRA: Parameter Efficient Tuning of Pre-trained Models using Dynamic Search-Free Low-Rank Adaptation,0.549166,"With the ever-growing size of pretrained models (PMs), fine-tuning them has
become more expensive and resource-hungry. As a remedy, low-rank adapters
(LoRA) keep the main pretrained weights of the model frozen and just introduce
some learnable truncated SVD modules (so-called LoRA blocks) to the model.
While LoRA blocks are parameter-efficient, they suffer from two major problems:
first, the size of these blocks is fixed and cannot be modified after training
(for example, if we need to change the rank of LoRA blocks, then we need to
re-train them from scratch); second, optimizing their rank requires an
exhaustive search and effort. In this work, we introduce a dynamic low-rank
adaptation (DyLoRA) technique to address these two problems together. Our
DyLoRA method trains LoRA blocks for a range of ranks instead of a single rank
by sorting the representation learned by the adapter module at different ranks
during training. We evaluate our solution on different natural language
understanding (GLUE benchmark) and language generation tasks (E2E, DART and
WebNLG) using different pretrained models such as RoBERTa and GPT with
different sizes. Our results show that we can train dynamic search-free models
with DyLoRA at least 4 to 7 times (depending to the task) faster than LoRA
without significantly compromising performance. Moreover, our models can
perform consistently well on a much larger range of ranks compared to LoRA."
UniMSE: Towards Unified Multimodal Sentiment Analysis and Emotion Recognition,-1.0,"Multimodal sentiment analysis (MSA) and emotion recognition in conversation
(ERC) are key research topics for computers to understand human behaviors. From
a psychological perspective, emotions are the expression of affect or feelings
during a short period, while sentiments are formed and held for a longer
period. However, most existing works study sentiment and emotion separately and
do not fully exploit the complementary knowledge behind the two. In this paper,
we propose a multimodal sentiment knowledge-sharing framework (UniMSE) that
unifies MSA and ERC tasks from features, labels, and models. We perform
modality fusion at the syntactic and semantic levels and introduce contrastive
learning between modalities and samples to better capture the difference and
consistency between sentiments and emotions. Experiments on four public
benchmark datasets, MOSI, MOSEI, MELD, and IEMOCAP, demonstrate the
effectiveness of the proposed method and achieve consistent improvements
compared with state-of-the-art methods."
In-Hand 3D Object Scanning from an RGB Sequence,0.597316,"We propose a method for in-hand 3D scanning of an unknown object with a
monocular camera. Our method relies on a neural implicit surface representation
that captures both the geometry and the appearance of the object, however, by
contrast with most NeRF-based methods, we do not assume that the camera-object
relative poses are known. Instead, we simultaneously optimize both the object
shape and the pose trajectory. As direct optimization over all shape and pose
parameters is prone to fail without coarse-level initialization, we propose an
incremental approach that starts by splitting the sequence into carefully
selected overlapping segments within which the optimization is likely to
succeed. We reconstruct the object shape and track its poses independently
within each segment, then merge all the segments before performing a global
optimization. We show that our method is able to reconstruct the shape and
color of both textured and challenging texture-less objects, outperforms
classical methods that rely only on appearance features, and that its
performance is close to recent methods that assume known camera poses."
FlowFormer: A Transformer Architecture for Optical Flow,0.998661,"We introduce optical Flow transFormer, dubbed as FlowFormer, a
transformer-based neural network architecture for learning optical flow.
FlowFormer tokenizes the 4D cost volume built from an image pair, encodes the
cost tokens into a cost memory with alternate-group transformer (AGT) layers in
a novel latent space, and decodes the cost memory via a recurrent transformer
decoder with dynamic positional cost queries. On the Sintel benchmark,
FlowFormer achieves 1.159 and 2.088 average end-point-error (AEPE) on the clean
and final pass, a 16.5% and 15.5% error reduction from the best published
result (1.388 and 2.47). Besides, FlowFormer also achieves strong
generalization performance. Without being trained on Sintel, FlowFormer
achieves 1.01 AEPE on the clean pass of Sintel training set, outperforming the
best published result (1.29) by 21.7%."
The NCTE Transcripts: A Dataset of Elementary Math Classroom Transcripts,0.781799,"Classroom discourse is a core medium of instruction - analyzing it can
provide a window into teaching and learning as well as driving the development
of new tools for improving instruction. We introduce the largest dataset of
mathematics classroom transcripts available to researchers, and demonstrate how
this data can help improve instruction. The dataset consists of 1,660 45-60
minute long 4th and 5th grade elementary mathematics observations collected by
the National Center for Teacher Effectiveness (NCTE) between 2010-2013. The
anonymized transcripts represent data from 317 teachers across 4 school
districts that serve largely historically marginalized students. The
transcripts come with rich metadata, including turn-level annotations for
dialogic discourse moves, classroom observation scores, demographic
information, survey responses and student test scores. We demonstrate that our
natural language processing model, trained on our turn-level annotations, can
learn to identify dialogic discourse moves and these moves are correlated with
better classroom observation scores and learning outcomes. This dataset opens
up several possibilities for researchers, educators and policymakers to learn
about and improve K-12 instruction. The dataset can be found at
https://github.com/ddemszky/classroom-transcript-analysis."
Ranking Info Noise Contrastive Estimation: Boosting Contrastive Learning via Ranked Positives,0.320536,"This paper introduces Ranking Info Noise Contrastive Estimation (RINCE), a
new member in the family of InfoNCE losses that preserves a ranked ordering of
positive samples. In contrast to the standard InfoNCE loss, which requires a
strict binary separation of the training pairs into similar and dissimilar
samples, RINCE can exploit information about a similarity ranking for learning
a corresponding embedding space. We show that the proposed loss function learns
favorable embeddings compared to the standard InfoNCE whenever at least noisy
ranking information can be obtained or when the definition of positives and
negatives is blurry. We demonstrate this for a supervised classification task
with additional superclass labels and noisy similarity scores. Furthermore, we
show that RINCE can also be applied to unsupervised training with experiments
on unsupervised representation learning from videos. In particular, the
embedding yields higher classification accuracy, retrieval rates and performs
better in out-of-distribution detection than the standard InfoNCE loss."
Interpretability for Language Learners Using Example-Based Grammatical Error Correction,0.451257,"Grammatical Error Correction (GEC) should not focus only on high accuracy of
corrections but also on interpretability for language learning. However,
existing neural-based GEC models mainly aim at improving accuracy, and their
interpretability has not been explored. A promising approach for improving
interpretability is an example-based method, which uses similar retrieved
examples to generate corrections. In addition, examples are beneficial in
language learning, helping learners understand the basis of grammatically
incorrect/correct texts and improve their confidence in writing. Therefore, we
hypothesize that incorporating an example-based method into GEC can improve
interpretability as well as support language learners. In this study, we
introduce an Example-Based GEC (EB-GEC) that presents examples to language
learners as a basis for a correction result. The examples consist of pairs of
correct and incorrect sentences similar to a given input and its predicted
correction. Experiments demonstrate that the examples presented by EB-GEC help
language learners decide to accept or refuse suggestions from the GEC output.
Furthermore, the experiments also show that retrieved examples improve the
accuracy of corrections."
3D Pose Based Feedback for Physical Exercises,0.147035,"Unsupervised self-rehabilitation exercises and physical training can cause
serious injuries if performed incorrectly. We introduce a learning-based
framework that identifies the mistakes made by a user and proposes corrective
measures for easier and safer individual training. Our framework does not rely
on hard-coded, heuristic rules. Instead, it learns them from data, which
facilitates its adaptation to specific user needs. To this end, we use a Graph
Convolutional Network (GCN) architecture acting on the user's pose sequence to
model the relationship between the body joints trajectories. To evaluate our
approach, we introduce a dataset with 3 different physical exercises. Our
approach yields 90.9% mistake identification accuracy and successfully corrects
94.2% of the mistakes."
XLCoST: A Benchmark Dataset for Cross-lingual Code Intelligence,0.864665,"Recent advances in machine learning have significantly improved the
understanding of source code data and achieved good performance on a number of
downstream tasks. Open source repositories like GitHub enable this process with
rich unlabeled code data. However, the lack of high quality labeled data has
largely hindered the progress of several code related tasks, such as program
translation, summarization, synthesis, and code search. This paper introduces
XLCoST, Cross-Lingual Code SnippeT dataset, a new benchmark dataset for
cross-lingual code intelligence. Our dataset contains fine-grained parallel
data from 8 languages (7 commonly used programming languages and English), and
supports 10 cross-lingual code tasks. To the best of our knowledge, it is the
largest parallel dataset for source code both in terms of size and the number
of languages. We also provide the performance of several state-of-the-art
baseline models for each task. We believe this new dataset can be a valuable
asset for the research community and facilitate the development and validation
of new methods for cross-lingual code intelligence."
LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models,0.637793,"This study focuses on using large language models (LLMs) as a planner for
embodied agents that can follow natural language instructions to complete
complex tasks in a visually-perceived environment. The high data cost and poor
sample efficiency of existing methods hinders the development of versatile
agents that are capable of many tasks and can learn new tasks quickly. In this
work, we propose a novel method, LLM-Planner, that harnesses the power of large
language models to do few-shot planning for embodied agents. We further propose
a simple but effective way to enhance LLMs with physical grounding to generate
and update plans that are grounded in the current environment. Experiments on
the ALFRED dataset show that our method can achieve very competitive few-shot
performance: Despite using less than 0.5% of paired training data, LLM-Planner
achieves competitive performance with recent baselines that are trained using
the full training data. Existing methods can barely complete any task
successfully under the same few-shot setting. Our work opens the door for
developing versatile and sample-efficient embodied agents that can quickly
learn many tasks. Website: https://dki-lab.github.io/LLM-Planner"
"Vision-Language Pre-training: Basics, Recent Advances, and Future Trends",0.408797,"This paper surveys vision-language pre-training (VLP) methods for multimodal
intelligence that have been developed in the last few years. We group these
approaches into three categories: ($i$) VLP for image-text tasks, such as image
captioning, image-text retrieval, visual question answering, and visual
grounding; ($ii$) VLP for core computer vision tasks, such as (open-set) image
classification, object detection, and segmentation; and ($iii$) VLP for
video-text tasks, such as video captioning, video-text retrieval, and video
question answering. For each category, we present a comprehensive review of
state-of-the-art methods, and discuss the progress that has been made and
challenges still being faced, using specific systems and models as case
studies. In addition, for each category, we discuss advanced topics being
actively explored in the research community, such as big foundation models,
unified modeling, in-context few-shot learning, knowledge, robustness, and
computer vision in the wild, to name a few."
Recurrent Memory Transformer,0.133018,"Transformer-based models show their effectiveness across multiple domains and
tasks. The self-attention allows to combine information from all sequence
elements into context-aware representations. However, global and local
information has to be stored mostly in the same element-wise representations.
Moreover, the length of an input sequence is limited by quadratic computational
complexity of self-attention.
  In this work, we propose and study a memory-augmented segment-level recurrent
Transformer (RMT). Memory allows to store and process local and global
information as well as to pass information between segments of the long
sequence with the help of recurrence.
  We implement a memory mechanism with no changes to Transformer model by
adding special memory tokens to the input or output sequence. Then the model is
trained to control both memory operations and sequence representations
processing.
  Results of experiments show that RMT performs on par with the Transformer-XL
on language modeling for smaller memory sizes and outperforms it for tasks that
require longer sequence processing. We show that adding memory tokens to Tr-XL
is able to improve its performance. This makes Recurrent Memory Transformer a
promising architecture for applications that require learning of long-term
dependencies and general purpose in memory processing, such as algorithmic
tasks and reasoning."
AnyFace: Free-style Text-to-Face Synthesis and Manipulation,0.19608,"Existing text-to-image synthesis methods generally are only applicable to
words in the training dataset. However, human faces are so variable to be
described with limited words. So this paper proposes the first free-style
text-to-face method namely AnyFace enabling much wider open world applications
such as metaverse, social media, cosmetics, forensics, etc. AnyFace has a novel
two-stream framework for face image synthesis and manipulation given arbitrary
descriptions of the human face. Specifically, one stream performs text-to-face
generation and the other conducts face image reconstruction. Facial text and
image features are extracted using the CLIP (Contrastive Language-Image
Pre-training) encoders. And a collaborative Cross Modal Distillation (CMD)
module is designed to align the linguistic and visual features across these two
streams. Furthermore, a Diverse Triplet Loss (DT loss) is developed to model
fine-grained features and improve facial diversity. Extensive experiments on
Multi-modal CelebA-HQ and CelebAText-HQ demonstrate significant advantages of
AnyFace over state-of-the-art methods. AnyFace can achieve high-quality,
high-resolution, and high-diversity face synthesis and manipulation results
without any constraints on the number and content of input captions."
Extractive is not Faithful: An Investigation of Broad Unfaithfulness Problems in Extractive Summarization,0.212583,"The problems of unfaithful summaries have been widely discussed under the
context of abstractive summarization. Though extractive summarization is less
prone to the common unfaithfulness issues of abstractive summaries, does that
mean extractive is equal to faithful? Turns out that the answer is no. In this
work, we define a typology with five types of broad unfaithfulness problems
(including and beyond not-entailment) that can appear in extractive summaries,
including incorrect coreference, incomplete coreference, incorrect discourse,
incomplete discourse, as well as other misleading information. We ask humans to
label these problems out of 1600 English summaries produced by 16 diverse
extractive systems. We find that 30% of the summaries have at least one of the
five issues. To automatically detect these problems, we find that 5 existing
faithfulness evaluation metrics for summarization have poor correlations with
human judgment. To remedy this, we propose a new metric, ExtEval, that is
designed for detecting unfaithful extractive summaries and is shown to have the
best performance. We hope our work can increase the awareness of unfaithfulness
problems in extractive summarization and help future work to evaluate and
resolve these issues. Our data and code are publicly available at
https://github.com/ZhangShiyue/extractive_is_not_faithful"
Unknown-Aware Domain Adversarial Learning for Open-Set Domain Adaptation,0.159793,"Open-Set Domain Adaptation (OSDA) assumes that a target domain contains
unknown classes, which are not discovered in a source domain. Existing domain
adversarial learning methods are not suitable for OSDA because distribution
matching with $\textit{unknown}$ classes leads to negative transfer. Previous
OSDA methods have focused on matching the source and the target distribution by
only utilizing $\textit{known}$ classes. However, this $\textit{known}$-only
matching may fail to learn the target-$\textit{unknown}$ feature space.
Therefore, we propose Unknown-Aware Domain Adversarial Learning (UADAL), which
$\textit{aligns}$ the source and the target-$\textit{known}$ distribution while
simultaneously $\textit{segregating}$ the target-$\textit{unknown}$
distribution in the feature alignment procedure. We provide theoretical
analyses on the optimized state of the proposed $\textit{unknown-aware}$
feature alignment, so we can guarantee both $\textit{alignment}$ and
$\textit{segregation}$ theoretically. Empirically, we evaluate UADAL on the
benchmark datasets, which shows that UADAL outperforms other methods with
better feature alignments by reporting state-of-the-art performances."
Seed-Guided Topic Discovery with Out-of-Vocabulary Seeds,0.384472,"Discovering latent topics from text corpora has been studied for decades.
Many existing topic models adopt a fully unsupervised setting, and their
discovered topics may not cater to users' particular interests due to their
inability of leveraging user guidance. Although there exist seed-guided topic
discovery approaches that leverage user-provided seeds to discover
topic-representative terms, they are less concerned with two factors: (1) the
existence of out-of-vocabulary seeds and (2) the power of pre-trained language
models (PLMs). In this paper, we generalize the task of seed-guided topic
discovery to allow out-of-vocabulary seeds. We propose a novel framework, named
SeeTopic, wherein the general knowledge of PLMs and the local semantics learned
from the input corpus can mutually benefit each other. Experiments on three
real datasets from different domains demonstrate the effectiveness of SeeTopic
in terms of topic coherence, accuracy, and diversity."
Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback,0.999184,"We apply preference modeling and reinforcement learning from human feedback
(RLHF) to finetune language models to act as helpful and harmless assistants.
We find this alignment training improves performance on almost all NLP
evaluations, and is fully compatible with training for specialized skills such
as python coding and summarization. We explore an iterated online mode of
training, where preference models and RL policies are updated on a weekly
cadence with fresh human feedback data, efficiently improving our datasets and
models. Finally, we investigate the robustness of RLHF training, and identify a
roughly linear relation between the RL reward and the square root of the KL
divergence between the policy and its initialization. Alongside our main
results, we perform peripheral analyses on calibration, competing objectives,
and the use of OOD detection, compare our models with human writers, and
provide samples from our models using prompts appearing in recent related work."
Photorealistic Monocular 3D Reconstruction of Humans Wearing Clothing,0.701912,"We present PHORHUM, a novel, end-to-end trainable, deep neural network
methodology for photorealistic 3D human reconstruction given just a monocular
RGB image. Our pixel-aligned method estimates detailed 3D geometry and, for the
first time, the unshaded surface color together with the scene illumination.
Observing that 3D supervision alone is not sufficient for high fidelity color
reconstruction, we introduce patch-based rendering losses that enable reliable
color reconstruction on visible parts of the human, and detailed and plausible
color estimation for the non-visible parts. Moreover, our method specifically
addresses methodological and practical limitations of prior work in terms of
representing geometry, albedo, and illumination effects, in an end-to-end model
where factors can be effectively disentangled. In extensive experiments, we
demonstrate the versatility and robustness of our approach. Our
state-of-the-art results validate the method qualitatively and for different
metrics, for both geometric and color reconstruction."
Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation,0.687172,"In this paper we present Mask DINO, a unified object detection and
segmentation framework. Mask DINO extends DINO (DETR with Improved Denoising
Anchor Boxes) by adding a mask prediction branch which supports all image
segmentation tasks (instance, panoptic, and semantic). It makes use of the
query embeddings from DINO to dot-product a high-resolution pixel embedding map
to predict a set of binary masks. Some key components in DINO are extended for
segmentation through a shared architecture and training process. Mask DINO is
simple, efficient, and scalable, and it can benefit from joint large-scale
detection and segmentation datasets. Our experiments show that Mask DINO
significantly outperforms all existing specialized segmentation methods, both
on a ResNet-50 backbone and a pre-trained model with SwinL backbone. Notably,
Mask DINO establishes the best results to date on instance segmentation (54.5
AP on COCO), panoptic segmentation (59.4 PQ on COCO), and semantic segmentation
(60.8 mIoU on ADE20K) among models under one billion parameters. Code is
available at \url{https://github.com/IDEACVR/MaskDINO}."
V2X-ViT: Vehicle-to-Everything Cooperative Perception with Vision Transformer,0.827607,"In this paper, we investigate the application of Vehicle-to-Everything (V2X)
communication to improve the perception performance of autonomous vehicles. We
present a robust cooperative perception framework with V2X communication using
a novel vision Transformer. Specifically, we build a holistic attention model,
namely V2X-ViT, to effectively fuse information across on-road agents (i.e.,
vehicles and infrastructure). V2X-ViT consists of alternating layers of
heterogeneous multi-agent self-attention and multi-scale window self-attention,
which captures inter-agent interaction and per-agent spatial relationships.
These key modules are designed in a unified Transformer architecture to handle
common V2X challenges, including asynchronous information sharing, pose errors,
and heterogeneity of V2X components. To validate our approach, we create a
large-scale V2X perception dataset using CARLA and OpenCDA. Extensive
experimental results demonstrate that V2X-ViT sets new state-of-the-art
performance for 3D object detection and achieves robust performance even under
harsh, noisy environments. The code is available at
https://github.com/DerrickXuNu/v2x-vit."
Concrete Score Matching: Generalized Score Matching for Discrete Data,0.516264,"Representing probability distributions by the gradient of their density
functions has proven effective in modeling a wide range of continuous data
modalities. However, this representation is not applicable in discrete domains
where the gradient is undefined. To this end, we propose an analogous score
function called the ""Concrete score"", a generalization of the (Stein) score for
discrete settings. Given a predefined neighborhood structure, the Concrete
score of any input is defined by the rate of change of the probabilities with
respect to local directional changes of the input. This formulation allows us
to recover the (Stein) score in continuous domains when measuring such changes
by the Euclidean distance, while using the Manhattan distance leads to our
novel score function in discrete domains. Finally, we introduce a new framework
to learn such scores from samples called Concrete Score Matching (CSM), and
propose an efficient training objective to scale our approach to high
dimensions. Empirically, we demonstrate the efficacy of CSM on density
estimation tasks on a mixture of synthetic, tabular, and high-dimensional image
datasets, and demonstrate that it performs favorably relative to existing
baselines for modeling discrete data."
Dialog Inpainting: Turning Documents into Dialogs,0.267734,"Many important questions (e.g. ""How to eat healthier?"") require conversation
to establish context and explore in depth. However, conversational question
answering (ConvQA) systems have long been stymied by scarce training data that
is expensive to collect. To address this problem, we propose a new technique
for synthetically generating diverse and high-quality dialog data: dialog
inpainting. Our approach takes the text of any document and transforms it into
a two-person dialog between the writer and an imagined reader: we treat
sentences from the article as utterances spoken by the writer, and then use a
dialog inpainter to predict what the imagined reader asked or said in between
each of the writer's utterances. By applying this approach to passages from
Wikipedia and the web, we produce WikiDialog and WebDialog, two datasets
totalling 19 million diverse information-seeking dialogs -- 1,000x larger than
the largest existing ConvQA dataset. Furthermore, human raters judge the answer
adequacy and conversationality of WikiDialog to be as good or better than
existing manually-collected datasets. Using our inpainted data to pre-train
ConvQA retrieval systems, we significantly advance state-of-the-art across
three benchmarks (QReCC, OR-QuAC, TREC CAsT) yielding up to 40% relative gains
on standard evaluation metrics."
Compositional Semantic Parsing with Large Language Models,0.516877,"Humans can reason compositionally when presented with new tasks. Previous
research shows that appropriate prompting techniques enable large language
models (LLMs) to solve artificial compositional generalization tasks such as
SCAN. In this work, we identify additional challenges in more realistic
semantic parsing tasks with larger vocabulary and refine these prompting
techniques to address them. Our best method is based on least-to-most
prompting: it decomposes the problem using prompting-based syntactic parsing,
then uses this decomposition to select appropriate exemplars and to
sequentially generate the semantic parse. This method allows us to set a new
state of the art for CFQ while requiring only 1% of the training data used by
traditional approaches. Due to the general nature of our approach, we expect
similar efforts will lead to new results in other tasks and domains, especially
for knowledge-intensive applications."
LEVEN: A Large-Scale Chinese Legal Event Detection Dataset,0.272608,"Recognizing facts is the most fundamental step in making judgments, hence
detecting events in the legal documents is important to legal case analysis
tasks. However, existing Legal Event Detection (LED) datasets only concern
incomprehensive event types and have limited annotated data, which restricts
the development of LED methods and their downstream applications. To alleviate
these issues, we present LEVEN a large-scale Chinese LEgal eVENt detection
dataset, with 8,116 legal documents and 150,977 human-annotated event mentions
in 108 event types. Not only charge-related events, LEVEN also covers general
events, which are critical for legal case understanding but neglected in
existing LED datasets. To our knowledge, LEVEN is the largest LED dataset and
has dozens of times the data scale of others, which shall significantly promote
the training and evaluation of LED methods. The results of extensive
experiments indicate that LED is challenging and needs further effort.
Moreover, we simply utilize legal events as side information to promote
downstream applications. The method achieves improvements of average 2.2 points
precision in low-resource judgment prediction, and 1.5 points mean average
precision in unsupervised case retrieval, which suggests the fundamentality of
LED. The source code and dataset can be obtained from
https://github.com/thunlp/LEVEN."
SPACE: Speech-driven Portrait Animation with Controllable Expression,0.175364,"Animating portraits using speech has received growing attention in recent
years, with various creative and practical use cases. An ideal generated video
should have good lip sync with the audio, natural facial expressions and head
motions, and high frame quality. In this work, we present SPACE, which uses
speech and a single image to generate high-resolution, and expressive videos
with realistic head pose, without requiring a driving video. It uses a
multi-stage approach, combining the controllability of facial landmarks with
the high-quality synthesis power of a pretrained face generator. SPACE also
allows for the control of emotions and their intensities. Our method
outperforms prior methods in objective metrics for image quality and facial
motions and is strongly preferred by users in pair-wise comparisons. The
project website is available at https://deepimagination.cc/SPACE/"
The Road to Explainability is Paved with Bias: Measuring the Fairness of Explanations,0.114216,"Machine learning models in safety-critical settings like healthcare are often
blackboxes: they contain a large number of parameters which are not transparent
to users. Post-hoc explainability methods where a simple, human-interpretable
model imitates the behavior of these blackbox models are often proposed to help
users trust model predictions. In this work, we audit the quality of such
explanations for different protected subgroups using real data from four
settings in finance, healthcare, college admissions, and the US justice system.
Across two different blackbox model architectures and four popular
explainability methods, we find that the approximation quality of explanation
models, also known as the fidelity, differs significantly between subgroups. We
also demonstrate that pairing explainability methods with recent advances in
robust machine learning can improve explanation fairness in some settings.
However, we highlight the importance of communicating details of non-zero
fidelity gaps to users, since a single solution might not exist across all
settings. Finally, we discuss the implications of unfair explanation models as
a challenging and understudied problem facing the machine learning community."
ComFact: A Benchmark for Linking Contextual Commonsense Knowledge,0.981684,"Understanding rich narratives, such as dialogues and stories, often requires
natural language processing systems to access relevant knowledge from
commonsense knowledge graphs. However, these systems typically retrieve facts
from KGs using simple heuristics that disregard the complex challenges of
identifying situationally-relevant commonsense knowledge (e.g.,
contextualization, implicitness, ambiguity).
  In this work, we propose the new task of commonsense fact linking, where
models are given contexts and trained to identify situationally-relevant
commonsense knowledge from KGs. Our novel benchmark, ComFact, contains ~293k
in-context relevance annotations for commonsense triplets across four
stylistically diverse dialogue and storytelling datasets. Experimental results
confirm that heuristic fact linking approaches are imprecise knowledge
extractors. Learned fact linking models demonstrate across-the-board
performance improvements (~34.6% F1) over these heuristics. Furthermore,
improved knowledge retrieval yielded average downstream improvements of 9.8%
for a dialogue response generation task. However, fact linking models still
significantly underperform humans, suggesting our benchmark is a promising
testbed for research in commonsense augmentation of NLP systems."
Goal-Conditioned Reinforcement Learning: Problems and Solutions,0.457539,"Goal-conditioned reinforcement learning (GCRL), related to a set of complex
RL problems, trains an agent to achieve different goals under particular
scenarios. Compared to the standard RL solutions that learn a policy solely
depending on the states or observations, GCRL additionally requires the agent
to make decisions according to different goals. In this survey, we provide a
comprehensive overview of the challenges and algorithms for GCRL. Firstly, we
answer what the basic problems are studied in this field. Then, we explain how
goals are represented and present how existing solutions are designed from
different points of view. Finally, we make the conclusion and discuss potential
future prospects that recent researches focus on."
Combining Attention Module and Pixel Shuffle for License Plate Super-Resolution,0.495009,"The License Plate Recognition (LPR) field has made impressive advances in the
last decade due to novel deep learning approaches combined with the increased
availability of training data. However, it still has some open issues,
especially when the data come from low-resolution (LR) and low-quality
images/videos, as in surveillance systems. This work focuses on license plate
(LP) reconstruction in LR and low-quality images. We present a Single-Image
Super-Resolution (SISR) approach that extends the attention/transformer module
concept by exploiting the capabilities of PixelShuffle layers and that has an
improved loss function based on LPR predictions. For training the proposed
architecture, we use synthetic images generated by applying heavy Gaussian
noise in terms of Structural Similarity Index Measure (SSIM) to the original
high-resolution (HR) images. In our experiments, the proposed method
outperformed the baselines both quantitatively and qualitatively. The datasets
we created for this work are publicly available to the research community at
https://github.com/valfride/lpr-rsr/"
Overview of the HASOC Subtrack at FIRE 2022: Offensive Language Identification in Marathi,0.2687,"The widespread of offensive content online has become a reason for great
concern in recent years, motivating researchers to develop robust systems
capable of identifying such content automatically. With the goal of carrying
out a fair evaluation of these systems, several international competitions have
been organized, providing the community with important benchmark data and
evaluation methods for various languages. Organized since 2019, the HASOC (Hate
Speech and Offensive Content Identification) shared task is one of these
initiatives. In its fourth iteration, HASOC 2022 included three subtracks for
English, Hindi, and Marathi. In this paper, we report the results of the HASOC
2022 Marathi subtrack which provided participants with a dataset containing
data from Twitter manually annotated using the popular OLID taxonomy. The
Marathi track featured three additional subtracks, each corresponding to one
level of the taxonomy: Task A - offensive content identification (offensive vs.
non-offensive); Task B - categorization of offensive types (targeted vs.
untargeted), and Task C - offensive target identification (individual vs. group
vs. others). Overall, 59 runs were submitted by 10 teams. The best systems
obtained an F1 of 0.9745 for Subtrack 3A, an F1 of 0.9207 for Subtrack 3B, and
F1 of 0.9607 for Subtrack 3C. The best performing algorithms were a mixture of
traditional and deep learning approaches."
"Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs",0.782825,"The formalization of existing mathematical proofs is a notoriously difficult
process. Despite decades of research on automation and proof assistants,
writing formal proofs remains arduous and only accessible to a few experts.
While previous studies to automate formalization focused on powerful search
algorithms, no attempts were made to take advantage of available informal
proofs. In this work, we introduce Draft, Sketch, and Prove (DSP), a method
that maps informal proofs to formal proof sketches, and uses the sketches to
guide an automated prover by directing its search to easier sub-problems. We
investigate two relevant setups where informal proofs are either written by
humans or generated by a language model. Our experiments and ablation studies
show that large language models are able to produce well-structured formal
sketches that follow the same reasoning steps as the informal proofs. Guiding
an automated prover with these sketches enhances its performance from 20.9% to
39.3% on a collection of mathematical competition problems."
KSG: Knowledge and Skill Graph,0.231202,"The knowledge graph (KG) is an essential form of knowledge representation
that has grown in prominence in recent years. Because it concentrates on
nominal entities and their relationships, traditional knowledge graphs are
static and encyclopedic in nature. On this basis, event knowledge graph (Event
KG) models the temporal and spatial dynamics by text processing to facilitate
downstream applications, such as question-answering, recommendation and
intelligent search. Existing KG research, on the other hand, mostly focuses on
text processing and static facts, ignoring the vast quantity of dynamic
behavioral information included in photos, movies, and pre-trained neural
networks. In addition, no effort has been done to include behavioral
intelligence information into the knowledge graph for deep reinforcement
learning (DRL) and robot learning. In this paper, we propose a novel dynamic
knowledge and skill graph (KSG), and then we develop a basic and specific KSG
based on CN-DBpedia. The nodes are divided into entity and attribute nodes,
with entity nodes containing the agent, environment, and skill (DRL policy or
policy representation), and attribute nodes containing the entity description,
pre-train network, and offline dataset. KSG can search for different agents'
skills in various environments and provide transferable information for
acquiring new skills. This is the first study that we are aware of that looks
into dynamic KSG for skill retrieval and learning. Extensive experimental
results on new skill learning show that KSG boosts new skill learning
efficiency."
Mental Disorders on Online Social Media Through the Lens of Language and Behaviour: Analysis and Visualisation,0.151935,"Due to the worldwide accessibility to the Internet along with the continuous
advances in mobile technologies, physical and digital worlds have become
completely blended, and the proliferation of social media platforms has taken a
leading role over this evolution. In this paper, we undertake a thorough
analysis towards better visualising and understanding the factors that
characterise and differentiate social media users affected by mental disorders.
We perform different experiments studying multiple dimensions of language,
including vocabulary uniqueness, word usage, linguistic style, psychometric
attributes, emotions' co-occurrence patterns, and online behavioural traits,
including social engagement and posting trends. Our findings reveal significant
differences on the use of function words, such as adverbs and verb tense, and
topic-specific vocabulary, such as biological processes. As for emotional
expression, we observe that affected users tend to share emotions more
regularly than control individuals on average. Overall, the monthly posting
variance of the affected groups is higher than the control groups. Moreover, we
found evidence suggesting that language use on micro-blogging platforms is less
distinguishable for users who have a mental disorder than other less
restrictive platforms. In particular, we observe on Twitter less quantifiable
differences between affected and control groups compared to Reddit."
Motion Transformer with Global Intention Localization and Local Movement Refinement,0.435482,"Predicting multimodal future behavior of traffic participants is essential
for robotic vehicles to make safe decisions. Existing works explore to directly
predict future trajectories based on latent features or utilize dense goal
candidates to identify agent's destinations, where the former strategy
converges slowly since all motion modes are derived from the same feature while
the latter strategy has efficiency issue since its performance highly relies on
the density of goal candidates. In this paper, we propose Motion TRansformer
(MTR) framework that models motion prediction as the joint optimization of
global intention localization and local movement refinement. Instead of using
goal candidates, MTR incorporates spatial intention priors by adopting a small
set of learnable motion query pairs. Each motion query pair takes charge of
trajectory prediction and refinement for a specific motion mode, which
stabilizes the training process and facilitates better multimodal predictions.
Experiments show that MTR achieves state-of-the-art performance on both the
marginal and joint motion prediction challenges, ranking 1st on the
leaderboards of Waymo Open Motion Dataset. The source code is available at
https://github.com/sshaoshuai/MTR."
Fine-Grained Scene Graph Generation with Data Transfer,0.752083,"Scene graph generation (SGG) is designed to extract (subject, predicate,
object) triplets in images. Recent works have made a steady progress on SGG,
and provide useful tools for high-level vision and language understanding.
However, due to the data distribution problems including long-tail distribution
and semantic ambiguity, the predictions of current SGG models tend to collapse
to several frequent but uninformative predicates (e.g., on, at), which limits
practical application of these models in downstream tasks. To deal with the
problems above, we propose a novel Internal and External Data Transfer
(IETrans) method, which can be applied in a plug-and-play fashion and expanded
to large SGG with 1,807 predicate classes. Our IETrans tries to relieve the
data distribution problem by automatically creating an enhanced dataset that
provides more sufficient and coherent annotations for all predicates. By
training on the enhanced dataset, a Neural Motif model doubles the macro
performance while maintaining competitive micro performance. The code and data
are publicly available at https://github.com/waxnkw/IETrans-SGG.pytorch."
Robust Speech Recognition via Large-Scale Weak Supervision,0.999121,"We study the capabilities of speech processing systems trained simply to
predict large amounts of transcripts of audio on the internet. When scaled to
680,000 hours of multilingual and multitask supervision, the resulting models
generalize well to standard benchmarks and are often competitive with prior
fully supervised results but in a zero-shot transfer setting without the need
for any fine-tuning. When compared to humans, the models approach their
accuracy and robustness. We are releasing models and inference code to serve as
a foundation for further work on robust speech processing."
Improving Multi-turn Emotional Support Dialogue Generation with Lookahead Strategy Planning,0.149254,"Providing Emotional Support (ES) to soothe people in emotional distress is an
essential capability in social interactions. Most existing researches on
building ES conversation systems only considered single-turn interactions with
users, which was over-simplified. In comparison, multi-turn ES conversation
systems can provide ES more effectively, but face several new technical
challenges, including: (1) how to adopt appropriate support strategies to
achieve the long-term dialogue goal of comforting the user's emotion; (2) how
to dynamically model the user's state. In this paper, we propose a novel system
MultiESC to address these issues. For strategy planning, drawing inspiration
from the A* search algorithm, we propose lookahead heuristics to estimate the
future user feedback after using particular strategies, which helps to select
strategies that can lead to the best long-term effects. For user state
modeling, MultiESC focuses on capturing users' subtle emotional expressions and
understanding their emotion causes. Extensive experiments show that MultiESC
significantly outperforms competitive baselines in both dialogue generation and
strategy planning. Our codes are available at
https://github.com/lwgkzl/MultiESC."
